the last topic of this week is volumetric textures.
the work we introduce here is volumetric illustrations, designing 3d model with internal textures.
so motivation is here.
so we can see carefully designed three dimensional illustration that shows complicated internal structure.
and this kinds illustration is very difficult to generate, and also, it is especially difficult to make it possible to interactively draw this kind of illustration as you cut an object, so that's a goal.
the goal is to design cuttable 3d models.
you have 3d geometry, and whenever you cut, you will get beautiful cross section, that is the goal.
and the program is very difficult to do.
traditional, standard 3d models there is nothing inside, if you cut it is empty.
if you want internal structure, you probably need body metric information however, body metric information is very difficult to generate.
you, essentially you have to paint individual pixel box in x, y, g space one by one.
especially if you want colors.
it's very, too complicated.
you can also use cd scanners or mri to scan but they just give you intensive values and there's no beautiful colors assigned and that's a problem we address and the base guide here is to use picture synthesis technique.
so as soon as you cut the marrow, [unknown] there is nothing inside.
but in the modeling phase, the designer specifies which texture elements to use to generate cross section.
using this information or hint system in the real time synthesizes the real texture.
so from the users point of view, it looks like there is an existing texture inside.
that's the idea.
i'm going to show you a video.
[blank_audio] so here's the system overview.
so you provide input image and then as soon as a user cut a 3d model.
make sure it's empty.
but system synthesis cross section automatically using texture synthesis technique.
so let me fast show you the user interface for browsing.
so here's an input solidity shape, and the user cut the shape and the system synthesizes the cross section and then you get this result.
and if you cut in different way, you get different texture.
so from users point of view, it looks like it has three dimensional textures.
but from the systems point of view, it just paints the cross section.
here's a cucumber, when you cut it, you get cross section everywhere.
so it was browsing interface and now we show the modeling interface.
so the modeling starts with the given 3d surface model, nothing inside just surface.
and the way we'll teach how to synthesize internal texture to the system, so user fast cut, example cross section, and they cut and see the inside.
and they user specifies, which texture type you use, isotopic, orientation or layered, or oriented.
then if the user chooses layered texture, the system asks the user to specify example textures.
say drop image here and the user drag and drop meat photograph.
and the user teaches which particles or image to use.
this is the outside, this is the inside and you'll get this.
and then also, user specify of there is a difference in volume and inside and outside.
and you teach which part of the sodium model is inside or outside.
it is these correspondences, now the system has enough information, and then synthesizes the picture, using the 3d modeling.
now given this information, now we are able to use our cut in different locations, the systems synthesizes it in the appropriate picture.
[blank_audio] in this system we supported three types, three types.
so, first one is isotropic, so there's an orientation.
so, it's the easiest one, like [unknown] or sponge, potato and others.
you just pick a type and then log on with a single texture, or orientation.
and then since this is automatically starts, like this.
the second one is layered structure, such as, carrots, or cakes, and others.
and this is also a layered structure.
and here is a select the layer picture, and then get an image, another set as we've already seen, use the space files inside or outside.
or top and bottom and you also need to space away the same thing for the 3d eh, geometry.
top and bottom.
and now we know the correspondence between difference images and the 3d geometry, and then system starts to synthesize the texture of our chocolate cake.
the same thing for carrot, you can specify inside, outside and the inside, outside for 3d shape.
and the system synthesizes the shape, texture.
the final one is oriented textures, like this bamboo shape.
bamboo fibers have a specific orientation.
so in that case user needs to specify the orientation of fibers.
so user input is two dimensional texture of a horizontal cut and then you get three dimensional volume difference, and then user specifies the orientation.
so here, user draws lines here and then orientation of hair is automatically generated, and the system synthesizes the texture along with orientation.
[blank_audio] sorry it's a little bit difficult to see in this presentation, but i hope you see, for example, more lines here and lots of dots here, and so.
and here is an example, modeling example, so you have a three dimensional tooth model.
first there is nothing inside, then you pick up a photograph of the insulation and then you put, specified additions and then you will get the body metric texture for a tooth.
that's it.
and here's a couple of results, like cucumber, or a donut, or bamboo, or tooth.
and, as i said, modelling phase, you use a specified how to paste the image to the 3d model from the closed section, by specifying outside, inside, and so on.
another way is like this.
so for the reference image, use a space slice inside and outside and then you compute the control mark, kind of diffusion over the distance from inside.
and then also you get the same control map for the cross-section.
for the information or notation given to the 3-d shape.
and then, given this to information system generates a synthesize cross section using textures synthesis algorithm.
and let me briefly describe the texture synthesis algorithm.
texture synthesis is a very popular technique in computer graphics.
and it generates a larger texture from input smaller texture.
and when our original paper was published in 99, and the basic idea is very, very simple.
so, for synthesising a new texture from each individual pixel, you just searches for the similar context pixel in the left virus.
and of you find a more similar one, just get a color or the more similar pixel just to cut into the frame.
so, just by repeating this many times starting from a [unknown] you get very, very realistic texture.
and this technique is very frequently used and recently, already used in commercial products.
so yeah, so original paper was published in 2004 as volumetric illustrations and texture synthesis, a lot of papers, but original paper was texture synthesis in iccv, '99.
and if you want to now the recent ones, a famous one is patchmatch.
published in 2009, and this is currently used in photoshop, and those applications.
there are a couple more, recent 3d picture in solid texture and not solid textures .and so these may be interesting for you.
thank you.
okay so this is the end of 3d modeling.
we introduced suggestive interface, sketch-based modeling, shape control by curves, and volumetric textures and let me go back to the initial discussion.
so the challenge in 3d modeling is how to compliment missing information, mainly depth or z bodies.
an approach is to user a design user interface, an automatic inference leveraging domain specific knowledge.
so, in the examples we show today, you know, for architecture modeling we use hard-coded rules for design for architecture models.
and for [unknown] organic shapes, we use the inflation algorithms, elimination [unknown] sets, so target is smooth.
and for all our modeling, we deduct very specialized structure and zooming in the editors.
and for cross sections, we use texture synthesis outwards.
yeah, thank you.
