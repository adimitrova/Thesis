The last topic of this week is volumetric
textures. The work we introduce here is volumetric illustrations, designing 3D model with
internal textures. So motivation is here. So we can see carefully designed three dimensional illustration that shows
complicated internal structure. And this kinds illustration is very
difficult to generate, and also, it is especially
difficult to make it possible to interactively draw this
kind of illustration as you cut an object, so that's a goal. The goal is to design cuttable 3D models. You have 3D geometry, and whenever you
cut, you will get beautiful cross section, that is
the goal. And the program is very difficult to do. Traditional, standard 3D models there is
nothing inside, if you cut it is empty. If you want internal structure, you
probably need body metric information However, body metric
information is very difficult to generate. You, essentially you have to paint
individual pixel box in x, y, g space one by one. Especially if you want colors. It's very, too complicated. You can also use CD scanners or MRI to
scan but they just give you intensive values
and there's no beautiful colors assigned and that's a
problem we address and the base guide here is to use picture
synthesis technique. So as soon as you cut the marrow,
[UNKNOWN] there is nothing inside. But in the modeling phase, the designer
specifies which texture elements to use to generate
cross section. Using this information or hint system in the real time synthesizes the real
texture. So from the users point of view, it looks
like there is an existing texture inside. That's the idea. I'm going to show you a video. [BLANK_AUDIO] So here's the system overview. So you provide input image and then as
soon as a user cut a 3D model. Make sure it's empty. But system synthesis cross section automatically using texture synthesis
technique. So let me fast show you the user interface
for browsing. So here's an input solidity shape, and the
user cut the shape and the system synthesizes the cross
section and then you get this result. And if you cut in different way, you get
different texture. So from users point of view, it looks like
it has three dimensional textures. But from the systems point of view, it
just paints the cross section. Here's a cucumber, when you cut it, you
get cross section everywhere. So it was browsing interface and now we show the modeling
interface. So the modeling starts with the given 3D surface model, nothing inside just
surface. And the way we'll teach how to synthesize
internal texture to the system, so user fast cut, example cross section, and they
cut and see the inside. And they user specifies, which texture
type you use, isotopic, orientation or layered,
or oriented. Then if the user chooses layered texture,
the system asks the user to specify example
textures. Say drop image here and the user drag and
drop meat photograph. And the user teaches which particles or
image to use. This is the outside, this is the inside
and you'll get this. And then also, user specify of there is a difference in volume and inside and
outside. And you teach which part of the sodium
model is inside or outside. It is these correspondences, now the
system has enough information, and then synthesizes the picture, using
the 3D modeling. Now given this information, now we are
able to use our cut in different locations, the systems
synthesizes it in the appropriate picture. [BLANK_AUDIO] In this system we supported three types,
three types. So, first one is Isotropic, so there's an
orientation. So, it's the easiest one, Like [UNKNOWN]
or sponge, potato and others. You just pick a type and then log on with
a single texture, or orientation. And then since this is automatically
starts, like this. The second one is layered structure, such as,
carrots, or cakes, and others. And this is also a layered structure. And here is a select the layer picture,
and then get an image, another set as we've already seen, use the
space files inside or outside. Or top and bottom and you also need to space away the same thing for the 3D eh,
geometry. Top and bottom. And now we know the correspondence between
difference images and the 3D geometry, and then system starts to synthesize the texture of our chocolate
cake. The same thing for carrot, you can specify inside, outside and the inside, outside
for 3D shape. And the system synthesizes the shape,
texture. The final one is oriented textures, like this bamboo shape. Bamboo fibers have a specific orientation. So in that case user needs to specify the
orientation of fibers. So user input is two dimensional texture
of a horizontal cut and then you get three dimensional
volume difference, and then user specifies the
orientation. So here, user draws lines here and then
orientation of hair is automatically generated, and the system synthesizes the
texture along with orientation. [BLANK_AUDIO] Sorry it's a little bit difficult to see
in this presentation, but I hope you see, for example, more lines here and
lots of dots here, and so. And here is an example, modeling example, so you have a three dimensional tooth
model. First there is nothing inside, then you pick up a photograph of the insulation and then you put, specified additions and then you will get the body metric texture for a tooth. That's it. And here's a couple of results, like
cucumber, or a donut, or bamboo, or tooth. And, as I said, modelling phase, you use a
specified how to paste the image to the 3D model from the closed section, by
specifying outside, inside, and so on. Another way is like this. So for the reference image, use a space
slice inside and outside and then you compute the control mark, kind of
diffusion over the distance from inside. And then also you get the same control map
for the cross-section. For the information or notation given to
the 3-D shape. And then, given this to information system
generates a synthesize cross section using textures
synthesis algorithm. And let me briefly describe the texture
synthesis algorithm. Texture synthesis is a very popular
technique in computer graphics. And it generates a larger texture from
input smaller texture. And when our original paper was published
in 99, and the basic idea is very, very
simple. So, for synthesising a new texture from
each individual pixel, you just searches for the similar
context pixel in the left virus. And of you find a more similar one, just
get a color or the more similar pixel just to
cut into the frame. So, just by repeating this many times
starting from a [UNKNOWN] you get very, very
realistic texture. And this technique is very frequently used and recently, already used in commercial
products. So yeah, so original paper was published in 2004 as Volumetric Illustrations and
Texture Synthesis, a lot of papers, but original
paper was Texture Synthesis in ICCV, '99. And if you want to now the recent ones, a
famous one is PatchMatch. Published in 2009, and this is currently
used in Photoshop, and those applications. There are a couple more, recent 3D picture
in solid texture and not solid textures .And so these may be
interesting for you. Thank you. Okay so this is the end of 3D Modeling. We introduced suggestive interface,
sketch-based modeling, shape control by curves, and volumetric textures and let me
go back to the initial discussion. So the challenge in 3D modeling is how to compliment missing information, mainly
depth or z bodies. An approach is to user a design user interface, an automatic inference
leveraging domain specific knowledge. So, in the examples we show today, you
know, for architecture modeling we use hard-coded
rules for design for architecture models. And for [UNKNOWN] organic shapes, we use
the inflation algorithms, elimination
[UNKNOWN] sets, so target is smooth. And for all our modeling, we deduct very specialized structure and zooming in
the editors. And for cross sections, we use texture
synthesis outwards. yeah, thank you.