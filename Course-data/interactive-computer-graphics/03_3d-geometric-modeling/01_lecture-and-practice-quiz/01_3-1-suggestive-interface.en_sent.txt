[sound] hi, this is interactive computer graphics, week three.
the topic we discuss here is 3d geometric modeling.
so the challenge behind this is user interface is still mostly two-dimensional.
so, the question is how to compliment in missing information?
so, mainly depths here.
so use [unknown] 2d and how to get 3d from 2d.
there's lots of problem with our progress here.
our solution, in general, is a user interface, an automatic inference leveraging domain specific knowledge.
so if you do not know what you do, it's almost impossible to infer dips, but if you know what you want to do, if you limit the domain and you can get reasonable results.
that's the basic idea behind the works i will introduce here.
and here are the topics that we will discuss in this week.
so first one is suggestive user interface for modeling of architectural models.
and then there's sketch-based modeling of larger and stuffed things.
and then we discuss shape control by curves, and then flower modeling, and then volumetric texture synthesis.
the first one is suggestive interface.
so, the work was published as chateau, a suggestive interface for 3d modeling.
the motivation is here.
so current graphical user interface is dominated through these many buttons, menus, and even more, nested menus.
it's very hard to find design command [unknown].
[unknown] about the operation on what you want to do on the main screen, the main field.
so if we were working on 3d modeling and if you want to do related to these three elements in the scene you can just highlight these three, which hints the computer to infer the request.
and then computer looks at the hints, and then provides proposal, for the data operations.
in this case, the system proposes a box, and those are our two possibilities.
so, in other words, review the first given arguments for the command, and then system automatically infer the command.
so let me show you a demo.
so here is a three-dimensional modeling system with a 3d space inside, and then you can sketch lines in this way.
but here, instead of using many commands on the menu.
we simply allow the user to highlight lines.
and then, for these highlights or hints, system pro, pro presents some suggestions.
well, why is drawing a plane and another is drawing triangle, the other is drawing a left angle.
and you can also ignore them and then create more.
and then given the in-sweep of [unknown] lines, system predicts, or suggests to make a rectangle, a box.
and then, again, if you do a line here, then given this hint, system suggests to cut a box.
you can also go back and then add more lines.
and then given this hint, system suggests to cut a corner.
so in this way, user provides the hints to the system and then the system presents suggestions.
so, this way, user does not really quiet the space [unknown] one, in the huge command [unknown], and then you can forecast the visual content of the task.
and if you highlight this, then the system predicts, or suggests drawing plane, and the user draws for example rectangle, triangle here.
and if you highlight these three, system suggests to make a face inside.
and then if you highlight one more, the system suggests extrusion.
and one interesting operation is like this one.
if you highlight these two and also one line here, about a third.
and this is, it was exactly dividing to the three.
we use again also the line somewhere here, and this is [unknown] divided into four.
so in this way a user can generate this kind of diagram just by, computing operations.
[blank_audio] and after some time operations, you can get these kinds of results.
and this kind of operation is very useful for repetitions, and also some symmetric structures and so on.
now, let me describe, briefly describe, the implementation behind the, system.
so, this is the input scene.
so highlighted elements and then no highlighted elements.
so, taking this example input scene then system is equipped with multiple suggestion engines, they kind of parallel engines working independently and then each engine consists of two parts.
one is examination part and one other is generator.
and the examiner examines the scene, and then tests whether the scene matches with expected rule.
and then if it passes examination, and then the generator generates the resulting scene.
so this is a very hardcoded program, program module provided the programmer.
but they all works in parallel.
and then specific engine and the act of specific input configuration.
and here's our list of suggestion engines.
we input method in this application.
one is [unknown] given a hint.
system generator [unknown] passing through the hint.
and also if you highlight closed roof, it suggest polygon, perpendicular two lines suggest rectangle, [unknown] suggest a box, and system suggest extrusion and pyramid shape.
now these are resizing and bridges, connecting two, two polygons and the extrusion and this is a cutting out and also corner cutting and trimming and intersection, duplication, repetition, mirror image and so on.
and the philosophy or concept is defined as this.
standard user interface is like this.
so the user provides very explicit command or very explicit instruction to the computer.
and then the computer just blindly, simply follows the instruction.
however, what we provide is more friendly, human to human like interactions.
so the user is working on the visual task directly, and then computer implicitly observes the action and then provides help and solution, and i think this kind of walking style can be useful.
one possible application is like this, so in your powerpoint or in any presentation, you have alignment show.
alignment to is hidden somewhere in the menu, and it's not easy to find.
for example, in this powerpoint, you can get there from some way around.
home, and somewhere, i don't know [laugh] height, alignment, and somewhere.
but it's not easy to find.
however, if you highlight these four almost aligned element, i think it's pretty reasonable, and also useful for the system suggest particular alignment, in align left or align center, and suggest to the user.
and if the user likes it, then it just create it, and it gets the result.
and this can be a very powerful help for the user.
so that's it and the original paper was published in 2001. and this work, our work is strongly inspired by a previous system called the sketch system.
so this sketch system takes two dimensional gestures and the system will automatically generate this kind of three dimensional scene.
so what they do is very interesting.
so you input this 2d and you need to infer 3d position.
to do it the system uses a [unknown] of every object that has to be put on top of every object.
in this way, the computer computes 3d depths and measures.
showing multiple candidates for values to choose is also presented before, the presented work is called design galleries and published in 1997. i also recommend you to take a look at this work.
thank you.
