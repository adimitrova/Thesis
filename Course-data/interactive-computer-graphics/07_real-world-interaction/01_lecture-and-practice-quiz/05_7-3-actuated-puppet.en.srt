1
00:00:00,310 --> 00:00:02,330
Our next topic is Actuated Puppet.

2
00:00:04,570 --> 00:00:08,710
The what we introduce here is an Actuated
Physical Puppet as an Input Device for

3
00:00:08,710 --> 00:00:10,480
Controlling a Digital Manikin.

4
00:00:10,480 --> 00:00:16,150
The Motivation here is that 3D
character posing is difficult.

5
00:00:17,320 --> 00:00:21,690
So, suppose you have a character
that you want to set the posing.

6
00:00:21,690 --> 00:00:24,770
And the most popular approach
I think is 3D widgets.

7
00:00:24,770 --> 00:00:27,570
On the screen,
you have a widget like this, and

8
00:00:27,570 --> 00:00:31,860
you use a mouse to control
individual joy dongles.

9
00:00:31,860 --> 00:00:35,690
However, this is very tedious to
control individual joint dongles.

10
00:00:35,690 --> 00:00:40,160
For each joint, you have three angles,
one by one, can take much time.

11
00:00:40,160 --> 00:00:42,570
Another approach is the Motion capture.

12
00:00:42,570 --> 00:00:45,300
You have a capture device and a unit.

13
00:00:45,300 --> 00:00:47,760
However, you need dedicated environment,
and

14
00:00:47,760 --> 00:00:50,680
that you also need a skilled actor, actor.

15
00:00:50,680 --> 00:00:54,210
And also another possibility is
to use Physical Input Device.

16
00:00:54,210 --> 00:00:55,350
This is very convenient.

17
00:00:55,350 --> 00:00:59,010
You can grab a Puppet and
then pose, and you get the 3D view.

18
00:00:59,010 --> 00:01:01,520
So you can use both
hands can be very good.

19
00:01:01,520 --> 00:01:06,150
However standard physical
input devices very stiff.

20
00:01:06,150 --> 00:01:10,740
You know if you, if it to relax,
it cannot hold a pose.

21
00:01:10,740 --> 00:01:14,920
And if its stiff enough to hold a pose,
it's very hard to control.

22
00:01:14,920 --> 00:01:18,220
And also you have to control,
manually, space for

23
00:01:18,220 --> 00:01:21,400
all joint angles,
which is inconvenient, in some cases.

24
00:01:23,040 --> 00:01:27,500
So, our approach is to add
several motors to each joint, so

25
00:01:27,500 --> 00:01:29,500
we get an Actuated Physical Puppet.

26
00:01:29,500 --> 00:01:32,768
So we not only use Puppet as input device,
but

27
00:01:32,768 --> 00:01:38,622
also the device reacts to the physical
batch of data to provide active feedback.

28
00:01:39,790 --> 00:01:41,580
And there are couple benefits to it.

29
00:01:41,580 --> 00:01:45,560
First, it's easy to load
existing pose into the robot, so

30
00:01:45,560 --> 00:01:49,790
you can start from existing
pose to accelerate posing.

31
00:01:49,790 --> 00:01:51,730
So it's one benefit.

32
00:01:51,730 --> 00:01:55,200
Another is intelligent
gravitational compensation.

33
00:01:55,200 --> 00:01:56,680
Here's a little bit explanation.

34
00:01:56,680 --> 00:02:01,550
As I said, if the joint is all free,
it's easy to control.

35
00:02:01,550 --> 00:02:06,080
But you know,
the it cannot hold it's posture.

36
00:02:06,080 --> 00:02:08,193
So it's inconvenient to And

37
00:02:08,193 --> 00:02:12,270
then another approach is always
approach turn off the sabo motors.

38
00:02:12,270 --> 00:02:13,830
Then it can be too stiff.

39
00:02:13,830 --> 00:02:18,780
It can hold existing pose, like this legs.

40
00:02:18,780 --> 00:02:25,350
However as a negative side it very
hard to control, change a pose.

41
00:02:25,350 --> 00:02:30,880
So what we do is, adaptively do it,
intelligent gravitational compensation.

42
00:02:30,880 --> 00:02:35,450
So if you do not touch this arm,
these legs, its con,

43
00:02:35,450 --> 00:02:41,160
fixed by a sabo motor by producing
a power against grav, gravity.

44
00:02:41,160 --> 00:02:44,520
However, if the user start
to manipulating the joint,

45
00:02:44,520 --> 00:02:46,830
the system automatically detects it.

46
00:02:46,830 --> 00:02:50,010
And then automatically turns
off some sabo motors, so

47
00:02:50,010 --> 00:02:53,510
you can push a berry with
very light weight force.

48
00:02:53,510 --> 00:02:57,880
So, that is intelligent
gravitational compensation.

49
00:02:57,880 --> 00:03:01,800
And then finally,
we also implemented active guidance,

50
00:03:01,800 --> 00:03:03,890
using measured human data.

51
00:03:03,890 --> 00:03:08,440
And this consist of joint coupling,
and data driven inverse kinematics.

52
00:03:08,440 --> 00:03:10,280
Let me describe a little bit more.

53
00:03:10,280 --> 00:03:14,799
So joint coupling is two
joints work together.

54
00:03:14,799 --> 00:03:20,840
What's easy to understand the example
is this hip joint, and knee joint.

55
00:03:20,840 --> 00:03:24,140
You know,
as you know if you move your leg.

56
00:03:24,140 --> 00:03:28,745
Upwards you if you control hip joint,
then knee joint also follows, right?

57
00:03:28,745 --> 00:03:35,360
It's very hard to keep the legs
straight as you rotate the hip joint.

58
00:03:35,360 --> 00:03:37,645
So, if you rotate the hip joint,

59
00:03:37,645 --> 00:03:41,490
it's very natural to also
bend the knee joint together.

60
00:03:41,490 --> 00:03:43,140
So, this is joint coupling.

61
00:03:43,140 --> 00:03:45,400
And with actuation you can do it,
you know,

62
00:03:45,400 --> 00:03:50,310
if you control the hip joint, the system
will automatically rotate the knee joint.

63
00:03:50,310 --> 00:03:52,140
This is joint coupling,

64
00:03:52,140 --> 00:03:58,170
which is very useful to generate
very natural human posture.

65
00:03:58,170 --> 00:04:02,554
So this one automatically avoids,
unnatural configuration.

66
00:04:02,554 --> 00:04:05,860
The another is,
data driven inverse kinematics.

67
00:04:05,860 --> 00:04:08,910
If you just control position.

68
00:04:08,910 --> 00:04:13,780
For example, suppose you control
the fingertip, and they go downwards, and

69
00:04:13,780 --> 00:04:18,370
if you apply simple inverse
kinematics result is like this.

70
00:04:18,370 --> 00:04:20,370
So it's mechanical value.

71
00:04:20,370 --> 00:04:22,520
Geometric, geometrically bodied.

72
00:04:22,520 --> 00:04:24,840
Finger tip follows the user control.

73
00:04:24,840 --> 00:04:30,900
However, joint only rotates along the alo,
along the arm.

74
00:04:30,900 --> 00:04:36,210
And then, resulting pose is very strange,
a unnatural force.

75
00:04:36,210 --> 00:04:38,470
And instead of that, we use data.

76
00:04:38,470 --> 00:04:43,800
We measure up, lots of natural
reaching gesture, over humour.

77
00:04:43,800 --> 00:04:47,290
And the user synthesize
appropriate motion.

78
00:04:47,290 --> 00:04:50,870
So here if the user pull down
the fingertip downwards, and

79
00:04:50,870 --> 00:04:54,300
then the character, the robot,
automatically puppet

80
00:04:56,070 --> 00:04:59,440
moves making a very natural motion,
using data.

81
00:05:00,820 --> 00:05:02,285
So, let me show you a video.

82
00:05:08,227 --> 00:05:13,400
So as I said Physical Puppet not only
controls a physical body of character,

83
00:05:13,400 --> 00:05:17,661
also body of character provides
feedback to the Physical Puppet to

84
00:05:17,661 --> 00:05:19,965
guide not to oppose anything.

85
00:05:26,456 --> 00:05:30,050
[INAUDIBLE] To the eight degrees
of freedom and connect to the PC.

86
00:05:34,760 --> 00:05:37,335
Yeah so primarily it's an input device.

87
00:05:37,335 --> 00:05:41,130
You control the pulse, and then you
sink [INAUDIBLE] up the same pulse.

88
00:05:42,220 --> 00:05:45,796
So this provides a very intuitive way,
of controlling character posture.

89
00:05:49,772 --> 00:05:53,530
This can be very tedious,
if you use two dimensional mouse.

90
00:05:53,530 --> 00:05:56,620
And one benefit of using sabo motors is,

91
00:05:56,620 --> 00:05:59,710
uploading pre defined postures
into a robot, our puppet.

92
00:06:01,370 --> 00:06:05,400
So, you can get pre-defined
postures in to the puppet.

93
00:06:05,400 --> 00:06:07,390
So this is a very good starting point for

94
00:06:07,390 --> 00:06:11,330
design, and
then this is Gravitational Compensation.

95
00:06:11,330 --> 00:06:16,730
You know, if the Torque is OFF to relax
then it cannot hold a given posture,

96
00:06:16,730 --> 00:06:18,400
you know, if you release it goes down.

97
00:06:19,480 --> 00:06:23,790
And on the other hand, if you to,
always turn on the torque power,

98
00:06:23,790 --> 00:06:27,220
then it can hold the posture,
but, very rigid, you know?

99
00:06:27,220 --> 00:06:28,380
You need strong power.

100
00:06:30,433 --> 00:06:31,475
To rotate.

101
00:06:31,475 --> 00:06:35,530
And this is a result of
automatic gravity compensation.

102
00:06:35,530 --> 00:06:37,370
So as you start pushing.

103
00:06:37,370 --> 00:06:39,470
The system turns off the power.

104
00:06:39,470 --> 00:06:43,590
So, you can change the pose,
with very light weight force.

105
00:06:43,590 --> 00:06:46,305
But also,
system can hold the posture after release.

106
00:06:52,965 --> 00:06:55,662
And then,
this is a result of Data-driven IK.

107
00:06:55,662 --> 00:06:58,510
So, if the Data-driven IK is turned off.

108
00:06:58,510 --> 00:07:00,555
The motion is very unnatural.

109
00:07:00,555 --> 00:07:05,530
It's very robotic motion, because the
robot doesn't change entire body shape.

110
00:07:05,530 --> 00:07:10,656
However.
If you turn on the inverse driven,

111
00:07:10,656 --> 00:07:15,770
Data-driven IK,
then the resulting motion is vary natural.

112
00:07:15,770 --> 00:07:20,550
So user control the fingertip, and then
system automatically bend his legs and

113
00:07:20,550 --> 00:07:24,280
then move the head and other arm.

114
00:07:24,280 --> 00:07:25,920
And this is a joint coupling.

115
00:07:25,920 --> 00:07:28,611
The user is controlling the hip joint, and

116
00:07:28,611 --> 00:07:32,591
the system automatically
controls knee joint, so.

117
00:07:38,582 --> 00:07:41,205
So, let me show you a couple
application scenarios.

118
00:07:41,205 --> 00:07:46,930
So, suppose you design in car seat, and
then the visibility should be preserved.

119
00:07:46,930 --> 00:07:48,270
So this, in this way,

120
00:07:48,270 --> 00:07:53,050
you can intuitively control the detail
monitoring in the car environment.

121
00:07:53,050 --> 00:07:56,070
And you can check the here,
is reachability.

122
00:07:56,070 --> 00:08:00,274
So you can check whether this puppet
can meet specific target in the car.

123
00:08:05,116 --> 00:08:07,020
So this one is load assessment.

124
00:08:07,020 --> 00:08:12,890
So this led indicates where the power
is necessary to hold the posture.

125
00:08:12,890 --> 00:08:15,110
So, this is useful for
analysis of environment.

126
00:08:15,110 --> 00:08:19,360
And this is a Visibility analysis.

127
00:08:19,360 --> 00:08:22,249
So by changing the posture of puppet,

128
00:08:22,249 --> 00:08:25,884
we can see which part of
the environment the puppet can see.

129
00:08:29,584 --> 00:08:32,473
So that's the idea.

130
00:08:32,473 --> 00:08:35,240
So let be briefly describe the algorithm.

131
00:08:35,240 --> 00:08:41,230
Specifically, I will briefly describe how
to do Data-driven Inverse-Kinematics.

132
00:08:41,230 --> 00:08:44,110
So as I said,
Data-driven I case like this.

133
00:08:44,110 --> 00:08:51,120
If you move a fingertip, then the puppet
makes a very natural human like motion.

134
00:08:51,120 --> 00:08:52,150
In order to do so.

135
00:08:53,540 --> 00:08:54,750
We get data.

136
00:08:54,750 --> 00:08:58,860
But let me first describe
Inverse-Kinematics in general.

137
00:08:58,860 --> 00:09:03,010
So in that Inverse-Kinematics,
is a very fundamental program,

138
00:09:03,010 --> 00:09:05,950
in character animation or
also in robotics.

139
00:09:05,950 --> 00:09:09,080
So suppose you have this kind of arc,
you have a base here,

140
00:09:09,080 --> 00:09:13,200
and then you have joint one,
joint two and joint three.

141
00:09:13,200 --> 00:09:15,490
And you have each joint angles.

142
00:09:15,490 --> 00:09:18,800
So, Forward Kinematics
is the standard way.

143
00:09:18,800 --> 00:09:23,550
So, given joint angles,
you get the position of the fingertip.

144
00:09:23,550 --> 00:09:28,050
So, this is fairly deterministic
single computation.

145
00:09:28,050 --> 00:09:33,100
However, what people usually want
to do is to specify target x,

146
00:09:33,100 --> 00:09:34,970
y position of fingertip.

147
00:09:34,970 --> 00:09:37,700
And then try to convert
appropriate joint angles.

148
00:09:37,700 --> 00:09:42,690
This is very infrequently
occurring problem to solve.

149
00:09:42,690 --> 00:09:46,890
And then it looks like this, given x,
y, you have gone to joint angles.

150
00:09:46,890 --> 00:09:50,520
This is inverse problem,
which is very difficult to solve.

151
00:09:50,520 --> 00:09:51,870
For many solutions,

152
00:09:51,870 --> 00:09:57,850
many other And there are couple
possible ways like purely geometric.

153
00:09:57,850 --> 00:10:02,780
So something like, minimize a change
from the current configuration or

154
00:10:02,780 --> 00:10:09,045
physically most you know, physically most
plausible shape, or as a data-driven.

155
00:10:09,045 --> 00:10:11,010
And Data-driven is a method we use.

156
00:10:12,530 --> 00:10:14,010
So, we do some synaptics.

157
00:10:14,010 --> 00:10:19,230
In the motion capture environment,
we ask for the person to reach many places

158
00:10:19,230 --> 00:10:24,730
around his body, and then we measure all
the postures, to get always position.

159
00:10:24,730 --> 00:10:29,720
So you get many data like this, x, y,
z position, and joint angles, x, y,

160
00:10:29,720 --> 00:10:31,390
z position, and joint angles.

161
00:10:31,390 --> 00:10:34,060
We get many data of these samples.

162
00:10:34,060 --> 00:10:38,530
And after that user input is
target fingertip location.

163
00:10:38,530 --> 00:10:42,160
And then we are identify
the nearby samples.

164
00:10:42,160 --> 00:10:43,540
And then just blend them together.

165
00:10:43,540 --> 00:10:46,010
And then you'll get,
a desired joint angle.

166
00:10:46,010 --> 00:10:49,493
So this is what we do in
the Data-driven Inverse-Kinematics.

167
00:10:51,790 --> 00:10:52,780
So here's the summary.

168
00:10:52,780 --> 00:10:57,690
So we presented, I presented actuated
puppet device for character posing.

169
00:10:57,690 --> 00:11:01,570
The user controls a virtual character,
using physical puppet, and

170
00:11:01,570 --> 00:11:04,260
also gets feedback from the system.

171
00:11:04,260 --> 00:11:08,700
And one important feature is
intelligent gravity compensation, and

172
00:11:08,700 --> 00:11:11,670
active guidance from the system.

173
00:11:11,670 --> 00:11:15,040
And we, I present
the Data-driven Inverse Kinematics.

174
00:11:15,040 --> 00:11:17,920
So, we take many snapshots, example for

175
00:11:17,920 --> 00:11:21,130
this, and then blend them
together to get natural posture.

176
00:11:23,880 --> 00:11:26,680
So, to learn more,
original paper is titles,

177
00:11:26,680 --> 00:11:31,280
An Actuated Physical Puppet as an Input
Device for Controlling a Digital Manikin.

178
00:11:32,340 --> 00:11:36,650
And if you want to know more about
the previous standard puppet devices,

179
00:11:36,650 --> 00:11:38,150
there's two papers.

180
00:11:38,150 --> 00:11:39,950
Dinosaur Input Device.

181
00:11:39,950 --> 00:11:41,830
And those of mice and donkeys, and

182
00:11:41,830 --> 00:11:44,920
specialize in the device for
[INAUDIBLE] for the animations.

183
00:11:46,410 --> 00:11:50,370
And Inverse Kinematics, as I said,
lots of work on these topics.

184
00:11:50,370 --> 00:11:53,340
So example base like is this one.

185
00:11:53,340 --> 00:11:57,580
Artist Directed Inverse Kinematics using
Gladiator basis function interpolation.

186
00:11:57,580 --> 00:12:02,700
So this is an example of
a Data-driven Inverse ICAD.

187
00:12:02,700 --> 00:12:05,370
And also there is a geometric approach.

188
00:12:05,370 --> 00:12:09,370
So natural Motion, Animation Solute
Constraining, and Deconstraining at will.

189
00:12:09,370 --> 00:12:12,650
So this one introduces
a purely geometric approach,

190
00:12:12,650 --> 00:12:16,590
to get natural posture
from finger tip positions.

191
00:12:18,380 --> 00:12:19,560
That's it for this week.

192
00:12:19,560 --> 00:12:21,894
I guess [INAUDIBLE].