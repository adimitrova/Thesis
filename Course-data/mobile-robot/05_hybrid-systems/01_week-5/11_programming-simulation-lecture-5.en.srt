1
00:00:02,030 --> 00:00:04,190
Welcome back.
This is week five.

2
00:00:04,190 --> 00:00:08,430
In week three we wrote a controller to
take our robot from point A to point B.

3
00:00:08,430 --> 00:00:10,660
This was called the go-to-goal controller.

4
00:00:10,660 --> 00:00:14,210
And in week four we designed a controller
that avoids obstacles.

5
00:00:14,210 --> 00:00:17,410
So, what we want to do this week is
combine those two.

6
00:00:17,410 --> 00:00:19,970
So that our robot can drive from some
point in the world to

7
00:00:19,970 --> 00:00:23,099
some other point in the world without
colliding with any of the obstacles.

8
00:00:24,280 --> 00:00:27,280
And the way that we're going to do that is
to arbitrate

9
00:00:27,280 --> 00:00:30,070
between the go-to-goal and avoid-obstacle
controller.

10
00:00:30,070 --> 00:00:32,650
And that really means, think about how
should we

11
00:00:32,650 --> 00:00:35,430
combine these two so that we make the
right decision.

12
00:00:35,430 --> 00:00:37,930
Should we be, should we be avoiding
obstacles?

13
00:00:37,930 --> 00:00:40,950
Or should we be going to goal?

14
00:00:40,950 --> 00:00:45,960
So the two techniques that we're going to
be using is blending and hard switching.

15
00:00:45,960 --> 00:00:48,545
And in blending what we're going to do is
we're going to

16
00:00:48,545 --> 00:00:52,285
create a new controller which combines
both the go-to-goal controller and the

17
00:00:52,285 --> 00:00:53,790
avoid-obstacle controller.

18
00:00:53,790 --> 00:00:56,520
Then what we're also going to test is

19
00:00:56,520 --> 00:00:59,220
switching between the go-to-goal and the
avoid-obstacle controller.

20
00:00:59,220 --> 00:01:01,320
So we'll either run the go-to-goal
controller

21
00:01:01,320 --> 00:01:03,660
or we'll run the avoid-obstacle
controller, and we'll

22
00:01:03,660 --> 00:01:08,130
switch back and forth depending on whether
the robot is close to an obstacle or not.

23
00:01:09,230 --> 00:01:11,870
And then we're going to do a third
experiment, which is

24
00:01:11,870 --> 00:01:14,900
to use the blended controller as an
intermediary between the two.

25
00:01:14,900 --> 00:01:17,310
So we're going to go to goal when we're
away

26
00:01:17,310 --> 00:01:18,940
from any obstacles, if we're getting close

27
00:01:18,940 --> 00:01:21,410
to obstacles, we'll switch to the blended
controller.

28
00:01:21,410 --> 00:01:24,450
And if we're within a dangerous distance
of the obstacle,

29
00:01:24,450 --> 00:01:30,660
we'll switch over to the intermed, into
the avoid-obstacles controller.

30
00:01:30,660 --> 00:01:33,780
So, what do we do when we, when we, when
we blend?

31
00:01:33,780 --> 00:01:37,030
What we're going to do is create one
single controller that does both.

32
00:01:38,050 --> 00:01:42,490
And what we'll do is first compute our
go-to-goal vector which is U

33
00:01:42,490 --> 00:01:48,390
gtg, and then we're going to compute the
obstacle avoidance vector, U ao.

34
00:01:48,390 --> 00:01:51,900
And we will know how to compute both of
those from the previous weeks.

35
00:01:51,900 --> 00:01:55,250
And what we want to do is we want to
combine these two in some way.

36
00:01:55,250 --> 00:02:01,350
And, one way to combine these two is to do
this in a linear fashion.

37
00:02:01,350 --> 00:02:03,200
So, what I'm going to do is take a

38
00:02:03,200 --> 00:02:07,950
fraction of the obstacle-avoidance vector
and take another fraction of

39
00:02:07,950 --> 00:02:10,870
the go-to-goal vector and just add them
together.

40
00:02:10,870 --> 00:02:17,130
And then what I should get is this vector
U ao go-to-goal.

41
00:02:17,130 --> 00:02:20,820
So so this is a combination of these two
vectors.

42
00:02:20,820 --> 00:02:25,390
And this vector will point us in some
direction that is both somewhat in

43
00:02:25,390 --> 00:02:29,170
the direction of the goal, and somewhat in
the direction away from the obstacle.

44
00:02:30,380 --> 00:02:33,050
And what I really want to point out here
too, is that I'm

45
00:02:33,050 --> 00:02:37,670
using u ao,n, and that just denotes that

46
00:02:37,670 --> 00:02:41,100
fact that I'm using the normalized version
of the

47
00:02:41,100 --> 00:02:44,970
vector, and that's nothing but, taking the
vector itself

48
00:02:44,970 --> 00:02:47,460
and dividing it by the magnitude of the
vector.

49
00:02:47,460 --> 00:02:49,550
And that way you get, a vector that's

50
00:02:49,550 --> 00:02:52,060
a, a unit length rather than some
arbitrary length.

51
00:02:52,060 --> 00:02:55,240
And that just allows us to if we take the
normalized

52
00:02:55,240 --> 00:02:58,430
version of the obstacle avoidance vector
and add it to the normalized

53
00:02:58,430 --> 00:03:01,100
versions of the go-to-goal vector.

54
00:03:01,100 --> 00:03:03,740
Then we get an equal balancing of the two
vectors

55
00:03:03,740 --> 00:03:06,785
rather than having to worry about what
their respective magnitude is.

56
00:03:06,785 --> 00:03:11,990
Hard-switching is going to work in a
little bit different way.

57
00:03:11,990 --> 00:03:16,370
What we're going to do is, we're going to
just use one controller at a time.

58
00:03:16,370 --> 00:03:20,790
So, for example, is like I said, if we're
close

59
00:03:20,790 --> 00:03:23,620
to the obstacle, we're going to want to do
obstacle avoidance.

60
00:03:23,620 --> 00:03:27,345
But, if we're clear of the obstacle, we're
going to want to just do go-to-goal.

61
00:03:28,590 --> 00:03:33,630
So, if we're away from the obstacle, use
the go-to-goal vector.

62
00:03:33,630 --> 00:03:38,500
If we're close to an obstacle, use the
obstacle avoidance vector.

63
00:03:38,500 --> 00:03:40,770
And the way we're going to do this is
we're just going to make

64
00:03:40,770 --> 00:03:45,920
a decision about how close the robot is to
the, to, to an obstacle.

65
00:03:45,920 --> 00:03:48,830
So for example, if one of your infrared
sensors on the robot

66
00:03:48,830 --> 00:03:52,270
senses a distance less than say, 15
centimeters,

67
00:03:52,270 --> 00:03:54,210
we might want to switch over to avoid
obstacles.

68
00:03:54,210 --> 00:03:56,770
But whereas if we're greater, at a
distance greater

69
00:03:56,770 --> 00:04:00,390
than 15 away from, 15 centimeters away
from the

70
00:04:00,390 --> 00:04:07,490
obstacle we can go, we are safe and we can
go ahead and do, just go to goal.

71
00:04:07,490 --> 00:04:13,830
And then the last one is to, is to use the
go-to-goal if we're some

72
00:04:13,830 --> 00:04:17,070
distance away from the obstacle, if we're
getting closer we're going to switch

73
00:04:17,070 --> 00:04:23,410
over to the combined blended version of
the vector or of the controller.

74
00:04:23,410 --> 00:04:28,070
And, then, if we're too close to the
obstacle, if it's unsafe for the robot

75
00:04:28,070 --> 00:04:32,380
to do, be worrying about where to go to,
worrying about going to the goal.

76
00:04:32,380 --> 00:04:34,200
We're going to switch over to avoid
obstacles.

77
00:04:34,200 --> 00:04:35,850
And that way we're going to ensure that
we're

78
00:04:35,850 --> 00:04:38,680
definitely not going to slam into any
obstacles.

79
00:04:38,680 --> 00:04:42,510
Now, the logic for deciding which
controller to

80
00:04:42,510 --> 00:04:45,610
use is going to end up in the supervisor.

81
00:04:45,610 --> 00:04:50,860
And the supervisor really considers each
controller to be its own state.

82
00:04:50,860 --> 00:04:53,360
And the supervisor can switch between
these states.

83
00:04:53,360 --> 00:04:55,730
Which means we're switching between the
different controllers.

84
00:04:55,730 --> 00:04:57,300
So, we're going to have three different
controllers.

85
00:04:58,420 --> 00:05:03,850
And, kind of going back to week three, an
example of this is if you look

86
00:05:03,850 --> 00:05:08,940
at, at the ex, execute function of the
supervisor and QB supervisor dot m, you

87
00:05:08,940 --> 00:05:15,030
may, might have seen that I had a
statement that says switch to state stop.

88
00:05:15,030 --> 00:05:18,550
And this means that I'm switching from the
go, go-to-goal controller that

89
00:05:18,550 --> 00:05:21,080
we were using at that time and switching
to the stop controller.

90
00:05:21,080 --> 00:05:22,980
And the stop controller is nothing but a
controller that

91
00:05:22,980 --> 00:05:26,510
sets the linear angular velocity of the
robot to 0.

92
00:05:26,510 --> 00:05:29,670
Now, we,

93
00:05:29,670 --> 00:05:32,760
we also had a condition when we wanted to
switch over

94
00:05:32,760 --> 00:05:35,890
to the start, to the stop controller from
the go-to-goal controller.

95
00:05:35,890 --> 00:05:40,550
And that condition was that the robot was
at its goal.

96
00:05:40,550 --> 00:05:44,120
So, and the, and the check_event function,
what it did,

97
00:05:44,120 --> 00:05:47,220
is it looked at, well, is this condition,
at_goal, true,

98
00:05:47,220 --> 00:05:51,450
and it was true whenever the goal or
whenever the

99
00:05:51,450 --> 00:05:56,080
robot was within a distance of d_goal of
the goal location.

100
00:05:56,080 --> 00:05:59,670
So that, that statement then becomes true,
which means that we have

101
00:05:59,670 --> 00:06:02,932
switched over into the stop controller
from the from the go-to-goal controller.

102
00:06:02,932 --> 00:06:05,240
And that was a very, very simple state
machine.

103
00:06:05,240 --> 00:06:07,007
because all it said was, that we start off

104
00:06:07,007 --> 00:06:10,690
in the go-to-goal state, or we're using
that controller.

105
00:06:10,690 --> 00:06:12,760
And then when we're close enough to the,
to

106
00:06:12,760 --> 00:06:15,420
the goal location, we switch to the other
state.

107
00:06:15,420 --> 00:06:18,310
Which is the stop state which corresponds
to the stop controller.

108
00:06:18,310 --> 00:06:19,720
It's very, very simple.

109
00:06:19,720 --> 00:06:21,250
What we're going to have to do this week
is going to

110
00:06:21,250 --> 00:06:22,720
be a little bit more complicated.

111
00:06:25,210 --> 00:06:27,600
And here's one example of a state machine

112
00:06:27,600 --> 00:06:30,790
that you could implement using all three
controllers.

113
00:06:30,790 --> 00:06:33,140
Or actually, four controllers.

114
00:06:33,140 --> 00:06:34,620
We're going to start off on the
go-to-goal.

115
00:06:34,620 --> 00:06:36,520
Because we're going to assume that the
robot starts somewhere.

116
00:06:36,520 --> 00:06:38,930
It's not going to be near an obstacle.
It wants to go to the goal.

117
00:06:40,000 --> 00:06:46,910
Then, if, we are at the obstacle, so
meaning that we're at some distance

118
00:06:46,910 --> 00:06:50,250
close to the obstacle, we're going to
switch into the blended controller

119
00:06:50,250 --> 00:06:54,370
with is the ao and go-to-goal controller.

120
00:06:54,370 --> 00:06:58,430
And if we leave the obstacle, meaning
we're

121
00:06:58,430 --> 00:07:01,030
some distance farther away from the
obstacle, we're

122
00:07:01,030 --> 00:07:06,260
going to, the condition obstacle_cleared
will become true,

123
00:07:06,260 --> 00:07:07,780
and we're going to go back to goal.

124
00:07:07,780 --> 00:07:08,980
And so, we could, you know?

125
00:07:08,980 --> 00:07:10,780
You can imagine that we can switch between

126
00:07:10,780 --> 00:07:14,170
these, whenever either one of these
conditions is true.

127
00:07:14,170 --> 00:07:14,670
And,

128
00:07:16,010 --> 00:07:19,900
but this gets a little bit more
complicated than that.

129
00:07:20,970 --> 00:07:26,440
If we are in the state ao_and_gtg, so if
we are in

130
00:07:26,440 --> 00:07:31,818
this state right here, and the robot is
some distance

131
00:07:31,818 --> 00:07:37,523
less than, dsafe.

132
00:07:37,523 --> 00:07:41,250
So what I want, we want, we're going to be
less than dsafe away

133
00:07:41,250 --> 00:07:45,790
from the obstacle, then this will become
true.

134
00:07:45,790 --> 00:07:49,270
And in that case, what happens is that we
switch

135
00:07:49,270 --> 00:07:53,710
from this state into this state right
here, which is avoid_obstacles.

136
00:07:53,710 --> 00:07:56,250
Because this is kind of like a last resort

137
00:07:56,250 --> 00:07:59,320
of, avoiding any collision with any
obstacles in the world.

138
00:08:01,560 --> 00:08:04,076
Now again, if, if we, if we're, end up in

139
00:08:04,076 --> 00:08:06,456
a, if we avoid the obstacle and we end up
in

140
00:08:06,456 --> 00:08:09,652
a, at a distance that is safely away from
the obstacle,

141
00:08:09,652 --> 00:08:14,130
we can switch back to the blended
controller in the middle.

142
00:08:14,130 --> 00:08:18,405
So you can kind of think about your, you,
the robot is always in some

143
00:08:18,405 --> 00:08:23,790
state so, in some state, and it takes a
transition if one of these is true.

144
00:08:23,790 --> 00:08:25,820
And then it switches to this other
controller.

145
00:08:25,820 --> 00:08:27,340
So then it ends up here.

146
00:08:27,340 --> 00:08:31,040
So if, if this one becomes true, it
switches back to this one.

147
00:08:31,040 --> 00:08:34,890
So you can just follow the, these
conditions from state to state to

148
00:08:34,890 --> 00:08:37,760
state to figure out where the robot, what
the robot is going to do.

149
00:08:39,050 --> 00:08:42,870
And I said that we're going to have four
states and four controllers.

150
00:08:42,870 --> 00:08:47,960
It's because I also have one for stopping.
So, if we are, if we

151
00:08:47,960 --> 00:08:53,260
are in this case in the go_to_goal state,

152
00:08:53,260 --> 00:08:56,590
in the, in the, in, in this controller,
end state.

153
00:08:56,590 --> 00:09:02,690
Then, [COUGH] if at_goal becomes true,
then we go ahead and stop.

154
00:09:05,310 --> 00:09:11,430
And, what you will probably notice here,
is that I don't have

155
00:09:11,430 --> 00:09:14,100
a connection from any of the other states
to the stop state.

156
00:09:14,100 --> 00:09:17,920
So, in this state machine, the only way
that the robot will

157
00:09:17,920 --> 00:09:21,420
stop at the goal location is if it's in
the go_to_goal state.

158
00:09:21,420 --> 00:09:24,180
If it's executing the go-to-goal
controller.

159
00:09:24,180 --> 00:09:30,500
So maybe a better design would be to also
have some paths down

160
00:09:30,500 --> 00:09:37,420
here, that's at, at_goal.
And the same thing for here.

161
00:09:41,020 --> 00:09:42,398
So maybe this was a better one.

162
00:09:42,398 --> 00:09:45,070
But you're free to design the state
machine

163
00:09:45,070 --> 00:09:46,950
whichever way you want, so long as you
make

164
00:09:46,950 --> 00:09:50,450
sure your robot doesn't collide with the
obstacle

165
00:09:50,450 --> 00:09:53,226
and ends up at the goal and stops there.

166
00:09:53,226 --> 00:09:55,680
Now, as far as implementation is

167
00:09:55,680 --> 00:09:57,900
concerned, the files that you'll be
interested

168
00:09:57,900 --> 00:10:02,680
in are first of all, the execute function
and the supervisor, so QBSupervisor.m.

169
00:10:02,680 --> 00:10:06,274
That's where we're going to implement the
logic for the state machine, where we're

170
00:10:06,274 --> 00:10:08,360
actual, well, I should say we're
implementing

171
00:10:08,360 --> 00:10:10,430
the state machine in the execute function.

172
00:10:11,690 --> 00:10:14,910
And the other file of interest is going

173
00:10:14,910 --> 00:10:18,610
to be this new controller which is
AOandGTG.m.

174
00:10:18,610 --> 00:10:21,120
So that's where you implement the blended
controller.

175
00:10:21,120 --> 00:10:25,280
And, of course, we'll also take advantage
of GoToGoal.m and AvoidObstacles.m.

176
00:10:25,280 --> 00:10:28,240
Not only in the design of the blended
controller, but also, we're

177
00:10:28,240 --> 00:10:31,430
going to switch it back and forth between
these controllers that we've already

178
00:10:31,430 --> 00:10:33,400
written in the previous weeks.

179
00:10:33,400 --> 00:10:38,105
So, let's see the blended controller in
action in MatLab.

180
00:10:39,300 --> 00:10:42,480
See here, I'm going to go ahead and launch
it, and

181
00:10:42,480 --> 00:10:45,710
of course I've already implemented it, and
we're going to run this.

182
00:10:46,900 --> 00:10:48,590
So, this is the blended controller.

183
00:10:48,590 --> 00:10:50,310
I'm going to click on the robot and follow
it.

184
00:10:50,310 --> 00:10:56,460
And, as you can see, the robot is avoiding
the obstacles.

185
00:10:56,460 --> 00:11:00,770
But it's also going to go to the skull
location, which is -1, 1 up here.

186
00:11:05,320 --> 00:11:08,300
And also has a condition for stopping.

187
00:11:08,300 --> 00:11:12,690
So what I've done here is I'm running the,
the, the blended controller.

188
00:11:12,690 --> 00:11:18,159
And if I am at the goal, then I stop.
And so, this is a success.

189
00:11:20,280 --> 00:11:24,530
Now, my tips for this week are, as usual,
make sure you read the

190
00:11:24,530 --> 00:11:28,810
section corresponding to this week's or
week five in the manual for more details.

191
00:11:28,810 --> 00:11:31,640
I also encourage you to really experiment
with

192
00:11:31,640 --> 00:11:34,170
different ways of blending the go-to-goal
and avoid-obstacles.

193
00:11:34,170 --> 00:11:38,120
So I showed you in an earlier slide one
way of combining the two vectors together.

194
00:11:38,120 --> 00:11:42,100
But I'm sure you can think of, of even
better ways of combining those.

195
00:11:43,230 --> 00:11:45,400
And also experiment with

196
00:11:45,400 --> 00:11:46,410
different state machines.

197
00:11:46,410 --> 00:11:49,640
So there's different, definitely different
ways of combining

198
00:11:49,640 --> 00:11:53,210
the different controllers or the different
states and conditions.

199
00:11:53,210 --> 00:11:55,730
To construct a state machine.

200
00:11:55,730 --> 00:12:01,600
And just explore and see what works the
best for you and good luck.

201
00:12:01,600 --> 00:12:05,130
[BLANK_AUDIO]