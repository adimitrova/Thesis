So, last lecture was really satisfying 
because there, we finally understood how we can do control design using the state 
and then at the same time, figure out what the state is and everything works. 
Thanks to this fantastic principle known, known as the separation principle. 
So, what it tells us is that we can completely decouple a control and 
observer design, and here, I have a rather important little parentheses that 
says, in theory. Now, there is a great American thinker 
that has figured out that this in theory is actually kind of important. 
This is Yogi Berra, the baseball player who presumably said, in theory, theory 
and practice are the same. In practice, they are not. 
Now, this is rather profound and it has some implications on the fact that just 
because the theory tells us something, we need to be aware of certain things at 
least. So, the first thing we need to be aware 
of is, the controller is really only useful once the estimate, that the 
estimated state is close to the actual state, 
meaning, that the controller doesn't really do anything useful until the 
observer has converged. So, what we want to do is want to make 
sure that the observer converges quickly. What that means is that we want the 
observer to be faster which in turn means that this eigenvalues that we were 
picking should be larger for the observer than the controller. 
Now, one thing we saw with large eigenvalues though, is that we get large 
gains. So, in the control side, this is kind of 
bad, because that means that we have large actuation signals, which means that 
we can saturate the actuators. In the controller side, I'm sorry, the 
observer side, that's no big deal because the observer is entirely done in 
software. There is nothing that's going to 
saturate, so we can actually make our observer eigenvalues large without having 
to run into issues like saturation. So practically, what we need to do is 
pick the eigenvalues typically in such a way that the controller eigenvalues are 
all, first of all, they all need to have negative real part, of course. 
And then, what we want to do is we want to make the observer eigenvalues bigger 
because that means that the observer is faster than what the controller is. 
So, here is a completely made up eigenvalue selection. 
But the important thing here is that the slowest observer eigenvalue, which really 
dictates how quickly the observer converges, is significantly faster than 
the slowest controller eigenvalue. So, that's something that we typically 
want when we're building our joint observer control design structures. 
Okay. Having said that, let's actually use this 
to control a humanoid robot. And this is the Aldebaran Nao that we're 
going to be working on, and in fact, what we can control on this thing are joint 
angles, meaning how the different angles are, are moving. 
And luckily for us, we actually have detailed models of these joint angles. 
In fact, for a given joint, the angular acceleration is 1/J times Ki minus B 
theta dot. And these things, well, they are physical 
things. So, J is the moment of inertia, i is our 
input, alright, so i is actually equal to u, here in this case. 
This is our input to the system. This is the current replying at the 
motor. Well, K is a torque constant that 
translates roughly currents into accelerations and then there's always a 
friction coefficient, the viscous friction coefficient in these 
motors. Now, luckily for us when you buy a robot 
like this, someone has already figured out these physical parameters and there 
are user manuals that describe what these parameters are. 
Now, we need to put this on state base form. And the first thing we're going to 
do, as always is say, well x1 is theta and x2 is theta dot, 
alright? We're also going to say that what we can 
match around this thing is the angle itself. 
So, y is going to be equal to theta. Well, with this choice, we get a linear 
time-invariance system that looks like this. 
x dot is 0 1 x 0-b/Jx and then we have this b matrix which is 0K/J times u and y 
is 1, 0 x is since we're pulling out the, the, orientation. 
Now, one nice thing about this system is that it is completely controllable and 
completely observable. So, what we have indeed learned in this 
class should be applicable. Okay. So, let's do that. 
The last thing we want to do though is we actually don't want to hold or stabilize 
the Nao into all the angles being zero. We want to be able to move it around. 
So, what we want to do is, we actually would like to track a reference angle. 
We would like the, the angle of joints to be something. 
So, I'm going to define a new variable e, it stands for error. 
It's not the estimation error, it's another error, which is the current angle 
minus the desired angle. And then as the second variable tossing 
in the angular velocity. And I would like to drive e to zero 
because if I have e=0, then I have theta equal to theta desired, meaning, I'm 
holding it at the angle I would like. And I have theta dot equal to zero, which 
means I'm actually holding it there. I'm not moving through it only. 
Okay, so this is what we would like to do. 
okay, then we need to write down the dynamics for our new variable e. 
Well, e dot, well, it's simply, Ax+Bu, because e dot is really, [SOUND] well, 
it's theta dot minus theta desired dot theta double dot, right? But this thing 
is 0 because the, the desired heading is constant, so all we're left with is theta 
dot, theta double dot, which is the same as x dot, 
right? This is the same as x dot so what we do is we plug in the equation for x 
dot and we get this. Now, we don't want to express this in 
terms of x. We want to express it in terms of e. 
And what we get if we plug in e is, we get this expression instead. 
Now luckily for us, a times this vector is actually equal to zero. 
And I encourage you to compute this so that you trust me. But having done that, 
what we get is that e dot is equal to Ae+Bu meaning we have same system 
dynamics as before but now, defined on this error, where the error is the 
current orientation or angle of the joint minus the desired angle of the joint. 
So, this is the dynamics we're caring about. 
Well, we have to do the same thing to the output. 
The output is Cx, well again, we replace x with e plus this vector. 
So, this is Ce+C times this vector, and remember that C was actually 1,0. 
So, if I take 1,0 times that, out comes data desired. 
So, my output is C times e plus theta desired. 
Now, this doesn't scare us one bit. We just plug it into our standard 
controller and observer design methodology. 
So, u is -K, not e because we don't know e but e hat, 
which is our estimate of e. And e hat dot, 
well, it has the standard predictor part and it 
has the corrector part. And the corrector part is the current 
output minus what the output would have been. 
And the only difference is I have to keep track of this little extra theta desired. 
But it's no big deal. It acts exactly the same way. 
So, this is now my control structure. And instead of me talking about it, why 
don't we move on to see an actual humanoid robot executing this controlled 
strategy. So now, that we have designed a, an 
observer based state feedback controller for controlling the joint angles of this 
humanoid robot, the Aldebaran Nao, we're ready to do it for real. 
And I'm here with Amy LaViers. She was a graduate student at Georgia Tech. 
And what she has done is made the Nao move its arms and its head, and even its 
upper body, in such a way that it is executing a friendly wave towards, 
probably you, who are watching this right now. 
And, what's happening is we're running the same controller on all the different 
joints with different desired angles to get the effect out. 
So, Amy, why don't we take the Nao for a little spin there and see what it can do? 
So, what's going on here is that we're sequentially running multiple desired 
angles and that's how we're getting this effect. 
In fact, why don't we watch this again because I think this is quite, it's quite 
charming to be honest. So, here we go. 
Observer-based state feedback controlling action. 
Oh, thank you very much, Amy. 
And thank you.