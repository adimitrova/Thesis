welcome back 
this is week four 
so halfway programming 

simulation lectures well 
assignments 
so congratulations making this far 
last week i talked goal to goal 
controllers allowed 
robots to drive current 
location to location in 
environment 
this week im going to talk 
to create an obstacle avoidance 
controller 
this obstacle avoidance controller, 
point is that we want to 
able to drive around environment 
without colliding 
obstacles 
so if youre driving a robot in 
living room you 
dont want to drive sofa 
get destroyed 
so this week going to take care 
that 
there actually many ways 
obstacle avoidance 
ive picked one particular way 
obstacle avoidance 
this is we 
first, going to interpret 
ir distance a point in coordinate 
frame 
sensor transform this point 
coordinate frame robot 
going to take this point thats 
in robots coordinate frame, 
transform 
world coordinate frame, so 
that 
we know obstacle is in 
world 
we will is compute a vector 
points to 
robot, we will use that an, 
sum together 
an obstacle avoidance vector 
we will is thing 
last week is going to 
use this vector use a pid controller 
to 
steer robot towards orientation 
vector 
effectively will happen is that 
robot will drive 
in direction that points away 
obstacles that nearby 
thus will avoid collisions 
so ive mentioned coordinate frame 
least four five times this slide 
i mean that 
we use coordinate frames to give meaning 
to points in sort space 
so i tell you that robot is 
located 
xy theta, you need to know 
coordinate frame im talking 
so, in cases im talking 
world frame 
this world frame is centered 
origin, 
im going to denote zero, 
zero 
so i pick this, this is in 
simulator 
respect to this world frame, 
location robot is given x y 
course, also respect to this 
world 
frame, we an orientation theta, 

so, the, robot, right here an 
orientation given theta, 
important that this theta is defined with, 

respect to x axis this world frame 
now, next coordinate frame that we 
is robots 
coordinate frame, this coordinate 
frame is located right robot 
so wherever robot is, center 
this robot, theres 
a cornered frame its, this, this we 
call robot frame 
so, respect to robot, this 
direction right here going in 
front robot, aligns 
robots orientation is, would theta, 
maybe called theta prime is 
equal to zero, in that robots frame 
but, theta prime in world frame, so 
maybe ill call this theta 
prime w f, would equal to actual 
theta robot 
now, 
reason that we care robots 
frame reference, is we 
know location sensors 
orientation sensors 
respect to robot, robot frame 
so robot knows example, that 
one particular sensor, mounted right 
here is, sensor number one 
this sensor, knows is, is located 
at, this point 
respect to robots coordinate 
frame, 
orientation along in this direction 
this orientation, respect to 
robot, is degrees 
in world frame, 
this orientation would also a function 
actual orientation robot 
so, lets call this maybe theta prime 
so we said that degrees, is 
thing 
pi 
we want 
to is, to figure sensor 
is, so theta prime 
s, in world frame this would not, 
nothing than, pi 
divided plus orientation 
robot 
so this would give you angle this 
sensor in world frame 
now, way that ive denoted this in, in 
manual is, using 
sorry, im going to color this 
is using, x sub four 
so this is x position sensor four 
in robots frame 
y position sensor four in the, in 
robots frame orientation 
sensor four in the, in robots frame, 
so in this case, theta four is actually, 
so this is equivalent to minus degrees 
thats orientation 
sensor respect to robot 
now, we go even one step 
this 
we define is, a coordinate frame, 
respect to sensor 
so sensor coordinate 
frame 
so getting fairly 
deep in here, but, point that is 
that we defy example 
here this sensor is frame in this 
case sensor you know, actually 
sensor four 
origin this coordinate 
frame is located sensor is 
located 
x axis that coordinate 
frame aligns orientation that 
sensor 
this is important 
going to do, is going to 
figure that distance 
that measuring is actually nothing 

a point in this coordinate system 
so, here, ive done is, robot 
measures a distance of, so this distance 
right here is d 
ive done is i said well in 
this, 
particular coordinate frame, this point 
right here 
is equal to this vector right here 
so d so going a distance 
d , 
x direction distance is 
y direction in that particular 
coordinate frame 
now, we really care in this, 
in, in, 
in controller is, well if i this 
point in 
this sensors coordinate frame, 
this 
point correspond to in world frame 
because, you imagine, if i 
example a, a point 
here that is an obstacle, i say 
that obstacle is 
this location in world, i know 
robot is 
that we make an informed decision 
to move robot 
thats exactly well 
so, in order you to able to 
calculate transformation between 
different coordinate frames, youre 
going to need to 
know to rotate translate in d 
i mean that is that if we 
a coordinate frame, 
so say, this is coordinate frame right 
here, i this point 
right here, so i a point right here, 
lets call that , 
this i also, i pretend that 
this point is a 
vector going origin to this point 
suppose 
i wanted to do, is rotate this vector 
translate 
lets say that i want to rotate 
im going 
to use this notation r, im going to 
say, translated one 
unit in x direction, two units in 
y direction pi four is 
translation 
so this r actually mean 
well, r is given this 
transformation matrix 
this transformation matrix is, 
does, is exactly i described 
going to take a vector and, you 
premultiply 
this vector r youre going to get the, 
the, vector transformed in space x 
y, translated x y 
rotated this theta prime right here 
so actually translating x prime y 
prime according to notation here 
so going back to example 
what, really, whats really going 
is 
that first, going to rotate 
vector by, 
pi , means 
that located at, squared 
, squared 
going add a translation in 
x direction a translation in 
y direction one unit two units 
means that, vector that i get, 
corresponds to plus squared 
plus squared 
so ive effectively done here is ive 
taken this point, , 
i translate, rotated translated 
to this point here, is , 
plus square root 
plus square root 
thats rotation 
translation works, so, 
so whether a point vector doesnt 
really matter 
point really is that ive gone 
this, 
this transformation, ive gotten a, a 
translation a rotation 
to a little bit specific, 
ive really 
done is so, this side i would so, 
so here 
this, this r, comma 
comma pi 
and, im multiplying, vector that 
im multiplying with, youll 
notice is that this is first a 
matrix, so we want to make sure that this 
is going to 
a matrix this to a valid 
multiplication 
going to is 
going to put point that 
translating, 
so lets call this xy, so this 
is x, wouldve been, equal 
to , y equal to 
always going to place to 
make, going to place a right here 
so, this stays a independent x 
y 
so, i telling you this 
well, you need this tool, you need this 
transformation 
matrix in order to transformation 

point in centers, reference framed 
way 
back to world, uh,to world 
coordinate frame 
this is entire calculation that 
youre going to 
you see here ive done is i 
have, point 
d sub i 
so this is distance that measured 
sensor i 
then, im transformation 
sensor frame to 
robot frame input 
rotation 
translation matrix is position the, 
position 
orientation sensor robot, in 
robots frame 
so this entire thing gives 
us this point in robots reference 
frame, instead sensors reference 
frame 
so, we to another rotation 
rotation translation 
we that using robots 
location 
location orientation in in the, in 
world frame 
we that, this entire thing, right 
here will, 
point, give us point, this original 
point right here, in world frame 
this is exactly this is 
so world frame coordinates 
this, 
this point detected this particular 
infrared sensor i, 
now, lets get to code 
that armed this tool 
first all, going to create, 
weve already created a new file this 
controller 
going to file, so 
controller, going to 
called avoidobstaclesm 
like this comment says, avoidobstacles 
is really 
steering robot away 
nearby obstacles 
really, way to think 
it, is going to steer towards 
free space 
and, first all, 
transformations 
going to happen inside this function 
called applysensorgeometry 
going to three parts in there 
we 
even get to pid part the, 
controller 
first part is to apply 
transformation, 
sensor, sensors, coordinate 
frame to robot frame 
really, im here is im em, 
already giving you location 
sensor, 
sensor eye in robots 
coordinate frame 
that i, i i want you 
to is first properly implement get 
transformation matrix 
according to equation that i gave on, 
previous slide, previous slides 
youve done that properly, 
course, youre going to to input 
here 
you to figure proper 
multiplication 
again, you look back 
ive done 
remember, one step, 
so really you is, r, 
xs, ys, theta multiplied 
di, , 
so this is 
i expect you to implement, right 
here 
then, going to next part, 
is transforming the, 
point robots coordinate 
frame to world coordinate frame 
so, this follows a si, the, a similar 
pattern we in previous 
slide 
again, you want to make sure is that 
this becomes input this 
youve already implemented get 
transformation 
matrix so spits 
appropriate r, youre going to 
to calculation 
so you pick previous vector, so im 
going to represent 
that scribbles multiply that r, 
x, y, theta 
that give ir 
distances, all, 
points that correspond to ir 
sensors in world frame 
we know where, obstacles 
in world free space 
in world, depending whether youre 
picking 
an obstacle youre picking an 
obstacle 
now, so like i said, weve computed 
world frame coordinates 
points 
so one points right here in 
green, we know theyre located in 
world, right 
so, we do, is we compute 
vectors robots to one 
points 
we do, is since theyre 
vectors we 
sum 
we sum we get this 
large vector 
thats point, that is going to end 
pointing away obstacles 
reason that is that 
sensors so example 
this sensor right here, that is detecting 
obstacles distance is 
really great, is going to contribute much 
this sensor is picking 
an obstacle close 
so you sum sensors, 
main contribution is 
going to along a direction is, 
away obstacle 
weve done that, we use 
orientation this vector use 
pid control much like we in doog, 
google controller to steer robot in 
to direction free space 
so here is code, in 
main execute function avoid 
obstacles controller 
one thing i would like you to pay 
attention to is that i created this 
sensor gains, 
i ask you in manual to think 
you want to structure 
sensor gains 
you want sensors to count 
equally, 
we contribute equally, you may 
care a particular sensor 
so example you care one 
thats in front thats third 
sensor 
so maybe this , so that you pay 

attention to obstacles that 
in front you 
you you want to pay 
attention 
to obstacles that side in that 
case you would maybe increase two, 
so sensor 
one five, that go to left to 
the, to right robot 
so, play around that you 
get interesting results 
again, here im going to, here im 
asking you to properly 
calculate uis, so one 
vectors 
then, going to sum 
together youre going to 
to figure angle this 
vector, so you get theta ao 
then, like last weekend, goal 
to 
goal controllers, so youre already 
familiar that, you need 
to compute error between, this angle 
that you want 
to steer to, actual angle 
robot 
now, to test this going to 
implement this controller 
run robot so lets see 
happens 
i mean, obviously were, we hope that 
robots going to collide 
walls obstacles 
that ive added to environment 
lets make sure this actually happens 
ive already implemented controller, 
so im going 
to head eh, go ahead launch 
simulator 
im going to hit play, going to 
follow this robot see 
so i clicked to follow it, 
going to see what, 
already turned away the, 
obstacle 
there is a wall phew, 
we made heres another wall yet 
again, robot turns away 
since ive implemented this controller 
correctly, 
robot drive around aimlessly 
around this environment 
we havent told needs to go, 
we 
told that needs to avoid 
obstacles 
and, in fact, next week, well talk 

to combine goal to goal controllers 
avoid obstacle controllers 
tips this week to refer 
to 
section week in manual 
details 
i always provided detailed 
instructions 
that help you get 
assignments 
also keep in mind that, even though 
this seems like a really difficult 
approach really 
tedious, you could probably think of, 
a 
way easier ways obstacle 
avoidance robots 
reason that ive done in a way 

we end a vector is that itll make 
a lot easier 
next week, we combine goal 
to goal controllers obstacle one 
controllers 
a matter 
blending two vectors 
together, we know definitely know to 
sum vectors together so 
stick ill see you next week 
