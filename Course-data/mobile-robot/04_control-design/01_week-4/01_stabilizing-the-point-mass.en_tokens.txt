welcome
to
the
module
4
of
the
course
control
of
mobile
robots
.
so
,
in
the
last
module
we
've
learned
about
linear
systems
and
we
saw
where
they
came
from
and
at
the
end
we
even
managed
to
control
them
a
little
bit
and
in
fact
we
felt
rather
good
about
ourselves
.
because
we
could
design
a
state
feed
back
controller
for
a
point
mass
that
stabilized
it
,
but
at
the
same
time
we
were
a
little
queasy
and
uneasy
about
this
whole
thing
because
we
had
to
have
x
meaning
the
state
to
do
our
control
design
but
in
reality
,
we
actually
do
n't
have
x.
we
have
y
,
the
output
.
so
what
this
module
is
devoted
to
is
trying
to
first
of
all
,
be
systematic
in
how
we
do
the
control
design
and
,
secondly
,
how
do
we
actually
overcome
this
seeming
paradox
of
needing
x
but
only
having
y.
so
what
we
're
going
to
do
in
the
first
lecture
,
is
stabilize
the
point
mass
.
we
're
going
to
return
to
our
old
friend
,
and
in
general
,
if
i
have
a
linear
system
,
x
dot
is
ax
+
bu
,
y
is
cx
.
the
dilemma
,
as
i
've
already
stated
is
that
we
seem
to
need
x
for
stability
but
all
we
really
have
is
y.
so
here
is
the
game
play
.
we
're
going
to
ignore
the
fact
that
we
do
n't
have
y.
instead
we
're
going
to
design
our
controller
as
if
we
had
the
state
itself
and
then
somehow
we
're
going
to
hope
that
we
can
figure
out
the
state
from
the
measurements
,
meaning
from
y
,
and
this
is
the
game
plan
we
're
going
to
pursue
throughout
this
entire
module
.
and
,
the
first
step
is
,
of
course
to
design
u
as
if
we
had
x.
so
step
one
is
to
,
do
the
control
design
and
we
're
going
to
use
a
method
called
,
pole
placement
.
and
,
pole
placement
is
a
rather
powerful
idea
.
so
if
i
have
my
point
mass
system
again
,
x
dot
is
ax+bu
,
where
we
have
our
old
friends
the
a
and
b
matrices
that
we
've
seen
over
and
over
again
.
well
,
state
feedback
means
that
,
what
we
are
going
to
do
is
we
're
going
to
pick
u
is
-kx
.
where
k
in
this
particular
situation
is
a
1
by
2
matrix
,
so
it
has
2
components
.
k1
and
k2
.
and
those
are
,
are
gains
.
and
we
've
already
seen
in
the
previous
module
,
that
k1
is
a
gain
that
looks
at
precision
.
and
k2
is
a
gain
that
looks
at
velocity
.
and
by
tweaking
them
,
somehow
,
we
can
get
the
system
to
be
,
behave
well
.
'cuz
we
've
already
seen
that
.
so
,
the
one
question
we
need
to
ask
first
,
is
,
of
course
,
is
,
how
do
we
actually
pick
these
control
gains
?
meaning
,
what
should
k
be
?
well
.
here
is
the
whole
idea
behind
pole
placement
.
when
we
plug
in
u
is
minus
kx
we
get
a
closed
loop
system
.
and
what
we
're
going
to
do
,
is
we
're
going
to
pick
k
such
that
the
closed
loop
system
has
the
right
eigenvalues
.
and
right
meaning
,
we
get
to
pick
them
.
and
the
risk
is
called
pole
placement
,
its
that
eigen
values
of
the
system
matrices
are
sometimes
referred
to
as
poles
and
what
we
're
going
to
do
is
we
're
going
to
make
them
be
what
we
want
them
to
be
,
in
particular
we
want
them
to
have
negative
real
part
because
that
is
what
we
need
for
asymptotic
stability
.
so
but
before
we
do
that
we
actually
need
to
figure
out
how
do
we
computer
eigenvalues
?
so
in
general
,
if
i
have
a
matrix
m
,
this
does
n't
have
to
be
a
2
by
2
,
this
is
just
some
general
m
,
then
every
square
matrix
m
has
a
so-called
characteristic
equation
associated
with
it
.
and
it
's
given
by
this
chi
m
of
lambda
,
and
it
's
kind
of
a
mouthful
.
it
's
the
determinant
of
lambda
times
the
identity
matrix
-m.
and
then
we
set
this
determinant
equal
to
and
the
lambdas
that
solve
this
are
eigenvalues
,
well
,
let
's
see
what
this
means
.
if
i
have
a
2x2
system
and
equal
to
m1
,
m2
,
m3
and
m4
then
lambda
i
,
meaning
lambda
times
the
identity
minus
m.
well
it
's
lambda
times
the
identity
minus
m
,
well
,
if
you
plug
this
in
,
you
get
the
following
matrix
.
okay
,
now
,
let
's
take
the
determinant
of
this
matrix
.
so
the
determinant
,
well
,
is
this
object
you
get
by
taking
this
element
times
this
element
.
and
then
you
subtract
away
this
element
times
that
element
.
this
is
how
you
do
it
for
2
by
2
matrices
.
in
general
it
can
become
even
more
complicated
.
but
in
this
case
,
i
get
this
times
that
which
shows
up
as
lambda
-
m1
*
lambda
-
m4
.
and
then
i
get
-m2
,
or
-
-
m2
*
-m3
,
which
shows
up
like
this
.
so
this
is
the
,
the
determinant
of
this
2
by
2
m
matrix
.
okay
.
we
need
to
set
this
determinant
equal
to
zero
,
so
aa
,
carrying
out
the
multiplications
we
have
second
order
equation
that
we
have
to
solve
for
lambda
in
order
to
be
able
to
find
eigenvalues
,
okay
.
lets
try
to
that
,
we
have
this
equation.the
way
we
solve
second
order
equations
,
is
while
there
are
formulas
for
this
it
is
possible
to
do
it
.
in
this
case
it
turns
out
that
lambda
is
this
rather
annoying
looking
expression
here
,
but
this
is
what
the
eigenvalue
,
the
2
eigenvalue
to
this
2x2
matrix
would
be
.
but
it
is
annoying
.
i
really
do
n't
want
to
do
this
.
so
the
question
is
there
an
easier
way
of
making
the
eigenvalues
be
what
we
would
like
them
to
be
.
turns
out
that
the
answer
is
,
yes
.
there
is
something
called
the
fundamental
theorem
of
algebra
.
and
this
fancy
looking
,
or
fancy
sounding
theorem
says
that
,
if
i
have
a
polynomial
,
the
roots
to
that
polynomial
are
determined
by
the
coefficients
,
which
means
that
you
know
what
?
i
actually
do
n't
have
to
solve
this
equation
.
here
i
have
coefficients
in
front
of
lambda
then
here
i
have
the
coefficients
that
are
n't
in
front
of
any
lamda
,
those
coefficients
alone
are
enough
to
implicitly
but
completely
determined
eigen
values
.
so
what
we
're
going
to
do
is
we
're
actually
not
going
to
solve
this
.
we
're
just
going
to
stop
here
and
say
,
fine
,
lets
start
massaging
the
coefficients
direct
.
so
if
we
go
back
to
our
point
mass
again
.
i
pick
u
as
-kx
.
then
i
get
x
dot
is
(
a
-
bk
)
x
we
've
seen
this
before
.
this
is
the
closed
loop
dynamics
.
and
in
particular
if
i
plug
in
what
k
is
i
get
a
-
bk
being
this
two
matrices
here
.
and
,
if
i
compute
that
,
i
get
0
,
1
,
-k1
,
-k2
.
and
i
,
encourage
all
of
you
to
perform
this
multiplication
at
home
,
just
to
make
sure
that
you
trust
that
this
is
indeed
now
let
's
compute
the
igon
values
or
at
least
the
co-efficients
in
this
thing
called
the
characteristic
equation
.
so
,
chi
a
minus
bk
lambda
is
the
determinent
of
this
matrix
or
the
negative
of
that
matrix
plus
lambda
times
the
identity
.
so
,
this
is
what
i
have
here
of
course
is
lambda
i
-
(
a
-
bk
)
.
and
,
if
you
compute
this
determinant
,
you
get
,
lambda
^
2
+
lambda
k2
+
k1
.
that
's
not
so
bad
.
and
the
neat
thing
here
is
that
again
,
all
we
care
about
these
coefficients
.
the
things
that
determine
what
the
roots
are
without
us
actually
having
to
complete
the
roots
.
now
why
does
that
help
us
?
well
,
what
we
're
going
to
do
now
is
we
're
going
to
pick
our
favorite
eigenvalues
in
the
whole
world
.
we
're
going
to
pick
the
eigenvalues
that
we
would
like
the
system
to
have
,
and
if
we
somehow
magically
manage
to
make
the
closed
loop
system
have
these
eigenvalues
,
then
the
characteristic
equation
would
be
lamda
minus
lamda
1
because
the
characteristic
equation
has
to
be
0
has
to
be
lamda
1
as
a
root
.
and
if
i
plug
in
lamda
1
,
i
get
0
here
.
similarly
if
i
plug
in
lamda
2
i
get
0
here
,
and
lamda
and
0
here
.
so
what
i
have
is
a
product
of
lamda
minus
these
desired
favorite
eigenvalues
in
the
whole
world
.
so
let
's
do
that
.
so
for
the
robot
or
the
point
mass
,
i
'm
going
to
pick
both
eigenvalues
at
-1.
i
need
,
i
know
that
they
need
to
have
negative
real
part
,
well
,
-1
is
particularly
simple
because
then
i
get
this
phi
of
lambda
which
is
this
desired
characteristic
equation
,
not
the
actual
characteristic
equation
but
the
desired
one
.
it
's
just
lambda
+
1
*
lambda
+
1
or
,
if
i
carry
out
this
multiplication
,
i
get
lambda
^
2
+
2
lambda
+
1.
now
,
what
we
need
to
do
is
simply
line
up
these
coefficients
with
the
actual
coefficients
that
we
have
.
so
if
i
do
that
,
i
see
,
this
is
the
characteristic
equation
.
this
is
what
i
would
like
it
to
look
like
.
well
,
here
are
the
coefficients
in
front
of
lambda
.
and
here
are
these
coefficients
that
are
hanging
out
by
themselves
.
all
we
do
now
is
simply
line
these
up
.
so
k2
has
to
be
=
2
,
k1
has
to
be
=
1
and
wahlah
,
i
've
actually
designed
the
k
matrix
that
i
need
.
so
now
all
i
do
is
i
plug
this
in
to
my
original
system
which
is
x
dot
is
ax
+
bu
but
i
've
closed
the
loop
right
now
with
u
being
-kx
and
i
have
successfully
stabilized
the
system
,
by
placing
the
eigenvalues
exactly
where
i
would
like
them
to
be
.
