so, last lecture was really satisfying 
because there, we finally understood how 
we can do control design using the state 
and then at the same time, figure out 
what the state is and everything works. 
thanks to this fantastic principle known, 
known as the separation principle. 
so, what it tells us is that we can 
completely decouple a control and 
observer design, and here, i have a 
rather important little parentheses that 
says, in theory. 
now, there is a great american thinker 
that has figured out that this in theory 
is actually kind of important. 
this is yogi berra, the baseball player 
who presumably said, in theory, theory 
and practice are the same. in practice, 
they are not. 
now, this is rather profound and it has 
some implications on the fact that just 
because the theory tells us something, we 
need to be aware of certain things at 
least. 
so, the first thing we need to be aware 
of is, the controller is really only 
useful once the estimate, that the 
estimated state is close to the actual 
state, 
meaning, that the controller doesn't 
really do anything useful until the 
observer has converged. 
so, what we want to do is want to make 
sure that the observer converges quickly. 
what that means is that we want the 
observer to be faster which in turn means 
that this eigenvalues that we were 
picking should be larger for the observer 
than the controller. 
now, one thing we saw with large 
eigenvalues though, is that we get large 
gains. 
so, in the control side, this is kind of 
bad, because that means that we have 
large actuation signals, which means that 
we can saturate the actuators. 
in the controller side, i'm sorry, the 
observer side, that's no big deal because 
the observer is entirely done in 
software. 
there is nothing that's going to 
saturate, so we can actually make our 
observer eigenvalues large without having 
to run into issues like saturation. 
so practically, what we need to do is 
pick the eigenvalues typically in such a 
way that the controller eigenvalues are 
all, first of all, they all need to have 
negative real part, of course. 
and then, what we want to do is we want 
to make the observer eigenvalues bigger 
because that means that the observer is 
faster than what the controller is. 
so, here is a completely made up 
eigenvalue selection. 
but the important thing here is that the 
slowest observer eigenvalue, which really 
dictates how quickly the observer 
converges, is significantly faster than 
the slowest controller eigenvalue. 
so, that's something that we typically 
want when we're building our joint 
observer control design structures. 
okay. 
having said that, let's actually use this 
to control a humanoid robot. 
and this is the aldebaran nao that we're 
going to be working on, and in fact, what 
we can control on this thing are joint 
angles, meaning how the different angles 
are, are moving. 
and luckily for us, we actually have 
detailed models of these joint angles. 
in fact, for a given joint, the angular 
acceleration is 1/j times ki minus b 
theta dot. 
and these things, well, they are physical 
things. 
so, j is the moment of inertia, i is our 
input, alright, so i is actually equal to 
u, here in this case. 
this is our input to the system. 
this is the current replying at the 
motor. 
well, k is a torque constant that 
translates roughly currents into 
accelerations and then there's always a 
friction coefficient, 
the viscous friction coefficient in these 
motors. 
now, luckily for us when you buy a robot 
like this, someone has already figured 
out these physical parameters and there 
are user manuals that describe what these 
parameters are. 
now, we need to put this on state base 
form. and the first thing we're going to 
do, as always is say, well x1 is theta 
and x2 is theta dot, 
alright? 
we're also going to say that what we can 
match around this thing is the angle 
itself. 
so, y is going to be equal to theta. 
well, with this choice, we get a linear 
time-invariance system that looks like 
this. 
x dot is 0 1 x 0-b/jx and then we have 
this b matrix which is 0k/j times u and y 
is 1, 0 x is since we're pulling out the, 
the, orientation. 
now, one nice thing about this system is 
that it is completely controllable and 
completely observable. 
so, what we have indeed learned in this 
class should be applicable. 
okay. so, let's do that. 
the last thing we want to do though is we 
actually don't want to hold or stabilize 
the nao into all the angles being zero. 
we want to be able to move it around. 
so, what we want to do is, we actually 
would like to track a reference angle. 
we would like the, the angle of joints to 
be something. 
so, i'm going to define a new variable e, 
it stands for error. 
it's not the estimation error, it's 
another error, which is the current angle 
minus the desired angle. 
and then as the second variable tossing 
in the angular velocity. 
and i would like to drive e to zero 
because if i have e=0, then i have theta 
equal to theta desired, meaning, i'm 
holding it at the angle i would like. 
and i have theta dot equal to zero, which 
means i'm actually holding it there. 
i'm not moving through it only. 
okay, so this is what we would like to 
do. 
okay, then we need to write down the 
dynamics for our new variable e. 
well, e dot, well, it's simply, ax+bu, 
because e dot is really, [sound] well, 
it's theta dot minus theta desired dot 
theta double dot, right? but this thing 
is 0 because the, the desired heading is 
constant, so all we're left with is theta 
dot, theta double dot, which is the same 
as x dot, 
right? this is the same as x dot so what 
we do is we plug in the equation for x 
dot and we get this. 
now, we don't want to express this in 
terms of x. 
we want to express it in terms of e. 
and what we get if we plug in e is, we 
get this expression instead. 
now luckily for us, a times this vector 
is actually equal to zero. 
and i encourage you to compute this so 
that you trust me. but having done that, 
what we get is that e dot is equal to 
ae+bu meaning we have same system 
dynamics as before but now, defined on 
this error, where the error is the 
current orientation or angle of the joint 
minus the desired angle of the joint. 
so, this is the dynamics we're caring 
about. 
well, we have to do the same thing to the 
output. 
the output is cx, well again, we replace 
x with e plus this vector. 
so, this is ce+c times this vector, and 
remember that c was actually 1,0. 
so, if i take 1,0 times that, out comes 
data desired. 
so, my output is c times e plus theta 
desired. 
now, this doesn't scare us one bit. 
we just plug it into our standard 
controller and observer design 
methodology. 
so, u is -k, not e because we don't know 
e but e hat, 
which is our estimate of e. 
and e hat dot, 
well, 
it has the standard predictor part and it 
has the corrector part. 
and the corrector part is the current 
output minus what the output would have 
been. 
and the only difference is i have to keep 
track of this little extra theta desired. 
but it's no big deal. 
it acts exactly the same way. 
so, this is now my control structure. 
and instead of me talking about it, why 
don't we move on to see an actual 
humanoid robot executing this controlled 
strategy. 
so now, that we have designed a, an 
observer based state feedback controller 
for controlling the joint angles of this 
humanoid robot, the aldebaran nao, we're 
ready to do it for real. 
and i'm here with amy laviers. she was a 
graduate student at georgia tech. 
and what she has done is made the nao 
move its arms and its head, and even its 
upper body, in such a way that it is 
executing a friendly wave towards, 
probably you, who are watching this right 
now. 
and, what's happening is we're running 
the same controller on all the different 
joints with different desired angles to 
get the effect out. 
so, amy, why don't we take the nao for a 
little spin there and see what it can do? 
so, what's going on here is that we're 
sequentially running multiple desired 
angles and that's how we're getting this 
effect. 
in fact, why don't we watch this again 
because i think this is quite, it's quite 
charming to be honest. 
so, here we go. 
observer-based state feedback controlling 
action. 
oh, thank you very much, 
amy. 
and thank you. 
