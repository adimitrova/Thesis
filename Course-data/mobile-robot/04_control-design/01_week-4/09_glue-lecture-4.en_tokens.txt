hello
,
and
welcome
to
glue
lecture
four
.
i
'm
smriti
chopra
,
your
instructor
for
the
glue
lectures
,
and
let
's
get
into
it
.
so
this
lecture
is
titled
controllability
and
observability
,
because
this
week
,
with
dr.
egerstedt
,
you
guys
learned
about
what
is
a
system
and
then
more
importantly
,
how
do
you
see
if
it
's
stable
,
unstable
?
and
if
it
's
unstable
,
how
do
you
stabilize
it
through
controls
?
but
before
you
can
do
that
,
you
need
to
see
if
the
system
is
controllable
.
and
let
's
say
you
did
stabilize
it
.
now
you
want
to
see
if
it
's
observable
,
because
,
you
know
,
you
do
n't
have
state
information
,
so
you
need
to
somehow
bring
in
output
,
etc
.
and
then
we
see
how
you
put
everything
together
.
so
in
this
lecture
,
we
're
just
going
to
go
over
this
one
big
example
clearing
all
these
concepts
for
you
guys
.
okay
?
so
let
's
start
with
system
stability
.
let
's
say
this
is
my
robot
,
and
just
an
arm
is
all
that
we
're
going
to
consider
,
which
is
your
theta
1
and
theta
2
to
join
the
angles
of
this
arm
,
two
angles
.
and
i
'm
going
to
see
that
my
state
is
this
guy
here
,
which
are
the
angles
and
their
velocities
.
and
my
a
matrix
is
this
.
this
is
how
my
state
relates
to
its
derivatives
,
right
?
this
is
given
to
us
.
so
this
is
what
our
system
looks
like
,
this
guy
,
by
this
equation
here
.
there
you
go
.
so
now
what
are
we
going
to
do
?
we
're
going
to
check
if
the
system
is
stable
.
does
it
blow
up
,
or
as
time
goes
to
infinity
,
or
is
going
to
be
stable
on
its
own
?
and
the
way
to
do
that
is
by
checking
the
eigen
values
of
a
,
right
?
so
in
matlab
you
can
simply
type
eig
a
,
or
you
can
sit
and
find
out
the
eigen
values
yourself
.
either
way
.
here
we
just
put
it
in
matlab
,
and
we
see
that
all
eigen
values
of
a
are
0.
and
we
know
from
our
lectures
that
when
the
eigen
values
are
all
0
,
that
means
your
system
is
unstable
.
so
we
found
out
that
for
this
system
,
this
particular
x
and
a
,
our
guy
is
unstable
.
okay
,
so
that
means
we
need
to
introduce
control
,
right
?
but
how
do
you
introduce
control
?
we
know
this
pretty
equation
here
,
x
dot
equal
to
ax
plus
bu
.
but
what
does
it
really
mean
?
what
is
b
?
what
is
u
;
u
of
course
,
is
our
control
signal
.
well
,
we
need
to
first
find
out
what
it
is
that
we
can
control
about
the
system
,
let
's
say
through
putting
motors
or
through
putting
actuators
,
etc
.
so
we
're
going
to
assume
that
we
can
control
the
acceleration
of
my
first
joint
angle
,
theta
and
if
we
do
that
,
then
we
see
that
our
b
matrix
turns
out
to
be
this
guy
here
.
why
?
because
now
,
when
you
put
b
here
in
this
equation
of
yours
,
you
'll
see
that
the
input
u
shows
up
next
to
theta
1
double
dot
.
that
means
you
can
influence
the
acceleration
of
my
theta
1
double
of
my
theta
1
,
right
?
that
's
where
my
input
shows
up
.
so
that
's
how
you
generate
your
b
matrix
.
now
that
we
have
this
,
great
.
but
can
we
,
with
this
particular
choice
of
b
,
actually
control
this
guy
or
not
?
that
is
,
do
we
see
if
it
's
controllable
of
not
?
and
for
this
we
have
a
very
simple
test
,
which
is
you
create
this
matrix
.
this
is
the
controllability
matrix
,
right
?
and
then
you
simply
check
the
rank
of
this
matrix
.
so
here
we
going
to
make
this
matrix
first
.
and
you
guys
should
be
comfortable
with
finding
matrix
multiplications
,
etc
.
not
for
maybe
such
big
systems
,
but
for
let
's
say
a
two
by
two
matrix
,
you
should
be
able
to
do
it
.
if
you
want
we
can
really
fast
go
over
one
example
.
for
example
,
this
is
your
a
,
right
:
0000
,
and
then
you
've
got
,
i
'm
going
to
find
ab
.
so
let
's
put
b
here
,
which
is
0100.
and
now
,
because
my
a
is
a
4
cross
4
,
and
my
b
is
a
4
cross
1
,
my
resulting
matrix
is
going
to
be
a
4
cross
1
,
right
?
and
let
's
multiply
quick
:
0
times
01000.
so
this
guy
,
because
there
's
a
one
that
lines
up
at
the
same
place
.
we
're
going
to
get
a
1
here
,
which
is
here
too
,
right
?
and
then
there
are
no
1s
that
line
up
,
so
you
get
a
0
,
0
,
and
0.
so
you
see
how
we
got
this
guy
here
,
which
correlates
to
this
vector
in
the
controllability
matrix
.
so
you
should
be
able
to
do
ab
,
a
square
b
,
etc
,
quite
easily
,
for
at
least
2
cross
2
matrices
.
and
now
we
're
going
to
check
the
rank
of
this
guy
,
and
it
turns
out
that
the
rank
here
is
2.
but
we
have
this
condition
that
the
rank
needs
to
be
full
rank
,
or
the
matrix
needs
to
have
full
rank
in
order
for
it
to
be
controllable
.
that
means
it
should
have
all
linearly
independent
vectors
,
right
?
and
what
do
you
mean
by
full
rank
?
basically
,
your
rank
should
be
equal
to
n
,
where
n
is
the
number
of
states
that
you
have
.
here
n
is
4
,
right
?
so
clearly
,
this
guy
has
rank
2
,
not
equal
to
4
,
and
that
's
why
this
guy
is
uncontrollable
.
and
in
case
you
do
n't
want
to
sit
and
,
you
know
,
compute
rank
,
etc
,
of
all
these
things
,
you
can
even
do
this
in
matlab
.
and
this
is
the
code
for
it
.
you
create
your
a
matrix
.
create
your
b
matrix
.
then
the
ctrb
function
will
give
you
the
controllability
matrix
gamma
.
and
then
you
just
do
rank
of
this
guy
and
pops
out
2
,
which
is
not
equal
to
4
,
we
know
that
,
and
so
it
's
uncontrollable
.
okay
?
all
right
,
perfect
.
so
now
what
do
we
do
?
it
's
uncontrollable
.
should
we
just
give
up
?
no
.
we
need
to
introduce
more
controls
somehow
,
right
?
and
then
we
saw
earlier
,
how
do
you
introduce
control
?
it
's
by
putting
actuators
,
putting
motors
,
seeing
what
else
you
can
control
.
so
here
in
this
case
,
let
's
say
now
we
can
control
theta
1
double
dot
,
and
theta
2
double
dot
,
the
acceleration
of
theta
2
as
well
.
and
of
course
,
then
what
will
happen
to
your
b
matrix
?
this
is
how
the
b
matrix
will
look
,
right
?
and
to
double
check
again
,
put
it
here
.
see
if
,
in
fact
,
u
shows
up
for
both
theta
1
double
dot
,
and
theta
2
double
dot
,
and
then
we
know
that
u
is
influencing
these
accelerations
,
right
?
okay
,
so
now
we
have
this
new
guy
,
and
we
have
to
check
if
this
is
controllable
or
not
.
and
we
do
the
same
thing
again
.
we
create
the
controllability
matrix
.
and
we
're
going
to
do
this
in
matlab
,
because
we
do
n't
feel
like
computing
everything
.
and
this
is
the
code
again
for
it
.
again
,
very
similar
to
what
we
did
earlier
.
this
time
your
controllability
matrix
is
going
to
be
much
bigger
,
because
you
have
two
vectors
here
in
b.
so
your
ab
is
going
to
have
dimension
4
plus
4
times
4
cross
2
,
which
gives
you
4
cross
2
instead
of
4
cross
1.
so
each
guy
here
is
going
to
be
your
,
you
know
,
b
,
ab
,
a
square
b
,
a
cube
b.
so
you
see
,
now
your
matrix
has
expanded
.
and
anyway
,
now
you
find
the
rank
of
this
guy
in
terms
of
this
rank
is
4
,
which
is
equal
to
the
number
of
states
we
have
,
and
so
we
are
full
rank
,
which
is
great
,
because
that
means
we
are
controllable
.
okay
,
so
now
that
we
are
controllable
,
for
this
particular
system
,
what
does
it
mean
?
it
means
that
i
can
use
u
to
make
my
original
system
,
which
was
x
dot
equal
to
ax
,
unstable
original
system
,
stable
,
right
?
and
how
do
we
do
that
?
we
use
state
feedback
.
that
is
,
we
say
,
u
is
equal
to
negative
kx
.
and
now
we
're
going
to
try
and
design
our
k
so
that
we
can
force
the
eigen
values
to
make
sure
that
this
system
is
stable
,
right
?
okay
,
let
's
go
over
this
example
,
because
finding
k
for
this
huge
4
cross
4
matrix
,
etc
,
is
really
cumbersome
.
we
'll
just
use
a
simpler
system
.
let
's
shave
off
one
angle
completely
.
so
let
's
just
think
of
our
state
as
theta
and
theta
1
double
dot
,
theta
1
dot
.
so
we
've
just
gotten
rid
of
theta
2.
no
problem
.
so
we
have
this
new
guy
here
,
but
again
,
now
we
have
to
do
this
entire
charade
again
.
first
we
need
to
find
out
,
is
this
guy
stable
or
not
?
and
i
'm
just
going
to
give
you
the
answer
.
you
should
do
it
yourself
,
just
to
convince
yourself
.
but
yeah
,
this
guy
is
unstable
.
so
i
'm
going
to
introduce
control
through
this
plus
bu
thing
.
and
again
,
i
'm
going
to
say
i
can
control
the
acceleration
.
i
'm
going
to
get
this
as
my
b
matrix
.
and
now
,
is
this
controllable
?
because
that
's
the
second
question
you
ask
,
right
?
and
i
'm
going
to
tell
you
it
's
controllable
.
you
guys
can
find
out
on
your
own
.
just
make
the
controllability
matrix
.
do
it
.
it
's
good
exercise
.
and
now
i
'm
going
to
come
back
to
,
okay
,
state
feedback
.
we
're
going
to
design
state
feedback
,
but
for
the
much
simpler
system
,
so
we
can
actually
work
it
out
ourselves
instead
of
putting
it
in
matlab
.
okay
,
with
that
,
so
how
do
we
do
this
?
we
know
that
our
system
is
controllable
,
and
we
have
this
guy
,
u
equal
to
negative
kx
.
so
let
's
put
u
into
this
equation
of
our
x
dot
,
and
we
get
this
new
guy
here
,
right
,
x
dot
is
equal
to
this
big
guy
here
.
okay
.
so
we
just
put
the
values
inside
.
a
,
this
is
a.
b
,
your
k
is
this
.
1
cross
2
matrix
,
k1
and
k2
,
two
gains
,
and
what
you
finally
get
after
solving
this
entire
thing
is
this
new
guy
here
,
or
simply
a
dash
,
right
?
so
you
have
this
new
a
dash
,
where
you
've
put
in
your
control
and
everything
,
which
is
this
matrix
here
.
and
we
all
know
that
if
you
are
given
a
system
x
dot
equal
to
ax
,
or
a
dash
x
,
or
whatever
,
to
see
if
it
's
stable
or
not
,
you
check
the
eigen
values
of
a
or
a
dash
.
in
this
case
,
we
have
control
over
k1
and
k2
,
so
we
're
actually
going
to
force
the
eigen
values
through
our
k1
and
k2
to
b
to
make
sure
that
the
system
is
stable
.
and
if
you
remember
,
the
eigen
value
's
one
condition
is
that
the
,
the
real
part
of
the
eigen
value
should
be
in
the
left
half
plane
,
right
?
so
we
're
going
to
force
,
through
our
k1
and
k2
,
the
eigen
values
to
be
in
the
left
half
plane
of
the
world
.
okay
,
with
that
so
how
do
you
find
the
eigen
values
?
so
in
the
first
slide
we
pretty
much
just
put
it
in
matlab
and
said
eig
a.
but
really
,
how
you
do
it
is
,
you
find
this
guy
here
,
the
determinant
of
a
dash
minus
lambda
i
,
which
is
really
,
if
you
follow
it
,
turns
out
to
be
this
.
so
basically
what
you
're
doing
is
,
you
're
saying
a
,
and
then
you
have
,
so
when
you
actually
solve
the
system
,
you
're
just
going
to
get
minus
lambda
1
,
1
minus
k1
,
minus
k2
,
minus
lambda
2
as
your
final
matrix
.
and
then
you
find
the
determinant
of
this
guy
and
solve
it
,
and
you
'll
get
this
equation
right
here
.
okay
.
another
exercise
that
you
guys
should
be
doing
on
your
own
.
and
it
's
good
stuff
.
okay
.
so
now
that
we
have
this
characteristic
polynomial
,
what
we
're
going
to
do
is
we
're
going
to
pick
our
two
favorite
eigen
values
on
the
left
half
plane
.
and
let
's
say
we
pick
negative
1
and
negative
2.
so
now
what
we
're
going
to
do
is
,
this
is
what
we
got
.
and
this
is
what
we
want
,
right
,
which
is
just
this
guy
here
.
so
we
are
just
going
to
simply
compare
these
two
guys
,
and
get
our
values
for
k2
and
k1
,
just
by
simple
comparison
of
two
polynomials
.
because
what
happens
now
is
that
,
with
this
particular
choice
of
k2
and
k1
,
my
system
,
with
this
particular
choice
is
going
to
actually
be
stable
.
just
one
quick
thing
.
so
yeah
,
when
you
put
this
k2
and
k1
here
,
in
this
guy
,
right
,
in
this
matrix
,
now
your
a
dash
is
definitely
going
to
have
this
eigen
value
.
this
is
what
it
really
means
.
and
because
we
chose
these
eigen
values
to
be
in
the
left
half
plane
,
we
know
that
this
new
system
is
going
to
be
stable
.
okay
.
so
yeah
.
there
you
go
.
we
have
state
feedback
on
a
simpler
system
.
we
chose
our
key
,
and
now
we
know
that
this
guy
is
stable
.
so
,
woo-hoo
.
but
now
,
we
come
to
another
annoying
thing
,
which
is
that
we
do
n't
know
our
state
.
we
are
very
happy
saying
that
,
oh
,
you
should
be
negative
kx
,
but
we
do
n't
have
this
x.
what
we
instead
have
is
x
hat
,
an
estimate
of
our
state
.
we
do
n't
even
have
that
,
but
this
is
what
we
are
using
really
.
and
now
we
need
to
find
this
estimate
of
our
state
.
and
for
that
,
again
,
now
we
have
to
introduce
this
concept
of
output
.
what
can
we
see
?
what
are
our
senses
?
what
can
we
measure
?
that
's
why
the
whole
y
matrix
and
the
whole
thing
comes
in
.
why
?
because
now
we
say
,
assume
we
can
see
this
guy
here
.
theta
1.
so
,
accordingly
,
my
c
matrix
is
going
to
be
this
,
and
my
y
is
equal
to
cx
.
again
,
why
?
because
when
you
put
the
c
guy
inside
here
,
you
'll
see
that
your
y
becomes
simply
theta
1
,
and
that
's
what
we
can
see
,
right
?
so
we
choose
what
we
can
see
,
we
choose
the
senses
we
have
,
and
then
we
create
c
,
and
accordingly
,
get
this
y
equal
to
cx
thing
.
but
now
we
come
to
this
other
whole
thing
of
,
is
,
is
this
observable
?
is
this
new
system
now
observable
?
the
new
system
being
these
guys
.
is
it
observable
?
which
means
,
that
can
i
,
in
fact
,
estimate
my
state
,
x
hat
,
based
on
this
particular
c
matrix
.
and
for
that
,
you
have
a
very
simple
test
,
very
similar
to
the
controllability
matrix
.
this
guy
is
called
the
observability
matrix
.
and
because
we
have
just
two
states
here
,
this
is
going
to
be
a
short
little
matrix
.
and
you
find
out
what
it
is
which
,
you
guys
can
.
and
then
you
check
the
rank
of
this
guy
.
this
rank
is
actually
equal
to
2.
is
it
full
rank
or
not
?
well
it
is
,
because
our
states
,
our
number
of
states
are
,
sorry
,
2
,
right
?
here
.
so
yes
.
it
is
in
fact
full
rank
,
which
means
that
this
guy
is
observable
.
perfect
.
that
is
great
.
so
yay
.
but
what
does
it
really
mean
?
again
,
just
to
reiterate
,
what
it
means
is
that
from
lectures
,
you
guys
remember
that
you
can
write
the
dynamics
of
your
estimate
of
your
state
in
this
form
.
where
l
is
just
some
gain
matrix
,
very
similar
to
your
k
matrix
for
controllability
,
right
?
and
by
saying
this
,
what
it
really
means
is
that
if
you
were
to
write
down
the
error
dynamics
given
this
guy
for
your
state
dynamics
,
you
get
this
matrix
here
,
which
looks
very
similar
to
a
minus
kb
right
?
for
,
if
you
guys
remember
from
your
earlier
controllability
analysis
.
so
very
nice
.
why
?
because
now
we
can
choose
l
the
same
way
that
we
chose
k
,
to
make
sure
that
the
eigen
values
of
this
guy
here
force
the
error
to
become
stable
,
or
in
fact
,
what
that
means
is
basically
force
that
the
error
does
not
blow
up
.
it
,
as
time
goes
to
infinity
,
the
error
actually
diminishes
to
0
,
and
that
's
what
really
observability
means
.
can
you
in
fact
find
an
l
that
will
make
sure
that
the
error
goes
to
0
,
which
means
that
my
estimate
will
become
equal
to
my
state
.
okay
,
perfect
.
so
for
the
quiz
,
it
's
important
you
guys
should
be
familiar
at
least
with
what
is
really
going
on
,
what
is
the
dynamics
of
my
estimate
,
error
,
etc
.
just
be
comfortable
with
understanding
what
it
is
that
's
happening
.
and
now
all
together
,
execution
,
because
this
is
the
most
important
part
,
right
?
we
have
got
these
little
blocks
everywhere
,
controllable
,
observable
,
blah
,
blah
,
blah
.
but
we
really
do
n't
know
how
to
put
it
all
together
.
and
that
's
what
we
're
going
to
do
now
.
so
this
is
our
system
.
x
dot
equal
to
ax
plus
bu
,
y
is
equal
to
cx
.
with
this
particular
choice
of
x
,
a
,
b
,
and
c
,
which
we
've
been
solving
all
this
while
.
okay
,
and
then
we
have
found
out
that
x
dot
equal
to
ax
on
its
own
is
unstable
,
and
then
by
introducing
b
and
c
,
the
system
is
controllable
and
observable
.
great
.
controllable
means
i
can
find
a
k
to
make
sure
that
my
system
becomes
stable
.
observable
means
i
can
find
l
to
make
sure
that
i
can
in
fact
estimate
my
state
,
right
?
so
let
's
put
it
all
together
.
so
i
wake
up
at
this
time
t
equal
to
t
nought
where
i
'm
at
some
x
equal
to
x
nought
that
i
do
n't
know
,
because
i
do
n't
know
my
state
.
but
i
'm
going
to
estimate
my
x
had
to
be
some
x
hat
nought
.
right
?
just
something
.
and
i
'm
going
to
start
my
loop
with
dd
increments
.
so
i
started
d
not
,
and
i
'm
going
to
start
incrementing
time
with
dd
increments
.
okay
,
and
i
'm
going
to
read
the
output
.
because
i
do
n't
have
my
state
information
,
all
i
have
is
the
output
,
so
i
'm
going
to
read
what
my
output
is
giving
me
.
okay
,
then
using
that
,
i
'm
going
to
compute
my
control
,
u
equal
to
negative
kx
hat
,
not
using
the
output
,
using
the
estimate
,
the
initial
estimate
that
we
had
.
simply
.
okay
and
,
remember
that
you
've
already
designed
k
and
l.
okay
,
so
you
compute
your
output
,
sorry
,
compute
your
control
,
and
then
you
send
this
control
signal
to
your
system
,
right
?
and
then
you
update
x
hat
using
your
dynamics
,
where
x
hat
was
this
guy
here
.
and
this
is
where
you
use
your
output
,
what
output
you
read
.
right
?
because
for
control
you
need
x
hat
,
so
now
obviously
you
need
to
see
where
is
your
new
x
hat
,
and
that
you
're
going
to
update
through
this
guy
here
.
and
just
remember
,
when
you
're
updating
your
dynamics
,
all
i
have
here
is
x
hat
dot
.
how
do
i
find
out
what
my
x
hat
should
be
the
next
time
instant
,
you
know
what
,
you
're
going
to
use
this
oiler
's
approximation
,
which
we
all
studied
together
in
the
glue
lecture
one
,
i
think
.
and
of
course
you
've
been
going
over
it
with
dr.
egerstedt
.
basically
,
your
next
step
is
your
previous
step
,
plus
dt
times
your
dynamics
.
right
?
so
that
's
what
we
're
going
to
do
.
we
're
going
to
find
out
x
hat
dot
,
and
then
we
're
going
to
just
say
our
next
guy
is
our
previous
guy
,
which
was
this
estimate
here
,
plus
dt
times
x
hat
dot
.
and
that
'll
give
us
our
new
guy
.
and
now
we
're
going
to
repeat
.
so
now
when
we
come
back
,
we
can
read
the
output
again
,
compute
the
new
controls
and
the
control
update
x
hat
,
etc
.
this
is
how
we
put
all
of
this
stuff
together
,
for
execution
,
in
your
code
,
etc
,
whatever
.
okay
,
and
with
that
,
check
the
forums
,
good
luck
with
quiz
four
.
all
the
best
.
