1
00:00:02,130 --> 00:00:03,750
Welcome back.
This is week four.

2
00:00:03,750 --> 00:00:06,040
So we're halfway through the programming
and

3
00:00:06,040 --> 00:00:08,280
simulation lectures as well as the
assignments.

4
00:00:08,280 --> 00:00:11,600
So congratulations on making it this far.

5
00:00:11,600 --> 00:00:14,250
Last week I talked about goal to goal
controllers which allowed our

6
00:00:14,250 --> 00:00:15,880
robots to drive from their current

7
00:00:15,880 --> 00:00:18,700
location to some location in the
environment.

8
00:00:18,700 --> 00:00:20,560
And this week I'm going to talk about.

9
00:00:20,560 --> 00:00:23,320
How to create an obstacle avoidance
controller.

10
00:00:23,320 --> 00:00:27,190
And this obstacle avoidance controller,
the point of it is that we want to be

11
00:00:27,190 --> 00:00:28,640
able to drive around the environment

12
00:00:28,640 --> 00:00:30,410
without colliding with any of the
obstacles.

13
00:00:30,410 --> 00:00:32,840
So if you're driving a robot in your
living room you

14
00:00:32,840 --> 00:00:36,690
don't want it to drive into your sofa and
get destroyed.

15
00:00:36,690 --> 00:00:39,120
So this week we're going to take care of
that.

16
00:00:39,120 --> 00:00:43,140
And there are actually many ways of doing
obstacle avoidance.

17
00:00:43,140 --> 00:00:46,380
And I've picked out one particular way of
doing obstacle avoidance.

18
00:00:47,580 --> 00:00:49,440
And this is how we do it.

19
00:00:50,520 --> 00:00:52,310
First, we're going to interpret the

20
00:00:52,310 --> 00:00:55,420
IR distance as a point in the coordinate
frame of the

21
00:00:55,420 --> 00:00:58,879
sensor and transform this point into the
coordinate frame of the robot.

22
00:01:00,140 --> 00:01:01,840
Then we're going to take this point that's

23
00:01:01,840 --> 00:01:04,710
in the robots coordinate frame, and
transform it once

24
00:01:04,710 --> 00:01:06,550
again into the world coordinate frame, so
that

25
00:01:06,550 --> 00:01:09,570
we know where each obstacle is in the
world.

26
00:01:10,800 --> 00:01:14,130
What we will do then is compute a vector
from these points to

27
00:01:14,130 --> 00:01:17,550
the robot, and we will use that as an, and
sum them together

28
00:01:17,550 --> 00:01:19,770
as an obstacle avoidance vector.

29
00:01:19,770 --> 00:01:22,770
And then what we will do is the same thing
as last week is we're going to

30
00:01:22,770 --> 00:01:26,230
use this vector And use a PID controller
to

31
00:01:26,230 --> 00:01:29,310
steer the robot towards the orientation of
the vector.

32
00:01:29,310 --> 00:01:32,670
And effectively what will happen is that
the robot will drive

33
00:01:32,670 --> 00:01:37,580
in the direction that points away from any
obstacles that are nearby.

34
00:01:37,580 --> 00:01:42,910
And thus will avoid collisions.
So I've mentioned coordinate frame

35
00:01:42,910 --> 00:01:46,350
at least four or five times on this slide.
What do I mean by that?

36
00:01:46,350 --> 00:01:50,210
We use coordinate frames to give meaning
to points in some sort of space.

37
00:01:50,210 --> 00:01:52,720
So when I tell you that the robot is
located at

38
00:01:52,720 --> 00:01:57,280
xy theta, you need to know which
coordinate frame I'm talking about.

39
00:01:57,280 --> 00:02:00,910
So, in most cases I'm talking about the
world frame.

40
00:02:00,910 --> 00:02:04,610
And this world frame is centered at the
origin,

41
00:02:04,610 --> 00:02:08,530
which I'm going to denote as just zero,
zero.

42
00:02:08,530 --> 00:02:11,530
So I pick this, where this is in the
simulator.

43
00:02:11,530 --> 00:02:19,160
And with respect to this world frame, the
location of the robot is given by X and Y.

44
00:02:19,160 --> 00:02:21,420
And of course, also with respect to this
world

45
00:02:21,420 --> 00:02:23,910
frame, we have an orientation of theta, of
it.

46
00:02:23,910 --> 00:02:33,610
So, the, the robot, right here has an
orientation given by theta, and it's

47
00:02:33,610 --> 00:02:36,220
important that this theta is defined with,
with

48
00:02:36,220 --> 00:02:38,930
respect to the X axis of this world frame.

49
00:02:42,050 --> 00:02:44,830
Now, the next coordinate frame that we
have is the robot's

50
00:02:44,830 --> 00:02:49,270
coordinate frame, and this coordinate
frame is located right at the robot.

51
00:02:49,270 --> 00:02:52,250
So wherever the robot is, at the center of
this robot, there's

52
00:02:52,250 --> 00:02:55,180
a cornered frame and it's, this, this we
call the robot frame.

53
00:02:55,180 --> 00:03:01,240
So, with respect to the robot, this
direction right here going out in

54
00:03:01,240 --> 00:03:07,030
front of the robot, which aligns with the
robot's orientation is, would be theta,

55
00:03:07,030 --> 00:03:13,170
what it's maybe called theta prime is
equal to zero, in that robot's frame.

56
00:03:13,170 --> 00:03:18,330
But, theta prime in the world frame, so
maybe I'll call this theta

57
00:03:18,330 --> 00:03:22,690
prime w f, would be equal to the actual
theta of the robot.

58
00:03:24,910 --> 00:03:25,410
Now,

59
00:03:27,380 --> 00:03:31,270
the reason that we care about the robot's
frame of reference, is because we

60
00:03:31,270 --> 00:03:35,290
only know the location of the sensors and
the orientation of the sensors;

61
00:03:35,290 --> 00:03:39,300
with respect to the robot, robot frame.
So the robot knows for example, that it

62
00:03:39,300 --> 00:03:46,910
has one particular sensor, mounted right
here which is, sensor number one.

63
00:03:48,120 --> 00:03:52,430
And this sensor, it knows is, is located
at, at this point

64
00:03:52,430 --> 00:03:56,520
with respect to its own robot's coordinate
frame, and its

65
00:03:56,520 --> 00:04:01,310
orientation along in this direction.
And this orientation, with respect to the

66
00:04:01,310 --> 00:04:06,860
robot, is 90 degrees.
But in the world frame,

67
00:04:06,860 --> 00:04:12,030
this orientation would be also a function
of the actual orientation of the robot.

68
00:04:12,030 --> 00:04:18,190
So, let's call this maybe theta S prime.

69
00:04:18,190 --> 00:04:23,440
So we said that was 90 degrees, which is
the same thing

70
00:04:23,440 --> 00:04:28,330
as pi over 2.
And what we want

71
00:04:28,330 --> 00:04:33,270
to do is, to figure out where the sensor
is, so theta prime

72
00:04:33,270 --> 00:04:38,480
S, in the world frame this would be not,
nothing more than, pi

73
00:04:38,480 --> 00:04:43,850
divided by 2 plus the orientation of the
robot.

74
00:04:43,850 --> 00:04:48,390
So this would give you the angle of this
sensor in the world frame.

75
00:04:50,810 --> 00:04:56,810
Now, the way that I've denoted this in, in
the manual is, using.

76
00:04:56,810 --> 00:05:02,120
Sorry, I'm going to color this out.
Is using, X sub S four.

77
00:05:02,120 --> 00:05:05,680
So this is the x position of sensor four
in the robot's frame.

78
00:05:05,680 --> 00:05:09,660
The y position of sensor four in the, in
the robot's frame and the orientation of

79
00:05:09,660 --> 00:05:15,380
sensor four in the, in the robot's frame,
so in this case, theta s four is actually,

80
00:05:17,220 --> 00:05:23,530
so this is equivalent to minus 45 degrees.

81
00:05:23,530 --> 00:05:26,010
because that's the orientation of the
sensor with respect to the robot.

82
00:05:27,320 --> 00:05:30,950
Now, we can go even one step further than
this.

83
00:05:30,950 --> 00:05:38,590
What we can define is, a coordinate frame,
with respect to the sensor itself.

84
00:05:38,590 --> 00:05:41,130
So each sensor has its own coordinate
frame.

85
00:05:41,130 --> 00:05:42,390
So we're getting fairly

86
00:05:42,390 --> 00:05:46,620
deep in here, but, the point of that is
that when we defy it for example

87
00:05:46,620 --> 00:05:48,510
here this sensor i's frame and in this

88
00:05:48,510 --> 00:05:51,500
case it's sensor you know, it's actually
sensor four.

89
00:05:51,500 --> 00:05:54,160
And again the origin of this coordinate

90
00:05:54,160 --> 00:05:58,770
frame is located where the sensor is
located.

91
00:05:58,770 --> 00:06:01,700
And the x axis of that coordinate

92
00:06:01,700 --> 00:06:04,439
frame aligns with the orientation of that
sensor.

93
00:06:05,940 --> 00:06:07,640
And this is important because

94
00:06:07,640 --> 00:06:12,530
what we're going to do, is we're going to
figure out that the distance

95
00:06:12,530 --> 00:06:14,390
that we're measuring is actually nothing
more

96
00:06:14,390 --> 00:06:16,800
than a point in this coordinate system.

97
00:06:16,800 --> 00:06:22,370
So, here, what I've done is, the robot

98
00:06:22,370 --> 00:06:28,000
measures a distance of, so this distance
right here is D

99
00:06:28,000 --> 00:06:32,660
4 and all I've done is I said well in
this,

100
00:06:32,660 --> 00:06:37,270
particular coordinate frame, this point
right here

101
00:06:37,270 --> 00:06:39,930
is equal to this vector right here.

102
00:06:39,930 --> 00:06:43,010
So D 4 0 so because we're going a distance
of D 4, the

103
00:06:43,010 --> 00:06:45,400
X direction the distance is 0 and

104
00:06:45,400 --> 00:06:48,870
the Y direction in that particular
coordinate frame.

105
00:06:50,520 --> 00:06:54,790
Now, what we really care about in this,
in, in,

106
00:06:54,790 --> 00:06:57,820
in the controller is, well if I have this
point in

107
00:06:57,820 --> 00:07:00,950
this sensor's coordinate frame, what does
this

108
00:07:00,950 --> 00:07:02,920
point correspond to in the world frame.

109
00:07:02,920 --> 00:07:08,260
Because, as you can imagine, if I for
example have a, a point

110
00:07:08,260 --> 00:07:12,650
up here that is on an obstacle, I can say
that the obstacle is

111
00:07:12,650 --> 00:07:15,240
at this location in the world, and I know
where the robot is and

112
00:07:15,240 --> 00:07:18,640
from that we can make an informed decision
about how to move the robot.

113
00:07:19,640 --> 00:07:21,280
And that's exactly what we'll do.

114
00:07:24,380 --> 00:07:29,240
So, in order for you to be able to
calculate the transformation between the

115
00:07:29,240 --> 00:07:31,040
different coordinate frames, you're
going to need to

116
00:07:31,040 --> 00:07:33,770
know how to rotate and translate in 2D.

117
00:07:33,770 --> 00:07:37,010
And what I mean by that is that if we have
a coordinate frame,

118
00:07:37,010 --> 00:07:43,360
so say, this is my coordinate frame right
here, and I have this point.

119
00:07:45,140 --> 00:07:50,410
Right here, so I have a point right here,
lets call that 1,0.

120
00:07:50,410 --> 00:07:55,830
Now this I can also, I can pretend that
this point is a

121
00:07:55,830 --> 00:08:01,300
vector going from the origin to this point
and suppose

122
00:08:01,300 --> 00:08:06,370
what I wanted to do, is rotate this vector
and then translate it.

123
00:08:06,370 --> 00:08:08,780
And let's say that I want to rotate it and
I'm going

124
00:08:08,780 --> 00:08:16,260
to use this notation: r, and I'm going to
say, translated by one

125
00:08:16,260 --> 00:08:19,140
unit in the x direction, two units in the

126
00:08:19,140 --> 00:08:24,140
y direction and pi over four is the
translation.

127
00:08:24,140 --> 00:08:26,080
So what does this R actually mean?

128
00:08:26,080 --> 00:08:31,290
Well, the R is given by this
transformation matrix.

129
00:08:31,290 --> 00:08:37,480
And what this transformation matrix is,
does, is exactly what I just described.

130
00:08:37,480 --> 00:08:44,150
It's going to take a vector and, when you
pre-multiply

131
00:08:44,150 --> 00:08:50,040
this vector by R you're going to get the,
the, the vector transformed in space by x

132
00:08:50,040 --> 00:08:56,570
and y, translated by x and y and then
rotated by this theta prime right here.

133
00:08:56,570 --> 00:08:59,830
So we're actually translating by x prime y
prime according to my notation here.

134
00:09:01,100 --> 00:09:03,370
So going back to my example.

135
00:09:03,370 --> 00:09:05,120
What, what really, what's really going on
is

136
00:09:05,120 --> 00:09:09,436
that first, we're going to rotate the
vector by,

137
00:09:09,436 --> 00:09:14,680
Pi over 4, which means

138
00:09:14,680 --> 00:09:20,000
that it's now located at, squared of 2
over 2, squared 2 over 2.

139
00:09:20,000 --> 00:09:25,220
And then we're going add a translation in

140
00:09:25,220 --> 00:09:30,380
the x direction and then a translation in
the y direction of one unit and two units.

141
00:09:30,380 --> 00:09:32,540
Which means that, the vector that I get,

142
00:09:34,620 --> 00:09:42,747
corresponds to 1 plus squared of 2 over 2
and 2 plus squared of 2 over 2.

143
00:09:45,620 --> 00:09:52,150
So what I've effectively done here is I've
taken this point, 1,0 and

144
00:09:52,150 --> 00:09:56,910
I have translate, rotated and translated
it to this point up here, which is 1, 1

145
00:10:01,280 --> 00:10:04,050
plus square root of 2 over 2.
2 plus square root of 2 over 2.

146
00:10:04,050 --> 00:10:06,830
And that's how the rotation and
translation works, and so,

147
00:10:06,830 --> 00:10:10,290
so whether it's a point or vector doesn't
really matter.

148
00:10:10,290 --> 00:10:13,200
The point really is that I've gone through
this,

149
00:10:13,200 --> 00:10:17,500
this transformation, I've gotten a, a
translation and a rotation.

150
00:10:18,540 --> 00:10:20,700
And to be a little bit more specific, what
I've really

151
00:10:20,700 --> 00:10:27,000
done is so, on this side I would have so,
so here

152
00:10:27,000 --> 00:10:33,110
this, this should have been R,1 comma 2
comma pi over 4.

153
00:10:33,110 --> 00:10:38,910
And, what I'm multiplying, the vector that
I'm multiplying with, what you'll

154
00:10:38,910 --> 00:10:41,620
notice is that this is first of all a 3 by
3

155
00:10:41,620 --> 00:10:45,820
matrix, so we want to make sure that this
is going to

156
00:10:45,820 --> 00:10:48,870
be a 3 by 1 matrix for this to be a valid
multiplication.

157
00:10:48,870 --> 00:10:49,970
And what we're going to do is we're

158
00:10:49,970 --> 00:10:52,840
going to put the point that we're
translating,

159
00:10:52,840 --> 00:10:58,430
so let's call this xy, so this

160
00:10:58,430 --> 00:11:03,900
is x, which would've been, which was equal
to 1, y equal to 0.

161
00:11:03,900 --> 00:11:08,650
And then we're always going to place to
make, going to place a 1 right here.

162
00:11:08,650 --> 00:11:11,660
So, this stays a 1 independent of what x
and y are.

163
00:11:13,790 --> 00:11:15,790
So, why am I telling you about this?

164
00:11:15,790 --> 00:11:19,160
Well, you need this tool, you need this
transformation

165
00:11:19,160 --> 00:11:21,890
matrix in order to do our transformation
from the

166
00:11:21,890 --> 00:11:25,970
point in the centers, reference framed all
the way

167
00:11:25,970 --> 00:11:28,420
back to the world, uh,to the world
coordinate frame.

168
00:11:30,360 --> 00:11:33,470
And this is the entire calculation that
you're going to be doing.

169
00:11:33,470 --> 00:11:38,320
As you can see here what I've done is I
have, the point

170
00:11:40,370 --> 00:11:41,940
d sub i 0.

171
00:11:41,940 --> 00:11:45,950
So this is the distance that was measured
by sensor i.

172
00:11:45,950 --> 00:11:51,150
Then, I'm doing the transformation from
the sensor frame to

173
00:11:51,150 --> 00:11:54,250
the robot frame and my input into the
rotation and

174
00:11:54,250 --> 00:11:58,640
translation matrix is the position of the,
and position and

175
00:11:58,640 --> 00:12:02,390
orientation of the sensor on the robot, in
the robot's frame.

176
00:12:02,390 --> 00:12:05,530
So now this entire thing gives

177
00:12:05,530 --> 00:12:07,380
us this point in the robot's reference

178
00:12:07,380 --> 00:12:09,770
frame, instead of the sensor's reference
frame.

179
00:12:09,770 --> 00:12:14,610
So, we have to do another rotation
rotation and translation.

180
00:12:14,610 --> 00:12:19,490
And we do that by using the robot's
location

181
00:12:20,850 --> 00:12:26,360
location and orientation in the in the, in
the world frame.

182
00:12:26,360 --> 00:12:30,770
When we do that, this entire thing, right
here will,

183
00:12:30,770 --> 00:12:36,910
point, give us the point, this original
point right here, in the world frame.

184
00:12:36,910 --> 00:12:38,400
And this is exactly what this is.

185
00:12:38,400 --> 00:12:40,980
So these are the world frame coordinates
of this,

186
00:12:40,980 --> 00:12:44,840
of this point detected by this particular
infrared sensor i,

187
00:12:49,390 --> 00:12:53,810
now, let's get to the code.
Now that we're armed with this tool.

188
00:12:55,020 --> 00:12:57,100
First of all, we're going to create, or

189
00:12:57,100 --> 00:13:01,030
we've already created a new file for this
controller.

190
00:13:01,030 --> 00:13:02,980
It's going to be it's own file, so

191
00:13:02,980 --> 00:13:07,060
it's it's own controller, it's going to be
called AvoidObstacles.m.

192
00:13:07,060 --> 00:13:10,240
And like this comment says, AvoidObstacles
is really

193
00:13:10,240 --> 00:13:12,830
for steering the robot away from any
nearby obstacles.

194
00:13:12,830 --> 00:13:14,400
And really, the way to think about

195
00:13:14,400 --> 00:13:16,400
it, is we're going to steer it towards
free space.

196
00:13:18,420 --> 00:13:22,130
And, first of all, all these
transformations are

197
00:13:22,130 --> 00:13:27,010
going to happen inside of this function
called apply_sensor_geometry.

198
00:13:27,010 --> 00:13:29,690
We're going to do all three parts in there
before we

199
00:13:29,690 --> 00:13:33,440
even get to the PID part of the, of the
controller.

200
00:13:33,440 --> 00:13:35,910
And the first part is to apply the
transformation,

201
00:13:35,910 --> 00:13:39,120
from the sensor, sensor's, coordinate
frame to the robot frame.

202
00:13:40,240 --> 00:13:43,920
And really, what I'm doing here is I'm em,

203
00:13:43,920 --> 00:13:48,880
already giving you the location of the
sensor,

204
00:13:48,880 --> 00:13:52,270
of each sensor eye in the robot's
coordinate frame.

205
00:13:52,270 --> 00:13:53,830
And that what I, what I what i want you

206
00:13:53,830 --> 00:13:59,834
to do is first properly implement the get
transformation matrix.

207
00:13:59,834 --> 00:14:05,100
According to the equation that I gave on,
on previous slide, previous slides.

208
00:14:05,100 --> 00:14:09,170
And once you've done that properly, of
course, you're going to have to input

209
00:14:09,170 --> 00:14:11,530
these here.

210
00:14:12,970 --> 00:14:15,570
And then you have to figure out the proper
multiplication

211
00:14:15,570 --> 00:14:18,570
and again, you should look back at what
I've done before.

212
00:14:18,570 --> 00:14:22,210
But remember, we're only doing one step,
so really what you should be doing is, R,

213
00:14:22,210 --> 00:14:29,705
xs, ys, theta S multiplied

214
00:14:29,705 --> 00:14:34,690
by di, 0, and 1.
So this is

215
00:14:34,690 --> 00:14:37,650
what I expect you to implement, right
here.

216
00:14:40,030 --> 00:14:45,110
Then, we're going to do the next part,
which is transforming from the,

217
00:14:45,110 --> 00:14:49,390
the point from the robot's coordinate
frame over to the world coordinate frame.

218
00:14:49,390 --> 00:14:52,160
So, this follows a si, the, a similar

219
00:14:52,160 --> 00:14:54,770
pattern as what we did in the previous
slide.

220
00:14:54,770 --> 00:14:59,800
Again, what you want to make sure is that
this becomes the input for this.

221
00:15:01,770 --> 00:15:03,950
You've already implemented get
transformation

222
00:15:03,950 --> 00:15:05,150
matrix so it's spits out the

223
00:15:05,150 --> 00:15:09,250
appropriate R, and then you're going to
again have to do the calculation.

224
00:15:09,250 --> 00:15:13,110
So you pick the previous vector, so I'm
just going to represent

225
00:15:13,110 --> 00:15:18,880
that by scribbles and multiply that by r,
x, y, theta.

226
00:15:18,880 --> 00:15:22,580
And that should give me all of the IR
distances, all, all

227
00:15:22,580 --> 00:15:26,940
the points that correspond to the IR
sensors in the world frame.

228
00:15:26,940 --> 00:15:30,150
And now we know where, where obstacles are
in the world or free space

229
00:15:30,150 --> 00:15:32,180
in the world, depending on whether you're
picking up

230
00:15:32,180 --> 00:15:34,010
an obstacle or you're not picking up an
obstacle.

231
00:15:36,930 --> 00:15:42,390
Now, so like I said, we've computed the

232
00:15:42,390 --> 00:15:44,720
world frame coordinates of all of these
points.

233
00:15:44,720 --> 00:15:46,880
So each one of these points right here in

234
00:15:46,880 --> 00:15:51,160
green, we know where they're located in
the world, right.

235
00:15:51,160 --> 00:15:55,400
So, what we can do, is we can compute

236
00:15:55,400 --> 00:15:57,550
vectors from the robots to each one of
these points.

237
00:15:58,720 --> 00:16:02,070
And then what we can do, is since they're
all vectors we

238
00:16:02,070 --> 00:16:03,410
can just sum them up.

239
00:16:03,410 --> 00:16:06,380
And we can sum them up and we get this
large vector

240
00:16:06,380 --> 00:16:10,240
that's point, that is going to end up
pointing away from any obstacles.

241
00:16:11,590 --> 00:16:15,970
And the reason for that is that these
sensors so for example.

242
00:16:17,570 --> 00:16:23,120
This sensor right here, that is detecting
no obstacles or the distance is

243
00:16:23,120 --> 00:16:27,090
really great, is going to contribute much
more than this sensor which is picking

244
00:16:27,090 --> 00:16:29,790
up an obstacle close by.

245
00:16:29,790 --> 00:16:34,590
So when you sum up all these sensors, the
main contribution is

246
00:16:34,590 --> 00:16:39,500
going to be along a direction which is,
away from the obstacle.

247
00:16:41,170 --> 00:16:47,550
And then once we've done that, we can use
the orientation of this vector and use

248
00:16:47,550 --> 00:16:53,310
PID control much like we did in the doog,
google controller to steer the robot in

249
00:16:53,310 --> 00:16:58,508
to the direction of the free space.
So here is the code, in the

250
00:16:58,508 --> 00:17:04,620
main execute function of the avoid
obstacles controller.

251
00:17:04,620 --> 00:17:06,100
One thing I would like for you to pay

252
00:17:06,100 --> 00:17:08,870
attention to is that I have created this
sensor gains,

253
00:17:08,870 --> 00:17:11,400
and I ask you in the manual to think

254
00:17:11,400 --> 00:17:15,000
about how do you want to structure these
sensor gains.

255
00:17:15,000 --> 00:17:17,980
Do you want all of the sensors to count
equally,

256
00:17:17,980 --> 00:17:22,480
do we contribute with equally, do you may
be care about a particular sensor more?

257
00:17:22,480 --> 00:17:24,040
So for example do you care about the one

258
00:17:24,040 --> 00:17:26,162
that's in the front and that's the third
sensor.

259
00:17:26,162 --> 00:17:30,760
So maybe this should be 3, so that you pay
more

260
00:17:30,760 --> 00:17:32,890
attention more to the obstacles that are
in front of you.

261
00:17:32,890 --> 00:17:34,860
Do you or do you want to pay more
attention

262
00:17:34,860 --> 00:17:36,450
to obstacles that are on the side in that

263
00:17:36,450 --> 00:17:41,300
case you would maybe increase these two,
so sensor

264
00:17:41,300 --> 00:17:43,190
one and five, that go to the left and to

265
00:17:43,190 --> 00:17:44,530
the, to the right of the robot.

266
00:17:46,420 --> 00:17:49,880
So, play around with that and you should
get some interesting results.

267
00:17:50,880 --> 00:17:55,840
And again, here I'm going to, here I'm
asking you to properly

268
00:17:55,840 --> 00:18:01,180
calculate each of the UIs, so each one of
the vectors.

269
00:18:01,180 --> 00:18:04,860
And then, we're just going to sum them
together and then you're going to

270
00:18:04,860 --> 00:18:09,210
have to figure out the angle of this
vector, so you get theta ao.

271
00:18:09,210 --> 00:18:11,094
And then, just like last weekend, the goal
to

272
00:18:11,094 --> 00:18:14,440
goal controllers, so you're already
familiar with that, you need

273
00:18:14,440 --> 00:18:18,390
to compute the error between, this angle
that you want

274
00:18:18,390 --> 00:18:20,640
to steer to, and the actual angle of the
robot.

275
00:18:24,630 --> 00:18:28,290
Now, to test this we're just going to
implement this controller

276
00:18:28,290 --> 00:18:30,720
and run it on the robot so let's see what
happens.

277
00:18:30,720 --> 00:18:34,910
I mean, obviously we're, we hope that the
robot's not going to collide with

278
00:18:34,910 --> 00:18:38,230
any of the walls or any of the obstacles
that I've added to the environment.

279
00:18:38,230 --> 00:18:39,750
But let's make sure this actually happens.

280
00:18:43,100 --> 00:18:44,970
I've already implemented the controller,
so I'm going

281
00:18:44,970 --> 00:18:47,940
to head eh, go ahead and launch the
simulator.

282
00:18:49,970 --> 00:18:55,310
I'm going to hit Play, and we're going to
follow this robot and see.

283
00:18:55,310 --> 00:18:58,510
So I clicked on it to follow it, and we're
going to see what, what it does.

284
00:18:58,510 --> 00:19:01,390
It's already turned away from the, from
the obstacle.

285
00:19:01,390 --> 00:19:04,850
Now there is a wall and phew,

286
00:19:07,380 --> 00:19:12,050
we made it and here's another wall and yet
again, the robot turns away.

287
00:19:13,830 --> 00:19:18,530
And since I've implemented this controller
correctly, the

288
00:19:18,530 --> 00:19:21,190
robot should just drive around aimlessly
around this environment.

289
00:19:21,190 --> 00:19:23,210
We haven't told him where he needs to go,
we

290
00:19:23,210 --> 00:19:26,430
just have told him that he needs to avoid
any obstacles.

291
00:19:26,430 --> 00:19:29,780
And, in fact, next week, we'll talk about
how

292
00:19:29,780 --> 00:19:33,210
to combine goal to goal controllers and
avoid obstacle controllers.

293
00:19:36,130 --> 00:19:38,730
My tips for this week are again to refer
to

294
00:19:38,730 --> 00:19:42,010
the section for Week 4 in the manual for
more details.

295
00:19:42,010 --> 00:19:44,680
And I have always provided very detailed
instructions

296
00:19:44,680 --> 00:19:48,100
that should help you get through these
assignments.

297
00:19:48,100 --> 00:19:51,140
And also keep in mind that, even though

298
00:19:51,140 --> 00:19:53,440
this seems like a really difficult
approach and really

299
00:19:53,440 --> 00:19:56,130
tedious, and you could probably think of,
of a

300
00:19:56,130 --> 00:19:59,220
way easier ways of doing obstacle
avoidance with robots.

301
00:19:59,220 --> 00:20:01,190
The reason that I've done it in a way
where

302
00:20:01,190 --> 00:20:05,120
we end up with a vector is that it'll make
it a lot easier

303
00:20:05,120 --> 00:20:06,730
next week, when we combine the goal

304
00:20:06,730 --> 00:20:09,310
to goal controllers and the obstacle one
controllers.

305
00:20:09,310 --> 00:20:12,440
Because then it's a matter of just
blending two vectors

306
00:20:12,440 --> 00:20:16,020
together, we know definitely know how to
sum vectors together so.

307
00:20:17,710 --> 00:20:19,740
Stick with it and I'll see you next week.