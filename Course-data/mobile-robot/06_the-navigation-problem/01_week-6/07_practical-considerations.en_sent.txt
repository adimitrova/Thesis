the outcome of the last lecture was, in  some sense, quite glorious.
we ended up with this beautiful hybrid  atomaton that solves the general  navigation problem.
and it had all these cool things in it.
now, the problem is that, after we have  solved the general navigation problem i  said, but it doesn't work.
it was a kind of annoying to be  completely honest and today i want to  make it work by dealing with some of the  practical considerations that we really  have to, to think about.
the first is that we have this notion of  xo everywhere.
now, its hard to see, but this is the  distance.
or the point where the obstacle is.
well, obstacles aren't points.
and it's not entirely, clear how we  should translate these, real world  obstacles that aren't points, into  something that we can deal with here.
the other is what i call fat guards.
here for instance, we're saying that the  distance to the obstacle should be  exactly equal to delta.
well we're never going to be exactly = to  delta, because sensors are noisy.
so what we need to do is, we need to say,  you know what?
the distance is delta +  -epsilon.
so we basically just need to just fact ta  fi the guards, make them larger.
so that instead of switching exactly when  we're at the distance delta, we're  building some slack into the system.
[inaudible].
and then, i have a third bullet here,  that i'm calling tweak, tweak, tweak.
and the point with that one, is that,  even if you have dealt with non point  obstacles.
and we have fat a fi our goal, guards.
there are parameters.
there are things like, cgtg.
which is the coefficient in front of the  goal to goal behavior.
we have things like, delta and epsilons.
and there are all these parameters that  we have chosen.
that, mathematically, they're all fine.
but, in practice, there is no way out of  the fact that you need to test, test,  test, and tweak your parameters.
and this is, in some sense, why robotics  is so hard.
and that's, how do you actually  transition from your beautiful  theoretical design, into something that  works on the actual robots.
well, lets start with obstacles that  aren't points.
green ball is the robot, red thingy is  the obstacle,  it's not a point.
now the first thing to note is that  almost all actual sensors they're really  the return points.
point [unknown], laser scaners, infrared,  ultrasonic sensors, all of them measure  distances to things in certain  directions.
so, here are the points that i'm actually  detecting on this obstacle.
so now the question is, how do i actually  deal with this situation?
where i have not one obstacle, where i  have one obstacle but for the purpose of  robot these are let's see, 1, 2, 3, 4, 5,  6 obstacle points.
so, i have 6 points all of a sudden.
then i somehow need to deal with.
so how do i do that.
well, we have some options.
one options is, you know what?
i'm really  not interested in driving into this  obstacle, so, the point in my algorithm  that i'm going to care about, is simply  the closest obstacle.
in this case, it's this point, right?
so,  i'm simply going to say that xo is there,  that's actually not bad, it's not a bad  idea at all and then this is supposed to  be straight line.
you avoid obstacle would simply take me  in this direction, just straight away  from the closest point.
that's not bad at all.
but you know what, we have all this other  information.
why don't we take that information into  account a little bit more?
so, another  option would be to, weigh and add  obstacle vectors together, depending on  the distances.
right so, here it's closer, so i'm going  to get more in this direction.
and i'm kind fo far away so i'm going to  get little in that direction.
and then i'm going to weigh these  together and maybe, get something out  like this.
that's better.
so, there are different ways of weighing  them.
let's say that i get these weighed or  scaled obstacle vectors.
and then my obstacle avoidance is simply  going to be some scaled version, or  weighted and scaled version of that.
so this would be, u avoid obstacle now.
and what you now need to do, to find x  obstacle which we need, is to backtrack  this thing, and say that this point here,  would be x o.  now x o is not necessarily a point that  we're measuring now.
it's the scaled and weighted version of  the other points but, this is a much  better way of of doing.now the last thing  i should point out this you know what ,  you should weigh these things depending  on the distance.but then you should also  weigh depending on the direction of  travel, [cough] excuse me and what do i  mean by that.well you know what, if i'm  really on my way in this direction  [noise].
what do i care about obstacles behind me.
why should i care about that.
i really shouldn't right?
so, what i  really want to do is weigh it also based  on the direction of travel and in that  case i would get a weighted obstacle  avoidance vector out like this.
so this is almost a i would say the best  way of doing it.
and that's in fact how we're going to do  it.
now, the last thing i want to point out,  though, you know, there's another option.
i should be able to collect all the  points i'm getting, building a map of it,  so here is the obstacle service.
and then, you know what?
instead of just  dealing with the questions, like you  know, sliding, or snow sliding.
maybe i can, plan my way around this  obstacle.
now, what i want to point out , this, in  this class, we don't say things like most  bestest,  because it's grammatical nonsense.
we stay with grammatically correct  things, which means that ultra4 is out.
what i really want to say is that  building maps is an entirely different  type of topic, and all that we are  learning in this class is still very much  applicable.
so, i just want to point out that there  are ways of building maps and then  planning in those maps and then you're  goal to goal behavior, for instance,  wouldn't aim at the goal point but aim at  following planned path based on these  obstacle maps.
so want to point out option 4 but its  really not part of what we're going to  pursue in, in the class.
now the last thing or did the second  thing i said is we need to allow for fat  guards and this is because no sensor is  perfect, no actuator is perfect.
robots aren't prefect, right?
so if i  have this as my navigation hybrid  automaton, when i'm doing f1 for some  reason until g is negative, then i'm  doing f2.
and then when g becomes positive i'm  doing f1 again.
this is not sufficiently fat.
because i may end up actually switching a  lot, i may do c note for instance or i  may not but, the point is that what i  really should do is replace these guys  with this,  right?
instead of saying g less than 0, i should  say g less than negative epsilon.
and instead of saying g positive, i  should say g greater than epsilon.
so instead of having this as my switching  surface, i'm actually building this  little corridor here where i'm saying,  i'm going to use f1 until i've gone  through the entire corridor and so here's  f1.
and then i'm going to use f2 until i've  gone through that corridor.
and this factification not only reduces  chattering but it also allows us to  switch not when we're exactly delta away  from an ob, obstacle but in somewhere  delta plus minus epsilon.
so always build fat guards as a practical  precaution against the fact that de,  deployed real world is not as clean as  the theoretical world on my powerpoint  slides.
and then, like i said, the final advice,  when it comes to practical  considerations, is even though you have  built a beautiful hybrid automotan,  you've thought about everything, you have  dealt with practical considerations and  that you deal with point obstacles or non  point obstacles as susceptible points  since [unknown].
you are using sufficiently [unknown]  guards, you still have to tweak, tweak,  tweak.
you have to test these parameters.
you have to do it over and over again and  like i said, this is what makes robotics  hard and why it's a little frustrating at  times, but at the end of it, it's also  what makes it satisfying when you get it  right.
so what i'm going to do in the next  lecture is not talk at you or to you at  all.
instead, what we are going to do is to  actually going to build this system that  we now have and tweak parameters until we  are satisfied with our glorious, great,  unifying navigation system.
