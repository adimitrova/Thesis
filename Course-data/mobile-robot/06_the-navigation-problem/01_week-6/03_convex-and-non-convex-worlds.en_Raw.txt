in the last lecture, we saw that we have 
really two choices when it comes to 
combining behaviors. 
we can either switch between them or we 
can blend them. 
and what i want to do in this lecture is 
really discuss a little bit further this 
issue of, of maybe not how we should 
combine them but if we need to introduce 
something more than just our dynamic duel 
of behaviors in order to deal with the 
navigation problem. 
and as a hinted act at the end of last 
lecture, was the induced mode, 
the sliding mode is somehow going to be 
important. 
but what i want to do today is start by 
discussing different kinds of worlds or 
environments. 
and i'm going to start simple with worlds 
where everything is a point, the 
obstacles are all points. 
and then, i'm going to start building up 
more and more complex scenarios to see 
when do we actually need to introduce 
another mode or another behavior in order 
to be able to act well in the world. 
so, i'm going to start with points then 
i'm going to add a little bit of spatial 
dimension to these points so they're 
going to be circular obstacles. 
then, we're going to generalize that to 
something called convex obstacles. 
we're going to make it harder than by 
making them nonconvex. 
and finally, we're going to look at 
labyrinths. 
so, basically the maze problem. if you're 
a, if you're a rat, 
a lab rat trying to get to the cheese, 
what kind of behaviors do you need to 
actually find, find the cheese? so, let's 
start like this and what i'm going to do 
now is basically discuss the different 
worlds at the rather high level by 
drawing cartoons of what's going on. 
and then, in the next lectures, we're 
going to be a little bit more precise 
about what's going on. 
but let's start with point worlds. 
as always, blue means the robot, here's 
the robot. 
green means go and red means obstacle. 
and this little disk around the obstacle 
is simply me saying, this is the distance 
when it's unsafe to, to travel towards 
the obstacle and just switch, somehow, to 
avoiding obstacle. 
either with a hard switch or a bland and 
in this case, it really doesn't matter 
too much which one we do. so, 
the robot, well, it's simply going to 
start [sound] so here is go to goal. 
start moving towards the goal and then 
here, right? we're now hitting the, the 
bad region. 
well, we know that the obstacle avoidance 
is going to push us away like this 
somehow so, you know, we do, we're going 
to do something like this and we got 
away. 
let's say, there's a little epsilon disk 
around it. 
so, here's avoid obstacle and then, now, 
we're going to switch back and start 
[sound] going towards the goal. 
so, this seemed like a slam dunk, we did 
well somewhat at least. 
so, maybe we can declare successful point 
worlds. 
in fact, i want to show you another 
situation where i move the point a little 
bit. now, [sound] i'm going towards the 
goal and here, 
go to goal, we want to move in this 
direction and avoid obstacle, you want to 
move in exactly the same direction. 
so, what could potentially happen in this 
set up is when you answer here, the robot 
just keeps oscillating back and forth and 
it's never really finding a way around 
itself. 
there is a really, really, really 
unlikely scenario that could happen if 
you have this bilinear line up where 
everything is on the same line, where you 
just end up switching back and forth 
without really making, making any 
progress. 
now, that is extremely unlikely when an 
actual robot is out in the world. 
that ain't going to happen because the 
world is always a little bit noisy, the 
sensors are always a little bit noisy and 
even the slightest amount of noise is 
going to push you out, away from this 
situation. 
so, the punch line, when we look at point 
worlds, is these two behaviors seem to be 
enough unless we're super unlucky. 
and i call this some kind of mild zeno. 
basically you may end up trasitioning 
back and forth with no progress but like 
i said. 
in the real world, we're going to have 
noise, so points we don't really worry 
too much about. 
well, let's go up in complexity. 
let's look at circles. 
well again, let me draw a cartoon on 
what's going on. 
now, the red dot is big but i'm going 
towards the goal. 
[sound] here, i'm going to start avoiding 
the goal and then let's say here, i'm 
going to start maybe, maybe i end up 
switching back and forth a couple times 
and then 
save. 
so, circular obstacles here seem pretty 
reasonable. 
it seems like our two behaviors are, are 
basically doing the same thing. 
now, if the circular obstacle was moved 
down, again, so the center of mass of the 
obstacle was bilinear, on the same line 
as the goal and the robot, the again, we 
would get stuck in this highly unlikely, 
never-gonna-happen-in-real-life scenario. 
but basically, circular obstacles are 
point obstacles, just larger. 
but philosophically, and complexity-wise, 
we can deal with them. 
now, the next level up in complexity is 
convexity versus non-convexity. 
so, on the left here, you see what's 
called a convex obstacle. 
it's basically a, it looks like a circle 
or a disk that's being squished a little 
bit. 
what makes it convex is that if i take 
any two points inside this obstacle and i 
draw a line in between them, that line 
lays entirely inside the obstacles, 
right? 
if i take the right obstacle, which is in 
fact, not convex then, you know what, if 
i take two points, we'll find this line 
lies entirely with in the obstacle. 
but if i take a point here and a point 
there, then this line actually falls 
outside of the obstacle. 
so, an obstacle or a set is convex if 
every line in between two points in the 
set lies entirely inside that set itself. 
so, we're going to start with convex 
obstacles as the first step up from 
circles or disks and then we're going to 
look at non obstacles. 
so, i have a nonconvex obstacle, right? 
it's not a circle anymore and what i have 
here is, well, now my red marker doesn't 
show up, but any line i can draw here, of 
course, is entirely within this this 
disk. 
so, let's see what's happening here. 
the robot starts moving. 
[sound] a straight line. 
and then here gets, let's say that they, 
they now want to starts avoiding the 
obstacles so maybe avoid obstacle is 
going to push it there, it may be pushed 
back. 
what's going to happen is there is a 
point when avoid obstacle is going to 
point straight away from go to goal and 
now and we've ended up in this situation 
that was super unlucky and unlikely when 
we had a point. 
but in the convex with noncircular 
obstacle situation, that situation is no 
longer super unlucky because we ended up 
in it. 
let me again point out what's happening 
is that we're getting here, 
let's say, here is actually the point 
where avoid obstacle wants to go in this 
direction, 
go to goal wants to go in this direction 
and by switching, we're ending up there, 
which is the unlucky point, but in this 
case, it's actually not unlucky. 
so, these two behaviors themselves, 
no matter, no matter if we blend them or 
switch between them, we actually get 
stuck. 
so, we need someway of you know what, 
getting around the obstacle and somehow 
we need to follow the boundary of this 
obstacle and not just switch back 
absent-mindedly between going into goal 
and avoiding obstacles. 
so, here is a situation where we clearly 
need to introduce another behavior in 
order to be able to navigate this 
obstacle. 
well, if you have a nonconvex obstacle, 
this is known as a robotic flytrap. 
what it is, it's, it's a nonconvex 
obstacle. 
it's a cul-de-sac. 
and you know what, this robot is going to 
get down here. 
first of all, it's going to get stuck 
here right, right, because here, we have 
this go to goal and avoid obstacle 
pointing in different directions but even 
if we were able to continue here, well, 
now all of a sudden, we're going away 
from the obstacle and, no, sorry, from 
the goal. 
clearly, we need something more than just 
go to goal and avoid obstacles to do 
this. 
we need some clever way not only of 
following the boundary of this obstacle 
but following it in such a way that we 
actually progress towards the goal 
globally even though we're locally in the 
short run and getting further away. 
so, nonconvex obstacles, 
it's even worse than convex obstacles. 
two, two behaviors certainly aren't going 
to work. 
well, what if you have a labyrinth? 
so this is, you know, you have a bunch of 
different things. 
you may have something extra here. 
you may have something here. 
you have a bunch of things. 
and the robot needs to figure out that 
it's supposed to do this, right? which., 
i mean, 
[sound] now i'm going to sound, try to 
sound like i'm from new jersey, forget 
about it. that was probably not so close 
with my swedish accent. 
but anyway, it ain't going to happen with 
just two behaviors. 
clearly, no way of dealing with that with 
only avoid obstacle and go to goal so 
what we need is really at least one more 
behavior that allows us to deal with 
worlds that aren't just circular 
obstacles or point obstacles. 
that are, in fact, convex or nonconvex or 
even, you know, labyrinths. 
we want to be able to solve this problem, 
we want our robotic rat to get the, the 
cheese. 
and that is going to be the topic of the 
next lecture. 
