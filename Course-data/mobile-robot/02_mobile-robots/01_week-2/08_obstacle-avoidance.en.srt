1
00:00:00,012 --> 00:00:05,611
So now we feel pretty confident abut our
ability to design controllers that take a

2
00:00:05,623 --> 00:00:10,681
robot to a goal location. In fact we've
seen it in design, we've seen it in

3
00:00:10,693 --> 00:00:16,444
simulation, and we've even seen it in real
life. But we have not discussed the issue

4
00:00:16,456 --> 00:00:21,241
of. Well what if the robot needs to do
something slightly more elaborate than

5
00:00:21,253 --> 00:00:25,931
just get to the point for instance you
typically don't want to hit things on the

6
00:00:25,943 --> 00:00:30,316
way over there so the one behavior that I
want to talk a little bit about is

7
00:00:30,328 --> 00:00:34,972
obstacle avoidance because goal to goal
and obstacle avoidance are really the

8
00:00:34,984 --> 00:00:40,553
dynamic duo of mobile robatics. ,, . We're
going to do more things, of course. But

9
00:00:40,565 --> 00:00:45,739
underneath the hood, there will always be
a goal to goal, and an obstacle avoidance

10
00:00:45,751 --> 00:00:50,856
behavior. And let's think a little bit
about how one should avoid driving into

11
00:00:50,868 --> 00:00:56,029
obstacles. Because going to goal location
was not. Particularly complicated.

12
00:00:56,031 --> 00:01:01,297
Well, we can clearly use the same idea as
we did in go-to-goal by defining a desired

13
00:01:01,309 --> 00:01:06,625
heading, and then simply, you know, steer
in that direction. So, let's say that we

14
00:01:06,637 --> 00:01:11,644
have the following. The robot, well, it's
the blue ball. And then we have this

15
00:01:11,656 --> 00:01:17,237
little red. C, which is the obstacle,
located at xo yo. And the reason that we

16
00:01:17,249 --> 00:01:22,842
know the location of this is because the,
the disc obstraction we talked about, when

17
00:01:22,854 --> 00:01:28,473
we talked about the sensors. Okay, if this
is a goal, we would steer towards it. That

18
00:01:28,485 --> 00:01:34,427
much is clear, now, the question is If it
is an obstacle which direction should we

19
00:01:34,439 --> 00:01:40,185
steer it, when it's not as clear. I mean,
here is a direction we can go in. You

20
00:01:40,197 --> 00:01:46,263
know, let's run away from the obstacle.
But that's a little overly cautious I

21
00:01:46,275 --> 00:01:52,070
think. At least sometimes, if I'm not even
on m way towards the, The red thing. Why

22
00:01:52,082 --> 00:01:56,321
do all of a sudden I have to insist on
going the opposite direction? So. This is

23
00:01:56,333 --> 00:02:00,790
one direction which we can go in, but it
seems a little, how should I put it. It

24
00:02:00,802 --> 00:02:05,016
seems a little skittish, or paranoid. We
should be able to be a little bit more.

25
00:02:05,132 --> 00:02:09,560
Clever, maybe like this. So if we're going
in this general direction, then we should

26
00:02:09,572 --> 00:02:13,583
maybe go perpendicular to the, the
direction to the obstacle. That's one way

27
00:02:13,595 --> 00:02:17,827
in which we could be thinking but there
are other choices we could make. Let's say

28
00:02:17,839 --> 00:02:22,299
that we have a goal. Again, we're not just
avoiding obstacles, we're actually trying

29
00:02:22,311 --> 00:02:27,165
to go somewhere. This obstacle The red
obstacle we see here. Well, it doesn't

30
00:02:27,177 --> 00:02:32,465
seem to matter if I'm going towards the
goal, what do I care about that obstacle.

31
00:02:32,577 --> 00:02:37,940
So, hey we could just ignore it. That's
one direction we could go in. Or we could

32
00:02:37,952 --> 00:02:43,515
somehow combine the direction to the goal
with some way of avoiding an obstacle. So,

33
00:02:43,627 --> 00:02:48,665
we could kind of move away from the
obstacle while somewhat getting towards

34
00:02:48,677 --> 00:02:51,944
it. To goal.
The point here is that there is no obvious

35
00:02:51,956 --> 00:02:56,376
correct answer, going to goal its clear
which direction we want to go in. When

36
00:02:56,388 --> 00:03:00,961
we're avoiding an obstacle its not as
clear, its not obvi, obviously have to go

37
00:03:00,973 --> 00:03:05,496
in this direction and we have choices and
some how some choices are better than

38
00:03:05,508 --> 00:03:09,275
others. So lets, lets look at some of
these choices that we have a little bit.

39
00:03:09,275 --> 00:03:15,122
Okay.
So we have the robot in blue, we have the

40
00:03:15,134 --> 00:03:22,239
obstacle in red. And we have the goal in
yellow. This was choice one. Pi 1 is, I'm

41
00:03:22,251 --> 00:03:29,381
going to call it Pi obst plus Pi. So Pi
obst is this angle, right? So, here is phi

42
00:03:29,393 --> 00:03:37,419
obst. And in fact, Pi obst is we can write
it as arc tangent y obst minus y over x

43
00:03:37,431 --> 00:03:45,278
obst minus x. So this is some way in which
we compute the angle to the obstacle and

44
00:03:45,290 --> 00:03:53,182
then we can say well Pi 1 suggestion one
which is the. The super paranoid robot

45
00:03:53,194 --> 00:04:00,147
who's avoiding obstacles at all cost, it's
adding Pi to the mix. And by the way why

46
00:04:00,159 --> 00:04:06,769
am I adding Pi, and not subtracting Pi?
All right, so, here's the, the, the angle

47
00:04:06,781 --> 00:04:12,177
I want to go to the, this is phi obst.
And, what I'm doing no is adding Pi.

48
00:04:12,293 --> 00:04:18,469
Right, so, this is , well the point is
that it actually doesn't matter if you add

49
00:04:18,481 --> 00:04:24,187
Pi, or subtract Pi, because by now we know
that angles are slightly scary objects.

50
00:04:24,303 --> 00:04:29,614
And, we always take something like r
tangents too, to ensure that we stay

51
00:04:29,626 --> 00:04:34,949
within minus Pi and Pi. Adding Pi or
subtrac ting Pi as long as we take. Some

52
00:04:34,961 --> 00:04:40,323
safety measures, it doesn't matter. So, we
can do the same thing. It doesn't matter

53
00:04:40,335 --> 00:04:45,580
which one we choose. But, that's one way.
Now, this direction is pure in the sense

54
00:04:45,592 --> 00:04:50,574
that I don't care where the goal is. I am
just going to move away from the obstacle

55
00:04:50,586 --> 00:04:55,860
as much as I can. So, I'm going to call
this pure avoidance. No notion of where

56
00:04:55,872 --> 00:05:02,193
I'm supposed to be going. Well, we had
another choice, right? We said, what if we

57
00:05:02,205 --> 00:05:07,961
go perpendicularly to this direction?
Well, so Pi 2 is Pi obstacle plus minus

58
00:05:07,684 --> 00:05:13,419
Pi. Well, what does that mean? It means
that if I do minus Pi over 2, I go in this

59
00:05:13,431 --> 00:05:18,179
direction. If I do plus Pi over 2, I go in
that direction. And there, here it

60
00:05:18,191 --> 00:05:23,634
actually matters if I do plus or minus.
And the question is, which one should we

61
00:05:23,646 --> 00:05:29,347
choose? Well, typically that depends on
where the goal is. So we should pick in

62
00:05:29,359 --> 00:05:33,979
this case minus Pi over 2 because that
moves us closer to the goal, while plus Pi

63
00:05:33,991 --> 00:05:39,217
over 2 moves us further away from the
goal. And the punchline here is really

64
00:05:39,229 --> 00:05:44,562
that this is not a pure strategy, because
we need to know where the goal is.

65
00:05:44,762 --> 00:05:48,808
Instead, what we're doing is we're
actually, I'm calling it blended in, in,

66
00:05:48,904 --> 00:05:52,984
in the sense that we're taking the
direction to the goal into account when we

67
00:05:52,996 --> 00:05:56,924
are figuring out in which direction we
should be going. So it's not a pure

68
00:05:56,936 --> 00:06:01,175
obstacle avoidance. If I just ask you to
avoid an obstacle, you say I can't,

69
00:06:01,271 --> 00:06:05,720
because it needs to know where the goal
is. In that sense, it's not pure. So,

70
00:06:05,822 --> 00:06:10,705
that's one choice. Well, remember this
one? We said, you know what? This obstacle

71
00:06:10,717 --> 00:06:15,300
is no big deal to us, we are just simply
going to go in the direction of the goal.

72
00:06:15,402 --> 00:06:20,245
Well, this is pure goal to goal. We're
just running one behavior. goal to goal,

73
00:06:20,347 --> 00:06:26,770
we don't care about the obstacle. And
what's more interesting is this choice, Fi

74
00:06:26,782 --> 00:06:34,100
4 which is really a combination of the
direction to the goal and the direction to

75
00:06:34,112 --> 00:06:41,300
the obstacle. And the interesting thing
here is that this is clearly a blended

76
00:06:41,312 --> 00:06:47,323
mechanism, somehow we combining go to
goal, type oyds with obstacl e avoidance

77
00:06:47,335 --> 00:06:52,385
of ideas and the punch line here is that
there are really two fundamentally

78
00:06:52,397 --> 00:06:57,777
different ways of combining, avoiding
slimming interstuff and getting to goal

79
00:06:57,789 --> 00:07:03,421
points and these ways of combining things
is called an arbitration Mechanism so we

80
00:07:03,433 --> 00:07:07,822
saw typically in this case two
fundamentally different arbitration

81
00:07:07,834 --> 00:07:13,021
mechanisms one is the winner takes all
approach which is a hard switch when we're

82
00:07:13,033 --> 00:07:18,292
just going straight away from the obstacle
right so here was the obstacle here was

83
00:07:18,304 --> 00:07:23,750
the robot with the robot was going there
we're doing just avoid obstacles. Or, if

84
00:07:23,762 --> 00:07:29,597
the goal was here, right? And we're going
straight to the goal, we're doing just go

85
00:07:29,609 --> 00:07:35,049
to goal. So, these would be two examples
of hard switches. Now, the two other

86
00:07:35,061 --> 00:07:40,717
examples we saw were blended behaviors.
One was, you're combining somehow, the

87
00:07:40,729 --> 00:07:46,094
angle to the goal and the angle to the
obstacle to produce a new desired angle.

88
00:07:46,756 --> 00:07:51,228
and the first blended behavior we saw was
one where we're kind of moving

89
00:07:51,240 --> 00:07:56,668
perpendicularly to the obstacle, but we're
doing it in such a way that we're getting

90
00:07:56,680 --> 00:08:01,410
closer to the goal. And these are two
valid ways of designing arbitration

91
00:08:01,422 --> 00:08:06,659
mechanisms. And in fact, we are going to
have to get systematic and careful about

92
00:08:06,671 --> 00:08:12,565
how to do it. And I should point out that
both Approaches have merit. Now the nice

93
00:08:12,577 --> 00:08:18,630
thing about the winner takes all is that
if go to goal is only going to goal, then

94
00:08:18,642 --> 00:08:24,681
I can analyze that. If obstacle avoidance
is only avoiding obstacles then I can

95
00:08:24,693 --> 00:08:30,843
analyze that, which means that from an
analysis point of view it's easier to deal

96
00:08:30,855 --> 00:08:35,512
with hard switches. However, it's not
necessarily the case that from a

97
00:08:35,524 --> 00:08:40,243
performance point of view hard switches
are to be preferred. Because, it seems

98
00:08:40,255 --> 00:08:44,801
like as I'm walking around I'm kind of
keeping an eye on where I'm going while

99
00:08:44,813 --> 00:08:49,573
not slamming into things. So I'm not
either going towards something or avoiding

100
00:08:49,585 --> 00:08:54,345
slamming into things. So it seems like
performance wise, blending or smoothing

101
00:08:54,357 --> 00:08:59,128
the two behaviors makes a lot of sense.
However, from an analysis point of view

102
00:08:59,140 --> 00:09:03,893
it's harder. So, the question is ho w do
you design your system in such a way that

103
00:09:03,905 --> 00:09:08,608
you can have your cake and eat it meaning
you can analyze what's going on and you

104
00:09:08,620 --> 00:09:13,414
still have good performance. So, we are
going to have to bite this bullet head on,

105
00:09:13,517 --> 00:09:18,276
and in fact we would be very systematic.
And what we have done in this module,

106
00:09:18,387 --> 00:09:23,634
module two is simply introduce mobile
robots. We've looked at some basic models.

107
00:09:23,745 --> 00:09:28,967
We looked at some basic ways in which
we're getting information about the world.

108
00:09:29,078 --> 00:09:34,720
And we designed some basic behaviors, but
to be honest, we haven't been particularly

109
00:09:34,732 --> 00:09:40,363
careful about what we did. Module one, we
were also not particularly careful, but

110
00:09:40,375 --> 00:09:46,338
there the focus was on control theory. So
mobile, mo, , module three is enough chit

111
00:09:46,350 --> 00:09:51,556
chat. Let actually start this course in a
more systematic and formal matter. So,

112
00:09:51,666 --> 00:09:56,062
we're going to return to module one. In
module three and then we're going to

113
00:09:56,457 --> 00:10:01,731
return to module two. And we're going to
see, can we do what we just did, did in a

114
00:10:01,743 --> 00:10:06,941
rather heuristic and ad hoc manner in a
systematic and more formal way. And the

115
00:10:06,953 --> 00:10:12,151
way to do it is to go to the wonderful
abstraction that is linear systems theory.

116
00:10:12,262 --> 00:10:14,868
So, that is the focus of the next module.