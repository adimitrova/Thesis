hello
and
welcome
to
the
seventh
and
final
programming
and
simulation
lecture
.
this
week
,
the
programming
assignment
comes
to
its
grand
finale
,
and
we
will
have
an
ro
,
quickbot
navigate
to
the
most
complicated
environment
yet
.
and
what
makes
this
different
from
our
navigation
,
from
from
week
five
,
is
that
we
need
to
answer
three
new
questions
this
week
.
and
the
first
one
is
,
we
need
to
keep
track
of
the
progress
that
the
robot
is
making
.
last
in
week
five
,
i
talked
about
this
problem
that
the
robot
can
get
trapped
inside
of
an
obstacle
.
and
if
it
does
,
it
does
n't
,
it
does
n't
know
that
it
's
not
making
progress
.
it
's
just
going
to
try
to
keep
going
to
the
,
to
the
goal
,
and
then
it
'll
avoid
the
obstacle
,
try
to
get
back
to
the
goal
,
and
it
'll
go
on
and
on
.
it
'll
never
make
any
progress
to
the
,
towards
the
goal
.
so
this
week
,
we
'll
actually
think
about
,
is
the
robot
making
any
progress
?
and
if
robot
is
not
making
any
progress
,
maybe
we
should
,
you
know
,
use
the
controller
from
week
six
.
and
follow
the
wall
either
to
the
right
or
to
the
left
.
so
we
're
all
have
to
make
a
decision
not
only
,
do
we
now
start
following
the
wall
but
in
which
direction
,
right
or
,
or
to
the
left
?
and
finally
.
we
also
need
to
again
revisit
our
final
[
inaudible
]
finite
state
machine
from
week
five
because
that
one
will
no
longer
cut
it
for
,
for
this
week
's
obstacle
course
.
we
're
going
to
have
to
,
to
really
think
about
if
we
're
in
a
certain
state
and
certain
event
becomes
true
.
to
which
other
states
should
we
switch
in
order
to
have
the
rogo
,
robot
progress
towards
its
ultimate
goal
,
which
is
to
reach
the
goal
location
.
and
of
course
,
do
n't
collide
with
any
obstacles
,
because
that
would
be
bad
for
our
quickbot
.
so
,
all
of
the
implementation
this
week
will
happen
in
the
supervisor
,
so
we
're
only
going
to
be
worrying
about
one
file
this
week
.
and
that
's
mainly
because
for
the
past
seven
weeks
or
six
weeks
we
've
written
all
of
the
necessary
controllers
that
,
that
we
need
to
,
to
solve
this
problem
.
and
unlike
the
previous
weeks
i
'm
actually
going
to
start
off
with
the
demo
this
week
.
to
show
you
what
it
looks
like
when
it
works
.
so
let
's
see
it
in
action
.
i
'm
going
to
go
ahead
and
launch
the
simulator
and
hit
play
.
and
we
're
going
to
click
on
the
robot
and
try
to
get
it
,
oop
,
there
we
go
.
and
what
you
see
here
is
first
of
all
the
robot
has
is
navigating
out
of
this
obstacle
that
it
's
trapped
inside
of
and
it
's
following
the
wall
nicely
,
or
the
boundary
of
the
obstacle
nicely
,
and
it
's
going
to
stick
to
the
wall
until
it
decides
,
hey
,
i
'm
going
to
peel
off
and
go
towards
the
goal
location
,
because
the
goal
location
is
somewhere
up
around
this
area
.
and
you
'll
see
the
robot
has
made
it
.
and
eh
,
in
the
next
couple
slides
,
i
'll
go
over
exactly
what
decisions
have
made
to
get
to
this
point
and
what
all
of
these
beautiful
colored
lines
actually
mean
.
and
one
more
thing
,
here
in
the
map
land
command
window
,
you
can
see
that
i
have
a
few
f
,
f
statements
and
these
are
.
the
robot
switching
between
a
state
,
so
i
can
actually
see
that
i
was
in
ao
and
go
to
goal
,
and
then
i
switched
to
avoid
obstacles
,
and
then
back
ao
to
ao
and
go
to
goal
,
and
then
to
avoid
obstacles
,
and
eventually
,
there
's
also
a
follow
wall
in
here
.
and
so
on
and
so
forth
.
but
let
's
get
back
to
the
slides
.
so
.
i
talked
about
progression
.
and
we
need
progression
because
if
we
were
just
to
use
the
controller
from
week
five
i
said
we
were
going
to
get
stuck
and
that
's
for
the
,
the
,
the
reason
for
that
is
that
the
robot
is
first
of
all
trying
to
go
to
the
goal
.
so
.
right
here
i
have
the
goal
to
goal
vector
.
and
that
was
ugtg
and
that
's
pointing
me
towards
this
goal
.
so
you
can
just
imagine
this
extends
to
here
.
so
is
our
goal
to
goal
vector
we
're
already
familiar
with
that
one
.
and
i
also
have
the
obstacle
avoidance
vector
.
and
perhaps
i
'm
either
going
truly
,
go
to
goal
,
or
perhaps
i
'm
doing
something
in
between
.
so
,
but
the
point
is
that
i
'm
trying
,
that
the
robot
is
really
trying
to
drive
itself
in
this
direction
,
or
in
this
general
direction
.
so
it
's
wants
to
go
to
this
,
to
this
goal
but
it
's
a
blocked
off
by
,
by
,
by
this
obstacle
and
it
has
to
somehow
navigate
around
it
.
now
,
[
blank_audio
]
with
respect
to
progression
,
what
i
want
to
do
is
i
want
to
keep
track
of
how
close
the
robot
gets
to
the
goal
.
so
,
first
,
in
the
previous
slide
the
robot
was
at
this
location
,
and
now
in
this
slide
has
progressed
to
this
location
.
and
it
's
actually
gotten
closer
to
the
goal
.
and
.
because
the
reason
it
's
gotten
closer
to
goes
goal
,
because
this
distance
to
the
goal
is
larger
than
this
distance
to
the
goal
.
and
the
way
that
we
update
our
progress
is
by
calling
the
function
,
set_progress_point
right
here
.
so
this
function
we
'll
call
and
we
'll
make
,
we
'll
say
,
well
,
you
know
,
the
robot
has
made
some
progress
,
and
we
're
going
to
save
its
progress
but
we
're
always
going
to
store
the
closest
it
's
ever
gotten
to
the
goal
location
.
and
the
reason
that
we
do
this
is
because
we
want
to
check
a
certain
event
,
and
this
event
is
called
progress
made
.
and
progress
made
to
checks
whether
the
current
location
the
current
distance
of
the
robot
to
the
goal
location
is
shorter
than
the
last
set_progress
point
.
and
if
so
,
it
returns
true
otherwise
it
returns
false
and
we
're
going
to
use
this
to
check
whether
you
know
our
robot
has
made
progress
towards
the
goal
or
not
.
so
,
what
we
saw
in
the
what
we
saw
in
the
simulation
,
was
that
the
robots
started
somewhere
over
here
,
and
then
it
drove
in
this
direction
and
it
started
avoiding
goals
and
now
it
's
gotten
to
this
point
.
so
it
's
kind
of
follow
this
general
trajectory
,
because
it
's
gone
here
,
it
's
probably
going
.
go
to
goal
,
and
then
here
,
it
's
doing
avoid
obstacle
,
and
then
here
,
it
gets
to
the
point
where
it
says
well
,
no
progress
made
.
so
,
the
robot
's
not
made
any
,
not
made
any
more
progress
.
so
,
time
to
make
a
decision
.
and
,
the
decision
that
the
robot
makes
is
that
when
it
's
no
longer
progressing
,
it
's
going
to
try
to
switch
into
the
follow
wall
behavior
.
but
an
important
question
is
,
what
should
the
direction
should
be
?
should
we
follow
the
obstacle
at
our
left
or
the
obstacle
on
our
right
side
?
and
we
're
going
to
make
this
decision
based
on
three
vectors
.
and
we
're
going
to
make
this
decision
based
on
the
goal
to
goal
vector
which
points
towards
the
goal
.
so
this
is
pointing
me
towards
the
goal
location
.
the
obstacle
avoidance
vector
,
which
is
pointing
the
robot
away
from
the
obstacles
.
and
we
're
going
to
inspect
both
the
follow
wall
vector
.
that
we
computed
last
week
.
in
the
,
on
the
right
side
and
on
the
left
side
of
the
robots
.
so
we
're
going
to
look
at
these
four
vectors
and
make
our
decision
whether
we
need
,
we
should
follow
an
obstacle
to
the
left
or
to
the
right
.
and
that
's
,
and
that
's
how
we
determine
the
follow
wall
direction
of
the
robot
.
and
the
way
we
're
going
to
do
this
is
we
're
going
to
ask
the
questions
,
is
this
vector
,
right
here
,
follow
wall
,
and
this
is
l
again
denotes
that
it
's
,
it
's
with
respect
to
the
left
,
is
this
between
the
vector
's
obstacle
of
ordnance
and
[
inaudible
]
.
we
're
going
to
ask
that
question
.
and
we
're
also
,
at
the
same
time
we
're
going
to
ask
.
is
this
vector
.
u
follow
wall
comma
r.
between
u
_ao
and
ugtg
.
and
of
course
you
can
argue
in
this
picture
,
well
they
're
both
,
right
?
because
this
is
one
,
this
is
between
[
blank_audio
]
this
one
right
here
is
,
this
vector
is
between
the
two
vectors
on
this
side
of
things
,
whereas
this
vector
right
here
is
between
these
two
.
on
these
thought-side
of
things
.
and
really
,
the
requirement
is
going
to
be
for
,
is
it
between
these
two
vectors
?
if
the
a
is
,
we
're
going
to
look
at
the
side
where
the
angle
between
u
go
to
goal
and
u
a
o
,
so
this
angle
between
them
is
less
than
pi
.
so
less
than
180
degrees
,
so
when
we
say
is
a
vector
between
these
two
vectors
.
it
has
to
be
between
them
on
the
side
where
it
's
less
than
,
probably
where
these
two
are
less
than
pi
apart
.
[
blank_audio
]
and
the
reason
i
'm
setting
it
up
in
this
way
is
because
that
allows
us
to
just
do
a
little
bit
of
linear
algebra
.
and
the
little
bit
of
linear
algebra
that
we
're
going
to
do
is
,
is
this
following
equation
.
so
what
i
have
here
is
i
have
the
go
to
goal
vector
.
i
have
the
obstacle
avoidance
vector
.
i
have
some
scalar
parameters
.
sigma
one
and
sigma
two
.
and
on
this
side
i
have
the
follow
wall
vector
that
i
care
about
.
in
this
case
,
i
pick
the
left
side
,
but
this
might
as
well
be
the
right
side
.
and
the
condition
is
that
we
're
going
to
solve
this
linear
equation
for
these
two
parameters
.
so
.
[
blank_audio
]
what
is
this
vector
equal
to
and
oh
,
i
'm
so
sorry
.
what
is
this
scalar
equal
to
?
and
what
does
this
second
scaler
do
?
and
we
can
compute
this
we
're
you
know
,
you
just
have
to
rearrange
this
a
little
bit
.
and
what
we
're
going
to
do
is
,
say
,
the
,
the
condition
that
we
're
going
to
come
up
with
is
,
as
follows
.
if
sigma1
is
greater
than
0
,
and
.
sigma
2
is
greater
than
0.
so
if
they
're
both
positive
,
that
implies
that
if
we
have
the
two
vectors
,
ugtg
and
uao
,
then
.
this
vector
ufw
,
of
l
is
between
those
two
.
so
it
's
not
on
the
other
side
.
it
's
,
it
's
on
this
side
between
the
two
,
because
this
,
because
this
angle
right
here
is
less
than
pi
,
that
's
going
to
be
our
condition
.
and
i
have
posted
2
pdf
's
online
,
and
in
and
announcement
that
go
over
why
this
exactly
works
.
why
this
linear
algebra
works
,
and
why
it
makes
sense
.
and
i
'll
have
and
,
and
then
,
those
notes
,
i
have
some
more
diagrams
and
a
lot
more
detailed
math
,
and
you
'll
be
able
to
follow
along
exactly
what
this
little
piece
of
linear
algebra
does
for
you
.
now
,
at
some
point
the
robot
is
,
the
robot
you
know
follows
the
,
follows
the
,
the
wall
,
the
obstacle
,
so
originally
it
was
over
here
.
over
here
and
then
it
drove
around
and
drove
around
.
and
this
was
the
,
this
was
the
best
progress
we
had
made
at
any
point
,
so
right
here
.
and
it
follows
it
around
,
follows
it
around
all
the
way
until
it
gets
to
this
point
right
here
.
and
at
this
point
,
it
says
look
this
distance
here
,
from
here
to
the
goal
,
is
less
than
the
distance
from
here
to
here
to
the
goal
.
and
if
that
's
the
case
,
and
i
no
longer
need
to
slide
,
and
sliding
refers
to
that
condition
that
i
just
talked
about
in
the
previous
slide
and
we
have
one
for
either
sliding
left
or
one
for
sliding
right
,
but
in
this
case
,
it
's
sliding
left
.
and
so
if
this
condition
is
no
longer
true
,
which
it
is
n't
because
the
,
because
as
you
can
see
right
here
these
vectors
are
no
longer
between
the
[
inaudible
]
goal
and
the
obstacle
points
vector
,
and
progress
has
been
made
.
if
those
two
conditions
hold
.
then
we
can
go
switch
back
to
go
to
goal
and
our
robot
can
go
ahead
and
make
its
way
to
the
goal
location
and
it
does
n't
,
it
no
,
no
longer
has
to
follow
this
obstacle
right
here
.
now
,
like
i
said
,
the
.
state
machine
,
the
finite
state
machine
from
week
five
is
no
longer
sufficient
for
this
particular
problem
so
you
're
going
to
have
to
design
a
new
one
.
and
the
design
is
up
to
you
,
but
here
are
a
few
pointers
of
what
you
should
probably
think
about
in
your
finite
state
machine
.
the
first
is
,
as
usual
.
if
the
robot
is
at
the
goal
,
then
you
stop
.
and
it
's
useful
for
that
as
the
first
thing
that
you
check
in
the
finite
state
machine
,
because
you
do
n't
want
to
execute
anything
else
once
you
're
at
the
goal
.
once
you
're
at
the
goal
the
robot
is
done
with
its
task
and
it
's
just
going
to
stay
in
the
stopped
state
.
also
,
if
the
robot
get
into
an
unsafe
distance
to
the
obstacle
,
we
immediately
want
to
switch
to
avoid
obstacles
,
because
avoid
obstacles
really
is
our
last
ditch
effort
to
make
sure
that
a
robot
does
n't
crash
with
,
with
obstacle
.
so
it
's
usually
a
good
idea
to
have
that
in
there
,
to
make
sure
that
there
are
no
collisions
.
then
also
,
you
want
to
have
the
condition
that
if
are
you
going
to
goal
or
maybe
you
're
doing
obstacle
[
inaudible
]
and
[
inaudible
]
goal
together
,
but
both
of
these
goal
seeking
behaviors
.
and
you
're
no
longer
making
progress
then
you
want
to
switch
to
either
to
follow
wall
and
you
want
to
do
that
based
on
the
condition
whether
you
're
sliding
,
you
're
suppose
to
slide
left
or
slide
right
.
and
i
talked
about
it
in
the
previous
slides
but
make
sure
you
have
that
in
there
.
and
the
fourth
one
is
if
you
do
get
around
the
obstacle
there
will
be
a
point
where
you
're
going
to
start
making
progress
again
toward
the
goal
location
and
you
will
probably
no
lee
,
no
longer
need
to
slide
along
the
wall
in
order
to
make
progress
,
so
if
those
both
tho
,
both
of
those
conditions
are
,
end
up
being
true
,
then
you
can
go
ahead
and
switch
back
to
your
goal-seeking
behavior
,
so
which
is
either
go
to
goal
,
or
what
i
usually
like
do
to
is
if
,
if
i
'm
close
to
an
obstacle
,
which
i
typically
am
because
of
the
follow
all
behavior
i
first
switch
into
avoid
obstacles
and
go
to
goal
before
i
switch
into
pure
go
to
goal
behavior
.
now
,
my
tips
for
week
seven
are
.
again
,
read
the
manual
.
it
has
more
details
.
and
also
read
the
handouts
,
the
,
the
additional
handouts
that
i
'm
going
to
be
posting
that
explains
the
linear
algebra
.
and
do
that
.
and
then
really
the
more
,
even
more
important
one
is
when
you
design
this
finite
state
machine
,
it
's
fairly
complicated
.
and
what
i
like
to
do
is
i
like
to
get
out
a
piece
of
paper
and
a
pen
and
i
like
to
draw
the
finite
state
machine
.
really
think
about
...
what
are
all
the
states
that
the
robot
can
be
in
,
and
what
are
the
events
that
can
take
it
from
state
to
state
,
and
then
construct
it
on
paper
before
you
even
start
coding
it
.
because
then
you
,
what
you
can
do
is
you
can
take
your
piece
of
paper
,
and
you
can
pretend
you
're
the
robot
and
you
can
go
step
through
and
,
and
see
if
you
can
make
it
.
all
the
way
around
the
obstacle
to
the
goal
location
.
and
then
after
that
,
you
can
implement
it
and
you
can
test
it
.
and
then
you
'll
always
,
always
have
this
piece
of
paper
to
go
back
and
forth
and
make
sure
,
hey
is
the
robot
actually
doing
what
i
designed
the
funded
state
machine
what
i
'd
de
,
how
i
'd
design
the
finite
state
machine
.
is
it
doing
that
,
is
it
not
,
and
that
really
makes
debugging
this
week
's
programming
assignment
much
easier
.
and
usually
i
would
end
the
video
lecture
here
,
but
i
have
one
extra
special
slide
for
you
this
week
.
and
that
's
the
what
's
next
?
well
,
it
is
the
last
one
,
but
the
simulator
and
it
's
documentation
will
be
available
outside
of
this
course
at
the
following
url
.
so
the
project
continues
to
lives
on
after
this
course
,
and
at
any
time
if
you
want
to
get
new
updates
to
the
simulator
.
if
you
want
to
check
in
.
have
their
new
robots
been
added
to
the
simulator
has
there
,
have
there
,
are
there
new
sensors
,
if
there
's
now
maybe
a
camera
sensors
,
or
,
whatever
it
may
be
,
you
go
to
this
url
,
and
you
'll
be
sent
to
a
webpage
where
there
'll
be
updates
.
and
there
also
will
be
links
to
a
github
repository
.
and
the
point
of
this
github
repository
is
for
everybody
to
have
access
to
share
improvement
.
and
using
improvements
can
be
either
,
hey
,
this
is
a
way
better
way
of
for
example
,
limiting
the
error
between
minus
pi
and
pi
.
i
want
to
add
that
to
the
simulator
.
you
can
go
ahead
and
do
that
there
.
you
can
also
add
new
robots
,
so
if
you
wanted
to
have
,
for
example
,
a
robot
that
's
more
like
a
car
you
can
add
that
to
the
simulator
and
then
have
that
become
part
of
the
official
project
.
and
the
same
thing
with
sensors
and
anything
else
that
you
think
of
,
so
i
would
really
like
to
encourage
you
to
consider
if
you
're
making
any
improvements
or
adding
anything
to
the
simulator
,
contribute
back
to
the
project
because
it
'll
just
make
everything
better
.
and
future
students
and
future
users
of
the
simulator
will
really
,
really
benefit
from
your
improvements
.
and
the
last
thing
is
just
,
thank
you
very
much
for
your
hard
work
and
your
participation
in
programming
assignments
.
i
've
seen
some
really
exciting
discussions
on
the
forums
,
it
makes
me
really
,
really
happy
and
privileged
to
witness
everybody
grow
into
seasoned
robotics
experts
during
the
course
of
this
of
these
seven
weeks
.
and
with
that
,
thank
you
very
much
and
goodbye
.
[
blank_audio
]
