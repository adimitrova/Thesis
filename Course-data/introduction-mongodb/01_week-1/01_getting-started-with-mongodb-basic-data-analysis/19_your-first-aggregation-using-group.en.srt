1
00:00:00,000 --> 00:00:06,085
So let's dive in and start to explore this data using the aggregation framework.

2
00:00:06,085 --> 00:00:08,970
We'll look at what work lays in front of us in order to

3
00:00:08,970 --> 00:00:12,405
transform this data set into something we can work with.

4
00:00:12,405 --> 00:00:15,250
In terms of differentiating audiences,

5
00:00:15,250 --> 00:00:18,720
one factor is going to be the language of a film.

6
00:00:18,720 --> 00:00:23,030
Ideally, it would be easy to segment movies based on language.

7
00:00:23,030 --> 00:00:25,510
So let's see what languages are represented

8
00:00:25,510 --> 00:00:29,025
here and what cleanup is going to be required.

9
00:00:29,025 --> 00:00:31,690
Here, I have a simple script that makes use of

10
00:00:31,690 --> 00:00:36,075
the aggregation framework to summarize the values in the language field.

11
00:00:36,075 --> 00:00:37,915
What I'd like to do first is run this,

12
00:00:37,915 --> 00:00:41,905
so that we can look at the output as part of the explanation for how this works.

13
00:00:41,905 --> 00:00:43,630
In order to run this for yourself,

14
00:00:43,630 --> 00:00:48,935
you will need to plug in the connection URI for your free tier cluster.

15
00:00:48,935 --> 00:00:50,740
Note that this is the connection for mine.

16
00:00:50,740 --> 00:00:55,515
You'll need to plug in the connection URI for yours. Now, let's run.

17
00:00:55,515 --> 00:01:01,415
And you can see from the output that there are many movies in multiple languages.

18
00:01:01,415 --> 00:01:03,530
But it immediately occurs to us to ask,

19
00:01:03,530 --> 00:01:06,350
how many are there in this mix of languages?

20
00:01:06,350 --> 00:01:08,100
Do we really need to deal with all of them?

21
00:01:08,100 --> 00:01:11,135
The other issue that might pop out at you is that,

22
00:01:11,135 --> 00:01:17,025
the languages are simply comma separated within a single string for each movie.

23
00:01:17,025 --> 00:01:21,023
This makes it difficult to filter on regardless of the database you're using.

24
00:01:21,023 --> 00:01:23,435
Since this is our first aggregation,

25
00:01:23,435 --> 00:01:26,545
let's discuss the syntax before we go further.

26
00:01:26,545 --> 00:01:29,700
We can then return to the issues we've just identified.

27
00:01:29,700 --> 00:01:32,525
Here we have a $group stage.

28
00:01:32,525 --> 00:01:34,445
The identifier first stage,

29
00:01:34,445 --> 00:01:37,840
always begins with the dollar sign.

30
00:01:37,840 --> 00:01:39,730
Group is no exception.

31
00:01:39,730 --> 00:01:43,580
A group stage groups its input documents by

32
00:01:43,580 --> 00:01:46,970
a specified identifier expression and

33
00:01:46,970 --> 00:01:51,870
applies any accumulator expressions supplied to each group.

34
00:01:51,870 --> 00:01:56,190
This identifier expression stipulates that we want each group

35
00:01:56,190 --> 00:02:01,930
produced to be identified by a dictionary containing a single field.

36
00:02:01,930 --> 00:02:04,789
The key for this field should be the string,

37
00:02:04,789 --> 00:02:10,200
language, and the value should be a distinct $language value.

38
00:02:10,200 --> 00:02:17,570
This type of expression in the MongoDB aggregation framework is a field path identifier.

39
00:02:17,570 --> 00:02:22,710
This identifies a particular field in input documents,

40
00:02:22,710 --> 00:02:24,810
and the semantics of this,

41
00:02:24,810 --> 00:02:28,440
are that it's the value of that field that

42
00:02:28,440 --> 00:02:32,280
should be used where this placeholder is found.

43
00:02:32,280 --> 00:02:37,740
So for every distinct value of language in this collection,

44
00:02:37,740 --> 00:02:44,430
this pipeline will create a group and apply the specified accumulator to this group.

45
00:02:44,430 --> 00:02:47,730
Using a dictionary, labeling each of

46
00:02:47,730 --> 00:02:52,680
these distinct values with what they represent that being language,

47
00:02:52,680 --> 00:02:55,385
ensures that the semantics are clear.

48
00:02:55,385 --> 00:02:58,680
The value around which each group was created is clear and

49
00:02:58,680 --> 00:03:03,450
it's also clear that the value reflects a language designation.

50
00:03:03,450 --> 00:03:08,370
This is important especially when the output contains a variety of results.

51
00:03:08,370 --> 00:03:13,515
As you know, an aggregation pipeline passes documents from one stage to another.

52
00:03:13,515 --> 00:03:18,300
This group stage is at the very beginning of our pipeline,

53
00:03:18,300 --> 00:03:24,010
so it will be applied to the collection on which the aggregate command is run.

54
00:03:24,010 --> 00:03:30,505
In this case, aggregate is being run on our movies_initial collection.

55
00:03:30,505 --> 00:03:35,305
Each document in the collection will be passed through this group stage.

56
00:03:35,305 --> 00:03:38,200
Group stages allow us to apply any number of

57
00:03:38,200 --> 00:03:42,630
accumulators that operate on the documents passed through the stage.

58
00:03:42,630 --> 00:03:45,955
$sum is one such accumulator.

59
00:03:45,955 --> 00:03:49,810
This expression means that for every document matching the identifier for a group,

60
00:03:49,810 --> 00:03:55,595
add one to a running count of the documents grouped around that identifier.

61
00:03:55,595 --> 00:03:58,035
There are a number of other accumulators,

62
00:03:58,035 --> 00:04:02,932
many of which you will encounter in this Coursera specialization.

63
00:04:02,932 --> 00:04:09,395
Here is the MongoDB document page that describes the available accumulators.

64
00:04:09,395 --> 00:04:12,420
There are several others for arithmetic operations.

65
00:04:12,420 --> 00:04:16,170
Several that work with lists or arrays

66
00:04:16,170 --> 00:04:21,370
and a couple that enable you to calculate descriptive statistics.

67
00:04:21,370 --> 00:04:26,330
Now, one big advantage of the aggregation framework is that all the work is done

68
00:04:26,330 --> 00:04:28,820
within the database server which has been

69
00:04:28,820 --> 00:04:32,805
optimized for the operators the aggregation framework supports.

70
00:04:32,805 --> 00:04:37,751
This, combined with indexes that support extremely fast lookup operations,

71
00:04:37,751 --> 00:04:40,070
means that using MongoDB in this way makes for

72
00:04:40,070 --> 00:04:43,806
a very powerful data manipulation and analytics toolset.

73
00:04:43,806 --> 00:04:45,680
Returning to our example here,

74
00:04:45,680 --> 00:04:50,510
once all input documents have been processed through this group stage,

75
00:04:50,510 --> 00:04:54,965
the stage will admit as output one document for each group.

76
00:04:54,965 --> 00:04:58,988
Each of those documents will contain two fields an _id

77
00:04:58,988 --> 00:05:05,180
field specifying the distinct value for a language that group represents,

78
00:05:05,180 --> 00:05:11,040
and a count field that contains the number of documents in that group.

79
00:05:11,040 --> 00:05:16,490
Since this group stage is both the first and the last stage in this pipeline,

80
00:05:16,490 --> 00:05:21,950
it is the output from the group stage that we receive as output from the entire pipeline.

81
00:05:21,950 --> 00:05:29,080
The last statement in this script is our call to the aggregate method.

82
00:05:29,080 --> 00:05:33,020
Note that we're using our client connection to access

83
00:05:33,020 --> 00:05:37,505
the mflix database attribute of this connection and

84
00:05:37,505 --> 00:05:42,021
the movies_initial attribute of the mflix database.

85
00:05:42,021 --> 00:05:49,535
Finally, we're calling the aggregate method of movies_initial.

86
00:05:49,535 --> 00:05:54,530
Aggregate is a collection class method and through aggregate,

87
00:05:54,530 --> 00:05:57,118
we're passing a single argument,

88
00:05:57,118 --> 00:06:01,390
the pipeline that we've constructed here.

89
00:06:01,390 --> 00:06:03,500
Note that the pipeline is a document,

90
00:06:03,500 --> 00:06:06,890
or more precisely because this is Python,

91
00:06:06,890 --> 00:06:10,152
the pipeline is a dictionary.

92
00:06:10,152 --> 00:06:12,695
Just two other things I want to point out.

93
00:06:12,695 --> 00:06:18,690
I'm using the pprint package so that we can print out nicely formatted output.

94
00:06:18,690 --> 00:06:22,165
And because we're using Jupyter Notebooks,

95
00:06:22,165 --> 00:06:25,030
I'm importing this clear output function

96
00:06:25,030 --> 00:06:27,640
so that we can run this as many times as we like,

97
00:06:27,640 --> 00:06:31,094
and each time the prior output will be cleared for us.

98
00:06:31,094 --> 00:06:33,595
Given the way we've structured this pipeline,

99
00:06:33,595 --> 00:06:36,606
the result is the output of hundreds of documents,

100
00:06:36,606 --> 00:06:38,710
each representing a distinct value for

101
00:06:38,710 --> 00:06:41,860
language and the count of the number of documents in

102
00:06:41,860 --> 00:06:48,250
the movies_initial collection that have that value for language.

103
00:06:48,250 --> 00:06:52,030
This isn't as useful as it could be and doesn't address our question of

104
00:06:52,030 --> 00:06:56,810
how many distinct document values there are in any real useful way.

105
00:06:56,810 --> 00:06:58,210
In order to do that,

106
00:06:58,210 --> 00:07:01,360
we'll need to expand our pipeline with a couple more stages.