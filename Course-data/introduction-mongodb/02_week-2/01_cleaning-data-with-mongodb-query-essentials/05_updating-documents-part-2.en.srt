1
00:00:00,240 --> 00:00:02,765
All right, so now let's talk
about how this script works.

2
00:00:02,765 --> 00:00:04,660
Let's begin at the top of the for loop.

3
00:00:04,660 --> 00:00:08,032
Here we're using find as
we did previously, but

4
00:00:08,032 --> 00:00:14,610
the filter that we're passing here is
an empty dictionary, or an empty document.

5
00:00:14,610 --> 00:00:19,740
The semantics of this for MongoDB
are that we expect this to retrieve as

6
00:00:19,740 --> 00:00:23,250
results from this query every
document in the collection.

7
00:00:23,250 --> 00:00:28,040
Now here what we're doing is limiting
it to the first 100 documents retrieved

8
00:00:29,340 --> 00:00:31,210
using the limit method.

9
00:00:31,210 --> 00:00:32,630
Limit is a cursor method.

10
00:00:32,630 --> 00:00:35,620
So find, as we know, returns a cursor,

11
00:00:35,620 --> 00:00:39,660
which allows us to iterate over
the documents that are retrieved.

12
00:00:40,750 --> 00:00:44,718
Limit is a cursor method which will
restrict the number of results that we see

13
00:00:44,718 --> 00:00:46,838
to, in this case, to the first 100.

14
00:00:46,838 --> 00:00:47,828
I could pass 1,000 here.

15
00:00:47,828 --> 00:00:50,090
I could pass 365.

16
00:00:50,090 --> 00:00:52,850
It just depends on what you need.

17
00:00:52,850 --> 00:00:54,240
Limit also returns a cursor.

18
00:00:55,440 --> 00:01:02,620
Now doing so as part of a for loop means
that Python will iterate on that cursor,

19
00:01:02,620 --> 00:01:08,180
and each time through movie will be
the next document in the collection.

20
00:01:09,490 --> 00:01:13,026
Suppose that we hadn't set a limit here,
or that it was quite large, thousands and

21
00:01:13,026 --> 00:01:14,146
thousands of documents.

22
00:01:14,146 --> 00:01:18,408
PyMongo and MongoDB work together
to do the right thing here which is

23
00:01:18,408 --> 00:01:22,240
to return the documents
in batches of many dozen.

24
00:01:22,240 --> 00:01:25,890
So with each batch, we have that many
documents on the client's side and

25
00:01:25,890 --> 00:01:27,160
are processing them.

26
00:01:27,160 --> 00:01:32,300
And as we get close to exhausting a batch,
PyMongo

27
00:01:32,300 --> 00:01:37,360
will go fetch more documents from
the server in another batch.

28
00:01:37,360 --> 00:01:40,590
And so rather than pull documents
across from the server one at a time,

29
00:01:40,590 --> 00:01:43,110
we're pulling them across in batches.

30
00:01:43,110 --> 00:01:47,260
And that's how we end up looping through
each of the documents in the collection.

31
00:01:47,260 --> 00:01:50,151
Now the next thing to look at
are these fields_to_set and

32
00:01:50,151 --> 00:01:51,980
fields_to_unset dictionaries.

33
00:01:53,140 --> 00:02:00,030
In the body of this loop, this is where
we are building those dictionaries

34
00:02:00,030 --> 00:02:04,450
that we see as the values for set and
unset in the update document.

35
00:02:05,630 --> 00:02:12,815
So the first thing that I do here is
loop through all of the fields, pulling

36
00:02:12,815 --> 00:02:17,750
out the individual keys and values for
each document as we pass through the loop.

37
00:02:18,920 --> 00:02:23,070
If the value is some
version of an empty string,

38
00:02:23,070 --> 00:02:24,660
then I remove it from
the movie dictionary.

39
00:02:24,660 --> 00:02:26,530
Note that I'm using copy here so

40
00:02:26,530 --> 00:02:30,120
that I can do that without getting
the dictionary change size error.

41
00:02:30,120 --> 00:02:34,404
I remove it from the movie dictionary, and

42
00:02:34,404 --> 00:02:41,320
I create an entry in the fields_to_unset
dictionary for that key.

43
00:02:41,320 --> 00:02:45,870
That's how I end up with, for
example, this metacritic entry in

44
00:02:45,870 --> 00:02:50,700
the unset dictionary for this document,
because there simply wasn't

45
00:02:50,700 --> 00:02:55,620
a metacritic value for this particular
document that I'm going to update.

46
00:02:55,620 --> 00:02:56,840
It was just the empty string.

47
00:02:57,970 --> 00:02:59,540
So I can save space and

48
00:02:59,540 --> 00:03:04,530
make my data a little bit more readable
by getting rid of all that empty data.

49
00:03:04,530 --> 00:03:08,700
And then we dive into a block
of code where I'm splitting

50
00:03:08,700 --> 00:03:10,870
string values into arrays.

51
00:03:10,870 --> 00:03:11,890
Note that for each one of these,

52
00:03:11,890 --> 00:03:16,420
I'm checking to see whether it actually
exists in the movie dictionary,

53
00:03:16,420 --> 00:03:21,020
because if it was the empty string,
I would have deleted it here.

54
00:03:21,020 --> 00:03:24,940
And note that for director,
writer, genre, and so

55
00:03:24,940 --> 00:03:30,660
on, I'm specifying that that field
should actually be eliminated

56
00:03:30,660 --> 00:03:35,220
as part of the update operation,
if it wasn't already eliminated here.

57
00:03:35,220 --> 00:03:39,891
And I'm saying let's add a field
called directors in this case that is

58
00:03:39,891 --> 00:03:44,260
the array that I get by splitting
that string value of directors.

59
00:03:44,260 --> 00:03:46,880
Likewise, for writers,
genre, language, country.

60
00:03:48,110 --> 00:03:53,330
Note that for cast,
I do the split, but I don't unset

61
00:03:53,330 --> 00:03:59,014
the cast field because I'm
using exactly the same name for

62
00:03:59,014 --> 00:04:05,984
the array version of that field,
rather than some plural form of cast.

63
00:04:05,984 --> 00:04:10,886
Here I'm simply changing the name of
fullPlot so that it is camelcase,

64
00:04:10,886 --> 00:04:14,980
and doing that same change here
to use rated versus rating.

65
00:04:16,220 --> 00:04:19,070
This is the chunk of code that
creates the embedded document.

66
00:04:20,340 --> 00:04:25,302
And here I'm converting string
representations of dates to date

67
00:04:25,302 --> 00:04:28,675
times using the datetime class.

68
00:04:28,675 --> 00:04:31,575
Finally, this is one of the more
interesting bits of this

69
00:04:31,575 --> 00:04:33,265
particular script.

70
00:04:33,265 --> 00:04:37,125
It's something we actually can't yet
do in the aggregation framework.

71
00:04:37,125 --> 00:04:41,515
Here, I am changing
the data type of runtime.

72
00:04:41,515 --> 00:04:43,665
More specifically,
I'm really doing two things.

73
00:04:43,665 --> 00:04:49,170
I'm first running a match on runtime,
because if you take a look at

74
00:04:49,170 --> 00:04:54,300
any runtime you'll see that it's this
ridiculous string of 1 space min,

75
00:04:54,300 --> 00:04:58,280
6 space min, 190 space min.

76
00:04:58,280 --> 00:05:01,260
It's not an integer, so
we can't do range queries.

77
00:05:01,260 --> 00:05:04,810
We can't do any of the types of analysis
we'd really like to be able to do because

78
00:05:04,810 --> 00:05:08,480
it's a string, and a string that's
in an inconvenient form at that.

79
00:05:08,480 --> 00:05:13,640
So here at the top I've compiled this
regular expression that will do a match

80
00:05:13,640 --> 00:05:16,490
and will group the different
components of the match in such a way

81
00:05:16,490 --> 00:05:20,340
that I can pull out the integer
component for that value.

82
00:05:20,340 --> 00:05:23,980
And then I simply convert
it to an int here, and

83
00:05:23,980 --> 00:05:26,540
make sure that runtime gets
added to the fields to set.

84
00:05:26,540 --> 00:05:29,030
So that here when I
construct the update doc,

85
00:05:29,030 --> 00:05:31,980
that's one of the changes
that will be made

86
00:05:31,980 --> 00:05:37,230
as we call update_one in order to make
the necessary updates to this document.

87
00:05:37,230 --> 00:05:41,190
Now something I want to point out here is
that note that we're not doing anything

88
00:05:41,190 --> 00:05:43,890
with title, nothing with year,
nothing with plot,

89
00:05:43,890 --> 00:05:47,140
nothing with any of these fields
where we've just got a 1 here.

90
00:05:47,140 --> 00:05:49,850
We're essentially we're just
passing the value through.

91
00:05:49,850 --> 00:05:53,310
As long as there is a value other than the
empty string, we're doing nothing with it.

92
00:05:53,310 --> 00:05:54,590
That's because to update,

93
00:05:54,590 --> 00:05:58,700
we only need to identify the fields
that we want to change in some way,

94
00:05:58,700 --> 00:06:04,610
whether it's setting them to a new value
or eliminating them from the document.

95
00:06:04,610 --> 00:06:11,500
Now in this example, we're using just two
of the update operators, $set, and $unset.

96
00:06:11,500 --> 00:06:14,670
There are a number of
other update operators.

97
00:06:14,670 --> 00:06:17,000
See the lecture notes for this lesson for

98
00:06:17,000 --> 00:06:20,060
a link to the relevant
MongoDB documentation.

99
00:06:20,060 --> 00:06:21,430
I can increment values.

100
00:06:21,430 --> 00:06:26,005
I can take the min and max,
multiplication, a number of operations

101
00:06:26,005 --> 00:06:30,865
with arrays and a whole host of other
types of updates that reflect the variety

102
00:06:30,865 --> 00:06:35,265
of different things we have to do when
we're transforming our data from messy and

103
00:06:35,265 --> 00:06:38,835
somewhat ill formatted to data
that we can actually use.

104
00:06:38,835 --> 00:06:42,669
So take a look at the docs to see what
else is possible in update operations.

105
00:06:43,860 --> 00:06:46,842
Lastly, I build my update_doc
from the fields_to_set and

106
00:06:46,842 --> 00:06:50,830
the fields_to_unset, those two
dictionaries I've been building all along.

107
00:06:50,830 --> 00:06:53,990
Note that each one of
these creates a new entry

108
00:06:53,990 --> 00:06:58,140
in either the fields_to_set dictionary or
the fields_to_unset dictionary.

109
00:06:58,140 --> 00:07:01,480
That's how I end up with
output that looks like this.

110
00:07:01,480 --> 00:07:06,000
Then if I were to run this,
eliminating the limit, and

111
00:07:06,000 --> 00:07:10,430
uncommenting my call to update_one,
I would,

112
00:07:10,430 --> 00:07:13,435
one at a time,
update each document in the collection.

113
00:07:13,435 --> 00:07:17,840
Update_one is great when I'm
updating a few individual documents.

114
00:07:17,840 --> 00:07:21,310
But when I'm trying to
reshape an entire collection,

115
00:07:21,310 --> 00:07:23,820
this is not a terribly efficient strategy.

116
00:07:23,820 --> 00:07:28,500
I'm going to change this script so
that I'm actually doing bulk writes,

117
00:07:28,500 --> 00:07:33,380
rather than writing one document
at a time back to the server.

118
00:07:33,380 --> 00:07:34,910
I'll show you how to do
that in the next lesson.