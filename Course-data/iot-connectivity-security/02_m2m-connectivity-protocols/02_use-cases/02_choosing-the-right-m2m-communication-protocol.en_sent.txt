[music] hello, welcome back.
in earlier video lectures, we have discussed the key properties of the application layer m2m communication protocols.
in this lessons, we will look at set of popular communication protocols with the goal to give some guidelines to select the right protocol for your system.
one thing that always needs to be considered is that selection between any protocols is a matter of compromise.
it's rare to find a situation where a protocol fits perfectly.
checking all the check marks.
in the light of this is always a good idea to divide your criteria at least into two categories.
the absolutely necessary must have features and the optional of good to have features.
absolutely, necessary will be the features that are critical to the project or the operations performed.
good to have features would be those that facilitate the operations further.
in this video lecture, we will describe and provide some of these criteria and use cases for the considered protocols.
these criteria are deployment scenario.
the deployment scenario is one of the most important factors to look into.
in what kind of scenario will a protocol be deployed?
would be a real-time system, telemetry, security, messaging?
what kind of connection will be provided?
is it a low power lossy network or a high throughput always on setup?
all of these cases require different features from the communication protocol.
security.
you need to determine what kind of security you need and then look into whether it is provided or not by your candidate protocols.
with the current emergence of malware and data breaches, it's very important to not only project data at rest, but also data in motion and this means the data that would be carried by the protocol.
communication paradigm.
if your link layer connectivity product goal is mesh-based.
meaning, there is no primary gateway or broker.
it make sense to use an application layer, communication protocol that has the same feature.
a protocol which offers direct client to client communication without a central server.
on the contrary, if you need to aggregate data from multiple sensors, it's better to use a protocol that has a broker or central server.
in this case, there is by default, only one data point, the broker from which all the information can be collected and processed.
payload format.
the cyber-physical system rarely works on its own.
generally, it is part of a larger system, such as a control or monitoring system.
in this case, design time and complexity can be reduced by using a protocol that supports the payload format of the rest of the system.
web connected system should utilize communication protocols that support web related formats, such as hdml, xml, even json or javascript object notation.
strictly, machine to machine systems should utilize protocols that provide support for json.
compatibility with existing installation.
it is important to know what kind of protocols and systems are in use at the moment in the environment in which your system will be installed.
this should be the primary guideline for your decision unless there are severe limitations in the current systems that are going to be fixed with the new one.
quality of service.
critical systems require strong quality of service.
some protocols offer built-in quality of service features.
some protocols do not, but rely on low layer protocols to provide them.
communication performance.
speed, throughput, cashing, complexity and quality of service are all factors of performance.
how fast are the connections established?
how much throughput can the protocol provide?
does it for a cashing and resending?
what is the communication complexity and how is quality of service handled?
all of these provide a measure of the communication performance of the protocol.
the first protocol to address is http.
http offers non-optimal performance, as it was designed for always on always reliable connectivity platforms.
however, it offers the highest level of flexibility and ease of integration into current and future cloud systems without any gateways or translations.
it also offers the most comprehensive support for different payload formats.
and moreover, the newer standard https offers solid security features.
the downside of http are low performance and high energy consumption.
also, it is a connection list protocol.
so new connections have to be established, frequently.
consider coap, constrained application protocol to be a cyber-physical systems and internet of things version of http.
it offers what http does plus it is lightweight, has basic quality of service features and higher performance in terms of processing power and memory consumption.
coap was designed in such a way that it is easy to build a gateway between http and coap.
and therefore, coap can be used, rather seamlessly in web-based scenarios.
mqtt or message queuing telemetry transport protocol is good for telemetry applications, of course, because it was originally designed for this purpose.
the main issue with mqtt is security.
it by itself doesn't provide any security features although it can used with lower-level security solutions, such as tls, transport layer security.
mqtt is very lightweight.
it doesn't offer any specific payload format support.
it just transmits everything has bias.
this makes its integration with current systems, rather difficult.
because of its quality of service features, it can handle unreliable connections very well and should be considered for applications where remote operations or messaging plays the key role.
xmpp or extensible messaging and presence protocol is all about messaging, and security.
if your devices or notes require messaging between each other and this messaging should be done securely, xmpp used the protocol of choice.
xmpp supports both one to one and group oriented messaging.
security alarm systems can use xmpp to alert users on their smartphones.
as most of the modern operating systems have some form of xmpp implementation already built-in.
cities can use xmpp to alert users about traffic changes due to construction work or natural disasters, for example.
xmpp suitable to mashing to mashing messaging and then relaying that information to humans or controllers.
on the downside, it is heavy and not very real-time.
dds or data distribution service protocol is about reliability and performance.
it has a comprehensive support for quality of service.
each message will get delivered to its recipient even if the broker, which the recipient is connected to goes offline.
this reliability feature is one of the key reasons why dds is preferred in military applications.
it also has a strong focus on security.
it's very scalable and can easily accommodate growing number of nodes.
in this module and the previous one, we have discussed different communication and connectivity protocols and the underlying architecture of the web and its protocols.
in the next module, we will move onto building web connectivity into embedded systems.
[music]
