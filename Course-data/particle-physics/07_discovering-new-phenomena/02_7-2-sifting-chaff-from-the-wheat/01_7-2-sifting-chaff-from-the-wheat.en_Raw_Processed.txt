music 
in this module, we discuss searches 
new phenomena beyond known ones 
described standard model 
in this video, we will talk 
life cycle a collision event 
time event is produced 
in heart a detector, 
until gets ready to 
processed in a physics analysis 
watching this video, 
you will know we trigger physics 
events in collider experiments 
we translate analog 
digital signals detectors 
to physical objects 
that we associate 
standard model particles 
events we triggered 
we deal large amounts 
data that produced in collider 
experiments 
that in connection to we 
need to search new physics 
you already learned in module , 
proton bunches containing hundreds 
billions protons collide lhc 
in collision points 
experiments installed 
this is one general purpose 
detectors lhc, atlas detector 
we already gone elements 
functions in video a 
if you take a look transverse 
view detector you will see 
that an onion structure 
is made various layers 
different detectors 
an inner detector inside a solenoid 
used tracking charged particles 
calorimeters electromagnetic 
hadronic shower measurements 
a muon spectrometer in 
toroidal magnetic field, 
muon momentum measurements 
protonproton collisions result 
in many particles decay to 
lightest elementary particles 
compatible quantum numbers 
leave signatures in 
detector digital analogue signals, 
reconstruct objects that we 
associate elementary particles 
so particles we reconstruct in 
detector electrons, photons, 
muons quarks, 
gluons particle jets 
details detector 
response to various particle types 
given in video a 
events that contain sufficiently 
interesting features to 
analyzed triggered 
stored processing 
events go 
event reconstruction 
to ensure an accurate measurement 
properties reconstructed objects, 
a calibration procedure is applied 
calibrated objects ready 
analysis 
in analysis, 
we need to compare 
data to theoretical calculations 
to achieve this, event simulations called 
monte carlo simulations performed, 
create artificial events based 
a specific theoretical assumption 
components in place, 
reconstructed 
calibrated data one hand, 
data simulated according to 
theoretical predictions hand, 
we ready to search 
new physics in data 
lets first understand 
components better 
lets start trigger 
this actually 
lhc is colliding proton bunches 
a maximum rate mhz 
event recorded 
experiment, containing digital 
analog information detector, 
a data size one megabyte 
so saving events would lead to 
terabytes data per second 
this is a huge amount data to store, 
also to process 
furthermore, events 
contain known physics, so 
we need to select to keep 
this is trigger system comes in 
trigger system large 
multipurpose experiments 
consists two main components, 
a hardware based one 
a software based one 
trigger system is built 
to extremely robust 
fast needs to take a reliable 
decision in a short time 
trigger helps selection 
interesting events, 
also applies upper limits in 
number events we select 
steps 
triggering events that contain new 
phenomena is an extremely big challenge 
we dont know a priori 
events would look like 
we therefore to build trigger 
selections generic enough to ensure we 
dont lose anything interesting, 
events we dont trigger 
simply lost forever 
events that triggered 
detector tells us elementary 
particles that created 
in collision process 
well properties 
typically particles 
relevant in searches new physics 
we will see in following 
videos this module 
an overview is given in video a 
here, we summarize detector response 
to main types particles 
electrons muons leave 
tracks in inner detector 
electrons reconstructed 
matching track 
electromagnetic shower 
muon, 
inner detector track is matched to 
a muon track in muon spectrometer 
photons, neutral, 
leave track in inner detector 
therefore associated to 
an electromagnetic shower track 
pointing to 
quarks gluons much 
complicated objects to reconstruct 
cant live 
to exist in bound states, 
already explained in module 
hadronize 
therefore reconstructed in 
calorimeter a hadronic shower 
algorithms scan calorimeter 
data in order to identify 
significant energy depositions, 
corresponding to quarks gluons 
resulting objects jets 
worth pointing that 
dominant process resulting 
a protonproton interaction is 
production quarks gluons 
therefore jets dominate 
detected final states 
neutrinos interact a detector 
therefore escape undetected 
however, we get 
information neutrinos 
using knowledge that 
in transverse plane, 
conservation momentum, 
vector sum momenta 
objects to zero 
so neutrinos associated a 
missing momentum in transverse plane 
neutral 
weakly interacting particle, 
dark matter candidates, 
will in fact behave like neutrinos 
will identified missing 
transverse momentum in detector 
missing transverse momentum is extremely 
important in searches new physics 
w, z, higgs bosons, top quarks, 
tau leptons decay immediately 
to elementary matter particles 
we reconstruct 
decay products 
in a detector, we therefore 
observe various event topologies 
based characteristics 
we classify events 
this is in fact we 
already trigger level 
we running algorithms that 
perform simplified reconstruction 
based characteristics 
events, we accept discard 
example, events high momentum 
objects, large multiplicity objects 
accepted trigger 
processing 
events low energy particles 
generally accepted, 
general interest 
since correspond to 
low q processes 
would also impossible to store 
process 
common ones 
despite fact that we finding ways 
to reduce amount data we need to 
process, 
we still generating 
incredibly large amounts data 
large amounts needed to ensure 
that rarest processes will produced 
saved in data 
would processes 
coming new physics 
this data gets reconstructed 
calibrated we said 
is products this 
process we eventually using 
without ever discarding original data, 
since we often need to reprocess to, 
example, 
improve reconstruction calibration 
in order to make best use 
large amount data, 
we use sophisticated methodologies, 
machine learning techniques 
statistical methods 
often cpu intensive 
this adds to computing 
needs lhc experiments 
is data simulation storage 
we need, also processing power 
this is a combination that 
creates a great challenge 
this challenge is addressed 
using major innovations in computing, 
computing grid 
numerous computing centers in universities 
world interconnected, 
forming a computing grid 
receive copies data 
give capability to 
scientists to run analyses 
processes this grid in an automatic 
transparent way 
research development in computing 
domain is in active progress 
task is always 
extremely challenging 
rewarding time 
this concludes this lecture 
in next video we will talk 
a specific type searches 
so called bump searches 
music 
