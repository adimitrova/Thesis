In this module, you'll be introduced
to the concepts of file formats, compression, data normalization,
and transformations. By the end of the module,
you'll understand why these are important. And you'll be able to make decisions
about which approach to use when. You'll also be able to use
the content featured in the module to help improve your research
data management practice. So what is a file format? A file format is a way of encoding
information within a computer file. A program or an application
needs to recognize that file format in order to be able to
access the content within the file. A web browser, for example,
will recognize HTML, things in hypertext markup language, and will be able to open
these files and display them as webpages. If a browser comes across a different type
of file it might call on a special kind of plugin to be able to open and
display those files. Otherwise, if it doesn't recognize
the file type, it may offer the option to download the file so
you can open it with the relevant program. The file format is often indicated as
part of the file name in an extension or suffix. Conventionally, the extension follows
a full stop in the file name, and has three or four letters that
identify the format such as jpg for JPEGs, or docx for a Word document. Files in proprietary formats usually
have to be opened by the specific software in which they've been created. So this means that somebody
without a license for that software can't
always open those files. In contrast, open formats are ones
in which the software company or the collective that's created that
software, has made it openly available. And this usually means that a number of
applications have been developed which can open those types of files. Adobe PDF is good example
of an open format. It can be opened by a number of
applications, not just Adobe products. File types are based on either text or
binary encoding. Text files are machine readable
through character encoding standards, such as ASCII and Uni-Code, whereas binary files are run by applicable
software and may be proprietary. Only binary formats can be executed. Some file types include both binary and
text, such as the rich text format. A big advantage of creating or
saving your research data in a text format is that the file can be read in a plain
text editor, like Windows Notepad, and is human-readable. They can be opened in any operating system
and by a wide range of applications. Some of the well-known file extensions
of plain text files are .txt, .csv, .asc, .html, and .xml. Most software packages allow export and
exchange formats, so you can create a text file for
import into another program. For example, in Microsoft Excel, you can
save your spreadsheet as a CSV file. File formats that are open,
non-proprietary and in widespread use, stand the best chance
of being readable well into the future. In contrast, proprietary formats,
especially those that are non-standard, that require specific
software applications or particular versions of that software,
are likely to pose issues for future use. Rapid changes in technology in the market mean that file formats can
very quickly become obsolete. This obviously has negative connotations
for long-term preservation and reuse. If you want your data
to be accessible later, you're best to convert
it to open standards. Data formats that conform to
agreed international standards are less likely to become obsolete, as there should be a range of software
applications that can read them. There may well be trade-offs in terms
of software functionality though, such as a loss of formatting or macros. Sometimes there is a de
facto standard that's used. PDF for example has become the de facto
standard for publishing documents on the web in a way that retains
the original layout, fonts, and text. At some point during your research,
you may need to convert or migrate your data files
from one format to another. This could be because you've upgraded
your PC, you've got new software, you're sharing data with a collaborator who uses
different software, you're using a shared platform, or simply because you want your
data files to be readable in the future. A checksum algorithm tool can be
used to compare the bits of a file when it's been moved from
one medium to another. Checksums are typically
run by repositories to perform data integrity checks. These won't work however,
if the file format has changed or if you're comparing files across
different computing platforms. At some point during your research you
may choose to compress your files. This could be to fit them onto
a particular storage device or for transmission or transportation. Compression is also known
as bit-rate reduction. It involves encoding
the information in fewer bits than the original representation. Zip is a de facto standard compression
format that's used on Windows, Macs, Linux, and Unix platforms. Zip is a lossless type of compression, which means the file should be identical
to the original once you unzip it. There are also lossy types of compression
associated with some multimedia file formats. These may result in some
kind of distortion or loss of quality fidelity when played. Tar, tape archive files,
are commonly used in Unix or Linux to bundle a set of files into one. Tar files may also be zipped
to reduce the file size. Lossiness can be one
trade off of compression. Another is the amount of processing
time it takes to compress and decompress the files before or during use. The amount of computing resource
needed can also be an issue, particularly in the case of very
large files or shared servers.