


--- SKIP ---: 01_why-is-calculus-going-to-be-so-much-fun.en.srt


--- SKIP ---: 01_why-is-calculus-going-to-be-so-much-fun.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-calculus-going-to-be-so-much-fun.en_SENTbySENT.txt
* [MUSIC]
* Welcome to calculus one
* I'm glad you're in this course, or maybequest for understanding calculus
* Alright, we really are on a quest, you know, we're taking thousands of years ofhuman ingenuity
* Right
* The sort of triumph of humankind to beable to understand numbers and functions
* All of these insights that humans have hadfor thousands of years, and we're just distilling all those downto short videos and exercises
* You know, and it's not going to be easy,all right
* To take thousands of years of insight, andtry to cram that in to short online learning modules, it's goingto be challenging to understand all thisstuff
* But I think the payoff is worth it
* You know
* Anf for me the payoff is worth it, because the concepts in calculus are justreally cool
* Calculus is a huge subject, and itcombines just a lot of different topics
* You know, a calculus course and thiscourse, introduces things like functions and limits, talk about infinity, talk about derivative, talk about area andintegrals
* And the big surprise is that all of these seemingly unrelated topics, end upbeing related
* Right
* There's connections between all of these different concepts that are appearing incalculus
* And I think those kinds of connections arejust very exciting
* Another cool thing about calculus, is thatwe get to do a lot of neat computations
* Alright, we're going to learn how tocompute derivatives, compute areas
* You know, but don't get me wrong
* Right
* At the end of this whole process, the goalisn't really to be able to compute things
* Right
* The goal is insights, it's understanding,it's some appreciation of the concepts, and how these conceptsconnect together
* And doing the computations is certainly a prerequisite to being able to understandthose concepts
* But I really hope to, to dig deeper, youknow, and to be able to see how all of these differentideas within calculus are related
* It's going to be a challenging quest, butI think it's a worthwhile quest, and I'm glad thatyou've chosen to join us
* Good luck
* [MUSIC]


--- SKIP ---: 03_how-is-this-course-structured.en.srt


--- SKIP ---: 03_how-is-this-course-structured.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-is-this-course-structured.en_SENTbySENT.txt
* [MUSIC] My other massive open online courses arebuilt around a calendar
* There's a start date, an end date, and then new material gets released everysingle week
* [BLANK_AUDIO] In contrast, this course is self-paced,meaning that not only can you sign up at any time, but you can start thiscourse at any time
* And then you can work through the material as quickly or as methodically as you'dlike
* My hope is that this new format will justlet a lot more people learn a lot more math, butit's an experiment
* You know
* And I hope that you'll be able to providesome feedback as to what's working well and what stillneeds to be improved
* So I personally just really appreciate anyfeedback that you can provide about this course and about how wecan make it better
* You know, I hope that working together we can really produce just a fantasticexperience learning calculus
* [BLANK_AUDIO] [MUSIC]


--- SKIP ---: 01_how-do-we-get-started-with-calculus.en.srt


--- SKIP ---: 01_how-do-we-get-started-with-calculus.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-do-we-get-started-with-calculus.en_SENTbySENT.txt
* [MUSIC] Well now, it's time to do some calculus
* Calculus is all about relationships
* All throughout the world,there's these quantities
* And some of those quantitiesare connected together
* Well how so
* Maybe one of those quantities isthe input to some sort of machine, or some sort of mathematical expressionthat transforms that quantity in to a new quantity, an output quantity
* Maybe two of those quantities are forcedto vary together for some reason
* Maybe you've just got a tableof numbers that tell you how to take certain input valuesto certain output values
* Maybe you've got a graph thatyou're reading that tells you how to take an x coordinate andoutput a y coordinate
* But regardless of how youconceptualize this idea, there's relationships between differentquantities in the real world and we're often encoding thoserelationships through functions
* The other big idea I wannathink about now are limits
* Sometimes I'm not just interested ina function's value at a single point
* Sometimes I wanna know what happensif I evaluated that function at nearby points as well
* And try to make sense of that precisely,that's what limits are gonna do for us
* So to begin our quest in calculus,we're gonna look at two big ideas
* We're gonna look at functions andwe're gonna look at limits
* [MUSIC]


--- SKIP ---: 01_what-is-a-function.en.srt


--- SKIP ---: 01_what-is-a-function.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-a-function.en_SENTbySENT.txt
* [MUSIC] Calculus study functions and this course is no exception
* We're going to be studying functions in this course, alright
* Functions like f of x or the sine function or the square root function
* And that raises a question what are functions?If If we're going to be studying functions, we should know what they are
* And that question is pretty metaphysical
* I mean what are numbers
* What are numbers for
* I mean that question doesn't make a lot of sense does it
* I, you know, it's not like a number four is a physical object that I can go look at it and see if it's got polka dots or it's striped or something, right
* But I know four objects when I see them, right
* I sort understand what numbers do more than what they are in some metaphysical sense
* The same is true about functions, right
* I'm not really going to tell you what a function is
* What I'm going to tell you is what a function does
* This is what a function does
* A function assigns to each number in its domain another number
* And this definition doesn't say anything about how the function does that assignment
* Let's see an example
* Just make up some example
* Suppose I've got some function, I'll call it f, f for function
* Maybe this function assigns to the number two, the number four
* So, I'll write f(2) is 4 or f(3) is 9 Or f(4) is 16 of f(5) is 25
* I'm just making this up
* This is a function
* And I'm telling you what number it assigns to each number, right
* f assigns the number two, the number four
* f(3) is 9, right
* So, f assigns to the number three, the number nine
* Well, look, I'm not going to just list off every single assignment that f makes
* So instead, one way to talk about these assignments is to use a rule, like f(x) = x^2
* And this single rule explains how all of these assignments are made, alright
* This rule said that f assigns to the number x, the number x^2
* So in particular, f assigns the number five, five squared or 25, or f assigns the number four, four squared which is sixteen or f assigns the number three, three squared which is nine, alright
* So, a lot of times, when you actually want to talk about how these assignments are being made, use some sort of rule like this: and you write f of x is something, to compute the output value, right
* So, a function assigns to each number in its domain another number
* One way to do that is with a rule
* Of course, this definition of function involves another word, domain
* What is a domain
* Unless, I say otherwise, the domain consists of all numbers for which the rule makes sense, right
* A function assigns to each number in its domain another number
* And the domain is just the numbers that I can plug in
* Let's take a look to see what I mean by this
* Suppose I've got a function f(x) = 1 / x
* So, that's a function given by a rule
* It takes an input x and produces the output 1 / x, right
* It assigns the number x, the number 1 / x
* But this rule doesn't always make sense, right
* I'm dividing by x, alright
* And to divide by x, what do I need
* Well, I must have that x is not zero, not permitted to divide by zero
* So, I can plug in any number for x except for zero
* And that's when this rule makes sense
* So, I'll summarize that by saying that the domain of f is all real numbers except zero
* So, a function takes some input and produces some output
* That's what it does
* But how is that supposed to make us feel, you know
* How are we supposed to imagine that
* Well, here's one metaphor that you could use to try to think about what a function is actually doing, right
* You could imagine a, a conveyor belt with the function, you know, And you could imagine the numbers coming in
* Boom
* Being hit by the function and then going out transformed somehow, by whatever the rule is of the function
* Here's what I'm talking about
* I've got a conveyor belt here, I got this big box, and imagine if that big box is the function
* And in here, I've got the input, imagine the number five
* Let's see what this machine is going to do
* Maybe this is the function f(x) = x^2 + x and I've got this number five here
* And I'll start the conveyer belt going so the number five starts moving through the machine and when the machine is done processing it, it comes out the other side and now, it's the number 30, alright
* Because f(5) is 5^2 + 5, which is 25 + 5 is 20
* So, we have seen how you can write down a function by using a, a rule involving these, these mathematical symbols, right
* x^2 + x
* You can also write down a function just using English words
* So, let's see an example of that, just make up a new function here
* I'll call it R(x) and I'll define Р вЂњРІР‚С™Р вЂєРІР‚РЋР вЂњРІР‚С™Р вЂ™Р’В R(x) to be thrice, that means three times, thrice the square root of x
* And here, I've computed some, some values of the function, you know, like the function that four is six
* Well, why is that
* Well, R(4) would be three times the square root of four, which is three times two which is six
* Okay
* Now, of course, when I do the calculation this way, you know, it's not too surprising that instead of writing this out in words, thrice the square root of x, I mean I could have just written three times the square root of x
* So, maybe you're not too impressed with this
* The point is that you can define a function just by writing down what the function is supposed to do using English words
* So, we've seen an example of a function that we defined just in terms of algebra, f(x) = x^2 + x
* I've also seen an example of a function that I define entirely with just English words
* We can kind of combine those two things, alright
* We can use the English to sort of pick out different kinds of of algebra
* Let's see an example of that now
* So, here's another function I just made up
* g(x) is x^22 if x is bigger than or equal to five
* And twice x if x is less than five
* The point here is that I'm using just a little bit of English
* So, this word, if, in order to select based on how big x is, a different algebraic rule for calculating the function and this is a little abstract
* Let me just do with some calculations and that might convince you, you know, how, how this notation is, this so-called piecewise notation works
* So, what is g(1)
* Well, let's take a look
* One is less than five so that means I use this second rule for calculating g, so it's two times one which is two
* What's g of, say, four
* Well, four is still less than five so I use the second rule again
* Twice the input, two times four and that means the output is eight
* But what is, say, g(5)
* Ooh
* Five is not less than five
* Five is greater than or equal to five
* So, this if is telling me to use the first of the two rules for calculating g so I'm going to use five squared as the output and that will be 25
* Or g(10)
* Well, ten is definitely bigger than or equal to five and it's bigger than five
* So, I again use the first rule and the output to this function is computed as ten squared or 100
* So, this is, you know, really more complicated than just using some algebra, right
* I'm using these if statements to select which of these two rules g will use to compute its output
* in principle, functions can be really complicated
* I mean, all the examples we've seen are just doing various kinds of algebra
* I mean, maybe different algebra, depending upon which value of x I'm plugging in
* But it's all, you know, adding, subtracting, multiplying, dividing that sort of thing
* But you can do really complicated things with, with functions
* let's see an example of something that is you know really different than doing straight up algebra
* I'll do a much crazier example
* Alright
* C(x) is the number of even digits in the number x, when x is a whole number
* It is zero if x isn't a whole number, so otherwise
* And it is a really different and crazy function, right
* So, C of, say, 7236 is two, and why is that
* This is a whole number so I use the first part of the rule
* And the number of even digits in this number, well, I count them
* That's odd, even, odd, even
* So, two and six are the two even digits
* The value of that function is two
* Well, let's take a look at this number here, 60,202
* That again is a whole number, so the value of the function at 60,202 is the number of even digits in x
* And this number has how many even digits
* One, two, three, four, five, they're all even digits so that value is five
* Here's another example
* Here's another 5-digit number
* 53,531
* Again, it's a whole number so I use the first part of the rule, the number of even digits
* I count how many of these digits are even
* Five is odd, odd, odd, odd, odd
* There are no even digits
* So, the value of this function is zero at this point
* Now, if I plug in a number that's not a whole number like this, this is not a whole number, then I use the otherwise part of the definition
* And the function at that point is just a zero
* So, we can use English to define a function but you got to be careful, alright
* Sometimes, when you write another definition of a function, you might write down something that's more ambiguous than, than you intended
* So, let's try to define a function
* Just making this stuff up, I'll call the function B(x) for bad
* And I'll say that the value of B(x) is some rearrangement of the digits of x
* And it's okay that I'm using English to define my functions
* There's nothing wrong with that
* But this definition is too ambiguous to be the definition of a function
* here's a definition of what goes wrong
* What is the function's value at 352
* Well, the function takes its input and rearranges the digits somehow, alright
* So, you might think that the functions value at 352 is 325
* Because 325 is some rearrangement of the digits of 352, right, I took the five and the two, swapped their positions
* But then, the functions value at 352 should also be 235 because 235 is also a rearrangement of 352
* The function's value with 352 should also be 532 because 532 is some rearrangement of the digits of 352
* This is terrible, alright
* A function is suppose to take its input and produce unambiguously a single output value
* But this so-called function takes this single input value and purportedly produces all these possible outputs
* This thing here is not a function, alright
* A function takes one input and produces one output
* [MUSIC]


--- SKIP ---: 02_when-are-two-functions-the-same.en.srt


--- SKIP ---: 02_when-are-two-functions-the-same.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_when-are-two-functions-the-same.en_SENTbySENT.txt
* [SOUND] So, who knows what a function is, right
* But I know what it does
* It takes an input value, and produces an output value
* And we've got a whole bunch of functions, right
* And we can take these functions and start asking questions about them
* What happens when you plug in a really big number, or a really small number
* Or, or what happens when you plug in two numbers that are nearby each other
* How are the outputs related, right
* Those are the kinds of questions that are going to occupy us for the rest of the term
* But even before we start thinking about questions like that, right
* There are some things that we can still ask about functions
* Like, how do you know when two functions are the same function
* For instance, here's two functions
* f(x) = (1+x)^2, g(x) = x^2 + 2x + 1
* Are these the same function
* Now, let's try
* Look at the value like f(2)
* f(2) = (1+2)^2, start replacing the x by two, 1 + 2 = 3
* 3^2 = 9
* Well, what's what's g(2)
* Well, g(2) would be 2^2 + 2 * 2 + 1
* 2^2 = 4, 2 * 2 = 4 + 1, 4 + 4 = 8 + 1 = 9
* Look, f and g, when I plug in x = 2 give me the same output value of nine
* And that should be a little bit surprising, right
* Because the way that f and g are telling me to compute their output is totally different
* f takes the input two, adds one to it and squares it to get nine
* g takes two, squares it, doubles it, adds those two numbers to one, to get nine
* So, the method by which f and g are doing the calculations is totally different, right
* This sequence of operations is not the same as this sequence of operations
* The, the rules are different
* And yet, look at this
* f(x), for any value of x, right
* Is 1 + x * 1 + x, right
* That's 1 + x^2
* Well, I could expand this out, right
* 1 * 1 + x, and then x * 1 + x
* I could combine some of these terms, right
* 1 + x + x = 2x
* x * x = x^2
* Look, 1 + 2x + x^2, that's g(x)
* this is really quite surprising
* f and g don't compute their output in the same way, right
* This one is doing something different than this function, and yet, for any input value, f's output value is this, which is the same by expanding out as g(x)
* Now, how we're going to deal with this
* We're going to say that f and g are at the same function, right
* Not because they have the same rule, right
* But because for every input value, they have the same output value
* Here's a much more subtle example
* Again, I got two functions
* f is defined like this
* f(x) = x^2 / x, and g is defined like this, g(x) is just x, the identity function
* Same question, is f the same as g
* Are these the same function
* Now, they're not the same rule, right
* This is not the same as this
* So, you know, it's a little more subtle, you know
* But that's okay, right
* Two functions are the same if they have the same output for each input
* So, let's see if that happens here
* let's just pick some value to get a first test
* Let's take a look at f(5), right
* f(5) would be 5^2 / 5, that's 25
* 5^2 / 5, that's 5
* Well, that's the same as g(5), right
* If I plug anything into g, I just get the same thing out
* So, plug in five, you get five
* So, at least at the value five, f and g agree
* You might think this always works, right
* Because of something like this
* You might want to say, well, f(x) that's x^2 / x, no matter what x is
* You might rewrite this x^22 as x * x / x
* And then, you'd be tempted to say, cancel one of these xes with the x in the denominator
* And then, you'd write equals x
* And x, well that's, that's g(x)
* So, this looks like a pretty convincing argument, right
* Over here, I've got f of x, I've got a bunch of equal signs
* And over here, I've got g(x)
* So maybe that means F and G are the same function
* Ha, but not so fast
* What happens if you plug in zero
* What's f(0)
* Well, I know what g(0) is
* g(0) is zero, right
* Zero is in the domain of g because zero makes sense for this rule
* But, what's f(0)
* Well, that would be zero squared over zero, whoa
* Okay
* You see this is terrible, right
* I cannot divide by zero
* This rule, x^2 / x doesn't make sense when x is equal to zero
* So, zero is not in the domain of f, but it is in the domain of g
* So, I'm going to say that these are not the same function
* They don't have the same domain, right
* f isn't defined at zero, and g is defined at zero
* In that sense, these are really different functions
* This example suggests that there's a real richness to this theory of functions, right
* And we're going to be studying it a lot more this term.


--- SKIP ---: 03_how-can-more-functions-be-made.en.srt


--- SKIP ---: 03_how-can-more-functions-be-made.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-can-more-functions-be-made.en_SENTbySENT.txt
* Functions are going to be the main star of the course
* So we should be building up in sort of a repertoire or library of functions that we might be interested in studying
* Here's the first function in our library f(x) = x, the identity function
* Whatever you plug in, this function outputs that same thing
* Here's another function, a constant function
* You pick some number c, c stands for constant
* Alright
* And you can define this function, f(x) = c
* Whatever you plugin for x, f just ignores that and then outputs the original value, c
* Here's a function, f(x) = 3x + 2
* And if you're thinking about stuff like that, why not stuff like this
* Pick two numbers, a and b, and then you can define a function like this, f(x) = ax + b
* You can think about fifth f(x) = x^5 or nth power, f(x) = x^n for some fixed value of n
* And about polynomials, like this complicated looking polynomial, f(x) = 2x^3 + 5x^2 - 2x + 1
* If you're thinking about polynomials, you might want to think about roots, f(x) equals, say the square root of x
* You might remember the absolute value function f(x) equals the absolute value of x
* You might have some experience with trig functions, like sines, cosines, and tangents, or with other transcendental functions like logarithms and exponentials
* So now we've got our small library of functions, the identity function, constant functions, polynomials, some trig functions, and I want more functions
* I, I want some way to be able to take two functions and produce a new function out of them
* Okay
* So in this setup I've got a conveyor belt and I've got two functions, a function here and a function here
* Let's pick out what these functions should be
* Maybe the first function I'll call f and f(x) would be 2X + 1
* So I'll call this function f and maybe the second function I'll call g and g will take its input and square it, so g(x) will be x^2
* So I'll label this function, g
* And now here, I've got a number 3 and I am going to run that number through the first function and whatever comes out of the first function, I'm going to plug in to the second function to see what comes out
* So let's take that number 3, let's start moving the conveyor belt
* It's going to go through the function f, f(3) is 2 * 3 + 1 to 6 + 1, which is 7
* So now we've got a 7 right there
* So the 3 went into the function and came out as a 7
* Now I'm going to take the output to f and put it in to the input of g
* So g(7), well it's going to be 7^2 and that'll be 49
* So here now, coming out of the function g, is the number 49
* And I could have written this in a little bit a little bit of a shorthand way
* I could have just written g(f(4)), right, f(3) is 7 and g(7) is 49
* So once I've got this sort of conveyor belt metaphor going on in my head, I could do the following trick
* I can take two functions
* I can take the output to the first function and plug it in to the input of the second function.


--- SKIP ---: 01_what-are-some-real-world-examples-of-functions.en.srt


--- SKIP ---: 01_what-are-some-real-world-examples-of-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-are-some-real-world-examples-of-functions.en_SENTbySENT.txt
* [MUSIC] So, there's all these different ways of taking two functions and producing new functions
* You could add, subtract, multiply, divide two functions, and could take two functions and compose them, meaning that the output for the one becomes the input for the other
* In light to this, I'd encourage you just to pick up your pen and just write down some extraordinarily complicated functions, alright
* The function that you write down has probably never been written down in the history of humankind
* I mean, there's just so many different choices that you could make when you are combining all the algebraic operations
* And that's part of what makes Calculus so amazing, right
* There's just a huge variety of functions out there
* But not, not every function really has its source in just combinations of algebraic symbols, right
* A lot of the functions that we want to study are really functions that are somehow coming from the real world
* So, I want to see some real world examples of, of functions right now
* So, here's one unit conversion from Celsius to Fahrenheit
* These are two different temperature scales
* So, the function would be f of x, it's 9 * x / 5 + 32
* So, this is just a linear function
* It's a number times x plus a number
* let's take a look what's f of zero
* And that would be 9 * 0 / 5 + 32
* Well, that's zero plus 32, that just 32 and, of course, zero degrees Celsius is the same thing as 32 degrees Fahrenheit
* Here's another example
* What's f of, say, 37
* Well, that's nine * 37 / 5 + 32
* 9 * 37 is 333 / 5 + 32
* 333 / 5 is 66.6, so 66.6 + 32 is 98.6
* And indeed, 37 degrees Celsius is the same thing as 98.6 degrees Fahrenheit
* So, this function takes in something in Celsius and spits out something in Fahrenheit
* Unit conversion is an example of a function, but hardly the coolest example
* This is a much cooler example from the real world
* What is this thing
* Well, this thing here is a microcontroller
* So, a very small computer and it's attached to a couple light emitting diodes, LEDs
* With a name like light emitting diode, you might think that they light up, and they could
* But in this circuit, I'm using the light emitting diodes in reverse
* I'm using them as light sensors
* This one happens to be a red one
* This one happens to be a green one
* So, what this circuit does is let me detect how much red and green light is falling on these sensors
* At the other end is a USB cable and it plugs into my computer so I can record the results
* The data that I gathered from the real world using the microcontroller
* It's really two different functions
* A function for the red LED and a function for the green LED
* Along the x-axis, I've plotted the number of seconds that have elapsed since June 5th, 2012 at 6:0303 p.m
* And on the y-axis, I'm plotting the number of clock cycles it took to discharge the LED
* So, what is the red function do
* It's input is a number a number of seconds that have elapsed since this particular moment in time
* It's output is how many clock cycles it takes at that particular moment in time to discharge the red LED
* Now, this thing was sitting in my windowsill, right
* And the sun was rising
* And as the sun rises, there's more light shining on the sensors which means fewer clock cycles are necessary to discharge the LED
* And you can see that in this graph, right
* The red function is decreasing as the sun rises
* There's tons more examples of functions coming from the real world
* Here's one, human population
* It's a function
* The input is a year, the output is the number of people alive during that year
* If you want to see this function just take a look at Wikipedia and their article on population growth
* There's a graph of that function, along the x-axis is years and along the y-axis is human population
* And as long as researching the Internet, here's another example of a real world function
* It's a function I'll call f of n, and it'll be defined by the rule f of n equals the number of Google hits when we search for the number n
* Let's try it out
* Let's figure out some values of this function like f of 188
* So I plug 188 into Google, and I find that there's about 1.08 billion hits
* So, the function at 188 is about a billion, alright, the input is 188 and the output of this function is the number of Google hits
* let's try about 4 * 188, that's 752
* And if I search for that, there's 308 million hits, alright
* So, f, the function, at 752 is about 300 million
* if we're persistent, we can plug inn lots of numbers, and make a really nice-looking chart like this
* Now, you do this for hundreds of numbers, right
* You type them into Google, you see how many Google hits you get
* And you can plot them, right
* It's a function so you can the graph of the function
* Along the x-axis is the number that I typed into Google
* On the y-axis is the millions of Google hits that I get
* And when you look at the graph of this function, it's not random
* There's real structure here, right
* The function is decreasing, right
* Larger values get smaller outputs because, you know, there is fewer webpages that talk about really large numbers than about popular small numbers
* But even more dramatically, when you plot this on this special log, log graph paper, the graph looks like it's sitting near a straight line
* I mean, that's, that's really amazing when you think about it
* I mean, this is some sort of pattern that's just hidden in the number of pages that talk about numbers
* I mean why
* Where is this coming from, right
* It's a function from the real world
* Input is a number
* The output is a number
* We want to understand that function
* Calculus is part of the tool kit for analyzing problems like this
* So, we've seen what functions do
* They take their input and they transform in into some output
* And we've even sort of got this mental image now, this metaphor of a machine
* A conveyor belt that's transforming the input into the output
* We've seen how to build a lot of new functions using algebra
* or say, composing two functions
* And we've thought about some real world examples
* [MUSIC] Now, we're going to be thinking more about functions for the rest of the term
* But if you've got questions right now, I encourage you to contact me as soon as possible
* And I encourage you to get started on the homework right away
* Good luck
* [MUSIC]


--- SKIP ---: 02_what-is-the-domain-of-square-root.en.srt


--- SKIP ---: 02_what-is-the-domain-of-square-root.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-domain-of-square-root.en_SENTbySENT.txt
* [MUSIC] So, before we talk about the domain of the square root function, we just want to remind ourselves what the square root function even is
* So here, I've made a graph of the square root function
* And along the x-axis, I plot the numbers one to sixteen and in the y-axis I've got the numbers one through four
* And then in this green curve here, I've plotted the the, the square root function
* What is the square root, right
* Well, here's an example
* Here, I've got the square root of four
* And I'm saying the square root of four is two
* What that means, is if I take the number two and I square it, I get back four
* I don't know, if I move over to, say, the square root of nine, I get three
* And that's because three squared is nine, alright, or if I move over a little bit further, the square root of sixteen is four
* And that's because four squared is sixteen
* I know there's some crazier values, too
* If I move over here to the square root of two, well, the square root of two is this sort of crazy number 1.414213 blah, blah, blah
* And maybe it's a little bit surprising, that if I take that number and square it, I get back two
* So, what's going on here, alright
* The square root function takes a number and spits out a new number, that new number when you multiply it by itself and you square it, you get back your original number
* Now, here's the question, what sorts of numbers can I take the square root of
* That's asking the question, what's the domain of the square root function
* Now, that we've seen the graph, let's try to write down in words a definition of the square root function
* So, in light of what we just seen, you might think that the definition of the function f(x) equals square root of x is a number which squares to x
* There's a problem with this though
* Take a look at say, f(9)
* What would f(9) be
* Well, if you're thinking the square root of x is a number which squares to x, then you might think that f(9) would be -3, alright
* Because -3^2 is 9
* But then, you might also think that half of nine should be three, right
* Because 3^2 is also 9
* This is bad, alright
* A function is supposed to be unambiguous
* It's supposed to have one output for each input
* If you take this as the definition of the square root function, just any number which squares to x, you've introduced some ambiguity, alright
* What's the square root of nine
* Is it -3 or is it +3
* Both of those numbers square to nine
* So, this is, this is bad, alright
* The solution is to change the definition
* Instead of having the the square root function be just a number which squares to x, you're going to take it to be the nonnegative number which squares to x
* This is better, alright
* In our example here, if I only am allowed to choose the nonnegative number, which squares to x, then f(9) equals -3, well, -3 is not nonnegative, -3 is negative
* So, that means that this isn't the case, right
* All I'm left with is f(9) = 3, right
* Three is the nonnegative number which squares to nine
* Alright
* So, this will be our definition for for, for the square root function
* The square root of x is the nonnegative number which squares to x
* There's one particular place where this plays out and it's extraordinarily important
* So, let's take a look at that now
* We've got our definition
* The squared of x is the nonnegative number which squares to x
* Now, there's one popular misconception that comes up because of this definition
* So, in light of the definition of the square root, right, the square root of a number being the nonnegative number which squares the number to the radical, you might be tricked into thinking that the square root of x squared is x
* That's not true and let's see why
* Let's do a specific example where say, x is -4
* So, if I replace the x's here by -4, the left hand side is the square root of -4 squared, right
* Square root of x squared but with x replaced with -4
* Now, - 4 * -4 is 16
* This is the square root of 16 and the square root of sixteen, the definition of the square root is the nonnegative number which squares to 16
* There's two numbers that square to 16, +4 and -4
* But the square root is by convention, the nonnegative one, so this is equal to 4
* Duh, look at what happened
* -4, square root of -4^2 + 4, that's the x over here
* This is not true, right
* You should not be tricked into thinking that that's the case
* Instead, something else is true, right
* What is true is this
* The square root of x squared is the absolute value of x
* And that works in this specific case, right
* When x is -4, the square root of -4 squared, the square root of 16 is 4
* And 4 really is the absolute value of -4
* Alright
* So, this is a mistake that comes up quite a bit
* People are often tricked into thinking that the square root of x squared is just x, alright
* They're just trying to cancel the square roots in the squaring
* That's not possible
* Instead, what is true is the square root of x^2 is the absolute value of x
* So, we've got a definition of the square root function and we've seen that the square root of x^2 is not just x, it's the absolute value of x
* Now, that doesn't actually address the original question, right
* The original question is, what's the domain of this square root function
* What sorts of numbers can I take root of
* For instance, can I take the square root of a negative number
* Let's see why not
* Very concretely
* Does it make sense, say, to talk about the square root of -16
* Well, if it did that would be some number
* So, I'll call that number k for crazy, alright
* And what do I know about that number k
* Well, k^22 would have to be -16
* Remember, the definition of the square root function
* It's a number that I square to get back the original number
* So, if there were a square root of -16, when I square it, I get back -16
* And imagining here that k is some real number
* And that means there's three possibilities
* Either k is positive, k is zero, or k is negative
* If k is positive, then k squared would also be positive because a positive number times a positive number is still positive
* But that can't be, because k squared is supposed to be -16
* So, this first possibility doesn't happen
* Now, if k were zero, then k squared would be zero, but k squared is supposed to be -16
* So, k isn't zero
* Is k negative
* Well then, what's k squared
* That would be a negative number times a negative number, and that would still be positive
* And that can't be because k squared is supposed to be -16
* So, this possibility also doesn't happen
* So, all of our possibilities have been eliminated, alright
* There can't be a real number k, which is the square root of -16
* Because if k were positive, k squared would be positive but k squared has to be negative
* k can't be zero because then k squared isn't negative and k can't be negative because then k squared is positive but k squared is supposed to be negative, alright
* The upshot is that it just doesn't make any sense to talk about the square root of a negative number
* In contrast, it does make sense to talk about the square root of zero, which is just zero, zero squared is zero
* And it also makes sense to talk about the square root of positive numbers
* So, to summarize the situation, we can say that the domain of the square root function is all the numbers between zero and infinity, including zero
* So, I'm using the square bracket
* But, of course, not including infinity because infinity is not a number
* Sometimes, you're asked to calculate the domain of a function that's more complicated than, than just the square root of x
* Let's see an example of that
* So, let's try this
* Let's try to find the domain of this function g, which is the square root of 2x + 4
* And remember, the domain consists of all the inputs for which the rule makes sense
* So, I just have to think which x values makes sense for this rule
* Well, in order to take the square root of 2x + 4, I'm going to need that 2x + four is not negative because I can't take the square root of a negative number so I need to guarantee that 2x + 4 is not negative, meaning greater than or equal to zero
* Now, I can subtract four from both sides and I get that 2x is at least -4
* Then, I can divide both sides by two
* Two is positive, so it doesn't change the inequality
* x is bigger than or equal to -2
* So, as long as x is at least -2, then 2x + 4 is at least zero, which means it makes sense to take the square root
* So, I can summarize the situation, the domain of g consists of all numbers greater than or equal to -2
* This is our notation for that
* I used a square bracket to include the -2 and the round bracket here on the infinity, because infinity is not number, it's not part of the domain
* So, that example was a little bit harder
* Let's do an even harder example where I've got multiple square roots, all right, the square root of something plus the square root of something
* And let's figure out the domain of this function that has two separate square roots
* This is the function T(x) equals the square root of 1 - x plus the square root of 1 + x
* Now, in order for this rule to make sense, I have to be able to take this square root and also take this square root
* In other words, in order to do this first square root, I'm going to need that 1 - x is bigger than or equal to zero, alright
* I need the thing under the square root to be nonnegative in order to do a square root
* In order to take this square root, I need 1 + x to be bigger than or equal to zero
* And both of these things have to be true in order to take both of these square roots and then add them together
* So, I'll put an and between them
* Now, I go to x to both sides and this inequality and I get one is bigger than or equal to x
* And I can subtract one from both sides of this and I'll get x is bigger or equal to -1
* And again, both of these things have to happen, right
* I need x less than one and x bigger than or equal to -1 in order to evaluate this function
* Let me write this in in a more reasonable way, right
* Instead of writing one bigger than or equal to x, I can write what I just said, x less than one
* And here, I'll write, this is x bigger than or equal to -1
* Now, I could write these inequalities as something about an interval
* I could say that x is in the interval -1 to 1, alright
* To say that x is less than one and bigger than or equal to -1, exactly means that your inside this interval
* And I'm using square brackets here, because I've got greater than or equal to, less than or equal to
* And then, I can summarize the situation by writing the domain of T is this interval, alright
* And this is describing the values of x for which this rule makes sense at the domain of the function T
* Let's do one more example
* some square root problem where I've also got an x squared term
* Let's calculate the domain of this function C
* C of x is the square root of 1 - x^2
* So, the domain consists of all the inputs for which the rule makes sense
* So, I'm looking for which values of x make the thing under the square root nonnegative
* There's lots of different ways to think about which values of x make this true
* one way is to factor 1 - x^2
* So, I could factor 1 - x^2 as 1 + x * 1 - x, alright
* That is equal to 1 - x^2
* I'm looking for when that's nonnegative
* This is a little bit easier to think about because now, I just got to figure out when these two terms have the same sign, alright
* When they're both positive or they're both negative, then their product is bigger than or equal to zero
* So, to think about that, I'll draw a number line
* And I'll first think about when 1 + x is positive and negative
* So, something special happens at -1, alright
* When x is minus one, 1 + x is zero
* When x is less than -1, 1 + x is negative
* And when x is bigger than -1, 1 plus x is positive
* Alright
* Now, compare this with 1 - x, alright
* 1 - x, something exciting happens at one, alright When X is less then one, 1 - x is positive
* And when x is bigger than one, 1 - x is negative
* Now, I'm not trying really to understand 1 + x or 1 - x, I'm trying to understand their product
* So, when I multiply those two together, I get 1 - x^2 and I want to know, you know, when is that positive or or negative
* Let me mark down the special points -1 and 1
* And now, 1 - x^2 is the product of these so I can think about various values of x
* So, when x is less than -1, then 1 + x is negative and 1 - x is positive, and a negative number times a positive number is negative
* When x is between -1 and 1, then 1 + x is positive and 1 - x is also positive in that region, so their product is positive
* And when x is bigger than one, 1 + x is positive and 1 - x is negative, so their product is negative
* Now, this gets me most of the way there, alright
* Because what I'm trying to understand is when this product is nonnegative and I can see that it's positive in this region, I could also think about what happens when I plug in -1 and 1
* When I plug in -1, I get 1 - 1 which is zero
* And when I plug in one, I get 1 - 1 which is zero
* So, the function is, in fact, is zero in between here at -1 and 1
* So, I'm just trying to figure out which values of x make 1 - x^2 nonnegative
* Well, -1, 1, and anything in between
* So, one way to summarize the situation is to say that the domain of my function C consists of all real numbers between -1 and 1, including -1 and 1
* So, I'm using the square brackets
* As long as x is inside here, then 1 - x^2 is nonnegative
* That means it makes sense to take the square root and that's the domain of C
* [MUSIC]


--- SKIP ---: 01_morally-what-is-the-limit-of-a-sum.en.srt


--- SKIP ---: 01_morally-what-is-the-limit-of-a-sum.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_morally-what-is-the-limit-of-a-sum.en_SENTbySENT.txt
* [MUSIC] There are subtleties even to things that appear as simple as addition
* Here, I've got some addition problems
* 4279 + 1202, 4279 + 1190, 4269 + 1207, 42731202
* + 1191, and 4270 + 1100 You'll notice that they're all close to this problem
* The numbers that I've been listing off are all hovering around this problem
* Anyway, I'm going to give out these problems to some people and have them try to do them
* [MUSIC] Hi, I'm [UNKNOWN] and I'm Math junior undergraduate at Ohio State
* [MUSIC] Yeah
* My name is Jacob Turner
* I'm a graduate TA here at OSU
* [MUSIC] Alright
* People are finished doing the arithmetic problems
* Let's record the answers
* So here, 4270 + 1200 was 5470
* 4279 + 1202 was 5481
* The next one is 5476, I've got 5467, and the last one was 5464
* what do all these numbers have in common
* They're all really close together
* Is that just an accident
* Of course, it's not an accident, right
* Here's the fact
* Near the sum of two numbers is the sum of two nearby numbers
* These arithmetic problems are not just random arithmetic problems
* Look at the numbers I'm asking them to add
* 4277 and 1190, those Those numbers are really close to 4273 and 1191
* Which is really close to 4270 and 1200
* Which is really close to 4269 and 1207, alright
* Near the sum of two numbers is the sum of two nearby numbers, all of the answers are nearby as well
* How does this relate to limits
* Let's take a look
* Here's how it relates to limits
* The limit of f of x plus g of x as x approaches a, is the limit of f of x as x approaches a plus the limit of g of x, as x approaches a
* How is this related to those arithmetic problems
* Well, remember what this limit is saying
* This is saying, what can I make f of x plus g of x close to, if I'm willing to make x sufficiently close to a
* Well, it's going to be close to whatever I can make f of x close to added to whatever I can make g of x close to, right
* It's the same kind of setup, right
* Near the sum of two values is the sum of the nearby values
* For the limit of a sum is the sum of the limits
* We can use this fact to do some calculations
* Let's see how
* So, here's a limit problem
* The limit of x squared plus x as x approaches two
* I really want you to resist the temptation to just plug in two
* We're going to be using our limit laws to try to evaluate this limit
* Now, this is the limit of a sum, and the limit of the sum is the sum of the limits provided the limits exist
* So, this limit of x squared plus x is equal to the limit of x squared as x approaches 2 plus the limit of x as x approaches 2
* Now, what's the limit of x squared
* Because the limit of the products is also the product of the limits provided the limits exist, this is the limit of a product
* This is the limit of x times x
* That's what x squared means, it's x times x
* So, I could rewrite this as the limit of x times x, as x approaches 2+
* Now what's the limit of x as x approaches 2
* This is asking, what does x get close to when x gets close to 2
* Or, some more precisely, what can I guarantee that x is close to if I'm willing to make x sufficiently close to 2
* The limit of x as x approaches 2 is 2, alright
* So, this limit is just two
* Now, this a limit of a product, and the limit of a product is the product of the limits provided the limits exist
* So, this limit is the limit of x as x approaches 2 times the limit of x as x approaches to +2
* Now again, the limit of x as x approaches two, right
* What can I guarantee that x is close to if x is close to 2
* Well, two
* So, this is just 2
* This limit is the same thing, it's again just 2
* And here, I have +2
* 2 * 2 + 2 is 6, which is the value of the limit of x squared plus x as x approaches 2
* The takeaway message here is ask not what your country can do for you but what you can do for your country
* Or in other words, that the limit of a sum is the sum of the limits provided the limits exist
* It's the same rhetorical device right, x-y, y-x
* Alright, the limit of a sum is the sum of the limits provided the limits exist
* I hope this is very memorable because these kinds of chiastic rules are going to be used throughout our time together in order to evaluate limits
* Soon, we're going to see that the same sort of pattern holds not just for sums, but for differences, for products and almost for quotients
* Good luck
* [MUSIC]


--- SKIP ---: 02_what-is-the-limit-of-sin-1-x.en.srt


--- SKIP ---: 02_what-is-the-limit-of-sin-1-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-limit-of-sin-1-x.en_SENTbySENT.txt
* [SOUND] So here's a table of values of the function F of X equals sin 1 / X
* F of one is really sin of one, it's like 8.
* F of 1
* which is really sin of one over 1
* sin of 10 -.5
* F of 01.
* This will be sine of 100, it's also about -0.5
* F of 0.001, which is like sine of 1000, well that's 0.8 and some more, right
* So the question is these numbers aren't really getting close to anything in particular
* Can you really say that if you evaluate f at values which are close to but not equal to zero, that the outputs are actually getting close to anything in particular
* I mean this is positive, negative, negative, positive, negative, positive, negative, it's looking pretty bad
* Instead of a table, let's look at a graph
* Here, I've got a graph of the funtcion f (x) = sin 1 / x
* And you see the middle of this graph is just that horrible green blob
* Right
* It's really hard to make out any detail
* You might think that's just a consequence of the fact that I'm drawing this graph with such thick lines
* You know, and if I used thinner lines to draw my graph, maybe I could, you know get rid of this green blob and really see some detail
* Even if I dial down the size of the lines that I'm using to draw this graph, the blob thing is still there, you know
* And it's really there in the graph of the function
* Even if these lines were true lines, zero thickness, it wouldn't be possible to fit even a single atom next to the Y axis without touching the graph of this function
* The graph is oscillating wildly near zero
* Even if your input is very close to zero your output could be anything between -1 and 1
* So in light of this evidence, the limit of sine 1 / x as x approaches 0 does not
* [SOUND] exist
* Which sometimes I'll abbreviate DNE, for does not exist
* what does it even mean to say it doesn't exist
* What do we mean by the definition of limit
* To say the limit equals something means that I can make the output as close as I want to l by making x close to a
* So when I say this limit doesn't exist, I mean it's not the case that this limit is equal to anything, okay
* If you tell me this limit is some positive number, well look
* When I evaluate the function at a number very close to 0, the output is negative
* So the limit is probably not some positive number but there's also inputs very close to zero that give positive outputs so that the limit is pulling out a negative number either
* Limit is pulling out zero either cause none of these numbers are getting close to zero
* So in this sense
* This limit just doesn't exist because it's not the case that this limit is equal to anything in particular
* If you tell me this limit is equal to l, I'm going to show you numbers close to zero which aren't close to l
* Let's see another example along the same lines
* This is a particularly confusing example because in the function f(x)x) = sine pi / x
* The function evaluated at 1 is 0
* That's pretty clear because that is sine of pi and sine of pi is zero
* About the function at 0.1, I'm counting that's also equal to zero
* The function at 0.01, that is also zero
* This can be kind of confusing
* When you take a look here, I typed in sin pi divided by 0.01 on to my calculator
* This is calculating the function's value at 01.
* If I ask my calculator to do this, it is not telling me the answer zero, right
* The calculator's giving me this, admittedly, a very small number, right, E -11 here
* But it's still not actually zero
* So, can I convince you that this is even true
* That the functions value at 01
* actually is equal to zero
* What is f (0.01)
* Well it's the same as sine, of pi / 0.01
* Now here I'm taking pi and I'm dividing it by 0.01
* That's the same thing as what
* That's the same thing as multiplying a 100
* I'm dividing by a hundredth, that's the same as multiplying by a 100
* So this function at.01 is sine of 100 pi
* What's sine of 100 pi
* Well, think back to what the graph of sine looks like
* Here's a graph of sine, zero to two pi
* If I do it again
* Here it is at four pi, and I drew it again
* Here it is at six pi, and I'm going to keep on going
* And eventually, I'm going to get to 100 pi
* And at that point, sign really is going to be equal to zero
* Calculators are great, they're also terrible
* This calculator can't really calculate with pi, all it can do is calculate with some approximation to pi
* We can use our human mind to evaluate this function exactly
* In light of this evidence, you might be tricked into believing that the limit of f(x) as x approaches 0 is equal to 0
* After all these points are approaching zero, and function evaluating each of these points is zero
* So maybe that means that this is true
* So it looks like the limit is equal to zero
* But, what happens if I look at some other points
* We'll take a look at this example
* Here's the same function, f of x equals sign of pi over x
* This function, if I evaluate it at 75
* is this, maybe a little bit mysterious number, negative 866
* and so forth
* If I evaluate this function at 075
* you get the same thing
* If I evaluate the function at 0075,
* I get the same thing
* At 00075
* I get the same thing, .000075, I get the same thing
* So, what's going on here
* Well what is this number
* I mean 0.8666
* This isn't just some sort of random number
* Right
* This is in fact negative the square root of three over two
* And it looks like this function at all of these points has the same value, negative the square root of three over two
* So does that mean that the limit as X approaches zero of F of X, [SOUND] is equal to negative the square root of three over two
* [SOUND] I mean again all of these values, .75.075.0075, these input values are approaching zero, and the functions value at all of those inputs is the same
* So, what gives, is the limit zero, is a negative point A, which is it?
* Okay, okay, I've been little bit too tricky in picking my input points
* Since the same function, F of X equals Sin pie over X, and here, I am picking a collection of points, again approaching zero, .7, .07, .007, .0007
* Its getting closer and closer to zero
* But now, my output values are looking pretty random
* I mean, they are not over the same, for instance
* So this is, maybe some evidence, that, the limit
* Of sine pi over x as x approaches zero
* Doesn't exist
* Here I've got a bunch of input points that are getting closer and closer to zero but my output values at least don't appear to be getting close to
* We're not just learning
* We're exploring
* [SOUND] I encourage you to cook up you own examples
* We've seen a couple examples now of where limits don't exist but can you come up with more
* [SOUND]


--- SKIP ---: 03_what-is-the-limit-of-sin-x-x.en.srt


--- SKIP ---: 03_what-is-the-limit-of-sin-x-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-limit-of-sin-x-x.en_SENTbySENT.txt
* [MUSIC] So here's a great function to look at
* The function is going to be defined by f(x) = sine x / x
* My question is what's the limit of this function, as x approaches zero
* Let's try to guess the limit by looking at a table of function values
* So here's a bunch of input values that are getting closer and closer to zero, right.1, .01, .001
* It's getting closer and closer to zero
* Then looking at my output values from my function, right
* So f(1) is sine of 1 / 1
* It's the sine of 1
* f(.1), that's sign of 1
* over 1,
* it's 99.
* A little bit more
* f(.01) is 9999
* a little bit more
* And you keep looking down here and these numbers seem to be getting close to something, alright
* 999999
* this is really, really close to one
* So based on this table of values your tempted to guess that the limit of f(x) as x approaches 0 is 1
* Another way to gain some insight about this limit will be to look at the graph
* Here's the graph
* This is the graph of sign x over x
* And you can see that when x equals zero, functions not defined there because I can't divide by zero, so I got this little hole in the graph
* Nevertheless, I'm claiming that the limit as x approaches 0 is equal to 1 which actually means that I can make the output as close to 1 as you like, if you're willing to have the input be close enough to 0
* Instead of talking about closeness, push this red button and turn on this red interval
* So when I say close to one, what I really mean is the output is inside this, this red interval
* And that red interval might be really big or it might be really small
* But to be close to one is going to mean inside the red interval
* The point is that, can turn on this blue interval
* And as close as you want the output to be the one, I can promise you that the output is within the red interval if the input is within this blue interval
* When the red interval is really big, well that's not much of a challenge
* I can have a really wide blue interval and anything inside the blue interval has output landing inside the red interval
* But even when the red interval is very, very small there's still some tiny blue interval so that whenever x is within the blue interval, the output is within the tiny red interval
* In other words, even if you want the output to be really close to one
* I can promise you that the output is that close to one, if you're willing to have the input be close enough to zero
* So, we've looked at the function values, we've looked at the graph
* We've got this idea that the limit of sine x over x as x approaches zero is equal to one
* But it's just that, it's just an idea
* We don't yet have a rigorous argument that this limit is equal to one
* Here's a sketch of a more rigorous argument that the limit of sine x / x, as x approaches 0 is equal to one
* It turns out that for values of x which are close to but not equal to zero, this is true
* Cosine of x is less than sine x over x, and sine x over x is less than one
* Now why would you care about this
* Note, the limit of cosine x as x approaches zero is one and the limit of 1 is 1 because the limit of a constant function is just that constant
* So I know that the limit of this side is one and the limit of this side is one and what I'm trying to conclude is that the limit of the thing in between is also one
* And it turns out there's a way to do this
* Let's take a look
* Here's what we're going to use, the squeeze theorum
* Suppose you've got three functions, I'm calling them GF and H
* G(x) is less than equal to f(x) and f(x) is less than equal to H(x)
* For values of x that are near A, but maybe these inner qualities don't hold at the point A
* Also, suppose that the limit of G(x) as x approaches A, is equal to the limit of H(x) as x approach A, is equal to sum L
* So the limit of G(x), the limit of H of X are the same value, L
* The, you get to conclude the limit of f as x approaches a exists and it equals l
* Why is this thing called the Squeeze Theorem or some people call it the Sandwich Theorem or the Pinching Theorem
* Let's take a look
* Just pictorially, why is this called the squeeze theorem
* I've got an example here
* Three functions
* G, F, and H
* And again, G(x) is less than F(x), F(x) less than H(x)
* Now, note, the limit of G(x) as x approaches A is L
* And the limit of H(x) as x approaches A is L
* F is squeezed, or sandwiched, between H and G
* And consequently, the limit of f as x approaches A is also equal to L
* Now, we're going to use the squeeze theorem to try to understand the limit of sin x over x
* So we've got the Squeeze Theorem
* And what do I know
* I know that cosine X is less than sine x / x is less than 1 for values of x that are close to but not equal to 0
* And the limit of cosine x as x approaches 0 is equal to 1
* If you like, because cosines continuous and cosine of 0 is 1
* Also the limit of 1 as x approaches 0 is equal to 1 because the limit of a constant function is that constant
* So the limit of this function is one, the limit of this function is one as x approaches zero
* And that means by the Squeeze Theorem, the limit of sine x / x is also equal to 1 [MUSIC]


--- SKIP ---: 04_what-is-the-limit-of-x-2-1-x-1.en.srt


--- SKIP ---: 04_what-is-the-limit-of-x-2-1-x-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-is-the-limit-of-x-2-1-x-1.en_SENTbySENT.txt
* [MUSIC] Limits are probably the most important concept in this course
* So we should really have a definition of what we mean by limit
* Now here is what we mean by limits
* To say that the limit of f of x as x approaches a is equal to L means that f of x can be as close to L as desired by making x close enough to a
* There is a tons of subtlety to this definition so it's worth to look at an example
* So let's take a look at this function
* This is the function that takes an input x and spits out x^second minus one divided by by x minus one
* So let's try plugging in number three into this function
* So I plug in number three into this function and I have to just compute, right
* Three squared minus one over three minus one well, that's three squared is nine minus one is eight three minus one is two and nine divided by two is four And sure enough, out of this function comes the number four Let's look at that example again but with a little bit more detail
* this is actually a pretty complicated function
* Alright
* But I can open up the function
* Alright
* And take a look at how the functions actually doing its calculations
* You can think of this function as having three different steps
* Alright
* One of the steps squares its input and subtracts one, and so I calculate the numerator
* Another step just subtracts one from its input
* The outputs of those two steps then get plugged into the division
* And that's how I get the output of this big complicated function
* Now, something like x^two - one, you could also think of that as having some, you know separate steps as well
* But this is good for right now
* Okay
* Now let's see what happens
* I take the number three and I plug it into the function
* Alright
* Now I'm going to be calculating the numerator and the denominator separately, so I'll take those 3s, and up here, I'll look at three^two - one and I'll get out eight
* And down here, three - one became two Now the eight and the two get plugged into the division, and eight divided by two is four and that becomes the output of the function, right
* Input's three, output is four but when I look at it this way, I can see how all the steps are, are playing out
* Okay
* I evaluate the function at three, but who cares
* Well, let's try to evaluate the function at one instead of at three
* So what happens when we plug in the number one into this function
* I got the number one here
* I'm going to look inside
* I'm going to open up this function
* Now imagine I've got this number one
* I'm going to plug it into the function
* All right
* Now I'm going to be evaluating the numerator and denominator separately, so I'm going to take this one and split it up, and plug it into the numerator and the denominator
* The numerator sends its input to its input squared minus one
* So one^two minus one is zero and the same thing down here, one - one is zero Now I've got 0 and 0 which I'm going to be plugging in to the
* Okay, very bad
* Right
* I'm dividing by zero and I can not proceed, so this function is not defined at one
* So I can't plug one into the function
* But if I wanted to figure out what the function's value was that inputs near one, I could do that
* So let's try to plug in one point one instead so let's plug one point one into this function
* I can't plug in one because I need to divide them by zero, but let's try plugging in one point one I'm going to open up the function again and take one point one plug it into the function
* Now one point one is going to to be evaluated in the numerator and the denominator
* one point one^second minus one is twentyone
* And one point one minus one became one
* Now twentyone and one are going into the division
* And twentyone divided by one is two point one So when I evaluate the function at one pint one I get out two point one
* Instead of just plugging in one value, let's plug in a whole bunch of values
* We'll make a table
* So use that same function again
* F of x is x^second minus one divided by x minus one Now, I can't plug 1 into the function, 'because if I plug in one, I'd be dividing by zero, and I can't divide by zero
* One isn't in the domain of this function
* But I can plug in numbers near one, right
* And we saw that one point one if I plug in that, I get two point one
* Right
* And if I plug in one point zero one I get two point zero one If I plug in 1 point zero zero one I get two point zero zero one
* Right
* And so on
* If I plug in 1.000001 I get 2.000001
* Right
* Well, what's going on here
* I could summarize this situation by saying the following
* The limit of x squared minus one over x minus one as x approaches one is equal to two
* Why is that
* Well, this is because
* I can make x^2-1 over x minus one
* As close to two as I want
* If
* I make x
* Close enough
* To one
* Lets see
* Here's my table alright if you want the output of this function to be within a billionth of two all you need to do is to make sure that your input is within a trillionth of one alright
* As long as your input is close enough to one you can guarantee that your output is as close to two as you like
* This is just looking at a table of values
* You know, maybe a dozen values and seeing what they're getting close to
* It would be a lot better if there were a more convincing argument
* So let's go back to our definition of limit
* To say the limit of f of x equals l means that f of x can be made as close to l as you desire by making x close enough to a
* And let me emphasize something
* Close enough
* But not equal
* To a
* Why does something like this matter
* Well, let's go back to our example
* In our example the function wasn't defined at one
* But the limit doesn't depend upon the function's value at one
* It only depends on the function's value near one
* So x squared minus one over x minus one is equal to x plus one as long as x isn't equal to one right
* As long as x isn't one this is a true statement
* So now what's the limit as x goes to one of x squared minus one over x - one
* Well, this is the limit as x approaches one of x
* one = one
* because the limit doesn't depend upon the value of the function at one
* It only depends upon the values of the function near one
* And as a result, these two things have the same limit
* Even better the limit of x plus one, as x approaches one, well that's the limit of a sum
* And the limit of a sum is the sum of the limits
* So I can rewrite this limit as the limit as x goes to one of x plus the limit as x goes to one of one
* And what the limit of x as x goes to one
* Well that's asking what can I make x close to if I make x close enough to one
* Well that's one
* And the limit of one as x goes to one is asking me what's one close to when x is close to well there's not even an x in this right wiggling x doesn't affect this at all so that limits also one
* And one plus one is two so indeed the limit
* x^twenty two minus one divided by x - one as x approaches one is two
* Limits provide information about what a functions values are approaching, alright
* It's a way of accessing otherwise forbidden information
* I might not be able to plug in the value one, because that would have entailed dividing by zero
* And yet I know, that the functions output is as close to two as I like
* As long as the input is close to but not equal to one.


--- SKIP ---: 01_what-is-the-limit-of-a-product.en.srt


--- SKIP ---: 01_what-is-the-limit-of-a-product.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-limit-of-a-product.en_SENTbySENT.txt
* Here is an arithmetic problem, 660 * 310
* I'm going give this exercise to Bart
* So, the product of 660 and 310 is 204,600
* But, what if I perturb these inputs a little bit
* Instead of assigning this multiplication exercise, I could have assigned this multiplication exercise, 664 * 311
* Let's give this to somebody else
* Hi
* My name is Vadranna
* So, 664 * 311 is 206,504
* Which isn't so far off of the answer that Bart got when he multiplied 660 times 310 and got 204,600
* So, look at this
* We've got two different problems
* The input to these multiplication problems are similar, the outputs are also similar
* Let's do some more, very similar multiplication problems
* [SOUND] Hello, my name is Sean Gory
* [SOUND] Oh, this is great
* Look
* 204,600, 206,504, 206,926, 204,702
* We multiplied all of these pairs of nearby numbers, and the result of the multiplications were also nearby
* There's a limit lesson hiding at all of this
* If the limit of f of x as x approaches a is L, and the limit of g of x as x approaches a is M, then the limit of f of x times g of x as x approaches a is equal to L times M
* In other words, the limit of a product is the product of the limits provided those limits exist [SOUND]


--- SKIP ---: 02_what-is-the-limit-of-a-quotient.en.srt


--- SKIP ---: 02_what-is-the-limit-of-a-quotient.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-limit-of-a-quotient.en_SENTbySENT.txt
* [SOUND] Fundamentally, limits are promises
* When I tell you the limit of F of X equals L, as X approaches A; I'm promising you something
* I'm promising you that I can get F of X as close to L as you like as long as X is close enough to A
* Thinking of limits as promises helps us to understand statements like these
* Let's suppose that you tell me that you know the limit of f of x as x approaches a is equal to something, maybe this is equal to l
* And maybe the limit of g of x as x approaches a is equal to m
* What that really is, is a promise that you can make F of X as close to L as I like
* And it's a promise that you can make G of X as close to M as I like, as long as I'm willing to make X close enough to A
* But if you can promise me that you can make F of X close to L, and G of X close to M
* Then I can turn back and promise you that F of X plus G of X is as close to L plus M as you like
* Alright
* If I want to make this close to something, I just ask you to make F of X close enough to L, and G of X close enough to M
* So that F of X plus G of X, is as you like to L plus M
* In other words, the limit of a sum is the sum of the limits
* And the limit of a difference is the difference of the limits
* And the limit of a product is the product of the limits
* And what about quotient
* And something similar is true for division
* If the limit of F of X as X approaches A is L
* And the limit of G of X as X approaches A is M, which isn't zero, then the limit of F of X over G of X, as X approaches A is L over M
* In other words, the limit of the quotient is the quotient of the limits, provided those limits exist and, the limit of the denominator is non-zero
* Let us do something with our new found knowledge about limits of quotients
* Here's a limit problem: I'm going to limit x-squared over x plus one as x approaches two, alright
* I'll promise you that x-squared over x plus one is close to something whenever x is close enough to two
* This is the limit of a quotient, and the limit of the quotient's the quotient of the limits, provided the limit of the denominator is not zero, and in this case, it's not
* So the limit of the quotient is the quotient of the limits
* [SOUND] Here's the limit of the numerator
* The limit is X approaches two of X plus one
* This is the limit of the denominator
* Now this is the limit of x squared
* X squared is X times X
* This is a limit of a product
* And the limit of a products the product to the limits so I can replace the limit of the numerator with a limit of X as X approaches two times the limit of X as X approaches two
* because this is the limit of X times X and here's the product limits
* Limit of X times the limit of X as X approaches two
* The denominator here is the limit of X plus one as X approaches two but that's a limit of a sum and the limit of the sum is the sum of the limits
* So the limit of X plus one [SOUND] is the limit of X plus the limit of one, as X approaches two
* Lets keep going
* So I've got the limit of X times the limit of X over the limit of X plus the limit of one
* And all of these limits are being taken, as X approaches two
* What's the limit of X
* That's asking what can you guarantee X is close to if you're willing to have X be close enough to two
* Two is the limit of X as X goes to two
* So limit of X as X goes to two is two
* The limit of X as X goes to two is doubt is for multiplying, divided by limit of X as X approaches two plus with the limit of one as X approaches two
* This is asking, what can I guarantee one is close to two if I am willing to have X be close enough to two
* Well, one is already close to one, right
* The limit of a constant is that constant
* So this is just one
* Two times two is four
* Two plus one is three
* And so the limit of this expression is four-thirds
* At this point you are asking yourself why is the rule for limits of quotients different than limits of the products
* A limit of a product is a product of the limits
* Laws of limits exist
* Why do I have to worry about the limit of a nominator being non-zero, when I'm taking the limit of a quotient
* Most basically the problem is that you can't divide by zero
* You can't go around telling people that the limit of a quotient is a quotient of the limits because the limit of the denominator might be zero and then you'd be telling people to divide by zero, which they can't do
* You can't divide by zero
* But you can think about it even a little more subtlety
* You know, let's kind of unpack this a bit
* Here's an example to think about: the limit of x over x minus three as x approaches six
* This is no problem, alright
* The numerator is a number close to six, it's how we're thinking about it, and the denominator is a number close to six minus three
* A number close to six minus three, that means the denominator is a number close to three
* Now, we've got a number close to six divided by a number close to three
* Well, that's a number close to two
* And, indeed, I mean, this limit is equal to two
* I can make this quotient as close to two as I like
* Because I can make the numerator as close to six as I need, the denominator is as close to three as I need, to guarantee that this ratio is as close to two as you like
* So that limit is two
* But what if instead of asking about the limit as x approaches six, I'd ask about the limit as x approaches three
* Well, then what would I know
* Then I'd know that the numerator was a number close to three, and the denominator was a number close to three minus three
* The denominators aren't close to zero
* The limited denominator is zero
* That's exactly the scenario that the rule for taking limits of quotients is forbidding us from considering
* We're not allowed to use the rule for limits of quotients here because the limited denominator is zero
* But what really goes wrong
* I mean, yeah, I can't divide by zero
* Fine, I'm not going to divide by zero, I'm just dividing by numbers close to zero
* But what happens when I divide by numbers close to zero
* A number close to three divided by a number close to zero
* Is that close to anything
* If a number's close to zero it might be positive, and very small
* Three divided by a small positive number is a huge positive number
* What if the denominator were a number close to zero but negative
* Very small, negative number close to zero
* Three divided by a small but negative number
* That would be a hugely negative number
* Every negative
* Well, this means this thing should be getting close to both a gigantic positive number and a very, very negative number
* This thing isn't getting close to anything
* Fundamentally that's the problem but not all is lost
* Think about this slightly harder example: the limit of x-squared minus one over x minus one as x approaches one
* It's a limit of a quotient
* So your first temptation is to replace the limit of a quotient, by the quotient of the limits
* But you can't replace it without quotient of limits, because the limit of the denominator is zero
* The limit of X-1 as X approaches one is equal to zero
* So it seems like our limit laws have failed us
* And then we have got one more trick up our sleeve
* Look at the numerator
* X squared - one that factors as X+1 times, X-1
* First record that fact
* And I am going to record the fact that the numerator factor is X+1 times X-1
* Now I've still got a limit of a quotient and the limit of the denominator is still zero
* So it seems like we're stuck
* But now I've got a factor of X minus one in the numerator and a factor of X minus one in the denominator, and I can use that fact
* What I want to do is imagine canceling these, right
* I'd like to write that this is equal to the limit of just X plus one, as X goes to one
* But note, these are not actually the same function
* Alright
* This thing up here is not defined at one, this thing is defined at one
* And yet the limit doesn't care
* The limit only depends upon values of the function near one
* And near one, this and this are exactly the same
* I'm not allowed to plug one into this, I am allowed to plug one into this
* They're different functions
* But those functions are equal if you're only considering values that are near and not equal to one
* As a result, these limits are the same
* This is another limit of a sum, and the limit of a sum is the sum of the limits, so this is the limit of X plus the limit of one as X approaches one
* The limit of X as X approaches one is one
* The limit of one, which is a constant, as X approaches one is one
* This is one plus one
* This is two
* And so that limit is equal to two and our limit laws have again saved the day
* [SOUND]


--- SKIP ---: 01_how-fast-does-a-ball-move.en.srt


--- SKIP ---: 01_how-fast-does-a-ball-move.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-fast-does-a-ball-move.en_SENTbySENT.txt
* Here we are at a lecture hall at The Ohio State University
* I'm Bart Snap
* Today, we're going to see how we can use Calculus to study the path of an object through space, in particular this orange ball
* When the ball leaves my hand, it's going pretty fast
* But as it approaches the ground, it's going faster and faster, and faster until it hits the ground, bounces up at nearly the same speed
* And then it's going quickly, but slower, slower, slower, until, it reaches its pinnacle and then it stopped
* And then it starts falling back down again, slowly at first, but then quicker, quicker and quicker, and then I, grab the ball
* So how fast was the ball moving well lets see
* The total distance the ball traveled was about, 3.14 meters and the total time the ball traveled for, was about 1.1 seconds
* Dividing this, we find this is equal to 2.85 meters per second
* This is the average speed of the ball
* Now, of course, I took the ball and I threw it down with some force and then it came back up and hovered here and then came back down if you recall
* So, what I'm trying to say is the speed of the ball was changing the entire time and this is the average speed and so sometimes the speed was faster and sometimes it was slower
* Here
* So, think about when I just threw the ball down
* From leaving my hand to touching the ground, that was about 2
* seconds
* And the distance it traveled was about one meter
* One meter divided by 2
* seconds is 5 meters per second
* So we found the average speed to be 2.85 meters per second
* But that's not really the instantaneous speed of the ball
* Because when I threw down the ball, the ball was traveling much faster
* And then the ball bounced up
* And then it started slowing down
* And then it slowed down to almost no speed at all
* And then it came back into my hand going a little faster
* So how do we figure out how fast the balls going at say one of those other time intervals
* We found the average speed over the course of the entire trajectory the full 1.1 seconds to be 2.85 meters per second
* However if we only consider the first 2
* seconds we find the average speed to be five meters per second, this makes sense because if you watch the video you see the ball is moving rather quickly in the first 2
* seconds of its trajectory
* You probably asking yourself, how does Bart know that the ball traveled one meter during the first 2
* seconds of its journey and 3.14 meters during the whole of 1.1 second journey down up and down
* Well, we know this because we got the video
* Alright, here Bart is just about to release the ball from his hand
* And 1, 2, 3, 4, 5, 6 frames later, the ball hits the ground
* There's 30 frames being shot in every second so that means that it took 6 / 30 or 2
* seconds for the ball to hit the ground
* Making a bunch more measurements, I can combine all this information in a graph
* This is a graph of a function the input to this function is time so along the x axis I'm plotting time and seconds
* The output to the function is the height the height of the ball at that particular moment in time
* Now, on this graph, I can go back now and try to figure out how fast the ball is moving at say 4
* seconds after Bart releases it and at 8
* seconds after Bart releases it
* So let's try to figure out how fast the ball is moving at 4
* seconds
* Here I've marked the position of the ball, .4 seconds after Bart releases the ball
* Now we don't really have any way of figuring how fast the ball is moving at that particular moment
* What I can do is figure out the average speed of the ball during some time interval
* So as sort of a first guess to how fast this thing is moving at 4
* seconds, I'm going to figure out the average speed of the ball between 4
* seconds and 6
* seconds
* Alright, so I've got this handy table here, of function values at 4
* seconds
* The the ball was 101.1 centimeters above the ground and 6
* seconds after Bart released the ball, the ball was 16.8 centimeters above the ground
* So I can put that information together to figure out the speed of the ball between 4
* and 6
* seconds
* Alright
* So 4
* seconds to say 6
* seconds at 4
* seconds on my chart the ball was a 101.1 centimeters above the ground
* At 6
* seconds the ball was a 161.8 centimeters above the ground
* Now this time interval has a length of 2
* seconds
* And how far did the ball move during that time interval
* Well 161.8 - 101.1 is 60.7 centimeters
* So during the 2
* seconds that elapsed from 4
* seconds to 6
* seconds after Bart released the ball, the ball traveled a distance of 60.7 centimeters, which means the speed, which is the distance traveled over time is 60.7 over 2
* centimeters per second, which is 303.5 centimeters per second or 3.035 meters per second
* Which is about seven miles per hour
* Now I could do a little bit better, alright
* Here I'm calculating the average speed of the ball between 4
* and 6
* seconds, but I'm trying to figure out how fast the ball is moving at this particular moment
* So instead of just calculating the average speed during this time interval to be about seven miles per hour, I could do it over a shorter time interval, all right
* Instead of 6
* to 4,
* I could go from 4
* to say 5.
* Here's half a second after Bart released the ball
* And I could figure out the average speed of the ball during this part of its trajectory
* Let's see how we calculate that
* Well, it's the same kind of game
* All right?.4 seconds after Bart released the ball, the ball was 101.1 centimeters above the ground
* 5
* seconds after Barb released the ball, looking back at my table I find that the ball was 136.5 centimeters above the ground
* 136.5 centimeters
* This time interval was 1
* seconds long
* And how far did the ball move during that time interval
* Well, that's 35.4 centimeters
* 136.5 minus 101.1 is 35.4
* So, the ball moved 35.4 centimeters
* During the point one seconds that elapsed point four seconds to 5
* seconds after Bart released the ball
* Speed is how far you've traveled over how long it took you so if I divide these this is the speed of the ball the average speed of the ball between point four and point five seconds and this works out to be 354 centimeters per second I mean I'm dividing by this very nice number point one
* which is the same as 3.45 meters per second which is about eight miles per hour
* And indeed, if you look back at this, this chart, between 4
* and 6
* seconds, yeah
* Maybe the average speed was u, about seven miles per hour
* Between 4
* and 5
* seconds the average speed was a little bit higher
* You know, the average speed here worked out to be eight miles per hour instead of seven miles per hour
* The average speed of the ball during this time interval is higher than during this whole time interval
* We're still not there
* We are trying to figure out how fast the ball is moving at this particular moment right not the average speed between 4
* and 5
* seconds
* To get closer, right, we should take an even smaller time interval
* Instead of 4
* to 5
* well, why not look back on our handy chart here and see well, here is where the ball is at 4
* seconds
* Here's where the ball is at 42
* seconds
* We could use this information to figure out the speed of the ball just during the very tiny time interval between 4
* and 42
* seconds after Bart releases the ball
* Well, let's do that
* All right
* So again, .4 seconds after Bart releases the ball, the ball is 101.1 centimeters above the ground
* .42 seconds after Bart releases the ball, the ball is 109 centimeters above the ground, that's what this chart is telling me .42 seconds after Bart releases the ball, 109 centimeters above the ground
* So that means during the very tiny time interval 02
* seconds that elapsed between 4
* seconds and 42
* seconds after Bart releases the ball, the ball has traveled how far well 109 - 101.1 centimeters is just 7.9 centimeters
* So in two hundredths of a second the ball has traveled 7.9 centimeters
* To figure out the speed I again divide 7.9 / 02
* is 395 centimeters per second
* Which is 3.95 meters per second
* Which is about 9 miles per hour
* This is a much better approximation to the instantaneous speed of the ball at 4
* seconds
* Look, here's the graph again
* Between point four and point six seconds, the ball is travelling maybe seven miles per hour on average
* Between point four and point five seconds, the ball is travelling maybe
* Eight miles per hour between 4
* and 42
* seconds we just calculated that the speed of the ball is about nine miles per hour
* And that makes a whole lot of sense
* Right
* The speed of the ball from here to here is slower than the average speed from here to here
* Which is slower than average speed from 0.4 to 0.42 seconds
* The ball's slowing down in its trajectory, so the average speed over these shorter time intervals is decreasing
* So, let's figure out how fast the ball was moving at 8
* seconds
* That's when the ball was at the top of its trajectory
* we can't really do that
* All I can really do is figure out the average speed of the ball over some time interval but I've got a table of values of the function
* And I know how high the ball was at 8
* seconds after release
* It was 182 centimeters, and I can compute its average speed over a very short time interval, like the time interval between 8
* and 81
* seconds after release, all right
* And the ball didn't move very far during that time interval but of course that time interval also isn't very long, so it's not super clear how fast the ball might be moving on average during that time interval
* We can do the calculation though
* Let's do it now, so
* 0.8 seconds after the ball was released, the ball was 182 centimeters above the ground
* 0.81 seconds after the ball was released, the ball was 181.9 centimeters above the ground
* Now this time interval between 8
* and 81
* seconds has the duration of just one hundredth of a second
* 81
* - 8
* is 01.
* That's a very short amount of time and during that short amount of time, how far do the ball move
* Well, 181.9 - 182 centimeters, that's just.1 centimeters
* And if we're being pedantic, it's negative 1
* centimeters
* All right
* The ball fell between 8
* and 81
* seconds, so this number is recording not only how far it moved but also the direction that it moved in
* It's really displacement instead of a distance
* Anyhow, .01 centimeters divided by 01
* seconds, that will give me the velocity, right
* Displacement over time
* So if I divide these, this ratio here is 10 centimeters per second or -10 if I am keeping track of the direction its moving in
* It's falling down at a speed on average of ten centimeters per second during this time interval
* That's -.1 meters per second
* Which is about.2 miles per hour or -.2 miles hour if I'm keeping track of the direction it's going
* Anyway, .2 miles per hour is a really slow speed, right
* The ball is not moving very much on average between 8
* and 81
* seconds
* In light of this, it might make sense to say that the instantaneous speed of the ball at.4 seconds is nine miles per hour
* Now, why
* Well, the average speed between 4
* and 6
* seconds is maybe 7 miles per hour
* The average speed from 4
* and 5
* is about eight miles per hour
* The average speed between 4
* and 42
* seconds is about 9 miles per hour
* You know and based on this, it seems like if we took a really short time interval, just after 4
* seconds and tried to calculate how fast the ball was going on average during that very small time interval, you might conclude that the average speed during a very small time interval is about 9 miles per hour
* It's in that sense that we're going to say that the instantaneous speed of the ball at point four seconds is 9 miles per hour
* When you play the same game 8
* seconds into the balls journey, alright
* When it's just to the top of its trajectory
* So the average speed of the ball, between 8
* and 81
* seconds is exceedingly slow, and you can see that in the video, alright
* The ball is barely moving, at the top of its trajectory
* What's the instantaneous speed of the ball at the top of its trajectory
* It's zero, right
* I mean yes
* The average speed over a time interval between 8
* and 8000001
* seconds isn't zero
* But if you look at an average speed over an exceedingly small time interval, those average speeds over shorter and shorter time intervals are as close to zero as you like
* That's the sense in which the instantaneous velocity at the top of the trajectory, the limit of the average velocities over small time intervals, is zero
* Isn't calculus amazing
* We're using the idea of limits to compute instantaneous speed
* Using a little bit of math, we can understand the world around us
* That's the power of calculus
* [MUSIC]


--- SKIP ---: 01_what-else-is-there-to-study-about-functions-and-limits.en.srt


--- SKIP ---: 01_what-else-is-there-to-study-about-functions-and-limits.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-else-is-there-to-study-about-functions-and-limits.en_SENTbySENT.txt
* We've already have been thinking aboutfunctions and about limits
* And now I want to think deeper into thosetwo ideas
* In terms of functions, I want to think,what does it even mean for a function to becontinues
* How does that relate to limits
* And what are some consequences of afunction's being continuous
* And in terms of limits, what would I thinkabout different kinds of limits now
* I want to think about one side of limits
* I want to know what can I say about afunction's output if I'm looking at input points that are justa little bit below some point
* Or if I'm just looking at input pointsthat are a little bit above some point
* It'd be a one sided limit
* I want to know what happens when I evaluate a function at very large inputpoints
* That'd be a limit as x approachesinfinity
* I want to be able to say, maybe, that myfunction's output value is as large as I'd like as long as my input point isclose enough to some chosen point
* That'll be saying that the limit equalsinfinity
* So, these are some of the ideas I want tolook at
* I want to look at limits that areapproaching from one side
* I want to look at limits involvinginfinity in various ways
* I think there's a lot of reallyinteresting questions to ask along these lines, so let's getstarted
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_what-is-a-one-sided-limit.en.srt


--- SKIP ---: 01_what-is-a-one-sided-limit.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-a-one-sided-limit.en_SENTbySENT.txt
* [MUSIC] Up to now, we've been thinking a lot about limits
* We've been considering f(x) when x is close to but not equal to a
* Let's refine that a bit now
* Instead of thinking about x close to a
* I'm going to think about x close to the right side of a or x close to the left side of a
* Super-sized definition
* So we say the limit of f(x) as x approaches a from the right, I'm going to use this little + sign to mean from the right
* So if this is equal to l, it means that f(x) is as close as you want to l, this is just like before, provided x is near enough a on the right-hand side
* So we're going to use a little + sign to denote approaching from the right-hand side
* Now we're going to play a same game for approaching from the left-hand side
* So let's say the limit of f(x) as x approaches a from the left-hand side is equal to l means that f(x) is as close as you want to l just like usual, provided x is near enough a on the left-hand side
* Let's go see some picture of this at the blackboard
* Really helps to see a graph
* Here's a graph of a made up function that I'm called f(x)
* You'll note that f(x) has some issues at the input 3
* There's an empty circle here and a filled-in circle here so if I plug in 3, my output valley is 2
* And indeed if I plug in numbers that are just a little bit above 3, I get out numbers that are close to 2
* On the other hand, if I plug numbers that are a little bit less than 3, I get out numbers that are close to 1
* We can summarize our observations with these two statements
* The first is that the limit of f(x) as x approaches three from the right-hand side is equal to 2
* And that makes sense because I can get the output of the function to be as close to 2 as I'd like if I'm willing to evaluate the function of inputs that are close to but just a little bit bigger than 3
* Similarly, the limit of f(x) as x approaches two from the left-hand side is equal to 1
* We think back in the graph, I was getting outputs that are close to one if I evaluated the function inputs which are close to, but just a little bit less, than 3
* So in this case, the two sided limit doesn't exist
* I can't say that f(x) is getting close to anything if all I know is that x is close to 3 but the left and the right hand limits do exist
* I can say that f(x) is getting close to 1
* If x approaches 3 from the left-hand side, and I can say that f(x) is getting close to 2 if x approaches 3 from the right-hand side
* This situation comes up quite a bit where you compute and you find that the right and the left hand limits exist but they disagree and consequently, the two side of limit doesn't exist
* I can summarize it like this
* If the limit of f(x) as x approaches a from the right, is different than the limit of f(x) as x approaches a from the left, then the two sided limit the limit of f(x) as x approaches a does not exist
* It works the other way as well
* If the limit from the right-hand side is equal to the limit from the left-hand side, let's call our common value l, then the two sided limit, the limit of f(x) as x approaches a, no + or -
* So this is just the usual old limit
* Then this limit exists and it's equal to that same common value, l
* The homework will challenge you with many more situations of one sided limits
* If you get stuck, contact us
* We are here to help you succeed
* [MUSIC]


--- SKIP ---: 02_what-does-continuous-mean.en.srt


--- SKIP ---: 02_what-does-continuous-mean.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-does-continuous-mean.en_SENTbySENT.txt
* [SOUND] Let's think back to our friend the square root function
* What's the square root of two
* Well, the square root of two is about 1.414
* What's the square root of 2.01
* It's awfully close
* It's 1.417 and a bit more, which is really close to the square root of two
* What's the square root of 1.99
* Well, it's also really close to the square root of two
* It's 1.410 and a bit more, which is really close to 1.414
* The point here is that nearby inputs are producing nearby outputs
* Let's try to see these numbers
* What does the graph of the square root function look like
* Is this the graph of the square root function
* Take a look at what happens right here
* Nearby inputs are not being sent to nearby outputs
* Inputs very close to two
* Say something a little bit less than two and something a little bit bigger than two, are being sent to outputs that are quite far apart
* The numbers show that couldn't have been the graph of the square root function
* But what does the graph for the square root function look like
* This is what the graph for the square root function looks like
* It looks continuous, it's one nice curve
* In particular, nearby inputs give rise to nearby outputs
* Let's try to capture the concept of continuity
* A bit more precisely than just a picture on the graph
* Here's sort of a moral definition of what I mean when I say f of x is continuous at a
* So morally I mean that inputs near a are being sent to outputs near f of a
* From this perspective, it looks like the function, F of X equals the square root of X is continuous at two because inputs near two are being sent to outputs near the square root of two
* How do we make this intuition a little bit more precise
* Here is a precise definition, to say that F of X is continuous at A is to say that the limit of F of X as X approaches A is equal to F of A
* Now think back to what we mean by limit, to say that the limit f of x equals f of a is to say that I can make f of x as close to f of a as you like as long as x is close enough to a
* But that's really the spirit of continuity
* Continuity is trying to say that nearby inputs are sent to nearby outputs, and this limit statement is capturing that sense
* It's saying that I can make the output close to the output at A as long as the input is close to A
* This definition's pretty involved
* We've got to try to unpack this a bit
* What does it really mean to say that the limit of F of X equals F of A as X approaches A
* To make this statement I really need to know that f of x is defined at the point a
* I can't talk about f of a unless I know that a is the domain of f
* Talk about the limit of f of x I also need to know that the limit of f of x as x approaches a exists
* I need this to be some number so I can talk about it being equal to some other number
* Well once I've got these two statements, then it makes sense to claim that the limit of F of X as X approaches A is equal to F of A
* But before I can make this third and final statement, I'm really assuming that these two preceding things hold, alright
* So the definition of continuity is a little bit more subtle than it seems
* It's really these three parts
* The function has to be defined at the point
* The limit has to exist and be equal to some number, and then I can say that number, the limit is equal to the functions value
* So it makes sense to talk about the function at that point
* Nothing we've done so far really captures the idea that the graph is a single curve, a single continuous curve
* We've always just been working at a single point
* This is the definition of continuity at the single point A
* But often we want to talk about continuity on a whole interval at once
* So we'll get rid of this and we'll make this solely a fancier definition
* To say that the function is continuous on a whole interval from A to B is to say that for all points C in between A and B so C is bigger than A and less than B, so C is in the interval A to B
* Then F of X is continuous at that point C
* So this is what we mean when we talk about continuity on a whole interval at once
* So that's the definition for open intervals
* What about closed intervals
* We have to be even a bit more careful when we talk about continuity on a closed interval, A B as opposed to the open interval A B
* So if we say that the function is continuous on the closed interval from A to B
* We mean that F of X is continuous on the open interval from A to B so in between A and B
* But then what happens at A and at B
* Well, the limit of F of X as X approaches A from the right hand side, is equal to F of A
* And the limit of F of X as X approaches B from the left hand side is equal to F of B
* [SOUND]


--- SKIP ---: 03_what-is-the-intermediate-value-theorem.en.srt


--- SKIP ---: 03_what-is-the-intermediate-value-theorem.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-intermediate-value-theorem.en_SENTbySENT.txt
* [SOUND] So far, we've been selling continuity as something about nearness
* Continuous functions preserve nearness, so nearby points gets into nearby points
* But continuity isn't just about how small changes become small changes
* Continuity has consequences for the global structure of the function as well
* Here's one of them
* I've graphed just some random looking continuous function
* And I've picked a couple input points, input point a, input point b
* Here is the point a, f of a, here's the point b, f of b
* And on the y-axis I've got the value f of a and the value f of b
* Now, in between f of a and f of b, I've just picked some random value
* I'm calling it y
* Here's a consequence of continuity
* There has to be some corresponding input x so that if I plug in x, [SOUND] I get out y
* This is the so-called intermediate value theorem
* Let me write down a more precise definition now
* So here's a statement of the intermediate value theorem
* Theorem says the following
* Suppose f of x is continuous in the closed interval between a and b, and that y is some point between f of a and f of b
* Then, there's an x between a and b so that the function's output, when you plug in x, is equal to y
* Here's a real world example, or if you like, a real world non-example of the intermediate value theorem
* Is it possible for me to be standing here in one moment and over here in the next moment without actually occupying the points in between
* What does the intermediate value theorem say
* My position is a continuous function of time
* So, if I'm standing here at say, time t equals zero seconds, and I'm over here at say, time equals three seconds, mustn't there be a time when I'm standing, say, right here
* Yeah, maybe it's a time t equals two seconds
* Who knows
* What the intermediate value theorem says is that for a continuous function, all of the intermediate values are actually achieved at some point along the way
* [SOUND]


--- SKIP ---: 04_how-can-i-approximate-root-two.en.srt


--- SKIP ---: 04_how-can-i-approximate-root-two.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_how-can-i-approximate-root-two.en_SENTbySENT.txt
* [MUSIC] So, I get a number like the square root of two
* And square root of two is irrational
* So, how am I going to figure out what it's approximately equal to
* Well, it turns out that it's approximately, you know, 1.414 and a bit more
* But how would ever figure that out
* How would I know that that's approximately the value of the square root of two
* Let's use the intermediate value theorem to try to pull it
* I want to use the intermediate value theorem to approximate the square root of two
* To do that, I'm going to use this function, f(x) = x^2 - 2
* Notice something about this function
* This function is equal to zero when x is the square root of 2
* And how is that
* f of the square root of 2 is the squared of two squared, which is two, minus two, which is zero
* So, if I'm trying to approximate the square root of 2, what I'm going to think about this, is that I'm going to look for a positive value, that I can plug into this function to make it a square root of zero
* How am I going to find such a value
* You know, the other good thing about this function is that it's continuous
* And then, I can plug in some values, like f(1)
* Now, what's f(1)
* It's one squared minus two and that's minus one
* And I can plot that on my graph right here, and it's this point right here
* And take a look at, say, f(2)
* f(2) would be two squared minus two, which is two
* And I can plot that on my graph, right here
* It's 2, 2
* Now, f is a continuous function and at one, it's negative
* And at two, it's positive
* So, it's a continuous function
* It's negative at one and it's positive at two
* By the intermediate value theorem, there must be a point in between when the functions value is equal to zero
* And you can see that on the graph
* We're looking for that point
* That is the square root of two where this graph crosses the x-axis, the positive x-axis
* And that's the point that we're looking for, right
* The intermediate value theorem promises me there's a value in between where the functions value equals zero
* And I can see that there must be such a point on the graph
* And now, I know that that value is between one and two
* And I can do better
* I can cut this interval between one and two in half and I get that f(1.5)
* Well, 1.5 squared is 2.25 - 2 is 0.25
* [SOUND] Alright
* So, that's, say, this point on my graph
* Now, what do I know
* I know that the squared of two, which is where this graph crosses the x-axis, is between one, where the function is negative and 1.5, where the function is positive
* And I can do better, alright
* I can pick some other point
* Let's be brave and pick 1.4
* And if I plug in 1.4, well, 14 squared is 196
* So, 1.4 squared is 1.96 - 2, that makes this -0.4, alright
* This is barely below the x-axis
* And I can plot that point here
* And now, I know that the square root of two, the positive input to this function, which is equal to zero, well, it must be between 1.4 and 1.5
* Because the function's value at 1.4 is negative and the function's value at 1.5 is positive
* So, this is not so bad
* I mean, we, we could do this with a few calculations on the blackboard
* Let's, let's bring out some sort of computation device so we can try to get an even better approximation to the square root of two
* So here, I've got a function
* The function is f(x) = x^2 - 2
* And you can see that if I plug zero into the function, I get out -2 because 0^2 - 2 is -2
* Now, this is a physical function
* I've got this knob here
* And as I spin this knob, the function's input value changes
* So, for example, if I spin it up to f(05.), f(1/2), that's negative 1.75 and that's right because if I take a half squared, I get a quarter, and a quarter minus two is -1.75
* Now, I could spin the input up to one
* f(1) is -1 = because 1^2 - 2 is -1 or f(1.5), well, 1.5 squared is 2.25, 2.25 - 1 is 0.25
* Now, this is positive or I could wheel it back down a little bit
* And I see that when I get to 1.41, the function's output is negative again
* Then, I could increase the function's input a bit
* Oh, now the function's output is positive again, at f(1.145)
* And then, I could decrease the value a little bit
* Oh, now, the function's output value is negative again and that would increase the output value a little bit
* Oh, now, the function's output is positive and I could decrease the input a bit
* Now, the function's output is negative, could increase the input a little bit
* Now, it's positive, could decrease the input a little bit
* Now, it's negative again
* Now, Look at what happened, right
* What's going on
* I'm looking at the function f(x) = x^2 - 2 and I'm walking back and forth across the point where this function is equal to zero
* And as I walk to the left and to the right, the function is positive and the function is negative
* And I'm getting closer and closer to a, to the actual place where the function is equal to zero and what is 1.41421356
* It's awfully close to the square root of two
* And if you think the square root of two and square it and subtract two, you get zero
* What we just saw with the knob that I was turning is actually an incredibly general technique for figuring out where a continuous function crosses the x-axis
* And we can do it very efficiently
* Let's take a look at how we might do this a little bit more carefully
* Here, I've drawn a graph with some random looking continuous function and I've labeled some points along the x-axis
* Imagine that we couldn't see this whole graph
* Just imagine that the only thing you can do is interrogate this function
* You can ask this function at some input point, are you positive or negative
* We're trying to figure out where, approximately, this continuous function crosses the x-axis
* We're looking for a zero of this continuous function
* How might the game begin
* I'll let it begin by asking the function, are you positive or negative at zero
* And the function is positive at zero
* And then, maybe I'd ask at sixteen
* At sixteen, is this function positive or negative
* And I'd see the function is negative
* The function's value is negative at sixteen
* Because it's a continuous function and the function's value at zero is positive and the function's value at sixteen is negative, I know that there's a zero in between
* There's some point in between that if I plug it into the function, I get zero out
* Now, I could cut that interval in half
* I could plug in eight and I could ask the function at f(8), are you positive or negative
* And the function f(8), the value of the function at eight is positive
* Now, look
* I know the function's value at eight is positive, the function's value at sixteen is negative
* So, by the Intermediate Value Theorem, there must be a value in between, right there, where the function's value is zero
* And now, I could take that interval and cut it in half again
* I could take a look at twelve, which is exactly between eight and sixteen
* And I could ask the function, at f(12),12), are you positive or negative
* And the function's value at twelve is negative
* [SOUND] So now, I know by the intermediate Value Theorem, the function zero zero of this function must land between eight and twelve and I could cut that interval in half again
* I could look at ten, and I could ask the function, well, if I plug in ten, are you positive or negative
* And the function's value with ten is negative
* And now, I know that the zero must land between eight and ten, because the function's value at eight is positive and the function's value at ten is negative, so there must be a zero in between, a point where the function's value is equal to zero
* Now, I could cut that interval between eight and ten in half again
* I could look at nine
* And I could ask the function, at nine, are you positive or negative
* And if I plug in nine, it looks like the function is positive
* And that means that a value that I can plug into the function to make the output zero lies between nine and ten
* And this is really quite remarkable
* I, I, I could cut the interval between nine and ten and half again and see if it was between nine and 9.5 or 9.5 and ten
* And I could keep doing this every time I'm getting a little bit more precision as to the exact value of the input that would make the function zero
* The other really neat thing about this is that I could have just tried all of the values between zero and sixteen
* I could have plugged all seventeen of those numbers into the function to figure this out
* But by doing this clever cutting in half method, this bisection method, I managed to only ask six questions, right
* I asked the function's value at zero and sixteen, at eight and twelve, at ten and at nine, and by only asking six questions, I was able to narrow down a region where a zero resided
* Now, that's pretty quite efficient, much better than asking seventeen questions
* So, this is a very general technique for figuring out where zeroes of continuous functions lie
* And I encourage you to pick your favorite function and see if you can approximate a root, a zero of that function
* [MUSIC]


--- SKIP ---: 01_why-is-there-an-x-so-that-f-x-x.en.srt


--- SKIP ---: 01_why-is-there-an-x-so-that-f-x-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-there-an-x-so-that-f-x-x.en_SENTbySENT.txt
* [SOUND] Here's an application of the intermediate value theorem I'm very fond of
* Here's how it goes
* Suppose you've got a function f
* f is continuous in the closed interval between zero and one
* And whenever x is between zero and one, f of x is between zero and one
* So that's what you've got to suppose when you get out of this
* Then, there is a point x, x between zero and one, and f of x = x
* It's telling you that there exists an input
* So that if you apply f to that input value, you get the output which is the same as the thing you plugged in
* You call these things fixed points
* You imagine that f is moving around the points between zero and one, and you're finding a point x which doesn't move a fixed point
* Why is something like this true
* Let's see
* Let me use the Intermediate Value Theorem but I'm not going to apply the Intermediate Value Theorem to f but I'm going to make up a new function
* g(x) = f(x) - x
* What do I know about g
* g's continuous
* f is continuous by assumption
* The identity function x is continuous and differences of continuous functions are continuous
* So, g is a continuous function and the closed interval 01
* I also know some of the values of g
* What's g of zero
* Well, g(0) is by definition f(0) - 0
* f(0) is between zero and one
* So I've got a number between zero and one minus zero, that number's at least zero
* I also know something about g(1)
* g(1) is by definition f(1) - 1 f(1) is between zero and one, it could be zero, could be one
* But, a number between zero and one minus one is less than or equal to zero
* What do I know altogether
* I've got a continuous function g, its value at zero is bigger than equal to zero
* Its value at one is less than equal to zero
* By the intermediate value theorem, this gives me a point x so that g(x) = 0
* Why do I care about finding a point x so that g(x) is equal to zero
* Well, if I take a look at what g(x) is equal to, g(x) is f(x) - x
* So, I found a point x so that f(x) - x is equal to zero
* I found a point x so that f(x) = x, I found the fixed point
* So, we've seen why this is true
* Let'd try to apply this to a specific example life f(x) equals cosine x
* Now, here I've got a graph of cosine and that the graph of y equals cosine x
* Now, what do I know about cosine
* I know cosine's continuous and cosine of a number between zero and one is a number between zero and one
* So, our statement applies to it
* There's a fixed point for cosine
* There's some value of x between zero and one so cosine of x equals x
* Let's see if we can find that on a computer
* Okay
* I've got cosine loaded up on to my computer
* Cosine of one is about 0.54
* Let me decrease the input
* And I notice that cosine of 0.68 is 0.77
* Here the input is smaller than the output
* Let me increase the input
* Now, notice what happened
* Now the input is 0.74 but the output is smaller than 0.74
* Cosine of 0.74 is just 0.73
* Now, it decreased the input
* Oh, the opposite thing happened
* Now the input is smaller than the output
* Now, I'll increase the input
* I'll decrease the input
* Increase the input
* And you can see that I, I can sort of zoom in or narrow in on the correct value of of x so that cosine of x is equal to x
* Sees in the computer I found that this point here is at about 0.739
* So, without a number between zero and one, cosine of that number is itself
* It's a fixed point for cosine
* These kinds of fixed point theorem statements that assert the existence of fixed points, they pervade mathematics
* Here's another example
* I've got a map of Ohio right here
* Let me apply a continuous function to this map
* [SOUND] I'm going to throw it down to the ground, stomp on it
* And now let's take a look at it
* [SOUND] The question is, is there a point on the map which is exactly above its corresponding point in the ground
* And indeed there is
* I'll use this pin to stab through that point
* [SOUND]


--- SKIP ---: 02_what-does-lim-f-x-infinity-mean.en.srt


--- SKIP ---: 02_what-does-lim-f-x-infinity-mean.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-does-lim-f-x-infinity-mean.en_SENTbySENT.txt
* People have thought, people have wondered about infinity for thousands of years
* We're going to continue that tradition of thinking about infinity, but we're going to focus in on one specific instance of infinity in mathematics
* What does it mean to say that the limit of a function equals infinity
* Here's what it means
* The limit of F of X, as X approaches A equals infinity means that F of X is as large as you like
* Provided x is close enough to A
* As a bit of a warning, I'm not saying that this number limit F of X, X approaches A is equal to this number, infinity is not a number
* What I am doing here is attaching a precise meaning to the entire statement that the limit of F of X is infinity
* So, that's what it means precisely, but what does it mean practically
* Let's go to the board
* This is an example, the limit of one over X squared as X approaches zero
* Now this limit is not equal to a number
* One over X squared is not getting close to a number when X is approaches zero
* But one over X squared is as big as I want it to be if I'm willing to put X close to zero
* For instance, if X is within a 1000th of zero, what happens
* Well to say X is within a 1000th of zero is to say that X is between minus.00 and.001
* Now, X is also non zero here because I don't want to divide by zero
* So I've got a non zero number within a 1000th of zero
* What does that mean about X squared
* [SOUND]
* Well that means that X squared is, it's bigger than zero because if I square any non zero number, it's positive and it's less than, [SOUND] a millionth
* So if I take a number within a thousandth of zero and I square it, that was within a millionth of zero
* And [SOUND] what does that mean about one over X squared
* Well if X squared is within a millionth of zero, one over X squared is now bigger, [SOUND] than a million
* What happened, right
* I made one over x squared very large by making x close enough but not equal to zero
* And there's nothing particularly special about these numbers
* If I wanted one over x squared to be bigger than a trillion, I would just need x to be within a millionth of zero
* This example is at once maybe too complicated because I've got some explicit numbers in here
* And maybe this formula is not complicated enough to, to really get a sense of what's going on
* Let's look at a slightly more complicated function
* So what's the limit of X plus two over X squared minus 2x plus one as X approaches one
* And this is a limit of a quotient
* So your first temptation is to think the limit of a quotient the quotients the limits
* But what's the limit of the denominator
* The denominator is a polynomial
* Polynomials are continuous
* So I can evaluate the limit of the denominator just by plugging in one
* And if I plug in one, I get one minus two plus one
* That's zero
* The limit of the denominator is zero
* So I can't simply say that the limit of the quotient is the quotient of the limits in this case
* Because the limit of the denominator is zero
* And that limit law does not apply in this case
* What am I going to do
* Well I could also notice the denominator factors
* X squared minus 2X plus one, I can rewrite that
* [SOUND] X squared minus 2X plus one is X minus one squared
* [SOUND] So instead of evaluating this limit, I could try to look at this limit, the limit of X plus two over X minus one squared as X approaches one
* Now what do I know
* The numerator is X plus two and if X is close to one, I can make X plus two close to three
* What about the denominator
* A number close to one, minus one squared, is a number close to zero
* But not just a number close to zero
* It's a positive number close to zero
* So let me write this down
* Alright
* The numerator [SOUND] is about three
* [SOUND] And the denominator [SOUND] is about what
* Well, it's some small but positive number
* [SOUND]
* And what happens if I take a number, like, near three, and divide it by a number which is small and positive
* That number can be as big as I like
* So I can make this quantity as large as I like, if I make x close enough to one
* Because I can make the numerator close to three, and I can make the denominator as close to zero and positive as I like
* And if I take a number close to three and divide it by a number close to zero, I can make a number as large as I want
* So this limit [SOUND] is equal to infinity
* The homework includes even trickier situations
* For instance, limit problems where x approaches negative infinity, instead of infinity
* If you get stuck I encourage you to contact us
* We're here to help you.


--- SKIP ---: 03_what-is-the-limit-f-x-as-x-approaches-infinity.en.srt


--- SKIP ---: 03_what-is-the-limit-f-x-as-x-approaches-infinity.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-limit-f-x-as-x-approaches-infinity.en_SENTbySENT.txt
* [MUSIC]
* A lot of calculus is about understanding the qualitative features of functions
* Nobody really cares about f of 17
* But you might care about f of a big number, qualitatively
* We're going to try to make this concept of big number a bit more precise
* Well, here's how we're going to get around talking about a big number
* We're going to talk about the limit
* The limit of f of x as x approaches infinity equals to l
* Means that f of x is as close as you want it to be to l, provided x is large enough
* So instead of talking about just plugging in a big number, I'm going to say F at some big number, so to speak, is equal to L if I can make the output of F close to L by plugging in big enough numbers
* At this point we've seen a bunch of different definitions of limits
* But they're all united by a common theme
* What if someone had asked us to cook up a definition of the limit of F of X equals infinity as X goes to infinity
* Could we come up with a definition for this
* Yeah, absolutely we can, here we go
* The limit of F of X as X approaches infinity equals infinity means that I can make F of X as large as you want it to be provided X is large enough
* Consistently when we're talking about infinity in limits we're never actually talking about a specific value
* We're just talking about a value which is as big as you want it to be
* Let's go do an example at the blackboard
* There is a question
* With the limit, of 2x over x+1 as x approaches infinity
* Before we dive into this analytically, lets get some numeric evidence
* This is my function, again fx)= of 2x over x+1.1
* I want to know qualitatively, what happens when I plug in big numbers in this function
* So, lets say f100)
* of 100
* Well, that's not too hard to figure out
* 22 times 100 is 200 and 100 plus one is 101
* Now, 200 divided by 101 is pretty close to 2
* And there's nothing too special about 100, right
* If I'd done this four million I would have gotten two million over a million in one, which would be even closer to 2
* Numerically, it looks like this limit's two, but we just figured that out by plugging in some big numbers
* I want a more rigorous argument, some analytic that is limit is actually equal to two
* How I'm going to proceed
* My first guess would be to use the limit law for quotients
* This is the limit of a quotient which is the quotient of limits provided the limits exist and the limit of the denominator is none zero
* Bad news here is the limits don't exist
* The limit of the numerator is infinity which isn't a number
* So I can't use my limit law for quotients here
* Instead I'm going to sneak up on this limit problem by wearing a disguise
* I'm going to multiply by a disguised version of one
* I'm going to multiply by one over x divided by one over x
* Now this is just one
* Admittedly, I have changed the function
* The function's not defined anymore at zero
* But for large values of X, this doesn't affect anything
* And I'm taking the limit as X goes to infinity
* So I only care about agreement at large values of X
* I'll do some algebra
* This limit has now the limit of 2X times one over X
* Which is two divided by the limit of X plus one times one over X
* Which is one plus one over X
* Maybe it doesn't look like I've made a lot of progress here, but this is a huge progress
* The limit of the numerator is now a number, it's two
* And the limit of the denominator is also a number
* And a non zero number, at that
* So I can use my limit law for quotients
* This is the limit of a quotient, which is the quotient of a limit
* It's the limit of two, the numerator divided by the limit of the denominator, as x approaches infinity
* The limit of the numerator is just the limit of a constant, which is 2
* The limit of the denominator is a limit of a sum, which is the sum of the limits provided the limits exist, and they do
* The limit of 1 is just 1
* And what's the limit of 1 over x as x approaches infinity
* Well that's asking, what is 1 over x close to when x is very large
* Well I can make 1 over x as close to zero as I like if I'm willing to make x large enough
* So the limit of 1 over x as x approaches infinity is zero
* That means my original limit is 2 over 1 plus zero, which is 2
* [MUSIC].


--- SKIP ---: 04_why-is-infinity-not-a-number.en.srt


--- SKIP ---: 04_why-is-infinity-not-a-number.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_why-is-infinity-not-a-number.en_SENTbySENT.txt
* [SOUND] Infinity is not a number like seventeen
* Don't treat it as a number
* Let, let me show you something that people do all of the time
* Here it is
* People write down the interval from zero to infinity including zero, which is fine but including infinity, which is not okay
* Infinity's not a number
* What people should be writing down is this
* The interval from zero to infinity including zero but not including infinity
* Because infinity's not a number
* Why am I freaking out about this
* What's so bad about thinking of infinity as if it were some number
* Now, if you start trying to do arithmetic with infinity, you're liable to walk straight into a trap
* Let me demonstrate for you by walking into one of these traps myself
* Let's treat infinity as if it were a number
* Well, what's infinity plus one in that case
* I got infinitely many things and I add one more
* That's the same as having infinitely many things
* So, infinity plus one would equal infinity
* Now, what else would I know about infinity as a number
* Well, what would infinity minus infinity be equal to
* This would be a number minus itself, and a number minus itself is zero
* So, you're going to treat infinity as a number, you're going to be believing these two statements
* You're going to believe infinity plus one is infinity and you're going to believe infinity minus infinity is equal to zero
* This is how these numbers would work
* This is actually very bad
* Let's just look at infinity plus one minus infinity, and let's subtract infinity from both sides
* And you said infinity minus infinity is equal to zero
* But, what's infinity plus one minus infinity
* Well, that would be infinity minus infinity plus one
* Infinity minus infinity is zero
* This would be zero plus one
* That side would be one
* So, if you're going to treat infinity like a number, you're going to end up telling me that one equals zero
* That's ridiculous
* The upshot here is that you can't do arithmetic with infinity
* Infinity's not a number like seventeen
* But something comes to save the day
* We can do limits
* For instance, consider this problem where I'm doing a calculation involving infinity
* But instead of working with infinity directly, I'm phrasing it as a limit question
* What's the limit of x * x - 1 as x approaches infinity
* Well, x is as large as I like
* By making x big enough, I can make x as big as I like
* x - 1 is also as large as I like, by making x big enough, I can make x - 1 as big as I like
* And what happens if I multiply together two numbers which are as large as I like
* Well, the product of two numbers that are as big as I want them to be can be as big as I want them to be
* So, in that sense, the limit of x * x - 1 as x approaches infinity is equal to infinity
* So, what about our original example
* What's infinity minus infinity
* [LAUGH] Well, it depends
* Here's one possibility
* Let's consider the limit of x^2 - x as x approaches infinity
* Now, this is a limit of a difference
* You might remember back, the limit of a difference is a difference of the limits provided the limits exist
* Ignoring that last part about whether the limits exist, [LAUGH] you might just blindly start writing down the limit as x approaches infinity of x^2 minus the limit of x as x approaches infinity
* This is no good, right
* The limit of x^2 as x approaches infinity, that's equal to infinity
* And the limit of x as x approaches infinity, that's infinity, right
* I can make x^2 as large as I like if x is big enough, and I can make x as large as I like if x is big enough
* So, what just happened
* I'm running the limit of a difference as the difference of the limits, but these limits don't exist, right
* They're equal to infinity and infinity is not a number
* Now, I'm left with infinity minus infinity
* I don't know what to do, right
* Who knows what that's equal to
* That's exactly the sort of thing I'm not permitted to think about
* Instead, if I wanted to know the limit of x^2 - x as x approaches infinity, I could rewrite this limit as the limit as x goes to infinity of, what's another way of writing x^2 - x
* Could write it as x * x - 1
* And we saw just a minute ago that the limit of x * x - 1 as x approaches infinity is equal to infinity
* So, in this case, it seems that infinity minus infinity is infinity
* On the other hand, infinity minus infinity could be seventeen
* Let's see how
* Here again, I've got a limit of a difference of two things
* Something minus something as x approaches infinity
* Now, if I blindly just apply the limit of a difference as the difference of limits without remembering that that's only valid if the limits exist, let's see what happens
* And then, I get the limit as x approaches infinity of the first thing, which is x + 17, minus the limit of the second thing which is just x
* Now, what's the limit of x + 17 as x approaches infinity
* Well, I can make x + 17 as large as I like if x is big enough, so that's infinity
* And what's the limit of x as x approaches infinity
* Well, I can make x as large as I like if x is big enough, so that's also infinity
* So I've again walked into the trap of writing down infinity minus infinity, right
* I applied the limit of a difference equals the difference of the limits without remembering that that's only valid if the limits exist
* And in this case, the limits only exist in the weak sense that I can write down that they equal infinity
* Anyway, I don't want do that
* Now, how could I figure out what this limit's equal to
* Well, this is a limit of something and I could rearrange the something, right
* This is the same as the limit as x approaches infinity
* What's another way of writing this
* x + 17 - x, I could have just written seventeen
* Now, what the limit of seventeen is as x approaches infinity
* Well, what the limit of seventeen as x approaches anything at all
* That's just seventeen
* So, in this admittedly contrived case, infinity minus infinity ended up equaling seventeen
* [SOUND]


--- SKIP ---: 01_what-is-the-difference-between-potential-and-actual-infinity.en.srt


--- SKIP ---: 01_what-is-the-difference-between-potential-and-actual-infinity.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-difference-between-potential-and-actual-infinity.en_SENTbySENT.txt
* [MUSIC] Let's consider this limit
* The lim (2x-x), as X Р Р†РІР‚В РІР‚в„ў Р Р†РІвЂљВ¬РЎвЂє = Р Р†РІвЂљВ¬РЎвЂє
* That's a true statement, but there's two totally different ways to think about this statement, and it really hinges on the distinction between potential and actual Р Р†РІвЂљВ¬РЎвЂє
* To have a potentially infinite pile of fish is to have an endless supply of fish, as many fish as you'd like to have, and that sense really goes will with how we're thinking about infinity in these limits
* To say the limit of 2x minus x equals infinity, as x approaches infinity, is to say that I can make 2x minus x as big as I like, as long as x
* Big enough
* Contrast that with actual infinity
* To have an actually infinite pile of fish would be to have, right now, a pile of fish that contains infinitely many fish at this very moment
* Is it possible to combine that way of thinking with infinity, with these kind of limit statements
* Let me share with you a fable, to see one of the paradoxes that results
* Once upon a time, there was a house
* I lived in that house, with my cat
* And we lived, near a lake, and this lake is full of fish, so every day we went fishing
* And each day I caught two fish
* The first day I caught fish labelled 1 and 2
* Now, my cat prefers eating the lowest number of fish in our stockpile, so my cat ate the fish numbered 1
* The next day, I went fishing again, and I caught fish labelled 3 and 4
* And my pet, still preferring to eat the lowest numbered fish
* Eats fish number 2
* Another day another fishing expedition, I go fishing again, I get 2 more fish, label 5 and 6, my cat preferring to eat the lowest number fish in our stock pile eats fish number 3
* I go fishing the next day and I get 2 more fish, fish label 7 and 8, my cat preferring to eat the lowest numbered fish in our stock pile eats fish number 4
* And so it goes forever
* Each day our stockpile gets bigger
* There's more fish in my pile every single day
* And yet, at the end of time, do any fish remain
* On the Nth day my cat ate the Nth fish
* So which fish survives my cat's appetite
* Human beings want to understand infinity, but reasoning about actual infinity is liable to walk us straight into those kinds of paradoxes
* Instead, limits by focusing our attention on potential infinity provide a way to reason about infinity that avoid those kinds of paradoxes
* [MUSIC] It provides a way for mere human beings to think about infinity in a precise way
* [MUSIC]


--- SKIP ---: 02_what-is-the-slope-of-a-staircase.en.srt


--- SKIP ---: 02_what-is-the-slope-of-a-staircase.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-slope-of-a-staircase.en_SENTbySENT.txt
* [MUSIC] Hello
* I'm at the Knowlton School of Architecture at the Ohio State University
* And today, we're going to measure the slope of some staircases, namely, this staircase here and this even larger staircase
* You may think that this larger staircase is steeper than this staircase because, well, this staircase is harder to climb
* But let's actually find out
* And we're going to find out by measuring how far the staircase goes up by how wide each step is
* When I measure this step, I see that it goes over twelve inches and it rises about six and a quarter inches
* On the other hand, we have this larger staircase here
* Let's see what its slope is
* So, when I measure, I get 36 inches for the width of each step
* On the other hand, [SOUND] I find that the height of each step is about 18-3/4 inches
* Now, that we've made the measurements, let's go compute the slope
* So, we've measured our stairs and we found out that the small steps went up by 6.25 inches and they were 12 inches wide, okay
* This gives us a slope for the small steps of 6.25 all over twelve
* But there were also large steps
* Let's draw those in
* Here we go
* So, this was one of the large steps and then, we had another one
* It goes off and it builds, it climbs over there
* It goes down like this
* This is a large step
* Alright
* The height of the large step was this place right here
* 18.75 inches, that's the height of the large step
* And the width of the large step was 36 inches
* Okay, great
* So, the slope of the large steps is 18.75 all over 36
* These two slopes are the same, because we can simplify, we can reduce this fraction to be dividing the numerator by three and dividing the denominator by three, we get 6.25 / 12
* And we can see, if we connect the tips of these stairs with a line or this makes a line of the desired slope and see how the large stairs and the small stairs all meet at the corner of this line
* The fact that the staircase with the large steps and the staircase with the small steps have exactly the same slope is evidenced by the fact that they have the same railing
* There's the railing for the staircase with the large steps and here's the railing for the staircase with the small steps
* And they're exactly at the same angle
* So, we've seen that the staircase with the larger steps and the staircase with the smaller steps actually have exactly the same slope
* Now, let's use the slope to estimate how tall the staircase is after you've gone a certain distance in the horizontal direction
* How high up am I now
* Here, you can see that we have a tape measure where we're measuring the width or the horizontal distance that I traveled here on the staircase
* And if we get to the point where I was standing, we'll find out that it's about 23 feet
* Now, how high was I standing when I was up there
* So, now that we've made our calculation, let's check our calculation
* Okay
* Now, we have a question
* We went to a certain part on the staircase, say, right here
* And then we measured
* We, we, we, we marked, we had a point in mind and we measured the distance on the ground to that point
* We found out that it was 23 feet, okay
* So, if you remember, the slope of a staircase was 6.25 / 12, which is approximately 0.52
* We want to know this height, x
* So, we went x / 23 to be approximately 0.52
* Solve for x
* Multiply both sides by 23 and we get x is approximately 0.52 times 23
* 0.52 times 23 is 11.96
* So, x is approximately 12 feet
* Now, let's go check our answer
* So here we are, checking our measurement
* [MUSIC] And I can see, it's almost exactly twelve feet
* [MUSIC]


--- SKIP ---: 03_how-fast-does-water-drip-from-a-faucet.en.srt


--- SKIP ---: 03_how-fast-does-water-drip-from-a-faucet.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-fast-does-water-drip-from-a-faucet.en_SENTbySENT.txt
* [MUSIC] The faucet has a slow leak
* It's dripping
* How much water is being wasted
* Let's find out
* Now, I'm going to start the timer and see how full the measuring cup is after, say, three minutes
* [MUSIC] So, after three minutes of dripping, the drip has put approximately 13 milliliters of water into this measuring cup
* Here, I have a cube that holds one liter of liquid
* How long would it take our dripping faucet that drips 13 milliliters per three minutes to fill this cube that holds 1000 milliliters
* [MUSIC] Alright
* It's been about 90 minutes
* Let's see where we're at
* It looks like almost exactly 400 milliliters
* So, we've collected some data and now, let's see if we can figure something out
* Alright
* Here at time and time and water
* After three minutes, we found that 13 milliliters of water are inside the measuring cup
* This tells us that the water is entering the measuring cup at a rate of 13 milliliters for three minutes, which is equal to or approximately [SOUND] 4.3 milliliters per minute
* Later, we checked it and we found that after 90 minutes, there were 400 milliliters in the cube this time
* Well, this tells us since going from here to here, we have a difference of 87 minutes and going from here to here, we have a difference of 387 milliliters, this gives us a new rate
* It says, that we have 387 milliliters per 87 minutes and that's approximately 4.4 milliliters per minute
* Aha
* This looks like it's linear growth
* I know that the slopes are slightly different but such a, such a small difference that if we plot it, it should be linear
* Now, at what time is there one liter of water in the cube
* That would be 1,000 [SOUND] milliliters
* At what time
* So, we should use t for the variable there
* We have to solve the following equation
* We want 1000 / t to be approximately well, what's between 4.3 and 4.4
* 4.35, okay
* Ha, ha
* So now, that's the same as saying, t is equal to 1,000 / 4.35 five, this is approximately 230 minutes
* 230 minutes is 3 hours, 50 minutes
* [MUSIC] At this point, 3 hours and 50 minutes has gone by
* If we check the cube, [MUSIC] we see it's right at a 1,000 milliliters
* [MUSIC]


--- SKIP ---: 01_what-is-the-official-definition-of-limit.en.srt


--- SKIP ---: 01_what-is-the-official-definition-of-limit.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-official-definition-of-limit.en_SENTbySENT.txt
* [MUSIC] So now we learn what the official definition of limit is
* To say that the limit of f(x) = L as x approaches a, means the following
* It means that for all epsilon bigger than zero, this backwards three is the real number epsilon or the Greek letter, a variable
* So for all epsilon greater than zero, there's a delta greater than zero, this is the Greek letter delta
* So, for all epsilon greater than zero, there's a delta greater than zero
* So that if, this, if the absolute value of x - a is between zero and delta, then, the absolute value of f(x) - L is less than epsilon
* When you say it like that, I think it's really hard to see how this has any relationship to what a more intuitive description of this limit statement might be
* I mean, what's this trying to get at
* It's trying to say f(x) is as close as I want to L by making x sufficiently close to a
* So, how, how to reconcile those, those two perspectives, right
* How does this have anything to do with things being close
* The key, take a look at this absolute value of the difference, right
* The absolute value of x - a is the distance between x and a
* So to say that the distance between x and a is between zero and delta is to say that x is within delta of a, alright
* The distance from x to a is less than delta
* And to say that the distance between x and a is bigger than zero is just to say that the distance between x and, and a, you know, isn't zero, right, x isn't a
* So I can rewrite that, maybe in a little bit easier way
* [SOUND] So instead of saying that, it's the same thing to say, if x is not equal to a, so the absolute value of x - a isn't zero, and x is within delta of a
* So the distance between x and a is delta
* And I can do the same thing to this absolute value of a difference, alright
* The absolute value of f(x) - L, that's the distance, between f(x) and L
* And the sum of the distance between f(x) and L is less than epsilon
* Well, that just means that f(x) is within epsilon of L
* So, I'll rewrite that as that
* [SOUND] Here we go
* [SOUND] Then f(x) is within epsilon of L
* So, I think when, when you write it like this, it makes a little bit more sense, right
* To say that the limit of f(x) = L as x approaches a, means that for all numbers epsilon, epsilon is measuring how close I want f(x) to L, then, there's some corresponding number delta, which is how close x has to be to a
* So that whenever x is that close, delta, within delta of a, then f(x) is really within epsilon of L
* And to say that the limit of f(x) = L means that no matter which epsilon I choose, there's some corresponding delta, so that whenever x is within delta of a, then f(x) is within epsilon of L
* Now, how this actually gets played out in, in more concrete situations can be, you know, kind of complicated, but this is really the official definition of what it means to say that the limit of f(x) equals L as x goes to a
* [MUSIC] And we're going to be trying to unpack this definition to see what it might mean in some specific cases.


--- SKIP ---: 02_why-is-the-limit-of-x-2-as-x-approaches-2-equal-to-4.en.srt


--- SKIP ---: 02_why-is-the-limit-of-x-2-as-x-approaches-2-equal-to-4.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_why-is-the-limit-of-x-2-as-x-approaches-2-equal-to-4.en_SENTbySENT.txt
* [MUSIC] So, what does it mean to say that the limit of x^2, as x approaches 2, is 4
* Strictly speaking, it means that you can make x^2 as close as you want to 4 by making x sufficiently close to 2, but talking in that way can be a little bit confusing
* So I'm going to sort of format it here as, as if it were a dialogue
* Alright
* So you're going to make some sort of demand
* You're going to demand that x^2 be close to 4
* Maybe you're going to demand that x^2 be within 1/10 of 4
* Alright
* So that means you're, you're asking that x^2 be between 3.9, 3.9 is a 1/10 less than 4, and 4.1, which is a 1/10 more than 4
* So you're going to make some demand that the output be close to 4 and I have to satisfy your demand by making x sufficiently close to 2
* Now, what does that mean
* I'm going to satisfy your demand by stipulating that x be within some small distance of 2
* So, how close is sufficiently close
* Well, in this case, let's make let's make x be within a 1/100 of 2 and see what happens
* So x is within a 1/100 of 2 and that means that x [SOUND] is bigger than 1.99 [SOUND] and smaller [SOUND] than 2.01
* And if x is bigger than 1.99, then x^2 is bigger than 3.9601, and if x is smaller than 2.01, then x squared is smaller than [SOUND] 4.0401
* And, and look at these numbers, 3.9601, that is bigger [SOUND] than 3.9, and over here, 4.0401, that's smaller than 4.1
* So notice what happened here
* If x is within a 1/100 of 2, then x is between 1.99 and 2.01
* But if x is between 1.99 and 2.01, then x^2 is between 3.9601 and 4.0401, and if x^2 is bigger than 3.9601, it's bigger than 3.9, and if x^2 is smaller than 4.0401, it's smaller than 4.1
* So that means demanding that x be within a 1/100 of 2, in fact, forces x^2 to be between 3.9 and 4.1
* In other words, it forces x^2 to be within a 1/10 of 4
* So if your demand is that x squared be within a 1/10 of 4, I can satisfy that demand by simply requiring x to be within a 1/100 of 2
* Now, I can do the same thing for other demands that you might make
* You might have demanded that x^2 be within a 1/100 of 4 and I can do that as well
* So that would mean that x^2 is between 3.99 and 4.01
* Well, if x^2, if you want x^2 to be between 3.99 and 4.01, I'm going to have to make some condition on how close x have to be to 2
* So let's try a 1/1000
* So if x is within a 1/1000 of 2, that means that X, it'll be between 1.999 and 2.001
* And if x is bigger than 1.999, then x^2 is bigger [SOUND] than 3.996001
* And if x < 2.001, then x^2 < 4.004001
* Now, look at these numbers, 3.996001, that is bigger 3.99, and 4.004001, that is smaller than 4.01
* So if x is within a 1/1000 of 2, that means x is between 1.999 and 2.001
* That means that x^2 is between 3.996 and 4.004, a little bit more
* That makes x^2 be, between 3.99 and 4.01, which is exactly what you demanded
* So this is the structure of, of what it means to say that the limit of x^2 is 4 as x approaches 2
* It means no matter close you demand x ^ 2 to be to 4, even if this epsilon were replaced by a very tiny number
* I'd be able to find some other distance, some number to put here, so that as long as x is that close to 2, then x^2 is as close as you wanted to the number 4
* So the exercise, below asks you to take a look at another situation like this to see if you can figure out number to put here to satisfy some condition that someone might make on you
* [MUSIC]


--- SKIP ---: 03_why-is-the-limit-of-2x-as-x-approaches-10-equal-to-20.en.srt


--- SKIP ---: 03_why-is-the-limit-of-2x-as-x-approaches-10-equal-to-20.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_why-is-the-limit-of-2x-as-x-approaches-10-equal-to-20.en_SENTbySENT.txt
* [MUSIC] Here's a claim
* The limit of 2x as x approaches 10, is 20
* Now, to justify this claim using an epsilon delta argument I have to be able to prove that delta for every epsilon, alright
* You're going to demand that 2x be within epsilon of 20
* I'm going to satisfy your demand by saying x is within some number delta of 10
* [SOUND] So proof, let epsilon be bigger than zero
* I don't know how small a number epsilon you're going to choose
* I'm going to set delta equal epsilon over two
* I'm going to check now that this value of delta will work to satisfy your demand involving epsilon
* So, if zero is less than x - 10 is less than delta, right
* If x is within delta of 10, then if you multiply by 2, we see that 2 * x-10 is less than 2 delta
* But what's 2 delta
* Delta is epsilon over 2
* 2 delta is just epsilon
* So then, 2 times the absolute value of x-10 is less than 2 delta, which is epsilon
* [SOUND] And so, 2 times the absolute value of x-10, that's the absolute value of 2x - 20, and that's less than epsilon
* So look at what we've shown, alright
* Some epsilon bigger than zero, a corresponding value of delta is going to be epsilon over 2
* And then, I verify that if x is within 10, is within delta of 10, then 2x is within epsilon of 20
* And that's exactly what it means to say that the limit of 2x is 20 as x approaches 10
* For every epsilon, there's some delta so that whenever x is within delta of 10, then the function 2x is within epsilon of 20
* You can imagine trying to do this with other functions, right
* But I'll let you try that
* You can try that in the exercise included below
* [MUSIC]


--- SKIP ---: 01_what-comes-next-derivatives.en.srt


--- SKIP ---: 01_what-comes-next-derivatives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-comes-next-derivatives.en_SENTbySENT.txt
* [MUSIC] A major theme in calculus is change
* You've got one thing affecting somethingelse, you want to know, how does changing this one thingaffect this other thing
* Often the relationship between these twothings is given by a function, right
* You've got some kind of function that hasinputs and outputs
* And you're wiggling that input point, andyou want to know how the output value viewchanges
* Very concretely
* You might ask for the ratio of change inthe output valve view to change in the input point and that ratio,that's the derivative
* Alright
* Derivatives measure how change in theimport affects the out port
* At least infinitesimally
* And studying derivatives is exactly whatwe're going to do now
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_what-is-the-definition-of-derivative.en.srt


--- SKIP ---: 01_what-is-the-definition-of-derivative.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-definition-of-derivative.en_SENTbySENT.txt
* [MUSIC] We want to capture precise information about how wiggling the input effects the output
* Here's the difinition of derivative that will allow us to do exactly that
* The derivative of f at the point x is defined to be this limit
* The limit of f(x+h)-f(x)/h as h approaches 0
* Now, when this limit exists, I'm going to say the function is differentiable, alright
* If the derivative of f exists at the point x, I'm going to to say the function is differentiable at that point x
* Sometimes, you'll see different definitions of the derivative
* Here's an equivalent one
* The derivative of f at x could equivalently be defined as this limit, the limit as w approaches x of f(w)-f(x) all over w-x
* Now, how does this definition relate to our original definition of derivative
* The derivative of f at x is this limit involving h
* Well, look
* In both cases, the numerators are measuring how the output is changing
* Here, I'm plugging in a nearby input and I'm looking at how much the output changed compared to the output at x
* And h is measuring exactly how much that input changed by
* Here, I'm again measuring the difference of two output values
* Here, w is my new output value, which is close to x
* Alright, down here, h is just measuring how much I wiggled x by
* Here, w is actually just some nearby value of x
* And in both cases, the denominator is measuring how much the input was changed
* Here, h is exactly how much the input was changed by
* Here, w-x is measuring how much the input changed by
* The other thing that makes these definitions sometimes a little bit tricky is that people will give you a definition that's not at the point of x
* For instance, here's a definition of the derivative of f at the point a
* It's the limit of f(x)-f(a)/x-a as x approaches a
* You can compare the first and the third definitions here
* This first one has a w and an x and w is approaching x to get the derivative at x
* This bottom one, I'm trying to compute the derivative at a and x is approaching a, alright
* So, the roles of w and x and the role of x and a are somehow analogous here
* Now, think back to when we were talking about continuity last week
* We started out with a definition of continuity at a single point and then we expanded that definition to be continuity on a whole interval
* We played the same game with the derivative
* Here we go
* If the derivative of f exists at x, whenever x is between a and b, but not at a, or at b, we won't worry about that, just whenever x is between a and b
* And if this happens, then, we say that f is differentiable on the interval (a,b)
* So, as a little bit of a warning here, this is not a point
* This is an interval
* It's all the numbers between a and b, not including a, not including b
* Now, contrast this with continuity, when we talked about continuity on an interval, I also had separate definitions for continuity and closed intervals or half-open intervals
* But that doesn't really make so much sense for the derivative
* here's why
* The derivative is measuring how much wiggling x affects f(x)
* And if I'm standing in the middle of an interval, I can wiggle x
* Even if I'm standing pretty close to b or pretty close to a, I can always wiggle just a little bit to the left and a little bit to the right, no matter how close I'm standing to a or how close I'm standing to b, unless I'm standing, say, at the point b
* If I'm standing right at b, I can wiggle to the left
* But I can't wiggle at all to the right without walking right outside of the interval
* So, in light of this, I don't really want to talk about differentiability on closed intervals
* I only want to talk about differentiablity when I can honestly talk about wiggling the input and that's only true on open intervals
* There's plenty of other subtleties to this
* If I differentiate a function which is differentiable on a whole interval, then I get a new function, f'
* Specifically, the derivative of f at the point x will be written like this, f with this little tick mark, and we're going to pronounce that prime, f'(x)
* The point here is that I can define the derivative, right, as this limit of this quotient
* And when you think of it this way, if this is really a function, right
* This is a rule that defines some new function, so I can regard f'(x) not just as a specific values that I get by plugging specific values of x, but honestly as a function
* Alright
* This thing is the sort of thing I can plug any value of x into and see what I get out
* It's a function that somehow derived from f
* Maybe hence, the name derivative
* There's a whole bunch of different notation that you're going to see for the derivative in the wild
* Here are some of these
* Alright, the derivitive of f at the point x might be written as f'(x), like we've just been seeing
* Or it might be written d/dxf(x) or Dxf(x), or a bunch of other things, right
* Lots of different people have their favorite notation for these
* But really, this f' notation and this d/dx notation are what we're going to be using in this course
* There are upsides and downsides to these various choices of notation
* For instance, here's a huge upside to this d/dx notation
* It's really emphasizing that the derivative is a ratio, right
* It looks like df, the change in the output, dx, the change in the input, somehow revealing a little bit of how the derivative is actually defined
* The f'(x) notation doesn't emphasize that the derivative is a ratio, but it does emphasize the derivative is a function
* When we use the f'(x) notation, at least you can tell this thing is a function
* You've clearly labeled the input, x
* Differentiating gives a new function, even the name suggests that
* The derivative is somehow derived from the original function
* And if the derivative is now a function, you can then differentiate the derivative
* And differentiate that, and keep on going
* And dig deeper and deeper and deeper, trying to uncover more and more secrets about the original function, f
* All of that is yet to come
* But the point is just that there's so much yet to explore
* [MUSIC]


--- SKIP ---: 02_what-is-a-tangent-line.en.srt


--- SKIP ---: 02_what-is-a-tangent-line.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-a-tangent-line.en_SENTbySENT.txt
* [MUSIC] Here I've graphed some function
* Notice what happens if I zoom in on one little piece of the graph, right
* If I just focus on one part of the graph, well, that little bit of graph sort of looks like part of a straight line
* Another way to think about this is as a limit of secant lines
* By secant line, I mean, I'm going to pick two points on the graph and I'm going to put a line, the secant line, through those two points
* But, I can do better
* By taking this point and moving it closer to a, this red line is going to be a better approximation to the orange curve near the point a
* So, instead of putting it through those two points, let me put the secant line through, say, these two points, this point at a and this point that's nearby
* And now, the line segment through those two points is a much better approximation of the orange curve
* And I can do better and better by taking a limit, by putting those two points closer and closer together, I can get my secant line to be a better and better approximation to the orange curve near the point a
* What we're really calculating here is a limit
* So here, I've got an input a and an input a+h, and here are the corresponding points on the graph of the function
* I'm going to put a secant line through those points
* What I want to know is what's the slope of that secant line because I'm going to take the limit as this a+h point is moved closer to a as h goes to zero in other words, and that'll make this secant line move closer and closer to the tangent line, to the curve
* Okay, so what's the slope of the secant line
* Well, the rise is f(a)+h-f(a)
* The run is h
* So, the slope of that secant line is this, f(a+h)-f(a)/h
* If I take the limit as h goes to 0, I get this: the limit as h goes to 0 of this slope
* We've seen this, this is the derivative of the function at the point a
* Let's find the equation of the tangent line in a concrete example
* Here's a graph of y=x^2
* Let's figure out the equation of the tangent line to that graph at the point (3,9)
* So to do that, we're going to use the derivative and I know that the derivative of x^2 is 2x
* So, the slope of the tangent line at the point 3 is 2*3=6, and that's the slope of the tangent line
* I also know a point that the tangent line passes through
* It should be passing through the point (3,9), right
* The point (3,9) is on the tangent line
* So, if I know the slope of the tangent line and I know a point on the line, I can write down an equation for the line using point slope form
* So, y minus the y coordinate on the line is the slope time x minus the x coordinate on the line
* So, this is an equation for this red tangent line
* [MUSIC]


--- SKIP ---: 03_why-is-the-absolute-value-function-not-differentiable.en.srt


--- SKIP ---: 03_why-is-the-absolute-value-function-not-differentiable.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_why-is-the-absolute-value-function-not-differentiable.en_SENTbySENT.txt
* [MUSIC]
* When I say a function is differentiable, what I really mean is that when I zoom in, the function looks like a straight line
* This is the graph of the absolute value function
* Let's zoom in on the origin
* No matter how much I zoom in, this graph doesn't look like a straight line
* Consequently, the absolute value function is not differentiable at 0
* We can also see this from the limit definition of derivative
* So we just going to name the absolute value function f, for the time being
* What I am trying to calculate is the derivative of f at 0
* I want to know is this function differentiable at 0
* By the definition the derivative is the limit
* As h approaches 0, of the function, at |0 + h| - |0| / h
* Now I can simplify that a bit
* The absolute value of 0 + h, is just the absolute value of h, and the absolute value of 0, so I don't even need to subtract 0
* And I"m dividing by h
* Now what's the limit as it approaches 0 of absolute value h/h
* That limit doesn't exist and consequently this function's not differential at zero
* If you wonder why that limit doesn't exist, well think back to our 2 sided 1 sided limit discussion from before
* What's the limit as h approaches 0 from the right-hand side of |h| / h
* It's 1
* Well what's the limit as h approaches 0 from the left-hand side of |h| / h
* It's -1
* And 1 is not equal to -1
* Because the one-sided limits disagree The two sided limit doesn't exist
* And this limit calculating the derivative means that this function is not differentiable at 0
* Of course, that raises the question why should you care about differentiable functions at all
* Here's some terrible looking function
* But it's differentiable
* So if I zoom in on some point, the thing looks like a straight line
* Calculus is all about replacing the curved objects that we can't understand with straight lines, which we have some hope of understanding
* [MUSIC]


--- SKIP ---: 04_how-does-wiggling-x-affect-f-x.en.srt


--- SKIP ---: 04_how-does-wiggling-x-affect-f-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_how-does-wiggling-x-affect-f-x.en_SENTbySENT.txt
* [MUSIC] Remember, f prime of x is encoding how wiggling x affects f of x
* We can see this by thinking about slopes of tangent lines as well
* Here, I've drawn in orange the graph of some random function y=f(x)
* And this point, a f(a) I've drawn in red the tangent line to the graph
* I want to know how is the output f affected when input moves from a to a+h
* I want to know what happens when I wiggle the input over by adding h
* Let me zoom in on this picture a little bit
* Here, I've got this tangent line, and the slope of that tangent line is the derivative of the function at the point a
* That means that this triangle can be understood, right
* This slope being f'(a), this base being h means this height is h*f'(a)
* In order to get this slope as f'(a), rise over run better be equal to f'(a), this divided by this is f'(a)
* this is giving me some information about how wiggling the input will affect the output
* If I move from a to a+h, well, on the tangent line m' moving up to this point which isn't so far off of the real value of the function up here
* Now, if I made h really, really small, I'd be doing an even better job of staying close to the graph of the function when I follow the tangent line
* Instead of starting with the function and trying to figure out the derivative, we can imagine that we know a little bit of information about the derivative and try to figure out something about the function
* Let's make up a concrete example
* Suppose that I've got some function f, and all I know is that its derivative is 3x, and its value at 2, is 4
* Just knowing this information without a rule for the function at this point, can I say anything about the function's value at, say 2.01
* Yes, I can
* Right
* f(2.01), well that's f(2) plus how much the output changes when I go from 2 to 2.01
* Well, the output change is approximately something that I can compute from the derivative, right
* The derivative is infinitesimally the ratio between output change and input change
* So if I multiply by how much I change the input by the ratio of input change to output change, this should be approximately the true output change
* Now, in this case, I know what these numbers are
* 0.01 times the derivative of f(2) is 6
* Which means that this is about 4+0.06 which is 4.06
* And that's about what this function at 2.01 is equal to
* One more cat moves into the neighborhood
* What happens to the mouse population
* Right
* A small change to one thing will affect something else
* That's what the derivative is encoding
* [MUSIC]


--- SKIP ---: 01_why-is-sqrt-9999-so-close-to-99-995.en.srt


--- SKIP ---: 01_why-is-sqrt-9999-so-close-to-99-995.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-sqrt-9999-so-close-to-99-995.en_SENTbySENT.txt
* [MUSIC] Sometime in the future, we're going to see the following derivative rule
* But, I want to mention it now just so we can see an example of how derivatives play out in practice
* The derivative of the Р Р†РІвЂљВ¬РЎв„ўx is 1/2Р Р†РІвЂљВ¬РЎв„ўx
* You might already believe this if you believe the power rule, right
* The derivative of x^n is nx^n-1
* So, if n is 1/2, then I've got that the derivative of x^n, now 1/2, is n, 1/2, times x^n-1
* And conveniently, 1/2-1=-1/2
* This is really the same as this, it's just written here with the square root symbol instead of with the exponents
* We can use this derivative rule to help explain certain numerological coincidences
* Let's take a look
* Look, the Р Р†РІвЂљВ¬РЎв„ў9999 is 99.9949998, okay, so it keeps on going forever
* It's irrational
* But, this is bizarrely close to 99.99 instead of 499 just saying it's close to 99.995
* Is this just a coincidence
* This isn't a coincidence
* Look
* The square Р Р†РІвЂљВ¬РЎв„ў10000 is 100 because 100^2 is 10,000
* What I'm really doing here is wiggling the input
* I'm going from 10,000 to 9,999
* In other words, I'm trying to calculate the Р Р†РІвЂљВ¬РЎв„ў10000-1, wiggling the input down a bit
* What does the derivative calculate
* Well, the derivative calculates the ratio between output change to input change
* So, the Р Р†РІвЂљВ¬РЎв„ў10000 wiggled down a little bit is about the Р Р†РІвЂљВ¬РЎв„ў10000 minus how much I change the input by times the ratio of how much I expect the output change compared to the input change
* Now, we can try to calculate the derivative at 10,000
* What's the derivative at 10,000
* Well, it's 1/2Р Р†РІвЂљВ¬РЎв„ў10000
* The Р Р†РІвЂљВ¬РЎв„ў10000 is 100, so it's 1/2*100
* 1/2*100 is 1/200, which is 0.005
* Look, the Р Р†РІвЂљВ¬РЎв„ў9999 is so close to 99.995 because the Р Р†РІвЂљВ¬РЎв„ў10000 is 100
* And, when I shift the input down by one, this derivative calculation is suggesting that the output should be shifted down by about 0.005, and indeed it is
* This is a great example of calculus
* Yes, you could have asked your calculator to compute the Р Р†РІвЂљВ¬РЎв„ў9999, but you couldn't have asked your calculator to tell you why
* Why is that answer so mysteriously close to 99.995
* In short, calculus is more than calculating
* It's not about answers, it's about reasons
* It's about explanations about the stories that human beings can tell to each other about why that number and not another
* But, that's not say that the numbers aren't fun to play with themselves, and we can use this same trick to do other amazing feats like Р вЂ™Р’В·Р вЂ™Р’В , we can try to estimate the Р Р†РІвЂљВ¬РЎв„ў82
* I know the Р Р†РІвЂљВ¬РЎв„ў81 is 9
* I'm trying to say something about the Р Р†РІвЂљВ¬РЎв„ў82
* I'm trying to wiggle the input up a little bit
* Well, derivatives have something to say about that
* The Р Р†РІвЂљВ¬РЎв„ў81+1, the Р Р†РІвЂљВ¬РЎв„ў82, would be about the Р Р†РІвЂљВ¬РЎв„ў81, which is 9, plus how much I expect the output to change
* I wiggled the input, I expect the output to change by some amount
* Well, the derivative is measuring how much I expect the output to change by
* So, I'm going to take the derivative of the function at 81, at the square root function at 81, I'm going to multiply by how much I'm wiggling the input by
* This will be how much I expect the output to change when I change the input
* Now, in this specific case, what's the derivative at 81
* Well, that's 1/2Р Р†РІвЂљВ¬РЎв„ў81, which is 1/2*9
* The Р Р†РІвЂљВ¬РЎв„ў81 is 9, which is 1/18
* So, I would expect the Р Р†РІвЂљВ¬РЎв„ў82 to be about 9+1/18 because I expect wiggling the input up to wiggle the output up by about 1/18
* And this is pretty good
* There's actually two different ways to tell if this isn't such a bad guess
* Here's here's one way to tell
* What's what's 1/18
* Well, it's 0.05 repeating
* And, what's the actual value of the Р Р†РІвЂљВ¬РЎв„ў82
* It's 9.055
* Look, it's pretty close to 9 plus this
* That's pretty good
* Another way to see that this isn't such a bad guess is just to take 9+1/18, and square it
* When I square 9+1/18, I get 9^2+2*9/18+1/1/8^2
* 2*1/2=1
* This is 81+1=82, and 1/18^2 is the very small number 1/324
* So, either way you look at it, we're doing pretty good to guess the Р Р†РІвЂљВ¬РЎв„ў82 is about this, and we're doing it with derivatives
* Again, it's derivatives for the win
* By relating the input change to the output change, we're able to estimate the values of functions that would be very hard to access directly
* [MUSIC]


--- SKIP ---: 02_what-information-is-recorded-in-the-sign-of-the-derivative.en.srt


--- SKIP ---: 02_what-information-is-recorded-in-the-sign-of-the-derivative.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-information-is-recorded-in-the-sign-of-the-derivative.en_SENTbySENT.txt
* [MUSIC] In the future, we're going to have a lot of very precise statements about the derivative
* But before we get there, I want us to have some intuition as to what's going on
* Let's take a look at just the S, I, G, N, the sign of the derivative
* The thick green line of the plot is some random function, and the thin red line is its derivative
* And note that when its derivative is positive, the function's increasing, and when the derivative is negative, the function's decreasing
* We can try to explain what we're seeing here formally, where that calculation on paper
* So let's suppose that the derivative is positive over a whole range of values
* And, we also know something about how the derivative is related to the functions values
* The function's output or x+h is close to the functions output of x plus how much the derivative tells us the output should change by, which is how the input changed by times the ratio change of output change to input change
* Alright
* Now let's suppose that x+h is a bit bigger than than x
* Well, what that's really saying is that h is positive, right
* I shift the input to the right a little bit
* Well then, h*f'(x) is going to be positive because a positive number times a positive number is positive
* And that means that f(x)+h*f'(x) will be bigger than f(x)
* We're just add something to both sides of this inequality
* Now, f(x)+h*f'(x), that's about f(x)+h
* So, although this argument isn't entirely precise yet, what it looks like it's saying is that the function's output at x+h is bigger than the function's output at x
* So, if you plug in bigger inputs, you get bigger outputs
* What about when the derivative is negative
* We can play the same kind of game when the derivative's negative
* Here we go
* So again, x+h is just a bit bigger than x
* And in that case, h is positive
* But I've got a positive number times a negative number, h times the derivative of f is negative
* Now, if I add f(x) to both sides, got that f(x)+h*f'(x) is less than f(x)
* But this is approximately the new output value of the function at x+h
* So, I've got that the function's output at x+h is a little bit less than its output at f
* So, a bigger input is giving rise to a smaller output
* Even a little bit of information, whether or not the derivative is positive or negative, says something about the function
* And you can see the same thing in your own life
* For instance, suppose that the derivative of your happiness with respect to coffee is positive
* What does that really mean
* Well, that means that you should be drinking more coffee because an increase in coffee will lead to greater happiness
* Of course, this is only true up to a point
* After you've had a whole bunch of coffee, you might find that the derivative of your happiness, with respect to coffee, is zero
* You should stop drinking coffee
* Now, this makes sense because the derivative depends upon x, right
* It depends upon how much coffee you've had
* Not very much coffee, the derivative might be positive
* But after a certain point, you might find that the derivative, vanishes
* This seems like a silly example
* coffee and happiness
* But, so many things in our world are changing
* And those changing things affect other things
* The question is that when one of those things changes, does the other thing move in the same direction or do they move in opposite directions
* And the sign, the S, I, G, N of the derivative records exactly that information
* [MUSIC]


--- SKIP ---: 01_why-is-a-differentiable-function-necessarily-continuous.en.srt


--- SKIP ---: 01_why-is-a-differentiable-function-necessarily-continuous.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-a-differentiable-function-necessarily-continuous.en_SENTbySENT.txt
* [MUSIC]
* Remember, continuity is all how nearby inputs are sent to nearby outputs
* Differentiability is how wiggling the input affects the output
* In light of this, they seemed related, right
* Something like the following seems plausible
* Here's the theorem
* Theorem
* If f is differentiable at a, then f is continuous at a
* In other words, a differentiable function is continuous
* Morely, we know that a differentiable function is continuous
* But were advanced enough at the is point in the course to give a precise argument using limit
* Here we go
* Let's suppose that f prime of a exists
* In other words, that means a certain limit exists
* What limit
* Well, the limit of f(x)-f(x)/x-a as x approaches a
* This limit of a difference quotients computes the derivative for the function at a
* So, to say that the derivative exists is to say that this limit exists
* Now, here comes the trick
* What I'd like to compute is the limit of f(x)-f(a) as x approaches a, but I don't know how to do that directly
* But, I can rewrite this thing I'm taking the limit of as a product
* Watch
* Instead of taking this limit, I'm going to take the limit as x approaches a of x-a times this difference quotient, times f(x)-f(a)/x-a
* Now, as long as x isn't equal to a, this product is equal to this difference
* Now, why does that help
* Well, this is a limit of a product
* So, by one of the limit laws, the limit of a product's the product of the limits as long as the limits exist
* And in this case, they do
* So, this limit of this product is, the product of the limits
* It's the limit of x-a as x approaches a, times the limit of f(x)-f(a)/x-a
* I'm only allowed to use this limit law because I know both of these limits exist
* Now, this first limit, the limit of x-a as x approaches a, that's 0
* And this second limit, well, this limit exists precisely because I'm assuming differentiability, the function's are differentiable
* So, this limit is calculating the derivative at a, and zero times any number is equal to zero
* The upshot here is that we've shown that the limit of f(x)-f(a)=0 as x approaches a
* Why would you care about this
* How does that help us
* We know that the limit of f(x)-f(a) as x approaches a is equal to 0
* What that means is that the limit of f(x) as x approaches a is equal to f(a), but this is just the definition of continuity
* So now we know that f is continuous at the point a
* That's where we ended up
* Remember, what we started with
* We started by assuming that f was differentiable at a
* And after doing all this work, we ended up concluding that f is continuous at the point a
* So, differentiability implies continuity
* One way to keep track of arguments like this is to think about clouds and rain
* Theorem
* If it is rainy, then it is cloudy
* A shorter way of saying this, rainy implies cloudy
* Now the question is, does it go the other way
* If it's cloudy, is it necessarily rainy
* Can you think of a cloudy day with no rain
* Yes, today
* Let's look out the window
* It is very cloudy but there's no rain
* Beyond clouds and rain, let's bring this back to the mathematics
* A differentiable function is continuous, can you think of a continuous function which isn't differentiable
* You might want to hit pause right now, if you don't want the puzzle given away
* Here's an example of a function which is continuous but not differential, the function f(x)=|x|
* We recently saw that the absolute value function wasn't differentable at zero
* But how do we know that the absolute value function is continuous everywhere
* We know that the absolute value function is continuous
* I mean, look at it
* It's all one piece
* But, we can do better
* We can use our limit knowledge to make a more precise argument
* We know that f(x)=|x| is continuous for positive inputs
* It's continuous on the open interval from zero to infinity because the function x is continuous there
* And this function, the absolute value function, agrees with the function x if I plug in positive numbers
* Likewise, I know that the function is continuous on negative inputs because the function -x is continuous there, and the function -x agrees with this function on this interval
* The only sticking point is to check that the function's continuous at zero
* And if I know it's continuous for positive inputs, negative inputs, and it's continuous at zero, then I know that it's continuous for all inputs
* Now, how do I know that the absolute value function is continuous at zero
* Well, that's another limit argument, right
* The limit of the absolute value function when I push from the right-hand side is the same as the limit of the absolute value function when I push from the left-hand side, they're both zero
* And because these two one-sided limits exist and agree, then I know the two-sided limit of the absolute value function is equal to zero, which is also the function's value at zero
* And therefore, the abslute value function is continuous
* In the end, there's some relationship between differentiability and continuity
* Differentiable functions are continuous
* Mathematics isn't just a sequence of unrelated concepts
* [MUSIC] It's a single unified whole
* All of these ideas are connected at the deepest possible levels
* [MUSIC]


--- SKIP ---: 02_what-is-the-derivative-of-a-constant-multiple-of-f-x.en.srt


--- SKIP ---: 02_what-is-the-derivative-of-a-constant-multiple-of-f-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-derivative-of-a-constant-multiple-of-f-x.en_SENTbySENT.txt
* [MUSIC] Here is the question that I want to address right now
* What's the derivative of some constant multiple of some function
* Now, in this case the constant multiple is 2 but of course that 2 could be replaced by any sixth number
* If you don't like the D D X notation, another way to ask this question is this
* If you've got some new function G and it's the constant multiple times F, again in this case I'm using 2 as the constant, the question is, what's the derivative of G in terms of the derivative of F
* To gain some intuition, let's pick a specific example, and look at a graph
* So here's the graph, of, just some random function
* Let's suppose that I stretch this graph, in the y direction
* So now I stretch the y axis, and that corresponds to multiplying the function by a constant value
* In this case, to, how do the tangent lines change when I do this stretching
* So if I double the Y axis, the function changes by twice as much for the same input change
* So if I double the Y axis, the slope of the tangent line also doubles and that makes sense numerically
* Here's what I know
* I know that g of x is twice f of x
* G is this constant multiple of f
* I also know something about the derivative of f
* The derivative encodes how input changes become output changes, or, a bit more precisely, the derivative in the limit is the ratio of output change to input change
* So if I multiply the ratio of output change to input change by an actual input change, this at least approximately is telling me how much the output should change when I move from x to x plus h
* Right, f's new output at the input x plus h
* Is it's old output plus how much I expect the output to change
* This is a really nice way to summarize what the derivative's saying
* I know another thing
* I know that g of x plus h is twice f of x plus h just because g is twice f for any input value x, so in particular that's true when the input is x plus h
* These two statements are connected
* Alright, G of X plus H is twice F of X plus H and F of X plus H is approximately this
* So I can combine those two statements together in this statement
* G of X plus H is about twice f(x)+h is approximate value, right
* 2f(x)+2h*f-prime(x), which I've written as h*2f-prime(x)
* I made this a little bit nicer
* Since 2f(x) is g(x), I can replace this 2*f(x), with g(x)
* And this is really looking good
* This is telling me that g's output at x+h is about, g's output at x, plus how much I change the input by, times some quantity
* Now, considering that the actual derivative of g would tell me some information like this
* That g's output is about, g's old output plus how much I change the input by times the derivative
* You're beginning to see what's going on here, right
* Look, I've got the derivative of g here
* And I've got twice the derivative of f here
* And if you sort of believe that these statements are connected in this way, you might then believe that the derivative of g is twice the derivative of f
* The derivative of g here is twice the derivative of f
* We can formalize this as a rule
* Here's the constant multiple rule
* So let k be constant and suppose that f is just some function which is differentiable at the point a
* G is that constant multiple of f, so g of x is k*f(x)
* Given this setup, what the constant multiple rule is concluding, is that the derivatives are related in the same way
* The derivative at the point A is K times the derivative of F at the point A
* Now if you don't like this prime notation you could also write it using the D D X notation
* So here's how I write the constant multiple law using the D D X notation
* The derivative of k times a function is k times the derivative of that function
* I encourage you to keep practicing
* With time, you'll be able to calculate the derivative of just a ton of different functions
* [MUSIC]


--- SKIP ---: 01_why-is-the-derivative-of-x-2-equal-to-2x.en.srt


--- SKIP ---: 01_why-is-the-derivative-of-x-2-equal-to-2x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-the-derivative-of-x-2-equal-to-2x.en_SENTbySENT.txt
* [MUSIC] We're going to calculate the derivative of x squared with respect to x
* maybe a little bit more prosaically, I want to know how wiggling x affect x squared
* There's a ton of different ways to approach this
* Let's start by looking at this numerically
* So let's start off by just noting that 2 sqyared is 4, and I'm going to wiggle the 2 and see how the 4 wiggles
* Instead of plugging in 2, let's plug in 2.01
* 2.01 squared is 4.0401
* And let's just keep on going with some more examples
* 2.02 squared is 4.0804
* 2.003 squared, say, is 4.012009
* Alright, so those are a few examples
* I've wiggled the inputs, and I've seen how the outputs are affected
* And of course the, all the outputs are close to 4, alright
* But they're not exactly 4
* When I wiggled the input from 2 to 2.01, the output changed by about .04, and a little bit more, but that'ts a lot smaller
* When I wiggled the input from 2 to 2.02, the output changed by about .08, not exactly .08, but pretty close to .08
* And when I wiggled from 2 to 2.003, the output changed by about
* About .012 and a little bit more, but, you know, it's close
* Now look at the relationship between the input change and the output change
* The input change by .01, the output change by 4 times as much, about
* The input change by .02, the output change by 4 times as much
* The input change by .003, the output change by about 4 times as much
* I'm going to summarize that
* The output change is the input change magnified by 4 times
* Right
* The input change by some factor
* And the output change by about 4 times that amount
* Let's see this at a different input point
* Instead of plugging in 2, let's plug in 3 and see what happens
* So 3^2 is 9, but what's, say 3.1^2
* That's 9.61
* Or what's 3.01^2
* Well, that's 9.0601
* maybe wiggle down a little bit
* What's 2.99 squared
* That's close to 3 but wiggling down by .01
* That's 8.9401
* Let's see how much roughly the output changed by
* When I went from 3 to 3.1 the output changed by Out point 6
* When I went from 3 to 3.01, the output changed by about .06, and when I went from 3 down to 2.99, the output when down by about .06 again
* Little bit less
* Now what's the relationship between the input change and the output change
* Well here the input changed by .1, the output change by .6, about 6 times as much
* Again, the input change by .01, the output changed by About six times as much
* And when the input went down by .01 the output went down by about six times as much
* So again, we're seeing some sort of magnification of the output change to the input change, but now it's magnified not by four times But by six times
* So the important lesson here is that the extent to which wiggling the input affects the output depends on where you're wiggling
* If you're wiggling around 2, the output is being changed by about four times as much
* If you're wiggling the input around 3, the output is being change by about six times as much
* Instead of doing just a few numerical examples, let's generalize this by doing some algebra
* So, I'm starting with x^2 and I'm going to wiggle x and see how x^2 is effected
* So, instead of plugging in x, I'll plug in x + something, let's call the change in x, h
* Now I want to know, how is this related to x ^ 2
* Well I can expand out (x+h)^2, that's x^2+2xh+h^2
* So when I wiggle the input from x to x+h, how is the output being affected
* Well the output, is the old output value plus this change in output value 2xh+h^2, h^2 is pretty small
* When h is small, h^2 is really small so I'm going to throw that away for now
* And just summarize this by saying that the output change is 2xh and the input change
* Is h
* Now the derivative is supposed to measure the relationship between the output change and the input change
* So I'm going to take the ratio of the output change to the input change, and 2xh/h=2x, as long as h isn't 0
* This is the ratio of output change to input change and that makes sense, right
* Think back to what just happened here a minute ago, when we were plugging in some nearby values and seeing how the outputs were affected
* When I was wiggling the input around 2, the output was changing by about twice 2
* When I was wiggling the input around 3, the output was changing by about twice 3, alright
* 2x is the ratio of output change to input change
* If the algebra's not really speaking to you, we can also do this geometrically, like drawing a picture
* Here's a square of side length x
* The area of this square is not, coincidentally, x^2
* Now I want to now the derivative of x^2 with respect to x
* I want to know how changing x would affect the area of this square
* Now to see this here is another square
* This is a slightly larger square of side length x+h
* h is a small but positive number
* So how does the area of this new square compare to the area of this old square
* Let me put the old square on top of the new square, and you can see that when I change the input from x to x+h, I gained a bit of extra area
* The derivative is recording the ratio of output change to input change
* So, I want to know what's the ratio of this new area as compared to just the change in the input H
* So, let me pull off the extra area
* There is extra area, is this L shaped region
* How big is this L shaped region
* Well, this short side here, has side length h
* This side length here, is also h
* This is the extra length that I added when I went from x to x+h
* This inside has length x, and this inside edge has length x
* Now I want to know the area of this region
* To see that, I'm going to get out my scissors and cut this region up into 3 pieces
* Now here's one of those pieces
* And, here's another one of those pieces
* And, here's the third piece
* So these are the 2 long thin rectangles, and they've both got height h, and length x
* I'm also left with this little tiny corner piece
* And that little tiny corner piece has side length h, and the other side is also length h
* It's a little tiny square
* Well the limit, this little tiny corner piece, is infinitesimal
* I'm going to throw this piece away and most of the area is left in these 2 long, thin rectangles
* If I rearrange these long, thin rectangles a bit, can put them end to end
* They've both got height h
* So I can put them next to each other like this
* And their base is both length x
* So how much area is in this long thin rectangle
* Well, it's height h, it's width is 2x
* So the area is 2x * h
* Now this is the additional area, excepting for that little tiny square, which we gained when I changed the size of the square from x to x + h
* So the change in output is about 2 * x * h
* The change in input was h, so the ratio of output change to input change Is 2 * x
* Maybe what we're doing here seems a little bit wishy washy, not really precise enough
* But we can also calculate the derivative of x ^ 2 with respect to x, by just going back to the definition of derivative in terms of limits
* Carefully, f of x is x^2
* And the derivative of f is by definition the limit as h approaches 0
* F of x plus h minus f of x, the change in output divided by h, the change in input
* In this case f of x plus h is just x plus h squared and f of x is just x squared
* I'm dividing by h
* I can expand this out
* This is the limit as h approaches 0 of ((x+h)^2-x^2)/h
* Now I've got an x^2-x^2, so I can cancel those, and I'm just left with the limit, as h approaches 0, of (2xh+h^2)/h
* More good news, in the limit I'm never going to be plugging h=0, so I can replace this With an equivalent function that agrees with it when h is close to but not equal to 0
* In other words, maybe a little bit more simply, I'm canceling an h from the numerator to the denominator
* So, 2xh over h is just 2x and h^x over h is just an h
* Now what's the limit of this sum
* Well that's the sum of the limits
* It's the limit of 2x as h approaches 0 + the limit of h as h approaches 0
* Now as far as wiggling h is concerned, 2x is a constant, so the limit of 2x as h approaches 0 is just 2x
* And what's the limit of h as h approaches 0
* Well, what's h getting close to when h is close to 0
* That's just 0
* So, this limit is equal to 2x and that's the derivative of x^2
* What that limit is really calculating is the slope of a tangent line at the point x and we can see that it's working
* This is the graph of y=x^2
* At -4 the slope of the tangent line is -8 At 2, the slope of the tangent line is 4, and, at 6, the slope of the tangent line is 12
* There's a ton of different perspectives here
* We've been thinking about the derivative of x ^ 2 with respect to x, numerically, algebriaically, geometrically, going back to the definition of derivative in terms of limits, looking at it in terms of slopes of tangent lines
* What makes derivatives so much fun is that there just so many different perspectives on this single topic, no matter how you slice it
* We've shown that the derivative of x squared with respect to x is 2 times x
* Maybe you like algebra, maybe you like geometry, maybe you just like to play with numbers
* But now matter what your interests are, derivatives have something to offer you
* [MUSIC]


--- SKIP ---: 02_what-is-the-derivative-of-x-n.en.srt


--- SKIP ---: 02_what-is-the-derivative-of-x-n.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-derivative-of-x-n.en_SENTbySENT.txt
* [MUSIC] Here is the so-called power rule for differentiating x^n
* Nevertheless, here we go
* When n=1, the derivative of just x^1, which is just x, is equal to 1
* This should make sense because what's the derivative measuring
* The derivative is measuring output change compared to input change
* And, in this case, the function is just the function that sends x to x
* The input and the output are exactly the same
* So, the input and the output change is exactly the same, their ratio is just 1
* And consequently, the derivative of x, the derivative of the identity function is 1
* For the time being, we're just going to think about this when n is a positive whole number
* But even there, it's pretty tricky
* Admittedly, when n=1, you're probably going to be pretty unimpressed
* The derivative of x^n is n*x^n-1
* What's n
* n can be any real number except for zero
* You should think about what you don't want to plug in zero for n
* When n=2, that means we're differentiating x^2, which we studied a little bit ago
* Now, here is the power rule
* If I plug in 2 for n, I've got the derivative of x^2=2*x^2-1
* Or a bit more nicely written, the derivative of x^2=2x
* I really remember, we really did study this in quite some detail, you know, algebraically, numerically, geometrically
* When n=3, we can still study the derivative of x^3 in a geometric way
* So, here's the power rule
* You plug in n=3, and you get the derivative of x^3=3*x^3-1, 3*x^2
* We can see this geometrically
* We start with a cube of side length x
* And we're going to glue on three green slabs of side length x, x, h
* Now, in order to actually thicken up the cube, we've got to glue on a few more pieces, these blue pieces and this red corner piece
* But once we've done that, now we've built a cube of side length x+h
* How is the volume changed
* Well, most of the change in volume happened in these three green slabs, and those three green slabs have volume 3x^2h
* The change in the side length of cube is h
* Geometric argument is showing us that the derivative of x^3 is 3*x^2
* When n=4, we're trying to differentiate x^4
* But that would involve not a cube, but a hypercube
* [SOUND] It seems a bit ridiculous to try to gain intuition about the derivative of x^3 by doing something as esoteric as studying 4-dimensional geometry
* So instead, let's differentiate x^3 directly by going back to the definition of derivative
* So, let's proceed directly
* I want to compute the limit as h approaches 0 of x+h^4-x^4/h
* What is this computing
* This is the limit of the difference quotient
* This is the derivative of x^4 at the point x
* Now, to proceed, I'm going to make this a little bit smaller
* It's a bit too big to work with
* This is the limit I'm trying to calculate
* The first step is to expand out x+h^4
* And if I expand x+h^4, this is what I get
* (h^4+4h^3x+6h^2x^2+4hx^3+x^4)
* And now, you'll notice something very exciting
* I've got an x^4-x^4 so I can cancel those two terms and I'll be left with a limit of everything else
* h^4+4h^3x+6h^2x^2+4hx^3/h
* But more good news, every single term up in the numerator here, has an h in it
* So, I can cancel those h's without affecting the limit
* And this limit is the same as the limit of h^3+4h^2x+6hx^2+4x^3
* Why
* Well, look
* h^4/h gives me the h^3
* 4h^3x/h gives me the 4h^x/h gives me the 4h^2x, and so forth
* Now, we're practically there
* I want to evaluate this limit
* Most of these terms here have got an h in it, so when I take the limit, these terms are all 0
* The only term that survives is this one which as far as h is concerned is a constant
* It's the limit of 4x^3 as h approaches 0
* That's just 4x^3
* And because this whole mess is calculating the derivative of x^4, what I've really done here is shown, from the definition of derivative, that the derivative of x^4 is 4x^3
* This limit calculation is perhaps complicated enough to give us a glimpse into the whole story
* What's the derivative of x^n
* Trying to show the derivative of x^n is nx^n-1
* And to do that, we go back to the definition of derivative and try to calculate this limit
* The limit is h goes to 0 of (x+h^n)-x^n/h
* Just like the case when n was 4, the first step is to expand this out
* But here, it's a bit trickier, right
* To expand out x+h^n, I don't know exactly what n is
* n's just some positive whole number so I can't write down exactly what it is
* But I can write down enough of it to get a sense of what's going on in the story
* h^n+nh^n-1x+, and hidden in this dot, dot, dot is all kinds of other terms that have h's in them, plus nhx^n-1+x^n-x^n/h
* Just like before, I've got an x^n and a -x^n, so I can cancel those
* And now, I'm left with just these terms, still a bunch of terms with h's in them
* And note that every single term in the numerator here has an h, so I can then do the division just like before
* The h^n/h becomes h^n-1, and h^n-1x becomes nh^n-2x
* Everything in the dot, dot, dot here has at least an h^2 in it
* So, when I divide it by h, everything that's left over still has at least one h in it
* This last term nhx^n-1/h becomes nx^n-1 after I divide by h
* And now, look
* This is a limit
* As h approaches 0, this term dies, this term dies, all of these terms with h's in them dies
* The only thing that's left is this term here, nx^n-1, and that means that this entire limit is equal to nx^n-1
* This limit is calculated in the derivative of x^n
* So, what we've really managed to do is show that the derivative of x^n is nx^n-1
* [MUSIC]


--- SKIP ---: 03_what-is-the-derivative-of-x-3-x-2.en.srt


--- SKIP ---: 03_what-is-the-derivative-of-x-3-x-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-derivative-of-x-3-x-2.en_SENTbySENT.txt
* [MUSIC]
* You've heard of the, ask not what your country can do for you, but what you can do for your country rule
* These chiastic rules for limits
* The limit's the sum of the limits
* Same thing is true for derivatives
* Let's go to the board
* Here's the rule for derivatives
* The derivative of f + g
* Is the derivative of f + the derivative of g
* In short, the derivative of the sum is the sum of the derivatives
* Why does this make sense
* Well, think back to what the derivative is measuring
* The derivative is measuring how changing the input affects the output
* In this case, I want to know how changing x affects the sum of f of x and g of x
* Well, the sum is affected by the sum of the effects
* The sum of the derivative of f and the derivative of g
* Let' see this in a specific case
* Here's a specific case
* The function f(x) = x^3 + x^2
* Let's differentiate this
* I'm going to calculate d / dx (x^3+3=x^2)
* Now this is a derivative of a sum, which is the sum of derivatives
* Now we have to figure out what's the derivative of x ^ 3 and what's the derivative of x^2
* That's the power law
* derivative of x^3 is 3x^2, and the derivative of x^2 is 2x
* And now there's no more d/dx's
* We've calculated the derivative
* The derivative of x^3+x^2+2x
* Once we know this, we can figure out where the derivative is positive and where it's negative
* So, the derivative was 3x^3+2x and I want to know where that's positive and negative, which values of x make that bigger than 0, which values of x make that less than 0
* one approach to thinking about this is to factor through the x^2+2x
* I can write that as x(3x+2)
* And once I factor it like this I can figure out the SIGN of this by figuring out the SIGN of these two terms separately
* visualize this as a direct whole number line
* So x, here's a number line
* X is positive when it is bigger than 0 and negative when X is less than 0
* That's not too complicated
* Well look 3x+2
* Well, 3x+2, I draw a number line for that
* The exciting point is -2/3
* When x is less than -2/3, 3x+2 is negative
* And when x is bigger than -2/3's, then 3x+2
* Is positive
* Now, I really don't care about x and 3x+2 separately
* I want to put them together right
* I want to know when their product is positive or negative
* So, I write down the product x * 3x+2 make a new number line here
* I'll record both of these points -2/3 and 0 then I can think about what happens
* When x is less than -2/3 then x is negative and 3x+2 is negative
* So the product is a negative * a negative, which is positive
* When x is between -2/3 and 0, then x is negative but 3x+2 is positive and a negative times a positive number is negative
* And finally, when x is bigger than 0, well then x is positive and also 3x+2 is positive
* So the Is positive
* So, here on this number line, I've recorded the information about when 3x^2 + 2x is positive or negative
* Now we can use this information to say something about the graph
* Here's the graph of the function x^3+x^2
* Goes up, down and up, And that's exactly what you'd expect from the derivative, right
* We calculated before that if you're standing to the left of - 2/3's, then the derivative was positive, and indeed the functions going up
* Up
* Now once you get to -2/3, the derivative is 0 but then over here, between -2/3 and 0 the derivative is negative and indeed the graph is moving down until you get to 0 when the derivative of this function is positive again and the graph is going up
* Look, the sign of the derivative Positive, negative, positive is reflected in the direction that this graph is moving
* Increasing, decreasing, increasing
* Incredible
* By being able to differentiate x^2+x^3, we're able to gain real insight into the graph of the function
* We're not just plotting a whole bunch of points and hoping that we can fill it in with a straight line
* By looking at the derivative, we know that the function is increasing and decreasing
* We're able to say something, for sure
* [MUSIC]


--- SKIP ---: 04_why-is-the-derivative-of-a-sum-the-sum-of-derivatives.en.srt


--- SKIP ---: 04_why-is-the-derivative-of-a-sum-the-sum-of-derivatives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_why-is-the-derivative-of-a-sum-the-sum-of-derivatives.en_SENTbySENT.txt
* [MUSIC]
* Looks like I've got two functions f(x) and g(x), and they're both differentiable at a
* Then I can define a new function
* h(x) which is the sum of f and g
* Alright it's a new function, to compute h(x) I just plug x into f and I plug x into g and I add together whatever f and g give me
* Alright so that's a new function that I build from f and g
* Now here's the conclusion, right
* Then each prime of a is just the sum of the derivative of f at a and the derivative of g at a
* And to prove something like this, this is a really a theorem, right
* This is a theorem that tells me how to compute
* The derivative of the sum of functions
* And how do I prove something like this
* Why I just go back to the definition of derivative
* Alright
* The derivative of this function h at the point a is the limit as x goes to a of, h(x)-h(a)/x-a
* Now I know what h(x) is
* h(x) is f(x) + g(x)
* So I can plug that in
* Alright, so this is the limit as x goes to a of f(x)+g(x)
* And I also know what h(a) is, right
* I just plug in a for x
* And I get that h(a) is f(a)+g(a)
* And this is all divided by the same denominator, x-a
* Great
* I want to calculate that limit, right?
* Well, I can rearrange the numerator, so the numerator is the same as what
* This is f(x) + g(x) - f(a)
* Minus g of a, but rearrange the numerator and get f of x minus f of a plus g of a x minus g of a and this is divided by x minus a
* Now what do I do
* Well I can actually split this up into 2 separate fractions, alright
* This is f(x)-f(a)/x-a, g(x)-g(a)/x-a
* So this is the limit of f(x)-f(a)/x-a/x-a+g(x)-g(a)/x-a)
* That's a As a limit is x goes to a How do I calculate that limit
* Okay
* I'm just applying these, these rules for calculating limits and one for the rules of calculating limits is the limit of the sum is the sum of the limits provided the limits exist
* What are these 2 limits
* Well, this is really the derivative of f(a) and this is really the derivative of g(a)
* And I assume that f and g are both differentiable at a
* So, those limits do, do exist and I can apply the limit of the sum and the sum of the limits
* So this = the limit as x goes to a of f(x)-f(a)/(x-a) + the limit as x goes to a of g(x)-g(a)/x-a, because I know those 2 limits exist
* And I even know what they're equal to, right
* I have a name for those 2 limits
* This 1st limit is the derivative of f at a, this 2nd limit is the derivative of g at a
* So this is f prime of a plus g prime of a and that's exactly what I wanted to show,right
* I wrote down the definition of derivative of h at the point a, there is is and I applied properties of limits until I conclude that that limit is equal
* To the derivative of f(a) + the derivative of g(a), alright
* And this is what tells me how to calculate the derivative of a sum
* Alright, if I've got a sum of 2 functions, this is telling me that as long as those 2 functions are both differentiable at a, I can calculate the derivative by just adding together the derivatives of f and g
* And hopefully this, this should seem reasonable, right
* Because what is the derivative measuring, right, it's measuring how much change in the input changes the output
* Right, I want to know how much wiggling the input a, would effect the output of H, and that's what this derivative is measuring
* Right
* Well, that's really going to be, you know, somehow connected to how wiggling the input to f changes f and wiggling the input to g changes g and I'm just adding them together
* So I think this makes sense that, then the, how the output changes which would be the sum of how these 2 component functions change
* [MUSIC].


--- SKIP ---: 01_how-do-we-compute-derivatives.en.srt


--- SKIP ---: 01_how-do-we-compute-derivatives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-do-we-compute-derivatives.en_SENTbySENT.txt
* [MUSIC] I'm gonna say a little bit about howthis course as a whole is structured
* Right, we're really covering three topics
* Covering limits,derivatives, and integrals
* And for each of those three topics,we're looking at three different things
* We're looking at the definition,the sort of concepts behind it
* Looking at techniques,sort of how we work with those concepts
* And then we're looking at applications,what can we do with it
* So, take a look at limits, all right
* We learned about the definitions forthe concepts behind limits at first, and then we learned some techniques fordoing computations involving limits
* Say, using a little bit of algebra orthinking about infinity
* And now we want to thinkabout an application
* Why do we care about limits
* Well the reason that we care aboutlimits was because of the derivative
* Right?We use the limits to define the derivative and to introduce some ofthe concepts of the derivative
* And now that we've introducedthe concept of the derivative, we wanna go into the techniques orthe computational questions
* How do you actually compute a derivative
* And in order to do those kinds ofcomputations, we have to think about how would you calculate the derivativeof a product of two things, if you knew the derivativeof those two things
* Or how would you calculatethe derivative of a fraction if you knew how to differentiate the numerator andthe denominator separately
* Those are the kinds of questionsthat'll occupy us now
* [MUSIC]


--- SKIP ---: 01_what-is-the-derivative-of-f-x-g-x.en.srt


--- SKIP ---: 01_what-is-the-derivative-of-f-x-g-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-derivative-of-f-x-g-x.en_SENTbySENT.txt
* [MUSIC] What's the derivative of a product of two functions
* The derivative of a product is given by this, the Product Rule
* The derivative of f times g is the derivative of f times g plus f times the derivative of g
* It's a bunch of things to be warned about here
* This is the product of two functions, but the derivative involves the sum of two different products
* It's the derivative of the first times the second plus the first times the derivative of the second
* Let's see an example of this rule in action
* For example, let's work out the derivative of this product, the product of 1+2x and 1+x^2
* Alright, well here we go
* This is a derivative of product, so by the Product Rule, I'm going to differentiate the first thing, multiply by the second, and add that to the first thing times the derivative of the second
* So, it's the derivative of the first term in the product times the second term in the product, derivative of the first function times the second, plus the first function, 1+2x, times the derivative of the second
* So, that's an instance of the Product Rule
* Now, this is the derivative of a sum, which is the sum of the derivatives
* So, it's the derivative of 1 plus the derivative of 2x times 1+x^2 plus 1+2x times the derivative of a sum, which is the sum of the derivatives
* Now, the derivative of 1, that's a derivative of a constant function that's just 0, this is the derivative of a constant multiple so I can pull that constant multiple out of the derivative, times 1+x^2+1+2x times, the derivative of 1 is 0, it's the derivative of a constant, plus the derivative of x^2 is 2x
* Alright
* Now, I've got 0+2 times the derivative of x
* The derivative of x is just 1
* So, that's just 2*1*(1+x^2)+(1+2x)*(0+2x)
* So, there it is
* I could maybe write this a little bit more neatly
* 2*(1+x^2)+(1+2x)*2x
* This is the derivative of our original function (1+2x)*(1+x^2)
* We din't really need the Product Rule to compute that derivative
* So, instead of using the Product Rule on this, I'm going to first multiply this out and then do the differentiation
* Here, watch
* So, this is the derivative but I'm going to multiply all this out, alright
* So, 1+2x^3, which is what I get when I multiply 2x by x^2, plus x^2, which is 1*x^2+2x*1
* So now, I could differentiate this without using the Product Rule, right
* This is the derivatives of big sum, so it's the sum of the derivatives
* The derivative of one, the derivative of 2x^3, the derivative of x^2, and the derivative of 2x
* Now, the derivative of 1, that's the derivative of a constant, that's just 0
* The derivative of this constant multiple of x^3, I can pull out the constant multiple
* The derivative of x^2 is 2x and the derivative of 2-x, so I can pull out the constant multiple
* Now, what's 2 times the derivative of x^3
* That's 2 times, the derivative of x^3 is 3x^2+2x+2 times the derivative of x, which is 2*1
* And then, I could write this maybe a little bit more nicely
* This is 6x^2+2x+2
* So, this is the derivative of our original function
* Woah
* What just happened
* I'm trying to differentiate 1+2x*1+x^2
* When I just used the Product Rule, I got this, 2*(1+x^2)+(1+2x)*(2x)
* When I expanded and then differentiated, I got this, 6x^2+2x+2
* So, are these two answers the same
* Yeah
* These two answers are the same
* let's see how
* I can expand out this first answer
* This is 2*1+2x^2+1*2x plus 2x*2x is 4x^2
* Now look, 2, 2x^2+4x^2 gives me 6x^2
* And 1*2x gives me this 2x here
* These are, in fact, the same
* Should we really be surprised by this
* I mean, I did do these things in a different order
* So, in this first case, I differentiated using the Product Rule and then I expanded what I got
* In the second case, first, I expanded and after doing expansion, then I differentiated
* More succintly in the first case, I differentiated than expanded
* In the second case, I expanded then I differentiated
* Look, you'd think the order would matter
* Usually, the order does matter
* If you take a shower and then get dressed, that's a totally different experience from getting dressed and then stepping into the shower
* The order usually does matter and you'd think that differentiating and then expanding would do something really different than expanding and then differentiating
* But you've got real choices when you do these derivative calculations, and yet somehow, Mathematics is conspiring so that we can all agree on the derivative, no matter what choices we might make on our way there
* And I think we can also all agree that that's pretty cool
* [MUSIC]


--- SKIP ---: 02_morally-why-is-the-product-rule-true.en.srt


--- SKIP ---: 02_morally-why-is-the-product-rule-true.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_morally-why-is-the-product-rule-true.en_SENTbySENT.txt
* We've used the product rule to calculate some derivatives
* We've even seen a proof using limits, but there's still this nagging question, why
* For instance, why is there this + sign in the product rule
* I mean, really, with all those chiastic laws, the limit of a sum is the sum of the limits, limit of products is the product of limits, you'd probably think the derivative of a product is the product of the derivatives, I mean, you think that if you differentiated a product, it'd just be the product of the derivatives
* No, that's not how products work
* What happens when you wiggle the terms in a product
* We can explore this numerically, so play around with this
* I've got a number a and another number b, and I'm multiplying them together to get some new number, ab
* initially, I've said a=2 and b=3, so ab=6
* But now I can wiggle the terms and see how that affects the output
* So what if I take a and move it from 2 to 2.1
* Well, that affects the output, the output is now 6.3
* Conversely what if I move that back down and I move b from 3 to 3.1
* Well, that makes the output from 6 to now 6.2
* The deal here is that wiggling the input affects the output by a magnitude that's related to the size of the other number, right
* When I went from 2 to 2.1, the output was affected by about three times as much, the 3
* When I moved the 3 from a 3 to a 3.1, the output was affected by about two times as much and these affects add together
* What if I simultaneously move a from 2 to 2.1 and move b from 3 to 3.1, then the output is 6.51, which is close to 6.5 which is what you guessed the answer would be if you just add together these effects
* We can see the same thing geometrically
* Geometrically, the product is really measuring an area
* So let me start with a rectangle of base f(x) and height g(x)
* The product of f(x) and g(x) is then the area of this rectangle
* Now, I want to know how this area is affected when I wiggle from x to say x+h
* So lets suppose that I do that
* Let's suppose that I slightly change the size of the rectangle, so that now the base isn't f(x) anymore, it's f(x+h) and the height isn't g(x) any more, it's g(x+h)
* Now, how does the area change when the input goes from x to x+h
* Well, that's exactly just computing this area and this L-shaped region here
* I can do that approximately
* I actually know how much the base changes approximately, by using the derivative, right
* What's this length here approximately
* Well, the derivative of f at x times the input change is an approximation to how much the output changes when I go from x to (x+h)
* So this distance is approximately f prime of x times h
* Same deal over here
* When the input goes from x to x+h, the output is changed by approximately the derivative times the input change, so this length here is about g prime of x times h
* Now, I'm trying to compute the area of this L-shaped region to figure out how the area, the product changes when I go from x to x+h
* Let me cut this L-shaped region up into three pieces
* This corner piece is pretty small, so I'm going to end up disregarding that corner piece
* but let's just look at these two big pieces here
* This piece here is a rectangle and what's its area
* Well, its base is f(x) and its height is g prime of x times h
* So the area of this piece, is f(x) times g prime of x times h
* What's the area of this rectangle over here
* Well, its base is f prime of x times h and its height is g(x), so the area of this piece is f prime of x g of x times h Now, I want to know how did the area change when I went from x to x+h
* Well, that's pretty close to the, the sum of these two rectangles
* So the change in area is about f of x times g prime of x times h plus f prime of x times g of x times h
* The derivative is the ratio of output change, which is about this, to input change, which in this case is h
* I went from x to x+h
* So now, I can cancel these h's, and what I'm left with is f of x times g prime of x plus f prime x times g of x
* That's the product rule
* That's the change in the area of this rectangle when I went from x to x+h divided by how much I changed the input h
* The power rule isn't something that we just made up
* It's not some sort of sinister calculus plot designed to turn your mathematical dreams into nightmares
* This rule, the product rule, arises for understandable reasons
* If you wiggle one of the terms in a product, the effect on the product has to do with the size of the other term
* You add together these two effects and then you have some idea as to how the product changes based on how the terms change
* This is more than just a rule to memorize
* It's more that just a algorithm to apply
* The product rule is telling you something deep about how a product is effected when it's terms are changed
* [MUSIC]


--- SKIP ---: 03_how-does-one-justify-the-product-rule.en.srt


--- SKIP ---: 03_how-does-one-justify-the-product-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-does-one-justify-the-product-rule.en_SENTbySENT.txt
* [MUSIC] We can drive the product rule by just going back, to the definition of derivative
* So what is the definition of derivative say
* It tell us that the derivative of the product of f of x and g of x is a limit
* It's the limit as h approaches zero
* Of the function at x+h, which, in this case, is the product of f and g, both evaluated at x+h, because I'm thinking of this as the function, so I'm plugging in x+h, and I subtract the function evaluated at x, which is just f(x)*g(x), and then I divide that by h
* So, it's this limit of this difference quotient, that gives me the derivative of the product
* How can I evaluate that limit
* Here's the trick, I'm going to add a disguised version of zero to this limit
* Instead of just calculating the limit of f(x+h)g(x+h)-f(x)g(x), I'm going to subtract and add the same thing
* So here, I've got f(x+h)*g(x+h), just like up here
* Now I'm going to just subtract f(x+h)*g(x+h), and then add it back in, plus f(x+h)*g(x)
* This is just zero, I haven't done anything
* And I'm going to subtract f(x)*g(x) right here and I'm still dividing by h
* So these are the same limits, I haven't really done anything, but I've actually done everything I need
* By introducing these extra factors, I've now got a common factor of f(x+h) here and a common factor of g(x) here
* So, I can collect those out and I'll get some good things happening as a result
* Let's see exactly how this happens
* So this is the limit as h goes to zero, I'm going to pull out that common factor of f(x+h) [SOUND]
* And I'm going to multiply by what's left over g(x+h)-g(x) [SOUND] and I can put it over h
* So that's these two terms
* Now, what's left over here
* I've got a common factor of g(x)
* And what's left over
* f(x+h)-f(x) I'll divide this by h, and then the factor I pull out is g(x)
* So this limit is the same as this limit
* Now this is a limit of a sum
* So that's a sum of the limits provided the limits exist and we'll see that they do
* So this is the limit as h goes to zero of f(x+h)*g(x+h)-g(x)/h plus the lim as h goes to zero of f(x+h)-f(x)/h*g(x)
* Now what do I have here I've got limits of products which are the products of limits providing the limits exist, and they do and we'll see, so let's rewrite these limits of products as products of limits
* This is the limit as h goes to zero of f(x+h) times the limit as h goes to zero of g(x+h)-g(x)/h
* You might begin to see what's happening here, plus the limit as h goes to zero of f(x+h)-f(x)/h times the limit as h goes to zero of g(x)
* Okay, now we've got to check that all these limits exist, in order to justify replacing limits [INAUDIBLE] limits
* But these limits do exist, let's see why
* This first limit, the limit of f(x+h) as h goes to zero, it's actually the hardest one I think, of all these to see
* Remember back, we showed that differentiable functions are continuous
* This is really calculating the limit of f of something, as the something approaches x
* And that's really what this limit is, and because f is continuous, because f is differentiable, this limit is actually just f(x)
* But I think seeing that step is probably the hardest in this whole argument
* What's this thing here
* Well, this is the limit of the thing that calculates the derivative of g, and g is differentiable by assumption
* So, this is the derivative of g at x plus, what's this limit
* This is the limit that calculates the derivative of f, and f is differentiable by assumption, so that's f (x)'
* This is the limit of g(x), as h goes to zero
* This is the limit of a constant
* Wiggling h doesn't affect this at all, so that's just g(x)
* And look at what we've calculated here
* The limit that calculates the derivative of the product is f(x)*g'(x)+f'(x)*g, that is the product rule
* What have we really shown here
* Well, here is one way to write down the product rule very precisely
* Confusingly, I'm going to define a new function that I'm calling h
* So h is just the product of f and g now, h(x)=f(x)*g(x)
* If f and g are differentiable at some point, a, then I know the derivative of their product
* The derivative of their product Is the derivative of f times the value of g plus the value of f times the derivative of g
* This is a precise statement of the product rule, and you can really see, for instance, where this differentiability condition was necessary
* In our proof, at some point in the proof here, I wanted to go from a limit of a product to the product of limits
* But in order to do that, I need to know that this limit exists
* And that limit is exactly calculating the derivative of G
* So you can really see where these conditions are playing a crucial role in the proof of the product rule
* [MUSIC]


--- SKIP ---: 01_what-is-the-quotient-rule.en.srt


--- SKIP ---: 01_what-is-the-quotient-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-quotient-rule.en_SENTbySENT.txt
* [MUSIC] Given what we've done so far we can differentiate a bunch of functions
* We can differentiate sums and differences and products
* But what about quotients
* Given a fraction I'd like to be able to differentiate that fraction
* I like to be able to differentiate a really complicated looking function like f(x)=2x+1/x^2+1, for instance
* But we're stuck immediately because we don't have anyways to differentiate quotients, until now
* Here's the The quotient rule so to state this really precisely let's suppose I got two functions f and g and then I define a new function that I'm just going to call h for now
* H(x) is this quotient f(x) over g(x)
* Now I also want to make sure that the denominator isn't 0 at the point a so it makes sense to evaluate this function at the point a
* And I want ot assume that f and g are differential at the point a
* And I'm trying to understand how h changes so I'm going to need to know how f and g change when the input wiggles a bit
* Alright so given all this set up, then I can tell you what the derivative of the quotient is, the derivative of the quotient at a is the denominator at a times the derivative of the numerator at a
* Minus the numerator at a times the derivative of the denominator at a, all divided by the denominator at a^2
* Let's use the quotient rule to differentiate the function that we saw earlier
* So, the function we were thinking about is f(x)=2x+1/ x^2+1
* I want to calculate the derivative of that, with respect to x
* Now the derivative of this quotient is given to us by the quotient rule
* It's just the denominator times the derivative of the numerator minus the numerator times the derivative of the denominator
* That's all divided by the denominator squared
* Now, I've calculated the derivative of this quotient in terms of the derivatives of the numerator and denominator
* So we can simplify this further, X^2+1 times the derivative of this sum is the sum of the derivatives
* It's the derivative of 2x + the derivative of 1-2x+1 times at again, the derivative of a sum, so the derivative of x^2, with respect to x plus the derivative of 1
* And it's all divided by the denominator, the original denominator squared
* I can keep going, I've got x^2+1 times what's the derivative of 2x
* It's just 2
* What's the derivative of this constant
* zero, minus 2x+1 times, what's the derivative of x^2
* It's 2x, and what's the derivative of 1
* It's the derivative of a constant zero, all divided by x^2+1^2
* So, this is the derivative of the original function we're considering, there's no more differentiation to be done and we did it using the quotient rule
* We've done a ton of work on differentiation so far, we differentiate sums, differences, products, now quotients
* What sorts of functions can we differentiate using all of these rules
* Well, here's one big collection
* If you've got a polynomial divided by polynomial, these things are called rational functions
* Sort of an analogy with rational numbers which are integers over integers
* A polynomial over a polynomial is by analogy, being called a rational function
* Now, since this is just a quotient of two things you can differentiate, you can differentiate these rational functions
* This is a huge class of functions that you can now differentiate
* [MUSIC] I encourage you to practice with the quotient rule
* With some practice, you'll be able to differentiate any rational function that we can throw at you
* [MUSIC] [MUSIC]


--- SKIP ---: 02_how-can-i-remember-the-quotient-rule.en.srt


--- SKIP ---: 02_how-can-i-remember-the-quotient-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-can-i-remember-the-quotient-rule.en_SENTbySENT.txt
* [MUSIC] You're lost
* You're trapped on a desert island
* You have to remember the quotient rule
* How can you remember the quotient rule
* Even while trapped on that desert island, you'll remember the vague form of the quotient rule
* You'll remember, the numerator looks a little bit like the product rule
* It's a value times a derivative minus the other value times the other derivative
* But, you might not remember exactly where the minus sign goes, right
* You don't know if it's f(x)*g(x)-g(x)*f (x), or the other way around, g(x)*f(x)-f(x)*g(x)
* Which one is it
* If you weren't trapped on the desert island, you'd have access to Wikipedia
* And you could just look up the quotient rule
* [MUSIC] Even if you could just look it up let's think about it for a little bit
* Why is the quotient rule what it is
* To make it easy on ourselves let's suppose that f of x is positive and g of x is positive
* Now I'm trying to understand some of the derivative of the quotient which is really how is the quotient changing when f and g are doing some changing
* Let's make that really concrete
* Let's suppose that the numerator is getting bigger but the denominator is staying the same
* How does this change
* Well then that is bigger, right
* If you take Bigger thing and cut it into the same number of pieces
* Then, those pieces are bigger
* Now, we could play the game the other way
* I could keep the pieces the same size, but increase the denominator which would be cutting them into more pieces
* Right
* And if I take the same amount of stuff and divide it into more pieces, then each of those pieces is smaller
* Right
* So a same size number divided by a bigger number now this fraction is smaller
* How does this relate to the derivitaive
* Well think back to the sign, the s i g n of the derivative
* So same set up, f of x is positive, g of x is positive, maybe the denominator isn't really changing, but the numerator, is getting bigger And now I want to know, how is the fraction changing
* Well, the numerator's getting bigger the denominator's staying the same, the fraction should be getting bigger, which then tells us something about the SIGN of this derivative
* We can similarly analyze the situation involving the denominator
* So, if the numerator is positive and the denominator is positive and the numerator is not really changing, but the denominator is getting bigger then the fraction f of x over g of x is getting smaller
* So that tells us, again, something about the sign of the derivative of this ratio
* It's negative, because if the denominator's getting bigger, and the numerator's not really changing, this ratio is getting smaller
* How does all of this help us to identify the actual quotient rule
* How can we get rid of that imposter quotient rule
* So we've got to guesses as to what the quotient rule might be and I've got some information that we just thought about, right if the function's values are positive and the numerator's getting bigger and the denominator's not really changing that means the fraction's getting bigger
* If the numerator's not really changing but the denominator's getting bigger then that fraction's getting smaller
* Now these are truths
* And which of these truths are compatible with which of these guesses about the quotient rule
* Well, let's take a look
* This first guess about the quotient rule, let's see what happens if the numerator's not changing, but the denominator's getting bigger
* If the numerator's not changing, that kills this whole first term and the derivative of f vanishes then
* But the derivative that a nominator be positive, I'm imagining the value of the function is positive
* So, this is a positive number but a negative sign there, so this is now a negative numerator divided by a positive number
* So, if this were the quotient rule, it would be telling us that an increasing denominator makes this ratio smaller
* It makes the derivative negative, that's good
* That's really compatible with this picture
* Now, is this compatible with that
* Well, what would happen here if the denominator were increasing, but the numerator was staying the same
* If the numerator's staying the same, this is zero, which kills this term
* And I'm just left with this, and if the numerator is increasing then this term is positive and imagine the function's [UNKNOWN] positive
* So you got a positive thing divided by positive thing
* If these were the quotient row, an increasing denominator where the numerator remains the same would make this ratio Increase because this derivative would be positive or this can't be, this isn't the quotient rule, it's not compatible with this fact
* In fact, this is the quotient rule and we can see that it's also compatible with this first fact
* If the numerator is getting bigger but the denominator is staying the same well the denominator staying the same makes this term zero which kills this whole term and all I'm left with is this
* Now imagine g is positive and the derivative of the numerator is positive
* The derivator is getting bigger
* This is positive, I've got a positive thing divided by a positive thing
* That makes the derivative positive
* And that makes sense
* If the numerator's getting bigger and the denominator's staying the same, the derivative is positive and that's exactly what this true quotient rule is saying
* Fundamentally, I don't want you just to memorize all of these rules
* [MUSIC] I want you to understand why the rules are what they are
* I want you to get a feeling for why there's a negative sign in the quotient rule
* It really belongs there
* [MUSIC].


--- SKIP ---: 01_what-is-the-meaning-of-the-derivative-of-the-derivative.en.srt


--- SKIP ---: 01_what-is-the-meaning-of-the-derivative-of-the-derivative.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-meaning-of-the-derivative-of-the-derivative.en_SENTbySENT.txt
* [MUSIC] Thus far, I've been trying to sell you on the idea that the derivative of f measures how we wiggling the input effects the output
* A very important point is that sensitivity to the input depends on where you're wiggling the input
* And here's an example
* Think about the function f(x)=x^3
* f(2) which is 2^3 is 8
* f(2.01) 2.01 cubed is 8.120601
* So, the input change of 0.01 was magnified by about 12 times in the output
* Now, think about f(3) which is 3^3, which is 27
* f(3.01) is 27.270901 so the input change of 0.01 was magnified by about 24 times as much, right
* This input change and this input change were magnified by different amounts
* You know, you shouldn't be too surprised by that right, the derivative, of course, measures this
* The derivative of this function is 3x^2, so the derivative at two is 3*2^2 is 3*4 is 12 and not coincidentally, there's a 12 here and there's a 12 here, right, that's reflecting the sensitivity of the output to the input change
* And the derivative of this function at 3 is 3*3^2, which is 3*9 which is 27 and again, not too surprisingly here's a 27, right
* The point is just that how much the output is effected depends on where you're wiggling the input
* If you're wiggling around 2, the output is affected by about 12 times as much if we're wiggling around 3, the output is affected by 27 times as much, right
* The derivative isn't constant everywhere, it depends on where you're plugging in
* We can package together all of those ratios of output changes to input changes as a single function
* What I mean by this, well, f'(x) is the limit as h goes to 0 of f(x+h)-f(x)/h
* And this limit doesn't just calculate the derivative at a particular point
* This is actually a rule, right, this is a rule for a function
* The function is f'(x) and this tells me how to compute that function at some input X
* The derivative is a function
* Now, since the derivative is itself a function, I can take the derivative of the derivative
* I'm often going to write the second derivative, the derivative of the derivative this way, f''(x)
* There's some other notations that you'll see in the wild as well
* So, here's the derivative of f
* If I take the derivative of the derivative, this would be the second derivative but I might write this a little bit differently
* I could put these 2 d's together, so to speak, and these dx's together and then I'll be left with this
* The second derivative of f(x)
* A subtle point here is if f were maybe y, you might see this written down and sometimes people write this dy^2, that's not right
* I mean, it's d^2 dx^2 is the second derivative of y
* The derivative measures the slope of the tangent line, geometrically
* So, what does the second dreivative measure
* Well, let's think back to what the derivative is measuring
* The derivative is measuring how changes to the input affect the output
* The deravitive of the derivative measures how changing the input changes, how changing the input changes the output, and I'm not just repeating myself here, it's really what the second derivative is measuring
* It's measuring how the input affects how the input affects the output
* If you say it like that, it doesn't make a whole lot of sense
* Maybe a geometric example will help convey what the second derivative is measuring
* Here's a function, y=1+x^2
* And I've drawn this graph and I've slected three points on the graph
* Let's at a tangent line through those 3 points
* So, here's the tangent line through this bottom point, the point 0,1 and the tangent line to the graph at that point is horizontal, right, the derivative is 0 there
* If I move over here, the tangent line has positive slope and if I move over to this third point and draw the tangent line now, the derivative there is even larger
* The line has more slope than the line through that point
* What's going on here is that the derivative is different
* Here it's 0, here it's positive, here it's larger still, right
* The derivative is changing and the second derivative is measuring how quickly the derivative is changing
* Contrast that with say, this example of just a perfectly straight line
* Here, I've drawn 3 points on this line
* If I draw the tangent line to this line, it's just itself
* I mean, the tangent line to this line is just the line I started with, right
* So, the slope of this tangent line isn't changing at all
* And the second derivative of this function, y=x+1, really is 0, right
* The function's derivative isn't changing at all
* Here, in this example, the function's derivative really is changing and I can see that if I take the second derivative of this, if I differentiate this, I get 2x, and if I differentiate that again, I just get two, which isn't 0
* There's also a physical interpretation of the second derivative
* So, let's call p(t), the function that records your position at time t
* Now, what happens if I differentiate this
* What's the derivative with respect to time of p(t)
* I might write that, p'(t)
* That's asking, how quickly is your position changing, well, that's velocity
* That's how quickly you're moving
* You got a word for that
* Now, I could ask the same question again
* What happens if I differentiate velocity, I am asking how quickly is your velocity changing
* We've got a word for that, too
* That's acceleration
* That's the rate of change of your rate of change
* There's also an economic interpretation of the second derivative
* So, maybe right now dhappiness, ddonuts for me is equal to 0, right
* What this is saying
* This is saying how much will my happiness be affected, if I change my donut eating habits
* If I were really an economist I'd be talking about marginal utility of donuts or something, but, this is really a reasonable statement, right
* This is saying that right at this moment you know, eating more donuts really won't make me any more happier and I probably am in this state right now, because if this weren't the case, I'd be eating donuts
* So, let's suppose this is true right now and now, something else might be true right now
* I might know something about the second derivative of my happiness with respect to donuts
* What is this saying
* Maybe this is positive right now
* This is saying that a small change to my donut eating habits might affect how, changing my donut habits would affect how happy I am
* If this were positive right now, should I be eating more donuts, even though dhappiness, ddonuts is equal to zero
* Well, yeah, if this is positive, then a small change in my donut eating habits, just one more bite of delicious donut would suddenly result in dhappiness, ddonuts being positive, which should be great, then I should just keep on eating more donuts
* Contrast this with the situation of the opposite situation, where the second derivative happens with respect to donuts isn't positive, but the second derivative of happiness with respect to donuts is negative
* If this is the case I absolutely should not be eating any more donuts because if I start eating more donuts, then I'm going to find that, that eating any more donuts will make me less happy
* Let's think about this case geometrically
* So here, I've drawn a graph of my happiness depending on how many donuts I'm eating
* And here's two places that I might be standing right now on the graph
* These are two places where the derivative is equal to zero
* And I sort of know that I must be standing at a place where the derivative is 0, because if I were standing in the middle, I'd be eating more donuts right now
* So, I know that I'm standing either right here, say, or right here
* Or maybe here, or here
* I'm standing some place where the derivative vanishes
* Now, the question is how can I distinguish between these two different situations
* Right here, if I started eating some more donuts, I'd really be much happier
* But here, if I started eating some more donuts I'd be sadder
* Well, look at this situation, this is a situation where the second derivative of happiness to respected donuts is positive, right
* When I'm standing at the bottom of this hole, a small change in my donut consumption starts to increase the extent to which a change in my donut consumption will make me happier, alright
* If I find that the second derivative of my happiness with respect to donuts is positive, I should be eating more donuts to walk up this hill to a place where I'm happier
* Contrast that with a situation where I'm up here
* Again, the derivative is zero so a small change in my doughnut consumption doesn't really seem to affect my happiness
* But the second derivative in that situation is negative
* And what does that mean
* That means a small change to my donuts consumption starts to decrease the extent to which donuts make me happier
* So, if I'm standing up here and I find that the second derivative of my happiness with respect to donuts is negative, I absolutely shouldn't be eating anymore donuts
* I should just realize that I'm standing in a place where, at least for small changes to my donut consumption, I'm as happy as I can possibly be and I should just be content to stay there
* There's more to this graph
* Look at this graph again
* So, maybe I am standing here
* Maybe the derivative of my happiness with respect to donuts is zero
* Maybe the second derivative of my happiness with respect to donuts is negative
* So, I realize that I'm as happy as I really could be for small changes in my donut consumption
* But if I'm willing to make a drastic change to my life, if I'm willing to just gorge myself on donuts, things are going to get real bad, but then they're going to get really really good and I'm going to start climbing up this great hill
* It's not just about donuts, it's also true for Calculus
* Look, right now, you might think things are really good, they're going to get worse
* But with just a little bit more work, you're eventually going to climb up this hill and you're going to find the immeasurable rewards that increased Calculus knowledge will bring you
* [MUSIC]


--- SKIP ---: 02_what-does-the-sign-of-the-second-derivative-encode.en.srt


--- SKIP ---: 02_what-does-the-sign-of-the-second-derivative-encode.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-does-the-sign-of-the-second-derivative-encode.en_SENTbySENT.txt
* [MUSIC]
* Earlier we saw how the sign, the S-I-G-N,of the derivative encoded whether thefunction was increasing or decreasing
* Thinking back to the graph, here I've justdrawn some random graph
* What is the derivative encoding
* Well here this point a, the slope of thistangent line is negative, the derivative is negative, andyeah, the function's going down here
* At this point b, the slope of this tangent line is positive and the function'sincreasing through here
* All right
* The derivative is negative here, and it'spositive here
* The function's decreasing here, andincreasing here
* So that's what the derivative ismeasuring
* What is the sign of the second derivativereally encoding
* Maybe we don't have such a good word forit so we'll just make up a new word
* The S-I-G-N, the sign of the secondderivative, the sign of the derivative of the derivativemeasures concavity
* The word's concavity, and here's the twopossibilities, concave up where the second derivative is positive, and concave downwhere the second derivative is negative
* And I've drawn sort of cartoony picturesof what the graphs look like in these twocases
* Now, note it's not just increasing ordecreasing, but this concavity is recording sort of the shape of thegraph in some sense
* Positive second derivative makes it looklike this, negative second derivative makes thegraph look like this, and I'm just labeling these two things concave up and concavedown
* And this makes sense if we think of the second derivative as measuring the changein the derivative
* So let's think back to this graph again
* Here's this graph of some random function
* Look at this part of the graph right here
* That looks like the concave up shape from before, where the second derivativewas positive
* So we might think that the secondderivative is positive here
* That would mean that the derivative isincreasing
* What that really means is that the slope of a tangent line through this region isincreasing
* And that's exactly what's happening
* The slope is negative here, and as I movethis tangent line over, the slope of thattangent line is increasing
* The second derivative is positive here
* You can tell yourself the same story forconcave down
* So look over here in our sample graph
* That part of the graph looks like this concave down picture where the secondderivative's negative
* Now, if the second derivative is negative,that means the derivative is decreasing
* And yeah, the slope of the tangent linethrough this region is going down, right
* The slope starts off pretty positive overhere, and as I move this tangent line over, the slope is zero, andnow getting more and more negative
* So in this part of the graph, the secondderivative is negative
* What happens in between
* Where does the regime change take place
* So over here, the second derivative isnegative
* Over here, the second derivative ispositive
* There's a point in between, maybe it'sright here
* And at that point the second derivative isequal to zero
* And on one side it's concave down, and onthe other side it's concave up
* A point where the concavity actuallychanges is called an inflection point
* Alright, the, it's concave down over here,and it's concave up over here and the place where the change is taking place,we're going to, just going to call those pointsinflection points
* It's not that the terminology itself is soimportant, but we want words to describe the qualitativephenomena that we're seeing in these graphs
* Inflection points are something you canreally feel
* I mean, if you're driving in a car, you'rebraking, right
* That means the second derivative'snegative
* You're slowing down
* And then suddenly you step on the gas
* Now you're accelerating
* Your second derivative's positive
* What happened, right
* Something big happened
* You're changing regimes from concave downto concave up and you want to denote that changesomehow
* We're going to call that change aninflection point
* [MUSIC]


--- SKIP ---: 03_what-does-d-dx-mean-by-itself.en.srt


--- SKIP ---: 03_what-does-d-dx-mean-by-itself.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-does-d-dx-mean-by-itself.en_SENTbySENT.txt
* [MUSIC]
* Once upon a time, a long, long time ago ina cave somewhere, there was some cave person who firststarted studying numbers
* And then the cave person had an idea
* The idea is functions
* Instead of just studying numbers, thiscave person is going to study numbers depending on other numbers,the relationships between numbers
* There's another way to think aboutfunctions
* A different metaphor is that functions[SOUND] eat numbers, and after they're done processing them, they spitout [SOUND] some other number
* Functions eat numbers and spit outnumbers
* But the food chain keeps going
* The derivative is an operator
* And what that means is that it's like afunction for functions
* The derivative eats a function and afterit's done with it it spits out a new function, thederivative
* First we studied numbers
* Then we studied functions, which arenumbers that depend on numbers or things that you do tonumbers
* And now the derivative
* The derivative eats something which itselfeats something and spits out numbers
* And then the derivative spits out a new thing that eats numbers and spits outnumbers
* The derivative takes a function and givesyou a new function, and this ddx notation isso powerful, that you can start to talk aboutthe derivative even before you've applies itto any function
* Look at this, this is some sort of equation, but it's really a nonsenseequation
* The second derivative minus one
* What does it even mean
* Equals the derivative minus one, what am Idoing here
* Who knows
* The derivative plus one
* This sort of nonsense looks similar tosomething very reasonable, that x squared minus 1 is x minus 1 times xplus 1
* There's actually some sense to this
* So let's try to make sense of the righthand side
* After I apply it to a function
* So we don't even really know what thismeans, but the notation's so powerful that it's justgoing to lead us forward
* So I'm going to copy down ddx minus 1 inparentheses, and I have to figure out how I'm going to applythis thing to F
* I'm going to act like this distributes, soI'll write DDX of F
* Plus 1 times f
* Now I can keep on going, right
* This, if you kind of imagine, mightdistribute over this
* What would that, what would that mean
* I'm going to d/dx this whole thing, sod/dx of d/dx of f plus f, minus 1 times this
* So minus d/dx of f, plus f
* And now I can keep calculating, thederivative of the derivative of f plus f
* Well, the derivative of a sum is the sumof the derivative so that makes sense
* That's the derivative of the derivative off plus the derivative of f minus the derivative of f minus f, subtractingsumming F, so it's subtracting F
* Now good news, I've got a plus derivativehere, and a minus derivative of F there, so what I'mleft with is D Dx, D Dx of F, which I could write as the second derivative of Fminus F
* Well I could also write this as the secondderivative minus 1, applied to F
* And that's exactly what's on the otherside of this equation
* At this point, this is all a sort of cheating, so if this doesn't speak to you,don't worry
* The upshot though, is that differentiationis an operation that you apply to functions
* And it's possible to reason preciselyabout differentiation in the abstract just as anoperation
* [MUSIC]


--- SKIP ---: 01_what-are-extreme-values.en.srt


--- SKIP ---: 01_what-are-extreme-values.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-are-extreme-values.en_SENTbySENT.txt
* [MUSIC] The goal of computing is not numbers but insight
* I don't care that f(2) is equal to four
* I do care about the qualitative features of a function
* Here's a graph of some random function I just made up
* A significant qualitative feature of this graph is that right here is a valley in the graph and up here is a mountaintop
* Speaking of mountaintops and valleys is maybe too metaphorical, not precise enough
* Let's try to work out a better definition
* So, instead of calling this a mountain top, I'm going to call that a local maximum
* Let's be even a little bit more precise
* Let's suppose that that maximum value occurs at the input c, where the output is f(c)
* I'm going to call f(c) the local maximum value of the function near the input c
* Here's a precise definition, f(c) is a local maximum value for f if whenever x is near the input c, f(c) is bigger than or equal to f(x)
* Maybe this isn't even precise enough
* A big sticking point with this is this word near
* That's sort of a weasley word
* I can make this near precise just like we've been doing with limits
* I'll introduce sum epsilon
* So f(c) is a local maximum value for the function f, if there's some small number, that's what I mean by near
* So that whenever x is near c, and by near c, now, I'm in between c- epislon and c+ epsilon
* This is really close to c if epsilon is real small
* Okay
* So that, whenever x is contained in this interval, f(c) is bigger then or equal to f(x)
* We can give a similar sort of definition for the valleys
* Here's that same graph again and I've highlighted a local minimum on the graph of this function
* Near the input c, f(c) is the smallest output for the function
* A little bit more precisely, I'm calling it a local minimum value, because whenever x is near c, f(c) is less than or equal to f(x)
* Or even a little bit more precisely again just like for local maximums, I can replace near with espilon
* So f(c) is a local minimum value for the function, if there's some epsilon measuring the nearness, so that whenever x is between c- epsilon, and c+ epsilon, f(c) is less than or equal to f(x)
* Sometimes, I'm going to want to talk simultaneously about local maximums and local minimums
* So, we'll call either a local minimum or a local maximum a local extremum
* And this is kind of a pretentious word, but it's just a word that we can use so that we can talk about both of these concepts simultaneously, because they actually share quite a few features in common
* What if I want to talk about multiple extremums
* Well, what if we wanted to talk about an octopus
* Well, that's not really a problem, but, what if you wanted to talk about two of these things
* You might not call it an octopus, you might call it an octopuses now
* But, you'll find some people will get angry at you if you do that and I want you to call these octopi
* I probably don't really agree with them, but, the same problem comes up with minimums and maximums and extremums
* You're going to find some people who will demand that you call these minima, maxima, and extrema if you're talking about more than one of these things, but really, either is fine
* The world local here is really in contrast to the world global
* We'll say, in fact, everyone will say that f(c) is a global maximum value for the function f if no output of the function is larger than f(c)
* Maybe that's too cute of a way to say it
* Here's a more precise way to say it, f(c) is a global maximum value for the function if whenever x is in the domain of f, I'm only going to be considering inputs in the domain, of course, then f(c) is bigger than or equal to f(x)
* Do the same deal for minimal values, f(c) is a global minimum value for the function if whenever I've got a point in the domain f(c) is less than or equal to f(x)
* One subtle thing to point out here is that I'm not claiming, say for global maximum values that this is the biggest output of the function
* What I'm saying is that any other output isn't larger than f(c), f(c) is bigger than or equal to any other output of the function and the same deal for this global minimum
* I'm not saying this is the smallest output of the function, I'm just saying that any other output is bigger than or equal to this output
* Now we can see some examples of this
* Of this
* Here's that same graph we've been looking at so many times here
* Let's try to figure out where the local extrema are
* this point here is a local maximum, that's the biggest output value for nearby input values
* This point here is a local minimum, right
* You're sitting in that valley, that's the smallest output valley among nearby inputs
* And, up here is another local max and this local maximum is also a global maximum
* I mean, if you're really assuming that this graph just continues down to the left and the right-hand sides, you should also note that if you really believe this thing continues down like this, this function has no global minimum
* Nobody's promising you that there is a global minimum or a global maximum, but in this case, there isn't one
* There's no global minimum
* There can definitely be multiple local maximums, but there can also be multiple global maximums
* So here, I've drawn another graph, where I've rigged it so that these two output values are the same
* So these are both local maximums, but they're also both global maximums
* Alright
* So in this case, these are both global and also local maximums
* There's even more, dare I say it, extreme version of this
* Here, I've graphed the constant function y=17 is both a global maximum and a global minimum for this constant function
* The distinction between local and global maximums is really quite important, even in everyday life
* When you're standing at a local maximum, on the top of this mountain, small changes to your situation just make things worse, and yet, if you're willing to go through this valley, you'll eventually come up here to what at least appears to be to global maximum of this function
* [MUSIC]


--- SKIP ---: 02_how-can-i-find-extreme-values.en.srt


--- SKIP ---: 02_how-can-i-find-extreme-values.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-can-i-find-extreme-values.en_SENTbySENT.txt
* [MUSIC] If we care about extreme values, it would really help to know how to find them
* We can use a theorem, a theorem of Fermat
* Here's Fermat's theorem
* Suppose f is a function and it's defined on the interval between a and b
* c, is some point in this interval, this backwards e, means that c is in this interval
* Okay, so that's the set up
* Here's Fermat's Theorem
* If f(c) is an extreme value of the function f, and the function is differentiable at the point c, then the derivitive vanishes at the point c
* It's actually easier to show something slightly different
* So, instead of dealing with this, I'm going to deal with a different statement
* Same setup as before, but now I'm going to try to show that if f is differentiable at point c and the derivative is nonzero, then f(c) is not an extreme value
* It's worth thinking a little bit about the relationship between the original statement where I'm starting off with the claim that f(c) is an extreme value and then concluding that the derivative vanishes
* And here, I'm beginning, by assuming the derivative doesn't vanish and then concluding that f(c) is not an extreme value
* This is the thing that I want to try to prove now
* Why is that theorem true
* I'm going to get some intuitive idea as to why this is true
* Why is it that if you differentiable a point c with nonzero derivative there, then f(c) isn't an extreme value
* Well, to get a sense of this, let's take a look at this graph
* Here, I've drawn a graph of some random function
* I've picked some point and f'(c) is not zero
* Differentiable there, but the derivative's nonzero
* It's negative
* Now, what does that mean
* That means if I wiggle the input a little bit, I actually do affect the output
* If I increase the input a bit, the output goes down
* If I decrease the input a bit, the output goes up
* Consequently, that can't be an extreme value
* That's not the biggest or the smallest value when I plug in inputs near c, and that's exactly what this statement is saying
* If the derivative is not zero, that means I do have some control over the output if I change the input a little bit
* That means this output isn't an extreme value because I can make the output bigger or smaller with small pervations to the input
* I'd like to have a more formal, a more rigorous argument for this
* So, let's suppose that f is differentiable at c, and the derivative is equal to L, L some nonzero number
* Now, what that really means from the definition of derivative is that the limit of f(c+h)-f(c)/h as h approaches zero is equal to L
* Now, what does this limit say
* Well, the limit's saying that if h is near enough zero, I can make this difference quotient as close as I like to L
* In particular, I can guarantee that f(c+h)-f(c)/h is between 1/2L and 3/2L
* Notice what just happened
* So, I started with infinitesimal information
* I'm just starting with a limit as h approaches zero
* And I've promoted this infinitesimal information to local information
* Now I know that this difference quotient is between these two numbers as long as h is close enough to zero
* Now, we can continue the proof
* So, I know that if h is close enough to zero, this difference quotion is between 1/2L and 3/2L, I'm going to multiply all this by h
* What do I find out then
* Then, I find out that if h is near enough zero, multiplying all this by h, I find that f(c+h)-f(c)/h*h is between 1/2hL and 3/2hL
* I get from here to here just by multiplying by h
* Now, what can I do
* Well, I can add f(c) to all of this
* And I'll find out that if h is near enough zero, then f(c+h) is between 1/2hL+f(c) and 3/2hL+f(c)
* Okay
* So, this is what we've shown
* We've shown that if h is small enough, f(c+h) is between these two numbers
* Now, why would you care
* Well, think about some possibilities
* What if L is positive
* If L is positive and h is some small but positive number, this is telling me that f(c+h), being between these two numbers, f(c+h) is in particular bigger than f(c)
* That means that f(c) can't be a local maximum
* Same kind of game
* What if L is positive but I picked h to be negative but real close to zero
* Then, f(c+h) being between these two numbers, f(c+h) must actually be less than f(c)
* That means that f(c) can't be a local minimum
* You play the same game when L is negative
* Let's summarize what we've shown
* So, what we've shown is this
* We've shown that if a differentiable function has nonzero derivative at the point c, then f(c) is not an extreme value
* And we can play this in reverse
* That means that if f(c) is a local extrema, right
* If f(c) is an extreme value, then either the derivative doesn't exist to prevent this first case from happening, where f is differentiable at c, or the derivatives equal to zero, which prevents this second thing, f'(c) being nonzero
* So, this is another way to summarize what we've done
* If f(c) is a local extremum, then one of these two possibilities occurs
* Both of these possibilities do occur
* Here's the graph of the absolute value function
* There's a local and a global minimum at the point zero
* The derivative of this function isn't defined at that point
* Here's another example
* Here's the graph of y=x^2
* This function also has a local and a global minimum at the point zero
* Here, the derivative is defined but the derivative is equal to zero at this point
* We'll often want to talk about these two cases together, the situation where the derivative doesn't exist and the situation where the derivative vanishes
* Let's give it a name to this phenomenon
* Here we go
* If either the derivative at c doesn't exist, meaning the function's not differentiable at c, or the derivative is equal to zero, then I'm going to call the point c a critical point for the function f
* This is a great definition because it fits so well into Fermats theorem
* Here's another way to say Fermot's Theorem
* Suppose f is a function as defined in this interval and c is contained in there, then if f(c) is an extreme value of f, well, we know that one of two possibilities must occur
* At that point, either the function's not differentiable, or the derivative's equal to zero
* And that's exactly what we mean when I say that c is a critical point of f
* So, giving a name to this phenomena gives us a really nice way of stating Fermat's Theorem
* The upshot is that if you want to find extreme values for a function, you don't have to look everywhere
* You only have to look at the critical points where the derivative either doesn't exist or the derivative vanishes
* and you should probably also worry about the end points
* In other words, if you're trying to find rain, you should just be looking for clouds
* You just have to check the cloudy days to see if it's raining
* In this same way, if you're looking for extreme values, you only need to look for the critical points because an extreme value gives you a critical point
* So, this is a super concrete example
* Here's a function, y=x^3-x
* I've graphed this function
* I'm going to try to find these local extrema, this local maximum and this local minimum, using the machinery that we've set up
* So, if I'm looking for local extrema, I should be looking for critical points
* So, here's the function, f(x)=x^3-x
* I'm looking for for critical points in this function
* Those are points whose derivative doesn't exist, function is not differentiable, or the derivative vanishes
* But this function is differentiable everywhere
* Its derivative is 3x^2-1
* So, the only critical points are going to be where the derivative is equal to zero, right
* I'm looking for solutions to 3x^2-1=0
* I'll write one to both sides, 3x^2=1, so I am trying to solve
* I'll divide both sides by 3, x^2=1/3
* So, I am trying to solve
* Take the square root of both sides
* x is plus or minus the square root of a third, which is about 0.577
* And that let's me find these critical points, right
* These are places where the derivative is equal to zero
* The tangent line is horizontal and now I know the x coordinate of these two red points
* Here, are the x coordinates about 0.577, and here the x coordinate is -0.577, about.


--- SKIP ---: 03_do-all-local-minimums-look-basically-the-same-when-you-zoom-in.en.srt


--- SKIP ---: 03_do-all-local-minimums-look-basically-the-same-when-you-zoom-in.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_do-all-local-minimums-look-basically-the-same-when-you-zoom-in.en_SENTbySENT.txt
* [MUSIC] People have the idea that a local minimum means the function decreases and then increases
* Here's a local minimum on the graph of this random function
* And the misconception is that they all look like this
* That every time you got a local minimum on one side, the function's decreasing, and on the other side the function's increasing
* Plenty of local minima do look exactly like that
* But, there's also plenty of pathological examples
* For instance, consider this a somewhat pathological example
* I'm going to define this function f as a piecewise function
* If the input's nonzero, I'm going to do this
* 1+sin(1/x), which makes sense since x isn't zero, time x^2
* And if the input is zero, the function's output will also be zero
* In this case, there's a local minimum at zero
* How do I know
* Well, here's how I know
* Let's take a look at this function The claim is that f(x) is never negative
* How do I know that
* Well, what do I know about sine
* Sine of absolutely anything at all, no matter what I take this sine of, is between -1 and 1
* Now, if I add 1 to this, 1 plus sine of absolutely anything at all, is between zero and two
* Now, that's pretty good
* Now, think back to the definition of this function
* Here, I've got 1 plus sine of something, it doesn't matter what, alright
* 1 plus sine of anything, this is between zero and two
* Now, I'm multiplying it by x^2
* What do I know about x^2
* Well, x^2 is not negative
* It could be zero, it could be positive
* But no matter what x is, x^2 is not negative
* Now, I'm multiplying 1+sin(1/x), this number which is trapped between zero and to, by x^2 which is never negative
* And that means f(x) is not negative as long as x isn't equal to zero, alright
* As long as x isn't equal to zero
* I mean, this first case and this is a non-negative number times a non-negative number, so the product is also non-negative
* Now, the other possibility, of course, is that I plug in zero for x
* But then, f(0) is just by definition zero
* And that means in either case, no matter that I plug in for x, f(x) is never a negative
* Now if f(x) is never negative and f(0)=0, then I know that this must be the smallest possible output value for the function
* The only numbers that are smaller than zero are negative numbers, and the output of this function is never negative
* But this isn't the usual sort of local minimum where the function just decreases and then increases
* Well, here's the graph for our funciton f
* And, there is a local minimum at zero, but if I start zooming in, no matter how much I zoom in, there's no little region on which the graph is just decreasing and then increasing
* The graph is always wiggling
* The upshot here is that decreasing and then increasing is one way to produce a local minimum, but it's not the definition of a local minimum
* And not every local minimum arises in that exact way
* What a local minimum means is just that no nearby output value is smaller than that local minimum value.


--- SKIP ---: 04_how-can-i-sketch-a-graph-by-hand.en.srt


--- SKIP ---: 04_how-can-i-sketch-a-graph-by-hand.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_how-can-i-sketch-a-graph-by-hand.en_SENTbySENT.txt
* [MUSIC] Suppose I've got some function given by a rule and I want to make a graph of that function
* I wanted to plot say this function f(x) equals 2x cubed minus 3x squared minus 12
* First thing I might do is just plug in some values
* All right I'll pick
* Pick some inputs and I'll see what the function outputs at those inputs
* And once I've got this table of values, I could then plot those points on a graph
* The issue is, how do I really know what happens between these points that I plotted on the graph
* How do I know the graph isn't doing some crazy wiggling in between
* How do I know that I've really picked enough input points to really get a good idea of what this graph is doing
* We're going to use derivatives to make sure that we're really capturing the qualitative features of the function
* I might have been trying to graph a function, like f(x) equals sin Pi x, and if I just plugged in some whole number inputs, the function would always output 0
* That might trick me into making a graph like this, where I plot 0 as the output for all these whole number inputs
* I might, then, be tempted to just fill in this graph by drawing a straight line across
* But that's totally ridiculous, right
* This graph, you know, actually looks like this
* Not a horizontal straight line
* There's all kinds of extra wiggling that's happening that I missed because I chose my in points badly
* We're going to use derivatives to make sure that we're really capturing the qualitative features of the function and there's a ton of different ways to do this
* So let's work this out in one specific concrete example
* So let's keep working on the graph of this function, f(x) equals 2x cubed minus 3x squared minus 12x
* First thing I'm going to do is differentiate this, the derivative is 6x^2-6x-12, cause' the derivative of 2x^3 is 6x^2, the derivative of minus 3x^2 is minus 6x, and the derivative of minus 12x is minus 12
* There's a common factor of 6 here which I can pull out, and then I'm left with this quadratic, and I can factor that quadratic into (x+1) times (x-2)
* Now once I've got this nice factorized version of the derivative, I can then figure out where the derivative is positive and negative
* The derivative is positive when the input is more negative than minus and it's positive when the input is more positive than 2
* In between -1 and 2, the derivative is negative
* And at the point -1, and at the point 2, the derivative is equal to zero
* Now, since this function is differentiable everywhere, the only critical points are where the derivative is equal to zero
* These are the critical points, minus 1 and 2
* Alright
* So I found the critical points
* I found the derivative
* Now, I'll also find the second derivative of this function
* Which I get by differentiating this derivative
* If I differentiate 6x^2 I get 12x, if I differentiate minus 6x I get minus 6, and if I differentiate minus 12 I get zero
* Again, I've got a common factor of six so I'll pull that out and I'm left with 2x-1
* And now I can think about the SIGN of the second derivative
* And what do I know about that
* Well, the second derivative is negative if I plug in an x value which is less than 1/2 and the second derivative is positive if I plug in an x value which is bigger than 1/2
* All right, now I know a lot of information about the SIGN of the first and the second derivative, so I can use this information to say something about the function
* Let me look back to my preliminary graph that I made with just plugging in a few points
* All right, so here I plugged in a few points and what I'd like to be able to say now is where is the function increasing and decreasing
* And by looking at the sign of the first derivative I know that the function's increasing, decreasing, and then increasing
* Minus 1 and 2 are my critical point and in fact, they're local extrema
* This is a local maximum value, and this is a local minimum value down here, and I can also see that by considering the information given in the sine of the second derivative
* Since the second derivative's negative here, the functions concave down
* And since the second derivative is positive over here, the function is concave up
* And that makes this point into a local maximum and this point into a local minimum
* Alright, now that I've got all that information I can try to just fix the graph here filling it in
* So let's see, so I've got these points here and what do I know
* I know the function is increasing here, and now I know that it's decreasing here
* And I know that it's concaved down in this region
* Over the rest of the graph the rest concave up
* There's an inflection point here when x=1/2 and this point over here is a local minumum
* The function's decreasing by looking at the sign of the first derivative, until I get to two
* And then when I get to two, the first derivative tells me the function's increasing
* So there we go, I've drawn a graph of my function
* The point here is not to capture a perfect picture of the function
* It's like an impressionistic painting, the point is to capture all of the meaning all of the emotion of the function
* Compare that to a photograph which might be a perfectly accurate portrayal, but somehow misses everything that's essential
* So here's the graph that I drew in red, and here is a more perfect graph admittedly, that the soulless robot drew
* And you'll see that my graph really is just as good
* I mean, it captures all the qualitative information which is really what a human being cares about
* Functions increasing, decreasing, increasing
* You can see where it's concave down and where it's concave up
* And you can kind of see roughly where this function crosses the x axis
* Let's summarize the situation
* There's really 4 basic pieces that you're just gluing together when you're doing a lot of these curve sketching problems
* It depends on the SIGN of the first derivative, and the SIGN of the second derivative
* If the derivative is positive, and the second derivative is positive, then the function is increasing, and the slopes of the tangent lines are increasing
* If the function's derivative is negative but the second derivative is positive, that means although the function's decreasing, the slopes of those tangent lines are increasing
* We've got kind of complementary pictures over here when the second derivative's negative, here the function's increasing but the slopes of those tangent lines are decreasing, and here both the function is decreasing and the slopes of the tangent lines are decreasing
* A lot of the curve sketching problems amount to just gluing together these four basic pieces in the appropriate way.


--- SKIP ---: 01_what-is-a-function-which-is-its-own-derivative.en.srt


--- SKIP ---: 01_what-is-a-function-which-is-its-own-derivative.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-a-function-which-is-its-own-derivative.en_SENTbySENT.txt
* [MUSIC] Up until now, we've been considering the functions that you can get by starting with variables and numbers, and combining them using sums, products, quotients, and differences
* So we can write down, you know, functions like f(x)=x2+x/(x+1^)^10+x, all of this, -1/x
* But there's more things in heaven and earth that are dreamt of in your rational functions
* For instance, can you imagine a function f, which is its own derivative
* I'm looking for a functions, that if I differentiate it, I get back itself
* Now, if you're thinking cleverly, you might be able to cook up such a function very quickly
* What if f is just the zero function
* Or if I differentiate the zero function, differentiate a constant function, that's zero
* So this would be an example of function in its own deriviative
* But, that's not a very exciting example
* [SOUND] So let's try to think of a nonzero function, which is its own derivative
* How might we try to find such a function
* So to make this concrete, I'm looking for a function f, so if I differentiate it, I get itself and just make sure that it's not the zero function
* Let's have this function output one if I plug in zero
* Now, how could I rig this function to have the correct derivative at zero
* If the derivative of this function itself, the derivative of this function at zero should also be one
* Can you think of a function whose value at zero is one and whose derivative at zero is one
* Yes
* Here is a function, f(x)=1+x
* This function's value with zero is one, and this function's derivative at zero is also one
* But if the derivative of f is f, then the derivative of the derivative of f is also the derivative of f, which is also f
* So, the second derivative must be f as well
* So, if this function is its own derivative, the second derivative of f would also be equal to f
* Now, specifically, at the point zero, that means the second derivative of the function at the point zero would be the function's value with zero which should be equal to one
* is this function's second derivative at zero equal to one
* No
* If I differentiate this function twice, I just get the zero function, but I can fix this at least to the point zero
* If I add on x^/2, now, this function's derivative at zero is one and this function's second derivative at zero is one
* Since f is its own derivative, the third derivative of f must also be f
* No worries
* If the thid derivative of f is also equal to f, which is a consequence of the derivative of f being equal to f
* That means the third derivative of f at zero is equal to one, but this thing's third derivative is just zero
* But if I add on x^3/6, now, if I take the third derivative of this function and plug in zero, I get out one
* The fourth derivative of f must also be f
* Okay, yeah
* I gotta deal with the fourth derivative
* I'm out of space here, but no worries, I'll just get more paper
* Here, I've written down a function whose value at zero is one, whose derivative at zero is one, whose second derivative at zero is one, whose third derivative at zero is one, whose fourth derivative at zero is one
* And you can see, this is sort of building me closer and closer to a function which is its own derivative
* If I try to differentiate this function, what do I get
* Well, the derivative of one is zero, but the derivative of x is one, and the derivative of x^2/2 is x, and the derivative of x^3/6, well, that's x^2/2, and the derivative of x^4/24, well, that's x^3/6
* And yeah, I mean, this function isn't its own derivative, but things are looking better and better
* But the fifth derivative of f must also be equal to f
* Okay, yeah
* The fifth derivative
* I'll just add on another term, x^5/120
* And if you check, take the fifth derivative now of this function, its value at zero is one
* I've written down a function, so that if I take its fifth derivative at zero, I get one
* The sixth derivative of f must be equal to f
* The sixth derivative I am out of room, but here we, go
* Here is a polynomial whose value first, second, third, fourth, fifth and sixth derivative at the point zero are all one
* And you can see how this is edging us a little bit closer still to a function which is its own derivative, because if I differentiate this function, yeah, the one goes away, but the x gives me the one back, and the x^2/2, when I differentiate that, gives me the x
* X^3/6, when I differentiate that, gives me x^2/2
* X^4/24, when I differentiate that gives me x^3/6
* x^5/120, when I differentiate that, gives me x^4/24
* X^6/720, when I differentiate that, I've got x^5/120
* And now, of course, these aren't the same, but I'm doing better
* The seventh derivative must be equal to f
* To get the seventh derivative at zero to be correct, I'll add on x^7/5040
* The eighth derivative, I'll add on x^8/40,320
* The ninth derivative, I'll add on x^9/362,880
* Okay, okay
* This is, isn't working out
* We're not really succeeding in writing down a function which is its own derivative
* Let's introduce a new friend, the number e to help us
* Here is how we're going to get to the number e
* This limit, the limit of 2^h-1/h as h approaches zero is about 0.69, a little bit more
* On the other hand, this limit, the limit of three to the h minus one over h as h approaches zero is a little bit more than one, it's about 1.099
* If you think of this as a function that depends not on two or three, you could define a function g(x), right
* The limit as h approaches zero of x to the h minus one over h
* In that case, this first statement, the statement about the limit of two to the h minus one over h, that's really saying that g(2) is a bit less than one
* And, this statement over here, and if you think of this as a function g, this statement is really saying that g(3) is a bit more than 1
* Now, if you're also willing to concede that this function g is continuous, which is a huge assumption to make, but let's suppose that's the case
* If that's the case, I've got a continuous function, let's say, and if I plug in two, I get a value that's a little bit less than one, and if I plug in three, I get a value that's a little bit more than one
* Well, by the intermediate value theorem, that would tell me there must be some input so that the output is exactly one
* I'm going to call that input e
* In other words, e is the number, so that the limit of e^h-1/h as h approaches zero is equal to one, and this number is about 2.7183 blah, blah, blah
* Now lets consider the function f(x)=e^x
* So let's think about this function f(x)=e^x
* Now, what's the derivative of this function
* Well, from the definition, that's the limit as h approaches zero of f of x plus h minus f of x over h
* Now, in this case f is just e^x, so this is the limit as h approaches zero of e to the x plus h minus e to the x over h
* And this is e to the x plus h minus e to the x over h, so I can write this as e to the x times e to the h
* This is the limit then as h goes to zero of e to the x, e to the h minus e to the x over h, Now I've got a common factor of e to the x
* So I'll pull out that common factor and I've got the limit as h approaches zero of e to the x times e to the h minus one over h
* Now, as far as h is concerned, e to the x is a constant, and this is the limit of a constant times something, so I can pull that constant out
* This is e to the x time the limit as h goes to zero of e to the h minus one over h
* But I picked the number e precisely, so that this limit was eqal to one
* And consequently, this is e to the x times one, this is just e to the x
* Look, I've got a function whose derivative is the same function
* We've done it
* We've found a function which is its own derivative
* The derivative of e^x is e^x
* E^x is honestly different from this polynomials and rational functions
* We couldn't have produced that number e without using a limit
* E^x is the function that only calculus could provide us with.


--- SKIP ---: 01_is-there-anything-more-to-learn-about-derivatives.en.srt


--- SKIP ---: 01_is-there-anything-more-to-learn-about-derivatives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_is-there-anything-more-to-learn-about-derivatives.en_SENTbySENT.txt
* [MUSIC] We've been spending a ton of time onderivatives
* And at this point, you might be askingyourself, is there anything more to do with derivatives, andthe good news is, yes
* There's a lot more to see
* Right now I want to look at the chainrule
* The chain rule tells us how todifferentiate a composition of two differentiable functions and because lotsand lots of functions in the real world are written as compositions of differentiable functions, we'll then beable to differentiate just a ton more functionsby using the chain rule
* Now, looking ahead a bit further to see what else might be coming up on thehorizon
* Well, after the chain rule we're going tolearn how to differentiate functions like e tothe x, natural logarithm and then even further out we'regoing to learn how to differentiate trig functionslike sine and cosine
* And once we have all of that, and oncewe've got the chain rule, we'll be in a position to just differentiateanything you could write down by combining thosefunctions
* And then, even further out, as we lookeven further ahead in the course, we can see someapplications of differentiation
* Once we learn the mechanics ofdifferentiating, then we'll be able to get to theseapplications
* Things like, solving optimizationproblems
* All right, well
* Hang in there
* We think that the chain rule, butcomputations are going to get harder
* But, I know you can do it
* Good luck.


--- SKIP ---: 01_what-is-the-chain-rule.en.srt


--- SKIP ---: 01_what-is-the-chain-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-chain-rule.en_SENTbySENT.txt
* [MUSIC] Many of the functions that we'dmost like to differentiate are actually compositions of two different functions.This happens in the real world, too
* I mean, look, if you change the number offlowers, that's going to affect say how many rabbits there are around to you know,eat those flowers
* And if you change them with rabbits, that'll affect how manywolves that forest can support
* There's some really concrete examples of this.Here's a concrete example
* Suppose that f of x is the number of widgets producedwith an investment of x dollars, right
* With, with more money, maybe, you canbuild more widgets
* Suppose g of n is the income that you get by selling those nwidgets
* What you're probably really interested in is not exactly how manywidgets you produce
* What you'd like to know is, for a given investment, how muchmoney are you going to make, right
* Well, that's g of f of x minus your initialinvestment, right, g of f of x is how much money comes in when you sell the widgetsthat you produced with your initial investment of x dollars, right
* Thisquantity is measuring the profit on an investment of x dollars in widgetproduction
* We need some framework, some general picture that let's us understandhow one thing changing affects something else and how that thing's changing goes onto affect something else
* Specifically, if I've got some function h which is acomposition of two functions, g of f of x in this case, I'd like to know somethingabout the derivative of h
* I want to know how changing x affects f and then howchanging f goes on to affect g
* And I'd like some sort of formula that gives methat answer, right
* I'd like to know the derivative of h in terms of informationabout how x is changing affects f and how changing the input to g affects g
* I wanta formula for the derivative of h in terms of the derivatives of f and the derivativeof g
* This is exactly what the chain rule does
* What the chain rule says, is thatthe derivative of the composition is the derivative of g evaluated at f of x timesthe derivative of f evaluated at x
* Sometimes, people have the idea that thechain rule looks somehow, that you'd really expect the formula to look verydifferent
* I mean sometimes people think this formula looks a little bit weird, youknow
* I'm composing functions, but now it's the derivative of g composes just afunction f
* What's going on
* You might think that given the fact that thederivative of a sum is the sum of the derivatives
* You might be tempted to thinkthat the derivative of a composition should be the composition of derivatives,but that's not the case
* But the chain rule really is capturing what happens whenyou chain together these changes
* So let's think about this chain rule, thederivative of g of f of x is g prime f of x times f prime of x in terms of chainingtogether different changes
* I'm trying to calculate is how changing x changes g of fof x right
* This is the derivative of the composition
* What do I know
* Well, I knowhow changing x will change f of x, right
* This is what the derivative of f is, is,is measuring, right
* The derivative is the ratio of output change to input change.Now, in between here, what I have is the change in f of x will change g of f of xin some way
* This ratio of changes is really the derivative of g at the point off of x
* What is the derivative
* You plug in an input to the derivative to ask howwiggling that input would effect the output and that's exactly what this ratiois
* I'm asking how will f of x is changing affect g of f of x, right
* That's thederivative of g at the point that's wiggling, f of x.Well, if you think about it, now, if I just multiply these two things together,then I get the change in g of f of x divided by the change in x
* This is thechain rule, right
* If I multiply together g prime f of x and f prime of x, what I'mleft with is exactly what I want, the derivative of g of f of x
* You can seethis pictorially as well
* So here, I've drawn three number lines
* On the firstnumber line, I've drawn x and I imagine x is the input to f
* And on the secondnumber line, I've drawn f of x and f of x is now the input to g
* And on the lastnumber line, I've drawn g of f of x
* The essential question answered by thederivative is how changing x will affect g of f of x
* But since this is a compositionof functions, I'm going to analyze the effect of changing x and g of f of x instages, right
* I'm first going to see how this changing x affect f of x and how f ofx is changing affect g of f of x
* So let's imagine that I change x by a smallquantity
* I'm calling that small quantity h here, h is not a function, just somesmall number, the amount by which I'm wiggling the input
* Now, how is the outputaffected
* Well, that's exactly what the derivative measures
* Right
* The derivativeof f at x tells me how wiggling the input x would affect the output
* So f prime ofx, which is the ratio of output change to input change times an actual input changegives me a first order approximation of the output change
* So I imagine the outputis changing by about f prime of x times h
* Now, how does that change in value of f ofx affect g
* Well, I have to figure out how wiggling the input to g will affect theoutput of g and that depends on where I'm calculating the derivative
* I need tocalculate the derivative of g at the point f of x, because, f of x is the pointthat's doing the wiggling
* So, it's the derivative of g at the point f of x thattells me how wiggling the input around f of x would affect the output to g
* So it'sthat derivative times the amount by which the input changed, which is this quantityhere, f prime of x times h
* And when you look at it this way, you can see that foran input change to x of some small amount h, the output changes by about g prime fof x times f prime of x as much, which is exactly what the chain rule is telling meshould be the case
* Since this is the correct rule, that the chain rule reallyis the derivative of the outside at the inside times the derivative fu nction.Let's try to see a numerical example of this thing in action
* So as a numericalexample let's consider the function g of x equals x to the 4th power and the functionf of x equals 1 plus x to the 3rd power
* Andm maybe what I want to try to estimateis g of f of 1.0001, and now, approximately what is that equal to
* Well,it's not too hard to calculate g of, of 1, right
* What's f of 1
* Well, that's 1 plus1 cubed, well, that's 2
* So what's g of 2> Well, that's 2 to the 4th, well, that's16
* So I know that g of f of 1.0001 is going to be close to 16
* The question is,how is wiggling the input up to 1.0001 going to affect the output of thiscomposition of functions
* Well, I could do it in stages, right
* That's what the chainrule's telling me to do
* So I could calculate first the derivative of f at 1.Right
* And the derivative of f is 1 plus 3x squared, so the derivative of f at 1 is3
* And indeed, if I calculate f of 1.0001, that's about 2.0003 and a bit more
* Now, Iwant to try to calculate how changing the input to g will affect the output of g
* SoI should calculate the derivative of g and that's 4x cubed by the power rule, butwhere should I evaluate the derivative of g
* Your first temptation is to calculatethe derivative of g at 1, but that is not a good idea, because you're not wigglingthe input 1 to g
* What you're really should be calculating is the derivative ofg at 2, because it's this 2 that's going to be wiggling
* When you wiggle the inputto f, it's the output to f, f of 1, that's going to be changing, so you shouldcalculate the derivative of g there and what is that
* That's 4 times 2 cubed,that's 4 times 8, that's 32
* So what we're trying to calculate is g off of 1.0001 and we know that that's about g of, well, what's f of 1.0001
* It's about2.0003
* So what happens when I wiggle the input of g from 2 to 2.0003
* Well, thatshould be about the output of g at 2 which is 16 plus how much I change the input by,times the derivative of g at the point where the wiggli ng is happening, which is2 and that's 32
* And what's 16 plus 0.0003 times 32, that's 16.0096
* So g of f of1.0001 is about 16.0096
* And you can see this 96 just from the chain rule, right?The relevant thing to calculate is g prime of f of 1 times f prime of 1, right
* Thisis going to tell me how wiggling the input 1 affects the output and g prime of f of 1is 32, f prime of 1 is 3, and 32 times 3 is 96
* So, that's the chain rule and it'sgoing to take some time for the chain rule to really sink in
* But the chain rule issuper important for two very different reasons
* On the one hand, you've ta knowthe chain rule just to be able to compute derivatives
* A lot of the functions thatyou'll be asked to differentiate are actually compositions of differentiablefunctions, so you'll need to use the chain rule to finish those derivativecalculations
* But on the other hand, you've gotta know the chain rule just tounderstand how chained together changes work
* In the real world, a lot of thingschange, and those changing things affect other things, and those changing things,then go on to affect yet other things
* And you've got, got understand how thosechanges get composed together, in order to really understand how the real worldworks.


--- SKIP ---: 02_what-is-the-derivative-of-1-2x-5-and-sqrt-x-2-0-0001.en.srt


--- SKIP ---: 02_what-is-the-derivative-of-1-2x-5-and-sqrt-x-2-0-0001.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-derivative-of-1-2x-5-and-sqrt-x-2-0-0001.en_SENTbySENT.txt
* , I want to differentiate reallycomplicated functions
* As a concrete example take a look at the function f of xequals 1 plus 2x to the fifth power
* Let's try to differentiate this function
* Wecould approach this in a couple different ways
* First of all, I could just expand itout
* Alright
* So I'm just going to expand this out 1 to the fifth is just one, plusten x, plus 40 x squared, plus 80 x cubed, plus 80 x to the fourth, plus 32 x to the5th
* Now, it's just a polynomial so I can fearlessly differentiate it
* So, f primeof x, by differentiate this, the derivative of one is zero, the derivativeof ten x is ten, the derivative of 40 x squared is 80 x, and 240 x squared, 320 xcubed, and 160 x to the fourth
* Of course, if we're clever at this point, we can alsosee that this mess factors
* So it's sort of believable as a factor of ten here,since all of these coefficients end in a zero
* This is ten times one plus eight xplus 24 x squared plus 32 x cubed plus 16 x to the fourth
* What's way less obvious,I mean not obvious at all, is that this mess also factors
* It happens to be oneplus two x to the fourth power
* This is not an accident
* What if we insteadapplied the change rule to original problem
* So let's compute the derivativeto the change rule
* The first step is we're going to split up the function finto a composition of two functions, g and h, g here, the outside function is thefifth power function, and h, the inside function is one plus two x
* So if Icombine those two functions, save the composition, I get back f
* Now, I want todifferentiate f and, by the chain rule, that's the derivative of the outside, addthe inside function, times the derivative of the inside function
* In this case, whatis the derivative of the outside function
* The derivative of g is five x to thefourth
* So I'm going to take that but if evaluate it at h
* five h of x to thefourth multiply by the derivative of h
* What is the derivative of h
* Well, it'stwo
* Well, look what I got here
* I've got five, h of x is one plus two x to thefourth times two, that's ten times one plus two x to the fourth, that's exactlywhat we calculated before
* It's really nice example, because it shows that we'redoing the same calculation
* We're calculating derivative of the function oneplus two x to the fifth power, but we're doing it in two different ways,nevertheless, we get the same answer
* Somehow, mathematics is conspiring to beconsistent
* Okay, well, let's try another example
* Well, here's a more complicatedfunction, f of x equals the square root of x squared plus 0.0001
* What's thederivative of f
* We can't simply expand this function out, and in fact, if yougraph the function, you might think that the function is not differential, becausethe graph of the function has this sharp corner at the origin, but let's zoom inand see what this actually looks like if we zoom in close enough
* If we zoom inclose enough, the thing doesn't look like it has a sharp corner anymore
* It actuallylooks like it's curved and if we zoom in any further, the thing would look more andmore like a straight line
* What we're really seeing is the function isdifferentiable
* Now, we can verify this algebraically, we can use our derivativelaws, like a change rule, to actually calculate the derivative of this function.We'll differentiate this by using the change rule since this is really acomposition of two functions
* This is a composition of the square root functionand this polynomial, x squared plus 0.0001
* Alright, so the derivative of f isthe derivative of the outside function, which is the derivative of the squareroot, which is 1 over 2 square root And it's the derivative of the outsidefunction evaluated at the inside, which is x squared plus 0.0001
* I have to multiplyby the derivative of the inside function
* What is the derivative of x squared plus0.0001
* Well, that's the derivative of the x squared, since it's a constant and thederivative of x squared is two x
* So the dirivitave of f is one over two t imes thesquare root of x squared plus 0.0001 times two x
* I could make that a little bitnicer looking
* I could cancel these twos and write this as x over the square rootof x squared plus 0.0001
* What happens at zero
* So let compute the derivative atzero
* Well, if I plug in zero for x, I've got zero over zero squared plus 0.0001.The denominator is not zero, the numerator is zero, the derivative at zero is zeroand you can see that from the graph
* If I look at when x equals zero, the tangentline at that point is horizontal, the slope of that tangent line is zero
* Thederivative at zero is zero, and there's more awesome things that you can see bylooking at the derivative
* If you look at, say, the limit of the derivative as xapproaches infinity, that's the limit of this quantity, which is one, and the limitof the derivative as x approaches minus infinity is negative one and you can seethis visibly on the graph of the function
* If you plug in a really big number andlook at the tangent line there, that tangent line has slope close to one
* And,if you plug in areally negative number and look at the tangent line there, Thattangent line has slope close to minus one
* Our derivative rules are revealing factsthat are hidden
* This function looks like it's got a sharp corner, but we know, byapplying our differentiation rules, by using the change rule, that this functionis in fact differentiable
* And we know that if we zoom in close enough, the thinglooks like a straight line, the derivative rules really revealing this structure atvery small scales.


--- SKIP ---: 01_what-is-implicit-differentiation.en.srt


--- SKIP ---: 01_what-is-implicit-differentiation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-implicit-differentiation.en_SENTbySENT.txt
* , Sometimes you don't have a function, youhave a relation between two variables
* A classic example is x squared plus ysquared equals, say, 25
* The graph of the points in the plane that satisfy thisequation as a circle
* But that's not the graph of a function, right
* This graphfails the vertical line test
* For a given input value, say 4 in this case, there'smultiple y values which satisfy this equation
* So, I can't simply solve thisequation for y
* Nevertheless, if you pick a specific point like 4, 3, you might beable to find a function whose graph traces out that same curve
* So yeah, if I pick 4,3, there is a function, y equals the square of 25 minus x squared
* Which tracesout a piece of the whole curve, right
* I'm just ignoring the rest of this and thislittle tiny piece of the curve can be regarded as a function
* If I had picked adifferent point, then I'm going to pick a different function
* Instead of the squareroot of 25 minus x squared, if I wanted to stand down here, near the point 4, minus3, well then maybe I'd pick the function y equals negative the square root of 25minus x squared
* If I ignore the rest of this and I'm just looking at this curvehere, yet this curve by itself is a function
* If I ignore this, it satisfiesthe vertical line test
* This function is picking out a piece of the curve given bythis equation which is, yeah, only valid near the point 4, minus 3
* But maybethat's all I care about for the time being
* So, let's say there is a function,y equals f of x, that satisfies the original equation
* Well then, I can writethat down
* y equald f of x say satisfies the equation just means that x squaredplus f of x squared equals 25
* Now, I'm not saying that this gives me all of thesolutions, right
* The graph x squared plus y squared equals 25 is a circle fails thevertical line test
* There is no function that gives me all those outputs becausethere's multiple outputs for a given input
* All I'm saying is that I've gotsome function which traces out a piece of the whole curve
* Then, I candifferentiate
* So, this is true for a bunch of values of x that I candifferentiate this
* The derivative of this sum is the sum of the derivative, so thederivative of x squared is 2x plus the derivative of f of x squared
* I'm going touse a chain rule to do that
* It's the derivative of the outside function at theinside times the derivative of the inside function equals the derivative of 25,which is zero
* Now I can solve
* So, subtract 2x from both sides and I'm leftwith 2 times f of x times f prime of x equals negative 2x
* And then, I'll divideboth sides by 2 times f of x
* And I'll find that f prime of x is minus 2x over 2f of x, and I can cancel those 2's and just get minus x over f of x
* It seemslike a funny situation
* The derivative depends on more than just x
* It also hasan f of x
* in it
* Another way to say it is that the slope ofthe tangent line dy, dx, is negative x over y, right
* y is f of x
* And it doesreally seem a littie bit off putting initially in these kinds of calculationsthe slope of the tangent line depends on more than just x
* It's negative x over yfor this particular case
* But think back to the piacture for this case, right?The picture's a circle
* And what I'm saying is the slope of the tangent line isnegative x over y
* So, if you pick that point, say 4,3, and you ask what's theslope of the tangent line to the circle at the point 4,3 this equation is telling youthe slope is -4 thirds
* And yeah, that line is going down, the slope's negative.What's the slope of the tangent line to the curve at the point 4, negative 3
* Sameequation tells us that the slope there is 4 3rds
* And yeah, this line's going up.The slope of the tangent line is depending on more than just the x coordinate, right?You also need to know the y coordinate in order to know exactly what function you'reactually looking at near that point
* And that totally affects the slope of thattangent line
* To do all these sorts of calculations, the trick is the cha inrule
* For instance, if you're given somerelation like this, x squared plus y cubed equals 1
* You just got to make sure tothink of y as a function of x
* So that when you differentiate both sides, thederivative of the left hand side is 2x plus the derivative of y cubed equals thederivative of 1, which is 0, but what's the derivative of y cubed
* If y is afunction of x, then when you differentiate this, you've got to use the chain rule.It's 3 times the inside function squared, that's the derivative of the third powerfunction, times the derivative of the inside function
* I'll just write y prime.And as long as you're careful to use the chain rule, you'll be able to do thesekinds of implicit differentiation problems
* And you'll eventually solve fory prime in terms of both x and y
* The chain rule is our friend.


--- SKIP ---: 02_what-is-the-folium-of-descartes.en.srt


--- SKIP ---: 02_what-is-the-folium-of-descartes.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-folium-of-descartes.en_SENTbySENT.txt
* , The folium of Descartes is an algebraiccurve carved out by a certain equation
* By which equation
* This equation, x cubedplus y cubed minus 3axy equals 0
* It's the points on the plane that satisfy thisequation
* So, what's a folium
* Well, folium is justa Latin word for leaf, you know, the sorts of things that grow on trees
* So, where'sthe leaf
* Well, here's the leaf
* I've plotted the points on the plane thatsatisfy x cubed plus y cubed minus 9xy equals 0
* And this is the curve that Iget, and you can see it looks kind of like a leaf
* This is not the graph of afunction, it's really a relation
* x cubed plus y cubed minus 9xy is a polynomial intwo variables, in both x and y, in both
* I can't solve for x in terms of y
* Look,this graph fails the vertical line test
* For a given value of x, there'spotentially multiple values of y which will satisfy this equation
* So, what's thepoint of all these
* Well, once upon a time, Descartes challenged Fermat to findthe tangent line to this folium
* And Descartes couldn't do it but Fermat could.And now, so can you
* And you can do it with implicit differentiation
* So, let'suse implicit differentiation on this, thinking of y secretly as a function of x.So, the derivative of x cubed is 3x squared
* The derivative of y cubed, well,that's 3y squared times dy dx, that's really the Chain rule in action, minus,now it's got to differentiate this
* It will be 9 times the derivative x, which is1y minus 9x times the derivative of y, which is dy dx, and that's equal to 0.Alright, now I can rearrange this, the things with the dy dx, and the thingswithout the dy dx, and you gather it together
* So, 3x squared minus 9y plus,and the things with the dy dx term, 3y squared minus 9x dy dx equals 0
* Now, I'mgoing to subtract this from both sides
* So, I'll have 3y squared minus 9x times dydx equals minus 3x squared plus 9y
* And I'm going to divide both sides by this, soI'll have dy dx equals minus 3x squared plus 9y over 3y squared minus 9x
* And notethat we're calculating dy dx but the answer involves both x and y
* And you cansee, it's really working
* I can pick a point on this curve like a point 4, 2satisfies this equation
* Then, I can ask what's the slope of the tangent line tothe curve through the point 4, 2
* When I go back to our calculation of thederivative and if I plug in 4 for x and 2 for y, I get that the derivative is 4/5.And indeed, I mean, this graph is somewhat stretched, but, you know, yeah, I meanthat doesn't look terribly unreasonable for the slope of this line
* Problems likethis one, which once stumped the smartest people on earth can now be answered byyou, by me, by lots and lots of people
* Calculus is part of a human tradition ofmaking not just impossible things possible, but things that were once reallyhard much easier
* Well, in any case, there's plenty morequestions that you can just ask about different kinds of curves besides thisfolium of Descartes
* You can write down some polynomial with x's and y's, like ysquared minus x cubed minus 3x squared equals = 0 and then you can ask about thepoints, the x comma y's that satisfy this equation.And if you want to know the slope of the tangent line, use implicitdifferentiation
* The trick is just to use the Chain rule and to treat y as afunction of x.


--- SKIP ---: 01_how-does-the-derivative-of-the-inverse-function-relate-to-the-derivative-of-the.en.srt


--- SKIP ---: 01_how-does-the-derivative-of-the-inverse-function-relate-to-the-derivative-of-the.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-does-the-derivative-of-the-inverse-function-relate-to-the-derivative-of-the.en_SENTbySENT.txt
* , I often want to differentiate an inversefunction
* Say, I've got a function f
* The derivative of f encodes how wiggling theinput affects the output
* The derivative of the inverse function would encode howchanges to the output affect the input
* Here's a theorem that I can use to handlethis situation
* Here is the inverse function theorem
* I'm going to supposethat f is some differentiable function, f prime is continuous, the derivative iscontinuous
* And the derivative, at some point, a, is nonzero
* In that case, I getthe following fantastic conclusion
* Then the inverse function at y is defined forvalues of y near f of a
* So, the function f is invertable near a
* The inversefunction is differentiable for inputs near f of a
* And that derivative is continuousin your inputs near f of a
* And I've even got a formula for the derivative
* Thederivative of the inverse function at y is 1 over the original derivative, thederivative of the original function, evaluated at the inverse function of y.How can I justify a result like that
* Why should something like that be true
* One 1way to think about this is geometrically
* Here, I've drawn the graph with just somemade up function, y equals f of x
* What's the graph of the inverse function looklike
* Well, one way to think about this is that the inverse function exchanges theroles of the x and y axes, which is the same as just flipping it over, alright?What was the y-axis now, the x-axis, what, was the x-axis is now the y-axis
* And thisgraph here is y equals f inverse of x
* This is how you graph the inversefunction
* Alright
* So, let's go back to the original functionand if I put down a tangent line to the curve at some point, let's say thattangent line has slope m
* Well, what's the tangent line of the inverse function
* Thatwould be the derivative of the inverse function
* Well, if I flip over the graphagain to look at the graph of the inverse function, I can put down a tangent line tothe to the inverse function
* And that has slo pe 1 over m
* If m was the originalslope for the tangent line to the original function, 1 over m is the new slope to thetangent line of the inverse function
* Why 1 over m
* Well, that makes sense because Igot this graph by exchanging the roles of the x and y-axis, by flipping the paperover
* And that exchange is rise for run, and run for rise
* So, the slope becomesthe reciprocal of the old slope
* This slope business is reflected in thenotation, dy dx
* Som let's suppose that y is f of x, so x is f inverse of y,supposing that this is an invariable function
* If y is f of x, then f prime ofx could be written dy dx
* And if f is inverse of y, then the derivative of theinverse function at y, well, that's asking how's changing y change x could write thatas dx over dy
* Well, if you really take this notation seriously, what it lookslike it's saying, is that, dx dy, which is the derivative of the inverse function,should be 1 over dy dx, right
* The derivative of the inverse function is 1over the derivative of the original function
* But you have to think aboutwhere these derivatives are being computed
* So, maybe you believe that dx dyis 1 over dy dx, it makes sense that if you exchange the roles of x and y, thattakes the reciprocal of the slope of the line
* But where is this wigglinghappening, right
* dy dx is measuring how wiggling x affects y
* Wiggling aroundwhere
* Well, let's suppose that I'm wiggling around a
* So, I'm reallycalculating dy dx when x, say, is at a
* This is the quantity that records howwiggling x near a
* will affect y
* Well then, where's y wiggling
* Well, if x iswiggling around a, y is wiggling around f of a
* So, the derivative on this side isreally being calculated at y equals f of a
* And it's really necessary to keep trackof where this wiggling is happening in order to get a valid formula
* It'sactually easier to think about what's going on if we just phrase all of these interms of the Chain rule
* So, what do I know about the inverse function
* Well,here's f inve rse
* F of f inverse of x is just x
* Alright,what is the inverse function do
* Whatever you plug into the inverse function, itoutputs whatever you need to plug into f to get out the thing you plugged into theinverse function
* Alright
* So, this is true
* Now, if I differentiate both sides,assuming that f and f inverse are differentiable, then by the Chain rule,what do I get
* Well, the derivative of this composition is the derivative of theoutside at the inside times the derivative of the inside
* And that's equal to thederivative of the other side, which is the derivative of x is just 1
* Now, I'lldivide both sides by f prime f inverse of x and I get that the derivative of theinverse function of x is 1 over f prime of f inverse of x
* Is that a proof?Absolutely not
* The embarrassing truth is that this argument assumes thedifferentiability of the inverse function
* If this function, f inverse, isdifferentiable, then the Chain rule can be applied to it
* The Chain rule requiresthat the functions be differentiable
* Now, if the function is differentiable, thenthis Chain rule calculation tells me that the derivative inverse function is thisquantity
* But that's all predicated on knowing that the inverse function isdifferentiable
* How do we know that
* Well, that's actually the content of thistheorem, right
* The content of the inverse function theorem is not really thecalculation of the derivative of the inverse function
* It's really just thefact that the inverse function is differentiable at all
* That is a hugedeal, and it's not something that we can just get from the Chain rule
* Once we knowthat the inverse function is differentiable, then the Chain rule givesus this calculation
* But actually verifying if the inverse function isdifferentiable is really quite deep, that's why the inverse function theorem issuch a big deal
* The Chain rule requires that the functions I'm applying the changerule to be differentiable
* In contrast, the inverse function theorem is assertingthe differenti ability of the inverse function
* It's really saying much more,than just a computation of the derivative if the derivative exists
* It's actuallytelling me that the derivative exists
* I'm going to have to punt on saying much moreabout the proof of the inverse function theorem
* But nevertheless, we can nowapply the inverse function theorem to some concrete examples
* For example think aboutthe function, f of x equals x squared
* Well, what's the inverse function to this?Let's suppose the domain is just the nonnegative real numbers.Then, the functions invertible on the domain, and we know the name of theinverse is the square root of x
* What's the derivative of the original function?Well, we know that it's 2x, and the derivative is continuous and thederivative is not 0 provided that x is a positive
* This is all the stuff that weneed to apply the inverse function theorem
* Then, we know that the derivativeof the inverse function at x is 1 over the original derivative at the inverse of x.Now, the inverse fuction is the square root of x, so that's 1 over f prime of thesquare root of x, and what's f prime
* f prime is the function that doubles itsinput
* So, that's 1 over 2 square roots of x
* So, the derivative of the inversefunction, the derivative of the square root function is 1 over 2 square roots ofx, provided x is bigger than 0, right
* Just like before, this is a calculation ofthe derivative of the square root function
* We can also see thisnumerically
* So, the square root of 10,000 is 100, and you might ask what do you haveto take the square root of, to get at about 100.1
* Say, some numeric example.Well, think now about the functions that are involved here
* There's the squaringfunction and the square root function
* we saw the derivative of the square rootfunction is 1 over 2 square root x and the derivative of x squared, we already know,is 2x
* Where are we evaluating these functions
* Well, I'm evaluating the squareroot function at 10,000, right
* This is at x equals 10,000 
* And if I evaluate thatat 10,000, that's 1 over 2 times the square root of 10,000, that's 1 over 200.Where am I evaluating the other function, the x squared function
* Well there, I'mreally thinking of 100 as the input, so I'll evaluate that derivative at 100 and2x, when x is a 100 is 200
* And it's not too surprising, right, that 1 over 200 and200 are reciprocals of each other, because I'm calculating derivatives of a functionand the inverse function at the appropriate places
* Now, let's try toanswer the original question
* I'm trying to figure out, what do I have to take thesquare root of to get about 100.1
* Well, the ratio here is about 200 between theinput and the output
* So, if I want the output to be affected by 0.1, I should tryto change the input by about 200 times as much, and 200 times 0.1 is 20, so I shouldtry to change the input by about 20 and sure enough, if you take the square rootof 10,020, that's awfully close to a 100.1
* I hope that you'll play around withthese numbers
* All the conceptual stuff that we're doing, these theorems, I'm nottelling you these theorems to make numbers boring, right
* I'm telling you all thesetheorems to heighten your appreciation of the numerical examples.


--- SKIP ---: 02_what-is-the-derivative-of-log.en.srt


--- SKIP ---: 02_what-is-the-derivative-of-log.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-derivative-of-log.en_SENTbySENT.txt
* , In our quest for a function which withit's own derivative, we met e to the x
* Remember, the derivative of e to the x ise to the x
* What's the inverse function for e to the x
* What function undoes thatsort of exponentiation
* Well, we really don't have a name for that function yet,so we're just going to call it Log
* So in symbols, if e to the x is equal toy, then log y equals x, right
* Log is the inverse function for e to the,the log of something I must raise e to get back the thing I plugged into log
* Theselogs or logarithms are super important for a ton of reasons
* Take a look at this.Since e to the x plus y is e to the x times e to y, right
* This is the propertyof exponents, if you like
* There's a corresponding statement about log
* Log ofa times b is log of a plus log of b
* Or, a shorthand way to say that is thatlogarithms transform products into sums
* This is a big reason why we care so muchabout logs
* Once we've got this new function, log, we can ask what's thederivative of log
* So, if f of x is e to the x, the inverse function is log.If I want to now differentiate log, I can use the inverse function theorem
* So, thederivative of the inverse function is 1 over the derivative of the originalfunction evaluated at the inverse function of x
* Now, the neat thing here is that thederivative of e to the x is itself
* So, f prime is just f, and I'm left with f of finverse of x
* It's e to the log of x
* But log of x tells me what I have to plug intoe to get out the input, right
* f of the inverse function of f is just, it would bethe, the same input again
* So, this is 1 over x
* So, the derivative of log x isjust 1 over x
* And you can really see this fact on the graph
* Here's a graph of yequals log x
* And I should warn you right off the bat that the x-axis and the y-axishave totally different scales
* The x-axis goes from 1 to 100
* The y-axis in thisplot goes from 0 to 5
* it's going to make it not so easy to tell the exact values ofthe slopes and tangent lines, but you can see from this graph the importantqualitative feature
* That the graph is getting less and less slopey
* And if youlike, it's flattening out as the input gets bigger
* if I put down a tangent lineand I start moving the point that I'm taking the tangent line at to the right,you can see the tangent line slope is getting closer and closer to zero
* And, ofcourse, that's reflected by knowing the derivative of log x is 1 over x
* So, if xis really big, the tangent line at x is really close to zero in slope
* Think aboutlog of a really big number
* For instance, what's log of a million
* A log of amillion is about 13.815510
* And, of course, it keeps going
* I, it's anirrational number
* But, now the derivative of log, right
* Is 1 over its input
* So,what does that tell you that you might think log of a million and 1 is equal to?Well, the derivative tells you how much wiggling input affects the output
* So, ifI wiggle the input by 1, you expect the output to change by about the derivative.And yeah, log of a million and 1 is about 13.815511, right
* What's being affectedhere is in the millionths place after the decimal point, right
* It's the 6th digitafter the decimal point because it's being affected like a change of 1 over amillion
* All right
* I'm changing the output by about a millionth
* At thispoint, we can also handle logs with other bases
* So, let's suppose I want todifferentiate log of x base b, right
* This is the number that I'd raise b to, to getback x
* Well, there's a change of base formula for log
* This is the same as thederivative of, say, the natural log of x over the log of b
* But the log of b is aconstant, and the derivative of a constant multiple is just that constant multipletimes the derivative
* So, this is 1 over log b times the derivative of, here's anatural log of x
* But I know the derivative of the natural log of x, it's 1over x
* So, the derivative of log of x base b is 1over log b times 1 over x
* Or maybe another way to write this would be 1 overx times log b, if you prefer writing it that way
* e to the x is a sort of key thatunlocks how to understand the derivative of a ton of other exponential functions.For example, now that we know how to differentiate e to the x, we can alsodifferentiate 2 to the x
* So, let's suppose I want to differentiate 2 to thex
* Now, you might just memorize some formula for differentiating this
* But it'seasier, I think better, to just recreate this function out of the functions thatyou already know all the derivatives of
* So, in this case, let's replace 2 by e tothe log 2 to the x, right
* So, instead of writing 2 here, I've just written e to thelog 2, this is just 2
* But I've got e to the log 2 to the x and that's the same ase to the log 2 times x
* You know, this is a composition of functions that I know howto differentiate
* I know how to differentiate e to the, and I know how todifferentiate constant multiple times x
* So, by the chain rule, it's the derivativeof the outside function
* So, which is itself, e to the, at the inside function,which is log 2 times x, times the derivative of the inside function which inthis case is log 2 log x
* So, I'm just going to multiply by log 2
* Now, I couldkind of make this look a little bit nicer, right
* e to the log 2 times x, well,that's just 2 to the x times, again log 2
* So, the derivative of 2 to the x is 2 tothe x times log 2
* And, of course, 2 didn't play any significant role here
* Icould have replaced 2 by any other number and I'd get the same kind of formula
* WhatI hope you're seeing is that all of the derivative laws are connected
* Withpractice, you'll be able to differentiate any function that you build by combiningour standard library of functions and operations on those functions.


--- SKIP ---: 03_what-is-logarithmic-differentiation.en.srt


--- SKIP ---: 03_what-is-logarithmic-differentiation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-logarithmic-differentiation.en_SENTbySENT.txt
* ,, 
* I can cook up some really nastyfunctions, give them to you
* And then ask you to differentiate them
* For instance, Icould ask you to differentiate this function
* 1 plus x squared to the 5thpower, 1 plus x cubed to the 8th power, all divided by 1 plus x to the fourth,this to the seventh power
* In principle, there's nothing stopping you from plowingahead and computing the derivative
* You can totally differentiate this function.Right
* What's the derivative of this function
* Well, this function's a quotientso he needs the quotient rule
* The denominator of the quotient rule is theoriginal denominator squared
* So it's going to be the original denominator nowto the 14th power And the quotient rule, the numerator starts off with thederivative of the original numerator
* Now, the original numerator is a product
* SoI'll be able to do this derivative by using the, product rule and chain rule
* Soit's the derivative of the numerator imes the denominator
* And it keeps going,right
* Then I gotta subtract the, derivative of the denominator times thenumerator
* But, look, you can do this derivative just by careful application ofthe quotient rule, the product rule, the power rule, and the chain rule
* There isone thing stopping you, your sense of human decency
* It's just an awfulcalculation
* Nobody would want to do that
* So instead, I propose a trick
* But maybeit's not a trick, because it's a trick that fits into a general theme
* It'slogarithms
* Logarithms turn exponentiation into multiplication, and multiplicationinto addition
* Let's see how this helps us
* So here we go
* Instead of calling thisfunction f of x
* I'm jut going to call it y, because I'm getting ready to do a sortof implicit differentiation
* I'm going to first apply log to both sides of this
* AndI'll get log y
* And what's log of the other side
* Well it 's log of a quotient,which is a difference of logs, and logs of things to powers, which is that powertimes log of the base
* So this works out to 5 times log of 1 plus x squared plusThis log turns multiplication into addition
* 8 times log of 1 plus X cubedand this quotient becomes a difference, so, minus 7
* The 7 in the exponent, log 1plus x
* Now, we differentiate
* All right, so differentiating now, what's thederivative of log y
* Remember, y is secretly a function of x, so Idifferentiate log y
* It's the derivative of the outside, which is 1 over y, timesthe derivative of the inside, which, I'll write dy dx
* This is really an example ifyou like the implicit differentiation
* Alright, now I differentiate the otherside, 5, I just multiply it by 5 the derivative of log is 1 over, so 1 over theinside function and 1 plus x squared times the derivative of the inside functionwhich is 2x
* The derivative of 1 plus x squared is 2x
* All right, plus 8, and itsderivative log is 1 over at the inside function, 1 plus x cubed, times thederivative of this inside function, which is 3 times x squared, minus 7 over, thederivative of log is one over at the inside function, one plus x to the fourth,and the derivative of one plus x to the fourth is four x cubed
* We're almostthere
* So now, I just multiply both sides by y
* And I get that the derivative isthis thing calculated x y, y is this quantity
* I can write this a little bitmore nicely alright here's this 5 times 2x is 10x, 8 times 3 is 24, 7 times 4 is 28,and then I multiply by y
* So I found the derivative, here it is
* In general, thistrick logarithmic differentiation as it's called, works fantastically well forfunctions like these
* Rational functions that involve a lot of high powers.


--- SKIP ---: 01_how-can-we-multiply-quickly.en.srt


--- SKIP ---: 01_how-can-we-multiply-quickly.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-can-we-multiply-quickly.en_SENTbySENT.txt
* >> [music] Here's a fundamental question.How can I multiply numbers really quickly
* It's not like this is a particularly newproblem
* You can imagine somebody trying tomultiply 10, 15, 17 by 10, 20, 30, 35, 36, 37 and getting 500, 600 and 29.But you know, how would you ever do these kinds of calculations if you were trappedin a world filled with Roman numerals
* Thankfully, instead of Roman numerals,we've got place value
* Place value provides an algorithm foractually computing these multiplication answers.So, here we've got 17, here I've got 37
* If I want to do this multiplicationproblem, I just have to do this single digit multiplies.7 times 7 is 49
* 7 plus 4 is 11.3 times 7 is 21
* 3 plus 2 is 5.Add these numbers up, 629
* And that's exactly what I had here inRoman numerals
* What if the numbers were much, much biggerthan just 2 digit numbers
* What if the two numbers I wanted tomultiply each had 10 digits
* Well then, I've still gotta do all thesepara-wise multiplications
* Right down here, I'm going to end upwriting 100 digits
* At least 100 digits.Because for every pair of digits here, I've got to write down at least one digitdown here
* That's terrible.You know, and then I've got to add all of these things up before I before I'm ableto get the answer
* I mean that's a ton of work, right?You'd really hope that there'd be some way to speed this up.And there is a way to speed this up
* There's a ton of ways to speed upmultiplication
* Multiplication is such an importantoperation that humans have given it a ton of thought.We've really got a lot of different ways to try to make this faster, but maybe theeasiest way Is that of quarter squares
* So here's the trick.I'm going to use this table of quarter squares.This is n squared over 4, a quarter square, so here's n, here's the output.If I plug in 1, I get a quarter
* If I plug in 2, 2 squared over 4 is 1.3 squared over 4 is 2 and a quarter
* 4 squared over 4 is 4.5 squared over 4 is 6 and a quarter
* Okay, you can image I've got a really bigtable of these quarter squares
* Now, why does this help you multiply?We've also got this little algebraic fact
* A times b is a plus b squared over 4, thequarter square of a plus b minus a minus b squared over 4.So, instead of multiplying a and b, I'll add them together, look it up in thetable, take their difference, look it up in the table, and take the difference ofthose table values
* For instance, let's suppose that I want tomultiply 3 times 2
* I mean, this is a ridiculously easy case.But just to show off how it works
* Let's multiply 3 times 2.I'll add 3 and 2 and I get 5
* And I look it up in my table.And 5 squared over 4 is 6 and a quarter
* I take the difference, 3 minus 2 is 1.And if I look up 1 in my table, I get a quarter.And 6 and a quarter minus a quarter is 6
* Which is a product of 3 and 2.Quarter squares convert multiplication into an addition, a subtraction, two tablelookups and a final subtraction
* Let's try doing this on a much biggernumber
* Let's try to multiply 17 by 37 usingquarter squares
* So, the first thing to do is to figure outthe quarter square of 17 plus 37
* 17 plus 37 is 54.I've got a much bigger table of quarter squares here.Here's 54 on my table
* 54 squared over 4 according to my table is729
* Now, the next step is to look at thedifference of 17 and 37, which is 20, and look that up in my table of quartersquares
* Here's 20.And the quarter square of 20 is 100
* That's pretty clear.20 squared is 400, divided by 4
* So 100.Now what do I do to figure out the product of 17 and 37?Well, I'm going to take 729, I'm going to subtract 100, and I'm going to get 629,which is in fact the produce of 17 and 37
* But we did it using quarter squares, byjust adding the numbers together, taking their difference, looking up those numbersin the table and then taking the difference of the numbers in the table, Igot the product of these 2 numbers
* Admittedly, people don't talk too muchabout quarter squares nowadays
* What you've probably heard a lot moreabout is logarithms
* There's this property of exponents that eto the x times e to the y is e to the x plus y.The corresponding property of logs is that log of a product is the sum of the logs.The log of a times b is log of a plus log of b.You can use this property of logs to multiply very quickly provided you have alog table
* And I do have a table of logarithms.Here's my table
* Let's multiply 17 by 37.So, instead of looking up 17, I'm going to look 1.70 in my table and I find the logof 1.70 is about 0.23045
* Then, instead of looking up 37, I'm goingto look up 3.70 in my table, and the log of 3.70 is about 0.56820.I'm going to add together those two logs and I get 0.79865, and I just got to huntfor that number in my table
* Mercifully, the numbers are in order and Ifind that 0.79865 is right here in my table that's in the 9th column of the rowwhich starts with 6.2
* So the product of 17 and 37 must be 629.Why this works is that same basic fact about logs again.Logs convert multiplication into addition
* There's another way that we can exploitthis fact
* If I've just got two plain old rulers, Ican use the two rulers to add together numbers.Let's say, I want to add 3 and 2 together
* What I'll do is I'll put the 0 on the topabove the 2 on the bottom so that this distance is 2 units.On the top, the distance between 0 and 3 is 3 units.So, if I'm going to add 2 units to 3 units, I just read down and the answer is5
* If your 2 rulers, have a logarithmicscale, then you've just invented the slide rule.This is a logarithmic scale, so this distance, on the scale labeled D, startingat 1 and ending at this 7, this distance is log of 1.7.Now, next to that distance, I have to place a distance whose length is log of3.7
* Now I've placed the 1 on the scale labeledC, just above the 7 on the D scale
* The distance on the C scale from that oneall the way over here to 3.7 on the C scale, that's a distance which is reallylog of 3.7
* Since I've placed these two distances nextto each other, the total distance is just the sum of the logs, which is the log ofthe product
* So, here's the answer.Just below 3.7 on the top scale is what looks to be 6.3, just a little bit lessthan 6.3
* Now, I know the last digit of 17 times 37is going to be a 9
* So, the answer must be 6.29.For hundreds of years, these slide rules were state of the art for multiplying.So that you can join into this proud tradition, I encourage you to print outyour own slide rule, and try doing some multiplication problems on it.


--- SKIP ---: 01_how-do-we-justify-the-power-rule.en.srt


--- SKIP ---: 01_how-do-we-justify-the-power-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-do-we-justify-the-power-rule.en_SENTbySENT.txt
* , Remember back, remember back to thepower rule
* Well, what do the power rules say
* It's that the derivative of x to then, and some real number not zero, the derivative of x to the n is n times x tothe n minus one
* The power rule isn't just something we just made up
* It's aconsequence of the definition of derivative
* But how do we know it'sactually true
* Well remember, we've already worked this out when n is apositive whole number
* Then, the derivative of x to the n is the limit ofthis difference quotient
* This is the limit that calculates the derivative
* If nis a positive whole number, I can expand out x plus h to the n, and I get x to then plus n x to the n minus 1 times h plus things with lots of h's minus x to the nall over h
* Now, the x to the n and the minus x to the n cancel, the h herecancels this h here, and I'm left with a bunch of h's divided by h, there's still alot of h's in this
* And the limit of this constant, as far as h is concerned plus athing where h is in it, well, this goes to zero
* And I'm left with n times x to the nminus 1, which is the derivative of x to the n
* And this is a completely validargument and as long as n is a positive, whole number
* But there's plenty ofnumbers which aren't positive, whole numbers
* What if n equaled negative 1?Let's figure out the derivative of x to the minus first power
* Actually, thederivative of 1 over x
* This is a problem that we can attack directly using thedefinition of derivative
* Here, I've written the limit of the function of xplus h minus the function over h
* Now, to calculate this limit, I'll first put thispart in the numerator over a common denominator
* So, this is the limit as hgoes to zero, whole thing's over h
* But the numerator is now x minus x plus h,over common denominator for the things in the numerator, x plus h times x
* Now,what's x minus x plus h
* Well, in that case, this x and this x cancel
* And whatI'm left with is just negative h up there
* So, this is the limit as h goes to zero ofnegative h over x plus h times x all over h
* Great.Now, the h down here and the h up here cancel
* What am I left with
* I'm left withthe limit as h goes to zero of negative 1 over x plus h times x
* Now, how can I dealwith this
* Well, as h goes to zero, the numerator's just 1 but the denominator isapproaching x squared
* So, this limit is minus 1 over x squared
* What we'vecalculated here is the derivative of 1 over x, the derivative of 1 over x isnegative 1 over x squared
* Now, I can use this fact
* The fact that the derivative 1over x is negative 1 over x squared to compute using the change rule thederivative of 1 over x to the n
* This is a composition of two functions, thecomposition of the 1 over function and the x to the n function
* The derivative of 1over is negative 1 over the thing squared
* So, it's the derivative of the outsidefunction at the inside times the derivative of the inside function
* Thederivative of x to the n, if n says positive, whole number, I already knowthis, it's n times x to the n minus 1
* And x to the n squared is x to the 2 n
* So,I've got negative 1 over x to the 2n times n times x to the n minus 1
* Now, a minormiracle happens
* The x to the 2n and the x to the n minus 1, they're interacting, sothat I'm left with the x to the n plus 1 in the denominator, minus 1 times integerminus n in the numerator
* Now, this movie doesn't look so great
* But remember thatat 1 over x to the n is just another name for x to the negative nth power
* And this,if I rewrote this as x to a power, I could rewrite this as negative n times x to thenegative n minus 1 power
* And look
* What we've shown is the derivative of x tothe negative n is negative n x to the negative n minus 1
* This is verifying thepower rule holds even when n is a negative number
* Pretty good.We've done it now for all whole numbers
* But what about rational numbers
* So,here's a question
* How are the derivative of x to the 21/17 power is 21/17 times xto that power minus 1, 4/17
* Implicit di fferentiation to the rescue.Well, here's maybe a simpler case
* y is the derivative of x to the 1/17
* 1/17times x to the negative 16/17
* Well, let's set y equal x to the 1/17, and that meansy to the 17th power is x
* And I can apply explicit differentiation to y to the 17equals x
* So the differentiation precisely gets 17y to the 16 dy dx equals aderivative of x, which is 1
* Divide both sides by 17 times y to the 16th power andI get that dy dx is 1/17 times 1 over y to the 16th power
* But, y is x to the 1/17.So, dy over dx is 1/17 times 1 over y, is now x to the 1/17 seventeenth x to the16/17
* But, it's 1 over that, so I could write this as 1/17 times x to the negative16/17
* So now the chain rule finishes off the problem
* if I want to differentiate xto the 21/17 power, well that's the same as differentiating x to the 1/17 power tothe 21st power
* It's chain rule
* So that's the same as 21 times the inside, x to the1/17 to the 20th
* That's the derivative of the outside function versus the 21st powerfunction at the inside, times the derivative of the inside function
* Now,good news
* We calculated the derivative of the outside function
* This is 21 times xto the 1/17 to the 20th power times the derivative of x to the 1/17, which is1/17x to the negative 16/17
* well, this is 21 times x to the 20/17 times 1/17 x tothe negative 16/17
* And 20 minus 16 is 4
* It's 21 times x to the 4/17 over 17, it's21/17 x to the 4/17
* That's exactly what the power rule tells you when n is 21/17.We started off just knowing the power rule was true for positive whole numberexponents
* And now, after doing a little bit of work, we know that the power ruleholds for any rational exponent
* What about the function f of x equals x to thesquare root of 2 power
* Whoa
* What does that even mean
* It's a serious objection.What do I mean by a number raised to the square root of 2 power
* Well, what can Ido
* I can take x and I can raise it to the 1.4 power, by which I mean, I take xmultiplied by itself 14 times and then take the tenth root of that
* I can take xto the 1.41 power, by which I mean I take x multiplied by itself 141 times, and thentake the hundredth root of that
* And I can keep on going, right?If I want to take x to the 1.414 power, I'd multiply x by itself 1,414 times, andthen take the thousandth root of that
* If I were to take x to the 1.4142 power,right
* I take x and multiply by itself 14,142times and then take the 10,000th root of that number
* And I can keep doing this,and I'm getting closer and closer to the square root of 2
* And that's really whatthis function means
* It really means to take a limit of these functions I actuallyunderstand, functions where I'm taking x to a rational exponent
* We can handle thiswith a logarithm
* So, let's set y equals x to the square root of 2 power
* I want tocalculate dy dx
* So, the trick here is log
* So, I'm going to take a log of bothsides
* log of y is log of x to the square root of 2 power
* But log of something to apower is that power times log of the base
* So, I've got log y is the square root of 2times log x
* Now, I differentiate both sides and I find out that the derivativeof log y is 1/y dy dx, and the derivative of the other side is the square root of 2times 1/x
* Multiply both sides by y, and I've got dy dx is the square root of 2y/x
* But I know what y is
* y is the x to the square root of 2 power
* So, this isthe square root of 2 times x to the square root of 2 power divided by x
* In otherwords, it's the square root of 2 times x to the square root of 2 minus 1
* We'reusing logarithms to fill in the gaps in the quotient rule
* We're not just learninga bunch of derivative rules, we're actually learning why these rules work.Take a look
* The square root of 2 here plays no essential role in this argument.I could go back through this entire thing and replace the square root of 2everywhere I see it by the number n
* And what I'd see is that this logarithmargument is justifying the power rule
* The derivativ e of x to the n is n times x tothe 'n, n minus 1
* And so, we're really building the foundations of calculus
* Weare not just learning how to apply the rules to some calculations, we're learningto justify that these rules are the correct rules.


--- SKIP ---: 02_how-can-logarithms-help-to-prove-the-product-rule.en.srt


--- SKIP ---: 02_how-can-logarithms-help-to-prove-the-product-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-can-logarithms-help-to-prove-the-product-rule.en_SENTbySENT.txt
* , Remember back before, when we talkedabout the product rule
* You know, it goes like the derivative of f times g is thederivative of f times g plus f times the derivative of g
* It's a little bitmysterious considering that the product rule has a plus in it
* But we proved thispreviously, just by going back to the definition of derivative in terms oflimit
* And, calculating the necessary limit to show that, this product rule wasin fact valid
* We've already seen a proof for the products rule
* Originally wejustified the product rule by going back to the limit definition of derivative andmanipulating that limit
* But maybe that proof didn't speak to you, so now there'sanother trick that we can use
* We can use logarithms to replace the product with asum
* Let's see how
* So let's suppose that f of x is bigger than 0, and g of x isbigger than 0, say for all x
* I just want to do this for positive functions
* Okay.Now I'm going to use logs, so let's take the log of f of x times g of x
* And whatdo I know about logs
* Logs turn products into sums
* So the log of f of x times g ofx is the log of f of x plus the log of g of x
* I'm going to differentiate bothsides of this equation
* So the derivative log is 1 over, and by the chain rule,that's 1 over the inside function times the derivative of the inside function,which in this case is the derivative of f of x times g of x
* That's what I'd like tocompute
* What's the driv of the other side
* Well the derivative of the log is 1over, so 1 over the inside function times the derivative of the inside function,plus log of g of x is 1 over the inside function times the derivative of theinside function
* Now if I multiply both sides by f of x times g of x, whathappens
* Well if I multiply this side by f of x times g of x, I've then isolated thederivative of the product
* So this is just the derivative of f of x times g of x
* IfI multiply this side by f of x times g of x, f of x times 1 over f of x is just 1,but I'm left with a factor of g of x times f prime of x plus, and if I multiply thisterm by f of x times g of x, g of x times 1 over g of x is just one, but I'm leftwith an f of x, so f of x times g prime of x
* And look, this is the product rule
* Thederivative of the product is the, in this case, g of x times f prime of x plus f ofx times g prime of x
* So, I mean, the order's a little bit different, but it isthe product rule
* So we've justified the product rule another way using logarithms,but that raises a question, what's the point of having multiple proofs of asingle mathematical fact
* It's not as if having 2 different proofs of the productrule makes the product rule any more true
* What this argument has is in its favor isthat it's showing off a nice trick that you can do with logarithms
* There's atheme that products and quotients are much more complicated than sums and differencesArmed with logarithms, we can convert difficult products and quotients into mucheasier sums and differences, and that's a huge win for us.


--- SKIP ---: 03_how-do-we-prove-the-quotient-rule.en.srt


--- SKIP ---: 03_how-do-we-prove-the-quotient-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-do-we-prove-the-quotient-rule.en_SENTbySENT.txt
* , How do we prove the quotient rule
* Wellfirst, we should remember what the quotient rule says
* So, remember what thequotient rule says
* It says the derivative of f over g is the derivative of f times gminus f times the derivative of g all over the value of g
* Not the derivative of g.Just g of x squared
* But we haven't actually seen a proof of the quotientrule
* Why should the derivative of a quotient be governed by that crazy lookingformula
* Well, one way to justify this formula is to combine the chain rule andthe product rule
* So, we're trying to build our way up to the quotient rule sowe can first do the simplest possible case the quotient rule by hand if you like.What's the derivative 1 over x
* Well, 1 over x is just x to the minus first power.And if I differentiate this, that's the power rule
* We saw how to do that before.That's minus 1 times x to the minus second power
* Another way to write this is minus1 over x squared
* Now, if you weren't certain why the power rule held, you couldalso have calculated this derivative by hand by going back to the definition ofderivative
* This is actually how we justified the power rule for negativeexponents
* This limit, you can also calculate, is minus 1 over x squared.Knowing how to differentiate 1 over x is enough for us to differentiate 1 over g ofx by using the chain rule
* So, we're going to use the chain rule
* So, let me firstmake up a new function that's called f of x at function 1 over x
* So then f prime ofx is minus 1 over x squared
* The derivative that we just calculated
* Now,if I wanted to calculate the derivative of 1 over g of x
* Well, that's the same asthe derivative now of f of g of x, since I defined f to be the 1 over function
* Andby the chain rule, the derivative of this composition is the derivative of theoutside at the inside times the derivative of the inside
* The derivative of f isminus 1 over its input squared
* So, f prime of g of x is minus 1 over g of xsquared
* That's looking good
* That's like th e denominator of the quotient rule.Alright, times g prime of x
* so, the derivative of 1 over g of x is minus 1over g of x squared times the derivative of g
* Now, I've got the product rule
* So,if I can differentiate f and I can differentiate 1 over g of x, I candifferentiate their product which happens to be the quotient, f of x over g of x.So, I want to differentiate f of x over g of x, right
* I'm trying to head towardsthe quotient rule
* But I'm going to rewrite this quotient as a product
* It'sthe derivative of f of x times 1 over g of x
* Now, this is the derivative of productsso I can apply the product rule, which I already know
* And that's the derivative ofthe first times the second, plus the first times the derivative of the second
* But wecalculated the derivative of the second just a moment ago
* The derivative of 1over g of x is minus 1 over g of x squared times g prime of x
* So, I can put that inhere as the derivative of 1 over g of x
* It's minus 1 over g of x squared times gprime of x
* By rearranging this, I can make this look like the quotient rule thatwe're used to
* Let's aim to put this over a common denominator
* So, I could writethis as f prime of x times g of x over g of x squared plus, what do I have overhere
* Well, negative f of x g prime of x, the negative 1 f of x g prime of x, over gof x squared
* And I can combine these two fractions, f prime of x g of x minus f ofx g prime of x all over g of x squared
* That's the quotient rule, right
* We've gotto the quotient rule at this point
* And how is it we do it
* Well, think back towhat just happened
* I, I used the power rule to differentiate 1 over x
* Once Iknew the derivative of that, I could use the chain rule to differentiate 1 over gof x
* And once I knew the derivative of 1 over g of x, I could then use the productrule on f of x times 1 over g of x to recover the quotient rule
* What's theupshot here
* Why is it important that the quotient rule can be seen as anapplication of the chain rule and the product rule
* One reason is a pedagogicalone
* I think it's important for you to see that all these differentiation rules areconnected together
* I hope that will give you a better sense of the rules and, andmake them more memorable.


--- SKIP ---: 04_bonus-how-does-one-prove-the-chain-rule.en.srt


--- SKIP ---: 04_bonus-how-does-one-prove-the-chain-rule.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_bonus-how-does-one-prove-the-chain-rule.en_SENTbySENT.txt
* , The Chain rule is so important, it'sworth thinking through a proof of its validity
* You might be tempted to thinkthat you can get away with just cancelling
* What I mean is you might betempted to think that something like this works
* let's say you wanted todifferentiate g of f of x
* You might set f of x equal to y
* And then, you mightthink, well, what you're really trying to calculate is the derivative of g of y andokay
* And then, you might say, well, the derivative of g of y, that will be thederivative of g with respect to y times the derivative of y with respect to x, andthat's really the Chain rule
* I mean, this first thing is the derivative of g andthis other thing is the derivative of f just like you'd expect, and then you'retrying to say that you can just cancel, alright
* You're not allowed to justcancel
* I mean, the upshot here is just that dy/dx is not a fraction, alright
* Youcan't justify this equality by just canceling because these objects, the wayyou're supposedly doing the canceling, they're not fractions
* We need a moredelicate argument than that
* One way to go is to give a slightly different definitionof derivative
* Well, here's a slightly different way of packaging up thederivative
* The function f is differentiable at a point a, providedthere's some number, which I"m suggestively calling f prime of a, if thederivative of f at a, so that the limit of this error function is equal to 0
* Andwhat's this error function
* Well, it's measuring how far my approximation is thatI'd get using the derivative from the actual functions output if I plug in aninput value near a
* In some ways, that's actually a nicer definition of derivative,since it really conveys that the derivative provides a way to approximateoutput values of functions
* In any case, now, let's take this new definition ofderivative and try to prove the Chain rule
* Try to approximate g of f of x plush
* Try to discover the Chain rules
* So, I want to be able to express this in termsof the derivative s of g and f, at least, approximately, and then control the error.Well, I can do that for f because I'm assuming that f is deferential about thepoint x
* So, this is g of, instead of f of x plus h, f of x plus the derivative of fat x times h plus an error term, we should be calling error of f of h times h
* I'mgoing to play the same game with g
* This is g of f of x plus a small quantity
* Andif I assume that g is differentiable at the point f of x, then this is g of f of xplus the derivative of g at f of x times how much I wiggle by, which, in this case,is f prime of x h plus that error term plus an error term for g, which is theerror term for g
* And I have to put in how much I wiggled by, which, in this case, isf prime of xh plus the error term for f at h times h times that same quantity, fprime of xh plus the error term for f at h times h
* Alright, so that's exactly equalto g of f of x plus h and I'm including all of the error terms
* Now, we can expandout a bit
* So, this is g of f of x plus, you can multiply these two terms together,g prime of f of x times f prime of xh
* That's looking really good, because that'swhat the Chain rule is, right
* It's supposed to give me this as the derivativeof g composed with f
* Plus, I've got a ton of error terms now
* All those error termshave an h, so I'm going to collect all the h's at the end
* The first error term is gprime of f of x, this term here, times the error of f at h
* The next ones, plus theerror of g, at this complicated quantity, I was going to abbreviate hyphen, times fprime of x times h, I'm collecting all of these h's the end, plus the error term forg, at that complicated quantity, times the error for f at h, and all of that is timesh
* Alright
* Now, this is almost giving me the derivative of the composite functionprovided that I can control the size of this error term, right
* What I need toshow now is that the limit as h approches 0 of this error term is really 0, and theerror term, right, it's the part before th e times h, and it's g prime of f of xtimes the error term for f at h plus the error term for g times f prime of x, plusthe error term for g times the error term for f at h
* Now, why do I know that, thatlimit is equal to 0
* Well, I can do it in pieces, right
* It's the limit of the sum,so it's the sum of the limits
* and I know that this first term is 0 because it's gotan error f h term in it, and because f is differentiable, the error term goes to 0.I likewise know the same for this, alright
* This is, it also got an error fof h term in it
* The most mysterious term is this
* But if you think a little bitmore about it, the error of g at this hyphen thing, which I'm abbreviating thiswhole thing here, also goes to 0 as h goes to 0
* And that's another thing to knowthat the limit as h goes to 0 of this quantity is 0 which is then enough to saythat g of f of x plus h equals this quantity, actually implies that this isthe derivative
* So, here's what we've actually shown
* Suppose that f isdifferentiable at a point a and g is differentiable at the point f of a, thenthe composite function, g composed with f, is differentiable at a, with thederivative of g of f at the point a, equal to the derivative of g at f of a times thederivative of f at a.


--- SKIP ---: 01_what-are-derivatives-of-transcendental-functions.en.srt


--- SKIP ---: 01_what-are-derivatives-of-transcendental-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-are-derivatives-of-transcendental-functions.en_SENTbySENT.txt
* [MUSIC] We have learned how to differentiate justa ton of functions
* If we can differentiate two functions, wecan differentiate their sum
* We can differentiate their difference
* We can differentiate any polynomial
* If we can differentiate two functions, welearned about the product and the quotient rule, so we can differentiatetheir product and their quotient
* We've also seen how to differentiate e tothe x, and we know how to differentiatenatural log
* But there are still some functions that wecan't differentiate
* We can't differentiate trig functions yet
* We don't yet know how to differentiatesine or cosine, and that is now our task
* What is the derivative of sine
* What is the derivative of cosine
* Once we know those derivatives, we will be able to calculate, very complicatedexpressions involving trig functions
* Because we've already learned the changerule, which lets us differentiate thecomposition of functions
* So if we can just figure out what thederivative of sine of x is, and what the derivative of cosine of x is, then we'regoing to be able to differentiate all kinds of verycomplicated expressions
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_what-are-transcendental-functions.en.srt


--- SKIP ---: 01_what-are-transcendental-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-are-transcendental-functions.en_SENTbySENT.txt
* , Welcome back to Calculus One
* Andwelcome to week six of our time together
* Can you believe that we've been at theCalculus game for more than a month already
* And we've done a ton of stuff sofar
* Way back at the beginning of the course, we first met limits
* We exploredwhat it meant to evaluate a function near, but not at, a particular import point
* Andonce we have limits, we were able to define the derivative
* We explore howwiggling the input to a function would effect the function in some way
* Thatratio given by the derivative
* Then, we spent a lot of time focusing on how toactually compute the derivative
* Alright
* We learned all these derivatives rules ofthe product rule, and quotient rule last with the chain rule for actually computingderivative of functions
* And this week is no exception
* We continue that proudtradition of actually differentiating
* But in week six, we focus in on thetranscendental functions
* What are transcendental functions
* Now, most of thefunctions that we've been looking at thus far are really algebraic functions.They're, say, polynomials or rational functions, roots
* Transcendental functionsare functions that transcend algebra, like e to the x, or log
* Functions that wecouldn't have gotten to if all we had at our disposal was algebra
* Another greatexample of transcendental functions are sine, cosine, and tangent, thetrigonometric functions
* And if your not feeling super comfortable with trigfunctions, no worries
* We're going to review trig functions this week, as well.But by the end of this week, we're going to know how to differentiate those trickfunctions, and that sets us up for week seven
* And what happens in week seven?Applications of the derivative
* We're spending a ton of time focusing ontechniques of differentiation, and next week we'll see some applications
* The payoff is going to be huge
* Just one more week of calculations to get through, andthen we can see what all of this is used


--- SKIP ---: 02_why-does-trigonometry-work.en.srt


--- SKIP ---: 02_why-does-trigonometry-work.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_why-does-trigonometry-work.en_SENTbySENT.txt
* [music] What's trigonometry?Well here's the basic idea
* So I've got a bunch of right triangles,these are all right triangles, and this angle is the same in all of them, butthey're all different sizes
* So the side lengths are all different butthe ratios between the corresponding sides are the same.What do I mean
* Well, take a look at this big triangle.It's got some height that I'll label in, in orange, and it's got some width thatI'll label in blue
* Now the width of this triangle isn't thesame as this triangle, isn't the same as this triangle, isn't the same as thissmall triangle
* And the height of this triangle isdifferent than the heights of these three triangles.But look at the ratio of this height to this width.Alright, here's the height, here's the width, and if I double the width, Width.It's a little bit more than the height
* In other words the height is just a littlebit less than the twice the width and that's true for all of these triangles.The ratio of their heights to their widths are all the same, even though they'redifferent sizes
* That's the key fact that makestrigonometry work
* If you just draw some random righttriangle with given angles, it doesn't really make a lot of sense to askquestions about the side lengths, it really depends on how big the triangle youdrew
* But it does make sense to ask questionsabout the ratios of side lengths, those only depend on the angles.So we can give names to these ratios
* We call the sine of theta as the ratiobetween the height and the hypotenuse
* So if you like, the opposite side andhypotenuse
* So y over r in this diagram.The cosine of theta is the ratio between the adjacent side and the hypotenuse ofthe right triangle
* It's x over r in this picture.And the tangent of theta
* That's the opposite side over the adjacentside, it's y over x in this picture because the sine, cosine, and tangent ofthis angle theta
* And they're all just defined in terms ofratios of side lengths
* Now that we've got a definition of sine.We can, for instance, calculate sine of pi over 5.If we build a triangle, any right triangle with an angle of measure pi over 5.I built a right triangle
* And this angle is pi over 5.I can use my little ruler to measure the hypotenuse.The hypotenuse here is about 25.2 centimeters.And I can measure the opposite side, and the opposite side's about 14.8centimetres
* And sine is the opposite side over thehypotenuse, which means sine of pi over five is about 14.8.Over 25.2, which is about 0.59
* .


--- SKIP ---: 03_why-are-there-these-other-trigonometric-functions.en.srt


--- SKIP ---: 03_why-are-there-these-other-trigonometric-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_why-are-there-these-other-trigonometric-functions.en_SENTbySENT.txt
* [music] So we know about sine and cosinebut what about all those other funny trig functions?So maybe we already know about sine and cosine, we saw tangent already too.But tangent could be defined in terms of sine and cosine as sine theta over cosinetheta
* Cosecant is just defined to be 1 over sinetheta
* Secant is 1 over cosine theta andcotangent is 1 over tangent theta
* What's so special about those 6 functions?I mean why we'd have a function called cosecant if its just 1 over sine theta.Why don't we always just try 1 over sine theta.For that matter why even have a function called tangent if you can compute tangentin terms of sines and cosines
* It doesn't seeming like we need all ofthese functions
* To make matters worse, there's even otherfunctions that practically no one knows about anymore.In addition to these, there's the haversine function which is just definedto be sine squared of the angle over 2
* I mean you really don't need haversineonce you've got sine
* Considering that most of these functionscan be defined in terms of other ones, the reason for studying, you know, these 6trig functions isn't really mathematical
* You don't really need cosecant if you'vegot sine
* The reason for emphasizing these 6 trigfunctions is cultural
* These are the functions that people arelikely to see when they open some technical manual and knowing about thesefunctions can sometimes give you the right intuition for how to attack a problem.Because sine and cosine are the legs of a right triangle with angle theta andhypotenuse length 1 just by the Pythagorean theorem we get this that sinesquared plus cosine squared is equal to 1
* Now if you believe this identity and youcould divide this identity by cosine squared you get sine squared over cosinesquared plus cosine squared over cosine squared is 1 over cosine squared.Now because we've got all these other functions I could rewrite sine squaredover cosine squared as tangent squared, cosine over cosine is 1, and 1 over cosinesquared is secant squared
* And this is maybe an example of howknowing about the other functions can be helpful.Its a little bit easier to internalize this identity, I mean if you walk aroundand you happen to notice that secant squared you can think always going toplace over tangent squared plus 1
* Then say trying to internalize this middleidentity
* This also a lovely geometric picture thatkind a sells you on an idea that these 6 trig functions have some special role.For example, here is a unit circle and I've drawn an angle of measure theta andwe know what some of the lengths in this picture are.This length across the bottom here is cosine theta.And this length here, the height of that right triangle is sine theta.But it turns out that the other 4 trig functions are also encoded in the lengthsof other relevant lines in this diagram
* For instance this line here has lengthtangent theta and this line between the point and the y axis has length cotangenttheta
* And if you measure on the bottom here thelength from the origin to where this tangent line crosses that has lengthsecant theta
* And, if we measure over here, from theorigin to where that tangent line crosses the y axis, that segment has lengthcosecant theta
* So when you put all these functions downwe've got cosine and sine but we've also got very visibly cotangent, tangent,secant, and cosecant
* And the secant is measuring you knowsomething that's crossing the circle and the tangent is really measuring the lengthof part of this tangent line
* And if we take this picture and we gofader you won't get idea of how all the trig functions vary together.For instance by, by looking at this picture with theta moving you can get asense of how these functions are moving together.For instance, tangent and secant are moving together right when tangent isreally big, secant is really big
* And conversely when cotangent is reallysmall, cosecant is you know small, close to 1.They can use some idea as to why tangent is called tangent.Why is sine called sine
* So sine comes from this Latin word sinus,you know, like the thing in your nose
* It's like a opening, and if like that asan [inaudible] device you can remember that sine is measuring this side of theright triangle because you can imagine the right triangle sort of opens up in thatside.


--- SKIP ---: 01_what-is-the-derivative-of-sine-and-cosine.en.srt


--- SKIP ---: 01_what-is-the-derivative-of-sine-and-cosine.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-derivative-of-sine-and-cosine.en_SENTbySENT.txt
* [music].Once, we believe that sine and cosine are important functions, they're all about theconnection between angles and lengths
* Well, then we want to apply our usualcalculus trick
* What happens if I wiggle the input to sineand cosine
* You might think about trigonometry asbeing something about right triangles
* But, here, I've drawn a picture of acircle and you can rephrase all this stuff in terms of just geometry of the unitcircle
* So this is the unit circle.The length of this radius is 1 and I've got a right triangle here and this angleis theta
* That means this base here has like cosinetheta and the height of this triangle is sine theta.The coordinates then, or this point on the unit circle are cosine theta sine theta.Now, let's make that angle just a little bit bigger.Let's suppose that I make this angle just a big bigger, and instead of thinkingabout theta, I'm thinking about an angle of measure theta plus h and that meansthis angle in between has measure h
* We'll do a little bit of geometry tofigure out how far that point moved when I wiggled from theta to theta plus h.So let's think about this point here and let's draw the tangent line to the circleat that particular point
* Well, I'm going to draw a little tinytriangle, which is heading in the direction of that of that tangent line.And, so that it's tangent to the circle, the hypotenuse of that little tiny righttriangle here in red will be perpendicular to this line here.I can actually determine the angles in that little, tiny right triangle.So we go this big right triangle down here, and just because its a triangle,this angle theta plus this angle in here plus this right angle have to add up to180 degrees
* But I've also got a straight line here andthat means that this top angle plus this right angle plus this mystery angle mustalso add up to 180 degrees
* Well, this plus this plus this is 180degrees
* And this plus this, same right angle, plusthis mystery angle add up to 180 degrees
* That means that, that mystery angle andthat little tiny right triangle must also be theta.I'd also like to know the length of the hypotenuse of the little tiny triangle.Radians save the day
* How so?Well, I want to know the length of this little piece of arc.What else do I know
* I know this is a unit circle.And I know this angle here is h in radians.And the definition of radiance means that this little length of arc here has lengthh
* Now, let's put my tiny right triangle backthere
* I'm going to have the hypotenuse of thatlittle right triangle also be h
* It's going to be close enough, right,because this little piece of curved arch and this straight line are awfully close.Now that I know the length of the hypotenuse and the angles in that righttriangle I can use sine and cosine to determine the side lengths of the othertwo sides
* So I've got a little tiny right triangle,hypotenuse h, that angle there is theta, and that means that this vertical distancehere is h times cosine theta
* And the horizontal distance of that littletiny red triangle is h sine theta
* Okay.So how much did wiggling from theta to theta plus h move the point around thecircle
* So the original point here from angletheta had coordinates cosine theta sine theta.And the point up here which I got when I wiggled theta up to theta plus h, thatpoint has coordinates cosine theta plus h sine theta plus h.So how much did wiggling from theta to theta plus h move the point?Well, if I use this little right triangle as the approximation, sine theta increasedby about H cosign data, and cosign data decreased by about h sine theta.We're now in a position to make a claim about the derivative.In other words, from the picture, we learned that sine theta plus h is aboutsine theta plus h cosine theta
* And cosine theta plus h is about cosinetheta minus h sine theta
* And as a result, we can say something nowabout the derivatives
* How does changing theta affect sine?Well, about a factor of cosine theta compared to the input.So the derivative of sine is cosine theta
* And how does changing theta affect cosine?Well, about a factor of negative sine
* So the derivative of cosine is negativesine
* Maybe you don't find all this geometryconvincing
* Well, we could go back to the definitionof derivative in terms of limits and calculate the derivative of sin directly.So if I want to calculate the derivative of sin using the limit definition of thederivative, well, the derivative of sine would be the limit as h approaches 0 ofsine theta plus h minus sine theta over h
* The trouble now, is that I've gottasomehow calculate sine theta plus h
* How can I do that?Well, you might remember, there's an angle sum formula for sine.Sine of alpha plus beta is sine alpha cosine beta plus cosine alpha sine beta.If I use this, but replace alpha by theta and beta by h, I get this.Sine of theta plus h can be replaced by sine theta cosine h plus cosine theta sineh
* So let's do that.So, the derivative is the limit as h approaches zero of, instead of sine thetaplus h, it's sine theta times cosine h
* This first term, plus cosine theta sine hminus sine theta from up here and this whole thing is divided by h.So, this is sine theta plus h minus sine theta all over h.Now, I can simplify this a bit
* I've got a common factor of sine theta, soI can pull that out
* This is the limit as h approaches zero,pull out that common factor of sine theta
* What's left over is cosine h minus 1 overh plus, I've still got this term here, cosine theta sine h over h.I'll write that as cosine theta times sine h over h.All right
* So this limit calculates the derivative ofsine
* Now, it's written as a limit of a sum,which is a sum of the limits, provided the limits exist.So, I can also note that sine theta and cosine theta are constants.Right, h is the thing that's wiggling, so I can pull those constants out of thelimits as well
* So what I'm left with is sine theta.Times the limit as h approaches 0 of cosine h minus 1 over h.Plus cosine theta times the limit as h approaches 0 of sine h over h.Now, how do I calculate these limits
* Well, we've got to remember way back towhen we were calculating limits a long, long time ago.We can calculate these limits by hand, using say, the squeeze theorem.And it happens that this first limit is equal to 0 and the second limit is equalto 1
* So I'm left with 0 plus cosine theta.So, this is a limit argument, back from the definition of derivative that thederivative of sine is cosine
* So, regardless of whether you think moregeometrically or more algebraically, the derivative of sine is cosine and thederivative of cosine is minus sine
* Now, once you believe this, there is somesort of weird things you might notice, like what if you differentiate sine awhole bunch of times
* So the derivative of sine is cosine andthe second derivative of sine, is the derivative of the derivative.It's the derivative of cosine which is minus sine.And the third derivative of sine is the derivative of the second derivative andthe derivative of minus sine is minus cosine.And the fourth derivative of sine, well, that's the derivative of the thirdderivative, which is minus cosine
* And the derivative of a cosine is minussine
* So, the derivative of minus cosine issine
* So the fourth derivative of sine is sine.So that's kind of interesting
* If you differentiate sine four times, youget back to itself
* And we already know a function that if youdifferentiate just once, it spits out itself again, e to the x is its ownderivative
* So as sort of a fun challenge, you mighttry to find a function f, so that if you differentiate it twice, you get back theoriginal function, but if you differentiate it only once, you don't getback the original function
* And if you can do this, you can ask thesame question for even higher derivatives
* We know a function whose fourth derivativeis itself, but none of the earlier derivatives are the function again.Can you find a function whose third derivative is itself, but the first andsecond derivatives aren't the original function?That's a fun little game to play, anyway, it's a little challenge for you to try tofind such a function.


--- SKIP ---: 02_what-is-the-derivative-of-tan-x.en.srt


--- SKIP ---: 02_what-is-the-derivative-of-tan-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-derivative-of-tan-x.en_SENTbySENT.txt
* I want to differentiate tangent theta
* How am I going to do this
* Well, hopefully you remember that tangent theta is sine theta over cosine theta
* Why is this
* If you think back to the business about the right triangles, right, sine is this opposite side that I'm calling y over the hypotenuse
* And cosine is this adjacent side whose length I'll call x over the hypotenuse
* I'll call this angle theta
* Then sine theta is y over r, and cosine theta is x over r, so this fraction can be simplified to y over x
* That's the opposite side over the adjacent side
* That's tangent of theta
* So good
* I can express Tangent theta as sin theta over cosine theta, how does that help
* Well, I know how to differentiate sine and cosine, and by writing tangent this way, tangents now a quotient, so I can use the
* Quotient rule
* All right, so I'll use the quotient rule, and the derivative of tangent theta is the derivative of the numerator, which is cosine, times the der, denominator, which is just cosine, minus the derivative of the denominator, which is minus sine, times the numerator, which is sine
* And this whole thing is over the denominator squared, cosine squared theta
* Now, is this very helpful
* Well, I've got cosine times cosine, so I can write that as cosine squared theta
* And here I've got minus negative sine theta times sine theta, so that ends up being plus sine squared theta
* And the whole thing is still being divided by cosine squared theta
* Can I simplify that at all
* Well cosine squared plus sine squared, that's the Pythagorean identity
* That's just one
* So I can replace the numerator with just one, still over cosine squared theta
* And one over cosine squared theta, well, one over cosine is called secant, so this is really secant squared theta
* 
* So what all this shows is the derivative of tangent theta is second squared theta
* A moment ago we did a calculation using the quotient rule to see that the derivative of tangent theta is second squared theta
* And now I want to see how this plays out in some concrete example to get a, a real sense as to why a formula like this is true
* So here's a couple triangles
* They're both right triangles and the length of their hypotenuse is the same
* This angle I am calling alpha, let's this be a little bit less than 45 degree
* And this angle I am calling beta, and it's more than 45 degrees
* Now what you can say about the Secant of alpha and the Secant of beta
* You know, the Secant of alpha is definitely bigger than one
* I mean, what's the Secant
* It's this hypotenuse length divided by this length here
* And that's bigger than one
* How does it compare to beta
* Well, the secant of beta is quite a bit bigger than the secant of alpha, and why is that
* Well, the secant of beta is this length here, the hypotenuse, divided by this width, but this triangle is quite a bit narrower than this triangle
* So the secant has the same numerator, the hypotenuse, the same length, but the denominator here is quite a bit smaller, and if the denominator's a lot smaller, then the ratio, which is the secant, is quite a bit bigger
* Some of the secan of beta is bigger than the secan of alpha, and the secan of alpha is bigger than one
* And that means that secan squared alpha is also bigger than one
* And secan squared alpha is less than secan squared beta
* And the significance of that is right here, the derivative of tangent theta is secan squared theta
* So what does this mean
* Well, this, this is telling me how wiggling theta affects tangent
* It affects it like a factor of secant squared theta
* So in this example, where secant squared beta is a lot bigger than secant squared alpha, the effect of wiggling beta on the tangent of beta should be a lot larger than the effect of wiggling alpha on the tangent of alpha
* And you can see that
* Let me draw a triangle, where I've wiggled the angle alpha up a little bit
* I've made it a little bit bigger
* But I'm going to make the same hypotenuse
* All right, so this hypotenuse length is the same as this length, but I've made the angle a little bit bigger
* And how is the tangent of the slightly larger alpha compared to the tangent of alpha
* Well, the tangent of the slightly larger alpha is bigger than tangent alpha, but not by all that much
* Now compare that to when I wiggle beta up by the same amount
* I make beta a little bit bigger
* Right
* So I make beta a little bit bigger by the same amount that I made alpha larger
* And I think about how that affects the tangent of beta
* The tangent of beta is this height divided by, divided by this width
* And you can think about it, I mean this, this height maybe isn't increasing a whole lot
* But the width of this triangle is getting quite a bit narrower
* And because it's the ratio of that height to that width the tangent of the perturbed value of beta is quite a bit larger than the tangent of beta
* And you can, you know it's reflected in the fact the secant squared beta is a lot larger than secant squared alpha
* So these, these kind of facts, right
* The fact that the derivative of tangent is secant squared theta you, you can really get a sense for why these things might be true by thinking about triangles and how wiggling the angle will affect certain ratios of sides of the triangles
* But, if this seems a little too abstract we can kind of pull back a little bit and do do a numeric example next
* You know, and maybe the numerical example is sort of another way to see a formula like this in action
* Let's do a numerical example to get a sense as to what you might do with the fact that the derivative of tangent is secen squared
* Here's an example, let's try to approximate the value of tangent of 46 degrees
* Why is this an interesting example
* Well, we know the tangent of 45 degrees exactly, all right
* And figure that out by looking at a triangle, here's the angle, 45 degrees, a right triangle, because the an, angles add up to, 180 degrees
* So it's 45 plus 90 plus what
* Well, this must also be 45
* It's an isosceles triangle now, so these two sides are the same
* A tangent is the ratio of this side to this side because they are equal that ratio was one
* So I know the tangent of 45 exactly
* It's one
* But I am trying to figure out an approximation for the tangent of 46 degrees, the derivative tells me how wrigly an input affects the output, so I can use this fact and the fact that I know the derivative to try to approximate the tangent of 46
* In particular the tangent of 46 degrees is the tangent of 45 plus one degree
* And here you can see how I am perturbing the input a bit
* And this is exactly what the derivative would tell me something about
* A little bit of bad news, the derivative of tangent is only secant squared if I do the measurement in radians
* If I convert this to a problem in radians
* With radians, says the tangent of pi/4, which is 45 degrees, plus with one degree in radians, is pi/180 radians, right
* This is what I want to compute
* I want to compute the tangent of pi/4 plus pi/180
* And I'll do that with approximation using the derivative
* So according to the derivative this is about the tangent of pi over four, which is the tangent of 45 degrees, it's one
* Plus the derivative of pi over four, which is secant squared pi over four
* Times how much I wiggled the input by, which is pi over 180
* I know the tangent of pi over four
* It's one
* What's the secant of pi over four squared
* Well, if I pretend that these sides have length one, by the pythagorean theorem, this side must have length square root of two
* The secant is hypotenuse over this width
* So the secant of pi over four is square root of two
* So secant squared pi over four is square root of two squared, which is two times pi over 180
* Now if you know an approximation for pi, you can compute two times pi over 180 plus one
* And this is approximately 1.0349, and it keeps going Pi's irrational
* And this is not so far off of the actual value
* If we actually compute tangent of 46, the actual value is about 1.0355 and it keeps going
* AndР вЂњРІР‚С™Р вЂєРІР‚РЋР вЂњРІР‚С™Р вЂ™Р’В 1 0355
* is awfully close to 1.0349
* So we've successfully used the derivative to approximate the value of tangent 46 degrees.


--- SKIP ---: 03_what-is-the-derivative-of-sin-x-2.en.srt


--- SKIP ---: 03_what-is-the-derivative-of-sin-x-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-derivative-of-sin-x-2.en_SENTbySENT.txt
* [music].Let's combine the change rule and the derivative of sign to differentiate aslightly more complicated function
* Let's try to differentiate sine of xsquared
* We can realize this function as thecomposition of two functions
* I can write sine of x squared as thecomposition of f and g, where f is the sine function and g is the squaringfunction
* Now, how do I differentiate a compositionof two functions
* I use the chain rule.So I differentiate f and the derivative of f is cosine x, where the derivative ofsine is cosine
* And the derivative of g is just 2x.So now I want to differentiate the composition of f and g and that's by thechain rule f prime of g of x times g prime of x.In this case, f prime is cosine, so it's cosine of just g of x, which is x squaredtimes the derivative of g, which is 2 x
* So, the derivative of sine x squared withrespect to x, is cosine of x squared times 2x.Honestly, this is a pretty neat example
* In magnitude, this function, sine of xsquared, is no bigger than 1
* And yet, what do we know about thisfunction's derivative
* Well, the derivative of sine of x squaredis cosine of x squared times 2x
* And that function can be as large as youlike
* You can make cosine of x squared times 2xas big as you want, as long as you choose x appropriately.So what we have here is a function which isn't very big.The function's value is no bigger than 1 in magnitude, but the function'sderivative is very large
* And you can see that on the graph.The values of this function really aren't that large.The values are all hugging zero
* But the derivative, the slope of thetangent line is enormous
* Look over here.If you imagine a tangent line, that tangent line is going to have enormousslope
* The derivative over here is going to bevery large
* In spite of the fact, that the actualvalues of the function really aren't that large.This actually provides another lesson
* Just because 2 functions are nearby invalue, doesn't mean that their derivatives are anything close to each other.For instance, here is the graph of the cosine function.And here is the graph of a function sine of x square over 10 plus cosine of x.Since sine of x squared is between minus 1 and 1, this differs from the cosine by nomore than a tenth
* And, yeah, you can see the graph is reallyclose to the graph of cosine and yet this graph is way more wriggly.Let's zoom in and we can see the same sort of thing.Here's a zoomed in copy of just a cosine curve.And here's what happens if you zoom in on this other function.And in terms of the value, this other function really isn't different fromcosine very much
* But in terms of derivative, this functionis totally different than cosine
* This function is super wiggly, so thederivative of this function is enormous, even though the derivative of cosine is nobigger than 1 in magnitude
* If you think this is kind of aninteresting example, it's worth trying to cook up an even more elaborate example.Here's a very specific challenge for you
* Can you find a function that, just makeone up, so that your functions values and magnitude are less than c, and yourfunctions derivative and magnitude is less than c?So I want a specific number c, so that no matter what value of x you plug in, thefunction's value there and the function's derivative there is less than c inmagnitude
* But, I want that function to have secondderivative which can't be bounded by a constant.I want you to cook up a function so that, yeah, the values of the first derivativeare bounded by c
* But the second derivative can be as big oras negative as I'd like, by choosing x appropriately.Can you find a function like that?


--- SKIP ---: 04_what-are-the-derivatives-of-the-other-trigonometric-functions.en.srt


--- SKIP ---: 04_what-are-the-derivatives-of-the-other-trigonometric-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-are-the-derivatives-of-the-other-trigonometric-functions.en_SENTbySENT.txt
* [music] We've seen how to differentiatesine, and cosine and tangent, but how do I differentiate secant?So let's differentiate secant
* And one way to get a handle on secant isto write secant as a composition of two different functions.If I set f of x equals 1 over x, and g of x equals cosine x.Then f of g of x is secant x
* So if I want to differentiate secant, it'dbe good enough to differentiate f of g of x.And I can do that differentiation problem by using the chain rule.Now I can separately calculate the derivative of 1 over, it's negative 1 overx squared
* And the derivative of cosine is negativesine
* So putting this together, the derivativeof secant must be the derivative of f, which is minus 1 over its input squared atg of x and g is cosine
* So, with negative 1 over cosine squarethat's f prime of g of x times the derivative of g which is minus sine.Now I can put this together, the minus signs cancel and I'm left with sine x overcosine squared x
* But people don't usually write it this wayI could instead write this, as sine x over cosine x times 1 over cosine x.In other words, I could write this as, what's this term, this is tangent and thisis secant so I can write this as tangent x secant x.So the derivative of secant x is tangent x times secant x.We can play the same kind of game to differentiate cosecant.So what about the derivative of cosecant x?Well think about how I can rewrite cosecant, alright?Cosecant is the composition of the one over function and sine, right?Cosecant is one over sine
* So this is the derivative of f of g of x,where f is 1 over and g is sine, and by the chain rule, that's the derivative of fat g times the derivative of g
* And now I know what the derivatives ofthese functions are
* The derivative of 1 over is minus 1 over xsquared, and the derivative of g is cosine x.And consequently, the derivative of cosecant x must be minus 1 over, that'sthe derivative of f at g of x which is sine, so it's sine squared times thederivative of g, which is cosine x
* And I can combine these to get minuscosine x over sine x times 1 over sine x
* In other words, minus cosine over sine,that's minus cotangent x, and minus 1 over sine, well that's cosecant again.So the derivative of cosecant x is minus cotangent x times cosecant x.And we can complete the story by differentiating cotangent.Okay, so how do I differentiate cotangent x ?Well we actually have some choices
* One way would be to write this as thederivative of cosine x over sine x, since cotangent is cosine over sine.And then about the quotient rule
* Or, I could use the fact that cotangent isone over tangent, and then differentiate this using the chain rule.To differentiate 1 over something, that's negative 1 over the thing squared timesthe derivative of the inside function which is tangent x.And I know the derivative of tangent x that's secant squared, so this is negative1 over tangent squared x times secant squared x and that means the derivative ofcotangent is negative secant squared x over.Tangent squared x
* But people don't usually write it likethis
* Instead, I could simplify this.Having a secant squared in the numerator is as good as having a cosine squared inthe denominator, and having a tangent in the denominator, Is as good as havingcosines, in the numerator, and sines in the denominator.So, a negative secant squared over tangent squared is the same as negative cosinesquared over cosine squared times sine squared.Now, these cosines cancel And what I'm left with is negative 1 over sine squaredx
* But people don't even write it this way,right
* 1 over sine, well that's cosecant so thisis actually negative cosecant squared x
* Now that we've seen the derivatives of allsix of our trig functions, how are we suppose to remember these derivatives?Well here's a table
* Showing all the derivatives of these 6trig functions
* And you can see there's some real patternto this table
* The derivative of sine is cosine.The derivative of cosine has a negative sine.The derivative of tangent we saw is secant squared.And the derivative of cotangent is cosecant but with a negative sine.And the derivative of secant we just saw is secant tangent.And the derivative of cosecant is negative cosecant cotangent.So there's definitely some symmetry here, and you can exploit that symmetry to helpyou to remember these derivatives.


--- SKIP ---: 01_what-are-inverse-trigonometric-functions.en.srt


--- SKIP ---: 01_what-are-inverse-trigonometric-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-are-inverse-trigonometric-functions.en_SENTbySENT.txt
* >> [music] People often talk about inversetrig functions
* But that's nonsense.The trig functions aren't invertible
* Look at y equals sine x.Sine sends different input values, like 0, pi, 2 pi, 3 pi, to the same output valueof 0
* So, how are you going to pick the inversefor 0
* To get around this problem, we're onlygoing to talk about the inverses of trig functions after we restrict their domain.Here I've got a graph of sine
* And you can see this function is notinvertible
* It fails the horizontal line test.But, if I restrict the domain of sine to just be between minus pi over 2, and pieover 2, this function is invertible
* And, here's its inverse, arc sine.By convention, arc sine outputs angles between minus pi over 2 and pi over 2.And also by convention, arc cosine outputs angles between 0 and pi.And arc tan outputs angles between minus pi over 2 and pi over 2.Note that I'm calling these inverse trig functions arc whatever.You know, arc cosine, arc sine
* One reason to call these things arc cosineor arc whatever, is because of radian measure.If this is a unit circle, then the length of this arc is the same as the measure ofthis angle, in radians
* That's the definition of radians.So, to say that theta is arc cosine 1 half, is just to say that theta is thelength of the arc whose cosine is 1 half
* Now, what happens when we compose theinverse trig functions with trig functions?Before complicating matters by thinking about trig functions, let's think back toan easier example, the square root and the squaring function.And just like trig functions are not actually invertible, the squaringfunction's not invertible, because multiple inputs yield the same output.So we had to define the square root to pick the non-negative square root of x.And that means that if x is bigger than or equal to zero, then I have the square rootof x squared is equal to x
* But if x is negative, this is not true.The same sort of deal happens with trig functions.So if theta is between minus pi over 2 and pi over 2, then acrc sine of sin of thetais equal to theta
* But if theta's outside of this range, thisis not the case
* If theta's ouside of this range, yes, arcsine is going to produce for me, another angle, whose sine is the same as the angletheta
* But there's plenty of other inputs to sinewhich yield the same output
* Things are even more complicated if youmix together different kinds of trig functions.For example, the sine of arc tan of x happens to be equal to x divided by thesquare root of 1 plus x squared
* Where would you possibly get a formulalike that
* Well the trick is to draw a righttriangle, the correct triangle
* Well here I've drawn a right triangle.And I've got an angle theta
* And I've drawn this triangle so thattheta's tangent is x
* That means that theta is the arc tangentof x
* Now by the Pythagorean theorem, I know thehypotenuse of this triangle has length of square root of 1 plus x squared.And that gives me enough information to compute the sine of theta.The sine of theta is this opposite side x, divided by the hypotenuse, the square rootof 1 plus x squared
* This tells me that the sine of arc tan ofx must be x over the square root of 1 plus x squared.Drawing pictures will get you very far in understanding all of these relationships.I think it's basically impossible just to memorize all of the possible formulas thatrelate inverse trig and trig functions
* But if you're ever wondering what thoseformulas are, you just draw the appropriate picture, and then you canfigure it out right away
* .


--- SKIP ---: 02_what-are-the-derivatives-of-inverse-trig-functions.en.srt


--- SKIP ---: 02_what-are-the-derivatives-of-inverse-trig-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-are-the-derivatives-of-inverse-trig-functions.en_SENTbySENT.txt
* [MUSIC] What's the derivative of arc sine
* Well, I can't really compute this directly
* I don't know how to differentiate arc sine right off the bat
* So, I'm going to try to sneak up on the derivative of arc sine
* Now, instead of writing down arc sine all the time, I'm going to give it a different name
* I'll write f of x for arc sine x
* It just, it looks shorter
* Now, what do I know about arc sine
* Arc sine is the inverse function for sine
* So, at least for a range of values of x, f of sine x is x, right
* Arc sine tells me a value that I can take the sine of to get the input to arc sine, so if I evaluate arc sine at sine x, I get x, at least over a particular range of values of x
* So if this is true, and if f were differentiable, I could apply the chain rule and differentiate both sides
* So, let's just do that
* I'm just plowing ahead assuming that f is differentiable
* So, if I assume that f is differentiable, I differentiate f
* I get some mystery derivative
* I don't know what it is yet, I'm calling it f prime
* At the inside, which is sine x, times the derivative of the inside, which is cosine x
* And this is equal to the derivative of the other side which is one
* So, what I know now is that the derivative of arc sine at sine x is one over cosine x
* Try to divide both sides by cosine
* But, what I really want is a formula that tells me the derivative of arc sine at some point is some other point, alright
* I don't want to know the derivative at sine of x, in terms of cosine
* But, I can use a trick, right
* sine squared plus cosine squared is one
* So if I knew that cosign were positive, I could rewrite this and you should be a little skeptical as the quality, is one over the square root of one minus sine squared x
* You have to be a little bit worried here because you got to know that cosine's positive
* Okay
* But let's suppose it is
* So, if cosine's positive, then I can write cosine x as the square root of one minus sine squared x, and now I've got a formula for the derivative of arc tan, derivative of f, at sine x is something involving sine x
* So, I could rewrite this formula as just the derivative of arc sine at x, is one over the square root of one minus x squared
* So, there we go
* There is a formula for arc sine assuming that arc sine is differentiable
* Alright
* Because what I did is I just wrote down a function, you know, that I knew to be true
* I know that fsinx sine x is x for certain values of x
* And I just plowed through, differentiating it, assuming that it was differentiable
* And then, I figured out what a derivative would have to be if it were differentiable
* But note that I never actually verified that arc sine is differentiable
* I'm just telling you what the derivative is if it were differentiable
* So that's perhaps a little bit unfortunate
* Alright
* But nevertheless we're going to use this and this is in fact, the derivative of arc sine
* Now, we know how to differentiate arc sine
* Let's try to differentiate arc cosine
* We could do that in the same way
* f equals arc cosine to the chain rule trick
* We get a formula for the derivative of arc cosine
* Assuming it's differentiable, and it is
* But, I want to do it a different way
* I want to try to do it different attack, a different approach on the problem of calculating the derivative of arc cosine
* So, here's how we're going to start
* Take a look at this triangle here
* this angle's alpha, and I'm labeling this side to have length y, and the hypotenuse of this right triangle has length one
* Now, what this triangle's telling me is that the sine of alpha, which is this sign divided by hypotenuse, is y
* And consequently, the arc sine of y is alpha
* Now, what's arc cosine of y
* To figure that out let's draw another one of these triangles
* I'm going to label this side beta, and I'm going to imagine picking up this right triangle and flipping it over
* So that then this angle's beta, this angle's alpha, hypotenuse is still length one, but the side that I labeled y is now down here
* And what this triangle is telling me is that the cosine of beta, right
* Which is this width divided by the length hypotenuse is is y
* And consequently, the arc cosine of y is beta
* Why is that significant
* Well, this is a right triangle and the angles add up to 180 degrees, so alpha plus beta add up to 90 degrees, or pi over two radiants
* So, that means what
* I know that alpha plus beta is equal to pi over two
* Consequently, arc sine y plus arc cosine y, which is alpha plus beta, add up to pi over two
* Now, this formula is, you know, interesting in its own right
* But think about what it means differentiably
* I just calculated the derivative of arc sine and I'm wondering, what's the derivative of arc cosine
* Well, whatever it is, right
* These two functions add up to a constant, they're pi over two
* So, however wiggling y must affect arc sine, wiggling y must affect arc cosine in precisely the opposite way so as to make this sum a constant
* Said differently, right
* The derivative of this side has to be the derivative of this side
* But the derivative of this side is zero, that means the derivative of arc sine plus the derivative of arc cosine must be zero
* That means that the derivative of arc sine has to be exactly the negative of the derivative of arc cosine
* And since we know the derivative arc sine is one over the square root of one minus x squared, that means the derivative of arc cosine is negative one over the square root of one minus x squared
* My goal right now is to differentiate arc tan x, but that's too hard
* So instead, we're going to sort of sneak up on the derivative of arc tan x and figure out the derivative without explicitly knowing it to begin with
* So, here we go
* I'll make this a little bit easier, I don't want to keep writing arc tan x all the time
* So, let's give it a different name
* let's just call it f
* So f of x will be arc tan x for the time being
* Now, what do I know about arc tan
* Arc tan is one of these inverse trigonometric functions
* It's the inverse to tan
* So, I know what f of tangent x is
* Well, as long as x is between minus pi over four and pi over four, the arc tangent of tangent is just x
* Now, this is a really great thing, right
* Now if, if f were differentiable, I could use the chain rule on this
* So, let's just pretend that arc tan is differentiable and see what happens
* So, in that case, I differentiate this using the chain rule
* I got the derivative of f at the inside, times the derivative of the inside
* The derivative of tangent is secant squared
* [SOUND] The derivative of x is one, right
* So, I differentiated both sides of this equation, f tangent x equal to x
* The derivative of f tangent x is f prime tangent x times the derivative of tangent secant squared
* And the derivative of x, with respect to x, is just one
* Now, I'll divide both sides by secant squared x
* And I find out that f prime of tangent x is one over secant squared x
* Now, what do I do
* I, I'm trying to write down the derivative of f
* f is arc tan, and I want to know how to differentiate arc tan
* and what I've learned is that if f were differentiable, its derivative at tangent x would be one over secant squared x
* Well, here's a trick
* I know the Pythagorean identity
* I know that sine squared plus cosine squared is one
* So, if I take this identity and divide both sides by cosine squared, I get that tangent squared, right
* That's sine squared over cosine squared, plus cosine squared over cosine squared one, is one over cosine squared, that's a secant squared
* So, here's another trig identity, tangent squared x plus one is secant squared x
* So, up here where I've got one over secant squared x, I could have written this as one over, instead of secant squared x, I'll use the fact that secant squared x is tangent squared x plus one
* I'll put that in here and I get that the derivative of f, the derivative arc tan, at tangent x is one over tangent squared x plus one
* Now, this is a pretty great formula, right
* This is saying that the derivative at something is one over that same thing squared plus one
* So a more normal, a more common way of seeing this written is that the derivative of arc tan x is one over x squared plus one
* So, here's what we've done
* We've got the derivative of arc sine, is one over the square root of one minus x squared
* The derivative of arc cosine is exactly negative that, because the sum of arc sine and arc cosine is a constant, -1 over the squared of one minus x squared
* And we've calculated the derivative of arc tangent just now to be one over one plus x squared
* Excellent
* At this point, we've calculated the derivatives of arc sine, arc cosine, and arc tangent
* And now I challenge you to go and calculate the derivatives of arc secant, arc cosecant, and arc cotangent
* Have fun
* [MUSIC]


--- SKIP ---: 01_why-do-sine-and-cosine-oscillate.en.srt


--- SKIP ---: 01_why-do-sine-and-cosine-oscillate.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-do-sine-and-cosine-oscillate.en_SENTbySENT.txt
* >> [music].Sine is a periodic function
* You follow the graph of sine just wigglesup and down, forever and ever
* Let's try to get a sense as to why this isthe case
* Why does the graph of sine look like this?Why is sine moving up and down
* To get some intuition for this, let'sfirst imagine a very different situation
* Let's suppose that velocity is equal toposition
* And, I gotta imagine I'm starting here,and I start moving, right
* And I'm going to start moving slowly atfirst, but as my position increases, I'm going to be moving faster and faster,right
* As my position is larger and larger, myvelocity becomes larger and larger, which then makes my position larger and larger.So if this is the way the world works, I'm not bouncing around from minus 1 to 1 likesine
* I'm just being thrown off towardsinfinity
* We know what that situation looks like.If f of t is my position at time t, then f prime of t, the derivative of f at t is myvelocity at time t
* So saying that velocity equals position isjust saying I've got some function whose derivative is equal to itself.And, we know an example of that
* F of t equals e to the t is one example ofsuch a function
* So, to cook up a different situation,let's imagine something a little bit different.Instead, suppose that we're in the situation where my acceleration isnegative my position
* So that means that if I'm standing overhere, where my position is positive, I'm to the right of zero, then my accelerationis negative and I'm being pulled back towards zero.And then, as I swing past toward zero, now my position is negative, so myacceleration is positive, so I'm being pulled back in the other direction.And that's kind of producing this swinging back and forth across 0.This situation comes up physically in the real world.If you attach a spring to the ceiling, the spring's acceleration is proportional tonegative its displacement
* There's a function also that realizes thismodel
* To say that acceleration is negativeposition is as it is the second derivative of my position, which is my acceleration,is negative my function
* And yeah, we know an example.If f is sine of t, then the derivative of sin is cosine.And the derivative of cosine, which is the second derivative of sine, is minus sineof t
* And we know another function just likethis
* Look if, if g of t is cosine of t, then gprime of t is minus sine of t
* But then, g double prime of t, the secondderivative of cosine, is just minus cosine of t, because the derivative of sine iscosine
* So cosine is another example of a functionwhose second derivative is negative itself.We know even more functions like this
* For instance, what if f were the functionf of t equals 17 sine t minus 17 cosine t
* Well then, the derivative of f would be 17times the derivative of sine, which is cosine, minus 17 times the derivative ofcosine
* But the derivative of cosine is minussine
* So this is plus 17 sine t.So that's the derivative of f
* The second derivative of f is thederivative of the derivative
* This'll be 17 times the derivative cosine.Which is minus sin, plus the derivative of sin, which is cosine.So yeah, this is another example of a function whose second derivative isnegative itself
* If I take this function and differentiateit twice, I get negative the original function.So if you like, the reason why all of these functions are bouncing up and downlike this, is because in every case, the functions second derivative is negativeits value
* When the function is positive, the secondderivative is negative, pulling it down
* And when the function's value is negative,the second derivative is positive, pushing it back up.And so the function bounces up and down like this forever.


--- SKIP ---: 02_how-can-we-get-a-formula-for-sin-a-b.en.srt


--- SKIP ---: 02_how-can-we-get-a-formula-for-sin-a-b.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-can-we-get-a-formula-for-sin-a-b.en_SENTbySENT.txt
* [music] How do we really know that, thatangle sum formula is true
* What happens if I just rotate a singlepoint
* For instance, if I take this point here,the point (1, 0), and I rotate it through an angle of theta, then I end up at thepoint (cosine theta, sine theta)
* Somewhat similarly, if I take this pointhere, the point (0, 1), and I rotate counterclockwise through an angle oftheta, I end up at the point (minus sine theta, cosine theta).What if I rotate some other point (x, 0)
* Well, if I rotate (x, 0), say x is somenumber between 0 and 1, well, then I just think about where does (1, 0) go, right?(1,0) rotated at (cosine theta, sine theta).So (x, 0) must rotate to (x cosine theta, x sine theta), a point on the middle ofthis red line
* What if I rotate (0, y) through an angleof theta
* Similarly, if I've got some point, (0, y),say y is between 0 and 1, some point on this red line, if i rotate that pointthrough an angle theta, well the point (0, 1) rotates over to the point (minus sinetheta, cosine theta) on the circle
* So the point (0, y) rotates to a point onthe red line with coordinates (minus y sine theta, y cosine theta).All right
* Its exactly this point, but scaled by y.Okay, so we know how to rotate (x, 0), and we know how to rotate (0,y).How do i rotate (x, y)
* So, what if i rotate this point, (x, y),through an angle theta
* Well, lets rotate this, and all i reallyhave to figure out is, where does the point (x, 0) end up, and where does thepoint (0, y) end up
* Well, (x, 0) ends up at (x cosine theta, xsine theta)
* This point started off as (x, 0), and whenI rotate that through an angle theta, this is where it ends up.And this point started off as (0, y), and if I rotate that point through an angle oftheta, this point ends up at (minus y sine theta, y cosine theta).Now where does this point, (x, y) end up
* All I have to do is just add togetherthese two coordinates to figure out the coordinates of this other point.And that means that this point, (x, y) ends up at x cosine theta minus y sine ,and its y coordinate is x sine theta plus y cosine theta.So now i know how to rotate a point
* How does that help?The goal was to try to justify the angle sum formula.The trick is to think about what happens when you do successive rotations.If you first rotate through and angle alpha, and then an angle beta, that's thesame as rotating through an angle alpha plus beta all at once.Specifically, if I start with a point, (1, 0), and rotate through an angle of alpha,it ends up at (cosine alpha, sine alpha)
* I could then take that point and rotate itto the angle beta, and I've got a formula for that.Once I do that, the new coordinates are cosine alpha cosine beta minus sine alphasine beta, and then the y-coordinate is cosine alpha sine beta plus sine alphacosine beta
* But that's the same point as I'd get if Istarted with (1, 0), and just rotated the whole thing initially through the anglealpha plus beta
* This means that cosine alpha plus betamust be equal to cosine alpha cosine beta minus sine alpha sine beta, and sine alphaplus beta must be cosine alpha sine beta plus sine alpha cosine beta.These angle sum formulas can look very mysterious when they're written down, butthey're really coming from a very simple source.They're coming from the fact that rotating through one angle and another angle is thesame as rotating through the sum of those two angles..


--- SKIP ---: 03_how-can-i-approximate-sin-1.en.srt


--- SKIP ---: 03_how-can-i-approximate-sin-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-can-i-approximate-sin-1.en_SENTbySENT.txt
* >> [music] How can anyone compute sine?I mean nowadays, people use computers or caluculators.But by what mysterious force are these computational devices able to performthese computations
* How does the machine know what sine of oneis equal to
* So, that's a good question.How do we compute sine of 1 radian
* One way is to use a little bit ofcalculus
* So, what does calculus tell us?So let's let f of equals sine x, and the derivative of x is cosine x, the value off at 0 is 0, sine 00, and the value of the derivative at 0 is 1, because cosine 0 is1
* Now, I can use the derivative toapproximate the functions value
* The functions value near zero is thefunctions value at zero, plus how much I would be the input by, times the ratio ofoutput change to input change, the derivative at zero.Well given this, in our specific case the value of function 0 and derivative at 0 is1, and that means the functions value at h, for h very small, is about h.That means that sine of a very small angle is very close to that same value.Let's actually use some numbers
* So very concretely, sine of say 1 32nd isreally close to 1 32nd
* Now, in addition to this, we've also got adouble angle formula
* The double angle formula for sine saysthat sine of 2x is 2 times sine x times cosine x.You can derive this formula from the angle sum formula for sine.Sine of x plus x gives you this
* Alright.Another way to rewrite that a double angle formula is to write it entirely in termsof sine
* Alright.Cosine is the square root of 1 minus sine squared x.Well, as long as the cosine is positive, this is true.So, if I'm working with a value of x, which cos sins positive, then sin of 2 xis 2 times sin x times the square root of 1 minus sin squared x.We can put these pieces together
* Well, here's what we do.I know that sin of 1 32nd is very close to 1 32nd because 1 32nd is close to 0.And, sin of a number close to zero is about that.That same number
* Then I can use this double-angle formulaentirely in terms of sign to get an approximate value for sign of 1 16th byusing my approximate value for sign of 1 32nd.Then, I can use this double-angle formula again to get an approximate value for signof 1 18th, and again to get an approximate value for sign of 1 4th, and again to getan approximate value for sign of 1 half, and then again to get an approximate valueof sign of 1
* Which is really quite close to the actualvalue of sine of 1
* So, what happened?Calculus told us that sine of a small number, is close to that small number.The double angle formula let us transport that bit of information around zero topoints much further away
* All the way to approximate sine of 1.


--- SKIP ---: 01_how-can-we-multiply-numbers-with-trigonometry.en.srt


--- SKIP ---: 01_how-can-we-multiply-numbers-with-trigonometry.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-can-we-multiply-numbers-with-trigonometry.en_SENTbySENT.txt
* >> [music] We've already thought a littlebit about various ways that you can speed up multiplication.We've seen quarter squares, log tables, and even slide rules.There's another method that was super popular in the quarter century beforeNapier unveiled logarithms to the world
* The method has the admittedly verypretentious name of prosthaphaeresis
* The idea is to use a cosine productidentity, namely this formula
* The cosine of a times the cosine of b isthe cosine of a plus b and the cosine of a minus b, averaged together.Perhaps, somewhat surprisingly, you can use this cosine product identity tomultiply numbers
* Let's see how.So, let's try to use this trick to multiply 0.17 and 0.37.Now, these numbers are so small, you just multiply them out.But it'll demonstrate the trick that would work on more complicated looking numbers.The formula that we're trying to use is this cosine a times cosine b formula.I can only multiply together, cosines
* So, I should rewrite 0.17 and 0.37 ascosine a and cosine b
* Now, if I look at my table of inversecosine and I look up 0.17, I find that cosine of 1.39997 is close to 0.17.I can also use my table to compute arc cosine of 0.37 to be about 1.19179.In other words, if I take cosine of this number, I get really close to 0.37.Now, the formula that we're trying to use is this formula that tells me to compute aplus b and a minus b
* So, given that, I've got these approximatevalues for a, I can compute a plus b to be 2.59176 and a minus b to be 0.20818.Here, I've got a table of cosine values and if I look at 0.20, zero of column,first, second, third, fourth, fifth, sixth, seventh, eighth column, I find outthat cosine of 0.208 is about 0.97845
* And I can similarly use my table forcosine to approximate cosine of a plus b, it's negative 0.85261.Now, the formula that we've got for the product of cosine a and cosine b, tells usit's the average of cosine a plus b and cosine a minus b.I've computed cosine of a minus b and cosine a plus b, so all I have to do istake the average of these two numbers, and if I average these two numbers, I get0.06292
* Wow.I mean, look
* This average is really close to the actualproduct of 0.17 and 0.37, which is 0.0629
* We're managing to multiply togethernumbers by rewriting those numbers as cosines and using this formula that tellsme how to multiply cosines
* Instead of actually multiplying, I'vereplaced the multiplication with additions, differences, table lookups, andan average
* Logarithms are obviously a hugeimprovement over this method
* But it's pretty fantastic to think that400 years ago, humans were trying to figure out how they could usetrigonometric identities to do things like multiply numbers.That required a tremendous amount of creativity to think that the things abouttriangles would have anything to do with multiplying numbers.In other words, trigonometry is not just about triangles.You can do more than just understand triangles if you really understand a wholebunch of trigonometry
* .


--- SKIP ---: 01_why-would-i-ever-want-to-take-derivatives.en.srt


--- SKIP ---: 01_why-would-i-ever-want-to-take-derivatives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-would-i-ever-want-to-take-derivatives.en_SENTbySENT.txt
* [MUSIC] Now, where are we in this course
* Well, a long, long time ago, we werelooking at limits, right
* And we first studied the, the concept ofthe limit, and we learned how to compute withlimits
* And then went into application of limits,which was limits of difference quotients, whichwas the derivative
* And we studied some of the concepts of thederivative
* What is the derivative telling us about afunction
* And then we've been studying a turn oftechniques for computing derivatives
* And we learned about the product rule, thequotient rule, the chain rule
* Derivatives of some special functions likee to the x, log x, sines and cosines
* Where does that leave us
* We've studied the concepts we've studiedsome of the computations
* Now we're going to study applications
* Why would anyone care about derivatives inthe first place
* Right, what's the real world pay off
* There's a couple applications I want tolook at now
* One of those applications is just back tolimits
* If you want to calculate limits
* Turns out, sometimes you can usederivatives to calculate limits
* That's the story of lopital's rule
* But the second application this week ismuch more exciting
* It's related rates
* All the time in the real world, you've gotequations between different quantities
* And maybe you know how one of thosequantities is changing, well, if you start with that equation and you differentiateit, that gives you some relationship between therates, right
* The derivative of that equation will tellyou how one's things rate of change is related to somethingelse's rate of change
* And by translating sort of story problems,sort of real world scenarios
* Into equations, and then differentiatingthose equations
* We can learn, about the relationshipsbetween these different rates of change
* That's the story of related rates
* We're going to do a turn of the examplesof those, right now [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_how-can-derivatives-help-us-to-compute-limits.en.srt


--- SKIP ---: 01_how-can-derivatives-help-us-to-compute-limits.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-can-derivatives-help-us-to-compute-limits.en_SENTbySENT.txt
* [music] There are plenty of limits thatare really quite hard to evaluate
* Here's an example.Take the limit as x approaches 4 of the square root of x minus 2, divided by xminus 4
* Admittedly, that limit's not really thatdifficult to calculate
* Alright?The limit is 1 4th
* But we can also think about this, maybe alittle bit more intuitively
* Look at what's going on.The limit of the numerator is 0, right
* As x approaches 4, the square root of anumber close to 4 minus 2 is close to 0
* And the limit of the denominator is also0
* And because the limit of the denominatoris 0, I can't just use my limit of the quotients as the quotient of limits dealto evaluate this limit, right
* I'm genuinely in a difficult situation..And the problem is that the numerator being close to zero, is trying to makethis ratio small
* But when the denominator is close to zero,it's trying to make this ratio really big
* And neither the numerator nor thedenominator win the game
* Right?Those 2 forces balance off, giving the answer of 1 4th.But why
* Well, we can see this geometrically.So here I've graphed in green the function squared of x minus 2.That's the numerator
* And in orange I've graphed x minus 4.Y equals x minus 4
* And you can see that when x is equal to 4,these curves cross the x axis because when I plug in 4 here, I get zero.When I plug in 4 here, I get zero
* But also note that the green curve isgetting closer to zero more quickly than the orange curve.Let's replace those two functions with the approximations that we get by using thederivative
* Now, let me replace this green curve withthe tangent line to the green curve at the point where the green curve crosses thex-axis
* Well, here I go.Here's a picture just of that tangent line.Now I could compute that tangent line by doing a little bit of calculus.Alright
* This function is the square root of xminus 2
* If I differentiate that I get 1 over 2square root sub x, that's the derivative of the square root function.And the derivative of minus 2 is just 0
* Now I can evaluate that derivative at 4,and I get the derivative is 1 4th, and that's the slope of the tangent line.Here to the green curve
* Now I know that my tangent line shouldcross through the point 4, 0
* So here's equation that tangent line inpoint slope form and I can rewrite this a little bit more nicely as y equals aquarter of x minus 1
* So what happens to the limit problem whenwe replace those expressions by their tangent lines?So instead of thinking about this geometrically, I can just look back atthis original limit problem, and replace these pieces by their tangent lines.And we calculated the tangent line to the graph of the square root of x minus 2.To be one quarter times x minus 4, and the denominator is already a straight line.So, if I replace the numerator and denominator by the straight lineapproximations that are good for inputs near 4, this original limit problem istransformed into this limit problem
* But this limit problem is really easy todo, right
* I've got an x minus 4 in the numerator andan x minus 4 in the denominator
* So this limit is 1 quarter.It's important to emphasize that we really haven't done anything new here.We could have calculated this limit even without thinking about derivatives andtangent lines, but this perspective opens up a new way of approaching some limitproblems
* So here's how I can package this up.Into a situation that's maybe useful more generally.Suppose I got two functions, I got a function f and a function g.And let's suppose the limit of f as x approaches a is 0 and the limit of g of xas x approaches a is also 0
* And just for kicks, let's suppose that fand g are also differentiable, twice differentiable, you know, I want these tobe really nice functions
* Now let's suppose I want to try tocalculate the limit of f of x over g of x, as x approaches a.This might be a difficult limit to calculate.But what we just saw is that we could try to understand this a little bit better byreplacing f and g by their tangent line approximations.Another way to say that Is I'm just going to replace f of x and g of x by theirapproximations that I get from considering their derivative, right?So, the limit of f of x over g of x should be close to this because f of x is closeto this, right
* It's the value of f at a plus thederivative of f at a times how much the input changes when I go from a to x.That's approximately f of x
* And this denominator should be about g ofx
* It's g of a plus the derivative of g at atimes x minus a, that's about g of x
* So if you believe that the numerator anddenominator here are approximately f of x and g of x, you might then believe thatthese limits are also equal
* But this is a really great situation to bein because f of a say is equal to 0 if f is continuous there, maybe since it'sdifferentiable
* And g of a is also equal to 0 since g iscontinuous
* So that these f of a and g of a terms goaway
* And then I've got an x minus a and an xminus a term there, so those also cancel, and all I'm left with is just f prime of adivided by g prime of a
* So it seems like if you try to calculatethe limit of this ratio, what's really relevant is understanding something aboutthe derivatives of your numerator and denominator separately.At that point a
* The precise statement of this is usuallycalled L'Hopital's rule
* So here's a statement of L'Hopital's rule.Suppose I got two functions f and g and they're differentiable for inputs near a,and the limit of f of x and the limit of g of x as x approaches a are both 0.So these functions output is very small when their input is close to a.And the limit of the derivative of f divided by the derivative of g as xapproaches a, just exists
* And the derivative of g is not 0, when Ievaluate that derivative for inputs near a.If all of these conditions are true, then I get the fantastic conclusion that thelimit of f of x over g of x
* Is the limit of the derivative of f overthe derivative of g
* And the hope is that this limit is easierto compute then the original limit
* Let's try to use L'Hopital's rule in amuch trickier context
* So here's an example, let's compute thelimit as x approaches zero of cosine x minus one minus x quote over two all overx 2 the 4th power
* Now we can do it using L'Hopital's rule.So the limit of the numerator is zero and the limit of the denominator is zero.And these are really nice functions, so they're nice enough for us to applyL'Hopital
* So I should calculate the limit of thederivative of the numerator, divided by the derivative of the denominator and thatmight help me compute this original limit
* So here we go.The derivative of the numerator is minus sign x, that's the derivative cosine.Minus zero, that's the derivative of 1
* Minus x, that's the derivative of xsquared over 2
* Divided by, what's the derivative of x tothe 4th
* It's 4x cubed.Now here, I'm in a situation where the limit of the numerator is 0, because thelimit of sin x as x approaches 0 is 0 and the limit of x as x approaches 0 is 0.So, the limit of the numerator is 0 and the limit of the denominator is also 0.So here's the funny thing
* I could try to apply L'Hopital again tounderstand this limit
* So here we go.I'll use L'Hopital again
* I'll differentiate the numerator.The derivative of minus sin is minus cosine.And the derivative of x is 1
* So this is minus cosine of x minus 1.Divided by the derivative of the denominator which is 4 times 3x squared,or 12x squared
* Now what kind of situation am I in here?Well here, the numerator has limit 0 because cosine's limit is 1 and it'sattracting 1
* And the limit of the denominator is also0, so I'm again in a situation where the numerator and denominator are headingtoward 0
* So to understand this, I could again useL'Hopital to look at how quickly these terms are dying.So I apply L'Hopital again, and L'Hopital tells me to look at the derivative of thenumerator
* The derivative of minus cosine of x, issine x
* Minus 1, well that's just 0, divided bythe limit of the denominator
* Well, what's the derivative of thedenominator
* It's 24x.So now I'm again in a situation where the numerator and the denominator have limit0
* So I could again apply L'Hopital, and itwould tell me to look at the derivative of the numerator over the derivative of thedenominator
* The derivative of the numerator is cosinex and the derivative of the denominator is 24.But now look, the numerator has limit 1, and the denominator has limit 24, it'sjust a constant
* So this is a limit of the quotient and thequotient of limit, so this limit is, Is 1 24th.Now, L'Hopital then tells me that this limit being equal to 1 24th makes thislimit equal to 1 24th
* And because this limit exists, it thentells me that this limit is also equal to 1 24th.And because this limit then exists it then tells me that this limit is equal to 124th
* And then because this limit exists ittells me that the original limit is 1 24th.


--- SKIP ---: 02_how-can-l-hopital-help-with-limits-not-of-the-form-0-0.en.srt


--- SKIP ---: 02_how-can-l-hopital-help-with-limits-not-of-the-form-0-0.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-can-l-hopital-help-with-limits-not-of-the-form-0-0.en_SENTbySENT.txt
* [music] We already know how to calculatelimits that are a very small number divided by a very small number a zero overzero form
* So we've seen [unknown] Patel's rule forthe situation when limit the numerator limit of the denominator of both zero, butit turns out that[INAUDIBLE] rule is also valid when the limit of the numerator andthe limit of the denominator are both infinity.I mean you still got all the other conditions.You gotta check that the limit of the ratio of the derivative exists, thederivative of the denominator is not zero
* For values of x near a.But given these conditions, you then get the same fantastic conclusion.That the limit of f over g is the limit of the derivative of f over the derivative ofg
* Let's take a look at an example.Well, here's an example
* This is an example, you really don't needto use[UNKNOWN] a lot, but at least it demonstrates what the technique is.The limit on the numerator is infinity, the limit ofthe denominator is alsoinfinity, though that's maybe a little bit harder to see.And consequently We could use lopatol/g, and it would tell us to compute insteadthe derivative the numerator
* Which is 4 x plus 0, divided by thederivative the denominator, which is 6 x minus 1.Now can I calculate the limit of this as x approaches infinity.Yes, of course I could just do this directly too but I could again uselowbatal of I really wanted to
* The limit of the numerator is infinity,the limit of denominator is infinity
* So lobatall tells me to instead considerthe ratio of derivatives, the derivative of the numerator is 4, the derivative ofthe denominator is 6
* And now I'm in a situation where I'm justtaking the limit of a constant over a constant.That means that limit is 4 6th, which then tells me how to compute the originallimit, but, and this isn't the best way to do this problem, but at least itdemonstrates that you could use Lopital in a situation where you got infinity overinfinity
* Infinity.But not every limit is something going to zero over something going to zero, orsomething going to infinity over something going to infinity.Sometimes you might have a limit where it's a product, the first term is headingtowards zero and the second term is heading towards infinity.For example, here I'm asking what the limit as x approaches infinity of sin ofone over x times x
* This first term, sine of 1 / x, that'sgetting close to 0 when x is very large
* And the second term, just the x, that isgetting very big
* So this first term is having a tendency tomade this quantity smaller but the second term is having a tendency to make thequantity bigger
* You know, who wins?.Well with lobitol/g the only thing that we can really deal with is sort of a 0 over 0situation or an infinity over infinity situation and that's neither of these.But we can transform this problem into one of these situations.So instead of calculating this limit I'll calculate the equivalent problem, thelimit as x approaches infinity
* Of sine 1 over x in the numerator dividedby 1 over x
* So instead of multiplying by somethingwhich is going towards infinity, I'm going to divide by its reciprocal.The reciprocal of something going to infinity, is going to 0.So now I've got a situation where the numerator is going to 0, and thedenominator is going to 0, and this problem, equivalent to the originalproblem
* Is now amenable to L'Hospital's rule.So by L'Hospital's rule I would want to differentiate the numerator, differentiatethe denominator and then look at that limit to try to understand this originallimit
* Well, what's the derivative of, Of sine of1 over x, it's cosine of 1 over x, because the derivative of sine is cosine, timesthe derivative of the inside, which is minus 1 over x squared.And I'm going to divide by the derivitative of the denominator, which isminus 1 over x squared
* So, now how do I evaluate this limit?Well, the good news is that I've got a minus 1 over x squared in the numeratorand a minus 1 over x squared in the denominator.So this limit is the same as the limit as x approaches infinity of just cosine of 1over x
* But now, 1 over x is getting very close to0 and what's cosine of a number close to 0?It's 1
* So this original limit, is 1.You might have something near 1, being raised to a very high power.Here's an example
* The limit as x approaches infinity, of 1plus 1 over x, raised to the xth power
* So for very large values of x, the basehere, 1 plus 1 over x, that's close to 1, but the exponent is very large.If you take a number close to 1 and raise it to a very.Very high power it's actually unclear what you're going to get.Depending as to how quickly this is moving towards 1 and how quickly this thing isgrowing
* You get wildly different answers.Now this is not 0 over 0 or infinity over infinity.So I've got to transform this problem into something.Thing that L'Hopital can handle
* The trick here is to use exponentialfunctions
* So I'm going to rewrite this as e to thelog of the limit as x approaches infinity of 1 plus 1 over x to the xth power.E to the log of something does nothing, ritght?These are inverse functions
* But, log of a limit is the limit of thelog
* So this is.E to the limit as x approaches infinity of the log of 1 plus 1 over x to the xthpower
* Now log as something to a power is thatpower times the log, so this is e
* To the limit as X approaches infinity of Xtimes the log of one plus one over X
* Now what kind of situation am I in here?X is very large but log of a number close to one is close to zero.This is big number times number close to zero.That's the infinity times zero indeterminate form, so how am I going tohandle this
* We just saw a minute ago that I'm going tohandle this by
* Putting the infinity in the denominatorwith the reciprocals to make this 0 over 0, the sort of thing that[INAUDIBLE] canhandle
* So this is e to the limit as x approachesinfinity of lg 1 plus 1 over x divided by 1 over x.This is the same as this, but now I've got something approaching 0 divided bysomething approaching 0
* This is the sort of situationthat[INAUDIBLE] can help me with
* This is e to the limit, by lopital.The derivative of the numerator divided by the derivative of the denominator.The derivative of log is one over the inside function, times the derivative ofthe inside, which is minus one over x squared.Divided by what's the derivative of 1 over x, well it's the same thing here minus 1over x squared and this is the limit as x approaches infinity.Now I've got a minus 1 over x squared which cancels with the minus 1 over xsquared in the denominator
* And I've got 1 over 1 plus 1 over x as xapproaches infinity
* This is getting very close to one.So this is e to the 1st power, which is e
* And that means that this original limit,the limit of 1 plus 1 over x to the x power as x approaches infinity, is equalto e
* Or you might have a very large number,being raised to a very small power
* For example, let's say I want to come upwith the limit as x approaches infinity of x to the 1 over xth power.So the base here is very large, which have a tendency to make this number very big,but the exponent is getting close to 0, which would have a tendency to pull thisback down closer to 1
* So what is this?Well we can try to transform this into the sort of limit problem that[UNKNOWN] canhandle, and I can again do that with exponential functions.So I can rewrite this as e to the log of the limit of x to the 1 of xth power.And this is the limit as x approaches infinity.Now, this is the log of a limit
* Which is the limit of the log of x to the1 over xth power
* And this is the limit as x approachesinfinity
* But the log of something to a power isthat power
* So 1 over x times.The log of the base as x approaches infinity.Now I've got 1 over x, which is the number close to zero.Times log of x, which is a very large number.This is zero times infinity, so to speak
* So I should try to transform thisindeterminate form into something that labetalol can handle.Well, we'll write this a e to the limit of x approaching infinity, of say log x overx
* This is infinity over infinity, so tospeak
* That's the sort of thing that L'Hopital'sokay with, so instead of taking this limit.I could look at the ratio of the derivatives.The derivative of log x is 1 over x
* The derivative of x is 1.So I should look at the limit of 1 over x over 1 as x approaches infinity.Well, that limit is 0 and e to the 0 is 1, so the limit of x to the 1 over x as xapproaches infinity is equal to 1
* Or you might have a limit that looks likesomething going to infinity minus something going to infinity.So let's try to compute the limit as x approaches infinity of the square root ofx squared plus x minus x
* So this is a very large number minus avery large
* The infinity minus infinity situation.So we should try to factor this or rewrite this to get it into a zero over zero orinfinity over infinity
* The sort of thing I could apply lopitol/gto
* 2.So I could try to pull out an x from this, because x is going to infinity.I know x is a large positive number here
* So I could rewrite this as x times, sowhat if I pull out an x from here
* That's the square root of 1 plus 1 over x.Minus, when I pull out an extra one here I get minus 1.So really, this limit, for large values of x, so as x approaches infinity, is thesame as x times this quantity, the square root of 1 plus 1 over x minus 1.This is a large number
* What do I know about this number?Well this is the square root of 1 plus the reciprocal of a large number.This is close to 1 minus 1
* This second term is close to zero.This is infinity times 0 in determinate form.So I could rewrite this using our standard trick as 1 plus 1 over x minus 1.So this is now the numerator
* This thing's going to 0 divided by 1 overx
* The reciprocal of this.But I'm dividing by it, and that's the same as multiplying.So now I've got 0 divided by a number close to 0.I, it's 0 over 0 in determinate form
* So lopital tells me I can analyze this bylooking at the ratio of the, The derivatives, so I should look at the limitas x approaches infinity of, what's the derivative of this?Well, the derivative of the square root is one over two square root of the insidefunction, one plus one over x, times the derivative of the inside function.So the derivative of 1 over x
* And I don't have to worry about the minus1, because the derivitive of that's 0
* And I divide by the derivitave of thedenominator, so I'll just write derivative 1 over x.So now I've got derivative 1 over x in the numerator, derivative 1 over x in thedenominator
* This limit then, should be same as justthe limit of this
* So I should be looking at the limit as xapproaches infinity of 1 over 2 square root.Of one plus one over x
* Well, what's one plus on over x as xapproaches infinity, that's just one
* So this is one over two square root of anumber close to one, this is one half
* And, indeed, this original limit really isone half
* I mean, honestly, we didn't need l'hopitalto calculate that, but we could use l'hopital if we wanted to.To evaluate this limit
* Okay, okay.Let's summarize all the possibilities
* So here's this summary of everything youmight see in the[INAUDIBLE]
* If you see zero over zero, or infinityover infinity in a limit problem
* You can just apply L'Hopital, in thatcase
* But here, I've lifted off some of theother things that you might see
* And these in equations, there's nononsense equations, right
* But I hope they kind of tell you what youshould do
* So if you see, say 0 times infinity in alimit, and by that I mean, it's a product of things, one of which is limit 0, theother of which has limit infinity
* Well, you should transform this into oneof these cases so you can apply L'Hopital
* So you could do that by moving the 0 intothe denominator, and taking its reciprocal This is really infinity over infinity.Or, you could move the infinity in the denominator, and take its reciprocal.And now you've got 0 over 0
* If you see 1 to a very large power, orsomething close to 1 to a large power, right?You can use either the log to transform this.And e to the log of this is e to the large number times log of number close to 1.Log of a number close to 1 is close to zero.This is an infinity times 0 indeterminate form.But you know how to handle those
* Because you can convert them back intothese cases
* Which you can then use[INAUDIBLE].If you see infinity to the 0
* Well, you could use the same e to the logtrick
* And then the exponent here is 0 times logof a big number
* Or a number close to 0 times log of a bignumber
* But this is the 0 times infinityindeterminate form, which is right here
* We should transform you to these cases,which you then use L'Hopital on
* If you see 0 to the 0, by which I mean, anumber close to 0 raised to a power close to 0, you can again use the e to the logtrick And this is e to a number close to 0, times log and a number close to 0.What's log of a very small number
* That's very negative.So, this exponent is, again, the 0 times infinity in determinate form, which youcan then convert into this and apply L'Hopital To it.The last case is this infinity minus infinity case, and there, one thing youcould try to do is put it over some common denominator, so I'm thinking of the commondenominator here as being 1 over the product of these two terms, and here I'vegot 1 over the second term minus 1 over the first term.But the point here is that you can rewrite this difference of very large quantities.As a something getting close to 0 divided by something getting close to 0.Which is the sort of thing that you could then apply L'Hopital.


--- SKIP ---: 03_why-shouldn-t-i-fall-in-love-with-l-hopital.en.srt


--- SKIP ---: 03_why-shouldn-t-i-fall-in-love-with-l-hopital.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_why-shouldn-t-i-fall-in-love-with-l-hopital.en_SENTbySENT.txt
* [MUSIC] People often have this idea that l'Hopital's rule is really great
* I'm going to tell you why you shouldn't fall in love with l'Hopital's rule
* For one thing, l'Hopital's rule often leads to circular reasoning
* Let's go to the blackboard and take a look
* For example, here's a problem that you might be tempted to use l'Hopital on
* You know, in a limit as x approaches zero of sine x over x
* Now, what do you have to check
* Well, let's take a look at the limit of the numerator by itself
* The limit of sine x as x approaches zero, sine is continuous so that limit is just sine of zero, which is zero
* Numerator's limit is zero
* Limit of our denominator
* the limit of x as x approaches zero is zero
* So, yeah
* This is a zero over zero indeterminate form
* So, we have tried using l'Hopital
* l'Hopital tells us that this limit is equal to the limit as x approaches zero of the derivative of the numerator, which is cosine x over the derivative of the denominator, which is one
* Now, this limit is quite a bit easier to do, right
* This is really just the limit of cosin x as x approaches zero
* Cosine is continuous so this is just the value of cosine at zero, which is one
* And yeah, I mean, the limit of sine x over x as x it approaches zero, it is, in fact, one
* This looks good, alright
* The, the question though is how did you know that the derivative of sine X was cosine x
* You needed to know that in order to apply l'Hopital
* How did you know the derivative of sine x was cosine x
* Well, let's think back
* Right
* So, how did I know that the derivative of sine x was cosine x
* Well, taking a derivative is the same thing as a limit of a difference quotient
* So, to calculate, say, the derivative of sine at zero, I take a limit like this
* The limit if h goes to zero of sine 0 + h - sine 0 / h
* Sine of zero is just zero
* So, calculating this limit, which is calculating the derivative of sine at 0, is really the same as calculating the limit as h goes to zero, sine 0 + h, that's just sign h - 0 / h
* Now, what just happened
* I wanted to calculate the derivative of sine at zero, and to calculate the derivative of sine at zero, is really the same as calculating the limit at h goes to zero of sine h over h
* It's the definition of derivative
* And I was going to use this to evaluate the limit of sine x over x using l'Hopital, right
* l'Hopital doesn't just reduce a limit problem down to another limit problem
* It reduces a limit problem down to a limit problem and two derivative problems, right
* To, to do l'Hopital, you have to be able to differentiate the numerator and denominator
* So, if you're going to use l'Hopital to evaluate sine x over x as x goes to zero, you're going to have to differentiate sine x
* But then, to differentiate sin x at zero, which is what you're trying to do, to, to use l'Hopital, you have to be able to evaluate this limit, the limit of sine h over h
* You have to be able to do the limit you're trying to do already
* It's just circular reasoning
* So, what just happened
* I was trying to calculate the limit of sine x over x as x approaches zero
* I used l'Hopital
* l'Hopita told me to differentiate sine x
* But then, to differentiate sine x, I would've needed to be able to evaluate the limit of sine h over h as h goes to zero, the exact problem I'm trying to solve
* It's an example of circular reasoning
* There's other things that can go wrong with l'Hopital
* One of the conditions of l'Hopital is that the limit of the ratio of the derivatives has to exist
* let's see an example where that fails to happen
* Here's an example
* Let's take a look at the limit of x plus sine x over x as x approaches infinity
* Try to use l'Hopital
* So, I want to look at the limit of the numerator by itself
* The limit of x plus sine x as x approaches infinity is infinity
* The limit of the denominator by itself, the limit of x as x approaches infinity, also infinity
* This is an infinity over infinity indeterminate form
* It seems good
* Now, l'Hopital's tells me that to calculate this, I should look at the limit as x approaches infinity
* The derivative of the numerator, which is one plus cosine x over the derivative of the denominator, which is one
* Now, what's the limit of one plus cosine x as x approaches infinity
* Well, the limit of one is just one
* But what's the limit of cosine x as x approaches infinity, right
* Cosine just oscillates between -1 and 1
* This limit doesn't exist
* This limit doesn't exist
* Now, does that mean that this limit doesn't exist
* I, I, I wrote equals here, but remember, I'm using l'Hopital's rule, alright
* And what does l'Hopital's rule actually say
* It says, that this limit is equal to the limit of the derivative over the derivative, provided this limit exists
* And this limit doesn't exist in this case
* So, l'Hopital is silent as to the value of this limit
* Let's see if we can actually compute that limit some other way
* Alright
* So, let's try to do this limit some other way
* We're going to do the limit of x plus sine over x as x goes to infinity without using l'Hopital
* This is a limit of fraction, we could split up the fraction as a limit as x goes to infinity of x over x plus sine x over x
* Now, that's a limit of a sum, which is the sum of the limits provided the limits exist
* So, this is the limit as x goes to infinity of x over x plus the limit as x goes to infinity of sine x over x
* Now, what's the limit x over x as x goes to infinity
* Just one
* What's the limit of sine x over x as x goes to infinity
* Well, sine x is always between -1 and 1
* And x here is going to infinity
* I can make x as big as I like
* So, question is can I make this as close to zero as I like
* Yeah
* By making x large enough, a number between -1 and 1 / x can be made as close to zero as I like
* So, this limit is zero
* [SOUND] So, the sum of the limits is one [SOUND] and that's the limit of the sum
* That's the limit of x plus sine x over x
* It's one as x goes to infinity
* And this is true in spite of the fact that l'Hopital failed us, right
* When we did l'Hopital's in this problem, I was told to differentiate the numerator, divided it by the derivative of the denominator as x goes to infinity, and that derivative didn't exist
* It was oscillating between zero and two
* And in that case, l'Hopital is just silent
* l'Hopital requires that limit of the ratio of the derivatives to exist, and if it doesn't exist, l'Hopital doesn't say anything
* This limit does exist and then to see that requires some, some algebraic computation
* So, we manage to evaluate that limit
* The limit was one, but no thanks to l'Hopital
* The limit of the ratio of the derivatives didn't exist, it was oscillating
* We evaluated that limit by algebraic manipulation
* And don't get me wrong
* l'Hopital is awfully powerful
* There's plenty of situations where you want to use l'Hopital
* But often, you can get away with just doing some algebraic manipulation
* So, I encourage you, when you're doing those limit problems, don't forget that you can just algebraically manipulate things
* There might be an easier way than bringing out l'Hopital
* Only use l'Hopital if you absolutely have to use l'Hopital
* In other words, don't fall in love with l'Hopital
* [MUSIC]


--- SKIP ---: 01_how-long-until-the-gray-goo-destroys-earth.en.srt


--- SKIP ---: 01_how-long-until-the-gray-goo-destroys-earth.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-long-until-the-gray-goo-destroys-earth.en_SENTbySENT.txt
* >> [music] Suppose that we have some sortof substance, I'll call it gray goo, that converts anything it touches into more ofitself
* The rate of growth of this gray goo isproportional to its current size
* Well let's say that the constant ofproportionality is just 1
* So f of t will be the amount of gray goo,and the derivative of f of t is the rate of change in the amount of gray goo.So if the proportionality constant is 1, whatever they're saying is that the rateof change in the amount of gray goo is just the amount of gray goo.So if there's more gray goo, the rate of change in the quantity of gray goo is alsohigher
* What are the units of the derivative?Well let's have time measured in seconds and the amount of gray goo measured ingrams
* That means the rate of change in theamount of gray goo will be measured in grams per second.Let's suppose that when the experiment begins at time 0, we have 1 gram of graygoo
* So in symbols, that says that f of 0 isequal to 1 gram
* So after 0 seconds have elapsed, so at thebeginning of the experiment, I've just got 1 gram of gray goo.We can write down an equation for f of t
* Right.I know a function whose value at 0 is 1 and whose derivative is itself, whose rateof change is proportional to itself with proportionality constant 1.I know that function
* That function is just e to the t.How much gray goo is there after 10 seconds have elapsed?So that means I want to calculate f of 10 seconds.I don't know how much material there is after 10 seconds.It's e to the 10
* That's approximately 22,000 grams.And 22,000 grams is 22 kilograms
* So after 10 seconds, there's about 22kilograms of gray goo
* Okay, here is the big question.How long will it take until the entire Earth is converted into gray goo?So the mass of the Earth is about 6 times 10 to the 27th grams.So I'm looking for a time so that f of t is 6 times 10 to the 27th.In other words, I'm trying to find a value of t so that e to the t is 6 times 10 tothe 27th
* So I'm looking for t so that e to the t is6 times 10 to the 27th
* Well I can take log of both sides.I'm looking for t equals log of 6 times 10 to the 27th.This is natural log
* And this is log of a product which is thesum of the log
* So it's log of 6 plus log of 10 to the27th
* Now this is log of something to a power.So that's log of 6 plus 27 times log of 10, and I can approximate these.Log of 6 is about 1.8, and log of 10 is about 2.3.So I've got 1.8 plus 27 times 2.3
* That's 63.9, and this is in seconds.So you've got 63.9 seconds until the amount of gray goo is about 6 times 10 tothe 27th grams
* Once you unleash 1 gram of this material,you've got, what, 64 seconds
* In other words, you have no chance tosurvive
* Make your time.


--- SKIP ---: 02_what-does-a-car-sound-like-as-it-drives-past.en.srt


--- SKIP ---: 02_what-does-a-car-sound-like-as-it-drives-past.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-does-a-car-sound-like-as-it-drives-past.en_SENTbySENT.txt
* >> [music] Calculus is all about rates.And one main example of rates is velocity
* Remember velocity is the derivative withrespect to time of your position
* Velocity measures how quickly yourposition is changing
* Here's a particularly nice example that wecan look at
* A car driving past you.So I've drawn a diagram of the situation
* I've placed you at the origin, so yourcoordinates are 0, 0
* And I've placed the car here at this reddot
* Its x-coordinate is v t.I'm thinking of v as the velocity of the car, and t as the current time.And I placed this y coordinate at B so the car is going to drive along the line yequals b at a constant velocity v
* Let's compute how far the car is from you.I've drawn a line segment between you and the car.I don't know how long that line segment is.Well, imagining invisible right triangle here, I can use the Pythagorean theorem tomeasure the length of the hypothenus if I know the lengths of the two legs.This horizontal leg has length vt, the vertical leg has length b.The length of this hypotenuse, the length of this line segment is the square root ofthe sum of the squares of the lengths of the legs of the right triangle.How fast is the distance between you and the car changing?So I don't know how fast this, the distance between you and the car ischanging
* So take a derivative with respect to t.So this is the derivative of the square root of something.And the derivative of the square root function is 1 over 2 square root.So I'm going to be evaluating the derivative of the square root at theinside, which is vt squared plus b squared times the derivative of the insidefunction
* So the derivative of bt squared plus bsquared
* Now I'll just copy down the same thing, 1over 2 square root, v t squared plus b squared times.What's the derivative of this
* Well, it's the derivative of vt squared.So that's 2v squared t, plus the derivative of b, which is 0.So now I could write this all together
* I could, for instance, cancel this 2 andthis 2, and get that the derivative of the distance between you and the car is vsquared t over the square root of v t squared plus b squared.Let's take a look at this with a graph
* So here's a graph of that function.Remember, that function is the derivative of the distance between you and the car,so it's negative over here, because the car's distance to you is going down, andit's positive over here, because the car's distance to you is increasing.You can look at it here as a little tiny model.Here's the car
* Here's you right?The car maybe starts over here and then it drives past and how does the distancebetween you and the car change
* Well here the distance is getting less,less, less, less, less
* This is as close as the car gets to you.More, more, further, further, further away and that's exactly what you see from thisgraph, right
* The derivative's negative here because thecar is getting closer to you
* It's zero here when the car's as close asit ever gets to you and the derivative is positive over here because the car isgetting further away from you
* We can hear this in one of theexplorations on the website
* Here I've got a car, that's driving past.And here in blue is you, the observer
* Let's look at what happens when I turn onthe sound
* It's higher frequency and lower frequency.Higher, lower
* You're hearing the derivative.


--- SKIP ---: 01_how-fast-does-the-shadow-move.en.srt


--- SKIP ---: 01_how-fast-does-the-shadow-move.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-fast-does-the-shadow-move.en_SENTbySENT.txt
* [music] Here is a classic related ratesproblem
* So here's the question.You're walking away from a light source, at some speed, and you don't know how fastis your shadow's length changing
* There's a standard method to solving arelated rates problem, four steps
* So, step 1 is draw a picture, alright?You're told some sort of story, you should convert it into some diagram.Step 2, find an equation
* Given that picture, you should labeleverything in the picture so you can write down some equation.Step 3 is to differentiate that equation which would probably involve the chainrule
* And step 4 is to solve that equation forwhatever you're interested in finding out
* I mean, hopefully you're trying to findsome rate of something so, you're going to try to find one of these derivatives inthere
* Let's draw a picture to represent thisperson moving away from the light source
* Here's my picture, I've got a light sourceright here and I've got this person right here.And I imagine that person walking away from the light and I've drawn in theirshadow
* And I've drawn this beam of light justglancing across this person's head
* Now we'll turn this picture into anequation using similar triangles
* You might suppose that the originalproblem told us that the lamppost was 3 meters tall, and the person was, say, twometers tall
* And I can label the other relevant lengthson this diagram
* I'll call x the distance from the bottomof the lamppost to the person's feet, and the distance from the feet to the tip ofthe shadow, I'll call that s for shadow
* So, now I've got a nicely labeled diagram,and I can replace that nicely labeled diagram with a slightly more extractdiagram, where the person is now a vertical line, the lamppost is now avertical line, and I've got these triangles.The up shot here is that I've got similar triangles.This little triangle is similiar to this big triangle.Well, because the angles are all the same, right?Both of these triangles have a right angle here, they have the same angle here,consequently these angles are the same
* They're two triangles that have the sameangles, they're similar triangles
* And as a result, I get this equation outof the diagram
* This distance to this distance, x plus sto 3, must be the same as the corresponding ratio in to the othertriangle, which is this distance to this distance s over 2.With an equation in hand we can now differentiate.Thinking of my position and the shadow's length as a function of t, I could rewritethis equation as say, x of t plus s of t divided by 3 equals s of t divided by 2,right
* My position is a function of time and myshow's length is a function of time, and I can differentiate both sides of thisequation
* The derivative of this is 1 3rd, thederivative of x plus the derivative of s, and the derivative of the other side isone half the derivative of s
* And I could solve for the derivative of s.Let me first expand this out
* I've got 1/3 derivative of x plus 1/3derivative of s, is 1/2 derivative of s
* I'll subtract 1/3 s prime from both sides.Got 1 3rd x prime is 1 6th s prime
* 'Because a half minus a 3rd is a 6th.And then I multiply both sides by 6
* So I find out that s prime.This is the rate of change in the shadow's length is twice.X prime this is the speed for which the person is moving.There's a bit of a surprise to this answer.Take a look at this equation, It's telling you that the speed that your shadowslength is changing is just twice the speed that your walking.But it doesnt matter where your standing
* The value of x doesn't appear on this sideonly x prime appears on this side
* So that's kind of interesting right?The speed with which your shadow is growing only has to do with how fastyou're walking
* In fact, the speed at which your shadow isgrowing is exactly twice the speed at which you are walking.Assuming of course, you are two meters tall and the lamp post is three meterstall
* I think the important thing to take awayfrom this example is that similar triangles are hugely helpful.If you see similar triangles, use them
* There's also one thing that I think isvery funny about this particular solution to the problem.Here's the challenge for you to think about.If your velocity is 90% the speed of light, so you're almost going the speed oflight
* Then this formula would be telling youthat your shadow's length would be moving faster than the speed of light, is thatreally possible?


--- SKIP ---: 02_how-fast-does-the-ladder-slide-down-the-building.en.srt


--- SKIP ---: 02_how-fast-does-the-ladder-slide-down-the-building.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-fast-does-the-ladder-slide-down-the-building.en_SENTbySENT.txt
* [music].A classic related wraith problem involves a ladder leaning up against the side of abuilding
* Well, here's the setup.I've got a wall and the ground, and I've got a ladder resting on one side on theground, the other side, against the wall
* Ladder is 5 meters long and the bottom ofthe ladder is 3 meters from the base of a wall.I'm going to start pulling the bottom of the ladder away at a speed of one meterper second
* Just as I do this, how fast does the topof the ladder start moving down the side of the wall?That's the question
* I'm moving the bottom of the ladder.The ladder's sliding down the wall
* How fast is this side moving down thiswall
* So, remember we've got this four stepprocess
* The first step is to draw picture.Of course, I think this is already a pretty good picture.The second step is to write down an equation.So, I'm label everything in my diagram and then figure out what the equation is.So, now I want to label this, instead of 3, I'll call this distance from the wallto the base of the ladder, x
* And I'll call this distance from the topof the ladder to the bottom of the wall y
* And this speed, the speed with which I'mpulling the ladder away, that's really asking how quickly this distance ischanging
* So that's dx dt.So now I've labeled everything on my picture.So the equation here is just x squared plus y squared equals 5 squared becausethis ladder, even as it slides down the side of a wall, it still makes a righttriangle with this leg, this leg and this is the hypotenuse.And the length of the ladder doesn't change.It's always 5 meters long
* So, by Pythagorean theorem, tells me thatx squared plus y squared is 5 squared
* The third step is to differentiate.I'm going to differentiate the equation, regarding the variables as functions thatdepend upon t, time
* So let's take this equation anddifferentiate it
* So I'm going to be differentiating withrespect to time
* So d dt of x squared plus y squared is ddt of the length of the ladder
* Now the length of the ladder is notchanging, right
* The derivative of this constant is justzero
* How do I differentiate x squared plus ysquared
* Well, that's the derivative of a sum.So, it's the sum of the derivatives
* It's d dt x squared and d dt y squared.Now, I'm thinking of x and y as functions of t.So, I'm going to differentiate these with a chain rule.The derivative of something squared is twice the inside times the derivative ofthe inside plus, and now I gotta differentiate y thinking of it as afunction of t, and that's twice y times dy dt.That's zero
* Now I'll evaluate.So, now I just want to evaluate, all right?I know the values of x, dx, dt, and y, right?At this particular moment x is 3 meters, and dx dt is 1 meter per second, and y is4 meters
* And what I'm trying to figure out is dydt
* So, once I plug in what I know, I get thisequation
* And then I can easily solve for dy dt.And when I solve for dy dt, I get that dy dt is a negative 3/4 meters per second.Does the sign, the sign of that answer make sense?So, yeah
* Does it make sense that this is negative3/4 of a meter per second
* Well, take a look at our picture, right?I'm pulling the bottom of the ladder this way, right?So I'm moving the bottom of the ladder this way.And as I do that, the top of the ladder moves down the side of the building.Right
* So, as this distance, which is x, isincreasing, this distance, which is y, is decreasing.And so, yeah, it totally makes sense that dy dt is a negative.


--- SKIP ---: 03_how-quickly-does-a-bowl-fill-with-green-water.en.srt


--- SKIP ---: 03_how-quickly-does-a-bowl-fill-with-green-water.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-quickly-does-a-bowl-fill-with-green-water.en_SENTbySENT.txt
* >> [music] Let's fill up this bowl withthis green water
* We can graph the height of the water.On the x-axis, I've plotted time in seconds.And on the y-axis, I've plotted the water's height in pixels.And here's the curve that I get
* Each of these little crosses is one of themeasurements that I made at some given time, I measured the height of the waterand I get this curve
* What do you notice about this graph?So, one thing I notice right off the bat, is that the water level increases fairlyrapidly at first, but at the end of this process, the water level is stillincreasing but it's increasing more slowly.Of course, this makes sense since this bowl is narrower at the bottom than it isat the top, and the water is coming in at a constant rate.A bit more formally, alright, dv/dt, the change in volume of water over time,that's constant
* I'm pouring in water at a constant rate,but dh/dt starts off very large, the water's height is increasing very rapidlyat first
* And by the end of this process, dh/dt issmall
* So, I'd like a function that relates waterheight to volume
* Well, if I take a look at the side of thebowl, the bowl starts off fairly slanted, and then sort of flattens out, and that'swhat I'm graphing here
* I'm graphing the radius of the bowl.On the x-axis, I'm plotting the height, that's how far I am from the bottom of thebowl
* And as I move up the bowl, the radius ofthe bowl is increasing and that's what I'm plotting on the y-axis.And if you look at the bowl, right, the bottom of the bowl starts off very slantedand then it sort of flattens out
* And that's exactly what I'm representinghere with, with this broken line, right
* The bowl starts off fairly slanted andthen flattens out
* Once I know what the radius of the bowl isat a particular height, I can then think about the volume of water when then waterlevel is at some given height
* So, once I know the radius of the bowl ata particular height, from the bottom of the bowl, I can then make a graph thatshows the volume of water in the bowl, given a particular height of water.So, here on the x-axis, I'm plotting the height of the water.And on the y-axis, I'm plotting the volume of water in the bowl.And you can see that when the water is deeper, there's more water in the bowl.It's an increasing function
* Now, let's think a little bit about theslope of the tangent line to this graph
* The tangent line initially has not verylarge slope, compared to after a while, the tangent line has a much higher slope.And what that really means is that initially, for a given change in volume,there's quite a change in the height of the water.But after a while, the same change in volume leads to a less dramatic change inthe height of the water
* That really makes sense from our originalexperience, we poured all that water into the bowl.We think back to a graph of the water level in the bowl.Here, I've got time
* Here, I've got the height of the water.The water is flowing in at a constant changing volume per unit time.And initially, aIright, the slope of this tangent line is quite high, because thewater height is increasing very rapidly, but after a while, because there's thesame change in volume during this entire process, the change in the water height isless dramatic, right
* It's the same amount of water coming in,but the water's moving up the sides of the bowl less quickly.


--- SKIP ---: 04_how-quickly-does-the-water-level-rise-in-a-cone.en.srt


--- SKIP ---: 04_how-quickly-does-the-water-level-rise-in-a-cone.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_how-quickly-does-the-water-level-rise-in-a-cone.en_SENTbySENT.txt
* [music].>> Let's suppose that I have a cone of a certain size.Suppose, to make this very concrete, that I start with this little piece of acircle
* This circle has radius square root of 90centimeters, and the length of this arc here is a bit more than 18 centimeters,specifically, it's 6 pi centimeters
* I could cut this thing out, and then foldit up to make a cone
* Now let's fill that cone with water.How fast then, is the water level rising
* Here's a very specific setup for thisproblem
* All right, given this cone, here's thestory
* Water is pouring into that cone at theconstant rate of 1 milliliter per second, and remember that a milliliter of water is1 cubic centimeter of water
* Right now, there is pi milliliters ofwater in the cone
* So the current volume of water is pimilliliters of water in the cone
* More water is pouring in.The question is how fast is the water level rising?That's the related rates question
* I know how fast the water is coming in.I know the change in volume
* I want to know how quickly the waterheight is changing
* We can set this up as a related ratesproblem using the same four step process
* Draw a picture, write down an equation,differentiate that equation, and evaluate the resulting derivative.Now first I'm going to draw a diagram of the cone.I built the cone out of this little piece of a circle, a circle of radius squareroot 90 centimeters
* And this arc length is 6 pi centimeters.Now that's enough information to figure out the shape of the resulting cone.Since the curved part here is 6 pi centimeters, that tells me that thecircumference of this top circle of the cone is 6 pi centimeters.That tells me the radius of this is 3 centimeters.Now that's enough information now to figure out the height of the cone, allright
* I built the cone out of this piece ofcircle, whose radius was square root of 90 centimeters, and that ends up becomingthis length here, square root of 90
* And I know this length is 3, and what I'vereally got here is a right triangle
* All right?The hypotenuse has length square root of 90, this leg has length 3, and that tellsme that this leg, which is the height of the cone, is 9 centimeters.How does that diagram relate to the water level?Of course, what I'm really interested in is, how much water is in the cone.And the water has some height, which I'm calling h.And the water itself forms a cone, with some radius r.Now I need to write down an equation that relates all of these quantities.I'm trying to understand the volume of water in the cone, and here's the formulafor the volume of a cone of radius r and height h.The volume is one third pi r squared times h.The trouble is that there's really two variables here, not just one.Now if I think back to original shape of the cone, I can use similar triangles,right
* This big triangle is such that this lengthis three times this length
* And the triangle that I get here from thewater is similar to that original triangle.And that means that this length here, the radius, must be 1 3rd the height.That then lets me write down the equation for the volume of water, just in terms ofa single variable, h
* I can simplify this expression just alittle bit
* So I can combine the h squared and the hto give me an h cubed
* And the 1 3rd squared becomes a 1 9th,which combines with the 1 3rd, to give me 1 27th.So the volume is 1 27th pi times the height cubed.So now I've got an equation and I want to know how fast things are changing.So I differentiate
* So then I differentiate both sides herewith respect to time, thinking of v and h as a function of t.Well, now dv dt is the time derivative of v, and this is the time derivative ofthis, right
* The 1 27th pi is just a constant multiple.But I have to differentiate h cubed, thinking of h as a function of time.And I do that with the chain rule, and the derivative of something cubed is 3 timesthe inside function squared times the derivative of the inside, which is dh dt.To finish this problem off, remember what I'm trying to do.I'm trying to figure out dh dt
* I know v at this particular moment, and Iknow dv dt
* That's enough information for me to figureout dh dt
* Let's see how.Well here's what I'm initially told
* I'm told that there's pi milliliter ofwater currently in the cone, and I'm told that more water's pouring in at a rate of1 milliliter per second
* Now, I'd like to know the current waterheight, and I'm claiming it's 3 centimeters.I know that, because I've got this formula, right?I know that the volume is 1 27th pi times the current water height cubed.And in this particular case, if the volume is pi milliliters of water, then I cansolve for h, all right
* I divide both sides by pi and multiply by27 and I find that 27 is h cubed, and that means that the current water height is 3centimeters
* Now once I know that, I can take this factand the fact that I'm told dv dt, and plug those in to the formula that relates dv dtand dh dt
* Now I'm interested in dh dt, but I knowthat dv dt is 1
* And I know h, in this particular moment,is 3 centimeters
* Now all I've gotta do is just solve thisequation for dh dt
* And that's not so bad, right?The 3 times 3 squared that's a 27, which cancels this 1 over 27 and then I divideboth sides by pi and 1 over pi then is dh dt.So now I know how quickly the water height is changing.It's changing at the rate of 1 over pi centimeters per second at this particularmoment
* All told, this is a great example ofrelated rates
* I mean, there was all this geometry that Ihad to do to figure out the original shape of the cone.And then the formula for volume involved both the radius and the height of thecone
* And I had to do similar triangles to writedown a single equation for the volume of the water, in terms of the water height.And then I differentiated that, and then I went back and plugged in the originalvalues that the statement gave me to figure out dh dt.So this is really a great example of all those pieces coming together.


--- SKIP ---: 05_how-quickly-does-a-balloon-fill-with-air.en.srt


--- SKIP ---: 05_how-quickly-does-a-balloon-fill-with-air.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_how-quickly-does-a-balloon-fill-with-air.en_SENTbySENT.txt
* [music].>> I'm going to blow up this balloon
* Let's suppose that I'm blowing air intothat balloon at a constant rate, so the balloon's volume is changing at a constantrate
* How quickly is the radius of the balloonchanging
* We can model the balloon as a sphere.And recall the volume of a sphere in terms of its radius r.The volume of a sphere of radius r is 4 3rds pi r cubed.So how fast does the radius change as I blow the balloon up?So I've got the original equation for the volume of a sphere of radius r.I'm going to differentiate both sides with respect to time.So the derivative of v, with respect to time, is I'm going to write dv dt.And the derivative of the other side, with respect to time, we've gotta think alittle bit more about
* Now 4 3rds and pi are just constants.So I can pull them out of the derivative
* But I've still gotta figure out what thetime derivative of r cubed is
* To figure out the time derivative of rcubed, I'm regarding r, remember, as a function of t.So I use the chain rule, and the derivative of cubing is 3 times the insidefunction squared times the derivative of the inside function, so dr dt.So dv dt is 4 3rds pi times 3 times r squared times dr dt.Let's solve for dr dt, the rate of change in the balloon's radius.All right, so I'm going to solve for dr dt.Well, first thing I can do is, I've got a dividing by 3, and a multiplying by 3.So I don't need to do both of those operations.So this is 4 pi r squared times dr dt
* The other side is just dv dt.So I'll divide both sides by 4 pi r squared.And I'll find out that, dr dt is dv dt divided by 4 pi r squared.Can we really make use of this equation
* I, does this help us at all?Yeah, this makes sense
* We started with the original equation forthe volume of a sphere in terms of its radius.And I differentitated this equation
* And then solved for dr dt.And what this equation is telling me is that the change in radius, which is whatdr dt is measuring, the rate of change in the size of the balloon, well, it dependson how quickly the volume's changing, which is dv dt.But it also depends upon the radius, right?This is this r squared in the denominator
* In particular, a really big balloondoesn't get a whole lot bigger for a given change in volume, compared to a littletiny balloon, which gets quite a bit bigger for the same change in volume.It all has to do with that r squared in the denominator.When the balloon's radius is very small, a given change in volume results in quite adramatic change in the radius
* But once the radius is large, the rsquared in the denominator means that dr dt is then much smaller for the samechange in volume
* Another breath, and yeah, I mean, thething's still getting bigger, but much less dramatically..


--- SKIP ---: 01_why-is-optimization-part-of-this-course.en.srt


--- SKIP ---: 01_why-is-optimization-part-of-this-course.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-optimization-part-of-this-course.en_SENTbySENT.txt
* [MUSIC]
* We're often trying to pick the best ofsomething
* We're trying to optimize our lives
* Right
* We're given a bunch of choices, and we'vegot to make the best choice
* But how do we do this
* How do we do optimization
* Well, if I've only got 17 choices, I canjust try all 17 choices
* But what if the optimization problem ismore complicated
* What if I've got infinitely many choices
* What if I've got a function
* It takes a real input, and produces somereal output
* And I want to figure out which thing can I plug into this function, to give me thebiggest possible output
* There's lots of problems in the realworld, where this is basically the situation thatyou're in
* You know
* You get to choose how many hours that you work today, and that's really a, a realnumber
* Alright
* You can choose any number between zero and24
* And then you've got some sort ofhappiness, right
* There's some sort of effect on your lifeonce you've made that choice
* And you're trying to figure out how manyhours should you work today, to make yourself as happyas possible, say
* And that's really this kind of problem
* It's a problem where you've got afunction, which takes a real input, produces a real output, and you've got to figure out which input, makes the output as big aspossible
* Well, unlike a situation where you've onlygot finitely many choices, you just try themall
* When you've got infinitely many choices
* When your choice could be any real numberbetween 0 and 24, how can you choose
* You know
* You can't just try them all
* And it turns out that calculus comes intoplay
* We can use calculus to solve these kindsof optimization problems
* [MUSIC]


--- SKIP ---: 01_what-is-the-extreme-value-theorem.en.srt


--- SKIP ---: 01_what-is-the-extreme-value-theorem.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-extreme-value-theorem.en_SENTbySENT.txt
* [music] Subject to some conditionsfunctions are guaranteed to have maximum and minimum values here is the extremevalue thery it says that if a function F is continuous under closed.Interval a, b, then the function attains a maximum value and the function attains aminimum value
* If you don't like this, you can make it alittle bit more precise
* Here's a slightly more precise statementof the extreme value theorem
* It says: "If a function f is continuous onthe closed interval a, b," then this is really just making clear what I mean by,"attains a maximum value and attains a minimum value." All right?What I really mean is that there's some point, c and d In this interval so that nomatter what other value I pick in that interval, f of c is less than or equal tothat other value, and f of d is bigger than that other value.So f of c is the minimum value
* C is where f achieves that minimum value.And f of d is that maximum value
* D is where the function achieves thatmaximum value
* The extreme value theorem promises us thatthese extreme values exist, but it doesn't tell us how to find those extreme values.I mean, you could have a complicated looking but continuous function on theclosed interval between a and b
* And it might be hard to actually determinewhere the maximum value occurs, but the Extreme Value Theorem tells you that themaximum value is achieved somewhere on that closed interval.Nevertheless, even in that example, there are extreme values, it's just hard to findthem
* Now maybe that all seems obvious.One way to understand the extreme value theorem is to try to break it.Try to mess with it someone and see if it still works.This is sort of the car method to doing science, right?If I'm studying cars and I want to know what's important to making a car go.Well, I used to just take off the wheels and then see if the car still works.Doesn't work so well, right
* The fact that the car doesn't work when Ibreak the car's wheels off tells me that the wheels are important for the car,right
* Same game with this theorem.I want to figure out what the important parts of this theorem are so I'm going totry to break this theorem in various ways and if the theorem doesn't after I breakit, well that must have been an important part of the theorem.What if, for instance, we were studying a function on the domain zero to infinityincluding zero
* So, yeah, what if instead of closedinterval between these two numbers a and b, I'll have infinity be one of thosenumbers
* Then of course, then I have to make thatan open parenthesis there
* So if a function's just continuous on theinterval between zero and infinity including zero, does that mean that itactually achieves its maximum minimum values?Well no think about this example the function F of X equals X define on thatinterval this function does not achieve a maximum value.If you tell me that some number is the maximum output of this vunction I'm justgoing to add one to wahtever you say and that'll be a bigger to this function.This function does not acheive it's maxium output at given input.What if we were studying a function on a domain that was an open interval?Yeah, so what if instead of closed interval, I just said open intervalbetween these two numbers a and b
* Well then the function would not beguaranteed to have a maximum or minimum value, then take a look at this.Here is an example of a continuous function defined at an open interval minuspi over 2 and pi over 2 and this function does not achieve a maximum or minimumvalue on this interval
* I can make tangent as positive or asnegative as I'd like by choosing x close enough to one of these end points.What if I try to mess up the extreme value theorem by eliminating the condition atthe function being continuous
* So yeah, what if I break the statement ofthe extreme value theorem by removing the continuity equation because I'm notrequired the function be continuous anymore.So, if it's just some function that's defined on a close interval between a andb, does it guarantee the function that choose the maximum and minimum value.No
* Here's an example.Here's a picture of a graph of a discontinuous function and it's defined inthe closed interval between a and b, but here you can see that it's approachingsome value but never achieving that value and here it's approaching some value butnever achieving that value
* So this function does not Actually attainits maximum and minimum value on this interval.To get a better sense of what's going on, here's a much fancier way to talk aboutthe possible output values of a function
* So let's write I to represent someinterval
* It could be the open interval between aand b, the close interval between a and b, whatever, right?I is just a set of numbers
* What's f of a collection of numbers?What does that even mean
* Well this is the collection of all theoutput values if the input is in I
* So f of I is the set, or collection, ofall the f of xs whenever x is some point in the set I.And people sometimes call this the image of I.We can use this terminology to rephrase what we've been talking about.For example, the continuous image of a bounded interval, a bounded interval likethis interval between 2 numbers, need not be bounded.Here's an explicit example that we've already seen, take a look at thiscontinuous function, Function, tangent of X.Then we look at the continuous function
* Remember to look at the image of someinterval
* Here is a interval.And what's the output of this function if the input is between minus pi over 2, andpi over 2
* Well, the output can be anything.Alright
* So f of i is all real numbers.So even though I'm starting with things that aren't very big.The output is as big or as small as I'd like it to be.What it that bounded interval is also closed?A much fancier way of stating the extreme value theorem is to state this result.That the continuous image of a closed bounded interval is a closed boundedinterval
* You can really try this for yourself.You write down some crazy continues function so who knows what this continuesfunction might be some continues function and some interval which I'll call I.>> Between two numbers A and B
* So it's bounded because A and B arenumbers, right, and it's closed because I'm using the square brackets.And then what I want to think is what is all the outputs whenever the input is inI
* Well this is going to be the closedinterval
* Right, what's the smallest value, what'sthe minimum value that the function achieves?And the biggest output is just going to be whatever the maximum value is that thisfunction achieves
* So this statement that, continuous imageof a closed, bounded interval is a closed, bounded interval is really getting at thesame idea
* It's the extreme value theorem, saying ifyou start with a continuous function on some closed, bounded interval Then theouptputs are going to be between
* Including the minimum and maximum value.And the fact that these are square brackets here.The fact that these are closed interval are crucial.Because I'm telling you that the minimum value is actually achieved.And the maximum value is actually achieved.This way of talking is also useful for something like the intermediate valuetheorum
* So, yeah.You could say it's true that the continuous image of an interval is aninterval
* So if you take an interval and you pickyour favorite continuous function, f of that interval is just some other interval.That's the same as saying that over values in-between are achieved and that's reallywhat the intermediate value theory is getting at.This is just a very succinct way of stating the intermediate value theorem.The upshot here is that we're seeing there's something really special aboutcontinuity
* So here again is the extreme value fare Imean what we've learned is that continuity is really important.If someone just shows you some function that's not continuous don't expect thatyou're going to be able to find any extreme values they might not exist.It's also really important that this is about closed interval between two numbersalright a closed and bound interval and that's really important and if you'rebeing asked to find maximum minimum values not on a closed interval say you shouldn'texpect that they necessary exist
* They might not be there.So this theorem's going to help guide you towards the correct answer because ittells you what sort of answer to expect.


--- SKIP ---: 02_what-sorts-of-optimization-problems-will-calculus-help-us-solve.en.srt


--- SKIP ---: 02_what-sorts-of-optimization-problems-will-calculus-help-us-solve.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-sorts-of-optimization-problems-will-calculus-help-us-solve.en_SENTbySENT.txt
* [music].Welcome back to Calculus One, and welcome to week eight of our time together.Last week, during week seven, we began studying applications of the derivativeand we focused in on related rates problems.It's not so surprising, I think that calculus can solve these related ratesproblems
* After all calculus is all about how thingschange, so it makes sense that you could use calculus to study how things arechanging together
* This week, in week eight, we focus onoptimization problems
* Optimization problems are all about thebest of something, right
* You want to find the shape of a soup canthat maximizes the amount of soup for a given amount of metal.Or you want to find the shape of rectangular fence that encloses the mostarea for a given length of fence
* Or you want to find the shape ofrectangular fence that encloses the most area for a given length of fence.Or you want to understand why bubbles form the shapes that they do or why lighttravels on the paths that it does
* Right?All of these are problems about finding the best of something and that's reallydifferent in related rates problems
* Right?We're not just asking about how something changes, I'm actually trying to find apoint where some function achieves a maximum or a minimum value.And I think it is really surprising that calculus, which fundamentally, is allabout how things change can also be used to solve that problem.It can also be used to find a specific value or something really exiting happens.I also want to say thank you
* It's is a long and difficult course, andyou've made it now, more than half way through.Congratulations.


--- SKIP ---: 01_how-do-i-find-the-maximum-and-minimum-values-of-f-on-a-given-domain.en.srt


--- SKIP ---: 01_how-do-i-find-the-maximum-and-minimum-values-of-f-on-a-given-domain.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-do-i-find-the-maximum-and-minimum-values-of-f-on-a-given-domain.en_SENTbySENT.txt
* Provided some conditions are satisfied,the Extreme Value Therom guarantees the existence of maximum and minimum values.But how am I supposed to find those maximum and minimum values?We've actually already done this in some examples, but it's worth describing anexplicit process for finding maxima and minima.Here's a frour-step process
* First, differentiate your function Canfind all the critical points
* Those are places where the derivative isequal to zero or the derivative isn't defined.And also lists the end points if they're included in your domain.Check those points, right
* Check the end points, check the criticalpoints, and potentially you also need to check the limiting behavior if you'reworking on an open Interval
* Let's work an example.Okay, let's work an example
* Let's look at the function, given by therule f of x equals 1 over, x squared minus 1.This quantity squared
* But let's only consider this function on arestricted domain
* Let's consider, a maximum, minimum valuesof this function on the interval between minus 1 and 1.This open interval
* And now I differentiate.Yeah, the first step is to differentiate this function.So before I differentiate it, I'm just going to rewrite this.Instead of 1 over x squared minus 1 squared, I'm going to write this as xsquared minus 1 to the negative 2nd power
* It's going to make it a little bit easierfor me when I think about the derivative
* So what's the derivative of this function?By the power rule and the chain rule This is negative 2 times the inside, x squaredminus 1 to the negative 3rd power times the derivative of the inside which is 2xor another way to write this is negative 2 times 2x, that's minus 4x divided by xsquared minus 1 to the third power
* With the derivative in hand, I can findthe critical points
* Yeah, the next step is to list thecritical points, and also the end points if they're included.So let's see
* What are the critical points of thisfunction
* Will those be places where the derivativedoesn't exist, or the derivative is equal to zero.Let's first think about when the derivative is equal to zero.Well, in order for that derivative to be equal to zero, it's a fraction.When's a fraction equal to zero
* Well, that occurred exactly when thenumerator is equal to zero
* So I'm really just asking when is minus 4xequal to zero
* And that's just when x is equal to 0.So the only time when the derivative is equal to 0 is when x is equal to 0.Now the derivative doesn't exist when x is equal to 1 or when x is equal to minus 1but, you know, the functions not even defined in that case anyway.And I'm only considering numbers between minus 1 and 1 anyhow.Don't have to worry about those
* And I don't have to worry about endpoints
* Because, again, the interval that I'mconsidering doesn't include the end points, It's an open interval.So I'm just going to check x equals zero to figure out what's going on there.So let's think about this point where x is equal to zero.Well the derivative at zero is equal to zero.If I just plug in zero into this I can see that.What's the derivative at a number between minus 1 and zero?Well if I plug in a number between minus 1 and zero, x squared is then between zeroand 1, so x squared minus 1 is now a negative number cubed.The denominator is negative, but this is a negative number, negative 4 times anegative number
* So we've got negative times negativedivided by negative, that's negative
* So the derivative at a number betweenminus 1 and 0 is negative in this case
* And a similar kind of reasoning will showthat the derivative is positive if I evaluate the derivative between 0 and 1.So here is the deal
* I've got one critical point on thisinterval between minus 1 and 1
* And the function's decreasing betweenminus 1 and 0, and it's increasing between 0 and 1.So what does that mean about the point 0
* Well it means that the point 0 must be aplace where the function achieves a local minimum value.So I can summarize that here, f of 0
* Is by, this is the first derivative testis a local minimum value
* What about the end behavior?What happens when x is near negative 1, or when x is near 1?So that's really step 4 in this checklist, is to check the limiting or the endbehavior of this function
* What do I mean by that?I really mean look at this when X is just a little bit bigger than minus Y, or X isa little bit less than 1
* Alright, that's the end behavior of thisfunction
* These end points are actually included soof course I can't evaluate the function there but I should still see what happenswhen X is close to these endpoints
* Let's imagine I was trying to draw a graphof the function, alright
* How would I know from the derivative.I know the function's decreasing here and increasing here.And I know the function's got a local minimum value here, but linking to thefirst derivative test
* So the function's going down and then it'sgoing up
* But what happens at these two Values, whenI get close to minus 1 and when I get close to 1.When I get close to minus 1, the function is very, very large, and when I get closeto 1, on this side, the function's also very, very large.So if I imagined trying to draw a graph of this function?Right, it would be coming down like this, flattening out and then it would begetting very, very large again
* Let's summarize the situation.This graph will help us summarize the situation.Alright, what do I know
* I know that F of 0 is the smallest output,it's the minimum value that the function achieves on the domain, open intervalminus 1 to 1
* And there's no maximum value.By considering this limiting behavior, as x approached to the endpoints which aren'tincluded in this domain
* I can see that this function's output canbe made as positive as I'd like, right
* I can choose values of X to make theoutput as big as I want
* So I can't say this function actuallyachieves some maximum output value
* It doen'st achieve some maximum outputvalue
* But it does achieve a minimum output valueright here
* When x is equal to 0.And that output is 1
* It's important to emphasize that thedomain truly matters
* Yeah, what if I ask to find the maximumand minimum values of the same function f of x is equal to one over x squared minusone squared, but a different domain?What if I looked on the interval from one toinfinity this open interval
* Again we start by differentiating Well ofcourse, the derivative's the same
* The derivative of this function is stillminus 4 x over x squared minus 1 to the third power.Now, where are the critical points
* The only place that this derivative isequal to 0, is when x is equal to 0
* And the only place where the derivativedoesn't exist is just places where the function isn't even defined, right?So on this interval
* From one to infinity, there's no placewhere the derivative isn't defined or is equal to zero.So there's no critical points
* So what about the behavior near theboundaries of this interval
* What happens if X is just a little bitmore than one or when X is really, really big?So, we working on the interval from 1 to infinity.This open interval
* So, that means the limits that you'dconsider are the limits, the function as x approaches infinity and the limit of thefunction as x approaches 1 from the right hand side.And, doing calculation I find that the limit of the function as x approachesinfinity is 0 because, in that case the denominator can be made as large as Ilike, which makes this ratio as close to 0 as I like.And, the limit of the function as x approaches 1 from the right is equal toinfinity
* Because in that case if x approaches 1from the right this denominator can be made as close to 0 and positive as I'dlike which makes this ratio as large as I'd like.So in this case this function on this domain doesn't take a largest value anddoesn't take a smallest value
* The function's output can be made as bigas I'd like if I'm willing to choose x just a little bit bigger than 1 and thefunction's output can be made as close to 0 as I'd like if I'm willing to choose Xto be big enough
* In other words, the domain matters.I mean this function, if I'm considering the funciton on this domain, from -1 to 1.It does have a smallest output value
* And it should use its local minimum valuewhen x is equal to 0
* But if consider the same function.But on a different domain there's no critical point on this domain, right?And I studied the limiting behavior as x approached one, and as x approachedinfinity, and I found that I could make the output of this function as large asI'd like and as close to zero as I'd like
* So this function doesn't achieve a maximumminimum value on this interval.


--- SKIP ---: 02_why-do-we-have-to-bother-checking-the-endpoints.en.srt


--- SKIP ---: 02_why-do-we-have-to-bother-checking-the-endpoints.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_why-do-we-have-to-bother-checking-the-endpoints.en_SENTbySENT.txt
* [music] Really, why do we have to evenbother checking endpoints
* So, let's suppose that I want to find themaximum-minimum values of this function f of x equals x minus x cubed.That function, f, if I considered on the whole real line, doesn't achieve a maximumor minimum value
* F of x is really negative if x is reallypositive
* And conversely, f of x is really positiveif x is really negative
* True enough.So, let's ask a better question
* What if I want to maximize and minimizethis function on the closed interval for minus 3 to 3?This is now a continuous function on a closed bounded interval.So, the extreme value theorem guarantees that I'll be successful, right?It guarantees that there is some input which minimizes this function's value andsome input which maximizes this function's value on this interval.I'll begin by listing off the critical points for this function.So, I'll differentiate this function, right?And if I differentiate that function, the derivative of x is 1, and the derivativeof minus x cubed is minus 3 x squared
* Alright, so, there's the derivative.I'm looking for places where the derivative is equal to 0, or thederivative doesn't exist
* Well, this function is differentiableeverywhere
* So, there's no critical points where thederivative doesn't exist
* But there are going to be some placeswhere the derivative is equal to 0
* Let's find them now.So, I'm trying to solve this equation
* I'll add 3x squared to both sides, I'mreally trying to solve the equation, 1 equals 3x squared.Divide both sides by 3, so now, I'm trying to solve the equation 1 3rd equals xsquared
* Now, I'll take a square root of both sidesand I'll find that x is equal to the square root of a third or maybe negativethe square root of a third, so I'll write x is plus or minus the square root of athird
* These are the two critical points for thisfunction
* Oh, I'm also going to be careful to listthe endpoints
* And we'll see why we have to.So, here are the points that I should check, right?I should check the critical points, and I just found those two critical points.Negative square root of a third, and positive square root of a third.And I also want to check the endpoints, right?And my original question is asking me to maximize and minimize this function onthis interval, which includes the endpoint minus 3 and the endpoint 3.So, I'm going to include those on the list of points to check.So, where does this continuous function achieve its maximum value?And where does this continuous function achieve its minimum value on the givendomain
* So, let's go ahead and just evaluate thefunction at those four points
* Here are the endpoints, minus 3 and 3, andthe critical points plus or minus the square root of a third.And when I evaluate the function at these points, what do I find?Well, I find that the largest output occurs when x is negative 3.And the smallest, the most negative output occurs when x is equal to 3.At these critical points, the outputs, you know, in size no bigger than 1, it's about0.38
* What nightmarish scenario would've ensuedhad I forgotten to include the endpoints
* Well, here's the danger, right?This is actually what I'm saying
* I'm saying that if x is in this closedinterval, then the largest value of the function occurs when x is equal to minus3, and the smallest value occurs when x is equal to 3.If I hadn't included the endpoints in my chart, I would have been fooled intothinking that the largest output of this function was 0.38.But on this interval, on this closed interval between minus 3 and 3, thelargest output actually occurs at this endpoint.The upshot to all of these, is that the endpoints are, in some sense, criticalpoints
* Standing at an endpoint, you can't wigglefreely, so you really can't differentiate when you're standing at an endpoint.And a place where you can't differentiate that's one of the critical points.


--- SKIP ---: 03_why-bother-considering-points-where-the-function-is-not-differentiable.en.srt


--- SKIP ---: 03_why-bother-considering-points-where-the-function-is-not-differentiable.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_why-bother-considering-points-where-the-function-is-not-differentiable.en_SENTbySENT.txt
* [music] Why do critical points have toinclude places where the function fails to be differentiable?Here's a specific example that we can work through to see why it's necessary to checkpoints of non-differentiability
* You'll notice that I've included someabsolute value brackets to introduce some non-differentiability, okay?Anyway, here's the problem
* Find maximum and minimum values of thisfunction
* X minus the absolute value of x squaredminus 2 x, and do it on the interval between 0 and 3.Well, how do I proceed
* Let's differentiate, okay?So, I differentiate f prime is, well, the derivative of x is 1 minus the derivative.Okay, whoa, wait, what am I going to do about differentiating this absolute value?I can rewrite this function as a piece wise function, getting rid of the absolutevalue
* So, here's the original function where Igot an absolute value, and remember what absolute value does.Absolute value negates this input if the input's negative, right?So, the absolute value guarantees that it's output is positive with the samemagnitude as the original input
* So all I've got to do to rewrite f as apiece-wise function is to deal with that, right?I've just got to make sure that if this input is negative, then I better flip thesign, the sign of the absolute value
* Now, I want to know the derivative of thisfunction and I can compute that by just differentiating each piece in mypiece-wise define function
* So, here I go.I'm going to differentiate these two pieces separately.So, the derivative of f is also now a piece-wise function and I shoulddifferentiate this
* The derivative of x is 1 minus thederivative of this which is 2 x, that's the derivative of x squared, and thederivative of 2 x is just 2
* And this is if x squared minus 2 x.So, bigger than zero
* And the derivative of this is 1 plus thederivative of this, which is 2 x minus 2
* And this is if x squared minus 2 x is lessthan zero
* And you'll notice that I'm careful tochange the greater than or equal to here to just greater than.And the reason is because this derivative is not going to be defined when thisquantity is equal to 0
* Now, it is time to hunt for criticalpoints
* So, to simplify our hunt for the criticalpoints, I can rewrite f prime a little bit to make it a little bit easier to seewhat's going on
* So, what can we do here?Well, 1 minus 2 x minus 2, that's the same thing as three minus 2 x and 1 plus 2 xminus 2
* That's the same thing as minus 1 plus 2 x.Alright, and then I can rewrite this x squared minus 2 x greater than 0, and xsquared minus 2 x less than 0
* To say that x squared minus 2 x is biggerthan 0 is the same as saying that x is less than 0, or x is bigger than 2, and tosay that this is less than 0 is just to say that x is trapped between 0 and 2.Alright, now that I've got this nicer way of writing the derivative I can veryvisibly see that something terrible is happening when, when x is equal to 2.Because if this thing were differentiable there, you'd expect this quantity and thisquantity to agree when x equals 2
* But these things disagree when x is equalto 2, alright
* So, this function ends up not beingdifferentiable at 2
* Where is this thing equal to zero?Well, 3 minus 2x would vanish if x were 3 halves.But 3 halves doesn't satisfy this
* So, this first thing never results in acritical point where the derivative vanishes.What about this
* What about minus 1 plus 2 x?Well, this is equal to 0 if x is equal to a half.And that is in this region
* So here, what we know the derivative isequal to 0 if x is equal to a half and the function's not differentiable when x isequal to 2
* Well, a function's also not differentiablewhen x is equal to zero
* But remember, the end points of ourinterval that we're considering are 0 and 3.So, if you like, you can include 0 as a point of non-differentiability.But, it's in this list of end points so we're going to have to consider it anyhow.Note that there's something really special in this particular example.I really want to emphasize that 2 is a critical point not because the derivativeis equal to 0, but because the function is not differentiable at the .2.So, to finish off this problem, to find the minimum and maximum values of myfunction f, all I have to do is check the critical points and the endpoints.So, here's our endpoints, 0 and 3, a place where the derivative vanishes when x isequal to 1 half and a place where the derivative is not defined when x is equalto 2
* And where were the original function is?Alright, f of x is x minus the absolute value of x squared minus 2 x.So, what do we get when I plug in 0
* I just get 0.And when I plug in 3, I also get 0, right
* 3 minus, well, 3 squared is 9 minus 2times 3, that's 9 minus 3, that's 3
* 3 minus 3 is also 0.When I plug in 1 half, I get minus a quarter.And when I plug in 2, I get 2
* So, I've got my table.Where is the maximum and where is the minimum?So, the minimum value is here, when x is equal to 1 half, the functions minimumvalue is minus quarter
* And the maximum value is when x is equalto 2, the function's output is 2
* Had I not been careful to include x equals2, the point where the function fails to be differentiable,.I would have totally missed out on finding the maximum value of this function.It's really easy to see why this is so important by taking a look at a graph.We'll use the graph of this function x minus absolute value of x squared minus 2x on the intervals 0 to 3
* And you can see the minimum value occurswhen x is equal to 1 half and the maximum value occurs when x is equal to 2.And that point really is a place where the function's not differentiable.I mean, that's exactly why I see a corner there.The upshot here is that a point of non-differentiability, a place where thefunction fails to be differentiable could very well be where the maximum valueoccurs
* You can think of calculus as a maximumfinding machine and you're trying to find those maximum values.So, if Calculus fails you at some place, if the maximum finding machine is brokenfor some particular input, that could very well be where the maximum value is hiding.So, you're going to need to check there.


--- SKIP ---: 04_how-can-you-build-the-best-fence-for-your-sheep.en.srt


--- SKIP ---: 04_how-can-you-build-the-best-fence-for-your-sheep.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_how-can-you-build-the-best-fence-for-your-sheep.en_SENTbySENT.txt
* [music].Let's pretend that you're a shepherd and you want to build a fence for your sheep.Specifically, let's say that you've got 52 meters of fencing.And you're committed to building a rectangular pen for your sheep next toyour barn
* So how big of a sheep pen can you buildwith that much fencing
* Process is a standard one, it's got fivesteps
* The first thing I'm going to do is to drawa picture of the situation
* With a picture in hand and everythinglabelled with variables
* I can write down the thing I'm tying tooptimize, the goal
* With that, I can also write down theconstraints, right
* Not every combination of variables maybemake sense
* Maybe some domain issues to consider aswell
* Then in step four, I'm going to solve mygoal for a single variable
* And once I get a function of a singlevariable, I can apply calculus
* Right?This last step really means to say differentiate the function of a singlevariable, find the critical points, figure out where the largest and smallest valuesare
* That's my five-step process.First, I draw a picture, so let's rearrange this in a slightly nicerpicture
* I'll build my little sheep pen here.Here's my rectangular pen for my sheep that I built next to my barn.And I'd better label the side lengths here.The top and bottom will be x meters long and this side here will be y meters long.Now, what is it that I'm trying to maximize?Well, I want the fenced in area here to be as big as possible.So the thing I'm trying to maximize is the area of this pen and that area is x timesy
* Now at this point, you probably think,well I know how to maximize that function
* I'll just pick x and y to be absolutelyenormous
* And if an enormous number is multiplied byan enormous number, if I multiply x times y, the output will be enormous.Right, I'll build a sheep pen the size of the Milky Way.But there's a constraint
* Yeah, I mean, I can't simply build thisfence as big as I like, because I've only got 52 meters of yellow fence to beginwith
* So the constraint is that the length ofthis fence, which is 2x plus y is 52
* I'm saying equal 52, because I might aswell use all of the fence that I have to build this sheep pen.Another way to say that, is that this is what I'm trying to do.I'm trying to maximize this quantity, the area of the pen, subject to the constraintthat 2x plus y, the length of fence in my pane is 52 meters and I should say that xand y are nonnegative quantities
* It doesn't make any sense to make one sideof my sheet pane negative
* Now, I use to constraint to solve thething I'm trying to optimize for a single variable.Okay
* So I'm going to solve this for a singlevariable
* I've got that 2x plus y is 52, so I couldsolve for y, y is 52 minus 2x
* The quantity that I'm trying to maximizeis x times y, but if y is 52 minus 2x, then, I'm really trying to maximize xtimes 52 minus 2x, because this quantity is y.So this Is the function of a single variable that I'm trying to maximize.Okay, fantastic
* Now, I've got a function of one variableso I can apply calculus
* I can differentiate this thing and searchfor the critical points
* So let's call this a function f.So f of x is x times 52 minus 2 x, that dot is multiplication.I could distribute this and write f is 52 times x minus 2 x squared.Now, I can calculate the derivative, the derivative of f is the derivative of 52xminus the derivative of 2x squared
* The derivative of 52x is just 52.The derivative of 2x squared is 4x
* So, the derivative of f is 52 minus 4x.The critical points are places where the function's derivative vanishes or thefunction is not differentiable
* This function is polynomial, so it'sdifferentiable everywhere
* The only thing I have to worry about then,for critical points, is when this derivative is equal to zero.So for what values of x is that equal to zero?Well, the only place where this derivative is equal to zero is when x equals 13.I should also remember that I'm maximizing this function subject to this constraintand there were also some domain issues
* I don't want x to be negative.And, in order to ensure that y is nonnegative, if 2x plus y is 52, then xcan't be negative, but x also can't be bigger than 26.So, what's the situation here
* Well, I can summarize it.My critical points
* Well, there's really only one criticalpoint and the critical point is when x is equal to 13.Then I've also got some endpoints, right
* The endpoints to consider are when x isequal to 0 or when x is equal to 26
* So these are the three points to check.Now, I just have to figure out which of these values results in the best fence.All right
* So these are the three points that Ishould check, so I'll make a little table here.The x values that I'll check are 0, 26, and 13.And I'll figure out what the corresponding y value is and then I'll figure out xtimes y, which will be the area of the fenced in region if I use these as my sidelengths for my sheep pen
* So, let's see.If x is equal to 0 and I satisfy this constraint that 2x plus y is 52.If x is equal to zero, then y must be 52
* And if x is 26, then 2 times 26 plus whatgives me 52
* Well, then y is equal to 0.And if x is 13, then 2 times 13 is 26, plus what gives me 52?Well, then y must be 26
* Now, in each of these three cases, I canfigure out what the area of the resulting sheep pen would be.0 times 52 is just 0 and 26 times 0 is also 0.13 times 26 is 338
* So here, this is the best choice for mysheep pen
* This isn't just a great calculation.I hope that, intuitively, this method really makes sense.I mean, look, if x is equal to 0, that means I'm building my sheep pen justentirely up against the side of the barn
* And if y equals 0, well, that means I'mbuilding my sheep pen like this
* I'm just building fence that goes over andthen fence that comes right back
* Again, there's no area that this so-calledpen is enclosing
* That x equals 13 and y equals 26 is thebest choice for our sheep is clear if you think about how wiggling x would affectthe area of the sheep pen
* So here is the best solution, right, tohave x be 13 and y be 26
* What if I were to push this fence in justa little bit, all right
* I'd make the x values a little bit smallerand then make the y value a little bit bigger to compensate, right?Maybe x is 12 and y is 28
* Why is this worse?Well, think about what happens when I change from x equals 13 to x equals 12.I give up this region here and that's 26 square meters of fenced in region.I gain this region up here and this region up here, but this region up here is 12square meters and this region here is 12 square meters.So I'm giving up 26 square meters to gain 24 square meters.That's a bad deal
* This is really the whole crux of thematter
* Right?When you found the best thing, small changes to the best thing, don't make itbetter
* But if you hadn't found the best thing,then you could make a small change that would make it better.That's the whole idea, right
* That understanding how functions changecan be used to understand the best output for a function.


--- SKIP ---: 01_how-large-can-xy-be-if-x-y-24.en.srt


--- SKIP ---: 01_how-large-can-xy-be-if-x-y-24.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-large-can-xy-be-if-x-y-24.en_SENTbySENT.txt
* [music] Here's kind of an old timey puzzleabout numbers
* Suppose you've got 2 numbers which add upto 24
* You've got 2 numbers that sum to 24.How large can their product be
* When you take those 2 numbers that add upto 24, how big of a number can you get when you multiply them together?This is an optimization problem so let's draw a picture.Okay, maybe I can't draw a picture in this problem but at least I can label things.So, instead of just saying two numbers that sum to 24, let's give them the name.Two numbers, x and y, which sum to, to 24
* And instead of just saying how large cantheir product be, I can say, how large can, you know, x times y be?So, what's the goal
* Well, my goal here is really just tomaximize the product, so maximize x times y.And there's a constraint
* The constraint is that x and y have to addup to 24
* So, I'll write that as x plus y equals 24.Rats
* X,y isn't a function of a single variable.I need to rewrite it so it's a function of x alone.Now, since x plus y is 24, I could rewrite this as y equals 24 minus x.And consequently, x times y, which is the thing I'm trying to maximize, I couldwrite that as a function of a single variable, x times, and instead of y 24minus x
* So, this is the quantity now that I wantto maximize
* Now, I can apply Calculus.Let's differentiate and then find the critical points.So, here's this function of a single variable that I'm trying to maximize.My function is x times 24 minus x, that should be y or this is x times y, thisthing I'm trying to maximize
* But if I expand this out, I get 24x minusx squared
* Then, I can easily differentiate this.The derivative of this function is, what's the derivative of 24x?It's 24
* What's the derivative minus x squared?It's minus 2x
* I'm trying to find critical points, right?Critical points are where the derivative doesn't exist or where the derivative isequal to 0
* Now, this function's just a polynomial, soit's differentiable everywhere
* So, I don't have to worry about thefunctions derivative not existing somewhere.But I do have to find places where the derivative is equal to zero.So, when is this thing equal to zero
* Well, that's the same as asking, when 24is 2x
* That's exactly when x is 12.So, here is my critical point
* What sort of point is that?Well, let's think about the s, i, g, n, the sign of the first derivative.The derivative is positive if x is less than 12, and the derivative is negative ifx is bigger than 12
* What does that mean?Well, that means the function is increasing for x values less than 12.And the function is decreasing for x values bigger than 12.So, the function goes up, gets to 12, and starts going down.What kind of point does that make 12
* Well, that must be a maximum.So, I'll write f of 12 is my maximum value.So, what do we conclude
* So, here's our conclusion.A 144 is the maximum product of two numbers which sum to 24.Did we really need the awesome power of Calculus to solve this problem?No
* For example, you could have used atechnique like this
* There's the so-called arithmetic geometricmean inequality
* The AM-GM inequality.And what it tells you is the following
* That for numbers a and b, the arithmeticmean, just a fancy word for the average of a and b, is bigger than or equal to thegeometric mean, which is the square root of the product of a and b.And this inequality becomes an equality, if and only if a and b are the same.Now, how can you use something like this
* Well, in our specific case, what do weknow
* I know that x plus y is equal to 24 and ifthese two numbers add to 24, then their average x plus y over 2 must be equal to12
* But if this is their average by the AM-GMinequality, this must be bigger than or equal to the square root of x times y, thegeometric mean of x and y
* Now, how does this help us?Well, what if I square both sides, right
* Then I know that 144 is bigger than orequal to x times y
* And that's exactly what I'm trying tofigure out
* I'm trying to figure out how big can theproduct of x and y be, if I know what the sum is.And what this is telling me, is that the product can be no bigger than 144, withequality when x and y are both equal
* And that happens when they are both equalto 12
* That you don't actually need Calculus tosolve many of the problems that are assigned in Calculus courses, is perhapsone of the best kept secrets of Calculus instructors.A result like this AM-GM inequality, actually solves a ton of optimizationproblems
* You often don't have to resort to takingderivatives, if you can just apply a result like this.Calculus is a powerful tool but there are other ways to attack these problems.Don't be afraid to make use of other methods.


--- SKIP ---: 02_how-do-you-design-the-best-soup-can.en.srt


--- SKIP ---: 02_how-do-you-design-the-best-soup-can.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-do-you-design-the-best-soup-can.en_SENTbySENT.txt
* [music].Let's suppose that you work for a soup company, and they've given you a task, atask to design a soup can that can hold 300 times pi cubic centimeters of soup.This is really an optimization problem
* Your goal is to design a soup can using aslittle metal as possible, which nevertheless holds 300 pi cubiccentimeters of soup
* Okay, less dramatically, you're reallybeing asked to produce a cylinder with a given volume.I want the volume of the thing to be 300 pi cubic centimeters, and I want you tominimize the surface area, right
* This thing's got a side and a top and abottom
* And I want you to minimize the surfacearea for a given volume
* Probably helps to review a little bit ofthe geometry that goes into this problem
* Here's a picture of a cylinder right, andit's got some height that I'll be calling h and a radius that I'll call r.And the volume of this cylinder is pi r squared h.All right, pi r squared is the area, and I'm multiplying by h to compute the volumeof this disk dragged through space
* What's the surface area of this cylinder?Well 2 pi r squared counts the surface area of the top disk and the bottom disk.Each of those has pi r squared for their area.And the curved part of this cylinder has area 2 pi r h.Okay, let me draw a picture of my soup can.So, yeah, here's a little picture of our soup can, and you see I've labeled therelevant sizes
* The height of the can and the radius ofthe can is what I'm trying to figure out
* Now what is it that I'm trying tooptimize
* So I'm trying to minimize the surfacearea
* Here's that formula for the surface areaof this can, and I want that surface area to be as small as possible.Of course, if I wanted to make that surface area as small as possible, I justmake a really tiny soup can, right
* But there's a constraint.Well, the constraint is that soup can has to hold 300 pi cubic centimeters of soup.So I'm trying to make this quantity, the surface area, as small as possible,subject to the constraint that the volume of the soup can is in fact 300 pi.And I should also point out that the radius and height had better be positive.Otherwise, kind of nonsense
* This thing that I'm trying to optimizereally involves two variables
* It involves the height and also a radius.Yeah this is some bad news, right
* The quantity that I'm trying to minimizeinvolves 2 variables, involves r and h
* And calculus, as we've been setting it up,only works for understanding how a single variable changing affects something else.So I need to rewrite this function of two variables as a function of a singlevariable
* So, here we go, let's take this constraintand let's solve for h, all right
* And if I start doing that, well, h is 300pi over pi r squared and I can cancel these, pis and I'm just left with h is 300over r squared
* So, for a given radius, this is how tall Ineed to make the soup can to guarantee that the soup can holds 300 pi cubiccentimeters of soup
* Now, once I've got an equation for h interms of r, I can use this to rewrite the thing I'm trying minimize just in terms ofr
* So, here we go.The thing I'm trying to minimize now is 2 pi r squared plus 2 pi r times h, but h,in order to satisfy the constraint, is 300 over r squared.And now I can simplify this a little bit further, right?I've got an r and an r squared here
* So I can get rid of this square and getrid of this r
* And then, the thing I'm trying to minimizeis 2 pi r squared plus 2 pi times 300, which is 600 pi divided by r.So this is the quantity that I'm trying to minimize.Now that I've got this thing written as a function of a single variable, I'm reallytempted to do the fifth step here
* Apply calculus, right?If I got a function of a single variable, I could differentiate.Find the critical points
* Figure out where the maxima and minimaoccur
* But before we dive in to the calculus sideof this problem, let's just think about some creative solutions to the soup canissue
* For example, here's a little model of asituation
* Here's the sun, here's Earth and here ismy new plan for soup cans, right
* Really big radius, really tiny height,right
* Even if r is you know, 100 million miles,that can make h small enough so that this soup can contains exactly 300 pi cubiccentimeters of soup
* [laugh].Well, what's the surface area in this case?Is this a really good choice for a soup can, in, in terms of surface area?No, right
* If I make r really big, admittedly, thisquantity, 600 pi over r, which is measuring the curved area, that'll end upbeing very small
* Right, but 2 pi r squared when r is reallybig, this quantity, the amount of metal in the top and the bottom of the can isenormous right
* So this is not a great choice for soupcans
* So having the soup can shaped like a giantpancake is a terrible idea
* But what if I went the other way?Here is a piece of wire, what if I made the soup can really long and thin likethis piece of wire
* Well, here is that long, thin wire-shapedsoup can, right
* Even if I make the radius of my cylindervery small, if I make it long enough, then the soup can does hold 300 pi cubiccentimeters of soup, right
* And the question is, is this a reallysmart choice to minimize surface area, and no, it turns that if r is really small,that's really not all that helpful
* Yeah, if r is really small, then 2 pi rsquared is really small
* I don't need very much metal on the topand the bottom of the soup can
* But then 600 pi over r, which is how muchmetal is in the curved part of the soup can, this quantity is going to beenormous
* So really, we see that these two thingsare competing against each other
* A small value of r isn't really veryhelpful, and a really big value of r isn't very helpful.So our creative solutions didn't quite pan out.Let's do some calculus now
* Okay, so I'm going to think of thissurface area as a function of a single variable, r, right?Here it is, f of r is 2 pi r squared plus 600 pi over r, and I'm going todifferentiate, and here's the derivative
* All right, I differentiate 2 pi r squaredto get 4 pi r, and I differentiate this number divided by r.Well, 1 over r is negative 1 over r squared.That's its derivative
* And the I multiply by 600 pi.So this, is the derivative of this
* Now, I need to find the critical points.Now, remember what critical points are, right?Critical points are where the derivative vanishes, or where the derivative doesn'texist, right
* The function's not differentible.This function, that was differentible on its domain.All right
* You might worry when r is equal to 0.But that's not even in the domain of the original function.So I don't have to worry about that
* All right, now we've gotta figure out,when is the derivative equal to zero, so I'm trying to solve this.I'll add 600 pi over r squared to both sides.So 4 pi r must be 600 pi over r squared in that case.I'll multiply both sides by r squared, and I'll divide both sides by 4 pi.And I'll get r cubed is 600 pi over 4 pi
* The pis cancel, and 600 over 4 is 150, sor cubed must be 150
* In other words, r is the cube root of 150.This is the only critical point
* Now that I found the critical points, whatabout the end points
* Well, the end points actually aren'treally valid in this situation
* One of the end points might be when r isequal to zero
* But in that case, the soup can has novolume
* So I can't satisfy the constraint.The same thing happens when h is equal to zero.In that case, the soup can, again, has no volume.So I can't satisfy the constraint
* So, I don't have to worry about the endpoints, because they're not in the domain that I'm considering.But I do have to worry about the limiting behavior when r is really big or when r isreally small
* So, we actually already handled thelimiting behavior
* Right?We've already considered the situation when r is really small.That's the situation where the soup can's like a long, thin wire.And we checked, in that case the surface area is enormous.Right
* If r is small enough, the surface area canbe as large as you like, and still hold 300 pi cubic centimeters of soup.We also consider the situation where r is really large, right?When r was really big ,we had this sort of flat pancake shape for the soup can.And in that case, we again saw that if r is big enough, the surface area can bemade as large as you like, while still having that soup can contain 300 pi cubiccentimeters of soup
* So, the only thing that really remains isthis critical point
* And if you plug this critical point intothe original function, you get this as the resulting surface area, if you build yoursoup can with a radius of cube root 150 centimeters, and your height, whatever ithas to be in order to guarantee that the soup can contains 300 pi cubic centimetersof soup
* So how does this turn out?What's the best shape for a soup can
* So the best case for your soup can is touse a radius of the cube root of 150
* And you can see that from this graph.Here, I'm graphing the surface area for a given radius of soup can containing 300 picubic centimeters of soup
* And you can see that the graph goes uptowards infinity here
* And up towards infinity there.And that's exactly the situation when the radius is very small or very big.The derivative is negative and then positive.Right
* The function's decreasing and thenincreasing
* So this value really is a local minimum.And in fact, this is the global minimum of this function.Right
* And that's why this is the best choice foryour soup can
* Is this really a legitimate application ofcalculus
* Well, here's a task to think about.Right
* Go out, find some soup cans and checkthem
* Are they really building soup cans inorder to minimize the amount of metal that it takes to manufacture the can?Or perhaps there's other issues involved in manufacturing soup cans..


--- SKIP ---: 01_where-do-three-bubbles-meet.en.srt


--- SKIP ---: 01_where-do-three-bubbles-meet.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_where-do-three-bubbles-meet.en_SENTbySENT.txt
* [music] This is a story about threebubbles
* Well it's really about three bubble walls,alright
* I imagine that I've got this pane of glasshere, alright
* And I've got three points connected bythree edges of bubble
* So, where do these bits of bubble end upintersecting
* This actually turns out to be anoptimization problem
* Bubbles wants to be as small as possible.So, less colorfully, this is what I'm really asking for.I imagine that I've got a triangle, and I'm trying to find a point in the middleof the triangle so that the sum of these three lengths, a plus b plus c, is assmall as possible
* Try to minimize the total length ofbubble
* Let's make this concrete.Let's actually pick points and place the triangle at those point.Anyhow, we should be drawing a picture, right?We should be starting by drawing a picture.So, for concreteness, I'm going to put the 3 vertices here at 0,1, 0,0, and 1,0.And then, what am I trying to do, well, I'm trying to find a point, I call it x,y,in the in the middle of the triangle so that these lengths this length here, whichI'm calling a, the length from x,y to the origin, I call b, and the length from x,yto the point 1,0, which I'll call c
* I want a plus b plus c to be as small aspossible
* I'm trying to minimize the sum of thelengths to the vertices
* The way that I've set up this problem.The way that I've exactly positioned these 3 vertices introduces a symmetry that wecan exploit in this problem
* This configuration is symmetric across theline y equals x and the bubbles really shouldn't prefer one side or the other.I mean, what does bubble knows about left and right?So the solution, the point that minimizes the sum of the distances to these 3vertices should lie on this line, so I can say that its coordinates are x,x, sowhat's the goal
* So I'm trying to find the value of x, so,that this point x,x minimizes the sum of the distances to the 3 vertices.Now, how do I write that down
* Well, here's a formula for the sum of thedistances to these 3 vertices
* This first part, the square root of xsquared plus x squared
* That's just the Pythagorean Theorem,right
* How far is the point x,x from the point0,0
* Well, here's a right triangle.And the two legs of this right triangle both have length x.So, the length of a hypotenuse is he square root of x squared plus x squared.What, say, this term here, where is the square root of 1 minus x squared plus xsquared come from
* Well, take a look at this little tinyright triangle here
* This right triangle has this leg withlength x and this leg with length 1 minus x.So, how long is the hypotenuse, which is the distance from x,x to 1,0?Well, it's the square root of 1 minus x squared plus x squared.This last term, this square root of x squared plus one minus x squared, that'smeasuring the distance from 0,1 down to x,x.I can simplify this, somewhat
* This first term, this square root of xsquared plus x squared, well, I could rewrite that as just the square root of 2xsquared
* And both of these terms are actually thesame
* It's just the addition is done in adifferent order but, of course, it doesn't effect the value at all so I can writethis as two copies of just this first one, the square root of 1 minus x squared plusx square
* So, this is a slightly easier way ofwriting f
* We should also review if there's anyconstraints on this problem
* I'm going to find it a little bit easierif I assume that x is bigger than or equal to 0.In that case, the square root of 2x squared can be rewritten in an even easierway, right
* The square root of x squared is theabsolute value of x
* But if I assume that x is bigger than orequal to 0, then I could rewrite this as just the square root of 2 times x plus,and this other term, 2 times the square root of 1 minus x squared plus x squared.So, we've got our function of a single variable so we can apply calculus.We can differentiate
* So, here we go.I want to differentiate this
* F prime is, well, it's the derivative of asum, which is the sum of the derivative
* So, I have to first differentiate squareroot of 2 times x
* As just the square root of 2 plus 2 timessomething
* So, it will be 2 times the derivative ofthat thing
* It is the derivative of 1 minus x squaredplus x squared, all under this square root.Alright, and I can keep on going here
* I got the square root of 2 plus 2 times.How do I differentiate a square root
* Well, the derivative of the square root is1 over 2 times the square root but I use the chain rule so it will be 1 over 2times the square of the inside function here, which is 1 minus x squared plus xsquared times the derivative of the inside function.So, the derivative of 1 minus x squared plus x squared.Alright, let's do this again
* So, I got the square root of 2, plus, oh,I can cancel this 2 and this 2, so, I've got 1 over the square root of 1 minus xsquared plus x squared times, I got to differentiate this sum, which is the sumof derivatives again
* So, the derivative of 1 minus x squared,that's 2 times one minus x times the derivative of the inside function, thederivation of 1 minus x is minus 1, plus the derivative of x squared, which is just2x
* So, here's the derivative of f.With the derivative in hand, we can look for the critical points, places where thefunction either isn't differentiable or where the derivative is equal to 0.I don't have to worry about critical points where the derivative doesn't existbecause this function is differentiable everywhere.So, I'm just looking for values of x where the derivative is equal to 0.Let me rewrite this derivative even a little bit more nicely.So, the derivative is the square root of 2 plus, and it's this thing I want tosimplify a little bit here
* What do I got?I got 2x
* And then I've got another 2x here.So, it's 4x minus 2
* So, 4x minus 2 over this denominator, thesquare root of 1 minus x squared plus x squared.Alright, pretty good
* I'm looking for values of x where thatthing is equal to 0
* I'll subtract the square root of 2 fromboth sides
* That means I'm looking for values of x.So that 4x minus 2 over the square root of 1 minus x squared plus x squared, is equalto negative square root of 2
* And then, I'll multiply both sides by thisdenominator
* And that means I'm looking for values ofx
* So that 4x minus 2 is negative the squareroot of 2 times the square root of 1 minus x squared plus x squared.Now, how do I solve an equation like this
* Well, one trick I can use is to squareboth sides, and that might introduce extra solutions.But I can go back then and, and figure out exactly which solution is still a solutionto this original problem
* So, let's square both sides.So, I've got 4x minus 2 squared is negative square root of 2 times 1 minus xsquared plus x squared, this whole thing squared.And now, I can expand that out a bit, right?What's 4x minus 2 squared
* Well, that's 16x squared minus 16x plus 4.And what's this side
* Well, squaring the negative gets rid ofit
* Squaring the square root of 2 is 2, andthen the square of this thing, this is positive so it's just whatever is insidethe radical, which is 1 minus x squared plus x squared.Okay, so I got 16x squared minus 16x plus 4.I can expand this thing out
* Alright, this is a 1 minus 2x and thenhere, I got a plus x squared and another x squared so plus 2x squared.I'll expand this whole side out so that's 2 minus 4x plus 4x squared and I'llsubtract this from both sides and I'll get 12x uh,squared minus 12x plus 2, is equalto 0
* So, this is just a quadratic equation,alright, and I can solve that quadratic equation by using say, a quadraticformula
* And I get that x is 1 half 1 plus or minus1 over the square root of 3, alright
* So this is an application of the quadraticequation to solve this, quadratic
* Now, the issue here is that, it turns outthat I'm getting 2 solutions for x
* But only 1 of these is actually a placewhere the derivative is equal to zero
* So if you're careful, and you check.It turns out that this is in fact, a minus sign.So this is the only critical point x equals 1 half 1 minus 1 over the squareroot of 3
* So, I've got a critical point.Let's draw a picture and see exactly where the critical point lands inside ourtriangle
* So, doing a little bit of numerics thiscritical point ends up at being at point 2,1 and yeah, I mean I can plot this righthere
* This is the point x,x when x is equal tothis
* And, you know, maybe that looks believableas where these bubble walls would intersect in order to minimize the sum ofthese 3 distances
* There's more work to do.To actually show that critical point does indeed give rise to the global minimumvalue of this function, we need to do more work.But let's put that off for now
* Instead, I want to focus in on an anglecalculation
* In particular, I want to calculate thisangle here, the angle that this bubble and this bubble make at the point where theyintersect
* And I can do that with the law of sinescalculation but I also need to know to the length of this piece of the bubble and ifyou do the calculation, that will be the square of 2 3rd.Alright, so I'm going to use the fact that I know this length, oh, and I also knowthis bottom length is 1 and I know this angle, right?The line y equals x makes a 45-degree angle with the x-axis.So, I put all that information together into a law of sines calculation, right?Sine of pi over 4, that's this angle, a 45-degree angle divided by the length ofthe opposite side the square root of 2 3rd.Well, that sine of theta divided by the length of the opposite side which is 1.Now, I want to try to figure out what sine of theta is.Well, I've got all the bits of information here that I need.I know sine of pi over 4 is 1 over the square root of 2.So, it's 1 over the square root of 2, divided by the square root of 2 3rd isequal to sine of theta
* And this, yeah, if it calculate it, it'sthe square root of 3 over 2
* Now, you might be tempted just to applyarc sine to the square root of three over two.But you have to think a little bit about the domain here, exactly where does thisangle theta lie
* It's not between 0 and 90 degrees.A theta, if you look at the picture, is bigger than 90 degrees, so I'm looking foran angle between, say, 90 and 180 degrees whose sine is the square root of 3 over 2,and that actually nails down theta for us
* Theta is 2 pi over three radians or 120degrees
* So, these bubble walls meet at 120 degreeangles and we can see this for real in nature.Look at these 120 degree angles
* The calculations that we're doing here arejust symbols on the page
* And yet, somehow, they manage to governthe real physical world, right
* What do bubbles know about Calculus?But somehow, Calculus knows about bubbles.


--- SKIP ---: 02_how-large-of-an-object-can-you-carry-around-a-corner.en.srt


--- SKIP ---: 02_how-large-of-an-object-can-you-carry-around-a-corner.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_how-large-of-an-object-can-you-carry-around-a-corner.en_SENTbySENT.txt
* Here's another timeless classic, anotheroptimization problem that just comes up in all the calculus textbooks.Goes like this: you've got some big object and you want to move that big objectaround a corner
* The question is for some given corner, howbig of a object can you navigate around that corner.This is an example of the so called piano moving problem.A piano is way to complicated of an object to really understand in this course right,it's just got a way to much geometry going on there.So going to consider a simpler example
* So here's our diagram of a corner and Imentioned that I want to move this red stick around this corner without itgetting stuck
* Maybe it doesn't look like it but thisproblem can be set up as an optimization problem and we can solve it.It's an optimization problem, because I'm asking to know the length of the longeststick, that I can navigate around this corner.We have to think about where that stick can get stuck.Well the stick is going to get stuck when it's in a position like this.When it's touching these two walls and pressed up against this corner.So, what I actually have to think about is what's the shortest length of stick thatsimultaneously touches this wall, this wall and this corner.I think it's a little bit funny that in order to solve this problem, we end upminimizing something
* We actually want to figure out the longestlength, the maximum length of a stick that can be navigated around that corner.But to answer that problem, we end up solving a minimization problem.Well anyhow, let's proceed in our usual way.I'm going to draw a picture and label everything.So, here I have drawn this picture and I have labelled every thing.The width of this hallway is a, the width of this hallway is b, the length of thisstick is l, and makes this angle theta with this bottom wall.Now we gotta figure out what it is that we are trying to optimize.What's the quantity that we are trying to minimize?What's the goal
* So my goal is to minimize the length ofthis stick, right
* I want to know the shortest length thattouches these two walls and this corner, and that'll constrain the largest stickthat'll fit around this corner
* Now, my hallways have fixed lengths, andI'd like to express the length of this stick in terms of this angle theta.So I can break up the stick into 2 pieces
* There's a piece that goes from this wallto the corner and a piece from this corner to the other wall.So this piece here, well that's really the hypotenuse of a right triangle, whoseopposite side to this angle theta has length a.And that means this hypotenuse has length a times co-secant theta.Similarly here I got a right triangle and I have got this side length here is b so,the hypotenuse has length b times secant theta and the stick is just the sum ofthese two lengths so that gives me a formula for l in terms of theta.L is a cosecant theta plus b secant theta
* What's the constraint in this problem?Yeah I only need to think about theta being between 0 and pi over 2 in order totouch these two walls and the corner
* So now we've got a function, and it'sfunction of a single variable so we can apply calculus.So, I'm going to differentiate this function, right, the derivative of L withrespect to theta
* Well what's the derivative of cosecant?That's minus cosecant theta cotangent theta.And what's the derivative of secant
* Well that's secant theta Tangent theta.So that's the derivative of l minus a cosecant theta cotangent theta plus bsecant theta tangent theta
* With the derivative in hand I can now tryto find the critical points for this function.Now since this function L is differentiable on the domain that we'reconsidering, I don't have to worry about places where L fails to be differentiablewhen I'm looking for critical points
* I only need to find points where thederivative is equal to zero
* So for which values of theta does thisthing vanish
* Well, let's write this as an equationequal to 0, and let's add a cosecant theta contangent theta to both sides.So then I've got b secant theta tangent theta is equal to a cosecant thetacotangent theta
* I, I will divide both sides by co-secanttheta, cotangent theta and I will divide both sides by b so that I have got secanttheta, tangent theta divided by cosecant theta, cotangent theta is equal to a overb
* Now what do I notice here?Well dividing by cotangent is as good as multiplying by tangent.And secant and co-secant is actually tangent again.So this is in fact tangent cubed
* So I've got tangent cubed theta.Is equal to A over B
* If I take a cubed route now, I get thattangent theta is equal to the cube root of A over B.In over words, theta is arc tangent the cube root of A over B.So now I know what theta is, but I don't care about theta.What I really care about is L
* What's the length?So let's evaluate l of theta at the critical point.Now, where's the critical point
* It's where tangent of theta is equal tothe cube root of a over b
* I can build a right triangle with an anglewhose tangent is the cube root of a over b.I do that as follows
* I make this length 1.And this length the cube root of a over b and that makes the tangent of theta whichis this divided by this equal to this right and this is 1 in the denominator.That is the right triangle which means I can compute the length of hypotenuseright
* The length of hypotenuse is a square rootof the sum of these two lengths squared and that's what I had written.And here
* Okay, so I've got a right triangle.I've got an angle whose tangent is theta and I'm trying to calculate L of theta.And if you remember back L was defined in terms of cosecant and secant.And I can compute cosecant and secant for this angle theta whose tangent is thisquantity by reading off the cosecant and secant from this triangle.So the co-secant remember is a one over sine which means it's hypotenuse dividedby the opposite side length and that's what I got here, length by hypotenusedivided by length of opposite side and secant, remember is one over cosine sothat means it's the side length by hypotenuse divided by this length, whichis just one
* Now once I know cosecant and secant interms of this quantity here, I can then evaluate L at that quantity.So here we go, this is what I get when I plug in these quantities for coseekit, andseekit
* Get.Now this looks terrible, right
* Well, I can simplify this a little bit.What do you notice here
* I've got a dividing by the cubert of B inthe denominator, which is as good as putting a B to the thirds power up here.And here I'm going to separate out this B to B a B to the two thirds times B to theone third and move that inside the square root.The upshot is that this thing is in fact the same as this thing here.And now this begins to be a little bit more symmetric, right?I took the a and the cube root of a and that gave me the a to the 2 3rds and byputting a b to the 2 3rds inside here, I made this look a lot, a lot nicer.Okay
* Now I've got a common factor of the squareroot of b to the 2 3rds plus a to the 2 3rds here and I can collect that out.So now I've got a to the 2 3rds plus b to the 2 3rds times the square root of b tothe 2 3rds plus a to the 2 3rds
* Now this is the same thing, here.It's this thing times the square root that thing.And another way of saying that is just this quantity to the 3/2 power, right?This is this quantity to the first power, times the 1/2 power, and that gives me the3/2 power, here
* So, at the critical point, l of theta isequal to this quantity
* Now with a bit more work, we can show thatthis quantity is in fact the minimum value of l.We can summarize our answer
* So given a hallway of width A meeting ahallway of width B at some corner, what we've shown is that a stick of length atmost, A to the two thirds plus B to the two thirds, that quantity to the threehalves power can be navigated around that corner.And we can see this playing out in action
* I made a model that you can download Wellhere is an example
* I've got a hallway of width 64millimeters, that's a pretty small hallway, right?And I've got another hallway here, 27 millimeters.And the calculation that we've done tells us that a stick of length 125 millimeterswill just be able to turnaround, this hallway.So let's see
* Here's the stick and I start the stickmoving down the hallway, right
* And I start trying to rotate it around andeventually I'm going to bump up against the corner , but I'll just be able to makeit around the corner and then I'll be able to move it out of the hallway.Perhaps you're wondering where those numbers came from.Well here's where I got these numbers from, right?64 and 27, these are the widths of my hallways and this is the formula thattells us the largest stick that can pass through a hallway of these two widths.Now I chose 64 and 27 for, maybe two different reasons.One thing is that these are both perfect cubes.So, 64 to the one third power is 4 and 27 to the one third power is 3.The other thing that's nice about these numbers is that 4 squared plus 3 squaredis 5 squared, right
* These are Pythagorean triple.And 5 squared to the 1/2 is just 5
* So it's 5 cubed which is 125.


--- SKIP ---: 03_how-short-of-a-ladder-will-clear-a-fence.en.srt


--- SKIP ---: 03_how-short-of-a-ladder-will-clear-a-fence.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-short-of-a-ladder-will-clear-a-fence.en_SENTbySENT.txt
* [music] In our calculus class so far, someof the applications have involved sheep trapped inside fences and ladders leaningup against buildings
* Well, here's a scene that combines allthese things
* I've got a sheep, I've got a fence, I'vegot a ladder
* Here's a really tall barn.Here's the sun shining down on the ground
* Let's suppose that you're the sheep, stuckbehind the fence, but eager to get to the barn.The really good news is that you're not just a regular sheep, you're some sort ofninja sheep
* And you've got a supply of a bunch ofdifferent ladders
* The question is, what's the shortestladder that you can use
* You want to pick the shortest ladder thatyou can get away with, which goes over the fence and touches the barn.I mean, if the ladder is too short, it won't even go over the fence.But, even this longer ladder, I mean, it will get you over the fence, but thisladder is not long enough yet to get you all the way to the barn.At this point, you're probably feeling really bad.You now recognize that this is an optimization problem, but you're thinking,oh no, not again
* Not another optimization problem.Well, let me say a little more about exactly how tall the fence is, and how farit is from the barn
* Let's say that, that fence is 6.4 meterstall
* And let's say that the fence is 2.7 metersfrom the barn
* Is something sounding familiar here?Yeah, we've seen numbers like 64 and 27 come up before.We saw them in that hallway problem, right?What did I want to do in the hallway problem?I wanted to take some stick and figure out what the, in this case, longest stick wasthat I could navigate through this hallway.But as, remember, the issue was finding the shortest stick which simultaneouslytouched this bottom wall, this wall here in the corner.That's really the exact same problem
* We just have to think about this problemin, in different terms
* Instead of thinking of this as a wall, Ithink of this as the ground
* Instead of thinking of this is a wall, Ithink of this as the side of the barn
* And I want to pass through this point.I want to touch this corner, which really just means I want to clear the fence, youknow
* And because this problem happened to besolved by a stick of length 125 millimeters, this problem is going to besolved by a ladder of length 12.5 meters
* And here, and this drawing is actually toscale so I can, I can really demonstrate it, you know?Here, I position the ladder and yeah, this, this ladder is in fact long enoughto touch the ground, the barn, and just clear the fence.We've done a ton of stuff this week, but this is perhaps the most important lessonof all
* At it's core, mathematics is not aboutjust solving problems
* What we've done here is realize an analogybetween two seemingly different problems, alright?The problem of a stick turning a corner and a ladder clearing a fence.More than about solving problems, mathematics is really about these kinds ofanalogies, about being able to recognize that things that look different are reallythe same
* People have been doing mathematics forthousands of years, and there's been a ton of new mathematics developed in that time.So, you might think that with all the new mathematics, that mathematics would beconstantly splintering off and fracturing into different subjects.But that's not what's happened at all
* This desire to analogize, to unify.To see different parts of the elephant as the same elephant, right?This tendency has really kept mathematics together.It means that mathematics doesn't appear as a bunch of separate subjects, it reallyappears as a unified whole.


--- SKIP ---: 01_why-are-we-thinking-about-linear-approximation.en.srt


--- SKIP ---: 01_why-are-we-thinking-about-linear-approximation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-are-we-thinking-about-linear-approximation.en_SENTbySENT.txt
* [MUSIC] Calculus is rich enough that there's a tonof different ways to think about the conceptsin calculus
* Think about the derivative
* One way to think about the derivative isas the ratio of output change to some small,infinitesimal input change
* But another way to think about the derivative, is in terms of linearapproximation
* And that's the idea that we want toexploit right now
* This is really the story of, of all ofcalculus
* You know, you want to understand curvedobjects
* I want to understand some graph of afunction that's very curved
* And that's hard to do
* But, if I zoom in close enough on thefunctions graph right, if the function's differentiable, then when Izoom in, that graph looks like a straight line
* That's the idea of linear approximation
* We can study these complicated curvedgraphs by zooming in and imagining that, at leastapproximately, they're straight lines
* And there's a couple of huge benefits todoing this
* One thing that we can use this for, is toapproximate values of the function
* And the other thing that we're going to beable to use this for, is Newton's method
* We'll be able to do things like, at least approximately, find roots of verycomplicated looking polynomials
* [BLANK_AUDIO] [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 02_what-is-up-with-all-the-numerical-analysis-this-week.en.srt


--- SKIP ---: 02_what-is-up-with-all-the-numerical-analysis-this-week.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-up-with-all-the-numerical-analysis-this-week.en_SENTbySENT.txt
* Welcome back to Calculus I and welcome toWeek nine of our time together
* Can you believe that we've been at thisfor more than two months already
* It's crazy.The last two weeks, we've really been focusing on applications of the derivativein a particular word problem
* Right?Those related rates problems or those optimization problems.They're word problems, stories from real life.This week, in week nine, we're still doing applications of the derivative, but it'snot so much word problems anymore
* It's sort of numerical applications.In particular, we're going to look at Newton's method, which is a way ofapproximating a 0 of a function
* And we did that a while back.By using this bisection method and an intermediate value theorem but Newton'smethod is, at least when it works, much faster.And the other thing that we're going to look at is how knowing information aboutthe derivative lets you recover some numerical information about the originalfunction
* So if you knew for instance the derivativeand you wanted to approximate a value of a function, we'll see how you can do that.Well I hope you enjoyed these numerical examples.When, when I first took calculus I got to say that I didn't always enjoy all thenumbers that were coming up, you know
* I really just wanted to do all of thetheorems, you know
* But I think the numbers really make thissubject come alive
* So I encourage you, if you're skepticalabout all the numerical stuff this week, just take a look.I think it's going to be a lot of fun.


--- SKIP ---: 03_where-does-f-x-h-f-x-h-f-x-come-from.en.srt


--- SKIP ---: 03_where-does-f-x-h-f-x-h-f-x-come-from.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_where-does-f-x-h-f-x-h-f-x-come-from.en_SENTbySENT.txt
* [music].We've seen a little bit of this linear approximation business already.A long time ago, we saw this
* That, f of x plus h is approximately f ofx
* Well, that much at least is really justbecause f is say continuous, right
* Nearby inputs should be sent to nearbyoutputs, but let's suppose that f is differential, then we can say more, allright
* I'm going to add to this h times thederivative of f at x
* What is the derivative measure, right?It's the ratio of how much the output changes to an input changeinfinitesimally
* But for an actual input change of h, if Itake this, which is the ratio of output change to input change and I multiply itby how much the input change is
* This quantity should tell me how much Iexpect the output to change when I go from X to X plus H.Where does this formula actually come from?Well, let's think back to the definition of derivative.Right
* What's the definition of derivative?The derivative of F at X is the limit as h approaches 0 of f of x plus h minus f ofx, all over h
* Alright, that's the definition ofderivative
* Now how does that help us here?Well, if I just pick some value of h, an actual value of h, that's not 0 but closeto 0, then I get that f prime of x should be approximately f of x plus h for thatsmall but p-, you know, non, non zero value of h, minus f of x over h.So this is approximately equal, as long as h is small.Now I multiply both sides of this approximate quantity by h and I'll findthat h times f prime of x should be approximately F of X plus H minus F of X.And then I'll add F of X to both sides, and what I'll get is that H times F primeof X plus F of X should be approximately F of X plus H, and that's the statement thatwe had before, right
* That the value of function X plus H isapproximately the value of the function of X plus something I'm getting from thederivative
* The derivative of f at x times how much Iwiggled the input by
* So I've got this formula, but why do Icare about this formula at all
* Well, I care because this is really what Iwanted in the first place, right
* I really wanted to understand how wigglingthe input would effect the output, and fundamentally, you know, the derivativeisn't just some random limit that I cooked up for you to evaluate.It's supposed to say something meaningful about the function, and this is what'stelling us what the derivative means, right?The derivative really means something about how wiggling the input affects theoutput
* There's another reason to care about thisformula
* We can use this formula, in fact we'vealready used this formula to numerically approximate a function that might be hardto compute otherwise
* Um,, let's look at a function f of x willbe say, the cube root of x, and let's look at the input 125 and f at 125, right?What's the cube of 125
* That's 5, because 5 times 5 times 5,that's 125
* So the cube of 125 is 5.Now let's try to wiggle the input and see what happens.Let's wiggle by h, which will be three
* Three's not all that small, but comparedto 125, three's pretty small
* And I'd like to know what f of a plus his, right
* I want to know what the cube root of 125plus 3, 128 is
* And you know that's going to be hard toknow, right
* So I'm only going to know Approximately.But I can use the derivative here, right
* Because the derivative tells me howwiggling the input affects the output
* So as you can get the derivative of thisfunction at the input A
* So let's differentiate this function.And this is X to the one third, so the derivative is one third times X to theminus two thirds, right
* This minus 2 3rd as 1 3rd minus 1.It's a power rule
* Let's compute the derivative at the input125
* So that means I look at 1 3rd times 125 tothe negative 2 3rd power
* Well, 125 to the negative 3rd, thenegative 2 3rds power
* That's 1 25th, and 1 3rd times 1 25th,that is 1 75th
* So this tells me what the derivative is ata 125, now how does that help
* Remember the other formula for this linearapproximation game, that f of a plus h, which is what I'm trying to compute,should be approximately f of a plus h times f prime of a, and I know what all ofthese quantities are now
* F of a is 5, h is 3.And F prime at A is 1 75 and 5 plus 3 times 1 75 that's 5.04.Now, how close is that to the actual retail value of the cube root of 128.Well, it turns out that the cube root of 128 is actually about 5.0396841 and itkeeps on going, which is awfully close to 5.04.So our layer approximation game is working really quite well.This idea that the complicated function like the cube root function, with itscurved graph can be approximated very well, at least for short intervals bystraight lines, right
* This idea of replacing curved object withperfectly straight lines, that's a key idea of calculus.In short, curves are way too complicated for us to understand.Lines, on the other hand, just straight lines, are much easier for us to thinkabout.


--- SKIP ---: 04_what-is-the-volume-of-an-orange-rind.en.srt


--- SKIP ---: 04_what-is-the-volume-of-an-orange-rind.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-is-the-volume-of-an-orange-rind.en_SENTbySENT.txt
* [music] Here, I've got an orange.I'd like to measure say, the radius of the orange, thinking of this orange as aperfect sphere
* One way to do this would be to measure,say, the circumference of the orange around its equator.So here if I measure that it looks like it's about 24 centimeters.So the circumference of the orange is 24 centimeters.What does that tell me about, say the radius of the orange?Well that circumference Will be 2 pi times the radius of the orange.So if I divide both sides by 2 pi
* I get that the radius of the orange isabout 12 over pi centimeters
* How much rind is there on this orange?That could be formulated as a linear approximation problem.Well let's fit this up./g So, I just calculated the orange radius to be about12 over pi centimeters
* I want to figure out how thick the rindis
* Let me.Let me peel off a bit of the orange here
* Just want to measure how thick this iswith, say my little ruler here and yeah, maybe three millimeters.So, point three centimeters will be the rind thickness.Now how does knowing the rind thickness going to help me to calculate, at leastapproximate, the volume of the rind in this whole orange.Well I know the volume of a sphere, which by modeling the orange to be, is 4 3rds pir q
* And the rind volume, is at leastapproximately how much the volume changes when I take this formula, and replace rwith r minus h
* Right?When I take that sphere and I make it just a little bit smaller.That change in volume is the volume of the rind.And to understand how wiggling the input effects the output, I'm going to use thederivative
* The formula that I want to bedifferentiating here is this volume of a sphere of radius r.Which is 4 thirds pi r cubed [NOISE]And if I differentiate this with respect to r.The r cubed differentiates to 3r squared
* And the 3 in the denominator here willcancel this 3 by the power rule
* So the derivative will be 4 pi r squared.Now what I'm trying to approximate is the rind volume which is really the differencebetween a sphere of radius r and a slightly smaller sphere where I've shrunkdown just past the rind, right
* That difference will be the volume of therind
* And approximately this h times thederivitive of v at r
* Right, because this is asking how does theoutput change when the input goes from R minus H to R.And it's approximately the input change times the derivative.Now in this case what do I know
* The orange's radius is 12 over Pi, so I'lluse that for R
* And the rind's thickness is point threecentimeters so I'm going to use that for H.So this is point three centimeters Times 4 pi, times this radius, which is 12 over picentimeters squared
* So this is cubic centimeters.Well that's good because I'm trying to calculate a volume.And I'll just keep calculating here
* So it's point 3 times 4 pi times 144 overpi squared
* Cubic centimeters.And 4 times 144 is 576 times .3, the pi divided the pi squared is going to be a piin the denominator
* So I've got .3 times 576 over pi Cubiccentimeters
* That's about 55 cubic centimeters.So the volume of the rind is approximately 55 cubic centimeters.Now admittedly I could have calculated the volume of the rind just by calculating thevolume of the whole thing
* Calculating the volume of the whole thingwith the radius reduced by h, and taking a difference.But the neat thing here is that you can approximate that quantity by usingcalculus, right
* By thinking about this linearapproximation business
* I also want to see now how close thelinear approximation was
* Alright, so I've taken my orange andpeeled off all the rind, and I've taken the rind and smooched it down into thisball, and I'll try to calculate the volume now of this rind ball.I want to compute the volume of a rind, and I made that rind ball here, let me Letme compute the circumference of this rind ball.That's about 15 centimeters
* So the circumference of my ball of rind isabout 15 centimeters, that means my rind ball has a radius.15 over 2 pi centimeters
* And here, assuming my Rind ball is aperfect sphere
* This would be the volume of the Rind ball.But in here I gotta put the radius, which is 15 over.2 pie
* So, 4 3rds pie the radius cubed, andthat's about 57 cubic centimeters
* So, yeah, I mean, I actually took all therind off the orange and the value that we got is pretty close to what the linearapproximation told us the volume of rind should be.This perspective sheds some light on what might otherwise be seen as just somerandom coincidence
* Now what you notice is that the volume ofa sphere which is 4 3rds pi r cubed and the surface area of a sphere which is 4 pir squared
* These two formulas are related right.If I differentiate this volume formula with respect to r, I get the surface area.Formula
* Again we're seeing that calculus isn'treally about solving specific problems
* I don't care about the volume of the rindof this orange
* Right?If that was what calculus was good for, who would care?Right
* What calculus is really good at Isproviding a general framework and with that general framework we can begin to seethe patterns between different concepts
* Like this fact, the surface area of asphere is the derivative of the volume of a sphere with respect to the radius.That's not really a coincidence, right
* Calculus is providing an explanation forthat supposed coincidence.


--- SKIP ---: 01_what-happens-if-i-repeat-linear-approximation.en.srt


--- SKIP ---: 01_what-happens-if-i-repeat-linear-approximation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-happens-if-i-repeat-linear-approximation.en_SENTbySENT.txt
* [music] Well here is a linearapproximation problem
* So I've got some function F.And you don't know that function immediately, but I know it's derivative isequal to the function's value, say at all X.And let's suppose that I know this function's value at zero.So this function's value at 0 is 1, and then my goal is to find f of 1.Now we secretly know something, right
* I mean, I secretly know that this functionis really e to the x
* So when I say find f of 1.I really mean that I'm trying to calculate e to the first power, I'm trying tocalculate e
* The point, here, you know, isn't to thesay that answer is e, right
* The point is going to be to try toapproximate this quantity without actually knowing the value of e.We already know how to do this
* We can use linear approximation, allright
* I want to know what f of 1 is, and by thelinear approximation business, well it's not equal to, but it's approximately thevalue at 0
* Plus how much I change the input by timesthe derivative at 0
* Now I know the function's value at 0.The function's value at 0 is 1
* And since the derivative is equal to thevalue everywhere, that means I also know the derivative is 0.So the function's value is 1, the derivative at 0 is the same as functionvalue at 0, which is 1
* 1 plus 1 times 1 is 2 so approximately fof 1 is 2
* And since I secretly know that thisfunction is e to the x, I'm saying that e is about 2, 2 is a terrible approximationbut we can do better
* If we can do any approximation once, wecan do it a bunch of time
* So instead of this jumping all the way to1, let's first approximate f of 1 half and that will f of 0, plus how much I wiggledby which is 1 half times the derivative at 0.Well, f of 0 is still 1, 1 half is a half and the derivative at 0 is still 1.So this is 1 plus a half, this is 3 halves.Now we use data approximation to approximate f of 1.Yes, I'm sort of bootstrapping up here, now I want to know f of 1 at leastapproximately
* But instead of starting at 0, I'm going tostart at 1 half
* So that will be about f of 1 half, whichadmittedly I don't know but I got this approximation for it.Plus how much I changed to go from 1 half to 1 times the derivative at one half.Now f of one half is approximately this three halves, one half and the derivativeof one half I don't really know what it is but I still know that the derivative isequal to function's value and I've got an approximation of the function's value.So I can use that approximation here at the derivative at one half Is about 3halves
* And I've got 3 halves.And I've got 3 quarters
* That ends up being 9 4th, which is aslightly better approximation to the function's value of one.I mean, nine fourths is closer to the actual value of e.Well if two steps worked better than one step, ten steps will work even better.So here we go, let's approximate this function at 0.1.Well that's approximately the function value at 0 plus how much I change theinput by times the derivative at 0 and the function value at 0 is 1 plus 0.1 timesderivative of 0 is 1
* So approximately, E to the 0.1 is about1.1
* Now I repeat this process, I want to knowexactly what's the function's value at 0.2.That should be about the function's value at 0.1 plus 0.1 times the derivative at0.1
* So approximately the function values atpoint 0.1 is about 1.1 plus 0.1 times derivative at 0.1, which is about, no, seethis in fact the function values at 0.1 which is about 1.1.So 1.1 plus 0.1 times 1.1, it's kind of a mouthful.But that ends up being 1.21
* Now to approximate the function value at0.3
* All right, I'll start with the function'svalue at 0.2
* I go from 0.2 to 0.3 by adding 0.1.And then I multiply by the derivative, at 0.2.The function's value at 0.2 is 1.21 plus 0.1 times the derivative of 0.2, which isalso about 1.21, and 1.21 times 1.21 plus 0.1 times 1.21, that's 1.331.Now you might begin to see a pattern here, right?1.1, 1.21, 1.331, these are pieces of Pascal's triangle, really.I mean that makes sense considering how
* How I'm adding the number plus 0.1 timesthe number
* Lets just keep going.So let's compute f of 0.4, that's f of 0.3 plus 0.1 times the derivative of 0.3.Well, the approximation here for f of 0.3 is 1.331 plus 0.1 times 1.331, which is,1.4641
* Now I can do this again to get anapproximation for 0.5
* Right, I'm really just taking this numberand adding 0.1 times it and I get 1.61051
* Can do the same thing to approximate 0.6and I get 1.771561
* Can do the same thing to approximate 0.7,and take this number and add this number times 0.1, which is 1.9487171.Do the same game, do approximate f of 0.8
* So I take this number and add 0.1 timesthis number
* And I get 2.14358881 can do the same thingnow a 0.9
* So this number plus 0.1 times this numberand I get 2.357947691 and last
* I take this number and add 0.1 times thisnumber, and I get 2.5937424601, approximately e.Well, not so great
* But I mean, it's, you know, much closer tomy previous attempts, where I just used two steps, you know.So using ten steps is better, this technique of repeated linear approximationhas a name
* So instead of calling this you knowrepeated linear approximation people usually call this the Euler method.Lets summarize the algorithm
* So this is a set up.I've got a formula for the derivative of f, just in terms of f and x.So this cloud represents some formula that involves f of x and x and that's myformula for the derivative of f at x
* And let's say I know the value of f atzero
* Just some number and suppose I've pickedsome small number H
* Well what Euler method tells me to do, isI want to know F of H, well I already know how to do that.Right, that's just linear approximation
* It's f of zero plus h times the derivativeat zero
* I can use this formula, say to calculatethe derivative of F at zero
* And I know the value of f at zero.So I can get an approximation to the function's value H.Now the neat thing is I an keep playing this game, right?If I want to know an approximate value to the function at 2 times h, well that'sabout the function's value h plus h times the derivative at h.And now I know the function's value at h approximately.And I know the derivative at h, because I've got a formula for the derivative interms of f and x, and I know how to calculate f of h, approximately, and Iknow x, all right, it's h in this case
* And that means that I can get anapproximation to f of 2h and I'll just keep playing this game.If I want to know f of 3h, well that's about f of 2h plus h times f prime of 2h,so that's that linear approximation formula again.To go from 2h to 3h, I add h so f of 3h is approximately my function's value with 2hwhich I've already approximated, plus how much I change the input by, times thederivative of 2h
* And this I can also approximate, becausemy formula for the derivative just involves things I already know at leastapproximately
* Right, I know the value of f at 2happroximately
* And I can just keep on repeating this tomove myself further and further to the right and, you know, approximate values ofthe function that tend to get very far away from zero.The cool thing here is that I'm using, you know, linear approximation in each stage.And then I'm using the information from previous stages not only to approximatethe function's value, but also to approximate the function's derivative.I should wan you that in the really world, people don't really use the Euler methodso often
* But like any really great mathematicalidea, there's a ton of different riffs that you can play on this basic framework.For example since this is just going to end up being an approximation of thederivative anyhow, it's sometimes better not to pick a point which is all the wayon the left hand side of the interval I'm approximating over.So sometimes you'll see that say instead of using zero here, I might use h over 2.Instead of using h, which is really on the left hand side of the interval between hand 2h
* You'll see that sometimes people will use,say 3 halves h, which is smack in the middle of h and 2h.And say instead of using 2h here, people will sometimes use 5 halves h, which isright in between 2h and 3h
* So you can play some games, say bychoosing a different point to approximate the derivative at, and using the midpointis sometimes better
* Incidentally, if you've got someprogramming experience, I'd encourage you to try to write a program to do the Eulermethod
* It's really fun to be able to see thesecalculations come alive.


--- SKIP ---: 02_why-is-log-3-base-2-approximately-19-12.en.srt


--- SKIP ---: 02_why-is-log-3-base-2-approximately-19-12.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_why-is-log-3-base-2-approximately-19-12.en_SENTbySENT.txt
* [music] I'm going to approximate log 2 atthe natural log of 2 by starting at log of, of 1, which I know to be 0 and movingover one quarter each time until after four steps I arrive at 2.So here we go
* First I'll try to approximate log of 1plus a quarter
* This will be approximately log of 1 plus aquarter, which is how much I changed the input by, times, and I gotta approximatethe derivative somehow
* I don't really want to approximate thederivative of log at 1, and I don't really want to approximate the derivative of logat 5 4ths
* That will be an over and under estimate ofthe derivative over the whole interval
* So, I'm going to approximate thederivative by evaluating the derivative in the middle of this region at 1 plus an8th
* Alright the derivative of log is 1 over,so this is the derivative of log in the middle of the interval between 1 and 5/25.Alright
* So let's keep calculating here.Log of 1 is zero
* Plus a 4th times, what's 1 over 1 plus an8th, 1 plus an 8th is 9 8ths, so that's a 4th times 8 9ths.Since I'm taking the reciprocal
* And that is 2 9ths, so log of 5 4ths,according to this is about 2 9ths
* And I just keep on going right?Now I want to approximate log Of one plus a quarter plus a quarter.Well, that'll be about log of 1 plus a quarter, which is what I just calculated,plus a quarter times, now I gotta write down the derivative, and, again, I'm goingto pick the derivative of the middle of this interval.So, I'll evaluate the derivative at 1 plus 3 8ths which is right in between 1 plus aquarter and 1 plus 2 quarters
* I approximated log of 1 plus a quarter tobe 2 nineth plus a 4th times, what's this
* 1 plus 3 8ths?Well, that turns out to be 11 8ths but then I'm taking the reciprocal so I'llwrite 8 11ths
* So I've got 2 9ths plus 2 11ths.That works out to 40 99ths
* So that's approximately log of 1.5.Let's keep on going
* What's log of 1 plus 3 quarters.Well, that should be about log of 1 plus 2 quarters plus how much input changes to gofrom here to here, which is a quarter times the derivative.And now, where do I want to approximate the derivative?I'll approximate it in the middle of the interval again.So, it'll be 1 over 1 plus 5 8ths
* Well what's this?A log of 1 plus 2 quarters, log of 1.5, I just approximated that to be 40 99ths plusa quarter times 1 plus 5 8ths, that's 13 8ths.The reciprocal is 8 13th
* So this is 40 99ths plus 2 13ths whichthis is going to be a, a huge number
* It turns out 718 over 1,287.And, that's approximately log of 1.75
* Now, here we go.What's log of 2
* Well, that should be about log of 1.75.So, 1 and 3 quarters plus 1 quarter, so that's how much the input change is to gofrom here to here, times the derivative
* Which I'm going to approximate as 1 over 1plus 7 8th, right
* I'm going to approximate the derivative inthe middle of this interval
* And what does this turn out to be?Well, I just approximated this
* That was 718 over 1287 plus a quartertimes 1 plus 7 8th
* That's 15 8th.So 8 15th with the reciprocal
* So, that's 718 over 1287 plus 2 15th whichturns out to be 4448 over 6435, which is approximately 0.691.That is really great because log 2 Is actually closer to 0.693 but 0.691 isawfully close to 0.693
* And it's really fantastic that, you know,just on paper, right
* I'm able to get such a good approximationto log 2
* Let's use this same Euler method, or moreprecisely, the midpoint method, to approximate log 3.I use a little bit bigger step size here to save us some time.I'm going to put this same gain to, to approximate log of 3.Let's first do log 2
* By writing log 2 as log 1 and I move from1 to 2 by adding 1, so I'll add 1 times the derivative, and again I gotta pick 1then I'll evaluate with the derivative
* I don't want to evaluate the derivativelog at 1 or at 2, I want to do in between, so it would be 1 over 1 plus a half.So log of 1 is 0 plus 1 plus a half is 3 halves, but there's a reciprocal, sothat's 2 3rd
* So this is telling me that log of 2 isabout 2 3rds
* And I can do the same trick again with astep size of 1, so log of 3 is log 2 plus 1, which is how much I change by goingfrom 2 to 3 times the derivative, the approximation of the derivative somewhere,i'll do it in between again so it'll be one over 2 plus a 1/2 right.That's a point in between 2 and 3
* And I approximated log 2 to be 2 3rds and2 plus a half
* That's 5 halves, by the reciprocal, that's2 5ths
* And 2 3rds plus 2 5ths, common denominatorof 15, is 16 15th which is about 1.07
* How does this actually compare to log 3,well log 3 is actually about 1.0986, so I mean seriously, 1.07 is not such a badguess, compared to 1.0986 blah, blah, blah, right?In here I just used 2 steps and with a whole step size here of 1, right.So this is even a coarser approximation than a, the thing I used to approximatelog 2
* Now let's compute log 3 over log 2 or, ifyou like, log 3 base 2
* So log 3 over log 2 is about 1.584962501,it keeps going, right
* What you might notice here is that 1912ths is 1.583
* These are pretty close.We can rephrase this without using logarithms at all.So what I'm saying here is that log of 3 over log 2 is about 19 12ths.Well if this is true, that means that 12 times log 3 is about 19 times log 2.And my properties of logs, 12 times log 3 is same as log 3 to the 12th and 19 log 2is the same as log 2 to the 19th
* Now if these logarithms are approximatelyequal, you'd think then that 3 to the 12th would be approximately 2 to the 19th andyes, sure enough 3 to the 12th is 531441, and 2 to the 19th is 524288.And these numbers aren't so different
* This turns out to be maybe moresignificant than it seems at first
* Let's play around with this some more.These numbers 7, 12, 3 halves, 2, they're significant musically.Alright
* Two notes that are separated by a 5th areactually in a ratio of 3 to 3 in terms of their frequencies.Here, listen to two notes that are separated by a 5th.Those two notes are a 5th apart
* Now listen to two notes that are an octaveapart
* Those two notes are an octave apart andtheir frequency's in a ratio of two to one.Now the deal is that at 12 fifths is about seven octaves.Twelve fifths, that's like three halves, that's the ratio for a fifth to thetwelfth power is close to two to the seventh power, close to seven octaves.Here, let's, let's listen to 12 5th in a row.So that is 12 5th and now listen to seven octaves, starting at the same note.Notice that last note, right
* They're close to each other.And that's really an audio proof that 3 halves to the 12th power is almost two tothe seventh power.


--- SKIP ---: 01_what-does-dx-mean-by-itself.en.srt


--- SKIP ---: 01_what-does-dx-mean-by-itself.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-does-dx-mean-by-itself.en_SENTbySENT.txt
* [music] We've seen df/dx and we've seend/dx
* So now, we're going to think about justdx
* This sort of object is called adifferential
* [inaudible] about dx not d/dx, right?We've thought about that little bit already, right?As an operator, this the thing that does the differentiation.This object is what we're going to study right now.It's called a differential
* But what does that even mean?Geometrically, these differentials, so dy and dx, represented some change in thelinear approximation that I get using the tangent line.So here, I've got some function that I've graphed, y equals f of x.And here's a point, x, f of x
* And I've got a tangent line with a curvethere
* And here's some change in x, which I'mcalling dx, and here's some change in y, which I'm calling dy.And if you think about, what is the derivative?Well, I mean the derivative really is dy over dx, right, in some sense, you know.If you take the derivative and multiply it by how much the input changed by, I mean,you don't actually get how much the output changed by but you get an approximation tohow much the output changed by and as for this dy here is being used as, this dy isthe change in the linear approximation
* Okay, here's a statement in words.In words, dy is a change in the linearization, or the linearapproximation, or the tangent line approximation, to this function thatyou're thinking of as y, depending on x
* That's what dy is.I should emphasize that your dy's had better include a dx in there somewhere.At different points in your life, you'll develop hm, different ideas about what dxand dy really mean
* So, in a Calculus class, in this Calculusclass, if you really want to, you can think of dx and dy as infinitesimalquantities, very small quantities
* It's difficult to make this sort ofthinking entirely rigourous
* But that's certainly an okay way to thinkif you're trying to get some intuition for what these things are representing.Now, later on in your life, when you take some course, say, a differential geometrycourse, dx will then be given some better foundation.Dx will be revealed to be a differential form or a covector.I mean, you'll have some actual interpretation of dx but for the timebeing, you know, if you really want to, you can regard these things asinfinitesimal quantities
* But honestly, I wouldn't worry too muchabout how to actually think about these things and focus more on how to computewith these objects
* The basic trick is that if y is f of x,then dy is the derivative of f dx, and you don't even need necessarily todifferentiate f in a lot cases
* The differential satisfies many of thesame rules or analogous rules as just differentiation satisfies.So, for example, d of u and v, or u plus v I should say, is du plus dv.D of u times v, is a product rule, is du times v plus u dv, right?And there's a quotient rule
* I mean, this differential satisfied allthe same or let's just say analogous rules to derivatives.Let's take a look at an example
* For example maybe y is something here likex squared and, in that case, what's dy
* Well, dy is the derivative 2x times dx andyes, this does relate some change in x and change in y in terms of linearizations.But you don't even need necessarily to write it this way.You could if you wanted to write dx squared and then think that there is powerrule of a differential just like the usual power rule, which then says that this is2x dx
* So, in general, d of x to the n would benx to the n minus 1 dx
* We can cook up a more complicated example.For example, let's calculate d of x sine x.Well, this is d of a product and I can compute that by using the product rule fordifferentials, right
* What does that tell me?Well, it will be d of the first thing times the second thing plus the firstthing times d of the second thing
* Now, instead of writing dx times sin x, Icould write that as sin x dx
* And what's d of sin of x?Well, this is d of a function
* And remember, how do I take d of afunction
* Well, it's the derivative times dx.So, this is x times the derivative, which is cosine x times dx.Now, if I like, I could factor out the dx and I could write this as sin x plus x cosx dx, now, because I haven't done anything new here, right?I mean, I could have just differentiate x sin x but the point is I'm writing it downwithout ever, you know, taking derivative
* I'm sort of using the rule for how tocompute differentials, right
* Like the differential product rule and thefact that the differential of a function is the derivative dx.I'm being a little bit vague with how to deal with these differentials at thispoint
* But we're going to be seeing more of thesedifferentials in the coming weeks.


--- SKIP ---: 01_what-is-newtons-method.en.srt


--- SKIP ---: 01_what-is-newtons-method.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-newtons-method.en_SENTbySENT.txt
* [music].I often want to find approximate roots
* Well, here's the set up.I start with some nice function, f, nice meaning differentiable.Maybe the derivative is continuous, a, a reasonable function.And then I want to find some input, x, so that the function evaluated at that inputis equal to 0
* Now in practice, this is way too much toask for
* I'm not really going to be able to findsome particular input x
* I mean I might not even be able to writedown that input in any reasonable sense
* But what I can ask for is I can find somex so that, f of x is very close to 0
* Right I mean, maybe I can't find it sothat the output of the function is equal to zero.But maybe I can find an input so that the output there is really close to 0, reallysmall
* If you think back, we've already donethis
* Right.If you remember this video, where I use the Intermediate Value Theorem, I was ableto proximate a root of a function just by interrogating the function, evaluating itat a handful of points
* And, there was that bisection trick.So in this example it looks like the function evaluated that a is positive andthe function evaluated b is negative
* This function looks like a reasonable nicefunction who's continuous so the intermediate value theorem applies.And that mean in-between a and b, there's some input, where the function's output is0
* I can cut this interval in half and if Ilook in the middle of interval the function's output there is positive, andthat means just in between these two inputs there must be some input where thefunction's output is 0
* And then I could cut that in half again.And if I look at the input there, the output of the function is negative.And that means in between these two inputs there must be some input so the functionsoutput is 0
* And then I could cut that in half again.And if I look there the functions output is positive.So I've got a negative output Put in a positive output, so in between, by theintermediate value theorem, there must be some input where the function's output is0
* And so on and so forth, right?I'm getting closer and closer to the point where the function output is actuallyequal to 0, at least I can approximate it this way.The downside to this bisection method is just speed, it takes a really long time.So a different method, called Newton's method, is much faster than this bisectiontrick
* Well, this is faster when it actuallyworks
* So what is Newton's method.What I'm trying to do is find the x coordinate, where the graph of thisfunction crosses the x-axis right
* I want to know an input so this function'soutput there is 0
* And instead of marching in from eitherside, as in intermediate value theorem, Newton's method has us just start bymaking a potentially bad guess
* Here's my 1st guess.I'm going to call it x of 0
* And yeah, that's, that's not a very goodguess
* Because the function's output is all theway up here
* Not that close to 0.But after I've made that first guess, Newton tells us to draw the tangent lineto the curve
* Through, through that point.So here's the tangent line to the curve through that point.And then my next guess will be wherever that tangent line crosses the x axis.So here would be my next guess x of 1
* And then I just hope that, that next guessis better
* But I could repeat the process.Right
* I could do the same game here.This point is closer to 0
* And then I could again draw anothertangent line to the curve, through that point.And then this next place where that tangent line crosses the x axis that'll bex of 2, my next guess
* And at least from this picture it lookslike that's an even better guess as to where the graph of this function crossesthe x axis
* So at least pictorily that's what Newton'smethod is telling us what to do
* Let's write down the steps.Well here is Newton's method in words
* You start with some initial guess x0.The next step is to draw the tangent line through the point x0 f of x0, right.That's exactly what I did here
* I started with x0 and then I drew this 1stred Tangent line
* Now the next step is to figure out wherethat tangent line
* All right, the tangent line right there.Crosses the x-axis
* Now I'm going to use that for my newguess, x of 1
* Which I hope will be a better guess frommy original guess
* All right, my original guess was prettyfar away from 0
* X1, Which is where the tangent line herecrosses the x-axis
* I'm hoping that's a better guess.And yeah, at least in this example it is
* And then I'm going to repeat the process.Right
* In this picture, once I had my new guess Xof 1 I then drew the tangent line to the graph at X 1 comma F of X 1 and thattangent line intesect the X access at a point I'm calling X of 2 and I'm justhoping then that, that's even a better guess as to the actual point where thegraph crosses the X access
* All right, so that's this repeat process.And you can just keep repeating this as long as you want.And, you know, hopefully you're getting better and better guesses every time.As to exactly where that graph crosses the x-axis.Those worked this all out with equations
* Right?I'm going to write down the equation in the tangent line.And then solve for wherever that tangent line crosses the x-axis.So I'm going to start by thinking about this red line, right?This red line is the tangent line to the orange graph at the point x0, f of x0.And as a tangent line, so it has slope the derivative at x0.And here I've written down the point slope form Of the red line.Right
* It's y minus the y coordinate on the line,which is fx0, is equal to the slope of the line which is the derivative add x 0.Times x minus the x coordinate on the line, which is x0.Now, Newton's method tells me that I should use that linear approximation tothe graph, figure out where the linear approximation crosses the x axis and justhope that's a better approximation to where the orange curve actually crossesthe x axis
* So to do that, I'm going to set y equals 0and I'm going to solve for x
* Right.And that'll tell me where the red line crosses the x axis, if I solve thisequation for x
* Well, I can expand out, this side.Right
* And, the right-hand side of this equationis f prime, x 0 times x minus f prime x0 times x0.I'm going to add f prime x0 times x0 to both sides.So the equation becomes f prime x0 times x0 minus f of x 0 is equal to f prime x 0times x, right
* I just added f prime of x 0 times x 0 toboth sides
* And 0 here went away.Right
* So f prime x 0 times x 0 minus f of x 0 isequal to this f prime x 0 times x
* Now assuming that the derivative not equalto 0 at this point I'm going to divide both sides by f prime x 0.We're going to divide this side by f prime f 0, I just get x0.0 minus f of x0 divided by f prime x0, so that's this left-hand side divided by fprime of x0
* The f prime x0 here cancelled, and the fx0 divided by f prime of x0 is what I got here.And I'm dividing both sides by f prime of x0, so this side is just x.So the x coordinate where this red line crosses the x axis is this.And I'm going to call this my new hopefully improved guess, x sub 1.With this equation in hand, I can now write down the step by step process forNewtons method just using a formula
* Here's the step by step process.I start with some initial guess x sub 0, and then I'm drawing that tangent line tothe graph x 0 x of f 0, looking where that tangent line crosses the x axis to get mynew guess, right
* And this is the formula we just computed.X1, my new guess, is X 0 minus the functions value there divided by thefunctions derived there
* And with that new guess, I can then playthe same game
* Drawing the tangent line to the graph atX1, F of X1
* Figure out where that tangent line crossesthe x-axis, to get a newer guess x of 2
* Same formula works for that.It's the old guess minus the function at the old guess divided by the derivative atthe old guess, to get my new guess
* And I can just keep playing this game overand over again
* Hoping that each generation brings mecloser To a place where the function's value is in fact 0.Let's just summarize the formula
* So in summering I could say that my newguess which I'll call x of n plus 1, is my old guess minus the function's value of myold guess divided by the function's derivative at my old guess.And I can just keep repeating this over and over again.When this works, all right, when Newton's method actually succeeds, it works reallywell and it zooms in on that root really quickly.The problem is that I can't promise you that Newton's method will actually work.


--- SKIP ---: 02_what-is-a-root-of-the-polynomial-x-5-x-2-1.en.srt


--- SKIP ---: 02_what-is-a-root-of-the-polynomial-x-5-x-2-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-a-root-of-the-polynomial-x-5-x-2-1.en_SENTbySENT.txt
* [music] Just for fun I'd like to know aroot of the polynomial x to the 5th, plus x squared, minus 1.So here's the function where I want to find a root, right?I want to find some input that makes this function equal to 0.What do I know about this function
* It's continuous and I know that f of 0, ifI plug in 0
* It's 0 plus 0 minus 1.So f of zero is minus 1
* And f of 1 is 1 to the 5th plus 1 squaredminus 1
* That's 1 plus 1 minus 1, that's 1.So what I know here is I've got a continuous function.And its value at 0 is minus 1 and its value at 1 is 1.So there has to be some input between 0 and 1 where this function's output isequal to 0
* So I know there's a root there between 0and 1
* Let's find that root.Now, if we were just trying to find where some linear term was equal to 0.You can just solve for x, in that case
* If I were just trying to figure out wheresome quadratic was equal to 0
* There's the quadratic formula.If I were trying to figure out where ax cubed plus bx squared plus cx plus d wasequal to 0
* I could use a more complicated formula.It's the cubic formula
* It's way more complicated than thequadratic formula
* But there is such a formula.If I were trying to solve an equation like this that started with a X to the 4thterm, I could use the quartic formula to do that.The bad news is that here I'm trying to solve a quintic and there is no quinticformula in terms of the usual arithmetic operations plus, minus, times, anddivides, and taking roots
* Of course some quintics can be solved Imean, it's true
* Right?If I had instead been trying to find a solution to this equation, x to the 5thminus 2 equals 0, I'm looking for some value of x, take its 5th power andsubtract 2 and I'd get 0
* Yes, I could solve this quintec.Right
* I mean, its solution is the 5th root of 2.2
* But in contrast this particular example Xto the 5th plus X squared minus 1 can't be solved in the sense that I can't writedown using fractions, plus, minus, times, divides, and the taking of roots.A number which, if I take it's 5th power, add it to its square, and subtract 1, Iget back 0
* Right?I mean, that's the sense in which I can't solve it.I can't just write that thing down in terms of the operations that I have athand
* Knowing that requires something called theGalois theory
* So in light of Galois theory, what does iteven mean to find a, A root
* Well, I'm not going to be able to writedown the root
* But I can at least approximate the root byusing Newton's method
* So I can use Newton's method to at leastapproximate a root
* So here's the function whose root I wantto approximate
* Right?I want to find some input so that f is close to 0.And I'll first differentiate f
* So the derivative of f, well thederivative of x to the 5th is 5 x to the 4th, derivative of x squared is 2 x, andthe derivative of 1 is 0
* So I've got my original function.I've got my derivative, and then Newton's method tells me that I should make a firstguess
* My first guess will be 1.So I've made my initial guess
* What's my next guess?So my next guess according to Newton's method.We'll call that x of 1, would be my old guess minus the functions value of my oldguess, divided by the function's derivative at my old guess.And now my old guess is 1
* The function's value at 1, that's 1 to the5th plus 1 squared minus 1
* That's 1 plus 1 minus 1, that's 1.And the derivative at 1, now that's 5 times 1 to the 4th plus 2 times 1.That's 5 plus 2, that's 7
* So, my new guess is 1 minus 1 over 7.That's 6 7ths, so that's my new guess
* And 6 7ths really isn't that bad of aguess
* So my original guess, right, x0, that was1
* And f of 1 was just 1.My next guess, x1, that was 6 7ths, right
* And what's f of 6 7ths?Well that's 6 7ths to the 5th plus 6 7ths squared minus 1.That turns out to be about .197
* Right?So certainly this 6 7ths is a better guess than 1.Now armed with my better guess I can apply Newton's method again and hopefully arriveat an even better approximation to the rut.So I get a new guess, x sub 2, by taking my old guess, x sub 1, and subtracting thefunctions value there, divided by the functions derivative there.And when I do that I get something which is a about .812.X of 2 is an even better guess
* So I evaluate my function F at X 2, I getwell it turns out to be about .014
* So this new guess for the root of myfunction is even better then my old guess, right?My old guess was giving me .197 as the output This new guess is getting me closerto a 0 of the function looks like
* Well don't stop.I'll do it again
* I can do Newton's method again, right.And I'll get a newer guess even
* X of 3 will be x of 2 minus f of x of 2divided by the derivative
* Of, of f at x sub 2 n.This turns out to be about .809
* This last guess is even better.And this is really working quite well
* F at this new guess, x sub 3, turns out tobe about 0.000085
* And I'm getting much closer now to theactual 0 of this function
* These sorts of examples of polynomialswhere I can't explicitly write down the root.They really raise a fascinating question as to what it even means to find the root.All right, the intermediate value theorem promises me that there is a root.In this case, between 0 and 1
* And Newton's method, or this bi-sectionalgorithm permits me to get better and better approximations to that root.But it's only in that sense that I can ever find the root.It's in the sense that I can get as close as you want to that root.


--- SKIP ---: 03_how-can-newtons-method-help-me-to-divide-quickly.en.srt


--- SKIP ---: 03_how-can-newtons-method-help-me-to-divide-quickly.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-can-newtons-method-help-me-to-divide-quickly.en_SENTbySENT.txt
* [music] You've already seen a fewdifferent techniques for how to multiply quickly.Some of those techniques include quartersquares, using logarithms or asliderule
* And that method of prosthaphaeresis, whichinvolves arc cosine
* So yeah, there's a ton of differenttechniques that I can use to multiply two numbers quickly.But what if I could already multiply quickly, but I wanted to divide quickly?What if I wanted to calculate 1 divided by b?Well, we can use Newton's method to do this.Now, how we're going to use Newton's method.Well, Newton's method is really a trick for finding zeroes of a function.So, if I want to approximate one divided by b, the reciprocal of b, what I reallywant to find is some function where that number is a zero of the function.Newton's method will help me approximate that zero and consequently help meapproximate 1 over b
* There's a ton of different choices thatare possible for such a function
* Well, here's one choice.The function f of x equals 1 over x minus b.And let's just check, yeah, if I evaluate this function at 1 over b, that's 1 over 1over b minus b
* But 1 over 1 over b, the reciprocal of thereciprocal of b, is just b
* And b minus b is in fact 0.So, this function f does have 1 over b as a 0.Now let's apply Newton's method
* So how are we going to do this?Here is the formula for Newtons' method, right?This is the iterative formula, my next guess is my old guess minus this fraction.The function evaluate of my old guess divided by the derivative evaluate of myold guess
* And when this works, it's marching mecloser to a 0 of the function
* And here's the good function for doingdivision
* This function has a 0 at 1 over b.So, if I can get closer and closer to a zero of this function, I'm actuallycomputing 1 over b, which is what I want to do.So, let's try to rewrite this formula just by using this.And the first step here is to differentiate this.So, let's differentiate this
* Well, the differential goes back to x.So, the derivative of 1 over x is minus 1 over x squared, and the b here is theconstant
* So, I have to include it.So, this is the derivative of f
* Now, I'll use that to try to make thisNewton's method formula look a little bit nicer.So, x of n plus 1 is x of n minus the function evaluated, x of n, which is 1over x of n minus b, divided by the derivative evaluator x of n, which isminus 1 over x of n squared
* Now, to kill off this denominator, let'smultiple by minus x sub n squared divided by minus x sub n squared.That's just a sneaky version of 1, but it manages to kill off the denominatorsimplify this a bit
* I've got x sub n.I've got minus x sub n squared times 1 over x sub n, that leaves me with a minusx sub n
* And I've got a negative b, negative x subn squared, that's a plus b x sub n squared.I'm subtracting this
* So, I've got x sub n plus x sub n, that'stwo x sub n's, minus b x of n squared
* And I'll factor out an x of n, so x of ntimes 2 minus bx of n
* And what I've got here now is an iterativeformula that, at least when it works
* Applying this iterative formula is goingto move me closer and closer to one over b.But this formula doesn't involve division, it only involves multiplying andsubtracting
* So, this is a way to approximate 1 over bwithout ever dividing, right
* Just multiplying and subtracting over andover again
* Then, we'll make this even more concrete.Let's set b equals 7 so I can try to approximate 1 over 7.So here we go
* B will be 7.So, we're trying to approximate 1 7th using Newton's method.So, I make an initial guess
* And I'll make my initial guess 1 10th andmake some of the arithmetic work out, a little bit more reasonably.And I'm going to start with this initial guess, and I'll use this formula we justderived to improve this initial guess to a hopefully better guess.So, I take my original guess, 1 10th
* Multiply it by 2 minus b is 7, times myprevious guess of 1 10th
* I can calculate this.This is 1 10th times, instead of 2 I'll write 20 10th.And instead of 7 times a 10th, I'll write 7 10th.I got 20 minus 7 10th, so that's 13 10th
* So, 1 10th times 13 10th, that's 13 100thand that's a slightly better as to the value of, of 1 7th, but I can now repeatthis process using this formula again
* So, I'll get a better guess here x sub 2by starting with my previous guess, which is 13 100th.Multiply that by 2 minus 7 times my previous guess of 13 100th.I can calculate what this is
* So, 13 100th.Instead of 2, I'll write 200 100th, that's another name for 2 minus.Instead of 7 times 13, I'll multiply that out.I'll get 91 100th
* Now, 200 minus 91, that's 109 100th times13 100th
* And 13 times 109 is 1417, and 100 times100 is 10,000
* So, that's an even better approximation tothe actual value of 1 7th
* And I could appreciate the process again.The arithmetic gets, you know, sort of awful.But the point here isn't so much, you know, that I can actually do this onpaper, or that I would want to do this on paper.But that this procedure only involves adding, subtracting, and multiplying, andyet it ends up calculating a division problem.Well, how close are we to the actual value of 1 7th?1 7th is about 0.142857 and it keeps on going.So yeah, we're doing really quite well
* I mean, 0.14 is a pretty good guess as tothe actual value of 1 7th
* This method has a name.So, this technique usually goes by the name Newton-Raphson Division.And we just saw that it works for finding recipricols, but if you can findrecipricols and you can multiply, you can do division in general.Alright, if you wanted to approximate 3 7th using this technique, well, you justpoint out that 3 7th is 3 times 1 7th, right?And imagine that you can multiply, add, subtract, but the division is hard.Okay, well a moment ago, we approximated 1 7th, alright?We approximated 1 7th to be about 1,417 over 10,000.This was the second stage in the approximation.And 3 times 1,417 is 4251 over 10,000
* Which isn't so far off of 3 7th, right?The point though is that, you know, if division, but if division that onlyinvolves repeated adding, subtracting, and multiplying.


--- SKIP ---: 01_what-is-the-mean-value-theorem.en.srt


--- SKIP ---: 01_what-is-the-mean-value-theorem.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-mean-value-theorem.en_SENTbySENT.txt
* [music] How does information about thederivative connect back to information about the original function.There is a technical tool that connects this differential information just to thevalue of the function and that tool is the mean value theorum.Well here's a statement of the mean value theorem.Suppose that f is continuous on the closed interval between a and b, and it'sdifferentiable on the open interval a b
* So that's the setup.F is a pretty nice function
* Then there exist some point in between aand b, so a point in the interval a b
* So that the derivative of the function atthe point c, is equal to this
* Which is really calculating the slopebetween the point a f of a
* And b f of b.That statement seems really complicated
* Let's try to boil that down to a statementwe can really believe in
* Well, here's one interpretation.If that function is giving you position and the input to that function is time, sothat the derivative of that function is your velocity, then that formula is sayingthat your average velocity is achieved, at some point instantaneously.Right
* That fraction, that difference ratio, iscalculating the average velocity
* And instantaneous velocity is thederivative
* And the mean value theorem is saying thatthose are equal at some point in between
* Let's go back now to the officialstatement of the mean value theorem
* So here again, is the statement of themean value theorem, right, a nice enough function that there's some point in themiddle so that the derivative, your instantaneous velocity is equal to this.Which is, you know, if you like calculating your average velocity.We can take a look at this from a graph as well and might help even more.All right here's the graph of just some function that I've made up.And I've picked points a and b and it's certainly a nice enough function.I mean it's a continuous function a differentiable function, and I've pickedpoints a and b
* And here's f of a and f of b and then I'vedrawn this red line that connects the point a f of a and b f of b.And the slope of that line is exactly what this quantity calculates.All right, so I'll label this as the slope of that secant line.Now, if asserting the existence of some point in between, where the derivative hasthe same value as the slope of this secant line you know, it just sort of looks like,from this picture, maybe that point is here.And, yeah, it looks like if I draw a tangent line to the curve at that point,the slope of that tangent line, which is the derivative at the point c, is the sameas the slope of that red secant line
* Right?So, in the statement of the mean value theorem, this f prime of c, that's theslope of the tangent line
* To the graph of the function at the pointc, and this statement is asserting that the slope of tangent line at some point inbetween is equal to the slope of the secent line between a f of a, and b f ofb
* The mean-value theorem is often told as astory about somebody driving a car
* Well here's the story.At noon, you're in some city A, and at 1 p.m.You're driving your car and you've arrived in a city B, which is 100 miles away fromcity A
* You're driving your car and you've arrivedin a city B, which is 100 miles away from city A.Now what does the mean-value theorem say
* Well, the Mean Value Theorem tells youthat at some point in between, the derivative is equal to the slope of thesecant line
* Which in this story means, that at somepoint during your journey, your speedometer.Said 100 miles per hour
* Your speedometer's reporting yourinstantaneous speed, right
* That's this, the derivative of yourposition with respect to time, at some point in between.And I'm claiming that at some point it said 100 miles per hour, and that'sbecause your average speed was 100 miles per hour, right?In one hour you traveled 100 miles and that's exactly what this differencequotient is calculating
* So at some point along your journey, youmust have exceeded the speed limit
* Alright, so all this is very interesting,the mean value theorem, really great but what is this used for, how does the meanvalue theorem actually help us understand anything about a function once we knowsomething about its derivative
* Well, here's one very importantapplication; it's a theorem
* You've got some function f and it'sdifferentiable on some open interval and on that interval the derivative isidentically zero, so the derivative is just zero no matter what I plug in.Then that function is constant on that interval.So it's a really exciting result, because it's relating information about thederivative back to information about the value of the function.It's saying that if the derivative is equal to 0, that function only outputs onevalue
* It's a constant function.So let's prove this statement using the most valuable theorem, the MVT, or themean value theorem
* Well here we go.So I want to prove this and what I'm going to do is I'm going to pick two points,I'll call them a and b, in the interval
* And since f is differentiable on the wholeinterval and I've picked a and b inside that interval, this is actually enough toguarantee that the hypotheses, the Mean Value Theorem, applied.The function's continuous on the closed interval and differentiable on the openinterval a b
* Okay, now that means value theoremapplies
* So f of b minus f of a over b minus a isequal to the derivative of f at some mystery point c in between a and b.But no matter where I evaluate the derivative the assumption here is that thederivative is identically 0
* So that is equal to 0.This means that no matter which a and b I pick f of b minus f of a over b minus a isequal to 0
* Now how can a fraction be equal to 0?The only way the fraction is equal to 0 is if the numerator's equal to 0.So that means that f of b minus f of a is equal to 0.And now, if I just add f of a to both sides, I conclude that f of b is equal tof of a
* What I'm really saying here, is that nomatter which a and which b I pick, f of a is equal to f of b.So, f, is a constant function, right
* Any two output values are the same sothere must only be one output value
* Which is exactly what it means to say thefunction is constant.


--- SKIP ---: 02_why-does-f-x-0-imply-that-f-is-increasing.en.srt


--- SKIP ---: 02_why-does-f-x-0-imply-that-f-is-increasing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_why-does-f-x-0-imply-that-f-is-increasing.en_SENTbySENT.txt
* [music].The mean value theorem has some other applications where it connects derivativeinformation back to information about the original function.Well, here's a theorem
* Suppose the derivative of some function.So I'm assuming it's a differential function, is positive, it's greater thanzero on some open interval
* Then the function is an increasingfunction, meaning that it sends, bigger inputs to bigger outputs.You probably already believe that statement.But the mean value theorem let's us verify that it's actually true.Okay, so let's prove, this result
* I'm going to pick, two points a and b, butI want to make sure that I pick them in order.So I'm going to pick b bigger than a so I can talk about the interval a b.All right
* So I'll pick my two points.Now I'm going to apply the mean value theorem to the open interval a,b.And that's OK because I'm going to pick a and b to be in this open interval andthat's mean that f being differentiable satisfies the conditions of the mean valuetheorem
* The continuous on the closed interval a, band it will be differnetial on the open interval a, b.Okay
* So the mean value theorem then tells me tolook at f of v minus f of a over b minus a, and the conclusion is that this is thederivative of f at some mystery point in between a and b.Now the good news is I don't know much about the derivative but I know thederivative is positive
* So I know that f of b minus f of a over bminus a is positive
* The other thing that I know is that b isgreater than a and that means the denominator here b minus a is alsopositive
* So I've got mystery number divided bypositive is positive
* That means this numerator must also bepositive
* So f of b minus f of a is positive.Now, if I add f of a to both sides, I get that f of b is bigger than f of a.If f sends bigger inputs to bigger outputs then f is increasing.Increasing means that a bigger input is sent to a bigger output.So if b is greater than a then f of b is bigger than f of a and this argument worksfor any a and b In the open interval on which I know the derivative is positive.So I'm going to conclude that f is an increasing function, which is exactly whatI wanted to show
* So if the derivative's positive on a wholeinterval, then the function's increasing on that interval.But it's important to point out that I needed to know the sign, the s i g n ofthe derivative on that entire interval
* The mean value theorem ends of justpicking out a single point, that point c, where it'll examine the derivative.But in order to cover all my bases right because I don't know what point c the meanvalue theorem might make me look at 
* I've got to control the sign the S I G Non the derivative on the entire interval
* Alright, now I can play the same game whenthe sign of the derivative is negative
* So, if I know the sign the SIG derivativeis negative on some open interval then I include that F is a decreasing function.And, again this is just an application of the mean value theorem.Let's see the proof
* So, I'm going to start out by againpicking two points a,b in my opening interval and I'll again pick them so thatb is greater than a so I can talk about the interval a,b.And then applying the mean value theorem, I should look at, f of b minus, f of aover b minus a
* And the mean value theorem promises methat this is the derivative at some point, and I don't know what c is but it's thederivative at some point
* But I know that the derivative at anypoint Is negative so this must be negative.Now b minus a is positive because b's bigger than a.So I've got a number I don't know divided by a positive number is negative.That means that f of b minus f of a must be negative.Then I add f of a to both sides and I can conclude that f of b is less than f of a.In other words, f sends bigger inputs to smaller output.Since f sends bigger inputs to smaller outputs, f is a decreasing function.Once again we're seeing that the mean value theorem lets me relate informationabout the derivative, in this case the fact that the sign of the derivative isnegative
* Back to information about the originalfunction, in this case the function's decreasing.Alright, well lets summarize what we've learned thus far.So here are some applications of the mean value theorem.If f is differentiable on some open interval and depending as to what happensthen we know something about f on that interval.So if the derivative is identically zero, if the derivative is equal to zero nomatter what I plug in, then f is constant on that interval.If the derivative is positive no matter what I plug in, then f is increasing onthat interval
* And, if the derivative is negative, then fis decreasing on that interval.


--- SKIP ---: 03_should-i-bother-to-find-the-point-c-in-the-mean-value-theorem.en.srt


--- SKIP ---: 03_should-i-bother-to-find-the-point-c-in-the-mean-value-theorem.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_should-i-bother-to-find-the-point-c-in-the-mean-value-theorem.en_SENTbySENT.txt
* [music].A classic problem about the mean theorem problem that's often asked in Calculuscourses, well, that classic problem goes like this.Given a function f and points a and b, I want to find some other point c, so that fprime of c is equal to f of b minus f of a all over b minus a.The mean value theorem promises us that as long as f is a nice enough function, niceenough meaning it's differentiable on the open interval a b, continuous on theclosed interval a b
* That as long as f is a nice enoughfunction, then that's possible
* I can find that point c, so that thederivative of f at the point c is equal to f of b minus f of a over b minus a.Let, let's do an example where I try to find that point c.So let's do an example
* I'll have f of x, just making up someexample, that'll be x cubed and it will be on the interval where a equal 1 and bequals 4
* So really, what I'm trying to do is findsome point c so that the derivative of the function at the point c is f of b minus fof a over b minus a
* Now, in this case, f of b is 4 cubed,that's 64
* F of a is 1 cubed, that's 1.And b minus a, that's 4 minus 1
* This is 63 over 3.That's 21
* So I'm looking for a point c, where thederivative is equal to 21
* Now, can I do that?Yeah
* I just gotta differentiate this function.So here we go
* I'll differentiate this function, and Iget that the derivative of x cube is 3 x squared, and I'm looking for which valueof x is that equal to 21
* We'll divide both sides by 3.I'm looking for a value of x, where x squared is 7.And so divide both sides by 3
* And my x should be between a and b, right?So in that case, x is the positive square root of 7.And what I've really accomplished here, if I make a little graph, here's the x yplane, and I'll draw kind of a made up graph of the cubed function.All right, here's the point 1, say
* Here's the point 4.Here is 1,1
* Here's 4,64.Right
* The slope of the line here, all right, is21
* All right, the slope here is 21.And what I've really managed to do here is find that at the square root of 7, theslope of the tangent line is exactly the same as the slope of the line through 1,1, and 4, 4 cubed
* It's super important to emphasize thatalthough these kinds of problems are fun, and the mean value theorem guarantees thatfor nice enough functions we can find such a c, yeah, these are fun problems.The mean value theorem guarantees that it's possible.But that's not the point of the mean value theorem.The mean value theorem is more than just a computational result.It's really an existence theorem
* It's important to emphasize the power ofthese existence results
* Something like the mean value theoremtells you that something exists without you having to actually go out into theworld and find that thing
* Right?And having you do a ton of problems where you find the point c really wouldundermine that important lesson, right
* The power of the mean value theorem liesnot in the fact that you can actually go out and compute the value c, right?The power lies in the fact, the mean value theorem tells you that it's possible, thatyou know there's a value of c out there, without you having actually go and findit
* And because of that, it opens up the doorto all these interesting conceptual applications where we're relating, say,positive derivative on an interval to the fact the function's values are increasing.And that's really the power of the mean value theorem.It's a conceptual result that helps you relate Information about the derivative toinformation about the original function
* .


--- SKIP ---: 01_what-does-it-mean-to-antidifferentiate.en.srt


--- SKIP ---: 01_what-does-it-mean-to-antidifferentiate.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-does-it-mean-to-antidifferentiate.en_SENTbySENT.txt
* [MUSIC] We've done a ton of differentiating inthis course
* We've learned all these rules for takingderivatives, and we've been studying a bunch ofapplications of differentiation
* And things like optimization problems
* But now, I want to take all this differentiation stuff and run it inreverse
* I want to do anti-differentiation
* Well, what is anti-differentiation
* When we're just differentiating, we'rejust taking derivatives
* That means I'm giving you functions andyou're giving me the derivative
* When I ask you to anti-differentiate, Iwant you to do that in reverse
* I want to give you a function
* And then I want you to give me a function whose derivative is the functionI gave you
* That's anti-differentiating
* Starting with the derivative, and figuringout what function would I have to differentiate to get that, asits derivative
* It turns out thatР вЂњРЎС›Р вЂ™Р вЂљР вЂ™РІвЂћСћs quite a bit harderthan just differentiating
* No matter how complicated an expression Igave you, I know that you can differentiate it
* You just have to carefully apply the rulesof differentiation
* You know, things like the sum rule, theproduct rule, the quotient rule, the chain rule,derivatives of certain transcendental functions but Iknow that you can do it, it's just a matter of applyingthose rules
* It might be complicated but it's doable
* In contrast, anti-differentiating doesn'treally have so may rules associated with it
* It involves a lot more creativity, andtherefore, I think it's a lot more fun
* Of course, if it's going to be complicatedwe should ask ourselves why we're doing it at all,you know
* What's the point of undoingdifferentiation
* Why would you want to anti-differentiatein the first place
* Well, it turns out thatanti-differentiation is like a bridge between two different parts ofthis course
* Up until now, we've really been lookingat, at differentiation
* And then, the end of this course gets into integration, and this theory of, of areas,if you like
* A huge surprise is thatanti-differentiation will let us solve the integration problems that are coming up atthe end of this course
* So you can really think of anti-differentiation as a sort of bridgebetween the, the differentiation section of thiscourse, and the integration section of thiscourse
* That's a story that's yet to come
* For now, I just want to focus onanti-differentiation
* [SOUND] [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_how-do-we-handle-the-fact-that-there-are-many-antiderivatives.en.srt


--- SKIP ---: 01_how-do-we-handle-the-fact-that-there-are-many-antiderivatives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-do-we-handle-the-fact-that-there-are-many-antiderivatives.en_SENTbySENT.txt
* [music] Sometimes people ask for the antiderivative
* But instead of talking about the antiderivative it's probably better to talk about an anti deriviative.So why is this the and an distinction really important.Because a function can have more than one anti-derivative.Let's take a look at an example
* Let's think about the function f of xequals 2 x, to find on the whole real line.Can you think of a function whose derivative is 2 x?I'm looking for a function which differentiates to give me this function.So here's an example
* A big f of x equals x squared, and yes, ifI differentiate that function I get back 2x, which is in fact little f.So the derivative of big f is little f, or in other words an anti-derivative forlittle f
* Is big F.Okay
* Good.Now, can we think of another function whose derivative is 2x?Well, yeah
* Think about this function big G of x whichI'll define to be x squared plus 17 and big G's derivative is the derivative ofthis sum which is the derivative of x squared which is 2x plus the derivative of17 which is 0
* So big G differentiates to little f.And that means another anti-derivative for little f is big G.Okay great
* Now let's think of yet another functionwhose derivative is 2x
* Yeah, I can play this game all day.Big H of x is equal to say x squared plus 123.Big h differentiates to 2 x again
* So big h is another anti derivative oflittle f
* There's clearly a pattern here, right.What's the general story
* Well here's the general story.So I got this function f of x equals 2 x
* Any anti derivative of little f has theform big f
* Equals x squared plus c for some constantc
* All of out previous examples had thisform
* Like here the constant is 0, here theconstant is 17, here the constant is 123
* And what I'm claiming here is that anyother anti derivative is just x squared plus some fixed number.How do we know this
* Well, it goes back to the mean valuetheorem
* So, suppose I've got 2 anti-derivatives,big F and big G for little f
* In other words, I mean that if Idifferentiate big F I get little f, and if I differentiate big G I get little f.So, suppose I've got Two anti derivatives for little F.Now what can I do, like I define a new function called big H and big H will justbe big F minus big G
* Now what do I know about the derivative ofbig H, the derivative of big H is the derivative of F minus the derivative of Gbecause the derivative of the difference is the difference of derivatives.So this is the derivative of f minus the derivative of g.But what is the derivative of f
* It's little f.What's the derivative of g
* It's little f?This is little f minus little f
* Oh noes.This is 0, right
* The derivative of big H is 0.Now what does that mean
* Well if you think back to the mean valuetheorem From earlier in the course, if a functions derivative is equal to zero, andsay that function is defined on the whole real line, like our example with x squaredand two x, then, that means that this function is a constant.Right
* So that means that h of x Is a constant.Now, what that means is that the difference between F and G, these twoantiderivatives for little f, is just some fixed constant, right?In other words, F of x, is equal to G of x plus some constant.And this is exactly what we're trying to get at, right?This idea that if a function's got two different anti-derivatives.And the function's defined say on the whole real line.Then those two different anti-derivatives just differ by a constant or saiddifferently
* If you've got a specific anti-derivative,than any other anti-derivative is just that specific anti-derivative plus someconstant
* Let me say that again, and, and actuallywrite it down
* Suppose that little f is a function that'sdefined on an interval I
* That's really crucial that it's defined onan interval
* And suppose that big F is ananti-derivative of little f
* In other words if I differentiate big F, Iget little f
* Well then any antiderivative of little f,not just this one, any antiderivative has the form big F of x plus c for someconstant c.


--- SKIP ---: 01_what-is-the-antiderivative-of-a-sum.en.srt


--- SKIP ---: 01_what-is-the-antiderivative-of-a-sum.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-antiderivative-of-a-sum.en_SENTbySENT.txt
* [music] A long, long time ago we startedwriting down rules for differentiating
* We have rules for antidifferentiating aswell
* Suppose big F is an antiderivative oflittle f, and big G is an antiderivative of little g?By which I mean that if I were to differentiate big F I'd get little f.And if I were to differentiate big G I'd get little g.Now, can I find an antiderivative for the function F plus G?Specifically let's define a new function I'll call little h and little h of x willbe little f of x plus little g of x, right?So the function of little h is the sum of f and g.Now the claim, is that this other function that I'll call big H, which is the sum ofbig F and big G
* My claim is that this big H is anantiderivative for little h
* By which I mean that if I differentiatebig H I get little h and that's true, right?Because if I differentiate big F, I get little f and if I differentiate big G, Iget little g
* And the derivative of a sum is the sum ofthe derivatives so the antiderivative of a sum is the sum of the antiderivatives.It's better for me to say that an antiderivative for the sum, is the sum ofantiderivatives
* Yeah.But I want to write this down as a general principle.And before I can really write down that general principle, I'm going to introducea little bit of notation
* So suppose big F is an antiderivative oflittle f, that means any other antiderivative of little f can be writtenlike this, big F of x plus c
* Now, my notation for writing down theantiderivative of little f is this, is exactly this notation here, this longcurvy s
* So I'll write this, the antiderivative off with respect to x is big f of x plus c
* With this notation in hand this long s fordenoting, the antiderivative
* Now we can actually start to write downthe rules for antiderivatives, I in particular, I can write down the generalprinciple for anti differentiating a sum
* Now suppose then that the antiderivativeof little f is big F of x plus C and the antiderivative of little g is big G plusC
* Then what's an antiderivative of little fplus little g
* Well, we already saw this right?If I add together big F and big G that's an antiderivative for little f plus littleg
* So I could write down that the generalantiderivative of f plus g, is big F, plus big G, plus c.Or, I could write down this same, concept this way, that the antiderivative of fplus g, is the antiderivative of f plus the antiderivative of g.And this is really nice, right
* These are the some kinds of formulas thatwe've seen for derivatives right
* The derivative of the sum is the sum ofthe derivatives
* And as a result, the antiderivative of asum
* Is the sum of antiderivatives.So the antiderivative of a sum is the sum of the antiderivatives and this is thefirst of many antidifferentiation rules that we'll be learning.


--- SKIP ---: 02_what-is-an-antiderivative-for-x-n.en.srt


--- SKIP ---: 02_what-is-an-antiderivative-for-x-n.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-an-antiderivative-for-x-n.en_SENTbySENT.txt
* [music] You've already seen some exampleswhere we're antidifferentiating the powers of x.So here's an example
* What would I have to differentiate, right?What goes in this cloud
* So if I differentiate it I get 3 x squaredor stated differently, what's the antiderivative of 3 x squared.I've just got to think of some function because if I differentiate it I get 3 xsquared
* Well I can think of one.X cubed is an example of a function that if I differentiate x cubed I get back 3 xsquared
* What about the general case?So when I think about what would I differentiate to get x to the n.Here I'm going to suppose that x is some number but it's not negative 1.Right, so in other words I want to know what the anti derivative of x to the n is.Right, so I'm thinking what would I differentiate to get x to the n?And, I'm going to claim that it's x to the n plus 1, divided by n plus 1.Now how do I know that this is the anti-derivative of x to the n?Well all I've got to do is differentiate
* Alright, I'll differentiate x to the nplus 1 over n plus 1
* And I'll do that with the power rule andthe constant multiple rule
* This constant multiple just comes on outof this differentiation
* So I've got 1 over n plus 1 times thederivative of x to the n plus 1
* Now, what does the power rule tell me?Power rule tells me how to differentiate this.Right
* That's n plus 1, times x to the n plus 1minus 1 which is just x to the n
* But now this n plus 1 and n plus 1 cancelswhat I'm left with is just x to the n and that's exactly what I'm claiming rightthat the n type derivative of x to the n is x to the n plus 1 over n plus 1.I should be careful to point out something here.What if I wanted to anti differentiate a polynomial.For example let's suppose I want to find a function big f so that the derivative ofbig f is little f
* And maybe little f is a polynomial likemaybe little f is 15 x squared I don't know minus 4 x plus 3.All right so I'm really asking for an antiderivative of little f.I'm asking for a function whose derivative is this polynomial.We can totally do this
* So let's do this using the notation thatwe've been developing
* So I'm going to write antiderivative of 15x squared minus 4 x plus 3 dx
* And this is the antiderivative of a sum ofthe difference, and that's the sum of the difference of the antiderivative.So I can write this as the antiderivative of 15 x squared dx minus theanti-derivative of 4 x, dx plus the antiderivative of 3 dx.Now I've got the antiderivative of a number times something.So I can pull these numbers outside of the antiderivatives.So I rewrite this as 15 times the antiderivative of x squared dx minus fourtimes the antiderivative of x dx, plus, alright, the antiderivative of 3 dx.Okay
* Then I think what's the antiderivative of,of x squared
* What's just an antiderivative of xsquared
* Well, I know one.It's x to the 3rd over 3, right
* That's the power rule running in reverse.Minus 4 times, this is an antiderivative of x, something that I differentiate toget x
* Well, that's x squared over 2, right?If I differentiate x squared over 2, I get back x.And what's an antiderivative of 3
* What's something I differentiate to get 3?Well, 3x is such a thing, and to write down the most general antiderivative, I'mgoing to add plus C here
* So this is the antiderivative of thispolynomial
* And I could write this a little bit morenicely now since some of these things cancel.15 3rds is 5 x to the 3rd, minus 2 x squared, plus 3 x, plus c.Here we're using a sum rule, a power rule and also a constant multiple rule that wehaven't seen yet
* So it's worth writing down that constantmultiple rule explicitly
* Just remember what the constant multiplerule says for just differentiation
* Yeah.If I differentiate say some number a times some function big f of x, well that's justa times the derivative of big f of x
* And I can write down the same kind ofrule, but for antiderivatives
* For antiderivatives, if I'mantidifferentiating, say, a times little f of x.Well, this is the same as a times the antiderivative of f of x.Its not too difficult to justify this
* So yeah lets try to justify this constantmultiple rule for antiderivatives
* Lets suppose that f differentiates to giveme f of x
* So I'm really is supposing that big f isan antiderivative for little f
* Then this side here, I could rewrite atimes the antiderivative of f as a times big f, it's an antiderivative of f, right,plus C
* So that if I'm claiming that this, theantiderivative of a times f of x is this
* It's enough to just check that thederivative of this is really this
* And that's true, right?What's the derivative of a times F of x was exactly what I did up here, you know?These rules for antidifferentiation are exactly coming from the rules ofdifferentiation
* So the derivative of this constantmultiple times F of x is that constant multiple times the derivative of F of x,right, and I'm claiming that the derivative of F of x is little f.So this is a times little f of x
* Which is exactly saying that theantiderivative here, is this
* Which is what I'm trying to justify.


--- SKIP ---: 03_what-is-the-most-general-antiderivative-of-1-x.en.srt


--- SKIP ---: 03_what-is-the-most-general-antiderivative-of-1-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-most-general-antiderivative-of-1-x.en_SENTbySENT.txt
* [music] I must now unveil a secret whichis rarely revealed when people are first learning about antiderivatives.Consider for example the function f of x equals 1 over x.What is the general antiderivative for this function, right?What's the most general thing that differentiates to 1 over x?Well, I know what anti derivative log of the absolute value of x.And that's right
* Because the derivative of log absolutevalue x is equal to 1 over x
* So, an anti derivative of 1 over x is logof the absolute value of x
* In fact I know some other anti derivativesas well
* For example, the derivative of log of theabsolute value of x plus 17 is also equal to 1 over x, right, because the derivativeof 17 is 0
* More generally the derivative of log ofabsolute value of x plus some fixed constant is equal to 1 over x.So this is a very general anti-derivative for 1 over x.But there are many, many more anti derivatives where those came from.For example, here's another one that doesn't fit into the pattern that we'veseen thus far
* With the final function big F.And I'll define it using this, piece wise notation, right?So if x is positive the function big F will be defined to be log x plus 17, andif x is negative, the function will be defined to be log of negative x plus 20.And in fact, the derivative of this function is 1 over x, so this is anantiderivative for 1 over x
* The upshot here is that the constant couldbe different to the left and to the right of zero.So the most general anti derivative of 1 over x is a function of this form, right?Big F, log of x plus c if x is positive
* And log of negative x plus d if x isnegative, just for some constants c and d
* We can see this in a graph.Well here I've got a graph of y equals log x.And here I've got a graph of log negative x.And the point, is that I can move these two graphs up and down, independently,without affecting the derivative
* No matter how I move these graphs up anddown The derivative is always 1 over x
* I mean, if I just move this thing up anddown, it doesn't affect the slopes of the tangent lines at all.If I move this piece up and down, it doesn't affect the slopes of the tangentlines at all
* And I can move them up and downindependently
* 'Because I don't really have to line up atall, right
* I mean, since the function's not definedat zero, I don't have to worry about making them agree anywhere.I just slide them up and down Fully independently and nevertheless thederivative is always 1 over x
* One way to summarize this is as follows.So suppose that f is a function with an antiderivative big F.Then any other antiderivative for little f Has the form big F of x plus c of x.Right
* C's not a single constant anymore.C is some locally constant function
* The point is that this so called constantcould be different on different pieces of the domain.Just like in this example with 1 over x
* The constant can change on the right andthe left hand side of zero
* Here's the sad, sad truth.In spite of all of this, some textbooks nevertheless write that the most generalantiderivative of 1 over x is log of the absolute value of x plus some constant c.All of these provides a sneaky way out
* This is perfectly fine, right?So this is fine provided what
* Provided that c isn't a constant but c isa locally constant function of x.


--- SKIP ---: 04_what-are-antiderivatives-of-trigonometric-functions.en.srt


--- SKIP ---: 04_what-are-antiderivatives-of-trigonometric-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-are-antiderivatives-of-trigonometric-functions.en_SENTbySENT.txt
* [music] How do I antidifferentiate trigfunctions
* Sine and cosine are easy if we justremember their derivatives
* The derivative of sine of x, with respectto x, is cosine x
* And the derivative of negative cosine issine
* So what are their anti-derivatives?Knowing this, now I know some of the anti-derivatives.If the derivative of sine is cosine, then the anti-derivative of cosine is sine plusC
* And if the derivative of negative cosineis sine
* That means the anti-derivative of sine isnegative cosine plus c
* Well what about tangent?What would I differentiate to get tangent of x?Yeah, I'm asking what do I differentiate to get tangent or what's theanti-derivative of tangent
* I'm claiming, that the antiderivative oftangent is log secant x, plus some constant.How do I know this
* Well, to verify this is true, it's enoughto do a differentiation problem
* I need to check that the derivative of logof secant of x Is equal to tan of x
* And how do I know this?Well I have to differentiate this composition of functions.The composition of log and secant,
* Which I'll do in the chain rule, right.So what's the derivative of log
* It's one over.So it's 1 over the inside function times the derivative of secant.What's the derivative of secant
* It's secant tangent.Alright, so this is 1 over secant times secant x times tangent x.Now good news the secants cancel
* And what I'm left with is just tangent x.So I've found an antiderivative for tangent.But it's totally opaque as to how somebody would ever have gotten that as theanti-derivative of tangent
* And yet, once that candidateanti-derivative was revealed to us, we can verify that it's truly an anti-derivativejust by differentiating it and checking that it really gives us tangent.Ok, let's try another one of these kinds of problems.What's an anti-derivative of secant
* So I'm asking for a function, whosederivative is secant x
* Right?I'm looking for the antiderivative of secant x.What is that
* Well it turns out that the antiderivativeof secant x is this
* It's log, the absolute value of secant xplus tangent x
* Now again, it's totally mysterious, right,where this came from
* But we can verify that that's truly anantiderivative
* So to verify that the antiderivative ofsecant x is this, it's enough to differentiate this and end up with secantx
* So let's try that, alright?I'll differentiate log of the absolute value of secant x plus tangent x and whatdo I get
* Well, the derivative of log is 1 over theinside function, which is secant x plus tangent x.Times the derivative of the inside function.This is really the chain rule in action
* All right.Now, what's the derivative of this sum
* Well, that's the sum of derivatives,right
* So the derivative of secant is secant xtangent x
* And the derivative of, tangent.Is secant squared, and this is divided by secant x plus tangent x.Now note I can factor out a secant x here, and I've got secant x times the numeratoris tangent x plus secant x
* The denominator's the same thing.I mean I wrote it in the opposite order
* But now this is great, right?This cancels and what I'm left with is secant x.So yeah, the derivative of this is secant x and consequently the antiderivative ofsecant x is this
* This is really a key in to antimultiplying, to factoring
* If you remember our experience,multiplying and anti-multiplying, or factoring numbers, right.Factoring was hard
* I had to do a bunch of trial division tofigure out how to factor a number
* But once I had that factorization, orpurported factorization, in hand, then checking it was easy.Multiplying is something that you can do
* It's the same story here with derivatives,right
* Anti differentiating is hard, I mean itseems hard to figure out what the anti differentiating derivative is.But once you show me a guess, I can verify that your guess is correct by doing theeasy step of just differentiating and seeing if you're right.I hope that these examples are giving you some real respect for the truedifficulties of anti-differentiation
* Differentiating is a mechanical process.You just have to apply the rules carefully.But we've seen now that anti-differentiation requires flashes ofinsight, just cooking up the correct answer and then verifying that it'scorrect
* Well this seems, you know, impossible tocontinue, right
* How can we ever find anti-derivatives ifwe just have to keep hoping for insight to appear?Well the good news is that most of the rest of this course will be developingtools to make this kind of guessing more systematic right?Instead of relying on just sheer insight to solve these problems.We're going to be providing tools that will aid your insight or aid yourcreativity, or provide a little bit of structure so that you can exploit thepatterns that we're going to be seeing, and order the finite derivatives much moreeasily
* So I think it seems hard right now, butit's going to get a lot easier.


--- SKIP ---: 05_what-are-antiderivatives-of-e-x-and-natural-log.en.srt


--- SKIP ---: 05_what-are-antiderivatives-of-e-x-and-natural-log.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_what-are-antiderivatives-of-e-x-and-natural-log.en_SENTbySENT.txt
* [music] Now, we've seen how toantidifferentiate some trig functions and polynomials.Can we antidifferentiate, say, e to the x
* So, the most general antiderivative of eto the x, is just e to the x plus some constant C.How do I know that
* The derivative of e to the x is itself andconsequently the antiderivative of e to the x must also be itself and it's justplus some single constant C
* Since this is a function as to find in awhole real line, well, great, we've found an antiderivative for e to the x.What about an antiderivative for log
* So, in symbols, right, what I'm lookingfor is an antiderivative of the natural log of x, right, some function thatdifferentiates the natural log of x
* But have we ever differentiated anythingand got log as the answer
* Who knows?But it turns out that the derivative of x log x is not so far off, right?This is a derivative product, so by the Product Rule, it's the first thing timesthe derivative of the second plus the derivative of the first thing times thesecond thing, right
* So, the derivative of x times log x is 1plus log x, so not too far off
* Now, you can kind of tweak this a littlebit, right
* What's the derivative of x log x minus x?Well, that's the derivative of x log x minus the derivative of x which is 1.But I've just calculated the derivative of x log x.It's 1 plus log x and then minus 1, what I'm left with then is just log x, right?So, the derivative of x log x minus x is just log x.So, in light of that, we can summarize the situation as follows.So, yes, I mean, in, in light of this, I can say that the antiderivative of thenatural log is x times natural log of x minus x plus some constant C.All of this is just so awful
* It's just so depressing.You know, the answers are coming, but they're coming out of the void.I mean, they're just answers without any meaning or structure.We're finding these antiderivatives just by really clever guessing, you know, andit doesn't seem obvious how anyone would ever cook up these answers.I mean, if, if you're not feeling really depressed right now, you probably shouldbe
* You know, this is really bad.


--- SKIP ---: 01_what-is-the-antiderivative-of-f-mx-b.en.srt


--- SKIP ---: 01_what-is-the-antiderivative-of-f-mx-b.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-antiderivative-of-f-mx-b.en_SENTbySENT.txt
* [music] We've already seenanti-derivatives for sine and for cosine, so what's an anti-derivative for say,cosine 3x
* Right?I'm looking for some function that differentiates to cosine 3x.Well, there's basically one trick that we've been using throughout all of theseanti-differentiation problems
* It's guessing.Sine differentiates to cosine, so maybe sine of 3x is a good guess.But if I differentiate sine of 3x using the chain rule, I get the derivative ofthe outside function, that's looking good, at the inside function, that's lookinggood, too
* But times the derivative of the insidefunction which is 3
* So that's no good, but I can fix thatpretty easily, right
* If I just include a 1 3rd here, that rigsup everything perfectly, right
* Because then the 1 3rd here and the 3cancel, and I am left with cosine of 3x
* So, I can summarize this by saying that ananti-derivative for cosine 3x is 1 3rd sine 3x.And then, to get in the other anti-derivative, I just add some locallyconstant function c
* Well, that worked out.Let's try to do a slightly harder example
* Let's try to anti-differentiate say, sineof 2x plus 1
* Alright, I'm looking for some functionwhich differentiates to 2x plus 1
* I might guess that the answer will involvecosine
* Well, I know that cosine differentiates tominus sine
* So, my first guess might be cosine of 2xplus 1
* Because if I differentiate this, I getminus sine of the inside function, times the derivative of the inside function.So, this is not exactly this, so I haven't quite found an anti-derivative.But, it'll be easy to patch that up, right?If I instead look at a slightly different function.If I include a factor of minus 1 half in front of cosine of 2x plus 1, then thederivative would be minus 1 half times the derivative of cosine 2x plus 1, which isminus sine 2x plus 1 times 2
* And now, the good news is that the minus 1half, and this minus sign and this 2 cancel, and what I'm left with then isjust sine of 2x plus 1 which means I've found an anti-derivative, right?An anti-derivative for sine of 2x plus 1 is, according to this argument, negative 1half cosine 2x plus 1, plus some constant c.I can see a bit of a general principle here.Well, here's our set up
* I've got m and b, just a couple ofconstants
* And what I want to do isanti-differentiate a function evaluated at mx plus b.Alright, this is the general framework that's general enough to encompass theexamples we've done thus far, right
* F could be say, sine or cosine.In our first example, we looked at cosine of 3x, so m was 3 and b was 0.In our second example, we looked at sine of 2x plus 1, so m was 2 and b was 1 and fwas sine
* But, this is sort of a general examplethat encompasses some of the specific example which we're already taking a lookat
* Let's suppose that you already have ananti-derivative for f
* Yeah, let's suppose that I know how toanti-differentiate just f, and let's call that F, right?So, the derivative of F is f
* Now, how do I deal with the mx plus bpart
* Well basically, we're trying to guess.What I'm trying to find some function that differentiates to this, and I've got afunction that just differentiates to just f.So, let's see what happens if I differentiate F of mx plus b by using thechain rule
* Well, the derivative of F is f, evaluatedthe inside times the derivative of the inside, which is just m.Now, I can fix this if I include a factor of 1 over m here.Then, I get a factor of 1 over m here
* And that's great because then this 1 overm, and this m cancel
* So here, I've got a function whosederivative is f of mx plus b
* In other words, the anti-derivative of fof mx plus b is this, right
* It's F of mx plus b divided by m plus c.Instead of always just relying on guessing and hoping that we can guess the correctanti-derivative, we're going to be learning more and more general techniquesalong these lines
* The big one will go by the namesubstitution, or the chain rule in reverse.And as we develop more and more of these anti-differentiation techniques in ourtool box, we'll be able to anti-differentiate a whole lot morefunctions without relying on just flashes of insight.


--- SKIP ---: 02_what-is-an-antiderivative-for-e-x-2.en.srt


--- SKIP ---: 02_what-is-an-antiderivative-for-e-x-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-an-antiderivative-for-e-x-2.en_SENTbySENT.txt
* [music] Differentiating is a processreally guaranteed to work
* Alright, if somebody writes down afunction and asks you to differentiate it
* You can.It might be painful, alright, it might involve a lot of steps but it's just amatter of applying those steps carefully
* In contrast antidifferentiation might bereally hard
* Let's try a really hard example now.For instance, can you find some function so if I differentiate that function, I gete to the negative x squared
* Which is just another way of saying, Iwant to anti-differentiate e to the negative x squared.Right, what is that
* Well, let's make a guess and see if ourguess is correct
* I mean maybe, an antiderivative of e tothe negative x squared is I don't know, e to the negative x squared, over minus 2 xplus c, right
* I mean I'm not saying this is correct, butit could be true
* If this were the case, I can check it,right
* I can differentiate this side and see if Iget this
* So let's differentiate e to the minus xsquared over minus 2 x
* That's sort of the same thing asdifferentiating e to the minus x squared times minus 2 x to the negative 1st power.So that's a derivative of a product, which is assuming the product rule's good for,right
* So first I'll differentiate e to the minusx squared
* And I'll multiply that by the second termminus two x to the minus 1st power and I'll add to that the first term, e to theminus x squared times the derivative of the second term, which is minus two x tothe minus 1st power
* But what's the derivative of e to theminus x squared
* That's e to the minus x square cause thederivative of e to the is e to the
* Times the derivative of minus x squaredwhich is minus 2 x
* And then it's times negative 2 x to thenegative 1st power, right
* Plus e to the minus x squared times thederivative of minus 2 x to the minus 1st power.I'll just copy that down and we'll deal with it in a second.Because this is pretty exciting right here right.This term cancels, this term cancels, this is looking pretty good right.Maybe the antiderivative of e to the minus x squared really is this.Because when I differentiate this thing, at least I get a e to the minus x squared.The bad news is that I also get this term, right.And this terms out to be e to the minus x squared, now I gotta deal with this.It's again e to the minus x squared and then times the derivative of this.Well, when I differentiate this, I get a negative sign times this thing to thenegative 2nd power, right
* And then by the chain rule, the derivativeof the inside, which is negative 2
* And yeah, I mean this is, this is badright
* I mean I differentiated this thing righthere and I got back some of that included in the e to the minus x squared but alsoincludes non zero term
* So as result this is not the case.Well that didn't work but it wasn't from lack trying.In fact, an antiderivative for e to the negative x squared cannot be expressedusing elementary functions
* What do I mean by elementary functions?I mean things like polynomials, trig functions, e to the x, log, things likethat, right
* I mean, this is really a surprisingresult
* I mean there is a function whosederivative is e to the negative x squared, but it's not a function I can write down.Using the functions that I already have in hand.May be e to the negative x squared just an isolated terrible example.I can't answer differentiate e to the e to the x using elementary functions.I can't answer differentiate log, log x using elementary functions.I can't even answer differentiate this very reasonable looking algebraicfunction
* The square root of 1 plus x to the 4th.I can't find an anti-derivative of this just using elementary functions.So, what does this mean
* Let's try to summarize the situation.It's not just that many functions are hard to antidifferentiate.It's that many functions are impossible to antidifferentiate, not in the sense thatthey don't have an antiderivative
* But in the sense that we're not going tosucceed in writing down that antiderivative using the functions that wehave at hand
* In light of the difficulties ofantidifferentiating, the fact that there's no guaranteed answer, it means that weshould be happy that we can ever evaluate an antiderivative problem right.It also reflects the fact that some real creativity is needed.You know, if an answer's not guaranteed then potentially we're going to requiremore creativity to cook up the answers, even when they exist.


--- SKIP ---: 03_how-difficult-is-factoring-compared-to-multiplying.en.srt


--- SKIP ---: 03_how-difficult-is-factoring-compared-to-multiplying.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-difficult-is-factoring-compared-to-multiplying.en_SENTbySENT.txt
* [MUSIC] Here is an ancient saying,it is easier to destroy than to create
* Through mathematical instancesof this too like multiplying as compared to antimultiplying
* What is antimultiplying
* Normal people wouldn't talkabout antimultiplying
* They'd talk about factoring
* Here's an example
* Suppose somebody gives you a numberlike 247 to antimultiply that number, which is just my crazy way ofsaying factoring this number
* Means I want to write this assomething times something else
* And yeah, you can sort of playaround with this and try diving this by various numbers, and you'lleventually hit on 247 being 13 times 19
* Well, that seemed tohave come out of nowhere
* How did I figure that out
* Well, basically I just have tokeep trying to divide, right
* So to figure this out,maybe I'd first see is 247 divisible by 3
* Well, 3 goes into 247 82 times,but there's a remainder of 1
* So 82 time three isn't 247,I've got that pesky remainder
* Maybe I'll try five,does five go into 247
* Well clearly not, because the lastdigit's not a zero or a five, right
* How many times does fivego into this thing
* I guess 49 times, and I get 245 andthat gives me a remainder of 2
* Does seven go into 247
* That's a lot harder to seeif 7 divides this number
* 7 goes into this thing 35 times but 35 times 7 is 245 soagain there's a remainder of 2
* Does 11 go into this thing
* Does 11 go into 247
* It goes in there 22 times,but 22 times 11 is 242
* Which again leaves me with a remainder,in this case a remainder of 5
* And finally, I get to 13
* Does 13 go into 247
* Yes, 13 goes into this thing 19 times,right
* And that's exactly what I'm looking for
* But the easy way here to antimultiply, or to factor,is just to try a bunch of stuff
* And hopefully, you'll land on a product of numbersthat multiplies to your given number
* Why is factoring so difficult
* Yeah, so what we just saw isthat it was hard to factor 247
* It's hard to write this number asa product of two other numbers
* But if somebody comes up to you and asksyou to check that 19 x 13 is equal to 247, well that's super easy, right
* I can do this multiplication problem,right
* 9 times 3 is 27, 3 times 1 plus 2, 1 times 19, right, and I add
* And yeah, I mean, I get 247, right
* So it's easy to verify if I'm told theanswer that these numbers multiply to 247
* But it took some guessing, really, tofigure out that 247 factored in this way
* Well this is an example where undoingan operation is much harder than just performing that operation
* All right, here's a piece of paper
* It's very easy forme to rip the piece of paper
* It's harder forme to unrip the piece of paper
* And honestly, 247's not even that bad
* Take a look at this number, 311,512,699
* It turns out right that this number isthe product of two other whole numbers
* It turns out this is 17,551 times 17,749, but how would you ever have known that
* It would have been a realpain to do a bunch of tests to see which numbers divide this number
* And since these two numbers are prime, there's no other smaller numbersthat go into this number evenly
* So it would have been a ton of work
* And yet, if somebody tells you,do these two numbers multiplied to this, that is easy to verify, because you canjust multiply these two numbers and check that they reallygive you this number
* But undoing that multiplication,starting with this number and trying to find these two numbers,would really be a pain
* Now, in that situation, a computer couldjust search for the factorization
* But what if I gave you a numberthat was much, much bigger
* Well, here's a 240 digitnumber that I've cooked up
* I got this number by taking two primenumbers and multiplying them together
* Probably I'm the only person on Earth whoknows the factorization of that number
* I got that number by takingtwo big prime numbers and multiplying them together, but nobody elsebut me knows what those prime numbers are
* For someone else to come along and find those two factorswould be really difficult
* The cool consequence is that if I wereto reveal to you the factorization of that large number, well that would beevidence that I'm really who I say I am
* Because who else in the world knowsthe factorization of that enormous number.


--- SKIP ---: 01_knowing-my-velocity-what-is-my-position.en.srt


--- SKIP ---: 01_knowing-my-velocity-what-is-my-position.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_knowing-my-velocity-what-is-my-position.en_SENTbySENT.txt
* [music].Let's suppose that I have a formula for my velocity.For instance I made my velocity at time t is something like 3 minus 10 times t.With that equation in hand, can I then determine my position?Right
* Velocity and position are related in someway
* The derivative of my position is, welllet's, let's write that fact down
* P of t is my position at time t.V of t is my velocity at time t
* And the crucial thing here is if thederivative of my position, right
* The rate of change of my position isvelocity
* So, the derivative of p is v.So, I've written that as a derivative statement but I could also write it as anantiderivative statement
* So, I can write that p of t is anantiderivative of v of t, right
* Because p differentiates to v, theantiderivative of v is p
* Now, I want to use the fact that myvelocity at time t is 3 minus 10t
* That means in our specific case that myposition, being the antiderivative of the velocity and velocity is 3 minus 10t,right
* So, my position is the antiderivative ofmy velocity
* And we can solve that antidifferentiationproblem
* Well, here we go.Alright
* This is the antiderivative of adifference, which is the difference of antiderivatives.Now, I'd like to antidifferentiate 3, would be antiderivative of a constant suchthat constant times t
* And what's an antiderivative of 10 timest
* Well, that's 10 times an antiderivativefor t
* So, I got 3t minus 10 times.What's an antiderivative for t
* By the power rule, an antiderivative for tis t squared over 2
* And if I differentiate this, I get back t.I'm going to include a plus C here
* So I can rewrite this as 3t minus 5tsquared plus some constant C
* And now, that plus C has a perfectlyreasonable physical interpretation
* If I know my velocity, I know my positionas long as I know my initial position, as long as I know where I started, right?And that's what that plus C is encoding
* If I knew for instance that my position attimes 0 were say 4 units, then I could figure out what C would have to be right.That would tell me my position at some time t, be 3t minus 5t squared plus 4.This is an example where knowing my initial position, my position at time 0,and knowing my velocity for all time, is enough to figure out my position.In very fancy terms, this is an example of solving a differential equation.I started with the derivative information, and by antidifferentiating, I recoveredthe original function, up to a constant.


--- SKIP ---: 02_knowing-my-acceleration-what-is-my-position.en.srt


--- SKIP ---: 02_knowing-my-acceleration-what-is-my-position.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_knowing-my-acceleration-what-is-my-position.en_SENTbySENT.txt
* [music] Maybe I don't know my position andmy velocity, but I know my acceleration
* Maybe my acceleration at sometime t isjust a constant 8 units per second squared, right?So, I'm going to accelerate at a constant rate.Is that enough information to determine my velocity?We have to think back to how velocity and acceleration are related.My definition and acceleration is the change to the derivative in velocity,right
* Acceleration is rate of change invelocity
* Or in other words, right, velocity is ananti-derivative of acceleration
* So, I know that a of t is 8.Let's now solve for v
* Okay, so a of t, my acceleration, is justconstant function 8, and v of t is the anti-derivative of my acceleration, right.If I anti-differentiate acceleration, I'm going to get velocity.It means I'm anti-differentiating 8
* Well what anti-differentiates to 8 or 8t,plus some constant C
* It's that constant again.Right
* Knowing my acceleration doesn't determinemy velocity, it only determines my velocity up to some constant.I could be going really fast or really slow, but still accelerating at the samerate
* Well, in any case, I've at least got aformula for my velocity with that constant.Now, can I use that formula to determine my position?Same kind of game
* My velocity is the rate in change in myposition, right
* My velocity is the derivative of position.And that means position is an anti-derivative of velocity.So, let's anti-differentiate
* So, p of t is an anti-derivative of myvelocity, and I figured out my velocity a minute ago.My velocity is 8t plus c
* So, I want to anti-differentiate 8t plusc
* Well, it's an anti-derivative of a sum, soit's the sum of the anti-derivatives
* And what's an anti-derivative for 8 timessomething
* Well, that's a constant multiple, so it's8 times the anti-derivative of t, plus an anti-derivative for C.Now, 8 times, what's an anti-derivative for t?Well one of them is t squared over 2
* And what's an anti-derivative for C?Well, C times t is an anti-derivative for C.Then, I should add some constant here
* I'm going to call that constant big D.Right
* So, here's my position.I guess I could write this a little bit more nicely, coz the 8 and the dividing by2 simplify that I could write it as 4t squared, plus Ct, plus D.Well, that's kind of weird, right
* Why are there two constants in my answer?Just knowing that my acceleration is 8 units per second squared, doesn't tell memy initial velocity, right
* This quantity C here, is really v of 0.Right
* It's my initial velocity.And I could be accelerating at a rate of 8 units per second squared.But starting with any of a range of possible initial velocities, right?I could be going really fast at first or really slow at first.But still, always accelerating at 8 units per second squared.So, knowing this doesn't nail down C
* Similarly, just knowing my velocitydoesn't nail down my initial position
* Right?This D here is really p of 0
* Right?If I plug in t equals 0, I just get D
* And that means that D is really providingmy initial position
* So, if I know my initial position and myinitial velocity and my acceleration, then I can nail down an exact formula for myposition
* I can get rid of these mystery constants.The important lesson to take away here is that anti-differentiating can actually beuseful
* Anti-differentiating let's us take, say,velocity information and produce the position data.Or even better, in this case, it let us take acceleration information, figure outthe velocity, and then, take that velocity information to figure out my position.


--- SKIP ---: 03_what-is-the-antiderivative-of-sine-squared.en.srt


--- SKIP ---: 03_what-is-the-antiderivative-of-sine-squared.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-antiderivative-of-sine-squared.en_SENTbySENT.txt
* [music] With all that we've learned sofar, it's super easy to differentiate sine squared x, so I'm going to differentiatesine squared
* Well, it's the chain rule, right?It's the derivative of the outside function, which is the squaring function.So, it's 2 times the inside function, which is sine x, times the derivative ofthe inside, which is cosine x
* So there, that's the derivative of sinesquared x
* What if I wanted to go backwards?What if I wanted to anti-differentiate sine squared x?I want to anti-differentiate sine squared x.I'm looking for a function whose derivative is sine squared x.Well, me and my first guess for central function might be sine cubed over 3.Because if I differentiate this while I'm differentiating the outside function,which is cubing, so it's 3 times the inside function squared divided by 3, andthat's looking good
* There, I've got a sine squared x.The problem is that, now I've got to multiply this by the derivative of theinside function, which is sine, and the derivative of sine is cosine.So, the derivative of this is not sine squared x, it's sine squared x times thisextra cosine
* Oh, it seems really hard.Well, there's a so-called half angle identity.This is the trick
* That sine squared x is, according to halfangle identity, 1 minus cosine of 2x all over 2.Well, that's true
* But how does that identity help?Well, since sine squared x is 1 minus cosine 2x all over 2, that means theanti-derivative for sine squared x is equal to the anti-derivative of 1 minuscosine 2x over 2
* Now to do this, this is theanti-derivative of 1 half times something
* So, I can pull out that factor of 1 halfand just figure out how to anti-differentiate 1 minus cosine of 2x.Now, this is an anti-derivative of a difference, which is the difference ofanti-derivatives
* So, I want to anti-differentiate 1 and Iwant to anti-differentiate cosine 2x
* Now, what's an anti-derivative of 1?Well, it's just x
* And what's an anti-derivative of cosine2x
* Well, one such anti-derivative is sine of2x
* But then, I've got to divide by 2 tocompensate for the chain rule here
* It'll add plus c.So, there we go
* I could simplify this a little bit.I could write this as x over 2 minus sine 2x over 4 plus c, and there is my generalanti-derivative for sine x
* Maybe you really like this sort of thing.Well, if you are really having fun with this kind of thing, here's a littlechallenge that you can play with
* You can try to find an anti-derivativesay, for sine to the 4th, right
* And if you don't like the number 4, youcan make the 4 some other number, right
* But it's pretty fun.Then, you can try to apply some of the trig identities to replace sine to somepower with things that you can currently anti-differentiate.It's honestly pretty cool that these anti-differentiation problems are actuallydoable, that we can write down the anti-derivatives.


--- SKIP ---: 04_what-is-a-slope-field.en.srt


--- SKIP ---: 04_what-is-a-slope-field.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-is-a-slope-field.en_SENTbySENT.txt
* [music] There's a visual way to gain someinsight into these anti-differentiation problems.A visual method goes by the name of slope fields.So, what's a slope field
* The idea is that I start with somefunction
* Like, here's an example of function xsquared minus x
* But instead of just graphing the function,like I normally do here, I'm graphing the function's values.I make a graph
* But the thing that I'm graphing is littletiny line segments of that given slope, right?So, instead of plotting a value at some height, I draw little tiny line segmentswith that slope
* Now, you can see in this example that ifyou plug in 0 or 1 into this function, the output 0.And in this slope field, if you look at a point whose x value is 0 or whose x valueis 1, there I'm plotting just horizontal lines, lines of slope zero.Over here, I've got very high slope, and over here I've got very high slope.And that just reflects the fact that this function's value is very high when x isnegative and when x is positive
* And in between here, I've got just alittle tiny region where the lines are pointing down, right?Where the slope of these little line segments is negative.And of course, that's because there's a little tiny region here where thisfunction's value is negative
* Well, let's look at a specific example.With this specific example, function F of x equals x times cosine x.Now, I can draw the slope field for this example.Well, in that case, here's the slope field that I get.Imagine that I have an anti-derivative, a function f, whose derivative was F.That is, suppose I had some function, f, whose derivative was F.The slope field is drawn so that all these little line segments have slope equal tothe value of F, so I could use this slope field to try to draw a picture, the graphof my function f, right
* Let's suppose that my function maybestarts here
* And then, I could try to follow the slopefield along and try to use the information in the, in the slope field to try to drawa picture of what my function, f, must look like.So, these slope fields let you see the anti-derivative, right?If you follow the slope field, you're tracing out a function whose derivative isgiven by the slope field
* Now, we can find this anti-derivative, butwe're trying to anti-differentiate x cosine x.Well, our first guess might be x sine x
* I mean, that's a reasonable guess becausedifferentiating sine will give me the cosine and it, but what happens if Iactually differentiate this product
* Well, that's the sort of thing that I dowith the product rule which is x times the derivative, which is cosine.So, that's looking good
* But it's plus the derivative of the first,which is 1 times the second, which is sine x.So, the anti-derivative of x cosine x isn't just x sine x because I've got thispesky additional sine x term
* But I also know that the derivative ofcosine is minus sine
* So, if I add these things together, right?If I add them together, what's the derivative of x sine x plus cosine x?Well, it's these two things added together.But that's x cosine x, which is good, plus sine x minus sine x.So, it's just x cosine x
* So that means the general anti-derivativeof x cosine x is x sine x plus cosine x plus some constant c.And yeah, we can see this in the graph
* So here, I've graphed x sine x plus cosinex
* And you can see that it's really moving inthe direction of the slope field, which makes sense.Because the slope field is coming from x cosine x, which is the derivative of thisthing
* And, you know, I drew the slope field bydrawing little tiny line segments whose slope is x cosine x.So, since this thing differentiates to x cosine x, this thing is really movingalong the slope field
* The slope field picture also gives yousome insight into how the plus c really works.What is the plus c really accomplishing, right?It's moving the graph up and down
* And if you start with, you know, say xsine x plus cosine x, and then you slide that graph up and down, it's stillfollowing the slope field, right
* It's still an anti-derivative for x cosinex
* .


--- SKIP ---: 01_if-we-are-not-differentiating-what-are-we-going-to-do.en.srt


--- SKIP ---: 01_if-we-are-not-differentiating-what-are-we-going-to-do.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_if-we-are-not-differentiating-what-are-we-going-to-do.en_SENTbySENT.txt
* [MUSIC] This new content marks a sudden departurefrom what we've been doing in the course dofar
* Practically everything that we've done inthe course up til now has involved derivatives insome form
* And this is now a sudden departure fromthat topic
* Now we're going to be looking at area
* You might be thinking that this meanswe're going to be computing a bunch of areas, but itwould be more precise to say that this materialis about defining what the very idea of areaeven means
* Think way back, to when we were firstlearning about the derivative
* When we first learned about thederivative, you might have thought that we were computinginstantaneous velocity
* But it would have been better to thinkthat we were defining what the very notion ofinstantaneous velocity even means
* Right
* We needed all this machinery of limits to even think about precisely what thoseconcepts mean
* And the same is true for the material now
* Yes we're going to be computing areas, butreally we're setting up the machinery so that we can evendefine what area means
* Of course you might be wondering why isthis in this course
* Well it turns out that this really doesfit into the narrative of the course as awhole
* We just saw anti differiantion
* And the next thing after looking at area is going to be the fundamental theorem ofcalculus
* And what the fundamental theorem ofcalculus is going to do for us, it's going to relate anti differentiationand this process of, of computing area
* Unfortunately we've got to wait a littlebit longer to see that story
* And for the time being we really going tofocus on just defining what area means, we're going to review summation notion sothat we can write down these kinds of formulas
* But hang in there, the connection betweenthis material on area and all the stuff that we're doing on differentiation is going to becomecrystal clear very soon, once we get to the fundamental theorem ofcalculus
* Which it is arguably really the triumph ofthe whole course
* We've got a little bit longer to wait
* Good luck
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_how-can-i-write-sums-using-a-big-sigma.en.srt


--- SKIP ---: 01_how-can-i-write-sums-using-a-big-sigma.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-can-i-write-sums-using-a-big-sigma.en_SENTbySENT.txt
* [music] Sometimes, you'll see a Greekrestaurant with a name like this
* So, it's g, r, sigma, sigma, K restaurant.And my little rant here is that this does not say Greek restaurant.It says grssk restaurant
* That sigma is really a letter S.Right
* Sigma makes the s sound.Yeah, so grssk restaurant
* Well, this sigma makes an s sound, right?So, you know, forget this Greek restaurant story.What's another word that actually does start with s?Alright, a word that starts with s is Sum
* So, we're going to use that giant sigmafor sums
* Let's see an example.So, I'll write a big sigma for sum, and then below the sigma, I'll write what Iwant to start at
* Above the sigma, I'll right what I want toend at
* And here's what I want to add up.So, in this example, I first plug in n equals 1.Right
* And 2 times 1 minus 1 is 1.Then, I plug in n equals 2
* 2 times 2 minus 1 is 3.Then, I plug in n equals 3
* 2 times 3 minus 1 is 5.Then, I plug in n equals 4
* 2 times 4 minus 1 is 7.Then, I plug in n equals 5
* 2 times 5 minus 1 is 9.And I keep on doing this, right, until I plug in n equals 10.Which is 2 times 10 minus 1 which is 19
* So, to evaluate this sum, right, themeaning of these symbols is just to add up 1 plus 3 plus 5 plus 7, and so on, until Iget to 19
* We can compute this.Well, here we go
* Alright, 1 plus 3 is 4.4 plus 5 is 9
* Alright, 9 plus 7 is 16.16 plus 9 is 25
* 25 plus, what's the next number in thislist, is 11
* 25 plus 11 is 36.36 plus the next number that would come after 11 and this is 13.36 plus 13 is 49
* 49 plus, the next number is 15.49 plus 15 is 64
* 64 plus 17 is the next number, rightbefore 19
* 64 plus 17 is 81.And 81 plus 19 is 100
* So, yeah.If I add up 1 plus 3 plus 5 plus 7 plus 9 all the way up 19, by just adding up theodd numbers between 1 and 19, I get 100 and that's the value of this sum.If you have some programming experience, you can think of these sums as like loops.Formally, what does this notation mean, right?So, I put a big summation symbol, a big sigma.N goes from a to b, a and b are whole numbers.And then, I've got some expression involving n which I can write as afunction of n
* And what this notation means is just toplug in all the numbers between a and b, the whole numbers between a and bincluding a and b, into this expression, and then sum them all up.Right
* Giant sigma for sum.You know, so if I wanted to expand this out, if I want to right out what this isdoing, you know, I first plug in a, then I plug in a plus 1, then I add to that a,whatever I get when I plug in a plus 2, and then dot, dot, dot, I keep on going,right
* And then, I get closer to the n.Right before the n, I plug in b minus 1
* And then, I finish by plugging in b and Iadd up all these things and that's the value of this sum.Alright that's what this notation means
* There's one easy case where we can figureout the whole story
* What happens if we take the sum of just aconstant
* Some expression that doesn't depend on theindexing variable at all
* For instance, what is the sum, as n goesfrom a to b, of just the constant C, right?This is you know, sort of expression that doesn't involve n at all.So, to compute this, all we have to know is how many times C is being added intoitself
* Right, so this is C plus C plus, and itkeeps on going, you know, plus C
* But the whole issue is just how many timesC appears
* And C appears b minus a plus 1 times.That, that plus 1 maybe is a little bit confusing.But you can see that the plus 1 really belongs there, if you plug in somespecific values for, for b and a
* So, if I add C to itself, b minus a plus 1times, this sum is really just a multiplication problem, right.Repeated addition is called multiplication.It's C times b minus a plus 1
* So, the sum of C as n goes from a to b isjust C times b minus a plus 1.


--- SKIP ---: 02_what-is-the-sum-1-2-k.en.srt


--- SKIP ---: 02_what-is-the-sum-1-2-k.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-sum-1-2-k.en_SENTbySENT.txt
* Let's do another summation problem.The summation problem that I want to do, is the sum as n goes from 1 to a somenumber k of just n
* Alright?In other words, I want to add up 1 plus 2 plus 3 dot, dot, dot plus k, right.I want to add up the first k whole numbers.These are called triangular numbers
* The reason is because performing this sumis really counting the dots in a triangle
* Let me draw a picture.So, 1 dot, 2 dots Three dots, four dots, five dots.All right
* And then I'll keep on going until I get toK dots
* You know, and this picture here is atriangle
* Right?So this sum is counting the number of dots in a triangle.Having that k there makes this a very general problem, and anytime that you'reconfronted with a general problem, it helps to specialize to a specific case.In order to gain some insight
* So let's set k equal to 10.So I'm just going to do the sum n goes from 1 to k which is now 10 of n.Which means I'm going to add 1 plus 2 plus 3 plus 4 plus 5 plus 6 plus 7 plus 8 plus9 plus 10
* I could actually draw this as a triangle.Put down 1 dot, 2 dots, 3 dots, 4 dots, 5 dots, 6 dots, 7 dots, 8 dots, 9 dots, 10dots
* [laugh] So I've got this triangle, andthis sum is just the number of dots in this triangle.Now I just count those dots
* I just add those numbers up.1 plus 2 is 3, 3 plus 3 is 6, 6 plus 4 is 10, 10 plus 5 is 15, 15 plus 6 is 21, 21plus 7 is 28, 28 plus 8 is 36, 36 plus 9 is 45, and 45 plus 10.Is 55
* So the sum of the first 10 whole numbersis 55, and I drew 55 dots to make this triangle.But there's another approach
* Instead of just adding 1 plus 2 plus 3plus 4 plus 5 plus 6 plus 7 plus 8 plus 9 plus 10, I could add these in a differentorder
* I could add 1 and 10 together to make 11.2 and 9 together to make 11
* 3 and 8 together to make 11.4 and 7 together to make 11 , and I'm left with 5 and 6 and those two together make11, right
* So I've got five groups of 11, which meansif I add up all these numbers I get 55
* Armed with this trick I can do the samething to attack the problem in general
* So in general, I'm trying to do the sum, ngoes from 1 to k of just n
* Trying to add up the first k wholenumbers
* And if I write this in a different order,and let's say k is even, just to make this a little bit easier to think about.Alright I'll take the first number and the last number, and add those together.The second number and the second-to-last number and add those together.The third number and the third-to-last number, and add those together.And I'm going to keep on going, right
* And the first number and the last numberis, you know, I'm writing it as 1 plus K, that's fine.The second number and the second-to-last number, well that's also 1 plus K.All right, the third number and the third-to-last that's also 1 plus K.Right
* All of these things add up to 1 plus K.And the key question is just how many things I've got.All right
* And I'm pairing them off in twos.So, let's say this is an even number
* K is an even number.And I've got K over 2 pairs
* All of which add up to K plus 1.And that's just a multiplication problem
* Right?That means that this sum is 1 plus k times k over 2.So that's the sum of the first k whole numbers.If all this algebra doesn't really speak to you.We can redo this geometrically
* So what I want to calculate, right, isthis sum
* The sum as n goes from 1 to k of n.And geometrically, right, I can draw this pattern of dots, right?1 plus 2 plus 3 plus 4 plus 5 plus 6 in this case.But I could imagine that, you know, this is a specific picture that represents thegeneral case, right
* I've got this triangle, a k by k triangleof dots
* And this sum is just counting the numberof dots
* Right?1 plus 2 plus 3, that's exactly what the sum does.Now I'm going to count these dots
* So I'll make two copies of this picture.So now I've got two copies of this sum
* Right?There's another k by k triangle of dots
* And to count these dots I'm going to takethis triangle, rotate it, and slide it over here.So as to make not a k by k square, but this is a k plus 1 by k rectangle,alright
* As the bottom of this one just fits in,but it's a little bit wider
* I got this k plus 1 by k rectangle ofdots
* So I know there's k plus 1 times k dotsand this is two copies of the sum that I'm interested in.So 2 times the sum I'm interested in is k plus 1 times k, the number of dots in thisrectangle
* And consequently if I just divide by 2 Iget the formula that I'm interested in
* The sum of n, n goes from 1 to k is k plus1 times k over 2, right
* It's half of the number of dots in this kplus 1 by k rectangle
* A big part of the joy of mathematics isthat the same ideas can be presented with very different clothing.In this case, we're seeing really the same argument.But presented both algebraically and geometrically.


--- SKIP ---: 03_what-is-the-sum-of-the-first-k-odd-numbers.en.srt


--- SKIP ---: 03_what-is-the-sum-of-the-first-k-odd-numbers.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-sum-of-the-first-k-odd-numbers.en_SENTbySENT.txt
* [music] Since I know about triangularnumbers and I know how to sum constants, I can combine those two facts to some morecomplicated expressions
* For example, let's do the sum as n goesfrom 1 to k of 2n minus 1
* All right?And what this notation mean is that I plug in these numbers from 1 to k into thisexpression and add them up
* So, I plug in n equals 1, I get 1.I plug in n equals 2, I get 3
* I plug in n equals 3, I get 5.I plug in n equals 4, I get 7
* All right.And I'm going to keep going until I end with 2k minus 1.In words, right, what is this asking me to do?Well, 1, 3, 5, this is adding up odd numbers, right?So, I could say in words that this is the sum of the first k odd numbers.Right
* I'm going to add up the first k oddnumbers, 1 plus 3 plus 5, until I get to the k 5 number, which is 2k minus 1.Let's first work this out algebraically
* So, algebraically, I've got the sum of 2nminus 1 as n goes from 1 to K
* And this is summing this difference, so Icould write this as the difference of two sums.So, both of these are sums as n goes from 1 to k, but now I'm adding up 2n, I'm justadding up 1
* Now, I can pull out this factor of 2 bydistributivity
* So, this is 2 times the sum of n as n goesfrom 1 to k, minus just the sum of 1
* N goes from 1 to k.I have a bit of a formula for the sum of just the first k whole numbers, right.And if you remember back to that formula that's k plus 1 times k over 2.And what's just the sum of 1 as n goes from 1 to k?Well, this is 1 plus 1 plus 1 plus 1 k times.That's just minus k
* Now, this is 2 times something divided by2, so this is k plus 1 times k and then, minus k.Well, if I expand this out, I've got k plus 1 times k minus 1 times k.This is k squared
* So, the sum of the first k odd numbers isk squared
* But I can also see this fact that the sumof odd numbers gives me perfect squares
* I can see this fact geometrically.So, I'll draw, say one dot, and then I'll draw three more dots.All right
* This is 1 plus 3, it's 2 squared.Then, I'll draw five more dots
* 1 plus 3 plus 5, that's 3 squared.Then, I'll draw seven more dots
* All right, and that's 1 plus 3 plus 5 plus7, that's 4 squared
* And then, I'll draw nine dots, one, two,three, four, five, six, seven, eight, nine.And that's five squared
* 1 plus 3 plus 5 plus 7 plus 9 is 5squared, 25
* And I'll add 11 dots, one, two, three,four, five, six, seven, eight, nine, ten, 11.And 1 plus 3 plus 5 plus 7 plus 9 plus 11, right?The sum of the first 1, 2, 3, 4, 5, 6 odd numbers is 1, 2, 3, 4, 5, 6 squared, it's36
* So, the upshot here is that if you sum oddnumbers, you end up getting perfect squares.And, and that's cool independent of everything else right, you can see thatfact geometrically
* But the real take away here is to rememberyou can actually do summation problems, right?If somebody gives you a complicated sum, by using facts like the sum of just n, andthe sum of constants, you can combine those facts to evaluate more complicatedsummation problems.


--- SKIP ---: 04_what-is-the-sum-of-the-first-k-perfect-squares.en.srt


--- SKIP ---: 04_what-is-the-sum-of-the-first-k-perfect-squares.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-is-the-sum-of-the-first-k-perfect-squares.en_SENTbySENT.txt
* [music] What do we get if we add up abunch of perfect squares
* Say, the first k perfect squares.What I'm asking for is a formula for this sum.The sum of n squared as n goes from 1 to k, right?So 1 squared, plus 2 squared, plus 3 squared, plus dot, dot, dot, right?And so on, until I get to k squared
* What do I get if I add up the first k?Perfect squares
* Quite shockingly, the resulting formulaends up looking really nice
* This ends up being equal to k times k plus1 times 2 k plus 1 All over 6
* Really?Well, we can try it for some specific value.All right
* What if I do the sum and go from 1 to 4 ofN squared
* That's 1 squared plus 2 squared plus 3squared plus 4 squared
* That's 1 plus 4 plus 9 plus 16.4 and 16 make 20
* 1 and 9 make 10.20 plus 10 is 30
* So the sum of the first four perfectsquares is 30
* Is that really what this formula's giving?Well let's check it out
* So I'm going to put in 4 for K, 4 times 4plus 1
* Times 2 times 4 plus1 all over 6.What's that
* Well that's 4 times 5 times 2 times 4 plus1 is 9 divided by 6
* 6 is 2 times 3, so the 2 kills part of the4 and part of the 9 to give me 2 times 5 times 3.And yeah, I mean, 5 times 3 is 15, twice 15 is 30.It really works, at least for the value 4
* Of course, this isn't a proof in general.So how am I going to verify that, that statement is true?Well, one argument is a geometric argument, really a proof by picture.So here's a geometric or a diagrammatic way of writing down 1 squared plus 2squared plus 3 squared plus 4 squared
* Now I know there's 30 dots here, right.But I'm trying to draw a diagram that suggests a general pattern.Ok
* So let's try to add up.These, these four numbers
* I'm going to use this device here.What is this
* Well, what I've done here is I've taken 3copies of these k squares, alright
* So here's 1 square plus 2 square plus 3squares plus 4 squares
* Here's another 1 squared plus 2 squaredplus 3 squared plus 4 squared, and in the middle I sort of mixed it up a little bit.I've taken the lower lefthand corner dot, which is red, and I've lined them upvertically here
* I've taken the next, sort of three long Lshape which I've drawn in blue here, and I've straightened them out and placedthose three here
* I've taken the two five long orange L'sand straightened them out here, and then here at the top I've got one long brown Lcomprised of seven dots, and I've straightened that out right here at thetop
* So what's happened here?Right, I have taken three copies of my sums of squares, right so I've got threecopies of all these squares
* One set is down here, one sets down here,and the other set is mixed in the middle
* And now I can figure out how big arectangle this is 
* Well the bottom here this is a k by ksquare, k by k square and these are built out of the corners that are just 1 dot.So there's a whole bottom side is made up of 2 K plus 1 dots, k plus 1 plus k or 2 kplus 1
* What about along the other side?Well along the other side, I've got one dot plus two dots plus three dots plusfour dots and of course, this is just a specific picture.So in general, it will be 1 plus 2 plus 3 plus 4 until I get to k.So I have to figure out how tall this rectangle is, but I in fact know a formulafor 1 plus 2 plus 3 plus 4 up through k, alright.We figured that out already
* It's k times k plus 1 over 2.So I've taken three copies and built them into a rectangle who's base is 2k plus 1,and which is k times k plus 1 over 2 tall
* So that means that this sum, which is whatI'm trying to compute, must be
* Well its the, the height of this rectangletimes the width of this rectangle divided by 3, since I used three copies of, ofthese squares to build the big rectangle
* So I ended up dividing by 3.And this is in fact the formula that we had, right?The original formula was K times K times 2 K plus 1 times 2 K plus 1 all over 6.But that's just a rearranged version of this formula.There are other geometric arguments as well.Other proofs by picture that you could give.And there are other geometric arguments too.Here's another way to get at this sum of squares formula.I could right down my sum of squares as something built out of little tinycubelets
* Right?Here I've got one cube
* Underneath I've got 2 squared cubes right,but this is a 2 by 2 by 1 block
* Underneath I've got nine little cubes,right
* It's a 3 by 3 by 1 block.And underneath that I've got 16 cubes, a 4 by 4 by 1 block, right.And I can imagine that this thing is k high.I take six copies of this pyramid
* You know, fit them together.Flip one over and so forth
* Until I end up with a K by K plus 1 by 2Kplus 1 box
* Right?And that box must be comprise of K times K plus 1 times 2K plus 1 little tiny cubes.And since I used six copies of this thing
* Well that means the number of cubes inthis thing
* Which is the sum of 1 squared plus 2squared plus until I get to k squared
* Right?That sum must be k times k plus 1 time 2k plus 1 divided by 6.And here, we've given geometric arguments for this particular sum.But in the future we're also going to see some algebraic arguments.Right
* But we're going to wait on those a littlebit
* For the time being, this particularquality will be very helpful when we start doing some calculations of, Riemann sum.


--- SKIP ---: 05_what-is-the-sum-of-the-first-k-perfect-cubes.en.srt


--- SKIP ---: 05_what-is-the-sum-of-the-first-k-perfect-cubes.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_what-is-the-sum-of-the-first-k-perfect-cubes.en_SENTbySENT.txt
* [music] What do I get if I take one cubedplus two cubed plus three cubed plus so on plus K cubed?This is a truly remarkable fact it's called Nicomachus' Theorem, and it saysthat the sum of the first K perfect cubes is the square of just the sum of the firstK whole numbers, and it's literally a remarkable fact that these two things are,are equal, right
* I mean, you know, it just doesn't looklike this should be true at all, but it is.Now, once you believe something like this you could rewrite this sum of cubesformula in maybe a slightly easier way
* Right, once you've got the sum of cubes isthe square of just the sum of the first k whole numbers, while we already know aformula for some of the first k whole numbers.It's k times k plus 1 over 2, and I'm just squaring that.So now here is a formula for the sum of the first k perfect cubes.It's k squared times k plus 1 squared over 4.Right
* I just took this formula and squared it.Again there's a slick geometric proof of this fact.So let's add 1 cubed plus 2 cubed plus 3 cubed plus 4 cubed pictorially, of coursethe same arguments going to work in general, if I add up the first k perfectcubes
* Alright, well here's 1 cubed.Alright
* Here's 2 cubed.It's 8 dots, but I've arranged them in a, in a cube.Here's 3 cubed, all right
* It's 3 times 3 times 3, 27 dots, but I'vearranged them again in, in a cube shape
* And then 4 cubed would be 64 dots, but Ihaven't drawn all the dots in, right
* So I want to count all of these dots, andthe trick is to rearrange these dots
* So that's how most of these sort ofpictorial arguments end up going
* So I'm going to rearrange these dots like,like this
* So here I've made a square, and here's the1 cube, I added just, just 1 dot
* Here's the 2 cube, but I've rearranged itwhere 1 of the layers of the 2 by 2 by 2 cube is right here, and I've split theother layer in half
* So if I take this vertical 2 by 1 pieceand this horizontal 1 by 2 piece, I can rearrange them to make it 2 by 2 squarethat I stack on top of that one, which then gives me this again.Here's the 3 by 3 by 3 cube, it's 3, 3 by 3 squares.Here's the 4 by 4 by 4 cube
* It's 4 squares, but that top square isbeen cut in half
* Right, so this piece here, and this piecehere, would combine to give me another 4 by 4 square, which I can stack on top ofthese three to recover the 4 by 4 by 4 cube.Now I could put five 5 by 5 squares around, and then around that I could putsix 6 by 6 squares, but I'd cut one of those squares in half just like this.So the even layers I use square that's been cut in half, and the odd layers, Ican just stack them down
* The, the point here is that I end upproducing a square whose side length is 1 plus 2 plus 3 plus 4.You know, and of course this is being general.Alright, it would be plus k
* So this is 1 plus 2 plus 3 plus 4.I've rearranged the sum of cubes into a square, and that side length of thatsquare is the sum of the first k whole numbers.Good news now is that I've got a formula for the sum of the first k whole numbers.It's k times k plus 1 over 2
* So the resulting square has side length ktimes k plus 1 over 2, which then means that if I take the sum of the first Kcubes it's that number squared
* These kinds of formulas enable us toperform calculations that would be extraordinarily painful without access tothese formulas
* For instance, what if I wanted to add upthe first 100 perfect cubes, right
* That's the same thing as computing thesum, n goes from 1 to 100, of n cubed
* Now, because I've got a formula for this,because this is, the same as, just the sum of The first hundred whole numberssquared, right
* I know how to compute this, right?What's the sum of the first hundred whole numbers, well that's 100 times 101 over 2,and I just have to square that
* What's a 100 times 101 over 2?What's the sum of the first hundred numbers?It's 5,050 and I just have to square this
* And if I square this I get 2, 5, 5, 0, 2,5, 0, 0
* All right?So I get about 25 million, and this makes possible, you know, this calculation thatwould have been horrible tedious, right
* But because I've got access to thisformula, I can perform really amazing numeric feats, right?This would be horrible to calculate, but with this formula, I can just write downthe answer
* If you like these kinds of formulas,here's a challenge
* Here's the challenge.What's the sum of fourth powers
* The answer's going to be some polynomialin K, right, but you've gotta figure out which polynomial that is.One trick would be to plug in values
* Say K equals one, K equals two, K equalsthree
* And then try to find the polynomial thatpasses through those points
* Now that's your challenge.And there's a long tradition here
* Bernoulli for instance computed the sum ofthe first thousand tenths powers, and he did it 300 years ago.People have been thinking about these kinds of formulas for a really long time.


--- SKIP ---: 01_what-does-area-even-mean.en.srt


--- SKIP ---: 01_what-does-area-even-mean.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-does-area-even-mean.en_SENTbySENT.txt
* [music] We know what the area of arectangle is
* Well, if you've got a rectangle, say, ofwidth a and height b, what should the area of this rectangle be?The area of this rectangle is a times b
* So what's the area of a triangle?Well, if we've got a, triangle say of height b and width a, right.The area of this triangle is 1 half ab
* But why?Why is that the area of a triangle
* Well this is really what the area of thetriangle has to be in order to be consistent with the area of the wholerectangle
* I mean, look, I could take two of thesetriangles
* Right here's two triangles, both havewidth a and height b
* But if I push those 2 triangles together,then I've got the a by b rectangle
* So the area of these 2 triangles togetherhas to be the area of the rectangle a times b.But each of these triangles has half the area of the rectangle.So the area of just the triangle should be half the area of the rectangle.Another way to say this is just that, you know, areas sort of add.You know, area of some figure plus area of some other figure.Is equal to the area of those two things together.Right
* In this particular case, the area of thistriangle plus the area of this triangle, is the area of these two things together,which is the area of a rectangle
* You can play this kind of game to relatethe areas of different figures that supposedly have the same area.For example, I could start with a rectangle of width 2 and height 1.Or, I could start with a square whose side length is the square root of 2.Now, both of these figures have the same area, right?The area in both of these figures is 2
* And you might ask, well, you know, if thewhole deal with areas is just so that they sort of cut up and add appropriately.Is it possible for me to cut up this figure in order to get this figure?And, and yeah, it is in fact possible
* Right?If I cut along the diagonals here, these 4 pieces can be rearranged into these 4pieces here
* So, and very visibly, right, if youbelieve that, you know, sort of areas add in this way that I'm allowed to rearrangepieces
* Then you might believe that these 2 thingshave the same area, regardless of whether you do the calculation or not, right?These 2 pieces have the same area because I can take this thing and cut it up andget this thing
* Well here's a challenge for you rightalong these lines
* For instance can you take a 3x1 rectangle,and a square of side length root 3
* And visibly show that these things havethe same area
* I mean yes.The calculation, right, is telling me that they both have the same area of 3, 1 times3 is the same as the square root of 3 times the square root of 3.But what I'm looking for is some sort of geometric proof where you cut up thisthing and rearrange those pieces to build this thing, right.That's your challenge
* So this is really fascinating, right.What is area
* Area is a number, but that number capturesthis geometric idea that if two things have the same number, the same area, thenyou can take the one thing and chop it up into pieces to get the other thing.And yet that perspective is totally destroyed as soon as we start thinkingabout something with a curved boundary, like a circle.So here's a unit circle by which I mean the radius has length 1 unit.In the area of the unit circle is pi square units.I mean yes we know what the formula for the area of a circle says right, it saysthat the area of that unit circle Is pi square units.But what does that mean
* What does it mean to say the circle's areais pi square units
* Well I'll tell you what it doesn't mean.It doesn't mean that I can start with a rectangle of area pi square units.So say a rectangle of height 1
* And with pi, right?To say that the area of this circle is equal to pi does not mean that if I juststart with a rectangle with that same area, that I can necessarily make somefinite number of cuts to this rectangle
* And take those pieces and rearrange themto form this disc
* All right.There's really two competing concepts here.You've already got an idea of area, you know?Because you've seen area before
* And this idea of area is really based onthis idea that two things have the same area if you can cut the one thing up andrearrange the pieces to make the other thing.But as soon as you're dealing with objects with curved boundaries, say, you'vesuddenly got a problem, because it's not going to be possible for you to take thisobject and just chop it up and produce this nice smoothly curved object.So, somehow you've gotta refine what area even means.When I say that the area of a circle is pi square units, I'm secretly speaking in thelanguage of limits
* So, when I say that this circle has areapi, I mean that if I say cut it up into small enough little rectangles.The area of these rectangles, which actually makes sense, because I know howto calculate the areas of rectangles, by multiplying their widths times theirheights
* So, if I add up the areas of theserectangles, I get an answer that's as close as I'd like to the number pi.And I can get the answer as close as I want, provided I make these rectanglesthin enough
* And it's only in that sense that it, iteven means anything to say, that the area of the circle is pi.It's in the sense of that limit
* So even defining area requires talkingabout limits, which I think is remarkable
* I mean we learn about area in elementaryschool, right
* We never talk about limits in elementaryschool
* And yet somehow there's a real depth, areal subtlety to even this concept of area, you know?And I think that's really exciting
* Right?It suggests that there's something interesting yet to be learned even aboutconcepts that we think we understand really well.


--- SKIP ---: 01_how-can-i-approximate-the-area-of-a-curved-region.en.srt


--- SKIP ---: 01_how-can-i-approximate-the-area-of-a-curved-region.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-can-i-approximate-the-area-of-a-curved-region.en_SENTbySENT.txt
* [music] I want to be able to compute areasof curved regions
* For instance, here I've got the graph of yequals x squared
* And between 0 and 4, I could ask for somecalculation
* Some approximation, at least, of the areaabove the x axis and below the graph of y equals x squared, right.I want to approximate this area in here
* Practically, the only thing that Iactually know the area of is rectangles
* So, I'm going to replace this curvedregion with an approximation by rectangles.The first step is to take that interval, 0 to 4, and cut it up into some smallerpieces
* I'll partition the interval from 0 to 4into few pieces
* I'll cut it into 3 pieces.Let's cut it into a piece from 0 to 2 and piece from 2 to 3.And then, one more piece from 3 to 4
* So, I've partitioned the interval from 0to 4 into some pieces
* 0 to 2, 2 to 3, 3 to 4.Now, I'll pick some points inside each of those sub intervals, points where I'mgoing to end up sampling the function
* So, in this first interval, I'll pick thepoint 1
* In this second interval from 2 to 3, I'llpick the point 2
* And in the third interval from 3 to 4,I'll pick the point 3.5
* Right?So, I'm picking some sample points in each of the pieces of my partition.Now, I'll build a skyscraper picture
* A, a bunch of rectangles that approximatesmy curved region
* So, I'll sample my function at thesesample points
* And I'm going to draw this sort ofskyscraper picture
* So, I'm going to draw a box over the firstinterval of height, whatever the sample was.So, there is the height is given by the function's value at the sample point.In my second interval from 2 to 3, I sampled the 2.And I'll draw a little rectangle there
* And in my third interval from 3 to 4, Isampled at 3.5
* And then, I'll draw one more rectangleright there
* So now, my three sub intervals gave riseto three rectangles
* Now, what's the area of those rectangles?Well, this first rectangle has a height of 1 square and a width of 2.So, this first wide, but not very tall rectangle, has area 2.This rectangle here has a height of 2 squared and a width of 1.So, this rectangle has area 4
* And this last rectangle has a height of3.5 squared and a width of 1
* So, it has area 3.5 squared, which is12.25 square units
* And now, if I add 2 plus 4 plus 12.25, Iget then an area of 18.25
* And that's suppose to be an approximationto the area of the curved region
* Right, I replaced this curved region bythese three rectangles
* And I can calculate the areas of thesethree rectangles
* It's going to be about 18.25 and thatshould be not so far off from the true area of this curved region.So, that's an approximation, but we can do better.If we want a better approximation to the area under this curve, I'll just cut theinterval between 0 and 4 up into smaller pieces.I could, in this case, consistently choose the left end point to sample that and Ican draw a whole bunch of rectangles now
* And I could approximate the area under thecurve just by calculating the area of these rectangles.And by taking more and more rectangles thinner and thinner, I'll get anincreasing good approximation to the true area under this curve.I can also over estimate the curved region's area.I could also try to over estimate this
* I could cut this interval from 0 to 4 intoa bunch of small intervals
* And then, choose the right end point ofeach of each of these intervals to do my sampling at.And then, build the sort of skyscraper picture.Again, sampling at the right hand end point of each of my little tiny subintervals and I can build this little skyscraper picture.And by computing the area of the rectangles.Alright, the areas of these rectangles are a pretty good over-approximation to thearea under the curve
* I'm going to give a name to all thesekinds of approximations
* The name that were given to these thingsis a Riemann Sum, right
* Riemann was a mathematician.So, what's the procedure for setting up a Riemann Sum?Well it's really a multi-step process, right?Here's a picture that sort of summarizes the whole story.I'm trying to calculate the area under the curve between the points a and b and I'mdoing that approximation by approximating the curved area with these rectangles.And I can, of course, calculate the areas of these rectangles and add them up.But what's the first step
* Well, the first step is to partition thisinterval a to b, so that I can decide where to build my little skyscrapers.Alright, so the first step here is to partition the interval a to be and whatthat involves is choosing x not, which is just a.And x sub n which is b
* And then, choosing x1, x2, and so forth inbetween a and b, alright?
* In this picture, I've chosen x1, x2, x3,x4 And I've cut it up into one, two, three, four, five pieces.But, of course, you can choose how many pieces to cut it up into.The point is just to choose how many pieces to cut it up into, and then, choosewhere you're going to make those, those cuts in the partition.The next step is to choose sample points inside each of those sub intervals.Yeah, after I've decided where to cut up my interval a to b, I've chosen the xsub-I's
* Then, I introduce these blue samplepoints, right, the x sub i stars
* So, the next step is to choose samplepoints x sub i star, and those sample points will then be used to determine theheights of these rectangles
* I'm going to be evaluating the function atthose sample points
* Now, I can write down a formula for thearea
* Well the area is approximately the areasof all these rectangles added up
* Now, how big are each of these rectangles?The heights of these rectangles are coming from the function evaluated at thesesample points and the width has to do with how far apart the red cut points are.So, we can write down a, a formula for that, right?I'm going to write down a formula for the area.So, the area is approximately, and this is really Riemann Sum, right?It's the sum, i goes from 1 to n
* So, I'm going to add up all of therectangles
* And now, I've got to write down the areaof the I for rectangle or the height of the I for rectangle, is the functionevaluated at the sample point
* And the width of the ith for rectangle isx sub i minus x sub i minus 1
* Right?If I take the i cut point and subtract the previous cut point, the difference therewill tell me the width of that rectangle
* Let me show you on the picture again here.Alright
* So, the height of these rectangles arecoming from evaluating the function at the sample points and the width of, say, the1th rectangle, the first rectangle, is x sub 1 minus x sub 0.That's the width times height, that gives me the area.And if I add up the areas of all of the green rectangles, then I get anapproximation for the total area under the curve.And just to make it easy to talk about these things, there's some specific namesthat I want to give to particular kinds of Riemann Sums.For instance, if we pick our ith sample point, so x sub i star, to be the lefthand endpoint, x sub i minus 1
* Then, I can write down my Riemann Sum likethis
* It's the sum over all the rectangles of fevaluated at the left hand end point, that's sample point, times the width ofthat particular rectangle
* This is called a left Riemann Sum, justbecause I've chosen my sample points to be in the left hand side of the interval.Similarly, right
* There's a right Riemann Sum where I choosemy sample point to be on the right hand side, right?So, this would normally be x sub i star, but my sample point is my right handendpoint
* So, it's just x sub i.I'm going to call this thing a right Riemann Sum.


--- SKIP ---: 02_what-is-the-definition-of-the-integral-of-f-x-from-x-a-to-b.en.srt


--- SKIP ---: 02_what-is-the-definition-of-the-integral-of-f-x-from-x-a-to-b.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-definition-of-the-integral-of-f-x-from-x-a-to-b.en_SENTbySENT.txt
* [music] We've already got an idea of howwe can approximate the area of a curved region by replacing that curved regionwith rectangles
* We've already done this.If I want to approximate the area under the curve, I'll just add up the areas ofthese rectangles
* And that's a pretty cut approximation ofif these rectangles are thin enough
* If I make those rectangles thinner andthinner, that gives me better and better approximations to the area under thecurve
* In fact, more than just approximating thearea under the curve
* By making those rectangles thinner andthinner, I can write down a definition of the area under the curve.So by taking those triangles to be thinner and thinner.I'm going to get a better and better approximation to the area under thiscurve
* And I'm going to denote that limit bythis, the integral, which is this long, thin s, from a to b of the function dx,right
* That's how I'm going to write down thearea Under the graph of this function, above the x-axis, and between the line yequals a and y equals b
* It's going to be by this notation.Here is the precise definition of the integral.To precisely, the integral of this function from a to b is a limit overpartitions of the Riemann sum, alright
* And it's a limit over partitions whereI've also chosen some sample points for those partitions.And I'm taking the limit as a maximum width of a sub-interval in that partitiongoes to 0
* In order to ensure that all of the widthsof the sub-intervals are going to 0, I just demand that the maximum one, thebiggest one goes to 0, and that forces all the other ones to be small as well.I had to say that the maximum width goes to 0 to prevent some sort of bizarrescenario
* Well I've got one really big sub-intervaland then lots and lots of small sub-intervals right?I want to make sure that all of those sub-intervals are getting very narrow sothat I'm getting a very fine partition in the limit.There's no guarantee whatsoever that, that limit actually exists.On the other hand, here's a theorem
* If a function f is continuous then it'sintegrable, meaning that the integral, right, the integral of the function fromsay a to b actually exists
* So when I say integraable, what do I evenmean by integrable
* If I were to claim that the integral of ffrom a to b is equal to some number, big I, what that means is that no matter how Ipartition the interval from a to b, as long as that partition is fine enough.Alright, as long as the maximum width of any rectangle in my skyscraper picture issmall enough, right, as long as the widest one Is thin enough.Then no matter how I choose those sample points within each of the sub-intervals inmy partition, the resulting Reimann sum that I calculate is close to I.How close
* Well it's as close as I want it to be.Right
* To say that this is equal to something isreally to say something about a limit
* So that means that if I'm asserting thatthis is equal to I, it means that I can get the Reimann sum as close as I want toI by simply demanding that my partition is fine enough.Regardless of how I exactly choose those sample points.And all this talk about Reimann sums is reflected in the very notation in thatwe've chosen for the integral
* So here, I've got the integral, theintegral of f from a to b
* And here, I've got a Riemann sum, right,and this integral is defined to be a limit of these Reimann sums.And the notation really reflects their common origin, right?Here, I've got a summation symbol, a Greek sigma, Greek letter s.And here, I've got a long s
* Alright, these are both a kind of sum.And the thing I'm summing is the function evaluated somewhere times a change in x.And the thing I'm summing here is the same thing it's the function evaluatedsomewhere times a change in x
* So I hope that even the way I write downintegrals really reminds you that there are a limit of things that look like thisright
* The function evaluated somewhere timessome change in x being added up.


--- SKIP ---: 01_what-is-the-integral-of-x-2-from-x-0-to-1.en.srt


--- SKIP ---: 01_what-is-the-integral-of-x-2-from-x-0-to-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-integral-of-x-2-from-x-0-to-1.en_SENTbySENT.txt
* [music] Let's integrate x squared from 0to 1 by using the definition of integral
* Now, since the function x squared iscontinuous, it's integrable
* So, it won't matter exactly how we chooseour partition or how we choose our sample points as long as the partition is fineenough
* So, I'm going to choose a partition inwhich each of the subintervals has the same width, 1 over n.I'm going to divide the interval into n pieces each with the same size.Now, I've got to figure out exactly where those cut points are being made.And I'm labeling these points x sub i, so my left hand n point is x sub 0 and myright hand n point is x sub n, and my cut points in between where I'm cutting up topartition are i over n
* So, the first one here, or the one afterthe 0 of 1 anyway, is 1 over n
* The next one is 2 over n, the next one is3 over n, and each of those subintervals has the same width, 1 over n.Now, I also have to choose points to sample the function at, and I'm just goingto choose the right hand end point here
* So, my x sub 1 sample point will be 1 overn, my x sub 2 sample point will be 2 over n, and so on.And I can write down the Riemann sum, right?The Riemann sum is the sum, i goes from 1 to n, the function evaluated at the samplepoint times the width of this i-th interval, right?Which I could write as x sub i minus x sub i minus 1.Now, in this case some of this is a little bit easier.I know I can write this a little bit more nicely, right?F of x of i star, x of i star being i over n, and the function being the squaringfunction
* I can rewrite this Riemann sum as i over nsquared, and then x of i minus x of i minus 1.That's just the width of the i-th subinterval in my partition.And that's, you know, how far apart these numbers are, and that's 1 over n.So, there is my Riemann sum associated to this particular partition as my particularchoice of sample point
* I can evaluate that exactly by using someof the facts we've learned about sums
* In fact, I want to do a little bit morethan just evaluate this, right
* I want to take the limit of this as n goesto infinity
* And by choosing finer and finerpartitions, that's going to give me better and better approximations to the true areaunder the graph of this function, right
* That's the area that I'm trying tocalculate by evaluating this particular Riemann sum and taking the limit as thenumber of pieces in my equal length partition goes to infinity, okay?So, this is really what I want to calculate, alright?I want to calculate the limit as the number of things in my partition, each ofequal size, goes to infinity, right
* That's a finer and finer partition.And this is the Riemann sum that we had before.And this is calculating the integral from 0 to 1 of x squared.All right
* Well, how do I do this now?Well, this is the limit as n approaches infinity of the sum, i goes from 1 to n,and this is i squared over n squared times 1 over n.Now, n is a constant, so I can pull this out of a sum by using distributivity.This is the limit as n approaches infinity of 1 over n cubed times the sum of isquared, i goes from 1 to n
* Now we think back, I've got a formula forthe sum of the first n perfect squares, right?That formula tells me that this is the limit as n goes to infinity of 1 over ncubed times, and what's the sum of the first n perfect squares?It's n times n plus 1 times 2n plus 1 all over 6.Now, I could expand that out
* This is the limit as n goes to infinity of1 over n cubed times 2n cubed plus 3n squared plus n all over 6.And this limit, well, it really just matters, right?What these highest powers are
* There's an n cubed in the denominator, ora 6n cubed in the denominator, and a 2n cubed in the numerator.And as n approaches infinity, this is 1 3rd.Let's summarize this with an official looking statement.So, the integral from 0 to 1 of x squared dx, right?We've just calculated this as 1 3rd
* And what that's really saying is that ifI've got say, this graph here, say this is the graph of x equals x squared, thisintegral is calculating this area, right
* The area between 0 and 1 underneath thegraph of x squared, right
* This red area here is 1 3rd square unit asa result of the integral calculation
* Now, I can play around with this a littlebit
* So, to say that the integral from 0 to 1of x squared dx is 1 3rd, well, one thing I could do with this is I could multiplythis by 3, right
* What's 3 times the integral from 0 to 1 ofx squared
* Well, that's 3 times a 3rd, that's equalto 1
* But 3 times an integral, that's the sameas integrating from 0 to 1 3 times the function, right?And this is really worth thinking about
* I mean, here I'm taking this area andmultiplying it by 3
* Here, I'm calculating the area of thegraph stretched in the y direction by 3 times, right?And these are the same
* And this is saying that the integral from0 to 1 of 3x squared dx is equal to 1
* So, what does that mean?So here, I've graphed the function y equals x squared from 0 to 1.And the area in there is 1 3rd of a square unit.That's the first calculation that we did
* And, now what I'm claiming is that if Itook this same function here but multiplied it by 3, right?Which has the effect of stretching it in the y direction by 3 times as much.Well, that triples the area
* So, the original area here is a 3rd, butnow there's new area 1 square unit, right
* Which is what I've written here, okay?So, what does it mean to say that the area under the graph is one square unit?What I don't mean is that I can take a square of side length 1 and cut it up andexactly cover that region
* That's really not what I'm talking aboutwhen I claim that, that region has area 1
* If I claim that, that region is area one,I really mean two different things
* I mean that if I had a square with just alittle tiny corner nicked off of it, I could take that thing that has area justunder one unit and chop it up into little pieces and fit that thing entirely insidemy curved region
* Conversely, I mean that I could take asquare of side length 1 and just a little bit of extra area, and I could cut thatthing up into little tiny pieces and cover up my curved region, right?But it's fundamentally all about limits, right?This whole story isn't actually about achieving anything.It's just saying that I can get as close as I want, right?It's saying that I can take this almost 1 square unit entirely inside, or I couldtake a little bit more than 1 square unit and cover it up.But I'm never actually asserting that things are equal.I'm just saying that they are as close as I like them to be.


--- SKIP ---: 02_what-is-the-integral-of-x-3-from-x-1-to-2.en.srt


--- SKIP ---: 02_what-is-the-integral-of-x-3-from-x-1-to-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-integral-of-x-3-from-x-1-to-2.en_SENTbySENT.txt
* [music] Let's integrate x cubed from 0 to2
* In this case, the function x cubed is acontinuous function, therefore it's an integrable function.So, all I need is just to start with a fine enough partition and it won't matterhow I pick those sample points inside the partition.My Riemann sum will be close to the true value of the integral.So, I'll cut the interval from 0 to 2 into n pieces.Pictorially, I want to start with the interval between 0 and 2, and I want tocut it up into n pieces
* Now, the length of this whole interval istwo units long, so each is these pieces should have a went of 2 over n.And that, let me write down the formula, the cut point x sub i will be 2 over ntimes i, and that works out great 
* If i is 0, then I'm at the left handendpoint
* And if i is n, I'm at the right handendpoint
* And in between, I'm just marching from theleft hand side to the right hand side moving 2 over n each time.Now, how should I choose my sample points
* I'm just going to choose my sample points,x sub i star, to be the right hand end points.So, they'll be, in fact the same as x sub i.Now, I just have to write down the Riemann sum for this particular equal sizepartition and our chosen sample points
* In general, the formula for Riemann sum isthe sum, I think it's the sum, i goes from 1 to n of the function evaluated at thei-th sample point times the width of the i-th subinterval in my partition, right?This is the area of the rectangle
* And I'm adding up all those rectangles toget an approximation of the area under the graph.Well, in this specific case, what do I have?X sub i star is the same thing
* If I go back to this, x sub i star is thesame thing as x sub i
* So, I can just plug in 2 over n times i,and x sub i minus x sub i minus 1, that's the width of the i-th subinterval in mypartition
* But, I rigged it so that all of thesubintervals have the same equal width
* They've all got width 2 over n, okay?So, that's the sum that I want to calculate.Now, the function in this case is the cubing function.So, this is the same as the sum i goes from 1 to n of 2 over n times i cubedtimes 2 over n, which I could simplify somewhat.This is the sum i goes from 1 to n of 16, 2 cubed times 2, over n to the 4th, it's ncubed over n times i cubed
* So that's the particular Riemann sum inthis case
* Quizzes are just a specific Riemann sumfor a specific value of n
* To get the value of the intregal, I'mgoing to take the limit an n approaches infinity.Yeah, the integral from 0 to 2 of this function x cubed is the limit as n goes toinfinity of this Riemann sum
* Now, strictly speaking, right?This integral would be a limit over all the possible partitions.But since the function's integrable, it doesn't matter what partition I choose aslong as it's fine enough
* And n going to infinity makes finer andfiner partitions
* So, what I really want to calculate, inorder to calculate this integral, is to calculate this limit.Well, let's see if we can do that
* The good news here is that I've got aformula for the sum of cubes
* So, we will pull out that formula in aminute
* And I've also got a constant here.16 over n to the fourth is a constant
* It doesn't depend on i at all, so I canfactor that out of this sum by distributivity.So, this is the limit as n approaches infinity of 16 over n to the 4th times thesum of i cubed, i goes from 1 to n
* And now, I happen to know what the sum ofthe first n cubed is
* I can use that formula that we got frombefore
* That's the same as the sum of the first nwhole numbers squared
* And in this case, that's the limit as ngoes to infinity of 16 over n to the 4th times, that's n times n plus 1 over 2.That's the sum of the first n whole numbers and the sum of the first n perfectcubes is that squared
* Now, I've got to figure out what this is.Well, I can factor out a over 2 squared and that'll cancel part of the 16.So, this is the limit of n squared times n plus 1 squared times 4 over n to the 4th.And now this is the limit as n goes to infinity.This ends up being n squares time n squares plus lower order terms.So, this is, the biggest term here is 4n to the 4th over n to the 4th, so thislimit ends up being equal to 4
* And that is in fact the integral from 0 to2 of x cubed dx
* That integral, therefore, is equal to 4.Now, what if I wanted to do this integral over some other interval?Well, I could repeat this same kind of calculation to deduce that the integralfrom 0 to 1 of x cubed dx is equal to a quarter, right?But that would be another whole calculation that I'd have to work out.Let's say, I wanted to integrate over the interval 1 to 2.Well, there's a trick that you could use
* So, the integral from 0 to 2 of x cubeddx, we already calculated
* But forget the exact answer.What I want to note here is that this is related to two other integrals.Integrating from 0 to 2x cubed dx is the same as integrating from 0 to 1 of x cubeddx, and adding to that the integral from 1 to 2.Now geometrically, something like that hopefully makes some sense, right?If I draw a graph, here's 0, here's 1, here's 2.Here's the function y equals x cubed, say this first interval from 0 to 1 iscalculating the area here, right
* That's what this integral's calculating.The second integral from 1 to 2 is calculating this area here, right?And if I add together these two areas, I end up getting the area from 0 to 2, whichis what this integral's calculating
* Well, the nice thing here is that, since Iknow this integral and I know this integral, that's enough information torecover this integral
* The integral from 0 to 2, we saw a momentago, was 4
* The integral from 0 to 1, I'm claiminghere is a quarter, and that's enough information to tell me that the integralfrom 1 to 2 of x cubed dx, well, that must be exactly what I need to add onto aquarter to get 4, that must be 15 fourths, right?So, this red area in here must be 15 4th square units.What we're seeing here is that you can evaluate some integrals just by going backto the definition and using our knowledge of sums, but the sums are ugly, right?These are really terrible calculations
* This is the exact same situation thatwe've been in before
* A long, long time ago, we were faced withthe definition of derivative and we started computing some derivatives just bygoing back to the definition of derivative.But then, over time, we learned a bunch of rules which made differentiation a wholelot easier
* We're going to see the same thinghappening here
* Right now, we're just using these barehand arguments to calculate integrals
* But over time, we're going to develop moretools for evaluating integrals.


--- SKIP ---: 01_what-sorts-of-properties-does-the-integral-satisfy.en.srt


--- SKIP ---: 01_what-sorts-of-properties-does-the-integral-satisfy.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-sorts-of-properties-does-the-integral-satisfy.en_SENTbySENT.txt
* [music] There are some properties of theintegral that are worth summarizing
* For example, here's a property ofintegration that's often useful
* If I want to integrate from a to b, right?That's what this last integral is
* And it's the area under the graph betweena and b
* It's this whole region here that I'vecolored in
* But I could split that up into twoseparate integrals, right
* I could integrate from a to c at thisfirst red integral, and then I could integrate from c to b, that's the secondblue interval
* And if I add together those two areas, Iget the total area from a to b, right
* And that geometric fact is exactly what'swritten down here, with symbols using our fancy integration notation.There's also a constant multiple rule
* Well, here's the constant multiple rule.For some constant K, the integral from a to b of that constant times a function isthat constant times the integral of that function.And this also makes sense geometrically
* Here's two pictures.Here's the graph of y equals f of x
* Here's the graph of y equals K times f ofx
* This thing here calculates this area, thearea under the graph of K times f of x
* And it's K times just the area under thegraph of f of x
* And it makes sense.Because if you take this graph and your stretch it K times, that multiplies thearea by a factor of K
* What about the intergral of a sum?Well, the integral of f of x plus g of x from a to b, right?That's this total area here
* It's related to the area under the graphof f and the area under the graph of g, right?It's related to these integrals
* Here, in green, I've sort of demonstratedwhat the area under the graph of f of x looks like with a specific Riemann sum.And in here, in red, I've drawn some rectangles for the Riemann sum of g.But they're, you know, sort of shifted up a bit.Because this curve here is the graph of y equals f of Xx plus g of x.So, the heights of these rectangles are actually what I would get if I were tojust integrate g of x, right
* The distance between f of x plus g of x,and f of x is exactly g of x here in red
* So, this is kind of a proof by stacking,if you like, that the integral of f plus g is the integral of f plus the integral ofg
* A lot of these rules have analogs for thesigma notation stuff
* We had this rule that said I could havepasted together integrals
* And there's a corresponding rule for sumthat says, if I sum f of the numbers between 1 and m, and then f of the numbersbetween m plus 1 and K, that's the same as applying f to all the numbers between 1and K and adding that up, right
* So, this same kinds of rules, I mean,there's an analogy there
* Same kind of game here, right?I've got this constant multiple rule for integrals and I've got a correspondingconstant multiple rule for sums
* Of course, this constant multiple rule isjust called distributivity, right
* If I add up K times something, that's Ktimes the sum of these things
* But, it's the same kind of rule, right?I had this formula that said the integral of the sum is the sum of the integrals.We've got the same kind of formula for a sum, right?If I take a sum of f of n plus g of n, that's the same as adding up f of n forall the numbers between a and b
* And then, adding to that g of n for allthe numbers between a and b
* And we're also seeing some similarities tothe rules for derivatives
* I've got the constant multiple rule forintegrals
* I've got a constant multiple rule for sumsand I've got a constant multiple rule for derivatives.The derivative of a constant times some functions that constant times thederivative of the function
* Same kind of deals for sums, right?I've got this sum of the integrals is the integral of the sum.I've got this sum of a sum is the sum of the sums.And I've got the derivative of a sum is the sum of derivatives.Fundamentally, mathematics is not just about these rules, right?It's about the relationships between all of these rules.We're seeing various objects now, integrals, derivatives, the sigmanotation
* And they're all sharing some common rules,right
* And working out those relationships isreally part of the fun.


--- SKIP ---: 02_when-is-the-accumulation-function-increasing-decreasing.en.srt


--- SKIP ---: 02_when-is-the-accumulation-function-increasing-decreasing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_when-is-the-accumulation-function-increasing-decreasing.en_SENTbySENT.txt
* [music] We can get a much better sense forwhat the integral's actually computing by converting the integral into a function.So the way that I'm going to package together a whole bunch of integrals isinto a function, the accumulation function.What is the accumulation function going to do?Well, here, I've graphed y equals f of t on the t y plane.And I picked a fixed point a, and I imagine I've got another point that I canvary labeled x
* And the accumulation function, is theintegral from a to x
* So it computes the area between a and xunder the graph of this function
* And it's called the accumulation functionbecause I imagine that as I move x to the side, I'm kind of accumulating more andmore area
* I'm determining how much area I'veaccumulated between a and whatever I plug into the accumulation function.When is this accumulation function increasing?As long as this function little f is positive, the accumulation function isincreasing
* Look, to determine whether a function'sincreasing, I'd have to plug in bigger inputs and see if I get bigger outputs.That's what increasing means
* So if I were to plug in some bigger inputright, the accumulation function just figures out how much area is between a andthis bigger input
* And as long as my function's positivethere's now more area between a and this bigger input than there was between a andx
* So I can summarize this in saying.That f is positive, and that makes my accumulation function increasing.When is this accumulation function decreasing?Is it ever possible to integrate over a longer interval and yet get a smallervalue
* Yes, it sounds counter-intuitive, butthat's entirely possible
* And it really comes down to this issueabout what these integrals are really measuring.The integrals are not exactly measuring area, they're measuring signed area.So here's an example where the function that I'm graphing, y equals f of t, passesbelow the, I'm calling it here, the t axis.And when the graph is below and I'm calculating the integral, this area herecounts as negative in the integral
* So this area which is above the axis hereis calculated as honest area, but this area here is really contributing negativearea to the integral, right
* I mean, I'm taking this area and I'msubtracting this area to figure out the integral from a to x.What it comes down to is how this integral is defined.The integral is defined as a Riemann sum
* It's the functions value evaluated atvarious sample points times the widths of those tiny rectangles and if I'mevaluating the function and the functions value is negative then that's not reallyan area
* That's a signed area and it could benegative
* All right.Well in light of that, what happens in this particular place?Right
* What happens if I plug in a bigger inputto my accumulation function
* Is it possible that I could integrate overa longer interval, and yet get a smaller value.And yeah, this is an exact picture of the sort of situation where that happens.If I plug in a bigger input here, then when I integrate from a to this biggerinput, I'm not only subtracting this red negative area, I'm subtracting this largerred negative area
* And in that case my accumulation functionreally is smaller, right
* As I take x and drag it over here.I'm gathering up more negative area, and so my accumulation function is going down.I'll summarize that like this, if function's negative the accumulationfunction is decreasing
* What does this sound like?Well what that sounds like is that the derivative of the accumulation function isrelated to the thing I'm integrating, the so called integrand.A, if I'm integrating a positive function, accumulation functions increasing.And another way to say that the accumulation function is increasing wouldbe to say that the derivative is positive
* So the integrands positive, the derivativeof accumulation function is positive
* The function that I'm integrating isnegative, the accumulation function is decreasing.The derivative of the accumulation function is negative.Integrand negative
* Derivative of accumulation function alsonegative
* This is our first hint at the fundamentaltheorem of calculus
* Some sort of relationship betweenderivatives
* And integrals.


--- SKIP ---: 01_what-is-the-integral-of-sin-x-dx-from-1-to-1.en.srt


--- SKIP ---: 01_what-is-the-integral-of-sin-x-dx-from-1-to-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-integral-of-sin-x-dx-from-1-to-1.en_SENTbySENT.txt
* [music] What do we get if we integrate anodd function
* For instance, what happens when weintegrate the function sin x from minus 1 to 1, right, sin x is an odd function.Consequently, it looks like the answer is 0.Remember the integral is, is morally calculating an assigned area.So it's going to be calculating this area here but with a negative sign.And it's going to be calculating this area here as actual area.Right
* With a positive sign.And these two areas are equal, but the integral is going to count this area withnegative sign and this area with a positive sign.So the integral should cancel and the answer should be 0.But if you don't believe the geometry, we can work it out algebraically.So algebraically, I'm trying to integrate from minus 1 to 1 of sine x dx.And the first thing to think is that well if I'm integrating from minus 1 to 1, canwe write that as an integral of minus 1 to 0 of sin x dx, and add to that theintegral from 0 to 1 of sin x dx right
* Right, if I want to integrate all the wayfrom minus 1 to 1, it's good enough if I just integrate half way and then integratethe rest of the way, and there is two separate intervals.Now, how do I integrate from minus 1 to 0 sin x dx?Now if we think a little bit about what this really means, that would be the sameas integrating from 0 to 1 of sin minus x, alright?If I want to add up numbers from minus 1 to 0, it'll be good enough if I pick thepartition from 0 to 1 and then evaluate the sin at negative, those, those value.And you have to worry a little bit about how this dx changes but we are going to belooking at that in the future as well
* Okay, and I'm going to add to this theinterval from 0 to 1 of sine x dx that I've got right there.And what's sine of negative x
* That's negative sine of x, and here I'vejust got sine of x dx again
* But now I've got the interval from 0 to 1of negative sine dx plus the interval from 0 to 1 of sine dx.Well I can pull this minus sign out of the integral.If I'm integrating just a constant time something it's the same as that constanttimes the integral
* And now I've got negative something plusthe same thing so that is equal to 0
* Now in the future we're going to see morehow to justify those steps that I took algebraically, right?Why are those steps actually valid
* But in the meantime, the upshot here, thetakeaway message is just that symmetry can be exploited to calculate some integrals,right
* You can evaluate the integral of an oddfunction, as long as you're integrating symmetrically across 0, you can evaluatethat integral to be equal to 0 by exploiting symmetry.


--- SKIP ---: 01_what-is-the-big-deal-about-the-fundamental-theorem-of-calculus.en.srt


--- SKIP ---: 01_what-is-the-big-deal-about-the-fundamental-theorem-of-calculus.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-big-deal-about-the-fundamental-theorem-of-calculus.en_SENTbySENT.txt
* [music] Where are we in the course
* Well we've seen some stuff aboutanti-differentation, alright
* We learned how to start with a function,and find a function whose derivative is thatoriginal function
* We've also had the sudden change of pace,where we looked at integrals
* We looked at areas under the curves
* And now, I want to take those two seemingly unrelated topics and connectthem together
* That's what the fundamental theorem ofcalculus is, is going to do for us
* Alright, the fundamental theorem ofcalculus, tells us that evaluating integrals really amountsto finding anti-derivatives
* These two seemingly unrelated concepts of differentiation, and integration arereally related
* And this is really key insight of calculusas a whole
* I mean think about it, in what sense didNewton and Leibniz discover calculus
* Greek mathematics had these ideas right,Greek mathematicians were calculating areas of curved objectsby taking limits
* I have formulas for the areas of circles
* And the idea is of slope, okay, predateNewton and Livenets
* So, what was the insight that, that means that we credit Newton and Leibniz withdiscovering calculus
* What really amounts to the fundamentaltheorem of calculus
* It amounts to this idea that, differentiation and integration aresomehow related
* By thinking systematically and precisely,about how a function changes when you wiggle its input, and in particular, thinking about a derivative of the accumulationfunction
* Alright, we're able to see this, thisrelationship between evaluating a definite integral, andfinding an AI derivative
* And I want to do more now, than, than justshow you how to calculate integrals, by usingthe fundamental theorem of calculus
* That will be a big thing too, just theprocess of computing
* But I hope, that you'll understand some ofthe reasons why, the fundamental theorem ofcalculus is true
* So, I want to look at the fundamentaltheorem of calculus just from a lot of differentperspectives
* Alright, we should come on away from this,not just with the ability to compute, but also the ability to really communicatesort of an understanding, of this absolutelyamazing theorem
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_what-is-the-fundamental-theorem-of-calculus.en.srt


--- SKIP ---: 01_what-is-the-fundamental-theorem-of-calculus.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-fundamental-theorem-of-calculus.en_SENTbySENT.txt
* [MUSIC]
* I want to begin with a statement of he fundamental theorem of calculus
* Suppose the function little f, from the closed interval a to b, to the real numbers, is a continuous function
* And let's define a function big F, to be the accumulation function
* Right, that's the integral
* From a to x of the function on the left well then the function big F turns out to be continuous in the closed interval a to b differentiable on the open interval a to b and this is the big point the derivative of big F is little f
* We've seen a bit of evidence for this already
* And suppose I got the accumulation function
* So big F of x is the integral from a to x of f of tdt
* And now I can ask, how is the accumulation function changing
* Well, the accumulation function is increasing, meaning it's derivative is positive if the function that I'm integrating is positive
* And the accumulation function is decreasing, meaning the derivative is negative
* If the function that I'm integrating is negative
* And this suggests that the derivative of the accumulation function and the function that I'm integrating might be related in some way
* Here's a graph that's particularly compelling
* So, I'll draw the coordinate plane, here's the y axis, here's the t axis in this case and I'll draw some Random looking graph
* That'll be the graph y equals f of t
* And then I'll pick some point
* I'll call it a and some other point x
* And then I'll look at the area under the graph between a and x, rigth
* And that's the integral from a to x of f of t d t
* Right that area is the accumulation function evaluated x
* Now what's the derivative of the accumulation function
* What got the accumulation function, right f(x) equals the interval from a to x that f(t)dt and I don't know how that changes when x changes
* So lets make a small change in x
* Lets go from x
* To say x plus h and then ask how does the area in this region compare to the area in this much larger region
* What's big F of x plus h minus big F of x
* Yeah, so what's F of x plus h right that's the area
* From a to x plus h, minus F of x, big F of x
* That's the area from a to x, and that difference, right
* That difference is just the area inside here
* That little leftover piece is practically a rectangle of height, f of x, little f of x and width h
* I mean, this region is not quite a rectangle
* But it's awfully close to a rectangle of, width h
* And area f of x plus h minus f of x
* Now, remember, by goal was to differentiate the accumulation function
* And all I've got is this rectangle
* Whose width is about h, and whose height, you think about it, it's about f of x
* So what's up with this rectangle
* Alright
* I mean what I've really got here is a rectangle and its area is about f of x plus h minus f of x, this accumulation function
* It's width is h, and it's height is about f of x
* Well I've got a rectangle with this area and this width and, and this height
* Alright, what do I know
* I know its height times its width is its area, so if I take its area and divide by its width, I should get its height
* Now all this is just approximate, but let's write that down
* I The area of this you know, rectangle is f of x plus h minus f of x
* And if I divide by the width, I should get, the height
* What does that mean after I take a limit
* Oh of course this is only approximately true, but if I take a limit, right
* If I take a limit as h approaches 0
* This gives me the derivative of the accumulation function and that will in fact be equal to the function's value
* And that is the whole game
* The accumulation function F is an antiderivative of f
* Well this, I mean this is really remarkable
* For instance you might be wondering what's an anti-derivative of this function, little f of x equals e to the negative x squared
* Well if a functions continuous then we can find an anti-derivative
* The anti-dirivitive is the accumulation function
* So an anti-derivative of either the negative x squared is the accumulation function
* I can define a function big f of x to be the intregal from a to x, for some number a, of e to the negative t squared d t
* And if I differentiate this accumulation function, I get back e to the negative x squared
* So I found an anti-derivative
* For this function
* Well I can't write it down any more nicely
* Because I can't write down an anti-derivative for e to the negative x squared using the functions that I have at hand
* But nevertheless, the anti-derivative is the accumulation function.


--- SKIP ---: 02_what-is-the-integral-of-sin-x-dx-from-x-0-to-x-pi.en.srt


--- SKIP ---: 02_what-is-the-integral-of-sin-x-dx-from-x-0-to-x-pi.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-integral-of-sin-x-dx-from-x-0-to-x-pi.en_SENTbySENT.txt
* [MUSIC]
* Let's use the fundamental theorem of calculus to evaluate an integral
* Let's do the integral from zero to pi of sine x dx
* Let's call this function little f
* So, f of x, little f of x, will be sine of x
* Now, I need to find an anti-derivative for little f, right
* I need a function whose derivative is sin of x
* I know one already, right
* The derivative of minus cosine of x
* Well, if the derivative of cosine is minus sine, then I've got a minus sign there
* That's a little joke
* All right
* The derivative of minus cosine of x is sine of x
* So, minus cosine of x is an anti-derivative for sine of x
* Now, what does the fundamental theorem of calculus tell us to do
* The fundamental theorem of calculus tells me that if I want to integrate this function little f, I should find an antiderivative, which I've located, right
* Minus cosine, and then evaluate that antiderivative at these end points and take the difference
* So, in this particular case what do I get
* So, in this case, I've got a function big F, right this is my antiderivative, and it's minus cosine of x
* And according to the fundamental theorem, if I want to integrate from zero to pi, my function little f, which is sine x, I'm going to evaluate the antiderivative at pi and subtract the antiderivative at zero
* In this case my chosen antiderivative is minus cosine x
* So, it's minus cosine pi minus, minus cosine zero
* Now, what's cosine of pi
* That's minus 1 but it's negative minus 1
* That's 1 minus and cosine of zero is 1, but it's negative 1
* So, it's 1 minus negative 1, which is 2
* There are exactly 2 square units of area under the graph of sine of x
* between x equals 0 and x equals pi
* can we actually see that fact
* Well, here's a graph of y equals sine x and by the interval that we just did, the area under this curve is 2 square units
* Well, here's 2 square units, right
* The maxium value of sine is 1
* So, this is just at the same height as where sine hits its maximum here
* And its width, this rectangle is 2
* So, this is 2 square units
* And the claim is that I should be able to just about fit this under the graph
* So, I've got my scissors here and I'll just start cutting
* And if I cut
* here, this part now, and it fits pretty well with the graph
* And I've got this little bit left over
* Let me just
* Chop this off here
* I mean this is, this is looking pretty good
* Right
* I mean that's not, it's not perfect but I mean, you know, it looks like about 2 square units fit underneath this graph
* I always thought it was a little bit surprising that the answer, the area under the graph of sine x, turned out to be exactly 2 square units
* I mean, you might have thought that the answer would involve pi or something
* And the answer ends up being a lot nicer I think than you might have expected.


--- SKIP ---: 03_what-is-the-integral-of-x-4-dx-from-x-0-to-x-1.en.srt


--- SKIP ---: 03_what-is-the-integral-of-x-4-dx-from-x-0-to-x-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-integral-of-x-4-dx-from-x-0-to-x-1.en_SENTbySENT.txt
* [MUSIC]
* Let's find the area under graph of a polynomial
* So let's integrate from 0 to 1, the function x to the 4th dx
* To solve this problem, I can use the fundamental theorem of calculus
* So the first step is to find an anti-derivative of x to the 4th
* Well, what's an antiderivative just for x to the n
* Right, as long as n isn't minus 1, an antiderivative for this is x to the n plus 1 over n plus 1 plus c
* So for this specific problem, right, what's an antiderivative for x to the 4th
* Well, that'll be x to the fifth over 5 plus some constant c
* And it doesn't matter which anti derivative I pick
* So, just to emphasize that point, let's be a little bit ridiculous and, pick my anti derivative that I'm calling big F, to be x to the fifth over 5 plus 17, right
* And this really is an anti derivative for x to the 4th
* Because if I differentiate this function, I get the derivative next to the flipped over five, which is 5x to the 4th over 5 plus the derivative 17, which is 0
* And 5x to the fourth over 5 is just x to the 4th
* So I really have found an anti-derivative for x to the fourth right here
* It's x to the 4th over 5 plus 17
* Now I apply the fundamental theorem
* So the fundamental theorem tells me that, to integrate from 0 to 1
* The function, x to the 4th is the same as evaluating an anti derivative for x to the fourth at 1
* And subtracting that anti derivative evaluated at 0
* In this case, my chosen anti derivative is this function
* So I plug in 1
* I get 1 to the 5th over 5, plus 17, minus what I get when I plug in 0, which is 0 to the 5th over 5, plus 17
* And one fifth plus 17, minus 17 Well this is just 1 5th
* I can really see this fact
* So here's a graph of the function y equals x to the 4th, and we just saw is that the integral from 0 to 1 of x to the 4th dx is 1 5th, so there must be 1 5th of a square unit of area underneath this graph
* Let me get out my scissors
* Well here's a rectangle, and the width of this rectangle is one and the height of this rectangle is a 5th, so this rectangle contains 1 5th of a square unit of area, and it's the same as the area under this graph
* So let me cut this rectangle a bit
* I'll shove that piece Under there and I've got this leftover piece which I guess I have to do something with
* Huh
* Maybe I'll turn it over
* Maybe I'll cut off this piece here
* I'll put that there
* I'll rip this there, and sort of shove that in there, and there'll be a little bit up there..
* I mean it's not great, the job that I did here, but it's at least believable that there's a 5th of a square unit of area underneath this graph
* Admittedly this particular case, the area under the graph of X to a power, this particular case was known to Fermont before Newton
* And yet what we're really selling here isn't the answer to a particular problem
* It's a general technique for approaching these area problems
* If you want to find the area under a graph of a function instead of trying to do it by hand You can apply the fundamental theorem of calculus and reduce it to an antidifferentiation problem, which hopefully is easier
* This is an example of the way in which mathematics is a democratizing force
* Problems that at one time would have been only accessible to the geniuses on earth
* are now accessible to everybody, right
* At one time in history, you would've had to been the smartest person on Earth in order to calculate the area of some curved object
* And yet now, armed with the fundamental theorem of calculus, we can all take part in these area calculations.


--- SKIP ---: 01_what-is-the-area-between-the-graphs-of-y-sqrt-x-and-y-x-2.en.srt


--- SKIP ---: 01_what-is-the-area-between-the-graphs-of-y-sqrt-x-and-y-x-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-area-between-the-graphs-of-y-sqrt-x-and-y-x-2.en_SENTbySENT.txt
* [MUSIC]
* Let's use calculus not just to calculate the area under the graph of a function, let's use calculus to find the area between two curves
* Specifically, what's the area between the graph of y equals the square root of x
* And the graph of y equals x squared
* As usual, let's start by drawing a graph of the situation
* Here's my plane
* the graph of y equals x squared maybe looks like that
* And the graph of the square root of x, maybe looks like this in red
* So what's this area between curves even mean
* Well I really mean the area inside, this little wing shaped region here
* this point is worth thinking about, that point has coordinates 1,1
* let's set it up as an integration problem
* I can imagine carving this region up into lots of thin rectangles, right
* Setting up a[UNKNOWN] sum
* Let's draw some of those thin rectangles, in this region here
* And, you have to worry a little bit about exactly how tall all these rectangles are
* And how wide all these rectangles are
* Well, how tall are these rectangles
* Let's just pick one of the rectangles in particular to think about
* Let's pick this rectangle, and think about it
* How tall is it
* Well, its top edge
* Is on y equals the square root of x, and its bottom edge is on this orange curve
* The y equals x squared term
* So the height of that particular rectangle is its top coordinate minus its bottom coordinate, so it will be square root of x minus x squared tall And how wide is it
* Well, the width of this little tiny tri-, rectangle, is, not supposed to very big, right
* So let's call its width dx, right
* I'm imagining that its, width is, very narrow
* It's a very thin rectangle
* So that amounts to evaluating a certain integral
* Yeah, but which integral
* Well, I want to add up the areas of all these little boxes
* And these little boxes have heights given by this, and widths given by some small quantity, I'm[INAUDIBLE] dx
* So the integral that I want to calculate will be the integral of the area
* So it'll be the height
* The square root of x minus x squared
* Times the width which is DX
* And then what does my X go between
* Well the smallest value of X here is zero and the biggest value of X here is one so I'll have X going from zero to one
* So that's the integral that I want to calculate which will find the area in between these two curves
* I can evaluate that integral by using
* The fundamental theorem of calculus
* So, the fundamental theorem of calculus tells me to find an anti-derivative for this
* So, let's first thing
* What's an anti-derivative of the square root of x
* Well that's an anti-derivative of x to the one half power
* But remember my rule for anti-differentiaing x to a power
* It's x to that power plus one, so 3 halves is one more than a half, divided by that power plus 1, 3 halves so that when I differentiate this I get back x to the one half power and I'll just add some constant C on there to give myself the general anti-derivative
* What if I want to anti-differentiate x squared
* Well, that's maybe easier
* And it's the same power rule
* It's x to the third power, which is one more than two, divided by two plus one
* So that when I differentiate this, I just get back x squared, and I'll add a constant
* Now what's an antiderivative of the difference
* Well, the difference of anti derivatives
* So, the aniti derivative of the square of x minus x squared is the anti derivative for the squared of x which is x to the 3 halves over 3 halves, minus the anti derivative for x squared
* So, x to the 3rd over 3
* So, there's the general anti-derivative for this
* Armed with the anti-derivative, I can now evaluate the internal
* So, one way to write that is as follows
* If I went to integrate from 0 to 1, the squared of x, minus x squared dx
* I'll just write down the anti-derivative for this, or an anti-derivative for this
* Which is x to the 3 halves over 3 halves, minus x to the 3rd over 3
* That's an anti-derivative for this, plus 0, if you like
* And then, I'll evaluate this quantity at 0 and 1 and take the difference
* So, this is a little bit of fancy notation
* Just for plugging in x equals 1, plugging in x equals 0 and finding the difference
* And if I want to emphasize what I'm plugging in I might write even x equals 0 here just to emphasize that x is the variable that I'm working with
* Alright well let's do that
* let's plug in x equals 1 here
* And when I do that I get 1 to the 3 halves power over 3 halves minus 1 to the third over 3
* And I'll subtract what I get when I plug in 0
* SO I plug in 0, 0 to the 3 halves over 3 halves minus 0 to the third
* Over three
* Well this is easy to calculate now
* 1 to the 3 halves is 1
* So it's the reciprocal of three halves
* Which is 2 3rds, minus 1 to the 3rd, which is 1 over 3
* So that's just a third
* And here I've got minus 0
* So I've 2 3rds minus 1 3rd
* This integral ends up being equal to 1 3rd which is computing the area between the original curves
* I hope this problem wets your appetite for harder problems along these same lines, right
* You can imagine very complicated area calculations.


--- SKIP ---: 02_what-is-the-area-between-the-graphs-of-y-x-2-and-y-1-x-2.en.srt


--- SKIP ---: 02_what-is-the-area-between-the-graphs-of-y-x-2-and-y-1-x-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-area-between-the-graphs-of-y-x-2-and-y-1-x-2.en_SENTbySENT.txt
* [MUSIC]
* Let's find the area between two parabolas
* I want to find the area between the graph y equals x squared and the graph of y equals 1 minus x squared
* As usual let's start by graphing
* Well here's my coordinate plane
* I'll draw a graph of y equals x squared
* And the other curve is y equals 1 minus x squared, so I'll draw a downward-facing parabola
* there's the one side of it and there's the other side of it
* I'll draw some rectangles to get an idea about what Riemann Sum I really want to take the limit of
* So it's really the area inside here that I want to calculate
* Draw some some rectangles then for the for the Riemann Sum
* That would approximate that area
* Right, so there's some rectangles for the the Riemann sum that would approximate the area in there
* And then I can write down the heights and the widths of one of those rectangles
* Let's take a look and say this rectangle here
* Well, what's the width of that rectangle, will be real thin, so I'll call the width dx
* And what's the height of that rectangle
* Well the top of that rectangle is on the curve 1 minus x squared and the bottom of that rectangle was on the curve x squared
* So if we take the top coordinate minus the bottom coordinate, that will give me the height of this rectangle
* The top coordinate is 1 minus x squared
* The bottom y coordinate is just x squared
* So this quantity is giving you the height of this rectangle
* Oh, now I can write down the integral
* So I know the height and the width of these rectangles so the thing I want to add up are the areas of those little rectangles
* So I want to integrate the height
* 1 minus, this is 2x squared, times the width, dx
* But I'm trying to integrate from where to where, right
* What are the possible x values in this region
* Well, if we think about exactly where these two curves cross, right
* What's the x coordinate where these curves cross
* And this coordinate here is minus 1 over the square root of 2 and this coordinate is 1 over the square root of 2
* So I'm going to be integrating to compute the area from x equals negative 1 over the square root of 2 up to 1 over the square root of 2
* And it's this integral that'll calculate the area in between those two curves
* I can use the fundamental theorem of calculus to evaluate this integral
* Let's find an antiderivative
* So what's an antiderivative of 1, well x is an antiderivative of 1
* What's an antiderivative of 2 x squared, well 2 x to the 3rd over 3 differentiates to 2 x squared
* And I'm looking for an antiderivative of a difference, so it'll be the difference of antiderivatives
* Now I'll evaluate my antiderivative at the right and left endpoints
* Right, so I have to evaluate my antiderivative at the end points, which are 1 over the square root 2 and minus 1 over the square root of 2 and then take the difference
* So what do I get when I plug in 1 over the square root of 2
* I get 1 over the square root of 2 minus 2 times 1 over the square root of 2 to the third divided by 3
* So this is what I get when I plug in x equals 1 over the square root of 2 into my antiderivative
* And I subtract what I get when I plug in negative that, which is negative 1 over the square root of 2, minus 2 times negative 1 over the square root of 2 cubed, all over 3
* I can simplify this a bit
* Well, first off, I've got a quantity minus negative that same quantity
* That's just two copies of this same quantity
* Now I can keep calculating this and try to simplify this even a little bit further
* Now let's keep going
* So what do I have here
* Well it's 2 times 1 over the square root of 2, minus 2
* And here I've got 1 over the square root of 2 to the 3rd power
* So I could write that as a half
* Times 1 over the square root of 2
* That's really 3 copies of the square root of 2 divided by 3
* Okay
* But, 2 times 1/2, alright, cancels
* And then I've got a common factor of 1 over the square root of 2
* So I could, pull out that common factor of 1 over the square root of 2
* And when I pull that out I've got a one there minus a third is left
* now 2 times 1 over the square root of 2, that's just the square root of 2 and 1 minus a third well that's really 2 3rds, so what's left all over here is the square root of 2
* Times 2 3rds, this is the value of the integral and also then, the area between those two curves
* Before committing to this as my final answer, I should check to see that the answer's somewhat reasonable
* Well if we numerically approximate this, this is about 0.94
* So is a bit less than one square unit a reasonable answer
* Well the region that we're interested in fits inside a rectangle of height 1, and width the square root of 2 units
* The area of this rectangle is about 1.41 square units
* And the area of the region we just calculated to be about 0.94 square units, right
* This region inside here
* And it's pretty reasonable
* I mean, you know
* It looks like
* If this thing is about 1.41 square units it's not unreasonable to think that this is a little bit less than 1 square unit in this curved region, here
* Yea, we're really finding answers that accord with our geometric intuition.


--- SKIP ---: 03_what-is-the-accumulation-function-for-sqrt-1-x-2.en.srt


--- SKIP ---: 03_what-is-the-accumulation-function-for-sqrt-1-x-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-accumulation-function-for-sqrt-1-x-2.en_SENTbySENT.txt
* [MUSIC]
* Let's think a bit, about circles
* Let's think about the function little f of x equals the square root of 1 minus x squared
* What do we get if we graph that function
* We draw my coordinate axes, right
* And I'm trying to graph the function
* y equals the square root of 1 minus x squared and yeah, when I graph that, I get a semi-circle
* Now, we can compute this integral geometrically
* Well, let's think about the integral from 0 to 1 of the square root of 1 minus x squared dx, right
* That just calculates the area Inside this quarter circle, and what's that area
* Well, the whole unit circle has area pi
* So that quarter circle has area pi over 4
* This is a geometric calculation of an integral
* We can also look at the accumulation function
* Well here's a zoomed in copy of the graph of that semi circle and here's 0 and here's t
* So this area in here is exactly what the accumulation function calculates
* It's the integral from 0 to t
* Of the square root of 1 minus x squared right, that's this graph, d x
* Now my claim is that, that accumulation function can be written like this
* That, that integral is equal to t times the square root of 1 minus t squared all over 2 plus the arc sin of t over 2
* We can work this out in a couple different ways
* One way just involves differenciating
* So I'm going to differentiate this side and get, I hope, the square root of 1 minus t squared, alright, that will be a proof that an anti-derivative of the square root of 1 minus x squared is this
* So that's with t's replaced with x's
* Okay so let's try it
* Let's see if we can, if we can really pull that off
* So so let me just write down what I'm trying to show
* I'm trying to differentiate this whole thing
* So t times the square root of 1 minus t squared over 2, plus the arc sin of t over 2
* And that's differentiating a sum
* So I just had to differentiate this and add it to the derivative of this
* And this first term is a product
* It's the t times the square root of 1 minus t squared over 2
* So I'm going to differentiate that product using the product rule
* So it's the derivative of t, which is just 1 times the second thing
* Or the square root of 1 minus t squared over 2
* Plus the first thing t times the deriveter of the second thing alright d dt the squared of 1 minus t squared over 2 alright so that's the deriveter of this first term plus the deriveter of[UNKNOWN] t over 2 well the deriveter of art[UNKNOWN] Is 1 over the square root of 1 minus t squared, but then it's over 2
* So I'll put a 2 there
* Okay, so I'm making some progress
* I've still got to differentiate the squared of 1 minus t squared over 2 so, let's just, let's just keep going
* So this first term is looking really great
* This is the square-root of of one minus t-squared, over two
* And, of course, I'm trying to get the square-root of one minus t-squared
* So that's, that's looking pretty good
* Plus t times, now what's the derivative of this square-root
* Well, I'll put the over-two here
* So I just need to differentiate the square-root of minus t-squared
* And that's one over
* 2 times the square root of 1 minus T squared
* And then it's times the derivative of the inside function
* And the derivative of 1 minus T squared is minus 2T
* All right, so that's the derivative of the square root of 1 minus T squared over 2
* The over 2 is there, and that's the derivative of just the square root of 1 minus T squared
* And I'll just add the derivative arc sign t, one over two the square root of one minus t squared
* Okay, now I can simplify this a bit
* Right, what do I have here
* Well, I've got a minus two here and a two there
* So those will cancel and what I'm going to be left with here is , The square root of 1 minus t squared over 2
* Minus t squared, over 2 times the square root of 1 minus t squared
* That's this whole second term, plus 1 over 2 times the square root of 1 minus t squared
* Now I'm going to combine these last two terms, all right
* This is equal to what
* Well, I'll put 1 minus t squared over this common denominator
* So I've got this first term, the square root of 1 minus t squared over 2 Plus 1 minus t squared over that common denominator of 2 times the square root of 1 minus t squared
* Now I've got something divided by the square root of the same thing
* So I could replace this
* With, well, the first term, 1 minus t squared over 2 plus, this is something over the square root of the same thing, so the square root of 1 minus t squared over 2
* Now I've got something over 2 plus something over 2, that's just the square root of 1 minus t squared, and indeed We have made it to our goal
* I started by wanting to differentiate this expression and I ended up with the sqaure of 1 minus t squared
* The second method is a bit more geometric
* So I want to find geometrically the area in here
* And I can break that region up by drawing this line, so that I've got this circular sector and this triangle
* Now what's the area of the triangle piece
* Well, the height of that triangle is the square root of 1 minus t-squared, right
* The base is length t, and this hypotenuse is length 1
* So by the pythagorean theorem the height of that triangle is the square root of 1 minus t squared and that means the area of this triangle is its base t times its height the square root of 1 minus t squared divided by 2
* So that's the area of this triangle, What's the area of the circular sector
* Well, I've got an angle here which is theta and by a bit of geometry that angle is the same as that angle up there
* This length here is t, right
* We're going to need that in a minute
* So if I've got a circular sector with a radius 1 and a angle here, theta, that area is theta over 2
* This length is t
* So that means that I know a formula for theta in terms of t
* Theta is arcsine t, right, because, you know, really, sine theta is t
* And that means instead of writing theta over two for that area, I could write the area of that circular sector to be arcsine t over two
* So the total area here is arc sin t over 2 plus t times the square root of 1 minus t squared over 2
* Alright
* And that's exactly what I'm claiming in the accumulation function
* This term is calculating the area of that triangle
* And this term is calculating the area of that circular sector
* Now what happens if we evaluate the accumilation function at 1
* So what I would be calculating is the interval from 0 to 1 of the square root of 1 minus x squared dx
* And that's what I get when I just plug in t equals 1 here
* So 1 times the square root of 1 minus 1 squared over 2, 0
* Plus arc sign of 1 over 2 well that term is 0 and arc sign of 1 is pie over 2, so I've got pie over 2 over 2 that is just pie over 4 which is you know really the area of a quarter circle these pieces are coming together We can compute the accumulation function just by pure geometry or some trigonometry
* We can verify that its derivative really is the square root of 1 minus x squared
* And then we can recover the area of a semi circle this way as well, right
* No mathematical fact is an island.


--- SKIP ---: 01_why-does-the-euler-method-resemble-a-riemann-sum.en.srt


--- SKIP ---: 01_why-does-the-euler-method-resemble-a-riemann-sum.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-does-the-euler-method-resemble-a-riemann-sum.en_SENTbySENT.txt
* [MUSIC]
* Remember back to those good old days when we were approximating antiderivatives by using Euler's Method
* I'm going to be started with some function little f and I wanted to numerically approximate a function big F, whose derivative was little f
* And maybe I know big F's value at 0 is exactly 0, and I want to numerically approximate big F for values away from 0
* And the we did repeated linear approximation
* I pick some tiny h, and then I approximated big F of h
* Well, what do I know about big F Big F's derivative is little f
* So my approximation for big F at h is the value of big F at 0 plus h times the derivative of big F at 0
* Well, what is this
* The value of big F at 0 is exactly equal to 0
* And, I got plus h times, and the derivative of big F is little f
* So times little f at 0
* So I can use this as my approximation for big F at h
* And then I did it again
* So, I want to approximate big F at 2h
* Well that's big F at h approximately
* I mean I'm writing equals but I really mean approximately
* Big F of h plus h times the derivative of big F at h, right
* I start at F of h and I'm going to wiggle over by h and the derivative is encoding at least approximately, how much the output should change for a given input change
* This is what I get by doing another linear approximation
* But now I've already got an approximation for big f at h
* It's h times f of zero
* So I'll use that for my value of big F at h
* H times f of 0 plus h times
* And I know F prime of h
* I know big F's derivative is little f
* So I can use that here
* So this is just little f
* At h, so this is an approximation for big F at 2 h
* And then I did it a third time
* So then this is the method of Euler, right
* I want to approximate big F at 3 h
* Well that'll be big F at 2 h, plus how much I wiggled by, which is h times the derivative ff big F at 2 h
* And what do I know
* Well, I've already got an approximation for big F at 2 h, it's right here
* So, it's h times little f of 0 plus h times little f of h plus h times, and now what's my derivative of big F at 2 h
* Well, big F's derivative is little f
* So I can use that here
* This will be little f at 2 h
* And I just keep on going
* I want to approximate big F at 10 h, right
* I just be repeating this process
* It'll be h times f of 0 plus h times f of h
* Plus h times f of 2h, and it will keep on going until I get to h times f of 9h
* Now, what does that look like
* This looks like a Riemann Sum, right, and I would want to choose h to be very small
* So, really, if I wanted to approximate big F of x using the method of Euler I'd be using smaller and smaller values of h and calculating it like this, and what would I be calculating
* I'd just be calculating the integral from 0 to x of my function, right, of little f of td, dt
* And what do I know about accumulation functions
* Well, I know that the derivative of the accumulation function, right, is the original function
* And that's exactly what I want, right
* I mean, this is saying that the derivative of big F is little f
* So Euler's method amounts to calculating a Riemann's sum
* And Riemann's sum approximates an integral, the accumulation function, and the accumulation function is an antiderivative
* it all makes sense
* Right
* All of these things that appear different are really the same thing
* Euler's method then gives another perspective on why the fundamental theorem of calculus should be true.


--- SKIP ---: 02_in-what-way-is-summation-like-integration.en.srt


--- SKIP ---: 02_in-what-way-is-summation-like-integration.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_in-what-way-is-summation-like-integration.en_SENTbySENT.txt
* [MUSIC]
* I've been trying to sell you on an analogy
* The analogy is that integration is a whole lot like summation
* Now we've also seen the fundamental theorem of calculus, and the fundamental theorem of calculus tells us that integration practically amounts to antidifferentiation
* So how does the fundamental theorem of calculus fit into this analogy
* Well here's the analogy square
* I've got integrating and differentiating
* And integrating is like summing
* So what's the thing that's like differentiating but for the discrete world
* I'm claiming it's differencing
* Now how so
* Well, let's suppose that I've got a list of numbers
* Made my list of numbers is something easy like one, two, three, four, five, it could be more creative
* But let's suppose this is my list of numbers
* The accumulation function just amounts to adding up those numbers
* So in this case, it'd be 0 plus 1, 1 plus 2, 3 plus 3, 6 plus 4, 10 plus 5, and so forth
* The difference operator, it's like differentiation, but the difference operator amounts to writing out a new list
* The list of differences between success of numbers
* So in this case if I just had this list of numbers, I could write down the differences between the subsequent numbers in that list
* 1 minus 0 is 1, 3 minus 1 is 2, six minus 3 is 3, 10 minus 6 is 4, 15 minus 10 is 5, and so forth
* Now if I were to look at the list of differences in the list of the accumulation function, I'd get back the original list that I started with
* It's really worth repeating
* Right
* Taking differences between the sum of the first k numbers in my original list and the sum of the first k minus 1 numbers in my original list
* Just gives me back my original list of numbers
* And this is an analogous to the statement from calculus
* That if I take the derivative of the accumulation function, I give back the original function
* Mathematics isn't just about isolated facts, It's really about analogies between ideas
* It's just like in literature where metaphor plays such an important role.


--- SKIP ---: 03_what-is-the-sum-of-n-4-for-n-1-to-n-k.en.srt


--- SKIP ---: 03_what-is-the-sum-of-n-4-for-n-1-to-n-k.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-sum-of-n-4-for-n-1-to-n-k.en_SENTbySENT.txt
* [MUSIC]
* Let's find the sum of the 4th powers
* In particular, I want to calculate the sum, n goes from 1 to k, of n to the 4th
* Playing with this analogy, I could think about this problem the same way that I'd approach an integration problem
* I should try to antidifference n to the 4th
* I should try to find a list of numbers, whose successive differences are n to the fourth, just try to find a list of numbers whose differences are n to the 4th
* Let's just try to find some lists of numbers and their differences
* So as a first example let's take a look at say n to the 5th, and let's look at the 5th power
* So 0 the 5th is 0, 1 to the 5th is 1, 2 to the 5th is 32, 3 to the 5th is 243, 4 to the 5th is the same as 2 to the tenth that's 1024
* Five to the 5th is 3125 and so on
* So that's just lists of of 5th powers
* Now, let's try to find the differences between subsequent numbers in this list
* So the difference between 1 and 0 is 1
* The difference between 32 and 1 is 31
* The difference between 243 and 32 is 211
* The difference between 1,024 and 243 is 781
* And the difference between 1,024 and 3,125 is 2101 and so forth
* Now it's maybe not so helpful just to see specific numbers
* Let's try to write down a formula for this
* So I'll write the differences, between the 5th powers
* Well that's n to the 5th minus the previous 5th power, so minus n minus 1 to the 4th
* And then I could expand this out
* I could take n to 5th minus this thing expanded and I'd get 5 n to the 4th is the n to the 5th will cancel minus 10 n cubed plus 10 n squared minus 5 n plus 1
* Right, and the plus 1 comes from subtracting a minus 1 to the 5th
* Okay, so that formula there gives these green numbers, it's the differences in the 5th powers
* I'm going to play the same kind of game for a different list of numbers
* Let's try to find the differences in the list of say 4th powers, well that will be the 4th power of n, minus the fourth power of the pervious number of n minus 1
* And again I can expand this out and n to the 4th minus, there's an n to the fourth that cancels
* So the highest power that survives is an n cubed term with a coefficient of 4 minus 6 n squared plus 4 n minus 1
* So this formula tells me the differences between subsequent 4th powers
* Now I want to combine those, to get somehting with a difference of n to the 4th
* Okay, but how am I going to do that
* Well, here's something I could do to make it a little bit easier to see what's going on
* Instead of looking at differences between 5th powers, I can look at the differences between 1 5th of 5th power
* So I, that is the effect of dividing all these numbers by five
* And since all these coefficients except for the last one are multiples of five, that'll make that formula look a little bit nicer
* And I could do the same thing with with n to the 4th
* Instead of looking at 4th powers, I could look at 1 quarter of fourth powers, and I'd have the effect of dividing all of these coefficients by by four
* Let me just write down you know, what, what we've got here, kind of summarize the resulting formulas
* So, the differences between n to the 5th over 5, well, according to this that will be n to the 4th minus 2 n cubed plus 2 n squared minus n plus a 5th
* And I get a similar kind of formula for looking at differences of n to the 4th over 4
* It's this divided by 4 and that will give me an n, cubed minus 3 halves and squared plus n minus a quarter
* Well, let's just try to combine those two
* But how, exactly, do I want to combine them
* Well, the deal is that I've got an n to he 4th here, and that's really what I want at the end of this process
* I want something with the differences n to the 4th, because I'm trying to antidifference n to the 4th
* And I've got a minus 2n cubed
* And I've just got an n cubed here
* So if I took this and added two copies of this, I'd be in pretty good shape
* So what would I get in that case
* I'll be looking at the differences of n to the 5th over 5 plus two copies of n to the 4th over 4
* And that would give me an n to the 4th
* The n cubed term would go away
* I'd get a minus n squared, because I've got a 2n squared minus two copies of three halves n squared
* And then I get a plus n, because I've got minus n plus two copies of n
* And then a 5th minus 2 copies of a 4th will give me minus 3 tenths
* I could try to get rid of that n squared term by adding up on the differences of n cubed
* Why does that work
* Well, if you calculate the differences for the list of numbers n cubed over 3
* you end up getting, n squared minus n, plus a third
* So, if I take this and add this, that'll get rid of this n squared term
* Right
* So I'm going to look at the differences of n to the 5th over 5 plus two copies of n to the 4th over 4 plus n cubed over 3, and I'm left with an n to the fourth
* No more n squared anymore
* The plus n minus n also cancels, and then I've got minus three tenths plus a third, and that ends up being plus 1 30th
* Now I can get rid of the 1 over 30th term
* Now how do I do that
* Well, look at the differences of the list of numbers n over 30, and that's just 1 30th, right
* This list of numbers, each number in that list differs by 1 30th compared to the previous number in the list
* So if I take this and subtract n over 30, then the differences in that list are exactly n to the 4th, right
* By which I mean that I take d of n to the 5th over 5 plus 2 n to the 4th over 4 plus n to the 3rd over 3 minus n over 30
* And then I got n to the 4th plus a 30th minus a 30th and what I'm left with is just n to the 4th
* So in light of all of this, What do I know right know
* Taking differences between a list of numbers, and this accumulation function, adding up the first k numbers on the list
* Those are inverse operations, right
* This is the discreet version of the fundamental theorem of calculus
* In this particular case, the differences between these numbers give you the 4th power
* So if I sum the 4th powers I get this, at least up to some constant
* Now I just have to worry about that constant
* But then constant is zero, we can check it
* Here's a sum for n equals 1 just to 1 of n to the 4th
* And I can just plug in any value of K that I like, since this constant C doesn't depend upon K
* I can figure out what that constant is by looking at when K equals 1
* So, this is just 1
* But on the other side, I've got what I get when I plug in k equals 1
* Which is, 1 5th plus 2 times the 4th, plus, you know, 1 to the 3rd over 3
* So plus a 3rd minus a 30th, plus that constant c that doesn't depend upon k at all
* But a 5th plus a half plus a third minus a 30th is 1
* So I've got 1 equals 1 plus C
* So that means C equals 0
* And that tells me what the formula then, for the sum of the 4fourh powers is
* It's just this, and that constant is just 0
* This whole process is really analogous to the fundamental theorem of calculus and how we use it, right
* In this example I'm antidifferencing n to the 4th in order to sum n to the 4th
* In the same way that if I were to antidifferentiate x to the fourth, that would help me to integrate x to the 4th, right
* This analogy runs really deep.


--- SKIP ---: 04_physically-why-is-the-fundamental-theorem-of-calculus-true.en.srt


--- SKIP ---: 04_physically-why-is-the-fundamental-theorem-of-calculus-true.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_physically-why-is-the-fundamental-theorem-of-calculus-true.en_SENTbySENT.txt
* [MUSIC]
* Let's think about the fundamental theorem of calculus physically
* Let's define the function v by the rule that v of t is my velocity at time t
* Physically, what does the accumulation function of velocity mean
* Well that accumulation function, remember, is say, the integral from 0 to b, of v of t dt
* And this is really the distance, that I've traveled from time 0 to time b
* This also makes sense when we think back to Riemann sums
* But what would the Riemann sum say
* if I think about how far I traveled over a short time period, say, between time zero and time h for some small number h, right
* How far did I travel during that time period
* Well, I traveled for that small time period h and I was traveling at a speed of, I mean, you know, a velocity at time zero, say, is a good approximation
* And I imagine my velocity didn't change very much during this time period
* So, that's a pretty good approximation for how much I traveled during the first h moments of my journey
* What about between time h and time 2h, right
* How far did I travel there
* Well, the time that elapsed was h units of time
* And how fast was I going
* Well, I could use v of h
* My velocity of time h as a good approximation for my velocity over that time period, right
* My velocity is not necessarily constant
* But this is standing in for a reasonable approximation and my velocity is not changing too rapidly
* All right
* This is how far I traveled, right
* Time times velocity is distance
* All right
* Now how far did I travel between, say time 2h and time 3h
* Well, again, how long was I traveling for h units of time
* And how fast was I going
* v 2h is a reasonable approximation for my velocity during that time period
* And of course this keeps on going, right
* But what do I get if I add all of these things up
* Right
* What I'm getting is a Riemann sum
* And if I keep on adding these things up until I get, you know, all the way to, to b, right
* What I'm writing down is the approximation for this interval of a particular Riemann sum which approximates this integral and in the limit as h goes to zero, that Riemann sum will compute this integral
* So, summarizing that, the accumulation function of velocity, is displacement
* And what's the derivative of displacement
* It's velocity, right
* The derivative of my accumulation function in this specific case where the accumulation function is the accumulation function for velocity, right, the derivative of that accumulation function is the thing that I'm integrating, velocity
* That's the fundamental theorem of calculus
* Or in symbols, you know, the accumulation function, which is[INAUDIBLE] displacement, is the interval from zero to b of my velocity
* And what I'm asking is, how is that changing, right
* If that's my displacement when I travel from times 0 to times b, right
* What is the derivative with respect to the time that I've been traveling
* The derivative of displacement is velocity
* So physically, differentiating the accumulation function of velocity is to differentiate displacement
* It's to ask for the rate of change in my position, which is velocity, which is the integrand
* It's the fundamental theorem of calculus just wrapped up in physical clothing.


--- SKIP ---: 05_what-is-d-da-integral-f-x-dx-from-x-a-to-x-b.en.srt


--- SKIP ---: 05_what-is-d-da-integral-f-x-dx-from-x-a-to-x-b.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_what-is-d-da-integral-f-x-dx-from-x-a-to-x-b.en_SENTbySENT.txt
* We've seen what happens when we differentiate the accumulation function
* That's the fundamental theorem of calculus
* If I take the derivative of the integral from a to b of f of x dx, well what do I get
* Well, it's just f
* Of b, right
* The rate of the change of the accumulation function is the functions value
* But, what would happen if I were to differentiate with respect to the left hand end point instead of with respect to the right hand end point
* By which I mean
* What's the derivative with respect to a of the integral from a to b of f of x dx
* Right
* What happens if instead of diferentiating with respect to the top end point, I'm diferentiating with respect to the bottom end point
* I'm asking how is this function as a function of a changing
* Let's think about the graph
* Let's draw my coordinate axes
* And I'll draw some random looking function
* And I'll pick some points a and b
* And the integral from a to b calculates the area in here
* And I want to know how does that integral change when I wiggle a
* I'm asking to differentiate the integral with respect to this
* Left-hand endpoint
* So let's wiggle the left-hand endpoint
* Let's move it over a little bit to a plus h
* I'm imagining h is very small
* Alright, and I want to know, how does the integral change
* Well the quantity that calculates the absolute change in the integral is this
* What's this thing here
* This is the integral from a plus h to b
* And this thing here is the integral from a to b, so this difference is telling me how the integral changes when I replace a by a plus h
* Now if you think about it, what this is really calculating is, you know, related to the integral from just a plus h, right
* This integral is calculating this area, and subtracting this larger area
* So the difference is really just this area in here between A and A+H but it comes with a negative sign because I'm subtracting this smaller area and I'm subtracting now this larger area
* So I've got this negative sign here
* Now this region, if h is small enough, is practically a rectangle, and it's practically a rectangle of width h and height let's say f of a
* So, that means that this difference is at least approximately just h times the function's value at a
* Now how does that help
* Remember what I'm trying to calculate
* I, I'm trying to differentiate the interval from a to be with respect to a
* That means I'm trying to take the limit of this difference quotient
* But the numerator here, we just saw, is approximately, negative h times f of a
* And that means in the limit I expect to get an answer of just negative f of a, alright, these hs will cancel in the limit, and that's exactly what I hope for, right
* The derivitive of the integral from a to b with respect to the left hand endpoint a is negative f of a
* So I can summarize this
* So I can summarize this
* The derivative with respect to a of the integral from a to b of f of x dx is negative f of a
* This fact coheres with a certain convention about integration
* The convention that we use is that if we integrate from a to b
* the function f of x dx that's negative the interval from b to a of f of x dx
* So if you integrate the wrong way, so to speak, we want to count that as negative area
* >> Now in light of this convention, what do we know
* >> So d da of the integral from a to b of f of x dx is d da of this, negative the integral from b to a of f of x dx
* But now this is the derivative of the top end point which is just the usual fundamental theorem of calculus
* So this is negative f of a
* So the upshot here is that differentiating the integral from a to b, with respect to the left hand or bottom end point, Is negative the function's value
* And that make sense because if you increase the left hand endpoint that decreases the area
* Alright, so it seems reasonable that a negative sign should be popping up there
* And the cool thing is that, that fact is cohering with a convention about integration
* That compared to integrating the usual way, if you integrate the wrong way you introduce a negative sign.


--- SKIP ---: 01_how-can-we-compute-more-antiderivatives.en.srt


--- SKIP ---: 01_how-can-we-compute-more-antiderivatives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-can-we-compute-more-antiderivatives.en_SENTbySENT.txt
* [MUSIC] When we first learned about definiteintegrals, we learned about them as limits of remindsums
* And in a few cases that definition wasgood enough
* We are able to use a complicated lookingsummation formula, and take a limit and end up evaluating a definiteintegral just with our bare hands
* But usually that was much too hard
* So we very quickly learned about thefundamental theorem of calculus
* That reduced evaluating definite integralsdown to finding anti derivatives
* Now it turns out that finding antiderivatives is also really hard to do
* So, at this point, what we need are somebetter techniques, or just heuristics for how tofind those anti-derivatives
* And a big one is called U-substitution ormaybe the substitution rule
* And what it really amounts to, is justrunning the Chain Rule in reverse
* And, if you think back to how many timeswe're using the chain rule, when we were differentiating,we were using it all the time
* Right, there was all kinds of differentiation problems that involved thechain rule
* Well, if the chain rule appears so oftenwhen we're differentiating, we're going to need some way of runningthat chain rule in reverse
* And, that's exactly what substitution willdo for us
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_how-does-the-chain-rule-help-with-antidifferentiation.en.srt


--- SKIP ---: 01_how-does-the-chain-rule-help-with-antidifferentiation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-does-the-chain-rule-help-with-antidifferentiation.en_SENTbySENT.txt
* [MUSIC]
* In order to integrate a complicated function, I really just want to antidifferentiate complicated functions
* For example, can I antidifferentiate x times sin of x squared dx
* And if you think back to when we were doing all our differentiation stuff, a big deal was the chain rule
* We were always using the chain rule in order to differentiate things
* So for this problem I might try to think in terms of the chain rule, right
* I know some function who's derivative is sin, minus cosine differentiates to sin
* But, and I want an x squared in there somehow, so I'll put in x squared there, and I'll see, is that an antiderivative of this
* Well, let's try it
* So if I differentiate this, what do I get
* Well the derivative of the outside function is sin, evaluated the inside function times the derivative of the inside function, which in this case is 2x
* And I see whoops, I'm off, right
* I didn't quite get an antiderivative
* I'm off by this factor of 2, so I can fix that, I'll just divide this by 2, which will have the effect of dividing that by 2, but then these 2s will cancel, and now I have found an antiderivative for x times sin of x squared
* And yeah, that works, but it was totally adhoc, I mean how did I know to divide by 2, I just guessed and fixed my guess
* Mathematics really shouldn't be seen as just a series of tricks, a big part of mathematics is systematizing those tricks, finding the patterns that unify, trick into a tool
* In this case, we really want to systematize applying the chain rule in reverse
* So this process of applying the chain rule in reverse, goes by the name u substitution
* It's also just called substitution, but I'm going to call it u substitution to emphasize the conventional name u
* That I'm going to use for the inside function when we're running the chain rule backwards
* This is, any how, all too abstract, let's just see this in action
* So I'm trying to anti differentiate x times sin of x squared dx
* And the trick here, is to give a name to the inside function in the chain rule, I'm going to call that u
* And I want the inside function to be x squared, so I'll say that u is x squared
* Well then, what's du
* Right, what's the differential of u
* Well, du over dx is the derivative, which is 2x, so du is 2x dx
* I know you might feel kind of bad, because well I don't really see a 2x dx, I only see an x dx, but this sort of method going to, guides us to do the right thing
* I'd like to have an 2x dx so I could put a 2 here, as long as I'm willing to put a 1 half on the outside
* It's like doing nothing
* But now I've got a 2x dx in the integrand, and that'll become my du
* So this antidifferentiation problem is the same as sin u du, and I've got to make sure to include that one half on the outside, but now I know an antiderivative for sin of u, right, it's negative cosine
* So I've got one half and then an anti-derivative of sin of u is negative cosin plus c
* But I don't want my answer to be in terms of u so I rewrite this as negative one half cosin of u, which is x squared plus c
* There's something to notice here
* I'm using differential with the chain rule so that dx is playing a crucial role
* You might have thought that I was just writing dx at the end of my integration problem out of habit or tradition but that dx is legitimately there
* That dx is managing the substitution for us
* Let's see why this work
* Every differentiation rule has a corresponding anti-differentiation rule, right
* Let's say that I want to anti-differentiate f prime of g of x times g prime of x
* Well, secretly I can recognize this is the derivative of f of g of x with respect to x
* But let's suppose that I start writing it down using this substitution framework
* So I'm making a substitution u
* Is g of x, and in that case du is the derivative of g dx
* So this antidifferentiation problem is the antidifferentiation problem f prime of u, and this now du
* But I know an antiderivative of a derivative is just the original function
* And in this case, u is g of x, so this is f of g of x
* I don't know, 'cuz I mean I can really see this working, you know the derivative of this composition is this, I mean it's just the chain rule
* We're going to see a ton more examples of this technique, and we're going to see that the hard part boils down to determining what to set u equal to
* But if you're ever wondering why does use substitution work, remember, it's just a luren neock, I mean use substition is luren neock, a chain rule but in reverse.


--- SKIP ---: 02_when-i-do-u-substitution-what-should-u-be.en.srt


--- SKIP ---: 02_when-i-do-u-substitution-what-should-u-be.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_when-i-do-u-substitution-what-should-u-be.en_SENTbySENT.txt
* [MUSIC]
* Integrating is at its heart a creative process, right
* Differentiating is just applying a bunch of rules carefully but just applying the rules
* Integrating usually requires some sort of creative flash of insight
* For u-substitution in particular, there's a ton of creativity in picking the best u
* So if you're looking for how to pick u, right, what should you make u equal for your u substitution
* Well, I'd look for things that you can grab as du, right
* Try to find pieces of the integrand that look like the derivative of something
* Well, let's try that
* So, let's try the anti-differentiate, say, x over the square root of 4 minus 9x squared dx
* So I can see that x squared in the denominator and I can see the x in the numerator
* And I'm thinking, ahh, I put the x squared in the u so that the du will grab the x in the numerator
* Let's go
* So I proposed that u, should be 4 minus 9x squared
* And then what's du
* Well, calculate the differential of u by taking the derivative here and the derivative 4 is 0
* But derivative negative 9x squared is negative 18x for the dx
* And now you're thinking, oh, this is terrible
* I don't see a negative 18 anywhere in this problem
* But I can introduce one
* I can make a negative 18 there as long as I cancel it with 1 over negative 18 there
* So I've done nothing to the anti-differentiation problem
* I haven't changed the problem at all, this is just multiplying by 1, they cancel
* But I've now got a du in my integrand
* So, let's make that substitution
* This is now, well, the numerator is now just du, and the denominator is the square root of u
* Now I want to make sure to include the 1 over negative 18 in front
* And that integral I can do with the power rule
* So this is, still 1 over negative 18, and what's an anti-derivative of this
* Well this is the anti-derivative of u to the negative 1 half power, but that is exactly the sort of thing I can do with the power rule, right, so this is 1 over negative 18
* Times by the power rule this is u to the 1 half over 1 half plus C, which I could rewrite a little bit more nicely, dividing by 1 half is the same as multiplying by 2, so this is negative 1 9th the square root of u plus C
* Now I'll rewrite that in terms of x
* So, in terms of x, this is, well remember, u is 4 minus 9x squared, so this is negative 1 9th the square root of 4 minus 9x squared, is what u is, plus C
* So I found an anti-derivative of x over the square root of 4 minus 9x squared
* I should warn you here, something that makes anti-differentiations so hard is that similar looking integration problems can have totally different looking answers
* For example, we just saw how to anti-differentiate x over the square root of 4 minus 9x squared, we got this
* How do we anti-differentiate this very similar looking function 1 over the square root of 4 minus 9x squared, the only difference is that I got rid of the x and the numerator
* But that's a big difference
* That x and the numerator was facilitating the substitution
* I needed that x there in order to have something to fit into the du
* Without that x there, what am I supposed to do
* Well, I could try to factor out 2 from the denominator here
* I mean, I'm not going to make a substitution yet, I'm just going to try to rewrite the integrand, so if I factor out a 2 this is the anti-derivative of 1 over 2, times the square root of 1 minus 9 over 4x squared dx
* And you might be wondering, you know, why is there a 2 on the outside and a 4 on the inside because the square root of 4 is 2
* My plan here is to make the denominator look like the square root of, 1 minus something squared
* Rewrite this, integral again as 1 over 2, the square root of 1 minus, and instead of 9 quarters x squared, I'll write it as 3 halves x squared dx
* And now I'll make a u-substitution
* I'll say u equals to this 3 halves x
* So, 3 halves x so that du is 3 halves dx
* And now you're going to complain
* Well, I don't see a 3 halves dx
* Then, you do have a 1 half dx here, and I can manufacture a 3 here as long as I'm willing to put a 1 3rd on the outside that doesn't affect anything
* But now I've got a 3 dx over 2, so I've got a du
* 1 over the square root of 1 minus u squared
* Let's write that down
* So this whole thing is 1 3rdthe anti-derivative of 1 over the square root of 1 minus, this is u squared, and 3 halves dx is du
* Why is this a good idea
* Well this is a good idea because this is now 1 3rd, and I know something which differentiates to this
* Arc sin u, alright, is the anti-derivative of this
* To finish this, I'll replace u by 3 halves x
* So I get that this is 1 3rd arcsin of 3 halves x plus C
* Alright
* This is just 'cuz you is 3 halves x
* Look at how different this experience was
* Compared to that first integral that we did
* Just showed that the anti-derivative of 1 over the square root of 4 minus 9x squared is 1 3rd the arcsin of 3 halves x plus C
* And that looks totally different from anti-differentiating x over the square root of 4 minus 9x squared, right
* I didn't need any inverse trig functions there
* You know even though the integrands look relatively similar, right
* I'm mean I'm just missing an x but it totally transforms the answer
* Picking the best u for your u-substitutions really is an art form
* This is why people have integration bees just like they have spelling bees, right
* There's a real creativity to integrating.


--- SKIP ---: 03_how-should-i-handle-the-endpoints-when-doing-u-substitution.en.srt


--- SKIP ---: 03_how-should-i-handle-the-endpoints-when-doing-u-substitution.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-should-i-handle-the-endpoints-when-doing-u-substitution.en_SENTbySENT.txt
* [MUSIC]
* I'm mostly selling you on the idea of u-substitution, as a way to find anti-derivatives
* But anti-differentiation is just a means to an end
* The real goal, at this point in the course, is evaluating definite integrals
* Well, here's an example of a definite integral
* Let's evaluate the integral of 2x times x squared plus 1 to the 3rd power dx
* As x goes from 0 to 2
* We can do it with u-substitution
* The substitution that I want to make is u equals x squared plus 1, and in that case du, what's the derivative of this, is 2x dx
* And that's great 'cuz I've got a 2x dx right there
* So, this integration problem becomes the integral x goes from 0 to 2
* but what is the integrand now
* It's u cube du and I know the anti-derivative of u cube is u to the forth over 4 and I want to make sure that I evaluate this when x equals to 0
* And 2
* Now we replace u by x squared plus 1
* So this is x squared plus 1 to the 4th, over 4
* And I want to evaluate at 0 and 2
* Now we plug in x equals 2, and x equals 0, and take the difference
* Okay, well when I plug in 2, I get 2 squared plus 1 to the 4th over 4
* And when I plug in 0, I get 0 squared plus 1 to the 4th over 4
* What's 2 squared plus 1
* That's 5 to the 4th over 4 and that's 1 to the 4th, which is just 1
* A quarter
* And, now I got think about what's 5 to the 4th
* Well that's 25 times 25
* Tha'ts 625 over 4 minus 1 over 4
* And, now I can combine these into a single fraction, that's 624 over 4
* And that I can simplify a bit
* That's 156
* We did it
* But I could've finished this problem off in a slightly different but equivalent way
* Let's back up, I'll get rid of this, and let's suppose that I didn't go down this path but I just stopped here
* The problem is that my endpoints are in terms of x but my integrand now is in terms of u
* So I'm just going to change those endpoints
* So instead I'll see that, that integration problem is the same as the integral of u cubed du
* And when x is equal to 0, u is 1 and when x is equal to 2, u is 2 squared plus 1, which is 5
* So if I change the endpoint to be in term of u, then I don't have to go back to x
* So again I know the anti-derivative, it's u to the 4th over 4 and I'm evaluating it
* At 5 and 1 in term of u and taking the difference so when I plug in the 5, I just get 5 to the 4th over 4 and when I plug in 1 I just get 1 to the 4th over 4
* And 5 to the 4th is 25 squared which is 625 over 4
* And this is now the same as before
* Minus a quarter and, just like before, this ends up being 156
* Let's summarize these two different approaches
* The first time I went through this problem, I found the antiderivative in terms of x, alright
* I wanted to integrate this and I found an antidirivitive and I just evaluated it at b and a and took the difference
* In the second method, instead of finding the antidirivitive in terms of x, I change the endpoints to make the endpoints be in terms of u
* So, I took this original problem and after making the substitution u equals g of x, then I rewrote the endpoints to go from g of a to g of b in terms of u
* And then I found an antiderivative of f prime u du and now f of u and I evaluated that at g of b and g of a and took the difference
* At the end of it I'm doing the same calculation
* In both cases I'm calculating, you know, f of g of b, f of g of b, and I'm subtracting f of g of a, f of g of a, but I"m setting it up slightly differently
* In the first case I'm finding the anti-derivative in terms of x, and in the second case, I'm changing the bounds on the integral to be in terms of u.


--- SKIP ---: 04_might-i-want-to-do-u-substitution-more-than-once.en.srt


--- SKIP ---: 04_might-i-want-to-do-u-substitution-more-than-once.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_might-i-want-to-do-u-substitution-more-than-once.en_SENTbySENT.txt
* [MUSIC]
* Sometimes you might want to do u substitution more than once
* Imagine that you've got something just really terrible-looking, like trying to find an anti-derivative of this, negative 2 cosine x sin x
* Cosine, cosine squared x plus 1 dx, right
* Predefine an anti-derivative of this
* We can
* You might be thinking ugh, if I could just get rid of that cosine squared term
* Well to do that, let's say u, equaled a cosine x
* Let's write that down, so the substitution that I'm proposing, is u equals cosine x
* And that'll be good cause I've got a cosine x and a cosine squared x here and I can also see du in this intergrand, right
* What's du
* Well it's the differential of u
* What's the derivative of cosine
* It's minus sine, so the differential, then includes this dx, right
* Du is negative sine x dx
* Well let's make the substitution
* Let's see how it works out
* So this, anti-derivative problem is now, with a minus sin X DX, or become the DU but I'm left with a two cos X as U, the minus two and the sin X and the DX is going to be in the DU, but I got a cos sign, cos sign squared X is U squared plus one and everything else that's left over Is in this du
* Now I'll make another substitution
* I'll make v equal u squared plus 1
* Well let's write that down
* So the substitution that I'm proposing is v equals u squared plus 1
* And that's a good choice, because I've got a U squared plus 1 there, and I can see that the derivative of this appears here so this will grab quite a bit of the integrant
* Okay, let's site then the differential, DV in that case is the derivative to you DU so DV is 2U, DU and now I can write down what this anti-differentiation problem becomes 2u du ends up being the the dv
* And I've got a cosine of just v now
* Now I can anti-differentiate that no problem
* Right
* The anti-derivative of cosine v dv
* Is just, sine v
* I'll write plus c, right
* because the derivative of sine v is cosine v with respect to v, but probably the grader is not going to be too impressed with me if I express my answer in terms of a substitution that I just made up, right
* I shouldn't write down the answer in terms of v, I should be writing down the answer in terms of x
* Remember from before that v is u squared plus 1, so I can subsitute that in here, and instead of writing down sin of v plus C, I'll write down sin of u squared plus 1, and then I'll include that plus C
* Da, my answer is in terms of u, but the original question was in terms of x
* Let's remember what u was
* u was cosine x so I can make that final substitution back in here
* So instead of writing sine of u squared plus 1
* I'll write down sine of cosine squared x, because u is cosine x
* Plus 1, plus C
* So what am I claiming
* The original question was asking for an anti derivative of this crazy expression, and what I'm claiming, then, is that the anti derivative of this is sign of cosign squared X plus 1 plus C
* So we did it
* And I bet that you can imagine some truly terrible anti differentiation problems that involved substitutions within substitutions within substitutions
* Part of the problem with this calculus course, I suppose with calculus courses generally, is that the courses are sort of based on this idea of the instructor just providing problems to you
* Here's the challenge
* Invent some difficult antiderivative problems for yourself
* By cooking up your own antidifferentiation problems, you'll gain some insight into what makes antidifferentiation problems easy, or what makes antidifferentiation problems hard.


--- SKIP ---: 01_what-is-the-integral-of-dx-x-2-4x-7.en.srt


--- SKIP ---: 01_what-is-the-integral-of-dx-x-2-4x-7.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-the-integral-of-dx-x-2-4x-7.en_SENTbySENT.txt
* [MUSIC]
* We already know how to integrate
* And by integrate, I mean, anti-differentiate some fractions
* For instance, here is an anti-differentiation problem
* Let's anti-differentiate 4x plus 3 dx
* And I can do that with a u substitution
* we have to choose what u should be equal to
* I'll set u equal 4x plus 3, so that du is, what's the derivative of this, is just 4, and then the differential of u is 4dx
* Now, I don't see a 4dx in my integrand here, but I can manufacture a 4dx
* If I multiply by 1 4th and 4
* That's like doing nothing, right
* Those cancel, but now I've got a 4dx in my integrand
* So, the original anti-differentiation problem is 1 quarter of anti-derivative 1 over u du
* And I know an anti-derivative 1 over u du
* Alright
* It's log of the absolute value of u plus c
* And, I've got to make sure to include that constant on the outside of 1 quarter
* But I don't want to write down my answer in terms of u, I'd like my answer to be in terms of x
* Right
* I'm asking for an anti-derivative 1 over 4x plus 3, not somethings in terms of u
* So, I'll just replace u with what it's equal to
* So, altogether, I got 1 quarter log of the absolute value of 4x plus 3, plus c
* So, there's my anti-derivative of this fraction
* I also know how to anti-differentiate some reciprocals of a quadratic polynomials
* At least, here's a special case what's the anti-derivative 1 over x squared plus one dx
* Well, if you remember back, I know a function whose derivative is this
* Alright
* It's the inverse tangent function arctan
* So, at least I know how to anti-differentiate the reciporical of this particular quadratic polynomial
* Wonderfully, I can use that special case, the anti-derivative of 1 over x squared plus 1, to anti-differentiate the reciporicals of of other quadratic polynomials
* For example, can we find an anti-derivative of 1 over x squared plus 4x plus 7 dx
* Can you think of a function whose derivative is this
* I can't come off with an anti-derivative just off the top of my head
* But, I've got a trick up my sleeve, the trick is completing the square
* What that means is that I'm going to rewrite x squared plus 4x plus 7 and I want it to look more like the example I know, right
* The example that I know is this thing
* I know that the anti-derivative of 1 over something squared plus something
* So, I'm just trying to rewrite this quadratic polynomial, so it looks more like that
* So, I'm going to try to rewrite it, so it looks like x plus, you know, something squared plus plus something
* The trouble is how to find the blue and the red somethings
* Let's do some algebra
* So, I'm going to write this as x plus, instead of just a squiggle, I'll call it a,squared plus some other constant b
* And if I expand that out, what do I get
* Well, I get x squared plus a cross term 2ax, plus I got an a squared term
* and then a b left over that I add on
* So, I'm trying to make this quadratic polynomial look like this
* And the only term that I've got with an x here is this 2a should be 4
* Alright
* So, let me write that down
* So, 2a is equal to 4
* And that tells me what a is
* a should be 2
* I'll finish by finding b
* So, I've got x plus 2 squared plus some b is equal to x squared plus 4x plus 7
* x plus 2 squared is x squared plus 4x plus 2 squared, which is 4, plus b, is suppose to be equal to this
* And, that's tells me what b had better be
* Right
* I've got 4x and I've got an x squared, then I've got a 4 plus b is 7
* Alright, so 4 plus b is 7, so b is 3
* Let's summarize
* So, what I've got here is that x squared plus 4x plus 7 can instead be written as x plus, in this case, 2 squared plus, and then for b, I've got 3
* So, I've rewritten this quadratic polynomial as a linear term squared plus some constant
* Now, I'll use that fact in the integration problem
* Right, the original integral is 1 over x squared plus 4x plus 7
* And instead of doing that integral, I can do the integral of 1 over this equivalent thing, x plus 2 squared plus 3 dx
* That still doesn't exactly look like the anti-derivative problem that resulted in arctan
* Remember, the anti-derivative here that gave us arctan x has a plus one, but the thing we're looking at here has a plus 3
* So, I can fix that
* I can get a constant here
* I can factor out something
* I'll factor out a third and that will be integral of 1 over 1 over 3 times x plus 2 squared plus 1 dx, right
* This is the same thing as this, because this 3 times a third is just the 1 here that I haven't written
* And 3 times plus 1 gives me this plus 3
* I'll make a substitution
* Now, I'll make this substitution
* you might think that I could use a substitution where u equals 1 3rd x plus 2 squared
* But then, I need an x in the numerator, right
* So instead, I'm going to make it slowly different substitution, I'm just going to make this looks like u squared
* So, I'll set u to be 1 over the square root of 3 times x plus 2
* So now, this denominator looks like 1 over u squared plus 1
* And in that case, what's du
* Well, that means du is 1 over the square root of 3 dx
* Now, what does the integral become
* You might be concerned that you don't see 1 over the square root of 3 dx here, but I can manufacture one of those
* If I make this into the 1 over the square root of 3, I can put a 1 over the square root of 3 here, without affecting anything
* And now, I've got a du
* So, this anti-differentiation problem becomes 1 over the square root of 3
* The anti derivative of 1 over this, here, is u squared plus 1
* And this 1 over the square root of 3 dx, that is now my du
* And that's arctan
* So, this is one over the square root of 3
* Anti-derivative of this is arctan u plus c
* Now, I just have to replace that u with its value in terms of x
* So, this is 1 over the square root of 3 arctan, and u here is this, so I'll write that in here for u, 1 over the square root of 3 times x plus 2 plus C
* And now, I'm in a position to state a conclusion
* The original question was asking for an anti-derivative of 1 over x squared plus 4x plus 7, and we found it
* It's 1 over the square root of 3 times arctan, 1 over the square root of 3 times x plus two, plus some constant
* So, we've anti-differentiated this reciprocal of this quadratic polynomial
* Well, fantastic, and the same trick works in other situations as well
* Really, anytime you've been handed a quadratic polynomial but you wish you'd been given something squared plus a number, you should try completing the square
* [BLANK_AUDIO]


--- SKIP ---: 02_what-is-the-integral-of-x-10-x-1-10-dx-from-x-0-to-x-1.en.srt


--- SKIP ---: 02_what-is-the-integral-of-x-10-x-1-10-dx-from-x-0-to-x-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-integral-of-x-10-x-1-10-dx-from-x-0-to-x-1.en_SENTbySENT.txt
* [MUSIC]
* Even integrating something as "easy" as a polynomial can be rather surprising
* Let's integrate from x equals 0 to 1 just the polynomial x plus 10 times x minus 1 to the 10th power dx
* So there's some integration problem, just an integration problem for a polynomial
* Your first inclination might be oh, I know what to do, just have no fear
* I'll just expand everything in sight
* So, we've got x plus 10, times x minus 1, to the 10th
* Which you could expand by, you know the binomial theorem if you want
* We're going to get x to the 11th minus 55 x to the 9th
* Plus 330 x to the 8th minus 990 x to the 7th plus 1,848 times x to the 6th mi, I mean this is ridiculous
* Arr, yeah, so I mean yeah, you, you could do that
* You could just expand everything out
* But there's a better way right
* We can make use of U-substitution
* Yeah, we're not going to do that, let's do something else
* So instead let's set u equal x minus 1, and I could solve this for x
* That means that x is u plus 1
* All right, if I just add 1 to both sides
* And I could make this substitution in this problem
* So this integral from x goes from 0 to 1, is, what's x plus 10 if x is u plus 1
* I could write u plus 1 plus 10
* And whats x minus one, thats just u to the tenth power, and whats dx well if u is x du is dx
* So its the same as trying to do this integration problem
* In some text books this technique of startign with the use of substitution but then solving for x
* This is sometimes called back substitution
* regardless of the name, let's proceed
* So this is the integral, x goes from 0 to 1 of u plus 11 times u to the 10th du
* I could expand this, and that's the same as the Integral x goes from zero to one of u to the 11th
* Plus 11 u to the 10th du
* But this is just asking me to anti differentiate a polynomial which I can definitely do
* Alright
* This is u to the 12 over 12
* Plus, what's an anti-derivative of 11 u to the 10th, it's just u to the 11th
* But now I've got a little bit of an issue, right
* I've got x going from 0 to 1
* So here is u going from what to what
* Yeah, so how do we deal with those end points
* Well, when x is 0, u is minus 1
* So I'll put a minus 1 there
* And when x is 1, u is 0
* So I'll put a zero there
* And now, this is just as easy as plugging in zero, plugging in minus 1, and taking the difference
* So what do I get when I plug in zero
* I just get zero
* And what do I get when I plug in minus 1
* Well, I get minus 1 to the 12th over 12
* Plus minus 1 to the 11th
* Alright minus 1 to the 12 is just 1
* So this is 1 12th
* And minus 1 to the 11th well that's negative 1
* So I've got 0 minus what's this a 12 minus one that's negative 11th 12th
* But at 0 minus negative 11, 12ths
* So the integral is 11, 12ths
* So the calculation turned out to be pretty nice
* I mean 11 12ths, isn't a particularly difficult fraction to come up with
* The crazy thing to think about is that we could have approached this just by expanding everything in sight
* Yeah, I really could have expanded this thing out, and then just started anti-differentiating you know
* And finding this really was you know, I don't know x to the 12th over 12, minus I think it's 11 halves, x to the tenth plus a hundered and ten thirds x to the ninth right
* And it would keep on goign and id just evaluate that, exit one exit zero and take the differenc i mean i really could have done this by expanding
* And somehow that would of ended up giving me the same answer right, of eleven twelths
* Except that had I gone down that path, I would have been certain to have walked right into an arithmetic error
* The world of mathematical solutions is not divided into correct solutions and incorrect solutions
* It's really more subtle than that
* Mathematical solutions come in a ton of varieties
* Right, there's easy solutions and hard solutions
* There's solutions that are defending you against arithmetic errors
* And then there's solutions that are just walking you right into an arithmetic mess
* The fun of u substitution isn't just being able to do integrals, it's being able to do integrals in an efficient way that protects you from those arithmetic errors.


--- SKIP ---: 03_what-is-the-integral-of-x-x-1-1-3-dx.en.srt


--- SKIP ---: 03_what-is-the-integral-of-x-x-1-1-3-dx.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-integral-of-x-x-1-1-3-dx.en_SENTbySENT.txt
* [MUSIC] Generally speaking, anti-differentiating things with radicals is difficult
* For example, let's try to find an anti-derivative of, x over the cube root of x plus 1 dx right
* Let's try to anti-differentiate this
* Can I make a substitution to improve the integrand
* So what substitution do I want to make
* Well, I really have some choices, I mean, one thing I could do is I could make ux plus 1 and in that case, du is just dx
* And if u is x plus 1, then x is u minus 1, and I can then rewrite this anti-differentiation problem
* instead this becomes the anti-derivative of that x, but u minus 1 still cube root, but instead of x plus 1, it's now of u and the dx becomes du
* And I, I could actually do this, but I'm not going to head down that path
* Instead, I want to show you a trick by which you can get rid of the radical all together
* So instead let's set u, just to grab the whole denominator
* So u will be the cube root of x plus 1 and in that case, u cubed is x plus 1
* Or, in other words, x is u cubed minus 1
* And that tells me what dx is
* In that case, dx is 3u squared du
* Now I could make this substitution
* This transforms this integration problem to, the anti-derivative of x now becomes u-cubed minus 1
* The whole denominator just becomes u
* And then the dx here is now a 3u squared du, so I'll write 3u squared du
* And that's just a polynomial
* So I'll simplify this a bit, this is the anti-derivative of, what is this here, u cubed over u times 3u squared, that's 3u to the 4th minus 1 over u times 3u squared that's minus 3u, du
* And this, this is just a polynomial, so I can anti-differentiate this very quickly
* This anti-derivative is 3 5ths u to the 5th, minus 3 halves u squared plus C
* Now, we'll just replace u with what it equals in terms of x
* So u, remember, is the cube root of x plus 1, so putting that in here, I get 3 5ths, instead of u it's x plus 1 to the 1 3rd to the 5th
* So to the 5 3rds power, minus 3 halves x plus 1 to the 1 3rd squared, which is to the 2 3rds power plus C
* To make it easy to talk about this particular technique, it has a name
* The rationalizing substitution
* The original problem had a cube root in it, but I made a substitution to get rid of the radical, a rationalizing
* A challenge when doing u substitutions is that there really are multiple paths that you can take to the correct answer
* It's not even apparent how successful a particular substitution might be until after you've started applying it, right
* You have to take that first bite before you realize whether or not you're eating food.


--- SKIP ---: 04_what-is-the-integral-of-dx-1-cos-x.en.srt


--- SKIP ---: 04_what-is-the-integral-of-dx-1-cos-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-is-the-integral-of-dx-1-cos-x.en_SENTbySENT.txt
* [MUSIC]
* Sometimes the best substitution to make isn't even visible until after we've messed around with the integrand some how
* For example, what's the antiderivative of 1 over 1 plus cosine x
* Dx, what can you do
* your first move might be to try the substitution u equals cosine x, which case du is negative sine x dx, but there's no visible sine x in the integrand
* Well, since we're talking about invisible substitutions, we should try to mess around with the integrand
* Instead of doing that, let's try a different trick
* Let's try to multiply 1 over 1 plus cosine x by 1 minus cosine x divided by 1 minus cosine x
* This doesn't change the integrand at all, because this is just 1
* This trick makes a hitherto invisible substitution visible
* I'm getting ahead of myself a little bit
* Let's first apply a trig identity
* Oh, this is 1 minus cosine x in the numerator divided by, that's 1 minus cosine squared x, and then the trig identity is that 1 minus cosine squared x, well that's sine squared x
* So now I want to antidifferentiate 1 minus cosine x over sine squared x dx
* Well even that isn't so great
* Let's split it up
* Well then I get, that this is antiderivative 1 over sine squared x dx minus the antiderivative of cosine x over sine squared x dx
* Now that first integral is one that I can do
* Rewrite it as the antiderivative of cosecant squared x
* You know, I just have to think, do I know any function whose derivative is cosecant squared
* Yes, negative cotangent is an antiderivative of cosecant squared, of of x
* What about that other intergral
* Well I could read this as cotangent times cosecant and just recognize the antiderivative that way
* But to demonstrate the technique I can also apply u substitution to that antidifferentiation problem so let's let u equal sine x, and in that case, du is cosine x dx, which is great, because that's the numerator there
* So this this antidifferentiation problem becomes what
* This is the antiderivative of du over u squared
* And I just gotta think, how do I, antidifferentiate u to the negative second power
* Well that, is by the power rule plus1 over u plus c
* Alright, If I differentiate one over u, that gives me negative 1 over u squared
* Okay, but I don't want my answer to be in terms of u, right, I want my answer to be in terms of x
* So this is negative cotangent x plus, what's 1 over u, well that's 1 over sine x which, if I wanted to, I could write as cosecant x plus C
* Let's put it all together
* So what I'm claiming here is that the antiderivative of 1 over 1 plus cosine x dx is negative cotangent plus cosecant, plus some constant
* If you have it already, I hope you're getting the idea that there's some really clever things that you can try to make these substitutions work.


--- SKIP ---: 01_what-is-d-dx-integral-sin-t-dt-from-t-0-to-t-x-2.en.srt


--- SKIP ---: 01_what-is-d-dx-integral-sin-t-dt-from-t-0-to-t-x-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-d-dx-integral-sin-t-dt-from-t-0-to-t-x-2.en_SENTbySENT.txt
* [MUSIC]
* We've already seen how the chain rule can help us find the anti-derivatives
* Alright, that message is called u substitution
* I'm going to do more messing around with the chain rule and integration
* In particular, let's see what we can do with the chain rule, and the end points of integration
* Well here's an example to play around with, if I take the integral from 0 to x, of sine of t dt, well that's something
* But let's think about the derivative of this with respect to x
* And by the fundamental theorem of calculus this is sine of x
* The fundamental theorem of calculus is the derivative of the accumulation function is the integrand
* What if that upper endpoint were a function of x
* What I'm asking is what if this endpoint weren't x anymore
* But some function g of x right
* Then this wouldn't be sine of x anymore, be something else
* So to analyze this let's define a function f
* So that function will be given by this rule
* f of x is the integral from 0 to x of sine t dt
* Now what would it mean if we replace that right hand endpoint instead of being x if we replace that with g of x
* That would mean that I want to think about f of g of x, right
* What's f of g of x
* So, that's the integral from 0 to g of x, of sine t dt
* And specifically, right, what I want to know, is what's the derivative with respect x of f of g of x
* That's just the chain-rule
* So let me just write down the chain rule
* The derivative of f of g of x is the derivative of f at g of x times the derivative of g
* So what does it mean in this specific case
* Remember in this case, f of x is the integral from 0 to x of sine t dt
* So the derivative of f, by the fundamental theorem is sin of x and that means that the derivative of f of g of x, well that's just sin the derivative of f at g of x times the derivative of g
* Let's make it even more concrete
* Let's say that g is the squaring function
* Let me write that down
* So if I'm making g the squaring function, then the derivative of g is just 2x and in that case the derivative of f of g of x is sine of g which is x squared times the derivative of g which is 2x
* So let's write down our final answer in this specific case
* The final claim is that the derivative of the integral from 0 to g of x which in this case is x squared of sine t dt
* This is the derivative with respect to x of f of g of x
* This is sin of x squared times 2x and this statement, we can get by combining the chain rule and the fundamental theorem of calculus.


--- SKIP ---: 02_formally-why-is-the-fundamental-theorem-of-calculus-true.en.srt


--- SKIP ---: 02_formally-why-is-the-fundamental-theorem-of-calculus-true.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_formally-why-is-the-fundamental-theorem-of-calculus-true.en_SENTbySENT.txt
* [MUSIC]
* We've seen a bunch of arguments, or perspectives, on why the fundamental theorem of calculus should be true, but we've also paid a high price in this course
* We've been doing alot of things rigorously, and we've done the squeeze theorem
* Well with the squeeze theorem in hand, it's possible to give a rigorous formal proof of the fundamental theorem of calculus
* Well just to remind you this is actually what we're going to prove rigorously here
* I'm going to start with some function from this closed interval ab to the real numbers
* It's a continuous function, so it's actually integrable
* then I write down the accumulation function big F which takes the integral from a to x of the function little f
* And the big claim here, is that the derivative of the accumulation function is the function little f
* The statement of the fundamental theorem of calculus is about a derivative, so we're really trying to do two different things
* I'm trying to show that a limit of a difference quotient exists, that the derivative exists, and then second, I'm making a claim as to the value of that derivative
* specifically, I want to show that this derivative, which is defined to be the limit as h approaches 0 of big F of x plus h minus big F of x over h, I want to show that this is equal to little f of x
* But to make matters a little bit easier, I'm only going to consider the situation when h is positive
* So I'll put a little plus there
* Let's rewrite that difference of two accumulation functions, as a single definite integral
* Well how so
* Well let's just write this down
* So, this is the limit as h approaches 0 from the right of big F of x plus h, that's the integral from a to x plus h of f of t dt minus big F of x, which is the integral from a to x of f of t dt all over h
* But now this difference of integrals, can be written as a single integral
* This is the limit as h approaches 0 from the right, of, well, if I integrate from a to x plus h and subtract the integral from a to x, what's left over, is the integral from x to x plus h
* Of f of t dt all over h
* Let's think about how large and how small that integral can be
* Well, first some notation
* I'll define little m of h to be the minimum value of the function f on the interval between x and x plus h
* And I'll define big M of h, to be the maximum value of the function little f on the interval, well the same interval, a closed interval from x to x plus h
* Now you might be wondering, how do I know that there is a minimum and a maximum value
* Well, little f assumed to continuous, so by the extreme value theorem there is a minimum and a maximum value on a closed interval, and these are closed intervals
* This gives us a bound on the integral
* Specifically let's think about the integral from x to x plus h of the function little f, and since the function little f has a maximum value of big M on this interval, this integral is no bigger than big M of h times h
* And conversely, all right, the minimum value is little m of h, and that means that this integral is at least as big as little m of h times h
* Now let's divide both sides by h, and that doesn't effect the inequality because I'm only really thinking about the case when h is positive
* Well that gives me little m of h is less than or equal to the integral from x to x plus h, of f of t dt, over h, is less than or equal to big M of h
* Now, we apply the squeeze theorem
* Well how does that go
* Well let's think about the limit as h approaches 0 from the right of little m of h
* Now, remember what little m is, little m is the minimum value of the function f on the interval between x and x plus h
* And as h approaches 0 from the right, this minimum value of f It's just the value of f at the point x
* And for the same reasoning, the limit as h approaches 0 from the right of the maximum value, big M, the maximum value of f on that interval is also little f of x
* So what I've got here is this inequality, and the left-hand side and the right-hand side both have equal limit as h approaches 0 from the right, and that means that this middle term also has a limit that exists, and equals f of x
* Let me write that down
* So what I can conclude, is that the limit, as h approaches 0 from the right, of the integral from x to x plus h, of f of t dt divided by h, well that's equal to f of x
* And if I play the same game but think about h approaching 0 from the left
* I can get that, that limit is also f of x, and consequently, the two sided limit, as h approaches 0, of this term, is equal to f of x
* And so we've verified that the derivative exist, and it's equal to f of x.


--- SKIP ---: 03_without-resorting-to-the-fundamental-theorem-why-does-substitution-work.en.srt


--- SKIP ---: 03_without-resorting-to-the-fundamental-theorem-why-does-substitution-work.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_without-resorting-to-the-fundamental-theorem-why-does-substitution-work.en_SENTbySENT.txt
* [MUSIC]
* I've mostly been selling you on the idea of u-substitution as a method for finding antiderivatives, for evaluating indefinite integrals
* Let's think about what u-substitution says just for definite integrals
* So here's the setup
* I've got the integral x goes from a to b of some function f, not the derivative of f, just f g of x times g prime of x dx
* Now, how could I approach a problem like this so I can make a substitution
* U equals g of x so that du is g prime of x dx and, in that case, this integration problem becomes the integral of f of u u is g of x times this is du
* But now I've gotta change the bounds of integration
* When is x is equal to a, u is g of a, and when x is equal to b, u is g of b
* Assuming that those two integrals exist to justify the equalty of those two integrals
* It's just the chain rule and the fundamental theorem of calculus
* And yet, this statement, the equality of this integral and this integral, that's just a statement about two definite integrals
* I don't need to know the fundamental theorem of calculus in order to make this assertion
* This raises a fascinating question, u substitution is making a claim about definite integrals
* And yet the naive way to justify that claim goes through the fundamental theorem of calculus and the chain rule
* Is it possible to see why the statement about u substitution for definite integral should be true without resorting back to anti-differentiation
* Well, to gain some insight into this, here's a random graph that I made of some function that's nearly constant
* But the function I'm calling f
* And this, area, in here is the interval from 1 to 10 of f of udu
* And that's this area in here
* Now I want to imagine what happens when I do the substitution
* What happens when I replace
* U with x squared plus 1, and that changes du, right
* That's that formula that we saw a moment ago
* If I'm integrating f of u du, I could alternatively integrate f of g of x times du g prime of xdx, and I can imagine that in the graph, transforming from the u coordinates to these x coordinates
* Well the u-coordinates are more stretched out, right
* When x is 0, u is 1
* When x is 1, u is 2
* When is x is 2, u is 5
* And when x is 3, u is 10
* So if I redraw this picture in the, x-coordinates, it's as if I've taken this picture and squished it in, right, and when I squish it in
* Then I'm going to get a picture more like this
* And to calculate the area, there, I'd be calculating this integral
* The integral from 0 to 3, this is x, of f of what u is equal to in terms of x, du, which is 2x dx
* And the whole gimmick here is just that I'm trading the width in this picture for the height in this picture
* And the factor that relates the width here, the du's and the height here, well that's exactly this factor here, right
* That's du but written in terms of dx.


--- SKIP ---: 01_how-will-we-find-antiderivatives-for-more-complicated-expressions.en.srt


--- SKIP ---: 01_how-will-we-find-antiderivatives-for-more-complicated-expressions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_how-will-we-find-antiderivatives-for-more-complicated-expressions.en_SENTbySENT.txt
* [MUSIC] Armed with the fundamental theorem ofcalculus
* We can no evaluate definite integrals,just, by taking antiderivatives
* [LAUGH] Of course, just, is reallyoverstating it a little bit
* It can be quite difficult to find anantiderivative
* And the trouble is that it's hard to runour differentiation rules in reverse
* And remember a long, long time ago, welearned about the chain rule
* And if you take the chain rule, and yourun it in reverse, you get u substitution
* The difficulty though, is you know, whenyou're doing u substitution, you gotta make a choice for u, and that can bepretty hard
* Well now, we want to do the same kind ofgame with other differentiation rules
* I want to take the product rule, and runthe product rule in reverse
* We're going to call that integration byparts and, by being clever, we'll be able to evaluatea ton more integrals by doing them, byparts, by using the product rule in reverse onthem
* And one of those cool integrals that we'llbe able to evaluate, our integrals of powers ofsines and cosines
* And I think maybe it sounds a little bitdry
* But I think it's actually pretty fun tosee how we can do, these very fearsome looking integrals, with just a little bitof help from the product rule
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_what-antidifferentiation-rule-corresponds-to-the-product-rule-in-reverse.en.srt


--- SKIP ---: 01_what-antidifferentiation-rule-corresponds-to-the-product-rule-in-reverse.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-antidifferentiation-rule-corresponds-to-the-product-rule-in-reverse.en_SENTbySENT.txt
* [MUSIC] We've already learned about the chain rule in reverse
* That technique was u substitution
* I want to anti-differentiate a function evaluated at g times the derivative of g
* I can make a substitution and reduce that just down to anti-differenting f of this new variable u
* Now we're going to run the product rule in reverse
* What is the product rule
* Well the product rule tells us how to differentiate the product of two functions
* So here's two functions, f and g, and if I want to differentiate their product, using the product rule, right
* The derivative of the product is the derivative of the first, times the second plus the first, times the derivative of the second
* Now, integrate both sides
* So then I get that anti derivative of the derivative of f times g, is anti derivative of, what's this by the product rule
* Alright, it's derivative of the first, times the second, plus the first, times the derivative of the second
* But the antiderivative of the derivative is just the original function
* So let's write that down
* That tells me that an antiderivative of the derivative of f times g plus f times the derivative of g is this
* Which is just f of x times g of x, and I'll include a constant
* That's the integral of a sum, so its the sum of the intergrates
* So integrate f prime of x g of x dx plus integral of f of x, g prime of x dx and we get f of x times g of x plus a constant
* And that's one very symmetric way of writing down the product rule in reverse
* But we can rearrange it a bit more
* I'll subtract this integral from both sides, so the left hand side is just this integral
* So the integral of f of x, g prime of x dx is equal to, well heres what we got on the righthand side f of x times g of x
* But I'm going to subtract this
* Subtracting f prime of x g of x dx
* Now look at what this is saying
* It's saying that I can do this integration problem if I can do this integration problem
* And how do these two integration problems differ
* Well here I've got a function times a derivative and here I've got the derivative of f and an antiderivative of this
* Right
* g is an antiderivative of g prime
* So I can replace this integration problem with another integration problem
* Where I've differentiated part of the integrand, and anti-differentiated another piece of the integrand
* It'll be a bit easier to see what's going on if I make some substitutions
* Let's set u equal to f of x, and dv equal to g prime xdx
* And in that case d u is f prime x d x
* And what's an anti-derivative of this
* Well one of them is just g of x
* So I can use these substitutions to rewrite what I've got up here
* This integral is u times dv
* And it's equal to u times v, minus the integral of g is v
* And f prime dx is du
* So now I've got the integral of udv is uv minus the integral of vdu
* This is maybe why it makes sense to call this Integration by parts
* So I can integrate udv provided I can integrated vdu
* It's this trading game
* I'm trading this integration problem for this integration problem
* But now one part is differentiated and another part of the inner grand is antidifferentiated
* Maybe that'll make things better
* With u substitution, we had to come up with a single u
* In contrast, when you're doing integration by parts, when using this formula
* You not only have to pick a u, but you've got to pick a dv so that you can write your integrand as udv
* This makes parts a bit harder to apply the u substitution
* I've gotta find both a u and a dv
* But any time you're willing to differentiate part of the integrand at the price of antidifferentiating the other part of the integrand
* Well if that's something you're willing to do, parts will do that for you
* [BLANK_AUDIO]


--- SKIP ---: 02_what-is-an-antiderivative-of-x-e-x.en.srt


--- SKIP ---: 02_what-is-an-antiderivative-of-x-e-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-an-antiderivative-of-x-e-x.en_SENTbySENT.txt
* [MUSIC]
* The basic idea of integration by parts is that it lets you differentiate part of the integrand, but only if you're willing to pay a price
* And that price is anti-differentiating the other part of the integrand
* Well, let's try it
* For example, let's find an anti-derivative of x times e to the x
* If we're going to attack this integrand by parts, then I've got to pick a u and a dv
* I'd be willing to differentiate x
* That'll make x just go away
* And the price I'd have to pay is to anti-differentiate what remains
* But anti-differentiating e to the x is not much of a price to pay because e to the x is its own anti-derivative
* So let's set that down
* Let's set u to the x, because I'd like to differentiate that part
* And I'm willing to anti-differentiate what remains
* Now, let's figure out du and v
* Now if u is x, then du is dx
* And then, I've got to pick an anti-derivative for dv
* Now, in principle, there's a ton of anti-derivatives I could pick, right
* e to the x plus 17 differentiates the e to the x
* But I'll just pick the nice one
* I'll pick e to the x
* Now I've got u, dv, v, and du
* We can put it all together
* Parts tells me that an anti-derivative u dv is uv minus anti-derivative v du
* So, in this case, the anti-derivative of u dv is u times v, x times e to the x minus anti-derivative of v du, which is just dx
* But, I know how to integrate e to the x
* Anti-derivative of e to the x is just itself
* So, the anti-derivative of x, e to the x is x, e to the x minus e to the x plus some constant
* We did it, and we can check our answer
* So we have to differentiate this and make sure I get x, e to the x
* Let's try it
* So, if I differentiate xe to the x minus e to the x, I don't need to add the plus C because if I differentiate a constant, I just get 0
* All right, this is a derivative of a difference so it's the difference of the derivatives
* But now this is a derivative of a product, so I'm going to use the product rule
* I'm going to take the derivative of the first, so the derivative of x, times the second, plus the first times the derivative of a second, right
* That's the product rule
* And then I subtract, well, the derivative of e to the x is just itself
* And I've got the derivative of x, which is 1 times e to the x plus x times the derivative of e to the x e to the x minus e to the x
* And here's the slightly exciting part, right
* This and this cancel, and all I'm left with is just x times e to the x
* So, in fact, we have found an anti-derivative for x e to the x
* Here it is
* And of course, that makes sense because integration by parts is just a product rule in reverse
* Now, we can use the same trick to attack similar integration problems
* For example, let's say you want to anti-differentiate some polynomial in x times e to te x
* You could do this with parts
* Well, how
* Well, I've made this be u and I make this be dv
* And why is that such a great choice
* Well, think about what parts lets you do
* Parts lets you differentiate part of the integrand if you're willing to anti-differentiate the rest
* But anti-differentiating e to the x is paying no price at all because it's its own anti-derivative
* And, if you differentiate the polynomial, then you reduce its degree
* So, by doing parts enough times, eventually you're just anti-differentiating e to the x by itself, which you can definitely do.


--- SKIP ---: 03_how-does-parts-help-when-antidifferentiating-log-x.en.srt


--- SKIP ---: 03_how-does-parts-help-when-antidifferentiating-log-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-does-parts-help-when-antidifferentiating-log-x.en_SENTbySENT.txt
* [MUSIC] We could figure out our anti derivative for log x, by just guessing and then checking our answer
* But we can also get that anti derivative by using integration by parts
* So I want to know an anti derivative of , log x dx
* And just to remind you, this is natural log
* At first, it looks like there's nothing helpful here
* What would my u and my dv be
* The trick is to sit u log x that's the part of the anagram I'm going to differentiate as dv
* To be dx and it gets quite surprising, and that helps
* Let's see, so if u is log x then du is 1 over x dx
* And if dv is dx then an anti-derivative, just be x
* Now, what does parts tell us
* So by parts the integral of u dv, so log x dx, that's what I'm interested in
* Is u v so x log x minus the integral of vdu, which is x times du
* And I've got x log x minus x times 1 over x, that's just 1
* So I'm just anti-differentiating dx
* Then I've got x log x, what's an anti-derviative of 1, just x, and I'll add a constant
* So I'm claiming that the antiderivative of log x is x log x minus x plus some constant
* I think it's really surprising that, at least in this case, dv equals dx is a great choice
* Well here's a similar integration problem that you can try the same kind of technique on
* For example, here's a challenge
* Can you find an anti derivative of log of x squared?


--- SKIP ---: 04_what-is-an-antiderivative-of-e-x-cos-x.en.srt


--- SKIP ---: 04_what-is-an-antiderivative-of-e-x-cos-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-is-an-antiderivative-of-e-x-cos-x.en_SENTbySENT.txt
* [MUSIC] Integrating requires patience
* Sometimes you can start attacking the monster, but it might take a little bit of time before you start to see success
* Prepare to persevere
* Let's attack the indefinite integral of cosx times e to the x dx
* There's a metaphor here
* There's really different ways to win the battle
* Suppose this is you, and this is the integral that you're trying to attack
* One way, is you know, to try and do it by hand, right
* To take your shield and to take your sword, and just to evaluate that integral directly by, say going back to the definition of Riemann sum
* But we almost never attack integrals in this way
* Instead of using, you know, swords and shields, we're really using, you know, magic
* Right
* We're putting on our wizard hat
* And instead of trying to kill the intregral, right
* We use something like u substitution to transform that integration problem into a friendly integration problem that we can actually deal with, right
* We're never attacking integrals directly we're just transforming integrals by doing u substitutions or parts
* So let's try to transform the integration that we're attacking here
* Let's tranform e to the x cosx to something else
* So I'll use what u, I'll make u be e to the x
* because I don't really mind differentiating that
* And I'll make dv cosx dx
* Now in that case, the derivative of e to the x is just e to the x
* And what's an anti-derivative of cosine
* An anti-derivative of cosine is sine
* Now what is integration by parts say
* So then anti-derivative of cosx e to the x dx is U times V, so e to the x sinx minus the intergral of V du So, sinx, e to the x dx
* Well that didn't really help matters
* But the word of the day is persevere
* So let's persevere, and transform that integral into yet another monster
* So the monster in this case is this thing here
* let's try the same trick on that new integral
* So U will be e to the x again and dv here, will be just what's left over, sine x dx
* And in that case, if U is e to the x, then du is e to the x dx
* And, if dv is sin x dx, well, I've got other choices for more anti-derivative, but I'll have v be minus cosx
* Now, I've put this into the integration by parts formula
* So the antiderivative of sinx e to the x dx is uv, so minus e to the x cosx minus vdu
* So my-, the integral of vdu, so v is cosx, and du is e to the x dx
* Now what's happened thus far in the battle
* I'm attacking this integral
* I used integration by parts to transform the monster into something else
* It didn't help, so I used that magical weapon again
* I used integration by parts again to transform the integration problem into yet another integration problem and it didn't help
* Or did it
* What happens if I put these two integration facts together
* Well, and then I've got here, the integral of cosx, e to the x dx, is equal to e to the x sin x minus the integral of sinx, e to the x, dx, which is down here
* So minus negative e to x cos x plus the integral of cosine x e to the dx
* Lets persevere, lets keep going
* So this is saying the integral of cos x e to the x dx is e to the x sin x plus e to the x, cosine x, minus the integral of cosine x, e to the x, dx
* Now I'm going to add the integral of cos x e to the x, dx to both sides
* And what I'll then get is 2 times the integral of cos x e to the x, dx is equal to, well what's left on the righthand side, e to the x sin x plus e to the x, cos x
* And then I'll divide both sides by 2, and if I divide this side by 2 and this side by 2 well then these 2's cancel, and I find out that an antiderivative of cosine x e to the x Is e to the x sin x plus z to the x cos x all over 2
* What we did here is one of my favorite applications of integration by parts
* We didn't use integration by parts to solve, to evaluate the integral directly
* Instead, I applied parts twice and ended up with a clone of the original monster
* So how did that go
* Well, here you are, right, and you're a wizard, so here's your wizard hat, and here's the integral that we wanted to attack
* But we didn't attack this integral directly
* We didn't' even transform this integral by using U substitution
* Instead, we used parts twice and it seemed like that was a terrible idea because when I applied parts twice, I ended up with a clone of the original monster
* The same integral ended up appearing
* But, that other integral came with a minus sign
* And, consequently that monster ends up defeating itself and we're able to evaluate the integral without actually integrating at all
* If anything suggests that there's creativity in the battles ahead of us, I think integration by parts is telling us, to be prepared to be amazed.


--- SKIP ---: 01_what-is-an-antiderivative-of-e-sqrt-x.en.srt


--- SKIP ---: 01_what-is-an-antiderivative-of-e-sqrt-x.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-an-antiderivative-of-e-sqrt-x.en_SENTbySENT.txt
* [MUSIC]
* Sometimes it isn't clear that you can do integration by parts until after you perform some substitution
* For example, let's attack this integral, the integral of e to the square root of x, dx
* We'll start by making a substitution that looks totally unjustified
* But in retrospect, will turn out to be a brilliant move
* Well, here's the substitution I'm proposing
* Let's set u equal to the square root of x
* How does that change the integral
* So in this case, if u is the square root of x, then du is 1 over 2 square roots of x, dx
* in other words, right
* I could solve this and find that dx is 2u du
* Now, what does that end up doing to the integral
* Well, this integral then becomes the integral of e to the u, and instead of dx, it's now 2u du
* now it's a polynomial times an exponential function
* We can use parts
* But, if I'm going to use parts, I probably wanted to call them u and v, right
* But, I'll just change the names
* Instead of talking about u and dv, I'll talk about v and dw
* So, in this problem I'll have v be 2u and dw will be e to the u, du
* And now the derivative of v, right
* Gives me that dv is 2 du
* And an anti-derivative here I can pick one, I'll have w be e to the u
* So in that case, what does parts tell me
* Well, parts then tells me that this integral is the same as 2u, e to the u minus the integral of w, dv, which is e to the u times 2 du
* But now, this in integration problem that I can do
* I know an anti-derivative of e to the u
* So, this is 2u, e to the u minus 2e to the u
* I'm going to go back now
* And remember that I set u equal to the square root of x
* So, this gives me 2 square root of x, e to the square root of x minus 2e to the square root of x
* If I notice there's a common factor of 2e to the square root of x, I could collect those terms and write this as 2e to the square root of x times the square root of x minus 1
* And that's an anti-derivative for e to the square root of e
* And if I want to be a little bit more careful, maybe I'll include a plus C at the end
* We did it
* Contrast that with, say this integration problem, the integral of e and the negative of x squared dx
* This is an integration problem that I can't solve using the functions that I have at hand
* And that this problem looks really similar to the original problem here, e to the square root of x, right
* It's e to some power of x
* So, you'd think that if we can solve this one, we should also be able to solve this one
* Seemingly similar problems, right
* Can have totally different outcomes.


--- SKIP ---: 01_what-is-an-antiderivative-of-sin-2n-1-x-cos-2n-x-dx.en.srt


--- SKIP ---: 01_what-is-an-antiderivative-of-sin-2n-1-x-cos-2n-x-dx.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-is-an-antiderivative-of-sin-2n-1-x-cos-2n-x-dx.en_SENTbySENT.txt
* [MUSIC] When you're integrating powers of sines and cosines
* I've got a motto for you to remember
* You can trade sines for cosines or vice versa
* How so
* Well since sin squared plus cosin squared is 1, that is the Pythagorean identity, I can use this to get these two facts
* That I can replace sin squared x by 1 minus cosin squared, and can I replace a cosin squared by 1 minus sin squared
* This is often useful
* Let's try making some trades
* For example, let's try to anti-differentiate say, sine cubed of x times cosine squared of x, dx
* Our first inclination might be to try and make a substitution
* But rats, I mean if you were sin x right then du would be cosine x dx
* But I got a cosine squared term there that I have to deal with
* If I made different subsitiution like, you know u equals cosine x or when du, would be minus sine x dx
* But then I've got a sine cube term to deal with
* So instead, I'll trade a pair of sines for a pair of cosines
* So, instead of making a substitution immediately
* I'm going to trade a pair of sines for a pair of cosines
* What I mean, is that I'm going to rewrite the integrand as sine of x times sine squared of x times cosine squared of x
* And then I'm going to use the fact that sine squared is is what
* Well it's 1 minus cosine squared x
* All right, so I can rewrite the integral as this
* Now I can make the substitution u equals cosine x
* So, u is cosine x and in that case du is minus sine x dx which I don't quite see here
* But I can manufacture that by including a minus sign there
* So this becomes the integral of 1 minus u squared times u squared and then minus du
* Now I expand
* So this is negative the integral of u squared minus u to the 4th du
* Now I'll integrate
* So this is minus and I derivative of u squared is u cubed over 3
* And an anti derivative u to the 4th is u to the 5th over 5 plus c
* Now I'll substitute cosine x, for u
* And, we get negative cosine cubed, of x over 3, plus the negative of the subtraction Cosine to the 5th x over 5 plus c
* And this same kind of trick works in other cases too
* For example, what if I wanted to anti-differentiate sine to the 5th power times cosine to the 5th power
* Since I've got an odd number of cosines, I can trade all but one of them for sines
* What I mean is I can rewrite this integral as sine to the 5th times cosine squared squared times cosine x dx
* Right, this is four cosines times another cosine gives me cosine to the 5th
* But, now, I can use the fact that cosine squared is 1 minus sine squared
* So I can rewrite cosine squared squared, as 1 minus sine squared, squared
* And then times cosine dx
* And now we can finish by making a substitution
* I'll make the substitution, u equals sine x
* In that case, du is cosine x dx
* So, the integral becomes, instead of sine to the 5th, u to the 5th
* 1 minus sine squared is 1 minus u squared
* And that's squared
* And cosine x dx is du
* Is that going to work
* Yeah, I could definitely finish this off, I just expand this out and I get a polynomial u
* And I can anti-differentiate a polynomial u and then just replace u by sine of x to get the anti-derivative of sine of the 5th cosine of the 5th
* So what's the general pattern to this kind of trick
* The trick works as long as we've got an odd power on the sine, or an odd power on the cosine
* 'Cuz in that case, I can split off all but one of them
* And then I'll get say, sine times an even power of sine, times some number of cosines
* Or sine, times an even number of cosines, times cosine
* And since this an even number here, I can rewrite those in terms of the other
* So then I'll end up with a single sine times a bunch of cosines, really a polynomial and cosine x
* Or a polynomial and sine x times cosine, and then I can finish it off with a single substitution.


--- SKIP ---: 02_what-is-the-integral-of-sin-2n-x-dx-from-x-0-to-x-pi.en.srt


--- SKIP ---: 02_what-is-the-integral-of-sin-2n-x-dx-from-x-0-to-x-pi.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-integral-of-sin-2n-x-dx-from-x-0-to-x-pi.en_SENTbySENT.txt
* We already know how to handle some integration problems where the integrand is a powers of sines and cosines
* For example, I can anti-differentiate sine to and odd power
* How
* By trading in all but one of those sins for cosines
* Let's make this really concrete
* Instead of talking about an odd power well let's just make it 17
* Can I antidifferentiate sin to the 17th power
* Yeah, I can rewrite this problem as sin of x times sin squared x to the 8th power, because sin square to the 8th power gives me 16 copies of sin times more sin gives me 17 copies of sin, now we can trade sin squared for some cos signs right, sin squared is 1 minus cos sign squared to the 8th power
* So if I can do this anti-differentiation problem all I need to do is do this anti-differentiation problem
* And I can do that with a substitution
* So make the substitution u equals cosine x and in that case d u is minus sign x dx
* Now maybe you're complaining you don't see a minus sign
* And you'll only see sin, but I'll just put a pair of cancelling minus sins there, and I see a minus sin next dx so we got a du and the rest I can write in terms of u
* Specifically, this becomes negative, the n is derivative of 1 minus u squared to the 8 power du, is what's left over and this anti-differentiation problem that I can do and it is a little bit annoying cause I guess I gotta expand this thing out to find an anti-derivative of this, but I can do it
* But what if instead I'd had an even power of sine
* Well, maybe I'll anti-differentiate sine to the fouth power
* All right
* So this is not an odd power but an even power
* that's harder, I can't trade in all of my sins for cosines because I need just one left over to make the substitution work
* Instead, I'll use an identity, the half angle formula
* It let's me replace sined squared of x by 1 minus cosine of 2x over 2
* And it lets me replace cosign squared of x by 1 plus cosign 2x over 2
* How do those help
* Well I can rewrite this integral as the integral of sin squared, squared
* And now I can use this half angle identity
* This is the same as the integral of what sin squared
* Sin squared is 1 minus cos 2x over 2
* All right
* These are equal
* And still have to square that, dx
* Now, I expand
* So, I get this is the same as integrating
* Well, the cos 2x over 2 term, squared is cosigned squared of 2x over 4
* And there's our cross term
* The 1 half times minus cosign 2 x over 2
* And there's 2 of those
* So I end up getting minus 1 half
* cosigned 2x
* And there's the one half term squared just plus a quarter, so I just have to do this integration problem
* I can split that into 3 integrals
* So this gives me the integral of cos sign squared 2x over 4dx minus the integral of cos sign 2x over 2dx plus the integral of 1 4th dx
* Now, the second and third integration problem I can do, I'm just going to copy down this one again
* The integral of cos squared 2x over 4 dx
* This, here, well I could do this by making a substitution
* u equals 2x, say
* And then I'll get that this is sine of 2x divided by 4
* And if I integrate a quarter, I get 1 4th x
* What about that first one
* How do I integrate cosine squared
* So, to handle this, I can repeat the trick with the half angle identity
* But I'm looking at integrating cosign squared 2x
* So I'll replace x by 2x and I'll turn this into a 4x
* So I can use this identity
* How does that go
* Well I get instead of this the integral of 1 plus cosine 4x and instead of over 4 its now over 8 and then I'll just copy down these things again
* Sin 2x over 4 plus a quarter x
* Now I can put it all together
* So I want to and differentiate 1 8th
* I get 1 8th x
* And then I want to, and I differentiate cos 4x over 8, and I get sin of 4x over 32 and then I'll include the rest
* So, I'll subtract sin of 2x over 4
* I'll add a quarter x and I'll add some constant
* And I could combine the one quarter x and the 1 8x, so I could right this as 3 8x plus sine of 4x over 32 minus sine of 2x over 4 plus c
* I should say that in some cases you can get away with doing a bit less work
* So I want to calculate the integral from zero to pi of sine to the fourth and I'll again start the same way, right I'm going to integrate from zero to pi and I'll write this as sine squared squared
* Just so I can see how the half angle formula is going to help me
* Alright, now I'll use the half angle formula as the integral from zero to pi of 1 minus cosine2x over 2 squared, but now what do I want to do
* Well, I'll expand that out again, so this is the integral from 0 to pi of 1 fourth Minus the cross term is one half cosign 2x and then plus the cosign times squared 2x over 4
* And now there's a little trick
* I'm integrating from 0 to pi cosign
* Right I'm integrating cosign over an entire period
* And that ends up being 0
* So I can just throw this whole term away and now I can keep on going
* I can also use the half angle formula here
* So this is the integral from 0 to pi
* well I've still got the 1/4 plus, and then what does this become
* By the half angle formula, this is 1 plus
* And instead of 2x
* It's cosine 4x over 8, but I would again, if I integrate cosine 4x, x going from 0 to pi, that's integrating cosine ove 2 complete periods that ends up cancelling
* So I can just throw that term away, and all I'm really integrating now is a quarter plus an 8
* Well thats 3 8ths, but I'm integrating over an interval of life pi, so this definite integral is 3 8ths pi
* This turn out to be not so bad
* See I'm getting an answer of 3 8ths pi, but that's not really the point right
* The cool thing about setting this up as a definite integral is really just how easy it is to do the calculation since I can throw away some terms along the way that I know would integrate to zero.


--- SKIP ---: 03_what-is-the-integral-of-sin-n-x-dx-in-terms-of-sin-n-2-x-dx.en.srt


--- SKIP ---: 03_what-is-the-integral-of-sin-n-x-dx-in-terms-of-sin-n-2-x-dx.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_what-is-the-integral-of-sin-n-x-dx-in-terms-of-sin-n-2-x-dx.en_SENTbySENT.txt
* [MUSIC]
* We've already seen how difficult it is to integrate powers of sin
* For example, what's the inner goal from 0 to power of a 2 of sin the 32nd power
* Well it turns out that it's, what is this, 300540195 divided by 4294967296 times pi
* But how would I ever that
* That looks so random and yet there's more going on here
* In fact, this ends up being 3 times 3 times 5 times 17 times 19 times 23 times 29 times 31 all over 2 to the 32nd power
* What
* All those numbers suggest something's going on here that could hardly be an accident
* The goal of computing, the goal of numbers, the goal of everything that we're doing in this course isn't just answers
* It's insight
* So how can we gain some insight into why that integral works out like that
* Specifically our question is why does it factor, so nicely
* Right I mean there's no reason at least at this point for it to work out so nicely so why does it factor so nicely
* Well to gain some insight into this lets use parts to examine the relationship between the integral of sin to the nth power and sin to the n minus second power
* Well, let me write that down
* To answer this question, of why it factors is what I want to do is figure out some sort of relationship
* Between the interval from 0 to pi over 2 of sin to the nth power and the interval from 0 to pi over 2 to the n minus second power
* We'll use parts
* So lets start with this and I gotta pick a u and a dv
* So I'll have a u be a sin to the n minus 1 and dv, which would be the rest of this, will just be sine x dx, so udv gives me this integrand
* Now if that's u and that's dv, I gotta figure out what d, u, and v are supposed to be
* Well, if dv is sin of x, then an antiderivative for that is minus cosine x and, if u is sin to the n minus 1, then du, we've gotta differentiate this, that'll be the chain rule
* n minus 1 times sin to the n minus 2
* And then times the derivative of this
* What's the derivative of the inside
* The derivative of sin is cosine, and then dx
* Now we get a formular for parts
* So this integral is u v
* So sin, to the n minus 1, times cosine with a minus sin, evaluated at pi over 2 and 0
* Minus the interval from 0 to pi over 2 of v du, which is well here's n minus 1 sin to the n minus 2 cosine squared dx and I've got a minus sin there on the v so I'll make that plus
* Alright, now when I plug in pi over 2 that kills the cosine terms, and when I plug in 0, that kills the, the sin term
* So this thing here is just 0, and that means this original integral is just the integral from 0 to pi over 2 of n minus 1 times sin to the n minus 2 x
* And instead of, cosine square, there I'll right that as 1 minus sin squared x d x
* Now I can expand this out
* This is, really the difference between two integrals after I expand
* It's n minus 1 times the integral from 0 to pi over 2 of sin to the n minus 2 x, then minus n minus 1 times the integral from 0 to pi over 2 of sin to the n minus 2 times sine squared
* Is just sin to the nth power dx
* And we can solve this
* So, this is what I've got at this point
* I've that the integral from 0 to pi over 2 of sin to the n x dx is equal to this, after I did parts
* But now, I can add n minus 1 times the interval from 0 to pi over 2 sin to the nx dx to both sides
* And what do I get, well I'll get n times the integral from 0 to pi over 2 sin to the n x dx is equal to
* And on the other side I'll have n minus 1 the integral from 0 to pi over 2 sin to the n minus 2 xdx
* And I can divide both sides by n
* And if I divide both sides by n, alright, I find that the integral from 0 to pi over 2 of sin to the n xdx is n minus 1 over n times the integral from 0 to pi over 2 of sin to the n minus 2 xdx
* So this formula is telling me how to compute the integral of sine to the nth power in terms of the integral of sin to the n minus second power
* So I get started by knowing that the integral from 0 to to pi over 2 of sin to the 0 power of x dx
* That's just the integral of 1 from 0 to pi over 2
* Well that's just pi over 2
* So, what's the integral of sine squared on the interval 0 to pi over 2
* Well, using this formula, when n equals 2, I find that the integral from 0 to pi over 2 of sin squared x dx
* This is when n equals 2, is 2 minus 1
* Over 2, that's n minus 1 over n times the integral from 0 to pi over 2 of sin to the zeroth power
* But I know what sin to the zeroth power is, it's just pi over 2
* So this is 1 half 2 minus 1 over 2 times this which is pi over 2 which pi over 4
* So the integral from 0 to power over 2 sin squared x is just pi over 4
* What's the integral of sine to the fourth
* Well, let's use this formula when n equals 4 so the integral from 0 to pi over 2 signed to the fourth x dx
* That'll be 4 minus 1 over 4 times the integral from 0 to pi over 2 of sin squared xdx, and we just figured out what the integral of sin squared is right
* This is 3 4th times pi over 4
* What's the integral of sin to the 6th
* So, that means I should look at this formula when n equals 6
* So, the integral from 0 to pi over 2 of sin to the 6th x dx is, well if I put in n equals 6, I get 6 minus 1 over 6 times the integral from 0 to pi over 2 of sin to the 4th x dx, but I just figured that one out
* So, this is 5 6th times, well here's the integral of sin to the 4th, times 3 4th times pi over 4
* What's the integral of sin to the 8th
* Well, that means I should use this formula when n equals 8
* So, the integral from 0 to pi over 2 of sin to the 8th dx is, according to this when n equals 8, that's 8 minus 1 over 8 times the integral from 0 to pi over 2 of sin to the 6th x dx
* And we just figured out sin to the 6th
* This is 8 minus 1 over 8
* That's 7 over 8 times the integral of sin to the 6th
* Which is 5 6th times 3 4ths times pi over 4
* Okay, okay, we're seeing a pattern
* What's the integral of sin to the 32nd power
* So, the integral from 0 to pi over 2 of sin to the 32nd power
* Just following this pattern will be 31 over 32 times 29 over 30 times 27 over 28, and I'm going to keep on going until I get down to 5 over 6 times 3 over 4 and then finally times pi over 4
* Now we can cancel like crazy
* So this 3 and this 6 give me a 2
* This 5 and this 10 give me a 2
* This 7 and the 14 give me a 2
* The 9 and the 18 gives me a 2
* The 11 and the 22 gives me a 2
* The 13 and the 26 gives me a 2
* The 15 and the 30 gives me a 2
* The 17 survives, all right
* Let's see what else I can cancel
* the 19 is going to survive
* The 21, however, well the 21 is going to be killed by a 7 somewhere
* I can find a 7 in in the 28, so this gives me a 4 and this 21 gives me a 3 leftover can I kill that 3 somehow
* Yeah, that 3 can be killed by this 12 giving me 4 left over
* So this is entirely gone now
* the 23 is going to survive
* What about the 25
* Do I have any 5's
* Well, we've got a 5 in this 20, that gives me a 4, and then I've got a 5 here which will end up surviving
* I've got a 27 here
* Do I have any 3's down here
* Well I've got a 3 in this 24
* I can make this this 24 into an 8, if I convert this 27 into a 9
* the 29 is going to survive and the 31 is is going to survive
* So in the numerator, what all do I have
* Well, the numerator, I've got a 31, a 29
* A 9, a 5, a 23, a 19, and a 17, and way over here, a pi
* And in the denominator I've got a whole bunch of of 2's, right
* How many 2's do I have
* Well I've got 2 to what power
* I've got five 2's there, another 2 here, two more 2's, a 2, three more 2's, another 2, two more 2's, another 2, four more 2's, one more 2, two more 2's, one more 2, three more 2's, one more two, and then here, another four 2's
* And that's going to figure what are all of these number that I get when I add these things up and 5 plus 1 plus 2 plus 1 plus 3 plus 1 plus 2 plus 1 plus 4 plus 1 plus 2 plus 1 plus 3 plus 1 plus 4
* That's 32 two's in the denominator
* This was a triumph
* I'm making a note here huge success.


--- SKIP ---: 01_why-is-pi-22-7.en.srt


--- SKIP ---: 01_why-is-pi-22-7.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-pi-22-7.en_SENTbySENT.txt
* [MUSIC] We're going to sneak up on a certain fact
* I want to show that pi is less than 22 sevenths
* These are awfully close
* Pi is about 3.1416
* And 22 seventh is about 3.1429
* Alright
* These are awfully close
* And we'll do it with an[UNKNOWN]
* I'm just going to make something up, and it'll turn out in retrospect to be exactly what we need
* So the trick's going to be, do the integral from 0 to 1 of x to the fourth
* Times one minus x to the fourth all over one plus x squared dx
* How do I integrate that
* Well, before we actually do the calculation, let's notice something about the integrand
* the denominator here is positive
* And the numerator, well as long as x isn't 0 or 1, the numerator's positive as well
* It's continuous and I'm integrating a continuous function that's mostly positive except at the end point
* So that means that this integral ends up being positive as well
* We'll need that fact later
* The, the fact that the integral's positive
* But let's work now on the integrand
* I'm going to focus first on the numerator
* 1 minus x to the fourth
* If I just multiply this out I get x to the fourth minus 4x cubed plus 6x squared minus 4x plus 1
* And now if I multiply this by x to the fourth, that just adds 4 to each of these exponents
* This will be x to the eighth minus 4 x to the seventh, plus 6 x to the sixth, minus 4 x to the fifth, plus x to the fourth
* Let's get ready to do some long division
* So I'm just going to copy this down
* So, what did I get as the numerator, what was x to the fourth times 1 minus x to the fourth
* Expand it out, was x to the eight minus 4x to the seventh plus 6x to the sixth minus 4x to the fifth
* Plus x to the fourth, and I'm going to take that numerator and I divide it by one plus x squared, so this we're going to do long division
* I'm dividing this by, I write it as x squared plus one
* Okay, so that's the calculation I want to do
* I want to do this long division problem
* Well I gotta put something up here that I multiply by x squared plus 1 to kill x to the 8th
* And, for that I could use x to the 6th, because x to the 6th times x squared is x to the eighth
* And x to the sixth times 1, which is plus x to the 6th
* And I'm going to subtract that, and what do I get
* Well, the x to the 8th terms cancel, and I've got a minus 4x to the 7th
* 6x to the sixth minus x to the sixth is 5 x to the sixth minus 4 x to the fifth and plus x to the fourth
* Those survive and I'm subtracting anything as soon as copy them down, minus 4 x to the fifth plus x to the fourth
* Alright, now you gotta put something up here that I can multiply by x squared plus 1 to your minus 4 x to the seventh
* but minus 4x to the fifth
* because, that times x squared gives me minus 4x to the seventh and that times 1 gives me ooh, minus 4x to the fifth
* That's Great
* So this term dies and this term dies and let's copy down the terms actually it's 5x to the sixth
* Plus x to the fourth
* Now what do I put up here to multiply by this to kill this
* plus five x to the fourth will do it, because that times x squared gives me five x to the sixth, and five x to the fourth times one gives me plus 5x to the fourth
* And remember, I'm subtracting this
* So that kills this first term
* But here I've got what minus 4x to the fourth
* I'm going to write that over here
* So, minus 4x to the fourth is all that's left
* I've gotta put something up here to multiply by this to kill this
* How about minus 4x squared, because that times this gives me minus 4x to the fourth
* And then minus 4x squared
* I'm subtracting this so this becomes just 4x squared
* I've got to put something here to multiply by this to kill this
* Well plus 4 will do it
* Plus 4 times that gives me 4x squared plus 4
* And when I subtract this I get minus four left over and that's my remainder
* Now we can rewrite the integral
* So in light of the expansion of the numerator and the long division after I divided by 1 plus x squared
* This is the integral from 0 to 1
* Of, well, what did I get when I divided
* Was x to the sixth minus four x to the fifth plus five x to the fourth minus four x squared
* Plus four and then I had a remainder so minus four over one plus x squared
* This is an integral I can do
* Okay this is x to the seventh over seven
* That is the anti-derivative x to the sixth
* the anti-derivative here is four x to the sixth over six
* Plus an antiderivative here
* It's just x to the fifth, antiderivative here is minus 4 x to the third over 3
* Antiderivative of 4 is just plus 4x, and an antiderivative of 4 over 1 plus x squared, well the antiderivative of 1 over 1 plus x squared's arctan
* So this is minus 4, orcten x and I'm integrating from 0 to 1, so I'm just going to evaluate this from 0 to 1
* Now, what do I get when I evaluate this
* When I plug in 0, I get 0, 0, 0, 0, 0
* And arctan of 0 is 0
* So, I end up just subtracting 0
* So I only have to just evaluate this at 1 to figure out what this integral is equal to
* So when I plug in 1, I get 1 seventh
* Minus 4 sixths plus one minus 4 thirds plus 4 minus 4 times, and what's arctan of 1, well arctan of is pi over 4, let's simplify a bit
* So, I've got 1 seventh, and I'll put all these with a common denominator of three
* So, minus 2 thirds plus 3 thirds minus 4 thirds plus 12 thirds, and then minus 4 times pi over 4 is just minus pi
* Well now what do I have
* let's see here
* So I've got minus 2 minus 4 that's minus 6 thirds, 3 plus 12, that's 15 thirds minus 6 thirds
* That gives me 9 thirds leftover, and then also minus pi
* So I've got a seventh
* Plus, well 9 thirds is just 3 minus pi
* Well 1 seventh plus 3 that's 22 sevenths minus pi
* Here's the significance of this, remember back to the beginning
* Well way back at the beginning I pointed out that this integral is positive
* So what have we shown
* So we've shown that this, the value of the integral is positive
* In other words, that 22 sevenths is bigger than pi
* So this is really a fun example
* We've got all these pieces coming together
* We've got the derivative of arctan, long division of polynomials, the fundamental theorem of calculus
* All these forces combining to convince us that 22 sevenths is bigger than pi
* So if you want an entertaining challenge, here is an even more complicated integral to evaluate
* The interval x goes from 0 to 1 of x to the eighth of 1 minus x to the eighth
* Times 25 plus 816 times x squared and all of that over 3164 times one plus x squared
* And the answer that you get here is pretty entertaining.


--- SKIP ---: 01_what-can-we-do-with-integrals-besides-calculating-area.en.srt


--- SKIP ---: 01_what-can-we-do-with-integrals-besides-calculating-area.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-can-we-do-with-integrals-besides-calculating-area.en_SENTbySENT.txt
* [MUSIC] We've already used integrals to calculateareas and now, I want to use integrals to calculatevolumes
* I want to calculate the volume of somecomplicated object
* If I can cut it up into pieces, where Iunderstand the volume and each piece, then I can integrate to figure outthe volume of the whole thing, right
* You can take some complicated object andslice it up into slabs
* You can take some complicated object sliceit up into disks
* Take some complicated object, slice it upinto these washer shaped regions, right
* We're going to have all kind of differentways
* Of decomposing solid objects, in order tocalculate their volumes
* And this is really the first example ofsomething very general, there are all kinds of problems in thereal world where you can write down a, a Riemann sum thatyou would like to be able to, to calculate the, thelimit of, right
* A lot of real world problems are, aremodeled this way
* And if you, if you try to take the limitof a Riemann sum, what you're really trying to do is tocalculate the volume of an interval
* So, lots and lots of sort of, real world problems reduce down to some sort ofintegration problem
* [MUSIC] [BLANK_AUDIO]


--- SKIP ---: 01_what-happens-when-i-use-thin-horizontal-rectangles-to-compute-area.en.srt


--- SKIP ---: 01_what-happens-when-i-use-thin-horizontal-rectangles-to-compute-area.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-happens-when-i-use-thin-horizontal-rectangles-to-compute-area.en_SENTbySENT.txt
* [MUSIC]
* We dive into thinking more about volume and length and things, let's just focus a bit more on area
* So let's find the area inside here
* This orange curve is the graph y equals x squared, and this red line is just the horizontal line y equals 1
* So I want to figure out the area of this region which is below the red line and above the orange curve
* We already know how to attack a problem like this
* I take this region and cut it up into a vertical strips
* Alright, I'm going to imagine cutting it up into a whole bunch of thin rectangles
* And then I just want to add up the areas of those rectangles integrate
* Well to set up the intergral, and I should say pick a value of x
* And think now, how tall is this thin rectangle
* Well the top edge of the rectangle is at, 1, and the bottom edge is at x squared
* So, the height of this rectangle, here say, is one minus x squared
* That's the length here, say is 1 minus x squared
* That's the length here
* What's the width
* Well, I'm just going to call that dx
* Right, I'm going to imagine that these rectangles are real thin
* So, now the area of just this one rectangle is 1 minus x squared, that's its height times its width dx
* But I don't just want the area of this one rectangle
* I want to add up the areas of all these rectangles
* So, I'm going to integrate this from x goes minus 1 to 1
* Alright, and I get those end points by thinkin about how, small and how large x can be in this region
* So I put a minus 1 and a 1 there, and this definite interval will calculate the area of this region
* And I can calculate that definitne integral
* Let me just copy it down here
* The integral that I want to calculate is the integral x goes from minus 1 to 1 of 1 minus x squared dx
* And to calculate that integral, it's enough to use the fundamental theorem of calculus
* So I'll write down an anti-derivitive
* x minus x cubed over 3 is an anti-derivitive and then the fundemental theorum of calculus says evaluate this at 1 and at minus 1 and I take the difference
* So, I will plug in 1 and I'll get one minus 1 cubed over 3 and I am going to subtract what I get when I plug in minus 1 which minus 1 minus, minus 1 cubed over 3
* But what's this, this is 1 minus a third that's 2 3rd minus, minus 1 plus a 3rd which is negative 2 3rd, and 2 3rd minus negative 2 3rd, is 4 3rd
* So the area of this region is 4 3rd square units, but I could also do this by cutting the region up into horizontal strips
* So, here I am cutting this region up into some horizontal rectangles, which instead of being thin in terms of their width, they're now thin in terms of their height
* I just want to add up all of these not very tall rectangles to compute the area of this region
* So to do that I'm going to pick some value of y and I'm going to think about, for that value of y, how wide is is that rectangle
* Well let's think about this point over here, right
* This is the curve y equals x squared
* So for this value of y what's the corresponding value of x
* Well it's the square root of y, and that tells me how wide this whole rectangle is right
* And this point over here is negative the square root of y
* So, from here to here, is 2 square roots of y, that's the width of, of this rectangle, let me write that down
* So, I got the width of the rectangle is 2 square roots of y
* Now, how tall is that rectangle
* Well, let's call that dy, right, I'm imagining that the rectangle isn't very tall, really thin
* So the product 2 squared of y its width, and it's not very tall height d y
* That gives me the area of one of these thin rectangles and I'm going to integrate that
* But from where to where
* Well, y could be as small as 0 and as big as 1
* So this integral will calculate the area of this region, decomposed into horizontal strips
* I was going to do that integral, but I can definitely do that, right
* I can do this integral by using the fundamental theory of calculus
* I just copy that integral down over here
* It would be integrating from 0 to 1, 2 square roots of y dy, l only rewrite that as the interval from 0 to 1 of 2y to the 1 half power dy
* And now I can write down an anti-derrivitave of this by using the power rule
* So an anti-derrivitave is 2y to the 3 halves power, divided by 3 halves
* Right, an anti-derivative y to a power, is y to one more than that power, divided by one more than that power
* I want to evaluate that at 0, and at 1, and take the difference
* Well, when I plug in 1, I get 2 over 3 over 2
* When I plug in 0 I get 0, so the answer's 2 divided by 3 over 2, which I can rewrite as 4 3rd, which is the area of this region
* The neat thing here is that either way, we're getting the same answer, and I think this is more amazing than it seems at first
* I mean look, when I cut it into horizontal strips I ended up wanting to calculate this interval, the interval y goes from 0 to 1 2 square roots of y dy
* And when I cut the region up into these vertical strips I wanted to do the interval x goes from minus 1 to 1 of 1 minus x squared dx
* But these two intervals end up being equal because they're both calculating the area of the same region, they're both calculating 4 over 3 square units.


--- SKIP ---: 02_when-should-i-use-horizontal-as-opposed-to-vertical-pieces.en.srt


--- SKIP ---: 02_when-should-i-use-horizontal-as-opposed-to-vertical-pieces.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_when-should-i-use-horizontal-as-opposed-to-vertical-pieces.en_SENTbySENT.txt
* [MUSIC]
* We've seen that we can use either horizontal strips or vertical strips when using integrals to calculate area
* We end up computing the same number, the area of this region, whether we use vertical rectangles or horizontal rectangles, we're getting the same answer, the area of this region
* But if both work, which one should we choose
* The best choice depends on the shape of the region
* I like to think about how many different kinds of edges my rectangles will touch
* Here is an example to demonstrate what I mean
* I've drawn some region in here with three edges, this curved edge, this curved edge, and this straight edge along the x axis
* Now, I could calculate the area of the enclosed region
* Either by decomposing this into vertical strips or horizontal strips
* The bad news about vertical strips is that there's two different kinds of vertical strips
* There's vertical strips over here, and there's vertical strips over here
* The vertical strips over here touch the orange and the purple edge, and the vertical strips over here would touch the orange and the blue edge
* Contrast that with the much better situation that happens if I cut this up into horizontal strips
* All of my horizontal strips have an orange side and a blue side
* I only have one type of horizontal strip
* So I should calculate the area of a region like this using horizontal strips
* Let's take this advice and apply it to solve a specific problem
* So here's a bigger, specific version of this problem
* Let's figure out the area of this region
* this orange curve is the curve y equals the square root of x, and this blue curve is y equals the square root of 2x minus one
* And then here I've just got the purple line along the x-axis
* I've really got a choice as to how to approach this
* I could do this with vertical strips
* But then I'd have to do two different integrals
* I'd have to handle the case over here where rectangles are touching the orange line and the purple line
* And I'd have to do an integral over here where my rectangles are touching the orange line and the blue line
* It's going to be better to use horizontal strips
* In that case, all of the rectangles are the same kind of rectangle, they're a rectangle with one edge on this orange curve, and one edge on this blue curve
* Let me just draw one of those thin horizontal rectangles
* I have to figure out the size of that rectangle
* Let's suppose this thin strip is at height y
* I know how tall this strip is
* I'll call that dy
* But how wide is this green strip
* I should figure out what this point and where this point is
* And if I think about it a little bit, if this is y, I can solve this equation and find out that in that case x
* Is y squared, and I can similarly solve this equation and find out that if this point has a y coordinate y, the x coordinate will be y squared plus 1 over 2
* And that tells me the width of this green rectangle, it's this minus this
* I'm going to write down the area of that green rectangle
* So the width is y squared plus 1 over 2 minus y squared, that's how wide this rectangle is
* And the height of that rectangle is dy, so this product is the area of that green rectangle
* But of course I don't care just about that one rectangle, I want to integrate so that I'm adding up the areas of all kinds of thin rectangles
* And then in the limit I'm getting the area of this region exactly
* So instead of just this single rectangle, I'm going to integrate y goes from where to where
* Well, I look at my picture here, y can be as small as zero and as tall as this point up here which is one
* So y goes from zero to one and this interval calculates the area of that region
* Let's do the calculation
* This integral is the integral from 0 to 1
* for I can simplify the integrand a bit
* It's 1 half minus y squared over 2 dy 
* And now we can write an antiderivative for that
* So I add a derivative of 1 half
* One half y and a derivative of y squared over 2 is y cubed over 6
* I'm going to evaluate that at 0 and 1, take a difference
* But when I plug in 0 I just get 0
* So the answer is whatever I get when I plug in 1
* And that's 1 half times 1, minus 1 cubed over 6
* Could simplify that a bit, that's 1 half minus a 6th, and 1 half, well, that's 3 6ths, so 3 6ths minus 1 6th, is 2 6ths, which you might write as, 1 3rd
* So the area of that, shark fin shaped region is a third of a square unit
* Often, it's not there are right ways or wrong ways but there are better ways and worse ways, right
* Ways that are better in that they are quicker, safer, more elegant
* So don't just make good choices
* Make the best choices.


--- SKIP ---: 01_what-does-volume-even-mean.en.srt


--- SKIP ---: 01_what-does-volume-even-mean.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-does-volume-even-mean.en_SENTbySENT.txt
* [MUSIC] We've done a bunch of areacalculations at this point, so let's move up a dimension andthink about volume
* Let me ask, really loudly, what is Volume
* Of course, what is area, right
* Area is the thing thatintegrals calculate
* So instead of trying to givea definition of volume, let's just focus on how we're gonnacompute volume, whatever it is
* And we're gonna compute volume byintegrating the volume of little, tiny pieces that we cutup our objects into
* Let's work through an example
* Here's a cone
* I want to compute the volume of this cone
* Just for concreteness, let's suppose thatthe cone has a height of two units and a radius of one unit, andI want to compute its volume
* I want to set this thing upas an integration problem
* I want to cut this thingup into slices and add up the volumes of the little slices
* So imagine that I take this and I just slice it up intoa bunch of really thin pieces
* Now what's the volume of a slice
* Well that slice is practicallya little tiny cylinder
* So what's the volume of oneof these very thin cylinders
* Well let's suppose the cylinderhas some radius r
* And I'm going to call its height,its height should be really thin, so I'll call its height dx
* And in that case the volume of thiscylinder is, what's the area of the top
* It's pi r squared times its height,which is dx
* So, this here will be our formula forthe volume of one of these thin cylinders
* And, once again, we're seeing theimportance of the differentials, right
* We're using the differentialsto write down an equation for the volume of the thin cylinder
* Anyhow, let's put thistogether in integral
* But to set up the integral tocalculate the volume of this cone, I first have to figure out the volume ofone of the slices that make up this cone
* To do that,let's turn this cone on its side, and let's imagine that this is the point 0, 0
* So let's make this the y axis, sothe x axis will head in that direction
* Then what do I have here
* Well, this line is the liney equals x over 2
* Now I'll use that to figure outthe radius of one of those slices
* Pick some value of x, andlet's think about one of the slices
* One of these thin cylinders thatI'm using to build up the big cone
* I don't know the radius ofthat particular cylinder
* Well, it's this distance here, andI know the Y coordinate up there
* The Y coordinate is X over 2, so theradius is of this cylinder is X over 2
* I can write down the volume of that disk
* The volume is pie times the radius, which is x over 2 squared timesthe thickness of that disk which is dx
* And now I'm integratingthis from where to where
* Well x goes from 0 all the way down to 2,so this will be the integral from x equals 0 to 2 and this integralwill calculate the volumn of my cone
* And now we use the fundamentaltheorem of calculus
* I can simplify this a bit, I have someconstants here I can pull out, right
* I can pull out the pie andI can pull out 1/2 squared
* This is pi over 4 timesthe integral from 0 to 2
* Just x squared dx
* Now, what's an anti-derivative forx squared
* Well, x to the 3rd over 3
* And then, I'm integrating that
* I'm evaluating that at 0 andat 2 and taking the difference
* So when I plug in 0, I don't get anything,but when I plug in 2, I get 8
* That's 2 cubed over 3, and then minus 0
* So this is the volume of the cone,which I could simplify somewhat
* I could write this as 2 times pi over 3
* We did it
* Well, you could have just looked up thisformula in the back of some calculus text book, butthat's beside the point here, right
* The point here is that we'reteaching you the secrets of volume
* You can now verify that the formulas inthe back of the textbook are correct
* And that's part of the fun of mathematics,we're not just giving you information
* We're giving you the information and the tools with which to verifythat that information is correct.


--- SKIP ---: 02_what-is-the-volume-of-a-sphere.en.srt


--- SKIP ---: 02_what-is-the-volume-of-a-sphere.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-is-the-volume-of-a-sphere.en_SENTbySENT.txt
* [MUSIC]
* We're going to compute the volume of a sphere
* Well here I got a clay sphere
* And if I measure if I find that it's diameter its about 4.2
* The diameter is about 4.2 centimeters
* So its radius, say 2.1 centimeters
* Now, we're going to take this sphere and crush it flat
* And I want to make it so that it's about 1 centimeter thick
* Now I'll estimate the volume of that blob
* So we measure this thing's maybe a bit under 7 centimeters by a bit over 5 centimeters, and it's a centimeter thick
* So I'd guess that the volume is about 35 cubic centimeters
* But that wasn't all that precise
* But we can do the calculation precisely by taking the sphere, slicing it into discs thin cylinders
* Integrating those thin cylinders right and that'll give us the exact volume of the sphere
* So, we're going to take the sphere and I'm going to slice this thing up into lots and lots of little tiny cylinders
* We have to figure out the radius of each of those thin cylinders
* Well let me draw the picture again, alright
* Here's the plane, this is the y axis and the x axis, and I've got my circle in the xy plane
* And here is the sphere sitting in space
* And in some height call that height y
* I got a thin cylinder, what I want to do is to figure the radius of that thin cylinder
* Really what that amounts is figuring out the coordinates of this point here
* Right
* I want to figure out what that x coordinate is, so that x, y lands on that circle
* Well I know the equation for the circle in the xy plane
* That's x squared plus y squared equals r squared, r is the radius of the sphere that I'm thinking about
* And I can solve this for x
* X equals the square root of r squared minus y squared
* This is the radius of this little tiny thin blue cylinder here
* And I'm going to cut up my sphere into a whole bunch of these little tiny cylinders
* And add up the volume of those cylinders to give me the volume of the whole sphere
* Now I want to figure out the volume of that thin cylinder
* Now, what's the volume of this slice
* What's the volume of that thin cylinder
* Well, it's pi times the radius of that cylinider, which is given by this
* So the radius is the square root of r squared minus y squared and it's that radius squared
* Right, this is pi radius of cylinder squared, times the height of that cylinder, well the height of that cylinder is dy
* So this is giving me the volume of this thin cylinder
* We have to think about the end points of integration
* Well how big and how small can y be
* Well y goes all the way down here to minus r and y goes all the way up here to r
* So when I set up my integral and I want to integrate this, y goes from minus r to r
* Now we can integrate
* So first I'll simplify the integrand
* This is the integral y goes from minus r to r of pi times the square root squared, just r squared minus y squared dy
* Now I can simplify this a bit more
* I've got a constant, always pull that constant out
* This is pi times the integral from minus r to r of r squared minus y squared dy
* Now I've gotta cook up an anti-derivative of this
* Alright, to use a fundamental term of calculus
* So this'll be pi times, so what's an anti-derivative of just r squared, r is just a constant here
* So an anti-derivative of that will just be r squared times y minus an anti-derivative of y squared is y cubed over three
* I'll be ecaluating that from r and minus r
* But if you think about it a bit I can get away with using from 0 to r if I multiply this by 2
* And that'll simplify the calculation somewhat
* Alright, now I was going to plug in r and plug in 0
* So, when I plug in r, I get r squared times r minus r cubed over 3
* And when I plug in 0 I just get 0
* So I don't have to subtract that
* And I can keep working on this
* What do I do
* I got 2 pi r cubed minus 1 3rd r cubed
* Let's call this 3 3rd's cubed
* Alright, so this is now 2 3rd r cubed times 2 pi or this ends up being 4 3rd's pi r cubed
* We did it, yeah the volume of a sphere here of a radius r
* We just calculated it, its 4 3rds pi r cubed and we could reach into even higher dimensions
* For example, you could try to write down an integral that calculates the volume of a hyper sphere
* What's a hyper sphere
* Well, that's the higher dimensional analog of the regular old sphere, a sphere is sort of a stack of circles
* So a hypersphere will be a stack of spheres but in the fourth dimension.


--- SKIP ---: 03_how-do-washers-help-to-compute-the-volume-of-a-solid-of-revolution.en.srt


--- SKIP ---: 03_how-do-washers-help-to-compute-the-volume-of-a-solid-of-revolution.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-do-washers-help-to-compute-the-volume-of-a-solid-of-revolution.en_SENTbySENT.txt
* [MUSIC]
* Let's figure out the volume of a certain solid of revolution
* For example, let's think about this region inside here, the region that's below the graph of y equals the square root of x
* And above the graph of y equals x squared, just this little wing shaped region inside here and let's take that region and rotate it around the x axis
* When I take a region in the plane, and rotate it around an axis, I get a solid of revolution
* And the question is what's the volume of that solid
* Well let's cut this region up into little tiny thin rectangles, and then, instead of rotating the whole region, at once around the x axis
* Let's just imagine rotating each one of these little rectangular pieces around the x axis, and then adding up the volumes of pieces
* What do those little rectangles become when I rotate them around the x axis
* I'm going to take one of these little thin rectangles, and rotate them around the x axis
* Well, to just get a picture here let me just isolate a single rectangle, and imagine just taking this
* Thin rectangle, and rotating it around the x axis
* Well what would happen when I do that, alright, is that I'll end up getting a shape that looks a bit like that, alright
* That shape we're going to call a washer
* What's the volume of a washer
* Let me make this picture a little bit bigger, alright
* Here's a big picture of a washer
* And what are the parts of a washer
* Well, the washer is got a thickness which allows it to be thin
* So, I'm going to call it dx
* It's got a small radius which I'll call little r and then it's got a big radius which I'll call big R
* Now, If I were jsut thinking about whole scylinder of radius big r
* I know the volume of that
* The area of a circle of radius big r is pi big r squared
* So if I thicken that up, the volume of a cylinder of radius big r is pi, big r squared and the thickness here is dx
* But then I'm drilling out this middle part here to make the washer
* So I'm going to subtract from this the volume of this inside cylinder which is pi little r squared dx
* So this is the volume of just the washer and the part that remains and I can write this may be a little bit more reasonably as pi
* Times big r squared minus little r squared times the thickness, dx
* Now I'll use that formula, the volume formula for washer to write down the integral that calculates the volume of solid of revolution
* I'm going back to this picture here
* I want to figure out the volume of say, the washer at x
* So, first think about what's the big radius
* Well the big radius here is on the red curve, right that's the outside of the washer
* So big R is the square root of x
* And then the inside radius is on the orange curve and that's given by x squared
* so little r is x squared
* And that's the outside radius and the inside radius in my in my washer picture here
* Okay, now I just gotta use the formula for the volume of that washer, right
* And the formula for the volume of the washer there is pi times big R squared minus little r squared times the thickness of the washer, which is dx
* What about the endpoints of integration
* Well in my picture, x could be as small as zero, or as big as one
* Alright, I want to add up the volumes of washers for x between 0 and 1
* So my integral is going to go from x equals 0 to 1
* Now all that remains is to evaluate that integral
* So to begin, I'll simplify the integral a bit, this is the integral from 0 to 1, Р вЂќР вЂ№Р вЂ™Р вЂљ times square root of x square, that's just x, minus x squared squared, that's x to the 4th
* I've got a constant pi
* I'll pull that constant out
* This is pi times the interval from zero to one of x minus x to the fourth, and I've just gotta write down an anti derivative for that
* So that's pi times anti derivative of x is x squared over 2
* Minus anti-derivative x to the 4th, x to the 5th over 5
* I'm evaluating this at 1, and at 0, and taking the difference
* when I plug in 0 I don't get anything, so the answer is just whatever happens when I plug in 1, which is pi times one half, minus one 5th
* And, if I like, I could write this as a single fraction, this is pi times 5 10ths, minus 2 10ths
* Or, all together, pi times 3 10ths, so that's the volume of the solid of revolution
* And we did it.


--- SKIP ---: 04_what-is-the-volume-of-a-thin-shell.en.srt


--- SKIP ---: 04_what-is-the-volume-of-a-thin-shell.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_what-is-the-volume-of-a-thin-shell.en_SENTbySENT.txt
* [MUSIC]
* We can cut a three dimensional object up into shapes beyond just slabs, disks, washers
* Specifically instead of building an object out of disks, instead of building it by stacking up disks of varying radii
* We can build the object by wrapping it with these shells
* This shell thing is supposed to be like a cardboard mailing tube
* It's a cylinder sort of a thin wall
* But how are shells different from washers
* Well there are some similarities
* Both shells and washers are things that you get by taking cylinders and drilling out other cylinders
* But for washers, the thin dimension is its height
* And for shells, the thin dimension is sort of the thickness of this wall
* We need to write down a formula for the volume of a shell in terms of it's height, it's radius and that thin dr
* Let me label those parts on the diagram here
* So the height of the shell
* I'll call h, the thickness of the shell
* I'll call that dr, and the radius of the shell I'll just call r
* Now, if I get out my scissors of mathematics here and cut the shell
* You might imagine unrolling the shell, and then you just end up with a slab like this
* How big is this slab
* Well, the slab's height is still h
* The thickness of this slab is dr
* And how long is this slab
* Well the slab's as long as the circumference of the circle , which is 2 pi r
* And multiplying these three dimensions will give me the volume of the slab
* So you're guessing that the volume of the shell or the slab is 2 pi rh dr
* We can say something a bit more precise
* Well here's the shell again
* But instead of calling this dr
* Let's think of this as a big cylinder, with a little cylinder drilled out
* So both the cylinders have the same heighth, h
* But let's say the big cylinder has a radius, r
* And the little cylinder has a radius little r
* Let's write down the formula for the volume of the shell in between
* So now the volume of the shell, right, is the volume of the big cylinder pi big R squared h
* Minus the volume of the little cylinder that I drilled out, pi little r squared h
* In effect you'll recognize that this, this makes it look a lot like a washer
* But here's the difference, little r is really close to big R
* Right, I'm thinking of their difference as dr
* Right, very thin walled cylinder
* Well lets rewrite this volume anyhow
* I'm going to factor this out pi
* Big R squared, minus little r squared, h
* Now let's rewrite this
* This is a difference of squares, so I can write that as pie, big R plus little r
* Big R minus little r, h
* And thinking of the difference in these radii as being really small
* So I'm going to rewrite this term as dr
* So this is pi, big R plus little r, and I'll write h dr
* Now what do I do with big R plus little r
* Well this is the sum of these two radia
* I mean, if you think about big R and little r as being really close together
* I might as well just write this as 2 little r
* So I'll write this 2 pi little r
* That's 2 little r's, if I'm imagining big R and little r to be close together, h dr
* And you'll see this is the same as the formula that I got before for the volume of a shell
* This formula, the formula for the volume of a shell, to write down an integral that calculates the volume of a solid of revolution
* As an example, let's take this region
* This is the graph y equals 1 minus x squared
* And I just want to consider y greater and equal to 0, so consider this region inside here
* So let me write y less than or equal to 1 minus x
* So just to emphasize this, it's this region inside here, and let's take that, and let's rotate that region around the y axis
* To give myself this solid of revolution, I'm going to calculate the volume of that solid
* Admittedly, we could do this problem without using shells, but using washers
* In that case, I'd be chopping the region up into horizontal slices
* And each of these horizontal slices, when I rotate it around the y axis would give me a disc
* And then I just integrate the volumes of those discs to give me the volume of the solid of revolution
* But let's try it with shells
* In this case, I'll cut it up into vertical slices and I'll rotate these vertical slices around the y axes to produce shells
* And I'll integrate the volumes of those shells
* To give me the volume of the whole solid of revolution
* Now, we're going to use the formula, for the volume of a shell
* Let's just look at one of those shells
* So, here's one of these thin rectangles, I imagine, rotating this thin rectangle, around
* The the y axis to produce this shell
* Now, how how tall is this shell
* Well, the height of that shell is given right here
* It's 1 minus x squared
* The radius of the shell is x and the thickness of that shell is dx
* So, I put all those pieces together
* I can write down the volume of just that one, one shell
* And it'll be 2 pi, the radius of that shell
* The height of that shell, the thickness of that shell
* Now I have to worry about the end points of integration
* You might think that I'd be integrating from x equals minus 1 to 1
* But actually I only have to integrate from x equals 0 to 1
* Because rotating a thin rectangle over here also accounts for stuff happening over here
* So it's enough just to integrate from x goes from 0 to 1
* So I'll write that here, x goes from 0 to 1
* This integral will calculate the volume of my solid of revolution
* Finally, it's just a matter of evaluating the integral with the fundamental theorem of calculus
* And to do this integral
* Well I'll pull out these constants, 2 pi, the integral from 0 to 1 of x minus x cubed, when I combine these two terms
* Now I just have to write down an antiderivative here
* 2 pi, antiderivative of x is x squared over 2, anti-derivative x cubed is x to the 4th over 4
* And I'm evaluating this at x equals, 1, and x equals 0
* And I'm subtracting, alright
* That's the fundamental theorem of calculus
* But when I plug in 0, I just get 0
* So the answer is just whatever I get when I plug in 1
* And, that's 2 pi, a half minus a 4th, and a half minus a 4th is a 4th
* So, 2 pi times a 4th, and 2 times a 4th is a half
* So, pi over 2, is the volume of my solid of revolution
* We did it.


--- SKIP ---: 05_what-is-the-volume-of-a-sphere-with-a-hole-drilled-in-it.en.srt


--- SKIP ---: 05_what-is-the-volume-of-a-sphere-with-a-hole-drilled-in-it.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_what-is-the-volume-of-a-sphere-with-a-hole-drilled-in-it.en_SENTbySENT.txt
* [MUSIC]
* Let's compute the volume of a bead but first we have to figure out how we're going to build the bead as a solid of revolution
* So start with the X, Y plane and I'm going to draw a circle of radius two in the plane
* So, its a circle of radius 2 if I take this and rotate around the Y axis and I got a sphere, but I want to bead, so I am going to imagine drilling out a hole around the Y axis
* So to do that we can draw these vertical lines here
* This is the line x equals 1
* This is the line, x equals minus 1
* [NOISE] Okay, now if I just take the the region in here, and rotate that region around the y axis, that gives me a bead
* It's the same thing as giving me a sphere
* With a hole drilled out around the y axis
* We've got a choice
* We can attack this problem with shells or with washers
* If I want to do it with washers, since I'm rotating around the y axis, I'd be cutting this into horizontal strips
* Because if I take one of these horizontal strips and rotate it around the y axis, that gives me a washer, and that looks like here is my here's my big washer
* And that's, that works
* There's nothing wrong with that, but it turns out that if you do it the way the interval that you get is kind of yucky
* But let's try it instead with shells
* If I go with shells, then I'd be cutting into vertical strips
* Parallel to the axis of rotation
* And when I take one of those little vertical strips and rotate it around
* Well then exactly what I've got is, is one of these shell pieces
* Now we invoke the formula for volume of a shell in terms of dx
* So the formula is 2 pi, the radius of the shell
* Which if I think of just one of these pieces say at x, the radius is x, since that's how far it is from the axis of rotation
* The height of the shell, which I haven't figured out yet, times the thickness of the shell, which is then dx
* Now I need to determine the height of the shell
* So that big sphere has radius 2
* And this orange curve is that circle with radius 2
* So I can write down that that orange curve is y equals the square root of 2 squared minus x squared
* And, that's almost enough information to tell me the height of the shell
* Let me write down what the height of this shell is, then, the height of the shell is well, how tall is this thing
* Well here, from here to here, is the square root of 2 squared minus x squared, and then it's the same distance, down to the other side here
* So, the height, is twice this quantity
* So, I can write that down; 2 Pi X times the height of the shell, which is 2 times the square root of 2 squared, which is 4 minus X squared
* That's the height of the shell, and then the thickness of the shell dx
* Let's think about the endpoints of integration
* This purple line, right, was the line x equals 1
* And the orange circle, right, has radius 2
* So, x can take values between 1 and 2, and that tells me what my end points of integration should be
* So, this is the volume of just one of those shells, and I'm going to integrate that x goes from 1 to 2, to get all of the shells, and add them all up
* Finally, we integrate it's 2 pi times the integral from 1 to 2, and I'll write 2x, the square root of 4 minus x squared dx
* And this is really where shells shine, I set this up now, and you can see I can make a u substitution here
* So I'll set u equal 4 minus x squared, du in that case is minus 2x dx, put a minus sign there and a minus sign there
* Now I've got du square root of u, so this integral becomes minus 2 pi
* Square of u d u and I can change the endpoints, u goes from when x is 1, u is 3
* When x is 2, u is 0, and this is negative from 3 to 0, so I can rewrite this as 2 pi the integral from 0 to 3 of the square root of u du
* Now, that's not hard to do
* I can rewrite that integrand as 2 pi the interval of u to the 1/2 du from 0 to 3
* And I can easily anti differentiate that using the power rule
* So this is 2 pi, u to the 3 halves over 3 halves evaluated at 0 and 3
* Now, when I plug in zero I just get zero, so my answer is whatever I get when I plug in three
* So the volume is 2 pi times 3 to the 3 halves power over 3 halves
* Now, instead of writing 3 to the 3 halves power, I could write this as 2 pi over 3 halves times 3 times the square root of 3
* Right, that's the same as 3 to the 3 halves power
* But look, this 3 and this 3 cancel and I'm dividing by a half here, so this ends up being 4 pi times the square root of 3
* This is the volume of our bead
* We did it, but is the answer reasonable
* Well to think about how reasonable our calculation for the volume of the bead was
* We could think about how we build the bead, alright we build this thing by starting with the sphere of radius two and then drilling out a tube of radius one
* So if I start with the sphere of radius two and I subtract even more volume right, this cylinder of height four extends above the top of this sphere and below the bottom of the sphere
* So this is even more material than I removed to get the bead
* Well that means that the volume of this sphere minus the volume of the cylinder's got to be even a little bit less than the volume of the bead, right
* Because this is a little bit more, material than the material that we removed to get the bead
* Well how big are these three things
* This thing here is a 4 3rds pie radius cubed thats the volume of a sphere minus this thing here is pie r squared times height is the volume of a cylinder
* I could simplify this a bit this is a 4 times 8 so that's 32 3rd pi minus 4 pi, and I can simplify that a little bit further even, that's 20 3rd pi
* And what do we get to the volume of the big bead we calculated that to be 4 pi square root of 3
* And yeah, this quanitiy here is just a bit smaller than this quantity here
* So, it seems like our answer's reasonable.


--- SKIP ---: 01_what-does-length-even-mean.en.srt


--- SKIP ---: 01_what-does-length-even-mean.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-does-length-even-mean.en_SENTbySENT.txt
* [MUSIC]
* Here's a little puzzle about length
* I've got an isocoles right triangle
* And let's say that both of the legs of this right triangle have the same length 1
* And we know the length of the hypotenuse by the Pythagroem theorem
* Well, that tells us that this length is the square root of 2
* But let's try to think about this differently
* What if, instead of a smooth ramp, I made stairs
* I mean, instead of this ramp picture, I have a picture like this, right
* A staircase
* What's the length of the staircase
* The total length of the staircase is 2
* To see that, just look at the horizontal sections of the stairs
* That's the same as the entire bottom edge
* And the vertical sections of the staircase is the same as this whole edge
* So 1 plus 1 is 2
* What happens if I make those stairs even smaller
* The length is still 2
* Because again, all of the vertical sections of the staircase add up to this length
* And all of the horizontal sections of the staircase, and I'm[UNKNOWN] pushing them all down, add up to this length
* So, the total length of the staircase is still 2
* What happens if I make those stairs really small
* Well, even if the stairs are really, really small, the total length of the staircase is still 2
* What is going on here
* The length of the ramp is a square root of 2
* The length of the staircase is 2
* No matter how small I make the stairs, even if I made each stair the size of a proton, the staircase would still have length too
* The point is that even something as seemingly obvious as length, is more subtle than I think we give it credit for
* What we really need is some sort of definition of length
* We'll do it in terms of an integral
* So just like with volume or with area, I'm going to take this thing that I'm interested in, say the length here
* And try to break it up into little pieces that I'll then add up with an integral
* So let's imagine that I cut this up into little tiny pieces and that I just connect these by straight lines
* And then I can just add up the length of these little tiny straight lines and call that, in the limit, after I integrate, the length of this curve
* I want to write down an integral that captures that intuition
* Well, let's just look at one little piece of this thing here
* let's write a little triangle there so i can call the change in x dx, and the change in y dy and what I'm interested in is how long this little green line segment is
* Well, you might think then that little green line segment has the length square root dx squared plus dy squared
* And then you integrate to get the total arc length, just play around with that a little bit
* Specifically lets imagine pulling a dx outside of this
* So when I get this is the intergral
* The square root of 1 plus, and if I factor out a dx here, I have to include a dx in the denominator there
* And this has the advantage at least of now looking like the derivative, right, dy over dx, that's how I've been denoting the derivative, and this form is the sort of thing that I can integate
* So here's the formula that we're going to use
* The arc length from a f of a to b f of b along the graph of f is the integral x goes a to b of the square root of 1 plus the derivative squared and that's exactly what I saw here dx
* I hope that you're feeling just a little bit uneasy at this point
* I'm really treating dx and dy as if they're legitimate mathematical objects, and you should be a little bit uncomfortable with that at this point.


--- SKIP ---: 02_on-the-graph-of-y-2-x-3-what-is-the-length-of-a-certain-arc.en.srt


--- SKIP ---: 02_on-the-graph-of-y-2-x-3-what-is-the-length-of-a-certain-arc.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_on-the-graph-of-y-2-x-3-what-is-the-length-of-a-certain-arc.en_SENTbySENT.txt
* [MUSIC]
* We defined arc length using an integral
* The integral that we'll be using is this one
* I'm going to be integrating from a to b the square root of 1 plus the derivative squared dx
* Let's apply this to a specific problem
* Let's compute the arc length of a little piece of a graph
* So let's look at the graph of y squared equals x cubed and figure out the length of this arc from 0,0 to 1,1
* Now I could rewrite this equation
* Instead of writing y squared equals x cubed, I could write y equals x to the 3 halves power
* We'll start by differentiating
* So because of this, I can write dy, dx is 3 halves x to the 1 half power
* We'll put that derivative into the formula for arc length so I'm going to be integrating
* X goes from 0 to 1, the square root of 1 plus this derivative squared
* So, I'll write 3 halves, x to the 1 half squared dx
* Now, I just want to compute that integral
* But how
* Well, I can rewrite the integrand
* This is the integral from 0 to 1 of the square root of 1 plus 3 halves squared is 9 4ths
* And x to the one half squared, I'll write x, dx
* Just have no fear, keep going
* Well, I could use substitution
* u equals 1 plus 9 4ths x so that du is 9 4ths x or alternatively, dx is 4 9ths du
* And that means this integral, it's the same as the integral of square root of u times 4 9ths du and remind you bounce of integration
* Well an x is 0, u is 1 and when x is 1 u is 14 4ths
* Alright, now I just have to write down an anti derivative here, well I could write this as 4 9th, u to the 3 halves over 3 halves that's an anti-derivative for square root 2, evaluated at 1 and 13 4th
* So I'm just going to plug in 13 4th plug in 1, take the difference
* Okay, so this is 4 9th, I write, times 2 3rd, instead of dividing by 3 halves
* Times 13 4th
* To the 3 halves power minus 4 9th times 2 3rd times 1 to the 3 halves power and I got to simplify this little bit more even lets see here
* 4 times 2 is 8, okay that's also 4 to the 3 halves power
* So I can cancel all of these things
* And then I can simplify gotta do some arithmetic here
* So I've got what, 13 to the 3 halves power divided by 9 times 3 is 27, minus, this is 8 27ths just times 1
* And, if you don't like the 3 halves here, I could write this as 13 times the square root of 13 over 27 minus 8 over 27
* This, is the length of that arc
* We did it, but it worked out almost too well
* Alright that's the sad thing about arc length calculations
* Because the arc length formula involves that square root of 1 plus a derivative squared, it's extraordinarily unlikely
* And if you just give me some random function, I'm going to succeed in being able to evaluate that integral
* The sorts of things we can calculate the arc length of are pretty special sorts of things.


--- SKIP ---: 01_welcome.en.srt


--- SKIP ---: 01_welcome.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_welcome.en_SENTbySENT.txt
* Hello, my name is Helen Tibbo
* Welcome to Research Data Management andSharing
* Before I describe what we willbe exploring in this course, I would like to tell you a littlebit about the CRADLE project, and my background
* This MOOC was developed bythe CRADLE project at the University of North Carolina at Chapel Hill, and was funded by the Institute of Museum andLibrary Services, or IMLS
* The CRADLE project stands forCurating Research Assets and Data using Lifecycle Education, and is a collaboration between the Schoolof Information and Library Science, the Odum Institute for Research and SocialScience, and the UNC University Libraries
* EDINA and the Data Library atthe University of Edinburgh also contributed content to this MOOC
* The folks at the University of Edinburghhave created another great resource for learning about research datamanagement called MANTRA
* We strongly encourage studentsto explore this rich resource
* Now, a bit about me andwhy I am teaching this course
* I am an alumni distinguished professorat the School of Information and Library Science at UNC,where I teach courses on data management, digital preservation,and records management
* I was president of the Society ofAmerican Archivists from 2010-2011, and I have been the principalinvestigator on a number of IMLS funded projectsfocused on digital curation
* I am currently the head of the Standardsand Policies, Community Practice for the National Science Foundation funded Datanet Federation Consortium Projectbased at UNC
* So, why learn aboutresearch data management
* Today funding agencies and journalsare increasingly requiring researchers to share, archive, and plan forthe management of their data
* As research and information professionalsrespond to these new requirements, data curation knowledge is necessary forthe effective management, long-term preservation, and reuse of data
* This course will provide studentswith knowledge of data management, best practices throughoutthe research life cycle from the planning stage all the way towhen data will ideally be shared and made available withina trustworthy repository
* Besides responding to requirements,effective data management can also help researchersoptimize their research output, increase the impact of their research andsupport open scientific inquiry
* We will begin this course bybuilding a basic understanding of research data and data management
* We will then cover data managementplanning and funder requirements
* In module three, we will delve moredeeply into some best practices and suggestions for working with data
* And then in module four,we will discuss the benefits and challenges of data sharing, and some techniques to enable researchersto easily use each other's data
* We will end with a moduleon how to preserve data and the roles of trustworthy repositories
* By the end of this course, you will havea firm understanding of data management best practices, as well as many datamanagement tools and resources to help you foster data sharing and the conductof better science and scholarship
* Let's start
* [MUSIC]


--- SKIP ---: 01_research-data-defined.en.srt


--- SKIP ---: 01_research-data-defined.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_research-data-defined.en_SENTbySENT.txt
* [MUSIC] To begin this course,we need to first discuss some basics
* The most fundamental question forus is what are data
* While this may seem likea straightforward question, numerous organizations have tackled itresulting in a range of definitions
* It's important to note that dataare different for various disciplines and different context
* By the end of this lesson, you will be introduced to multipletypes of data in an array of contexts
* Data come in many forms from numeric and textual data to biological samples andphysical collections
* You will also be able to makethe distinction between research data and other associated researcher materials
* Some of which may berequired alongside the data to understand the data themselves
* And finally, and this is probably one of the mostimportant concepts in the entire course
* You will understand data in the contextof the research data life cycle
* To understand data management, is tounderstand data in all of its constructs
* From project planning, through thecollection of data to archiving that data as a research output afterthe project period has ended
* First, let's take a look athow others have defined data
* The National Institutes of Health, or NIH,define data as Р Р†Р вЂљРЎС™recorded factual material commonly accepted inthe scientific community as necessary to validateresearch findings.Р Р†Р вЂљРЎСљ Key concepts here include recorded and accessible data that others may lookat to validate a studies findings
* The National Science Foundation orNSF considers data to be something, determined by the community of interestthrough the process of peer review and project management
* NSFР Р†Р вЂљРІвЂћСћs definition points out the data areessential to the research community and not just to individual researchers orresearch teams
* NSF also offers some examples of data that make the rather abstractdefinition easier to understand
* As we know, examples are always useful
* The NSF list includes data, publications, samples, physical collections,software, and models
* It's interesting that NSF includesdata as an example of data, but the point here is there are many typesof data beyond quantitative datasets
* The National Endowment forthe Humanities, or NEH, also offers examples of data thatincludes citations, software code, algorithms, digital tools,documentation, databases, geospatial coordinates,reports and articles
* It is interesting to note that NEHincludes a wider array of data types than we see from NSF or NIH
* Any of these data types NEHdefines as humanities data, or Р Р†Р вЂљРЎС™materials generated or collected duringthe course of conducting research.Р Р†Р вЂљРЎСљ So what are some key conceptsin these definitions
* For NIH and NSF, the researchcommunity establishes definitions of data that involve validity andpresume data sharing among the community
* When you look at the examples providedby any of these organizations, you can see that data come inquite a significant variety of forms, almost to the point of being nebulous
* What is important to understand here is that data are products of researchthat are heterogeneous across and contextualized withinthe academic disciplines
* So to reiterate,data should be valid, shared, and are heterogeneous, and contextualizedwithin research communities
* [MUSIC]


--- SKIP ---: 02_types-of-data-and-metadata.en.srt


--- SKIP ---: 02_types-of-data-and-metadata.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_types-of-data-and-metadata.en_SENTbySENT.txt
* [MUSIC] Let's look at different types of data
* Probably what most of us think aboutwhen we use the term data is numeric or tabular data, what researchers mightrefer to as quantitative data
* And then there are other types
* Samples such as DNA orblood samples, physical collections, including plant specimens,software programs and code, databases, algorithms, model, and geodatabases
* Obviously, these are not allthe types of data out there
* Can you think of other examples
* What types have you encountered
* Please share them in the forum
* There are other research products thatneed to be considered alongside data in order for the data to be meaningful
* These include questionnaires, code books,and descriptions of methodologies
* Jillian Wallis, Elizabeth Rolando, and Christine Borgman describethis as background data
* Background data provides contextualinformation important in the analysis of the primary foregrounddata collected for analysis
* For example, what the temperature wasat the time a sensor reading is taken may be critical to understandingvariances in data a sensor collected
* And then there are research productsbuilt on the data that are essential for secondary analysis or meta-analysis andfor content dissemination
* These include reports, conference posters,articles, white papers, and books
* And we should include websites and blogs
* Another essential concept indata management is metadata
* This is a term that you will hearme refer to throughout this course
* Metadata is often definedas data about data
* This, of course, is a basic and circulardefinition that may not help us too much
* More specifically, metadata isstructured information that describes, explains, locates, orotherwise represents something else
* For our interest in this course,that something else is, of course, our target research data
* Metadata makes it easier to retrieve,use or manage an information source
* Data are nothing without metadata,especially digital data
* One cannot search for, identify, orinterpret data without robust metadata
* For each dataset, we need to knowat minimum, who created the data, when the data were created orpublished, and a title or descriptive nameused to refer to the dataset
* In this digital landscape,we also need a unique and persistent identifier forthe data so that we can locate it, even if the data are moved toa different location on the web
* Beyond these metadata elements,we can increase our ability to find and identify data if we haveinformation about these, along with the other 11 metadata elements that makeup the Dublin Core Metadata Element Set
* Dublin Core allows us to find andidentify data
* But to be able to interpret anduse data as they were intended, we also need to know quite a bit ofother information about the data
* The Data Documentation Initiative, or DDI, developed a metadata schemespecifically for this purpose
* Along with basic Dublin Core Elements, DDI prescribes additionalmetadata elements that provide specific informationabout data collection processes, variable-level descriptions,and methodologies
* [MUSIC]


--- SKIP ---: 03_research-data-lifecycle.en.srt


--- SKIP ---: 03_research-data-lifecycle.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_research-data-lifecycle.en_SENTbySENT.txt
* [MUSIC] When thinking about and doing datamanagement, it is critical to understand data in terms of their lifecycle andthe research projectР Р†Р вЂљРІвЂћСћs lifecycle
* For project planning to archiving, proper data management happensthroughout the research lifecycle
* Each stage of the lifecycleproduces specific data products and requires a variety of considerations,responsibilities, and activities
* There are numerous lifecyclemodels from simple to complex
* Let's look at a few
* Here is the research lifecyclemodel from the UK Data Archive
* Once data are created, which isrepresented in the circle at 12 o'clock, the data undergo subsequent stages,processing, analyzing, preserving, providing access to,and re-using the data
* The University of Virginia library createdthis research data life cycle model, which I think directly alignsto common research practice
* Here is the more complex and comprehensive data lifecycle modeldeveloped by the Digital Curation Center
* With data at the center of the graphic,you can see the various data curation activities as youmove to the outer rings
* This model brings together data,researchers and curators
* Now that you have beenintroduced to data and understand that data management refers toactivities throughout the data lifecycle, please take a moment to introduce yourselfon the forums and tell us about your data experiences, or maybe even questionsyou have about data or the course
* We have also provided someadditional readings for you to explore if you'reinterested in learning more
* And make sure you check outthe resources for this module
* [MUSIC]


--- SKIP ---: 01_why-manage-data.en.srt


--- SKIP ---: 01_why-manage-data.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-manage-data.en_SENTbySENT.txt
* [MUSIC] Now that we know what data are, in this unit, we will familiarize ourselves withthe meaning of data management, its importance, who is involved, and whereit fits within the research life cycle
* By the end of this lesson, you willbe able to define data management
* The term gets tossed around quite a bit inboth professional and researcher circles
* And having a clear concept ofwhat data management entails will be especially important asyou move forward with this MOOC
* You will also understandthe importance of managing data as a part of responsible researchconduct and the roles and responsibilities of stakeholdersin data management
* And last, but not least,you will be able to identify the various data management taskswithin the research lifecycle
* So what exactly is data management
* Data management refers to activities and practices that support long termpreservation, access, and use of data
* The activities surrounding data managementcan include planning, documenting data, formatting data, storing data,anonymizing data, and controlling access to data
* So why is it important to manage data
* Data management helpsresearchers do better research
* It helps researchers optimize use of data during the active phaseof the research project
* And helps them collaboratewith other researchers
* To use an analogy,let's think of doing our taxes
* If you manage your receiptseffectively during the year, doing your taxes is easier in April, and you're more likely tomaximize your deductions and get your taxes in on time without panic
* The same goes for data management
* If you have a plan and follow it,it is time well spent and it will simplify your life later on
* Data management also ensuresthat data is preserved for future researchers to discover,interpret, and reuse
* Further, it sustains the value of data
* When a research project has beencompleted, the data could be used to answer additional questions notconsidered during the original project
* You, the researcher, may also want to extend the study overtime to do longitudinal comparisons
* This is very difficult, if not impossible, if you have noteffectively managed your data
* And last but not least, todaya growing number of funding agencies, journal publishers, and researchinstitutions require data management
* These entities are demanding moretransparency in research projects, and data management is one wayprojects can meet this requirement
* Funders also often want to increasetheir return on investment by ensuring the data that is producedfrom a project is available for secondary analysis, replication,or reuse for future innovations
* [MUSIC]


--- SKIP ---: 02_data-management-stakeholders.en.srt


--- SKIP ---: 02_data-management-stakeholders.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_data-management-stakeholders.en_SENTbySENT.txt
* [MUSIC] Now, let's take a look at the array ofstakeholders involved in data management
* So, initially, you have the primaryresearchers, or principal investigators, who design the study,specify what data will be collected, and determine how to analyze the data anddraw conclusions from these analyses
* They come to know the data quite well, but in a large research project with complexdata, it can be difficult even for the primary researchersto know what they have
* Within a research project,you may also have graduate students or other staff members who are taskedwith collecting the data and managing it, andoften analyzing it as well
* Good data managementfacilitates clear communication between the primary researchers andgraduate students
* It also facilitates multiplestudents working together and the passing of information to new studentsfrom those who have left the project
* Institutions such as universities andresearch institutes, are usually involved in setting some ofthe internal data management policies
* Institutions may also providedata management resources to researchers includingdata management training, support for researchers writingdata management plans or services for archiving data
* A data repository curates data, ensures the long-termpreservation of data and provides access to data
* Data repositories workwith the data creators to ensure data remain useful over time
* Data repositories alsowork with data creators to place any necessary accessrestrictions on the data, including those determined byinstitutional or funder policies, embargoes, as well as any security andcopyright concerns
* The secondary user of the data isthe third party that comes into the picture later in the researchdata life-cycle and may use the data to verify published results, forsecondary analyses or for teaching
* Users can come from many backgrounds,including students, faculty, research project team members,private entities, businesses, government officials, journalists,or citizen scientists
* Funders are the agencies or organizations that provide the moneyto support a research project
* Most US Federal funding agenciesrequire researchers to actively and properly manage their data throughoutthe research projectР Р†Р вЂљРІвЂћСћs life cycle with an end goal of making the dataavailable and accessible for sharing, A data management plan is nowrequired of most project proposals
* These plans clearly outlinethe specifics of how the data will be effectively collected, managed, stored,and preserved for future access
* Publishers and Journals disseminatescientific discovery and maintain the integrity ofthe scientific record
* Publishers and Journals are increasinglyencouraging researchers to cite data, and some, such as PLOS, or the Public Library of Science, are issuingpolicies that require researchers to make data underlying published resultsavailable within a data repository
* As you can see there are many differentstakeholders involved in data management
* The variety of stakeholderssuggests that proper management of data throughout the researchlifecycle requires communication and cooperation between these various groups
* [MUSIC]


--- SKIP ---: 03_data-management-across-the-research-lifecycle.en.srt


--- SKIP ---: 03_data-management-across-the-research-lifecycle.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_data-management-across-the-research-lifecycle.en_SENTbySENT.txt
* [MUSIC] Now that we know what data management is,and who the people involved are, we will now show you where specificdata management practices fall within the research lifecycle
* To do this, we're going to usethe research lifecycle from the Data Documentation Initiative, or DDI
* During the initial phase of the researchlifecycle, that is the discovery and planning phase, researchers willneed to determine what type and format of data they are going to collect
* This may involve collecting new data, combining existing data sets oranalyzing existing data
* If the project involves human subjects,the researches will need to consider privacy, confidentiality,and other ethical issues
* In addition, researchers should considerwhat types of documentation they will create and the metadata standardsthey will use to describe their data
* These are some of the details that shouldbe included in the data management plan
* Further, researchers will need to identifythe potential reusers of the project data
* Who will use this data
* What might they use it for
* Will the data, once stripped of anypotentially identifying information, be useful for secondary reuse
* What access restrictionswill be placed on the data
* These are all questions thatthe researchers need to answer before the project even begins
* Contacting an information professionalearly in the research life cycle can assist researchers inanswering these questions
* As well as identifying appropriate datarepository, to archive their data
* Finally, during this phase,it is important for researchers to determine the possiblecosts surrounding data management
* This will involve documenting the data,formatting them, storing them, cleaning and anonymizingthem, and finally archiving them
* During the data collection phase,primary researchers make certain that the research team follows datamanagement best practices
* At this point, this can includefile organization, backup and storage strategies,as well as quality assurance protocols
* Deciding on file organization schemesincluding naming conventions and file versioning policiesat the very beginning will help make the datacollection process run smoothly
* This will decreasethe likelihood of duplicate or out-of-sync versions of the data
* You will also make locatingspecific documents and files at the end of the project much easier anddecrease the risk of losing content
* Backup and storage strategies will be implementedthrough the data collection process
* As we know,technology is not always a 100% reliable
* If a researcher has appropriate backup andstorage strategies in place, this will help protect against dataloss from the beginning of the project
* It is best to discuss options forsecure backup and storage with the institution'sIT department
* Quality assurance protocols outline anddocument the steps and processes necessary for checking and reviewingthe data during and after it is collected
* These protocols varyacross disciplines and it is the responsibility ofthe primary researcher and the project team to implement theseprotocols based on disciplinary standards
* It is also a good idea toconsider access controls and data security during thisphase of the lifecycle
* While working with the IT department, make sure to inform them of anysecurity concerns or needs
* If the data is sensitive then theappropriate steps will need to be taken to ensure that they are safely stored andonly accessible to authorized individuals
* Next is the preparation anddata analysis phase
* After collecting data, it may not bein a form that can be readily analyzed
* Researchers may need to clean,manipulate or process the raw data
* What is important at this point isdocumenting the changes to the raw data and creating a master version to beanalyzed and eventually archived
* A common tip here is to make the finalversion of the data read-only
* So it can't be inadvertently altered
* Once the master version of the data hasbeen prepared, data analysis can begin
* Data analysis can take manyforms across disciplines
* The most important thing to consider inthis phase is making sure to document analysis procedures such as additionalmodifications to the data, the model used, the code used to run the analysis, andhardware and software specifications
* Having this detailed information willhelp researchers write a better paper and do better science
* During the publication and sharing phase,a researcher will prepare their data files and other research materialsnecessary to interpret and reuse the data in the future
* Data management best practicesdictate that data be stored and made available to share ina trustworthy data repository
* This phase is an opportunity to consultwith information professionals or data repository staff
* Who can provide guidance asyou prepare data for sharing
* Researchers should make sure that theirdata management meets all of the needs and requirements of the repository
* This means that the data should bein the appropriate file format, should be cleaned to the specificationsof the repository, and to comply with applicable privacy laws andrequirements
* Additionally, all documentationshould be reviewed to ensure that the data can be reused andstandard metadata should be applied
* By working with a data repository, researchers can ensure that datawill be properly preserved
* Discoverable, and usable in the future
* The end of the project can seem likea bit of a blur and a time crunch
* But by following data management bestpractices throughout the research life cycle, you can rest assured that yourdata will be available for the long term
* At this point your data are safelystored in a data repository
* And you can begin planning foryour next project
* Some key repository functions gotensure the long term management of data include ensuringthe integrity of the data
* Protecting against data loss
* And providing access to data
* These and other functionsperformed by trusted repositories will be discussed in moredepth later in this course
* We covered a lot of data managementtopics in this module, but what is most important to take awayis that effective data management takes places in all phasesof the research lifecycle
* From planning a project,to collecting your data, to comparing and analyzing your data, and then finallypublishing and sharing your data in a repository that will see to theirlong-term management and preservation
* [MUSIC]


--- SKIP ---: 01_what-are-data.en.srt


--- SKIP ---: 01_what-are-data.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-are-data.en_SENTbySENT.txt
* [MUSIC] I define data very broadly
* I think it's from a digitalpreservation perspective, data can mean digitalinformation of any kind, including very specificoutcomes of research
* So structured data, research experiments,and things like that
* >> Data are those observablebits of information that help us understand a political process, a social process, an economic behavior,whatever it is that people are doing
* The data is that observable bit ofinformation that we can record and later analyze to helpunderstand those processes
* >> Data is evidence used for research and scholarly academic research of any kind
* So when you make a statementabout the world or about anything in it, you're relyingon some evidence for that statement
* If you say Proust has a wonderful passage, you're probably referring toa particular piece of text somewhere
* If you say 95% of the people inthe United States like vanilla ice cream, then there's probably someevidence underlying that
* They're both, they both can bedata if they're used as evidence
* [MUSIC] >> Typically, there are multiple typesof data that are being collected
* The data are almost entirelynumeric that I deal with
* I don't really deal with images or maps or text
* And it's all strange, collected forthe purpose primarily of research, not collected, say for health claims orfor other secondary purposes
* >> My data in my research,some of it is simulated data, some of it is survey data, some of it isdata produced by government agencies
* It's really all kinds,sometimes experimental data, most of it is observational data,data that comes from the world as it occurs rather than ina controlled laboratory
* But really, all different types ofdata are part of what I look at
* I'm more interested in the questionthat I'm trying to answer, then I go find the data that I need.


--- SKIP ---: 02_why-is-data-management-important.en.srt


--- SKIP ---: 02_why-is-data-management-important.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_why-is-data-management-important.en_SENTbySENT.txt
* [MUSIC] >> It's important to,as you start designing a study or an experiment or an observation,to think of how, what are you going to do with the datayou're going to be collecting, right
* And you're going to be producing
* And so, if this becomes part alreadyof your design and you have a, you think of long-term accessibility ofthat data, preservation of that data, already you have that in mind asyou're building your study or, again, your experiment
* Then, there are morechances that you make it, that it will be easier foryou to make it accessible to others
* >> So, students in my discipline at least,I mean, they need to be aware that data managementis a critical part of what they do, and will do, as either practicingengineers or scientists or researchers>> It's, you need to be able tokeep track of your data
* Keep track of the differentchanges you've made to your data
* Be able to, if you get sued forexample, as an engineer and you need to show your calculations
* You need to be able to manage all thatinformation, and be able to show it
* >> So, I see there being practical andsymbolic benefits
* >> The practical benefits I think are,there's a plot
* There's a plan, from cradle to grave
* What is the research question
* How are data being usedto address that question
* Are there other aspects of the researchproject that are required, the required data is there, and archiving requirementfor future use, and those sorts of things
* So that's the birth of the data,the growth of it, and the final archiving of it
* It's a practical way to begin whatis going to be a bunch of work
* They symbolic part, is it's a reason,it's a focus for people to talk
* >> I think there's a sense, I certainlyget the sense in libraries that people feel like we have a completelyknown set of data management practices
* I don't believe we do
* I think for a lot of domains thosepractices are still emerging
* So, I think that we should be reallyopen to identifying new kinds of data management practices, and figuringout what our role might be in them
* >> You need to have a digital librarianto do organization of your data
* You need to have a socialscientist who can come and help you how to arrange things,how to share things
* And you need to have some sort ofa policy maven who can come and say what type of policies you need forthese type of working together, sharing, and collaboration andthings like that
* So, in a sense, you need multiplecommunities together to form your, what you call, a scientific fabric
* And you have multiple people to come andread that.


--- SKIP ---: 01_introduction-to-data-management-plans.en.srt


--- SKIP ---: 01_introduction-to-data-management-plans.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction-to-data-management-plans.en_SENTbySENT.txt
* [MUSIC] At this point, you have a goodunderstanding of what is required to effectively manage data as you movethrough the research life cycle
* As you know, data managementcan seem quite the undertaking, when you consider all the aspectsof data management best practice
* But data management does nothave to be overwhelming, if you have a data management plan
* A data management plan or a DMP forshort is a formal document that describes the data produced inthe course of a research project
* And outlines the data managementstrategies that will be implemented both during the active phase of the researchproject and after the project ends
* If you have been involved in a researchproject supported by a major funding agency, you probably have a good ideaof what should be included in a DMP
* Many funding agencies,particularly federal agencies, now require grantees to submit a data managementplan as part of the proposal package
* If you think you or your clientsmay be applying for a grant from the National Science Foundation,the National Institutes of Health, the Alfred P Sloan Foundation, NASA, theInstitute of Museum and Library Services
* The National Endowment forthe Humanities, the Gordon and Betty Moore Foundation,the Institute of Education Sciences and the Economic andSocial Research Council, the Science and Technology Facilities Council,the Wellcome Trust, and while the list goes on you will need toknow how to write a comprehensive DMP
* Even if you won't beparticipating in funded research, writing a DMP will encourage youto think carefully about the data management needs of your research data andplan accordingly
* Remember, like planning foryour taxes, planning for data management will save you time andheadaches in the long run
* By the end of this lesson, you willbe able to identify the components of a good DMP, understandthe importance and purpose of DMPs, and be familiar with the DMP policiesof several funding agencies
* Also, you will add to tour toolkitsome great resources and tools for data management planning
* Let's go ahead and get started
* Just as I mentioned, many fundingagencies now require grantees to submit a data management plan as part ofthe proposal package submission
* This gives assurances tothe funding agency the project data will be accessible andusable over the long term
* They want to see that you haveestablished a strategy for managing your data throughoutthe research lifecycle
* Making plans for how you will collect,document, organize, and preserve your data are all partof the data management strategy
* This is important for funding agencies,for two primary reasons
* The first reason is transparency andopenness
* It is an expectation that publiclyfunded research data will be discoverable, accessible,and reusable to the public
* Since they underwrite federallyfunded grants, it is a government responsibility to ensure citizens can seewhere their tax dollars are spent and allow them to capitalize onthe products of these grants
* A data management plan that illustrateshow data will be made discoverable, accessible andreusable supports this responsibility
* The second reason is return on investment
* Making data discoverable,accessible and reusable, maximizes the researchpotential of the data and provides greater returns onpublic investments and research
* Well-managed data allows forverification or refinement of published research results,reduces the potential for scientific fraud, promotes new researchthrough the use of existing data, provides resources fortraining new researchers and discourages unintentionalredundancy in research
* By planning for data management, thesebenefits are more likely to be realized
* [MUSIC]


--- SKIP ---: 02_funding-agency-requirements.en.srt


--- SKIP ---: 02_funding-agency-requirements.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_funding-agency-requirements.en_SENTbySENT.txt
* [MUSIC] Let's take a look at the datamanagement policies from a few of the major US funding agencies
* The National Science Foundationdata management plan policy requires that proposalsinclude a supplementary Data Management Plan documentof no more than two pages
* That includes information on fivekey aspects of data management
* The types of data to be produced forthe project, data and metadata format and content, policies for access andsharing, including security provisions, policies and provisions fordissemination and reuse
* And plans for archiving, preserving,and providing access to the data
* The National Institutes of Healthrequires applicants seeking $500,000 or more in direct costs toprovide a description of how project data will be madeavailable in a data sharing plan
* This document should describe finaldataset formats, documentation, analytic tools necessary to use the data,data sharing agreements, and how and when the data willbe made accessible to others
* The National Endowment for the Humanitiessummarizes the content of data management plans they require with twoquestions that should be addressed
* What data are generated by your research
* And what is your plan formanaging these data
* To answer these questions,NEH requires that the DMP describe the data to be produced,how the data will be managed and maintained during the activephase of the project, any factors that might impact theresearcher's ability to manage the data, types of information thatneed to be managed and maintained alongside the data, how datawill be shared in a timely manner, and the facilities usedto preserve the data
* [MUSIC]


--- SKIP ---: 03_data-management-plan-content.en.srt


--- SKIP ---: 03_data-management-plan-content.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_data-management-plan-content.en_SENTbySENT.txt
* [MUSIC] In all of these three data managementpolicies, DMP should describe in detail all major aspects of data managementthroughout the research life cycle
* Here is a checklist for a data managementplan from the Digital Curation Center that list questions that shouldbe addressed in the DMP
* What data will you collect or create
* To answer this question, you shouldprovide a description of the data, including the type, format, and volume,with a justification of the format choice
* If there are any storage implicationsdue to the format or volume of the data
* You should include these as well
* How will the data be collected or created
* Describe the data collectionmethods to be used, including the standardsthat dictate these methods
* You should also discuss your plans fororganizing data files and applying version control,as well as how quality assurance protocols will be implemented during andafter data collection
* What documentation of metadatawill accompany the data
* It is important to determine whatinformation will be required to ensure that the data be understandable tosecondary users of the data, or for you and your team in the future
* In other words, you shoulddescribe the type of documentation that will be needed to accompany the datain order to interpret and use them
* These documents might includea description of the methodologies, a codebook that provides variable andvalue definitions, questionnaires or instruments, or analysis procedures
* How will you manage any ethical issues
* The DMP should demonstrate that you have considered criticalissues related to laws and guidelines
* Regarding the protectionof human subjects
* If your project will conduct researchinvolving human participants, you need to describe provisions forprotecting their confidentiality
* This should include strategies forhandling and storing sensitive data,restricting access to sensitive data, and preparing de-indentified datasets forsharing
* How will you manage copyright andintellectual property rights issues
* This is where legal issues of dataownership need to be addressed
* You need to identify the owner of the dataand their conditions for using the data
* If you are reusing third-partydata particularly property data
* You should discuss permissionswith the data producer
* How will the data be stored andbacked up during research
* To answer this question, you shoulddescribe provisions for storage
* And the degree to which they are adequatefor the type and size of your data
* Provisions forstorage should include plans for systematic back ups of the data files
* How will you manage access and security
* If the data are sensitive orshould otherwise be restricted
* To authorize project personnel
* You should describe indetail security measures that will be in place to protect the data
* You also need to describe the standardswith which those security measures comply
* Which data should be retained,shared, and/or preserved
* In thinking about how the data willbe used by others or by your team in the future, you should make note of thepotential value of the data and the effort that will be required to preparethe datasets for preservation and access
* What is the long-term preservationplan for the dataset
* Answering this question requires youto identify the repository you will use to archive the data and your plansto prepare and document the data to ensure that they will be preserved andusable into the foreseeable future
* How will you share the data
* Here you should identify the mechanismyou will use to share your data
* Describe how others might find your dataand how data files will be delivered
* You should also specify how you would likeothers to acknowledge or sight your data
* Are any restrictions ondata sharing required
* Again, if privacy concerns affectyour ability to share project data, you will need to discuss them andhow you will overcome these concerns to enable data sharing whether byproviding anonymized versions of the data
* Requiring a data use agreement orother mechanisms
* You may also choose to placean embargo on the data, to ensure you have exclusive useof the data for a period of time
* If this is the case,you should explain why this is necessary
* Who will be responsible fordata management
* Quite simply, you need to identify,by name if possible, who will oversee the implementationof the data management plan
* What resources will you requireto implement your plan
* For some projects with complex data,whether due to type, size, or the fact that project activities are geographicallydistributed among different institutions, data management might require specializedexpertise or special equipment
* You may also consider costsassociated with performing ongoing data management tasks,as well as the resources required for long-term preservation ofthe data in a repository
* [MUSIC]


--- SKIP ---: 04_data-management-planning-tools.en.srt


--- SKIP ---: 04_data-management-planning-tools.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_data-management-planning-tools.en_SENTbySENT.txt
* If this check list seems overwhelming,don't worry
* There are multiple data management plantools available to use online for free
* Two of these are the DMPTool producedby the University of California, Curation Center ofthe California Digital Library and DMPOnline developed bythe Digital Curation Centre
* The DMPTool allows researchers tocreate customized data management plans via a step-by-step wizard based oneach funding agency's requirements
* This wizard office resources,help text and suggested answers based on templates developed andreviewed by information professionals from the researches institution inthe California Digital Library
* When funding agency policies change,the DMPTool is updated
* This ensures that the informationis up to date and all new requirements are listedin the DMPTool templates
* DMPOnline like the DMPTool is the DCC'sdata management planning tool
* It offers guidance for researchers writingDMPs and includes templates specific to the requirements of UK funding agenciesand funding agencies outside the UK
* Institutions can also customizetemplates via DMPOnline
* For more information, check out the videosfor these tools on the resources page
* Writing a data management plan gets youto think through data management issues early on in the research life cycle
* By considering all of these issues, you will not only be in compliancewith data management requirements, you will also be better prepared toimplement data management strategies
* Even if you aren't required towrite a data management plan, this is a helpful processto do better research
* [MUSIC]


--- SKIP ---: 01_good-file-management-in-research.en.srt


--- SKIP ---: 01_good-file-management-in-research.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_good-file-management-in-research.en_SENTbySENT.txt
* In this module you will be introducedto the concept of data organization, or housekeeping, andgood file management practices
* By the end of the module,you'll understand why this is important
* And the benefits of file versioning,naming and renaming conventions
* Last but not least, you'll be able toapply the concepts that you learn in this module to help you manageyour data more effectively
* So, let's go ahead and get started
* First, let's take a look at whydata organization is so important
* At the start of your research project it'sreally easy to believe that you'll always remember how you're going to name yourfiles and where you've stored them
* But once your research gets underway, you'll very quickly accumulatea large volume of data
* You'll have multiple files in differentformats and lots of different versions
* And it's not only the data files either
* You're likely to have websites maybeblogs, articles and citations, methodologies, notes and spreadsheetsall relating to your research
* So if you're trying to finda particular data file that you need, especially if it's been namedinaccurately or inconsistently, it can be really frustrating, anda significant waste of research time
* Good file management practices arerequired to help you identify, locate, and use your data effectively
* And file naming conventionsare really important if you're wanting to share your datawith collaborators in a group space
* You want to make sure you're allapplying the same conventions and using those consistently
* So, what exactly are the bestpractices in organizing your data
* Firstly, research data files andfolders need to be labeled and organized in a systematic way, so they'reboth identifiable and accessible for current and future users
* The benefits of consistent datafiling labeling are numerous
* Let's take a look at some of these
* Data files are distinguishable from eachother within their containing folder
* They're easier to locate and browse, and they can be retrieved not only bythe creator, but by other users as well
* They can be sorted in a logical sequenceand are not accidentally overwritten or deleted
* Last, but not least, good data filenaming prevents confusion when multiple people are working on shared files.


--- SKIP ---: 02_file-naming.en.srt


--- SKIP ---: 02_file-naming.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_file-naming.en_SENTbySENT.txt
* We'll now consider the three main criteriathat you need to think about when you're deciding how to name andlabel your research data files
* First up, is the organisation
* This is important for future access andretrieval and should take into account any file naming constraints that are appliedby the system where you store your data
* Second up, is the context
* This may include content specific or descriptive information,irrespective of where the data is stored
* And the third one is consistency
* You should choose a single file namingconvention and apply that consistently throughout by including the sameinformation in the same order
* So forexample if you're going to use dates, you could follow a model like the ISOstandard, which applies four digits for the year, two for the month andtwo for the day, such as 20150907
* Whichever method you decide to adopt,just make sure you apply it consistently
* There are a number of commonelements that you should consider when you're developingyour file naming strategy
* These include a version number,the date of creation, the name of the creator, the descriptionof the content, the name of the team or department associated with the data,a publication date, and a project number
* Finally, you want to think about scalableyour file naming policy should be
* If you want to include a project number,don't limit yourself to two digits, or you can only have 99 projects
* Don't use generic file names either, that may conflict if your data weremoved from one system to another
* And if your working overmore than one computer, make sure your files are synchronized
* File names should outlive the originalperson who named the file, so your best to adopt group guidelines ratherthan everyone having their own procedure
* File and folder naming conventionsare key to maintaining a well-organized electronic directory anddrive structure
* A file name is the chief identifier fora research data file
* In most cases, the policy for file naming is left downto individuals or research groups
* There are a number of easy rulesthat you should be following when naming your files
* Firstly, you should keep filenames short and relevant
* Generally about 25 charactersis a sufficient length to capture enough descriptive information
* You shouldn't use special characters ina file name, as these are often use for special tasks in differentoperating systems
* You should use underscores insteadof full stops, or spaces, and if you include dates,you should format them consistently
* Never assume thata software application or instrument uses case dependency whennaming and renaming your flies
* So how do you rename hundreds of files
* Well most operating systems havein-built tools for file management
* There are also a number of software toolsthat can help you to manage your data files and folders in a more automated andconsistent way through batch renaming
* Batch renaming software exists formost operating systems
* There are many situations in whichbatch renaming may be useful
* For example, where images from digitalcameras are automatically assigned base file names,consisting of lots of sequential numbers
* Where proprietary software, or instrumentation generates crude,default, or multiple file names
* And where files are transferred froma system that support spaces or non-English characters,to one that doesn't
* Batch renaming software can be usedto substitute such characters with acceptable ones
* There are some bulk renaming tools for different operating systemslisted in the Mantra course.


--- SKIP ---: 03_versioning.en.srt


--- SKIP ---: 03_versioning.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_versioning.en_SENTbySENT.txt
* It's also important to distinguish betweenthe different versions of your data files consistently
* This ensures that there's a clear audittrail so you can track the development of your data files andreturn to earlier versions if needed
* You should pick a method of versioningthat makes sense to you and makes it clear to differentiatebetween the different data files
* A common form for expressing data fileversions is to use ordinal numbers such as 1, 2, and 3 for major version changes anddecimals for minor changes
* For example, version 1.1
* You should avoid using confusinglabels such as revision, final, final2, or definitive copy
* You may find that these accumulate and it becomes difficult to understandwhich version proceeds which
* You should always record changes toyour data no matter how small or insignificant they seem at the time
* You can use an auto backup facility forthis, if one's available, rather than saving andarchiving multiple versions
* You can also use a tracking facility onsoftware such as Google Docs or on Wiki's
* There are a number of version controlsoftwares, such as Subversion and TortoiseSVN which are commonly used forsoftware code
* Remember that you can also delete ordiscard obsolete versions of your data
* Just always be sure to retainthe original rule copy
* So, you've now completed this module wherewe've introduced you to the concepts of good research data organization, includingfile naming conventions and versioning
* You can take a look at the furtherresources, where you'll find additional references and links that you canfollow up for more information
* You may decide to come backto these later on, and start another module in the meantime
* If you do so, we recommend you moveon to the data file formats module.


--- SKIP ---: 01_file-formats.en.srt


--- SKIP ---: 01_file-formats.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_file-formats.en_SENTbySENT.txt
* In this module, you'll be introducedto the concepts of file formats, compression, data normalization,and transformations
* By the end of the module,you'll understand why these are important
* And you'll be able to make decisionsabout which approach to use when
* You'll also be able to usethe content featured in the module to help improve your researchdata management practice
* So what is a file format
* A file format is a way of encodinginformation within a computer file
* A program or an applicationneeds to recognize that file format in order to be able toaccess the content within the file
* A web browser, for example,will recognize HTML, things in hypertext markup language, and will be able to openthese files and display them as webpages
* If a browser comes across a different typeof file it might call on a special kind of plugin to be able to open anddisplay those files
* Otherwise, if it doesn't recognizethe file type, it may offer the option to download the file soyou can open it with the relevant program
* The file format is often indicated aspart of the file name in an extension or suffix
* Conventionally, the extension followsa full stop in the file name, and has three or four letters thatidentify the format such as jpg for JPEGs, or docx for a Word document
* Files in proprietary formats usuallyhave to be opened by the specific software in which they've been created
* So this means that somebodywithout a license for that software can'talways open those files
* In contrast, open formats are onesin which the software company or the collective that's created thatsoftware, has made it openly available
* And this usually means that a number ofapplications have been developed which can open those types of files
* Adobe PDF is good exampleof an open format
* It can be opened by a number ofapplications, not just Adobe products
* File types are based on either text orbinary encoding
* Text files are machine readablethrough character encoding standards, such as ASCII and Uni-Code, whereas binary files are run by applicablesoftware and may be proprietary
* Only binary formats can be executed
* Some file types include both binary andtext, such as the rich text format
* A big advantage of creating orsaving your research data in a text format is that the file can be read in a plaintext editor, like Windows Notepad, and is human-readable
* They can be opened in any operating systemand by a wide range of applications
* Some of the well-known file extensionsof plain text files are .txt, .csv, .asc, .html, and .xml
* Most software packages allow export andexchange formats, so you can create a text file forimport into another program
* For example, in Microsoft Excel, you cansave your spreadsheet as a CSV file
* File formats that are open,non-proprietary and in widespread use, stand the best chanceof being readable well into the future
* In contrast, proprietary formats,especially those that are non-standard, that require specificsoftware applications or particular versions of that software,are likely to pose issues for future use
* Rapid changes in technology in the market mean that file formats canvery quickly become obsolete
* This obviously has negative connotationsfor long-term preservation and reuse
* If you want your datato be accessible later, you're best to convertit to open standards
* Data formats that conform toagreed international standards are less likely to become obsolete, as there should be a range of softwareapplications that can read them
* There may well be trade-offs in termsof software functionality though, such as a loss of formatting or macros
* Sometimes there is a defacto standard that's used
* PDF for example has become the de factostandard for publishing documents on the web in a way that retainsthe original layout, fonts, and text
* At some point during your research,you may need to convert or migrate your data filesfrom one format to another
* This could be because you've upgradedyour PC, you've got new software, you're sharing data with a collaborator who usesdifferent software, you're using a shared platform, or simply because you want yourdata files to be readable in the future
* A checksum algorithm tool can beused to compare the bits of a file when it's been moved fromone medium to another
* Checksums are typicallyrun by repositories to perform data integrity checks
* These won't work however,if the file format has changed or if you're comparing files acrossdifferent computing platforms
* At some point during your research youmay choose to compress your files
* This could be to fit them ontoa particular storage device or for transmission or transportation
* Compression is also knownas bit-rate reduction
* It involves encodingthe information in fewer bits than the original representation
* Zip is a de facto standard compressionformat that's used on Windows, Macs, Linux, and Unix platforms
* Zip is a lossless type of compression, which means the file should be identicalto the original once you unzip it
* There are also lossy types of compressionassociated with some multimedia file formats
* These may result in somekind of distortion or loss of quality fidelity when played
* Tar, tape archive files,are commonly used in Unix or Linux to bundle a set of files into one
* Tar files may also be zippedto reduce the file size
* Lossiness can be onetrade off of compression
* Another is the amount of processingtime it takes to compress and decompress the files before or during use
* The amount of computing resourceneeded can also be an issue, particularly in the case of verylarge files or shared servers.


--- SKIP ---: 02_data-transformations.en.srt


--- SKIP ---: 02_data-transformations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_data-transformations.en_SENTbySENT.txt
* It's also a good idea toconsider data transformations
* There are a number of reasons,why you may wish to transform your data, either during your project, or afterwards
* Unlike the earlier discussion aboutmigrating files from one format to the other, data transformationsinvolve changing the actual data
* For example via anonymization
* For example in survey data collectedfrom questionnaires, multiple choice and other kinds of responses are usually codedas numbers instead of character strings
* This simple type of transformation hasthe advantage of easing data entry if you're typing in paper responses, and it also avoids inconsistenciessuch as typos in data values
* Qualitative data such as interviewtranscripts, can be transformed into quantitative data by applying textualcoding and categorization techniques
* Another reason for data transformation maybe to visualize the data more effectively
* A simple example is converting data wherethere's a numerator and a denominator from ratios to percentages, so you candisplay it on a bar chart or pie graph
* A number of methods may be usedto transform confidential or sensitive data, sothey can be shared with other researchers
* These include aggregation,and anonymization
* You've now completed this module
* Take a look at the further reading, whereyou'll find additional resources to learn more about file formats, compression,normalization, and data transformations
* You may wish to move on to the next moduleand return to these references later
* We recommend that you move on tothe module about documentation and data citation.


--- SKIP ---: 01_documentation.en.srt


--- SKIP ---: 01_documentation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_documentation.en_SENTbySENT.txt
* In this module, you'll be introducedto the concepts of documentation and data citation
* By the end of the module, you'llunderstand why documentation is important, and how and when to use metadata
* You'll also understandthe relevance of data citation, and will learn how to do this
* So why document your data
* By documenting your data systematically,you'll first and foremost help yourself
* You may be very familiar with yourdata when you're first creating it
* But the chances that you'll rememberwhat all of the variables and abbreviations mean in several months oryears are slim
* The importance of documenting your datawhile you're creating and analyzing it, and everything is still fresh inyour mind, can't be overestimated
* Others will also need gooddocumentation to understand your work
* This is particularly important if they'regoing to review your publications, try and validate your research findings, oreven use your data in new studies
* Some examples of datadocumentation are lab notebooks and experimental protocols,questionnaires, codebooks, data dictionaries,software syntax and output files
* Information about your equipmentsettings and calibration, database schema, methodology reports,and provenance information
* Laboratory notebooks are crucialdocuments to be properly managed
* They can help in assertingintellectual property rights, and can even help you defend againstclaims of scientific fraud
* In less extreme circumstances, they can demonstrate adherence withstandards of good practice and ethical integrity, and show compliancewith any contractual obligations
* Routine documentation of all lab work is an important responsibilityof laboratory researchers
* There are three levelsof data documentation
* Let's take a look at them one by one
* So first up we have projectlevel documentation
* Here you want to documentwhat the study set out to do, what the research questions andhypotheses were, and what methodologies, sampling frames,instruments, or measures were used
* This information may be included inyour theses, your published articles, data papers or technical reports
* Second, we have file ordatabase level documentation
* A, you should document, how all of the files that make upthe dataset relate to one another
* A readme.txt file isa classic way of doing this
* And finally, we have variable oritem level documentation
* This isn't just defining the variablenames at the top of the spreadsheet file, but including a full label to explainthe meaning of that variable
* In the course of publishing research,it's essential to cite your sources
* The reference list at the end of thepublication shows the credibility of your claims and also the prominence ofa particular theory or school of thought
* So this is no less true for datasets thanfor publications, but somehow the practice of proper data citation has been slowto take root in academic culture
* All too often we see very basic labels andcharts in publications, such as Source: OECD, without any properinformation in the references about how you can accessthe underlying data.


--- SKIP ---: 02_data-citation.en.srt


--- SKIP ---: 02_data-citation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_data-citation.en_SENTbySENT.txt
* In 2014, a group called Force11 issued the JointDeclaration on Data Citation Principles
* This has been endorsed bya number of scientific bodies and publishers, as well as individuals
* So why cite data
* By providing a citation for your data, you make it easier for other usersto identify and acknowledge it
* Data citation helps promotethe reproduce-ability of research results, it allows us to track the usage andimpact of data and it provides a structure by which we canrecognize and reward data creators
* So whats the best practicein citing a data set
* As a general rule of thumb you want tomake sure you include enough information for another use to be ableto locate the data set or the part of the databasethat you're referring to
* DataCite, an internationalstandards body founded in 2009, recommends the following fiveminimum citation elements
* A creator, a year of publication,a title, publisher, and identifier
* Here, identifier refers to any persistentID which uniquely identifies the object, including a DOI or even a URL,though this may be less persistent
* Two additional properties which may beadded are Version and ResourceType
* ResourceType refers to the classof object that is being citied, such as a dataset, database,map, sound file or website
* The UK data service recommends usinga title that indicates the subject matter, geography andtime period that the data covers
* Let's take a look at an example
* When citing data it makes sense to try andadopt the same style and order of references as your other works
* Bibliographic style guides andreference management software may help
* But inevitably,some judgment may be called for
* If so, err on the side of caution, and always provide more information thanless to help the users find the data
* In the case of a dynamic database,that is continually updated, it may be near impossible to refer backto the exact version that you used
* In such circumstances alwaysinclude a date of download
* In the life sciences it's commonto include an accession number with the database name whenyou're referencing sequence data
* You can see this inthe examples on screen
* So what if you're usingan unpublished data source
* Informal data sharingis relatively common
* But even if the data are unpublished,the citation principles still applies
* If somebody shared data with you,for example, via an email attachment, you can referencethis as a private communication
* Let's take a look at an example
* Last but not least, good practice indata documentation and citation can contribute to reaching a better standardof reproducibility of research
* Reproducibility is a fundamentalprinciple of the scientific method
* So you've now completed this module
* If you take a look in the further readingsection you'll find additional references to get more information ondocumentation and citation
* You can also move onto the next module,which is on storage and security.


--- SKIP ---: 01_storage.en.srt


--- SKIP ---: 01_storage.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_storage.en_SENTbySENT.txt
* So what would happen ifyou lost all of your data
* Have you ever consideredthat it might happen to you
* This module will introduce you to theissues involved in storing, securing and backing up your research data
* By the end, you'll be aware of thedifferent storage options available to you and will understand the importance ofdata backup, security and encryption
* At the very least, you'll be motivatedto avoid your own data loss scenario
* According to a survey released in 2014 byKroll Ontrack, a provider of data recovery and e-discovery products and services,hard disk drive crashes have more than doubled in the last four years, makingthem the most common cause of data loss
* When they surveyed over 1,000 customersabout the most common causes of data loss, 66% cited hard crash failure,compared to 29% in 2010
* This is followed by 14%claiming human error
* Software failure ranked as the third mostcommon cause of data loss with just 6%
* Your data are the lifebloodof your research
* If you lose your data, recovery maybe slow, costly, or worse still, it may not even be possible
* This is why it's so important to store andback up your data securely
* It's useful to think about how muchstorage you'll require and plan for that from the outset
* Also think about who willneed access to your data and what that means in terms ofwhere it should be stored
* By considering these issues at the outset,you can plan for them appropriately, and also include data managementcosts in your grant applications
* So where can you store your data securelyduring the course of your research
* There are various options such asnetwork drives, PCs and laptops, or external devices
* Let's take a look at the pros andcons of each of these
* Network drives are managedby staff centrally or those within your school,department, or college
* It's highly recommended that youstore your data to network drives
* This means that there'sa single copy of your data, that you can access it whenever you needto, and that it's backed up regularly
* Most importantly,it means that your data are held securely, minimizing the risk of loss,damage, or unauthorized use
* You can of course use PCs, laptops,and other external storage devices, such as hard drives,USB sticks, CDs, and DVDs
* These can be a convenient option dueto their low cost and portability
* However, they should never be used forthe master copy of your data
* Laptops and PCs can be lost and stolen
* And CDs, DVDs andmagnetic tapes all degrade over time
* Errors writing to CDs andDVDs are fairly common
* And obviously, these can be lost,misplaced, or damaged
* If you choose to use CDs, DVDs ormemory sticks, pick high quality products from good manufacturers andfollow the care instructions provided
* Regularly check the media to makesure they're not failing and periodically refresh them
* Refreshing means to copy yourfiles from one disk to another.


--- SKIP ---: 02_backup.en.srt


--- SKIP ---: 02_backup.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_backup.en_SENTbySENT.txt
* In addition to storing your data securely, you should also make surethat you backup regularly
* Keeping backups is probably the singlemost important data management task
* There's a real risk of loss through harddrive failure or accidental deletion
* The basic 3-2-1 principle of backupis that you have three copies of your files on at least twodifferent media with one offsite
* You should also test your backupsregularly to make sure that you could restore from them if needed
* There's a long list of questionsyou should ask when considering your backup strategy
* How will you back up your data
* How regularly will backups be made
* Will all the data be backed up, orjust that which has been changed
* A backup of changed data isknown as an incremental backup
* While a backup of all datais known as a full backup
* How often will full andincremental backups be made
* How long will your backups be stored
* How much drive space or how many CDs or DVDs will be requiredto maintain this backup schedule
* And how can you keep track ofdifferent versions of data, especially when backingup to multiple devices
* Once you understand what yourequire in terms of backup, check what services are availableto meet these needs
* It's also important to ascertainthe backup schedule and retention policies of any centralizedbackup services you may use
* For example, under the grandfather,father, son, rotation scheme, files may only be available for two to three monthsbefore the storage space is overwritten
* There are various cloud services thatyou can use to backup your data
* These typically allow you to store andsynchronize your files online and between computers
* Most offer a limited amount of space forfree and will charge you for additional storage or premium services
* Common service providers are Dropbox,Google Drive and OneDrive
* You can take a look at Wikipedia,which has a through comparison
* There are some obvious advantagesto using cloud services for backup
* No user intervention is required, so youdon't need to change tapes, label cd's or perform other manual tasks
* They provide a remote offsite backup copy
* Most provide encryption and versioning,and they're multi-platform
* There are, however,significant risks to using cloud services
* Some providers may store data outsideof the European economic area, so you may be in breach ofthe European Data Protection Directive, or your research funder's policy
* Restoration of the data may beslow depending on your bandwidth
* The stored data may not be entirelyprivate if it's unencrypted, and the service providermay go out of business.


--- SKIP ---: 03_data-security.en.srt


--- SKIP ---: 03_data-security.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_data-security.en_SENTbySENT.txt
* So what do we mean by data security
* Data security means ensuring thatyour research data are kept safe from corruption, andthat access is suitably controlled
* >> It's important to consider the securityof your data to prevent accidental or malicious damage or modification,theft, breach of confidentiality, and premature release of the data
* >> Consider who'll need access to the dataand when and how you will enforce any permissions or restrictions needed>> You should also have a clear policy and guidelines on who can make copies of thedata and whether these can be stored on mobile devices such as laptops,smart phones or USB sticks
* This is particularly important ifyou're creating sensitive data
* Making sure data is secure is partof information technology security
* You should always haveup-to-date antivirus software installed on your office andhome computers
* If you have sensitive data, it's best to store them on a computerthat's not connected to any network
* If this is impossible,you should encrypt the data or the PC
* Also bear in mind physical security
* An unnetworked computer is stillvulnerable to theft or malicious damage or modification of the data
* Highly sensitive data should be stored ina locked room or a safe when not in use
* Such data shouldn't be stored ortransmitted without encryption
* One basic aspect of security, that's oftenoverlooked, is user names and passwords
* There are some simple principlesthat you should follow here
* You shouldn't use your user name in youremail address or your Twitter handle
* Try to use an alias instead
* Avoid using really obvious phrases foryour password
* Such as your car registration number,your pet's name, your phone number or other dictionary words
* You shouldn't write your password downon Post-it notes or read it aloud, as you type it in
* And you should avoid usingthe same password for a cloud service that you use foryour university login
* Last but not least,you should avoid signing into secure sites from untrusted computers ornetworks such as Internet cafes,


--- SKIP ---: 04_encryption.en.srt


--- SKIP ---: 04_encryption.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_encryption.en_SENTbySENT.txt
* We recommended that you encrypt yourdata a few times in the last section, so what do we mean by data encryption
* Encryption is the process of convertingyour data into an unreadable code
* A user would need the encryption key orsecure password in order to read the file
* Encryption will protectyour data from disclosure, in the case that your laptop orstorage device is lost or stolen
* The University of Edinburgh DataEncryption Policy, warns that medium or high risk personal data or business information must be encryptedif it leaves the University environment
* Encryption is reliant onthe creation of a strong password
* The data can't be recovered ifthis encryption key is lost
* So you should establish a reliable and secure backup procedure forthe data and any associated passwords
* Encryption is an obvious step for laptop security, however there'sno one size fits all solution
* BitLocker, Pretty Good Privacy
* And other commercial softwarepackages are available, but you'll need to consideryour operating system
* If you keep sensitivedata on USB flash drives, it's recommended that you usedrives with encryption software
* These give protection tothe data if the drive is lost
* Especially if the data contained personalor commercially sensitive information
* Compared with ordinary USB flash drives,they only cost a modest amount more, so are a good buy
* Your local IT support service should behappy to advise on the suitability of any encrypted flash drive thatyou plan on purchasing
* So what happens to sensitive datawhen it's no longer required
* You may have anonymized your data and now want to dispose ofthe identifiable portions, or you may have agreed to delete your dataat the end of your research project
* File deletion is not enough to completelyremove sensitive data from your computer, it only removes the pointers to the disksectors in which the data reside
* The deleted files can be easily recoveredwith commonly available software
* So let's take a look at how you canpermanently remove sensitive data
* There are three main options available
* Data erasure, also known as data clearingor data wiping, uses special software to remove all data, while leaving the harddrive or storage medium still operable
* However, you should be aware thatcurrent techniques may not be completely successful on solid-state drives andUSB flash drives
* Degaussing is another way to remove data, it disturbs the alignmentof magnetic storage media
* But in many cases, it makes new mediasuch as hard drives and tapes unusable
* Physical destruction through shredding,pulverising or incineration is also an option
* You've now completed this module
* If you take a look at the further readingon the next slide, you'll get additional references and resources, so you can learnmore about storage, backup, and security.


--- SKIP ---: 01_interview-natalia-calanzani.en.srt


--- SKIP ---: 01_interview-natalia-calanzani.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_interview-natalia-calanzani.en_SENTbySENT.txt
* Thank you so much forcoming to speak to us today
* Could you just tell us in a coupleof sentences who you are and what you do as a researcher
* What your research is about
* >> Yep, my name is Natalia Calanzani, I'm a research fellow atthe University of Edinburgh
* And I currently work onthe feasibility study, trying to increase the uptakeof bowel cancer screening
* So that involves a database analysis but we're still waiting on our data set,and collecting data in primary care
* >> Great, can I ask what are yourstrategies for file management, file naming, versioning,just generally organizing data
* And how does that help you and yourcollaborator's make sense of the collected data and leave an audit trail foryourselves
* >> So, we have a server hereat the university where we store every file from the project
* And only the researchers who have receivedethical approval to check those files, they can access those
* And we name the files based on theirversions and the dates they were created
* And we try to use underscores insteadof spaces because we know that depending on the system you're using, ifyou have spaces you might have problems
* And this is important forus to be consistent but also so we make sure we're using the filewhich was been approved by ethics
* Because we end up having somany different versions
* So, it's good for you to keep trackof what exactly you are using
* And I have to admit that we could improvebecause when the file becomes obsolete we are still keeping those there soit is quite cluttered at the moment .So we couldn't improve on that>> Do you rely on institutional storage and back upsystems in the course of your research
* And how do you know yourdata are being kept secure
* >> Yes, so if you're dealing with patientdata and identifiable information, it's very likely that it's going to bemandatory for you to write forms and applications
* Lots of applications explaininghow data are kept secure
* And here at the university, Information Services has helpedus to develop those forms
* And they have explained to ushow our data are stored, and how the backup systems worked
* And they helped us develop a diagramshowing how we access data, and how the data are protected
* So I think we're quite certain thateverything is well kept and protected
* >> And what are some of the methodsavailable to you to protect patient confidentiality
* >> So we for the patient databases, like I mentioned, we're not allowed to publish anything forless than five cases
* If you had less than fivecases of a rare condition or something you're notsupposed to report that
* And of course, we're not allowed to copythese data sets to our own computers
* They all stay secure in the server
* >> We don't copy them to SB6 as well, forexample, and that avoids a lot of issues
* And only people who have receivedapproval to access these data sets, they access this data
* In terms of the patient form thatwe have that collect data and primary care practices, these are keptlocked In cabinets in our offices
* >> Well, thank you very much andgood luck with your research
* >> Thank you.


--- SKIP ---: 02_interview-shaun-bevan.en.srt


--- SKIP ---: 02_interview-shaun-bevan.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_interview-shaun-bevan.en_SENTbySENT.txt
* To start with, I was wondering if youcould give me an overview of your project
* And sort of the aims of the project,just in a couple sentences
* >> Yeah, sure.So the Comparative Agendas Project, or CAP for short,is actually a bit of a misnomer
* In reality,the CAP is a network of more than two dozen international projects onthe national and sub-national level
* All interested in measuring policyattention through public and governmental agendas
* >> Can you briefly describehow you organize your data, in relation to perhapsfile naming conventions, versioning Documentation,which obviously features quite heavily
* Metadata, etc
* >> In terms of the overall project, interms of bringing everything together and actually making it comparative,documentation plays a very important role
* These include the sort of mastercode book that I talked about
* Sort of documents all the ofthe inter-relations between the projects
* As in, if these are the things thatare included in health care in Mexico, for instance
* What are the things that are includedin health care in Denmark, in terms of that there are some things,in terms of that's the broad policy area
* But there are some issue that mightonly be covered in one country, some issues that might only becovered in another country
* Also includes the complete documentationwhich I have already mentioned in terms of the adnotated code books foreach individual langauge that allows different language users not onlyto trace the entire process but they understand the data regardlessof what language they are approaching things from and the sort of otherjust broad documents talking about the process of creatingthe master code book itself
* And also, the process for any new projects that might be interestedin joining the community as we're very sort of open community interested in otherresearchers that are looking to sort of expand what we're doing andwhatever in a particular way
* Just as important as sort ofthose documentation materials is detailed metadata
* For so many data sets, so many differentlanguages, it's very important to keep track of what each individual dataset measures in a particular way
* Oftentimes including more complete writeup than you would traditionally think of with metadata
* Explaining, say, what is a law in the UK
* What is a law in the United States
* What is a law in another country
* >> And one final question, I guess it's inrelation to new researches coming onboard
* Do you have any advice inrelation to organizing
* Documenting or storing data thatwill keep the new researcher on track in relation tp managing thatcontent for their own purpose
* >> Yeah, absolutely
* So as a researcher who, so I deal with quite a lot of different types of datasets, quite a lot of different data sets
* In general with different data structures,partially because the data structures relate to differenttools, different methods that I might use which means that while a dataset might all be based off laws
* There might be many different datastructures of laws that I will look at
* In relation to the particularstatistical method that I used
* In that sort of sense, both becausewhat you might want to do with data and the fact that oftentimes with large datasets, the type of large data sets that a lot people are gathering now, youmight envision a particular use for it
* That particular use might be for example, you want to look at lawproduction on a yearly level
* I cross many different countries,and you decide to potentially just make a yearly data set,maybe throw away some sort of data, because it just becomes excessive in termsof when that individual law might have been actually put on the booksin a particular way
* I would advise researchers away fromdoing that, and advise them to keep
* The sort of raw data,every bit of information that they did or were able to gather whenever they'rebuilding their data set, keep that, store that and be able to access that
* You never know whenever you mightwant to actually sort of change that to a quarterly analysis ora monthly analysis
* Or you might want to look at there's aparticular anomaly in some sort of way and you need to investigatethat in more detail
* So, I find it's generally best when you'reworking with data to work with the raw dataset and to transform that dataset intowhat you need for that particular project
* Oftentimes documenting some sort of way, whether that'd be documenting by handusing sort of the documentation for the statistical software thatyou're using to transform the data
* Such as R, MathLab or Stata or other sortof software in whatever particular way
* Using their log files, using their newfiles or other things to be able to document everything that you did so theycan easily go back and change things, but also so that you can easily debug anysort of issues that you might have
* Especially in very large data sets youmight not notice that there was something wrong with a calculation ora transposition of the data
* >> Yeah.>> Without changing into a wide data set format or a long data set format if you'reworking on panel data for instance
* So keep all that archived,keeping all that tracked so that you can fix thingswhenever you see errors
* So, you can easily change your data setto answer knew or different questions
* It's very good for you and it's very goodfor the people who might be interested in using your data for other purposesthat you haven't envisioned and while we all sort of want the outputs fromour own data in whatever sort of way, we want the research outputs andwe want other things
* We want the impact
* Getting people to use the data is a verybig part of that impact, very big part of getting people to cite, to care aboutthe work that you're doing as well
* >> [INAUDIBLE]Sean, many thanks
* >> Thank you.


--- SKIP ---: 03_how-does-good-data-management-add-value-to-research.en.srt


--- SKIP ---: 03_how-does-good-data-management-add-value-to-research.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-does-good-data-management-add-value-to-research.en_SENTbySENT.txt
* How does good data developmentadd value to research
* >> One of the key issues when you plan, or design in your research project isto have a data management plan
* Students usually forget, they get soobsessed with methodology that they forget how they're supposed to collect data,and how to record it and keep it
* One of the good things is, when you applyfor ethics, you have to think about it, which is quite helpful, but one ofthe things that I always tell my students which I think is helpfulis to think about
* What is your foryour data management plan
* How your auditing that this actually worksbecause like anything else in research or even in clinical practice ifyou give an intervention
* If you don't know if it works, youactually might have more harm than goods
* So if we data management plan, we havea plan how you're auditing that the data is collected as you think it is collected,and the quality of data is good, and you will be surprised as sometimesthat even the easiest data collection, if you don't have an audit
* Behind you, you might end up with errorsin it that could be later in the project
* It's helpful to prevent it early on
* >> As a patient I have twoviews on good data management
* The first view is that good datamanagement is keeping it safe, not giving it to people who shouldn't haveit, not leaving it around lying on trains because that's what the newspaperstells me happens to it
* It's sold to insurance companies andgoodness knows what else
* So on the one hand,that's good data management
* Keeping it safe, keeping my anonymitypreserved, but on the other hand, as a patient who's had some seriousillnesses, including cancer
* Good data management is actually makingsure its curated in the right way to be shared with other researchers,especially for rare cancers, or common cancers with a rare offshoot
* The only way you find out about theseillnesses, the only way we really know Know what treatments are actually going towork, is by sharing data across patients, across countries, andmaking sure it is comparable and free to everybody to use it, forlegitimate research purposes
* >> Sogood data management's absolutely crucial, it's an ethical responsibility that,>> Researchers have to honor the data they've beenprovided with and put it to best use
* It's also efficient, not just ethical
* It minimizes the wastage of moneythat's been invested in the research, and not only is it ethical andefficient, it's obligatory
* [INAUDIBLE]>> Sharing your data is really important for transparency
* So if you have your data there and it'savailable and it's in a usable format, then it means other people can,not just interrogate it and kind of Look at your work more closely,but they can also build upon it, so they can incorporate it intotheir future research, or it can become part of a bigger project ora master analysis or anything [INAUDIBLE]
* It's really important to thinkabout how you're going to share your data with other people andplan ahead for that.


--- SKIP ---: 04_do-you-think-data-sharing-helps-to-reduce-waste-and-increase-transparency-of.en.srt


--- SKIP ---: 04_do-you-think-data-sharing-helps-to-reduce-waste-and-increase-transparency-of.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_do-you-think-data-sharing-helps-to-reduce-waste-and-increase-transparency-of.en_SENTbySENT.txt
* Do you think data sharinghelps to reduce waste and increase transparency of research
* >> I guess this is anothervery obvious question and the answer must be yes becausewe produce tons of data, which are basically just lost becauseno one gets to know about it
* Some of that data is uselessbecause we not always create data that was done rather properly andso forth
* But we have a lot of datawhich is extremely useful, which goes into our reports,into our papers
* But, it's usually not the original data, it's usually just a means andcompound data
* And so sharing, I think sharingthe original data that is actually what we write about,would be extremely helpful for others to extract additional informationto answer questions that they might have, which we didn't have and so forth
* Also to check on the quality of our work,so sharing data I think is another, in a way, no brainer, but it's somethingthat researchers don't like to do
* >> Well, I'm a big fan of data sharing andthe use of data
* Because so much data is wasted, andso much research is then wasted
* And it's not just to reduce waste
* We have to remember it willincrease the knowledge creation
* And I'm more and more interestedin this knowledge creation story, because clinical trials are happeningall over the world, and if you can combine those data,you get more efficient research and you can of course that's automaticallyreducing waste at the same time
* >> Sotwo areas where I've used data sharing
* One is individual patientsystematic reviews, where you're doing a review ofall the studies in one area
* You can use the published data forthat, but actually it's more effort but you can get a lot more doneif you use the original data
* But that requires a standardizationprocess, cleaning up process, so you've got common outcomes, etc
* The second use for data sharingis to ask secondary questions, so quite a lot of the research I'vedone has taken existing databases but asked new questions of those databases
* Sometimes it's been trials thatI've been involved in personally, sometimes it's getting data setsfrom other people to do that
* But it means it's much easier to do thatthan to spend the hundreds of thousands, if not sometimes,millions of dollars or pounds in getting an original data set that wouldhave answered exactly the same question
* >> So what data sharing can achieve is the ability to answer a researchquestion with the available data
* When you don't need to go and gather anymore to actually answer the question
* So for example, a systematic review andindividual patient data meta-analysis of all the available data may successfullyanswer a research question without needing to get another researchgrant to go and collect more data
* >> And does it help transparency then
* >> So what do you mean bydoes it help transparency
* >> Well, does it increase the transparencyof research, this sharing of data
* >> Well I think so
* When you share data,you are exposing yourself to the need for external validationby another group of researchers, so they will always,they should always, seek to confirm that you're data show what you said theyshowed when you published them initially
* So I think you subjectyourself to scrutiny
* And I think making it an expectationof researchers also means that they are very careful in the way theycollect and document their research in the first place, knowing that datasharing is one day ahead of them.


--- SKIP ---: 01_benefits-of-sharing.en.srt


--- SKIP ---: 01_benefits-of-sharing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_benefits-of-sharing.en_SENTbySENT.txt
* [MUSIC] Thus far, we have touched on FINRAexpectations regarding data sharing as well as some of the data managementpractices that can help researchers share their data efficiently
* This includes followingmetadata standards, creating documentation andfollowing quality assurance protocols
* Now, we will delve more deeply intothe topic of sharing digital data
* By the end of this lesson, you will be able to identify someof the benefits of sharing data
* You will also be able to identifysome of the challenges and obstacles to data sharing
* And finally, you will recognize theimportance and elements of data citations
* Let's consider the key playerswhen it comes to data sharing
* First, there is the data creator orproducer
* This is the person or entity who ismaking the data available to share
* There is also the person who reusesthe data or the secondary data user
* Finally, there is the data repository
* This is where the data creatormakes the data available
* A data repository plays a key rolein enhancing the discovery and reuse of the data
* And ideally,creating a formal data citation
* So what are some ofthe benefits of data sharing
* As we discussed previously,funders are encouraging
* And in some cases, requiring researcherto make their data available for sharing to support transparency andopenness and maximize funders return on investment
* The specific benefits of data sharing tothe research community are numerous and discussed in much of the literature
* We will now look at the top tenbenefits of sharing research data
* For more information on data sharingliterature, check out the resources for this module
* Number one, sharing data reinforcesopen scientific inquiry
* Making data openly availabledecreases the potential for disagreements among researchers andallows scientific inquiry to progress unimpeded to the benefitof the entire research community
* Number two,sharing data supports the verification and replication of original results
* By making data available, data can be usedto verify or replicate published results
* Verification can bolster the originalresults or it can expose errors
* Either outcome helps strengthen and protect the integrity ofthe scientific record
* Number three, sharing data promotesnew research and allows for the testing of new or alternative methods
* While data creators may haveone research question in mind, the same data may be reused to answernew and innovative research questions
* Number four, sharing data encouragescollaboration and multiple perspectives
* Sharing data can begin conversationsbetween researchers across disciplines
* This could lead to cross-disciplinarycollaborations or the exchange of knowledge across fields that could resultin new innovative research approaches
* Number five, sharing data providesimportant teaching resources
* Data are extremely valuablepedagogical tools
* Instructors may use datain analytical exercises or students may model their own workafter high-quality data examples
* Data can also provide students withfirsthand experience in verifying results
* Number six, sharing data reduces costs by avoidingduplicate data collection efforts
* Avoiding unintended duplicate datacollections saves both respondents and researchers valuable time and resourcesand freeze up researcher funds for other projects
* Number seven, sharing data protectsagainst faulty or fraudulent data
* Over the past few years, there have been multiple stories inthe news about misconduct in research
* Sharing data promotes transparency andaccountability, which lessens the potential for purposefulfalsification or distortion of data
* It also allows reusers todetect unintentional errors
* And finally, the expectation thatothers may be verifying data should encourage greatercare in original analyses
* Number eight,sharing data enhances the visibility and overall impact of research projects
* Making research data availablewithin a data repository can increase the visibility of researchedproducts and increase the impact of a project by encouragingsecondary analysis of the data
* Scholars have also found a significantassociation between publishing data and increased citation rates
* In the end, sharing data does not onlybenefit the broader research community, but can also produce potentialcareer benefits for researchers
* Number nine, sharing datapreserves data for future use
* If a researcher makes their data availablefor sharing within a data repository, then they can be sure thatthe data will be available and understandable for the long-term fortheir own and others use
* Number ten, sharing data helpsthe broader community and individual researchers do better research
* By sharing data, researcherssupport both their own research and the broader research community resultingin science that is more accurate, more open, more knowledgeable andhas more resources at its disposal
* [MUSIC]


--- SKIP ---: 02_challenges-to-sharing.en.srt


--- SKIP ---: 02_challenges-to-sharing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_challenges-to-sharing.en_SENTbySENT.txt
* [MUSIC] We have just covered a lotof benefits of sharing data
* But there are also multiple challenges,or obstacles that can effect researchers ability orwillingness to share their data
* Let's now go over the top five of severalknown challenges to data sharing
* Number one, it takes time andeffort to make data shareable
* Making data publicly availablecan be a labor intensive and time consuming process
* In a 2011 survey of researchers,over 50% sited insufficient time
* And 40% sited lack of funding, as theirreasons for not making data available
* Number 2, perceived risks fromloss of control of the data
* By sharing data, researchers may believe they'rerelinquishing control over their data
* This can raise concernsthat they may be scooped or another researcher coulddiscover errors in their data, could reach contradictory conclusionsusing the data, or misuse the data
* Number 3, data contained confidential orsensitive information
* Data collected from human subjects maycontain protected health information, or personally identifiable information,and researchers are responsible for protecting this sensitive data
* In some cases,de-identifying data may be an option, but this can also be a laborintensive process
* In other cases,removing certain identifiable information could negatively effect the usabilityof the data for secondary analysis
* Number four, the ownership of the datamay be unclear or problematic
* Researchers must also consider if theyeven have the right to share the data
* In the case of collaborative projects, they will want to discussthe data with their partners
* In some cases, for instance,if the data were proprietary or funded by private entities, researchersmay not even be permitted to share the data due to intellectual property orcopyright concerns
* Number five, a lack of incentives forsharing data
* And last but not least, in many waysthe current academic culture lacks the incentive structure to properlyreward researchers who share their data
* Researchers gain career advancementthrough publishing articles in books often based on data
* However, there's currently nota similar reward system for publishing the data themselves
* There are no easy answers to overcomethese challenges as Christine Borgman states, "Sharing research data isan intricate and difficult problem
* In other words, a conundrum." However,one other challenge to sharing data that researchers havecited is a lack of experience and knowledge of data management
* By applying the data management practicestaught in this MOOC, researchers and other information professionals willhave more tools in their toolbox for successfully preparing data to sharein an efficient and effective manner
* [MUSIC]


--- SKIP ---: 03_data-citations.en.srt


--- SKIP ---: 03_data-citations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_data-citations.en_SENTbySENT.txt
* [MUSIC] As I mentioned before, one of the obstacles to sharing data is alack of career incentives for researchers
* One method to reward researchers forsharing their data is to ensure they receive proper acknowledgement andcredit for their data through citation
* Data citation provides a standardizedmethod for secondary users to cite data
* Data citations can also beused by data producers
* To cite their own data asstandalone research products
* For instance,NSF has renamed publications to products in its biographical sketch section ofits grant application where researchers can now list datasets along withpublications and other research products
* Currently, work is being donein the data curation field to establish data citation principles andstandards
* For instance, the Joint Declarationof Data Citation Principles, which is a synthesis of work bya number of prominent groups, has established principles to guide thedevelopment of human understandable and machine actionable data citations
* The eight principles include importance,credit and attribution, evidence,unique identification, access, persistence,specificity and verifiability, and interoperability and flexibility
* Another group doing important workin expanding the infrastructure and culture for citing data is DataCite
* DataCite works with data repositoriesincentives to assigned persistent identifierssuch as digital objectidentifiers, or DOIs, to data
* Through their work,data sites support simple and effective methods of data citation,discovery, and access
* The DOI insures that datacan be discovered online, regardless of where they are located
* So let's take a look at an actual datacitation generated by the data verse and look at how the elementsof this citation map to the joint declaration ofdata citation principles
* The author and data publisher,or distributer information, maps to the principle of credit andattribution, which stresses the importance of contributorsreceiving due credit for their data
* The version information maps tothe principle of specificity and verifiability, which stresses theimportance of having enough information to make sure the data retrieved andused are the same as the data cited
* Finally, the DOI maps directly tothe principles of unique identification, access and persistence
* The DOI provides a method for identification that is machineactionable as well as provides stable access to the data resourceusing a persistent identifier
* One thing researchers may want to considerwhen choosing a data repository for making their data available is whether therepository supports the creation of unique data citations that embody the jointdeclaration of data citation principles
* Proper citation of datasets supportsthe reproducibility of research, ensures proper credit for researchers,and enables the tracking of data reuse
* Although there are very real challengesthat may make it difficult, or in some cases, impossible to share data,there are significant benefits to both researchers andthe broader research community
* By using these techniques and informationprovided in this MOOC, you will be better equipped to overcome these challenges andreap the benefits of data sharing
* And don't forget, cite the data
* [MUSIC]


--- SKIP ---: 01_protecting-confidentiality-part-1.en.srt


--- SKIP ---: 01_protecting-confidentiality-part-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_protecting-confidentiality-part-1.en_SENTbySENT.txt
* [MUSIC] In this lesson, we're going to furtherexamine some of the data sharing challenges that we have briefly touchedupon and discuss some strategies for overcoming these challenges
* By the end of this lesson, we'll understand what is confidentialinformation, be aware of strategies for anonymizing data, understand how dataownership can affect data sharing, be aware of the types of accessrestrictions that may be placed on data, and know how to apply a standard licenseto data, to encourage sharing and reuse
* When collecting data thatdeal with human subjects, researchers have an ethical requirement toprotect the privacy of study participants
* This involves protecting an individual'sidentity during the collection, handling, storage, and sharing of data
* Often these ethical considerationsare outlined in a researcher's application to their institutional review board,or IRB
* There can be serious consequences ofconfidentiality is accidentally breached
* These consequences can negativelyeffect a researcher's career
* Negatively impacta research's institution, and may include hefty fines oreven legal sanctions
* Today, the news is full of horror stories of data breaches that may arise fromcareless data management practices
* In order to avoid thesesituations a researcher needs to think carefully duringthe data management planning phase about what confidentialinformation they may collect
* If the data will be de-identified andhow or if they will share the data atthe conclusion of the research project
* So what are the types of informationthat need to be protected
* First there is PersonallyIdentifiable Information, or PII
* PII is defined as anyrepresentation of information that permits the identity of an individualto whom the information applies to be reasonably inferred byeither direct or indirect means
* Note the reference to either direct orindirect means
* We will come back tothis idea in a moment
* Next, we haveProtected Health Information or PHI
* PHI is individually identifiablehealth information transmitted or maintained, in any form ormedium, by a covered entity
* And finally there issensitive information
* Which is information, that if disclosedthere is a significant likelihood of psychological, social, emotional,physical or reputational harm
* These definitions show the breadth ofinformation that researchers need to actively protect when managing andpotentially sharing data
* Now let's look at threetype of identifiers
* As we mentioned above,there are both direct and indirect ways a person can be identified
* Direct identifiers are those variables or information included within data thatexplicitly point to an individual or unit
* These include, Social Security numbers,phone numbers, and names, andare often the easy ones to spot
* The identifiers that can become moreproblematic are the indirect identifiers
* These are variables that may makeunique cases visible, particularly when combined with other individualattributes, such as race or income
* Finally, we have geographic identifiers
* Which may include indirectidentifiers such as a Zip Code or direct identifiers such asa complete mailing address
* Consider an example data set in whichdirect identifiers have been removed
* The data set representsthe population of US citizens, who have earned doctoral degrees in 1991
* Variables include the major fieldof study, race, sex and geographic region of the academic institutionin which the degree was earned
* Without direct identifiers such as name,phone number, mailing address,Social Security Number, and other information that link directlyto the identity of the individual it would seem that it would be impossibleto distinguish any given individual represented in this data set whichincludes over 25,000 people
* Let's take a closer look at these data
* If we were to take just the peoplewho earned their doctoral degrees in the science and engineering fields, we areleft with just over 14,000 individuals
* Of those individuals,2,119 received their degrees in the physical sciences1,707 of which are male
* Of that group,only 20 reported their race as black
* Having quickly gone from over25,000 people to just 20, how easy do you think it would be tofigure out who those 20 people are
* Well, only eight of them were astronomymajors it wouldn't take much more information to identify atleast one of these individuals
* If we knew where thosedegrees were granted, say in New York,we would likely know who that person is
* This example demonstrates thatprotecting confidentiality requires careful consideration and specialhandling of not only direct identifiers, but also indirect identifiers
* [MUSIC]


--- SKIP ---: 02_protecting-confidentiality-part-2.en.srt


--- SKIP ---: 02_protecting-confidentiality-part-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_protecting-confidentiality-part-2.en_SENTbySENT.txt
* [MUSIC] Now that we have familiarizedourselves with key definitions, let's move on to the laws that govern andregulate how confidential information is managed anda subject's privacy is protected
* We're going to focus on laws inthe United States, but different countries have different laws related tothe handling of confidential information
* Researchers should familiarize themselves with all applicable laws prior tocollecting confidential information
* We're going to cover three of the big laws that effect confidentialityin the United States
* Mainly, the Common Rule, FERPA, and HIPAA
* The Federal Policy forthe Protection of Human Subjects, known as the Common Rule, Governs humansubjects research that is conducted or supported by any federal department oragency
* The common rule establishesinstitutional review boards, IRBs, as the entities that oversee the ethicaltreatment of human subjects in research
* The Common Rule alsoestablishes requirements and protocols for gaining informedconsent from human subjects
* And establishes rules forthe protection of confidentiality
* FERPA or the Family Educational Rights andPrivacy Act applies to educational data
* And establishes a student's right ofprivacy for their educational records
* This includes personally identifiableinformation maintained by educational agencies orinstitutions that receive funds under an applicable program fromthe US Department of Education
* PII in this case includes both direct andindirect identifiers
* The Health Insurance Portability andAccountability Act, or HIPAA Privacy Rule, protects PHI held ortransmitted by a covered entity
* And the Department of Health and Human Services provides detailedguidance on de-identification methods
* In order to encouragethe dissemination of data
* The HIPAA privacy rule provides twomain methods for de-identification
* The expert determination method, allowsthe person with appropriate knowledge to apply statistical methodsto de-identify a data set and then determine that the risk of disclosureto an individual is very small
* The expert must alsodocument the methods and results that lead to this determination
* The Safe Harbor Method stipulatesthe removal of 18 types of identifiers
* The 18 identifiers include direct andgeographical identifiers
* And the final identifier in the listis in many ways a catch all for those indirect identifiersthat may be problematic
* Because of the clarity ofthe Safe Harbor Method, it has also been adopted in otherareas as a standard method for de-identification where laws andprocedures may be less clear
* The Inter-University Consortium forPolitical and Social Research, or ICPSR, also has information on methods forprotecting confidentiality in their guide to social science data preparation andarchiving which we will now describe
* The most straight forward method is completely removingthe problematic variables
* However, this could negatively affectthe usability of the data set for secondary analysis
* Fortunately, there are alternativeapproaches that may be used for handling indirect identifierswithin a data set
* First is top-coding,which involves restricting the upper range of a variable that may identifyoutliers or unique individuals
* Second is collapsing or combining
* Where you combine values into a singlevariable or merging data from two or more variables into one summary variable
* Third is sampling, where you releasea randomized sample of the larger original data set that provides analysisresults comparable to the original
* Fourth is swapping, where you use anindirect identifier to match unique cases
* Then swapping values of keyvariables between those cases
* And finally, there is disturbing the data
* Where you manipulate the databy adding random variation in the value while maintainingtheir statistical properties
* When it comes to qualitative data,anonymizing data is best done using a pre-plannedanonymization scheme
* An anonymization schemedescribes modifications to the qualitative dataset toprotect respondent confidentiality
* For example, a proper name should bereplaced with more generalized text that describes the demographicof the individual or the person's relationshipwith the respondent
* Specific dates, especially birth dates or important events, will also need tobe replaced with general markers
* Other types of information thatwould uniquely identify a respondent may have to be redacted orremoved completely
* In this case, a marker should indicate that an itemwas removed from the data set
* These are just some strategiesthat are used today to protect confidentialitythrough anonymization
* There are other strategies thatare currently being developed to protect confidential data
* However, the most common strategycurrently remains to anonymize data by removing variables,applying statistical techniques, or redacting information to lessen thepotential for identifying an individual
* To determine the best strategy foranonymizing data to maximize usability, a researcher should considerfuture research questions and carefully consider a variable'sanalytic importance
* It may also be useful to consultyour institutional review board, statistical experts, orinformation professionals
* Who have expertise dealing withsensitive or confidential data
* [MUSIC]


--- SKIP ---: 03_intellectual-property-and-data-ownership.en.srt


--- SKIP ---: 03_intellectual-property-and-data-ownership.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_intellectual-property-and-data-ownership.en_SENTbySENT.txt
* [MUSIC] One of the other areas that may beproblematic when a researcher wishes to share his or her data, is resolving andclarifying data ownership and intellectual property rights issues
* Intellectual property rights can bedefined as rights acquired over any work created or invented with the intellectualeffort of an individual or entity
* The question of howintellectual property rights relate to data in particularcan complicate this issue
* As we have discussed, research datacan come in many different forms which can affect whether data are subjectto intellectual property rights, different legal jurisdictionsmay also apply
* They have particular standards forcreative works, to data differently
* Because of these complexities,in order to effectively share data, researchers should first resolveany data ownership issues
* Resolving data ownership issues early, is particularly important becausethe person who has ownership over the data ultimately controls its dissemination,preservation, and destruction
* Ownership issues can become even moreproblematic and confusing because of the various stakeholders involvedin collecting and generating data
* Today, collaborative projects, especiallycross institutional collaborations or international collaborationscan complicate data ownership
* For this reason, it is important for researchers to come to an agreementat the beginning of a project
* Concerning how, when, andby whom the data will be used as the basis of publications aswell as shared in the future
* Institutional policies canalso influence data ownership
* In some cases,if a researcher is working for a university, then the data maytechnically be owned by the institution
* Researchers should be cognizant ofinstitutional data management and copyright policies whenconsidering data sharing
* It is important that researcherscontact their institution if they are unsure about theirintellectual property rights
* Funders may have policies related toownership rights of data that stipulate where and how a researchershould share their data or impose restrictions on data dissemination
* So being aware of funderpolicies is also essential
* In the case of usingextant proprietary data, researchers are often required to gainpermission from the producer of the data in order to legally share the original orderived data
* Because of the many stakeholders and policies that can affect data ownership,researchers may be confused over who actually owns the data which maymake them reticent to share the data
* We encourage researchersto contact information and legal professionals early inthe research data lifecycle, to assist them in determining whatpolices may affect data ownership
* [MUSIC]


--- SKIP ---: 04_access.en.srt


--- SKIP ---: 04_access.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_access.en_SENTbySENT.txt
* [MUSIC] As we have discussed,there are numerous benefits and challenges to sharing research data
* Because of the variety of stakeholdersinvolved in data management and the heterogeneity of data, access to data may vary based on externallimitations or researchers' needs
* Some of the challenges we discussed,such as data ownership issues or data containing sensitive orconfidential information may also affect how andwhere a researcher provides access
* As well as the types ofrestrictions placed on the data
* Today we will begin by discussingthree types of restrictions, or limitations, thatare commonly placed on data
* First are embargos
* Embargos are a specified period of timewhen access to data will be restricted
* Embargos commonly lastbetween 6 to 24 months
* And are often based on rights of first useor researchers needs to have sufficient time to publish using their dataprior to releasing them publicly
* Embargos can also be required by otherstakeholders such as publishers
* However, funders may requirethat data be made available in a timely fashion or within a certaintime-frame after the project completion, which could limit the lengthof possible embargos
* Another type of restriction that maybe placed on data is technological access restrictions based onuser affiliation requirements
* For instance, data users may be requiredto log in to a particular system and authenticate the relationship toan institution to access certain data
* These restrictions may stipulatethat membership be required for access, or that a data user be affiliatedwith a certain research group or institution, often dueto licensing agreements
* The final type of restriction wewill discuss is data use agreements
* A data use agreement explicitlyoutlines an agreement between the data producer and secondary data user
* And may impose rules for reuse,storage, re-dissemination and disposal
* Data use agreements are commonlyrequired when data have the potential to identify human subjectseither directly or indirectly
* Any data user who is requiredto sign a data use agreement should review this document carefully
* And comply with allaspects of the agreement, because violations canresult in consequences
* Ideally to optimize for use researchesshould make data as open as possible
* However, this may not always be feasible
* Clearly outlining any accessrestrictions within the terms of use and applying a standard license can positivelyimpact the potential for reuse
* Researchers should discusspossible access restrictions and licensing with a repository ofchoice to clarify their needs
* And also determine the types of licensessupported or required by the repository
* While there are multiple different waysand methods to assign a license or waiver to data, we're going to go intoa little more depth on one increasingly popular method, which is assigninga standard Creative Commons license
* Creative Commons is a US-based non-profit organization that has been a leaderin developing legal tools for sharing creative works overthe Internet since the 2000s
* A Creative Commons licensehas some key benefits
* Namely, it provides a robust legal code
* It provides a human-readable summarythat is understandable at a glance
* And it providesa machine-readable layer of code that can help make resourcesinteroperable across systems
* Under the 4.0 version, Creative Commons also conforms to both copyright anddatabase laws where applicable, which is particularly importantwhen discussing licensing data
* There are five main Creative Commonslicense categories
* Each has its own distinctive logo andabbreviation
* Attribution requires that userscredit the creator of a work
* NonCommercial stipulates that a workcannot be used for commercial purposes
* No Derivative Works states that you cannotalter, transform, or build upon a work
* ShareAlike requires that if you alter,transform, or build upon a work, then if you distribute the resulting work,you must assign an identical license
* And finally,CC0 does not reserve any rights, and releases the work into the public domain
* You will also see licenses thatare a combination of these categories
* For instance, CC BY NC ND means you must attribute the creator,the work cannot be used commercially, and no derivatives may becreated using the work
* Creative Commons is an onlinetool that helps users select an appropriate license and generatetext to apply the license to a work
* Today, while some groups,such as DataSite recommend researchers apply a CC0 license to data sets toallow maximum freedom to reuse the data
* This may not be possiblein all situations
* As we discussed in this lessonresearchers may have to impose access restrictions on certain data,which can take multiple forms, from placing an embargo on data torequiring a data use agreement
* However, in general, by explainingrestrictions within the terms of use and applying a standard license, a researchercan help enable informed reuse
* [MUSIC]


--- SKIP ---: 01_what-are-the-benefits-of-sharing-data.en.srt


--- SKIP ---: 01_what-are-the-benefits-of-sharing-data.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_what-are-the-benefits-of-sharing-data.en_SENTbySENT.txt
* [MUSIC] Oh, I think the reason to bepassionate about data sharing and replication is because ofthe impact it can have
* So it's really terrific that we eachindividually get to work on scholarship, and invent new things, and come up withdiscoveries that no one's ever known before in the history of the world,no matter how small they are
* It feels really great
* However, if you can actuallychange the infrastructure, and change the norms, then you can havean impact on many, many more people
* And collectively, we can do way betterthan any one of us can individually
* >> One purpose is a sort of sanity check, a basic can we reproduce this,can we see what you did
* Transparency and replicationaround that particular experiment
* Another is, more generally, for science tomove forward you need all of the evidence
* >> Data sharing always producesbetter quality data for my projects
* Just the process ofhaving to be rigorous and sufficiently well documented increating an archive data set
* That means I've got better data sets,better documentation
* Might all be the same data, butit's better for this project now
* Second thing is,I hope it'll help productivity
* [LAUGH] I hope by handing off this dataset to Dr
* Einstein's lab that this graph they will draw will actually get intothe public use, be published as a paper
* Maybe we'll get another prize
* But, fundamentally,these data will see the light of day, and we'll hence have betterproductivity from this study
* And then the third thingis kind of a more general hope that by archivingthe data that in the future, there will be some,not just for this project, but some larger purpose servedby having open access
* And sometimes that might be tangible,such as the public, who fund our research andparticipate in our studies, might have greater faith in research andthe process of research
* They might be less suspicious about whatthe government is doing with its research money, or what professors doin laboratories, and so forth
* >> When people talk about openaccess to data, they often still are talking about the article aboutthe research that points to the data
* But I think that we're alsogetting a sense that the nature of the research practice itself is changing
* And that there's an expectationto share the data, not only,here's my article about what I did
* So, I think it's part of that whole trend
* >> We are moving from things like phonesurveys, where we call people up and ask them how much they likeHillary Clinton, getting fewer and fewer responses on the phones,to looking at things that people say through blogs,through tweets, through Facebook, and analyzing their sentiments,their behavior
* And it seems to me that wehave a tremendous potential to use this information to understand humans, human behavior, and human institutions
* But we also have a tremendousresponsibility to make sure that that evidence base is available, not just to people who are working atFacebook, not just to people who are like, we're friends with the vicepresidents of Twitter
* But to the research community, and to the public at large, so that theyunderstand how, what we're learning, how it applies to their politicalinstitutions, their social institutions
* And that that evidence will beavailable long into the future, because we're just developingways of understanding it now
* So there's a lot more
* >> Most researchers have to makesome form of impact in their field, otherwise nobody recognizesthe worth of their research
* So they can make an impact by either having their data become the basis forfuture research, so somebody else's research willdepend upon your observations
* For that to happen, you have to shareyour observations or publish them, so other people can then dothe next generation of research
* >> What science is is the communityof people acting in cooperation and competition, in pursuit of the same goals
* When you have a communityof people doing that, then we can learn things that anyone of us couldn't possibly learn
* So that's really what science is
* That is what accounts for most of the progress in society overthe last several hundred years
* And that's what we want to contribute to
* >> So in that sense, It is like a village,it is like a community
* And belonging to a community meansthat you need to give your share to that particular community
* And data is the coin of the realm, andif you can share that with other people, other people will share the data with you,and everybody will be better for that
* [MUSIC]


--- SKIP ---: 02_what-are-the-drawbacks-of-sharing-data.en.srt


--- SKIP ---: 02_what-are-the-drawbacks-of-sharing-data.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_what-are-the-drawbacks-of-sharing-data.en_SENTbySENT.txt
* [MUSIC] Data could be repurposed in differentways, so it could be reused for entirely different things
* And we're finding thingslike YouTube videos can be used to determine whethersomebody has Parkinson's
* So that was not looking atspeech patterns in video, was not envisioned at collection,you can find that out
* Now, that can be a two edge sword
* So one of the problems with datasharing especially when you're sharing data about people, is that you mightviolate privacy and confidentiality
* It can be very difficult to allowserendipitous discovery of stuff, especially with rich sources like video orsocial networks, and also guarantee that no one will ever learn anything aboutan individual from that data source
* Besides confidentiality, another issue that somebody couldprove that you did something wrong
* Or stupid
* And that's an individual disincentive
* I think in general that's a socialincentive for data sharing
* In that it helps with error correction
* But it makes, from an individual point ofview, if the norm is not to share, that may disincent you from sharing, becauseyou could be proved to make a mistake
* And a third is that, it's likeeverything else, it takes time, effort
* For a lot of data, especially things in the social sciences, traditionalsurveys and stuff, the amount of bits, the size of the bits is so small thatstorage costs are not really the issue
* But for some new forms of data, videos, social networks,storage costs can be high
* And for anything, what you haveto do to document instrument etc
* So that not only you andyour research group understands it, but everybody else who's ina particular domain can understand it without talking to you,is going to be more
* That's capturing that tacit knowledge anddocumenting it
* Now peculiarly that's also maybe a goodthing from a scientific practice point of view, but it's an additional cost
* >> The drawbacks of sharing data, I guess I would think of them more asconsiderations in sharing data
* Because I think that, really,we should be sharing data
* We may have to delay
* And there could be valid reasons fordelays
* That could be that reasonablythe researchers who spend a whole lot of their time and effort in creativity andgetting the data have the window of opportunity to publishabout it, and I think that's valid
* One of the things we did at ICPSIwas have a delayed release, so you deposit it right away, there is a three year window in which theresearchers can do what they need to do
* And at that point its agreed upon,and then it will be shared
* If you wait until the research projectgets to that point, very often the data preservation can be less easy
* More costly
* >> Well I don't know if thereare drawbacks to sharing data, but there are certainlychallenges to sharing data
* Particularly in the social sciences
* Much of our data is about people andthose people have rights to privacy and rights to have their own beingprotected by us as researchers
* Often subjects exchange their data with the assurance thatthey will be protected in some way
* And so we have an obligation to dono harm as we're doing our research
* There are some challengesI think particularly for young scholars that spend a lot oftime and energy collecting their data
* They want to have an opportunity todo their research, publish out of their data before they have to expose itto the rest of the research community
* So there are challenges like thatin the process of sharing data, but I don't think thoseare reasons not to share data
* I think those are just issues thathave to be managed as we try to be more open about the sciencethat we're conducting
* [MUSIC]


--- SKIP ---: 01_why-archive-data.en.srt


--- SKIP ---: 01_why-archive-data.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-archive-data.en_SENTbySENT.txt
* [MUSIC] In this module we will be conveyingthe essential aspects of archiving digital data
* It's important that we coverthe topic in detail because simply storing data on a CD, or even in thecloud, is not the same as archiving data
* To ensure that data are accessible andusable over the long-term, data requires specific strategiesto preserve their authenticity and integrity, something a trustworthyrepository can provide
* At the end of this lesson, you will beable to understand the preservation needs of research data, distinguishbetween concepts of authenticity and integrity, and recognizethe different types of metadata and their roles in data discovery and reuse
* Preservation of digital data isespecially important because data is a valuable resource andcan be at risk if not properly preserved
* A key aspect of bothsuccessfully managing and sharing data is ensuring the datawill be available for future use
* However, data present real challenges forseveral reasons due to the nature of digital objects andthe heterogeneity of data
* Some of the major risks associated withlosing digital data include benign neglect, bit rot, obsolescence,and insufficient documentation
* Data loss due to benignneglect is the result of not having an active strategy in place forlong-term preservation
* Without an active preservation strategy,there are no guarantees that your data will be usable years later,or when others need it
* The ability to use data in digital formis contingent upon layers of technology, to access, read, and render the datafrom physical storage media
* Without you knowing it,data over time are subject to degradation
* This brings us to bit rot
* Digital data are represented as bits, orunits of machine-readable information
* These bits may degrade or become corruptedover time, which we refer to as bit rot
* This perceived rot may cause decreased,delayed, or faulty rendering of the data
* In addition, the physical mediaon which the data are stored, may also gradually decay
* Even if the data or the physicalstorage media have not experienced any deterioration, there is still a riskto data loss due to obsolescence
* With perpetual advancements in technology,software and hardware eventually becomeobsolete as time progresses
* Consider the researcher who has his orher research saved on a 5.5" floppy disk
* Because this storage mediumis rarely supported today, if at all, the data could be lost,effectively trapped on a floppy disk
* Likewise, if she saved these datain a proprietary file format, then the software company that developedit decided to discontinue its support for that file format,her data may have become unreadable
* An act of preservation strategy wouldinclude approaches to avoid obsolescence, such as constant monitoring of changesin technology, migration of files to current formats, and normalizationof files to non-proprietary formats
* Still, if the data are sound andthe technology is current, there is yet another potential cause of data loss
* Insufficient documentation presentsa risk to long-term data preservation
* A lack of complete andappropriate documentation and metadata can make it impossible tointerpret the data in the future
* Without a codebook,that contains variable and value labels, we're left with data that are essentiallymeaningless and unusable
* The addition of questionnaires,methodology reports, codebooks, and descriptive metadata,alongside the data, are essential for ensuring the datacontinue to be useful in the future
* [MUSIC]


--- SKIP ---: 02_authenticity-and-integrity.en.srt


--- SKIP ---: 02_authenticity-and-integrity.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_authenticity-and-integrity.en_SENTbySENT.txt
* [MUSIC] The primary goal of preservation isto safeguard the authenticity and the integrity of digital content
* We want to be sure that the dataare what we expect them to be
* As defined by the Society ofAmerican Archivists, authenticity is the quality of being genuine, nota counterfeit, and free from tampering, and is typically inferred frominternal and external evidence
* Including it's physical characteristics,structure, content, and context, because digital data are so vulnerable to change,whether inadvertent or not, ensuring the authenticity of any particulardata set is especially important
* This is very much related tothe issue of trust, particularly for data that will be shared for purposesof replication or secondary analysis
* Users of the data must have guaranteesthat the data have not been tampered with and represent the actualdata generated by the data producer
* If data have been altered in any waydocumentation detailing the alteration should be maintained andmade available alongside the data
* Establishing authenticity ofdigital data involves processes undertaken both by the researcher andthe data repository
* The UK Data Archives website providesa useful list of best practices to assist researchers in maintainingthe authenticity of their data files
* These best practices include maintaininga single master file of the data
* Assigning responsibility for masterfiles to a single project team member
* Regulating write access to masterversions of the data files
* Recording all changes to master files
* Maintaining all master files in casesubsequent versions contain errors
* Archiving copies of masterfiles at regular intervals
* And developing a formal procedure forthe destruction of master files
* As you can see, this list focuses onlessening the potential for unwanted or unintended changes to a filethrough write-access controls
* This list also points tothe importance of keeping careful documentation in relation to anychanges made to the master data file
* Having these formal procedures andclear roles and responsibilities in place will help researchers maintainan authentic final copy of their data, free of unintentional andunwanted changes
* Likewise, repositories have procedures andprocesses in place to maintain the authenticity ofthe data they house for safekeeping
* Establishing authenticity of datasubmissions requires the repository to collect and preserve descriptive andcontextual metadata to allow for appropriate identification andinterpretation of the data
* The repository must also document anyoperations performed on the data, including any automatic or manual manipulation of data files andtheir content
* Validation mechanisms should bein place to ensure transformed or modified data file versionsare representative of the original
* All of these actions are necessaryto provide users with a degree of trust in the authenticity of the data
* Data that are properly preserved not onlyhave the quality of being authentic, but they also have integrity
* Having integrity means that a digitalobject has not been corrupted over time or in transit between storage locations orsystems
* As Clifford Lynch, Director of theCoalition for Networked Information puts it, integrity is knowing with certaintythat we have in hand the same set of sequences of bits that came intoexistence when the object was created
* Just like with authenticity, there are some best practicesthat both researchers and information professionals can perform toattend to the integrity of digital data
* These include backing up critical or frequently used files usingan automated backup process
* Storing master files inopen source formats for long-term software readability
* Verifying backup copies offiles against original files by comparing checksum values,file size, and date
* Storing copies of files on twodifferent types of storage media
* And copying or migrating files tonew storage media every two to five years to avoid the effects of physicaldegradation of storage media
* These simple tasks can assistin avoiding corruption of digital files over timethrough redundancy and migration
* In addition, the verificationof files through checksums is an important mechanism fordata repositories to use to ensure the data files have not been modifiedin transit to the repository
* We will discuss these tasks inmore detail,while technology has increased our ability to inventnew ways of collecting and analyzing data,it also has inherent vulnerabilities
* Authenticity and the integrity ofdata can be achieved only through an active preservation strategy basedon standards and best practices
* [SOUND]


--- SKIP ---: 03_metadata.en.srt


--- SKIP ---: 03_metadata.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_metadata.en_SENTbySENT.txt
* [MUSIC] Now it's time to discuss a veryimportant topic that is near and dear to the hearts andminds of information professionals
* Metadata, as you learned ina previous module metadata is often defined as data about data
* More specifically and more accurately,metadata refers to structured information that describes, explains, locates orotherwise represents something else
* Metadata, which is preserved along sidethe data makes it possible to retrieve, use or manage an information resource
* Metadata is necessary forresource discovery, organization of electronic resources,interoperability across systems, digital identification of data andarchiving and preserving data
* Metadata comes in three forms
* Descriptive, administrative andstructural
* Descriptive metadata describes a work forthe purposes of discovery and identification
* Descriptive metadata includes informationsuch as the title, author and abstract
* This is the type of informationthat makes it possible to find the data you're looking for
* And to verify that what you'vefound is indeed what you need
* The Dublin Core Metadata Element Setis often considered core metadata or simple and concise resource description
* Administrative metadata is structuredinformation regarding the management and tracking of data over a period of time
* It may tell us the file type,when the file was created and who was permitted to access anduse the data file
* Administrative metadatacan be one of two types, rights management orpreservation metadata
* Rights management metadata dealswith intellectual property rights
* Preservation metadata records informationnecessary to properly archive and preserve digital materials
* PREMIS, which stands for PreservationMetadata Implementation Strategies, is a widely adopted metadata standard
* That includes both rights management andpreservation metadata
* PREMIS defines in the data dictionarywhat repository should know about the intellectual entities,objects, agents, events and rights associated withthe preservation landscape
* Structural metadata describes the physicalor logical structure of digital objects
* For data, structural metadataindicates how data elements are assembled into a single data set
* For instance, a typical data sethas a set of variables and values
* For a set of observations, structuralmetadata allows us to understand how these pieces are packagedwithin the dataset
* The Data Documentation Initiative or DDI, metadata specification,includes structural metadata elements that allow us to describe socialscience data at the variable level
* These elements include variableidentification, value categories and location of variableswithin the larger data set
* Many metadata standards alsospecify formatting conventions and control vocabularies for metadata entries
* Have you ever tried to findsomething in a database or some other information resource
* But when you performed a search,your query returned no results, even though you knew forsure the information was in there
* It happens all the time andbad metadata was likely to blame
* Good metadata are based on metadatastandards, which often require adherence to specific representationrules and controlled vocabularies
* Representation rules dictatecharacter formatting to ensure consistency in data entry
* For example data sitesrepresentation rules requires that in the creator name element the name beentered with the family name first and the given name after
* John Smith should be entered as Smith,John
* Controlled vocabularies prescribean authoritative list of terms to be used to express values andmetadata elements
* DDI's controlled vocabulary providesa list of terms to be used in DDI metadata elements
* Any time of formal entity whetherit be in the association, business, political party or school
* Should be referred to as organizationin the DDI analysis unit element
* Good standardized meta data also allowsmultiple systems with different hardware and software platforms
* Data structures and interfaces to exchange data with a minimalloss of content and functionality
* The open archive initiative protocol formetadata harvesting, or OAI-PMH, demonstrates how standardized metadatacan be shared across distributed systems
* OAI-PMH is a low entryinteroperability framework that facilitates the efficientdissemination of digital materials
* It allows one system to grab orharvest the metadata from multiple repositories to make the datasearchable from a single interface
* OAI-PMH submits one ofseven HTTP requests which returns an XML metadata filewith the requests records
* The success of this is very muchdependent upon good metadata
* To review, good metadata is standardized,consistent and interoperable, and facilitates discovery,preservation and archiving of data
* [MUSIC]


--- SKIP ---: 01_demonstrating-trustworthiness.en.srt


--- SKIP ---: 01_demonstrating-trustworthiness.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_demonstrating-trustworthiness.en_SENTbySENT.txt
* [MUSIC] In the previous lesson, we learnedthe importance of preserving data and some key concepts involved in properlyseeing to their long-term preservation including authenticity, integrity,and the assignment of metadata
* Now, we will go into more depth concerningthe role of trustworthy repositories and workflows, procedures, andbest practices for archiving data
* By the end of this lesson, you will recognize the benefitsof trustworthy repositories
* Understand the role of auditcertifications in demonstrating trustworthiness, and be able to identifykey archival standards and best practices
* Because data preservation is an active andongoing process, data repositories are best suited to oversee the long-termstorage and preservation of data
* There are different types of repositories,or archives, including domain, institutional, and location-specific,each having special expertise
* These varying types of repositories oftenhave different scopes and missions
* There is no one size fits all repository,and assessing the strengths and weaknesses of each will help researchersselect the best home for their data
* It is also important for the researcher to talk to repository staffearly in the research data life cycle, rather than at the very endwhen the project is over, and you have to figure out how to prepare yourdata files for submission to a repository
* A logical time to contact repositories is when you are writingyour data management plan
* Repository staff can assist researchersin understanding any specific data management requirements,such as accepted file types, metadata standards,documentation requirements, and associated costs, information that shouldbe included in the data management plan
* How do you know that the datarepository is one that you can trust with your data for years to come
* Since the data repository will be chargedwith the long term maintenance and preservation of a researcher's data, you will want to be sure the repositoryis a trustworthy steward
* Researchers andpractitioners in the digital archiving and preservation fields haveestablished specific standards and best practices for the long termpreservation of digital objects
* A repository that is trustworthy is onethat can show compliance to standards and best practices through policies and procedures that are both transparent andwell documented
* Adhering to standards and best practices is essential toachieving trust worthiness
* However, for repositories todemonstrate their trustworthiness, they must commit to transparency andseek audit and certification
* Without transparent policies andprocedures, assessing trustworthiness ofa repository is all but impossible
* Transparency requires thatrepositories make archival and digital preservation policies readilyavailable to stakeholders off and online
* Digital preservation policies, access anduse policies, data security policies, metadata policies, and others shouldbe clear and understandable to users
* This is an important aspect ofcommunicating repository services and capabilities to users, which gives assurances that theirdata are being properly cared for
* Another mechanism for repositoriesto demonstrate their trustworthiness is through audit and certification
* Three well known examples of audit schemesare DRAMBORA, the Data Seal of Approval, and the ISO 16363 Audit and Certificationof Trustworthy Digital Repositories
* Each provides detailed guidelines orspecific criteria for assessing the trustworthiness of digitalrepositories based on adherence, standards, and best practices
* Odd its may be completed usinga self assessment process, a peer review process,or an external audit
* Self-audits like DRAMBORA are useful tools that enable repositories toexamine their own policies and procedures against benchmarks toidentify areas for improvement
* DRAMBORA, which stands for Digital Repository Audit Methodbased on risk assessment, was developed by the Digital CurationCenter and Digital Preservation in Europe
* DRAMBORA offers a tool kit that guides thearchivist through a structured process to analyze the scope of the repository,repository activities and assets, risks and vulnerabilities,and calculations of risks
* It also allows the archivist todefine risk management measures, and produces self audit report
* Self audits are often the firststep toward external audits which can be more rigorous andlabor intensive
* The data seal of approvalfrom the data archiving and network surfaces or dense is a lowvary of option for external audit and certification through peer reviewtrustworthiness is judged according to 16 guidelines each of whichfalls into one of three categories
* Guidelines related to data producers
* Guidelines related to repositories
* And guidelines related to data consumers
* These guidelines align with a listof specific criteria, that if met, deem a repository worthyof a data seal of approval
* To be considered trustworthy,the repository must present public facing documentation, that demonstrates thatthe data can be found on the internet
* The data are accessible withclear rights and licenses, the data are in a usable format,the data are reliable, and the data are identified in a unique andpersistent way
* More rigorous is the ISO 16363 audit and certification of trustworthydigital repositories standard
* It isn't enough for repositoriesto claim that it is trustworthy
* ISO 16363 demands extensive evidence
* The audit examinesrepository attributes and responsibilities in threeprinciple categories
* Organizational infrastructure,digital object management, and infrastructure andsecurity risk management
* Each of these categoriespresents a series of metrics with which an auditor can judgerepository effectiveness
* For each metric, the repository mustbe able to demonstrate conformance by presenting actual evidence, such aspolicy documents, accounting budgets, training materials, system logs,contracts, and licenses
* Our repository that has earnedISO 16363 certification is able to present evidence ofconformance to over a hundred metrics
* While achieving this certification isrigorous, it is the most thorough and comprehensive today, andconsidered the gold standard
* It is important to note that auditsshould be performed routinely and periodically, especially sincetechnology is rapidly changing and can significantly impact workflows andprocesses
* With regular audits, repositoriesdemonstrate to their stakeholders that they are trusted data stewards
* [MUSIC]


--- SKIP ---: 02_data-curation-standards-and-best-practices-part-1.en.srt


--- SKIP ---: 02_data-curation-standards-and-best-practices-part-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_data-curation-standards-and-best-practices-part-1.en_SENTbySENT.txt
* [MUSIC] At the foundation of manyarchival standards is ISO 14721, reference model for an open archivalinformation system, or OAIS
* This reference model presentsa high-level framework For understanding archival concepts, defineselements & processes within digital repositories, andestablishes a set of responsibilities for the long-term preservationof digital information
* Repositories that consider themselvesto be OAIS archives are presumed to have mechanisms and workflows in placeto properly safeguard digital materials
* These mechanisms and workflows serve thespecific archiving needs of the designated community, which OAIS defines asan identified group of potential consumers who should be able to understanda particular set of information
* While the definition of designatedcommunity might change over time, the archive accepts responsibility forthe long-term preservation and availability of information forthat designated community
* The OAIS model has sixfunctional entities
* Ingest, archival storage,data management, administration, preservation and access, andillustrate the data curation and archiving workflows that takes place fromthe time a researcher submits his or her data to when a third-partyuser accesses the data
* When a repository receives data files, also known as the submission informationpackage or SIP, from the data producer, the ingest function performs several tasksto establish evidence of authenticity and to ensure that files are in proper formatsand include necessary documentation
* Standard ingest procedures includenormalization of files to formats that are optimal forlong-term preservation
* Optimal formats are determinedbased on careful consideration of sustainability and use factors thatcan affect the feasibility and cost of long-term file preservation
* For instance, if a researcher submitsan spss.sav data file to a repository, the repository may normalize the data fileinto a tab-delimited preservation format
* SPSS is a proprietary statisticalanalysis software program owned by IBM, a private company
* SPSS has had its share ofnew versions over the years, leaving old files unable to be renderedproperly by the latest versions
* Such old files are externally dependenton a computer running certain versions of the software, and only if the computer'soperating system supports that software
* Even for those skilled enoughto hack software code, many proprietary formatsare not transparent, making it impossible to access,much less modify or update the code
* During ingest,the repository will convert the SPSS file into a tab delimited format,which is widely adopted, non-proprietary or open source, andfree from external dependencies
* Preservation optimization also presumesthat the stamp includes supplementary documentation that enables appropriateinterpretation and use of the data
* The Ingest functional entity ensuresthat SIPs have all the necessary components that make data preservation,access, and reuse possible
* During Ingest, the repository alsoperforms the initial checksum or hashsum on SIP files
* A checksum is produced using an algorithmthat generates a unique string combination that is specific to the arrangementof bits contained in the data files
* This unique string combination canbe used to detect any changes to files resulting from corruption thatmay occur inadvertently over time, which is essential todemonstrating a file's integrity
* Because data are digital objectswith specific attributes, data repositories may performadditional tasks during ingest, including checks for confidentialinformation and data quality reviews
* Once ingest tasks have been completed, the SIP is considered to be an archivalinformation package, or AIP
* The archival storagefunction oversees storage, maintenance and retrieval of the AIP
* Once the AIP is moved into permanentstorage, the archival storage function manages storage hierarchy,performs routine error checking, refreshes storage media, andrecovers files in the event of a disaster
* Meanwhile, the data management functionprovides functionality for generating, maintaining, andaccessing descriptive information, ie metadata, to document the fileshoused in archival storage
* It also administers archival databasefunctions to include database management, updates, and queries
* Once the AIP files are placedin permanent storage, the customer can request access andretrieve data files
* This service and functionality isprovided by the access function, which coordinates these requests andassembles and delivers the final disseminationinformation package or DIP to users
* [MUSIC]


--- SKIP ---: 03_data-curation-standards-and-best-practices-part-2.en.srt


--- SKIP ---: 03_data-curation-standards-and-best-practices-part-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_data-curation-standards-and-best-practices-part-2.en_SENTbySENT.txt
* [MUSIC] Now that we have discussedthe archival ingest process storage, data management and access or to useOAIS language, have a sip becomes dip
* We will continue looking at the tworemaining OAIS functional entities as well as some otherarchival best practices
* For monishing the overall repositoryenvironment, the preservation planning function provides recommendations forpreservation and planning strategies to ensure that data are accessible andunderstandable to users over time
* These recommendations often includemigration and or emulation
* To protect against dataloss due to obsolescence, data repositories migrate digital contentfrom out of date storage media or software formats to more up to date ones
* This practice may be done automaticallywithin a preservation system or an archivist who maymigrate content manually
* Another option is emulation,emulation involves the recreation of the original computer environment allowingusers to access the digital object
* Whatever the strategy, preservationplanning involves ongoing evaluation of archival materials to identifyfile migration requirements
* Recommends changes to archive processesand policies and reports any risks
* Beyond the archive, the preservationplanning function also monitors the technology landscape anduses service requirements and adapts preservationrecommendations accordingly
* The successful implementationof preservation strategies and the overall operations of the archiverelies on the administration function to handle data submissionagreements with data producers, establish quality standards, andmanage infrastructure configurations
* Much of this is part of ongoing monitoringand assessment of archive operations
* Along with implementing and monitoringdata archiving operations and workflows, a repository also must be ableto demonstrate organizational, physical and economic stability
* A trustworthy repository can weatherthe storm of personnel transitions, infrastructure mishaps andtightly resourced environments, without any disruption inpreservation activities
* However, there are alwaysunforeseen circumstances that can potentially resultin organizational failure
* To deal with such cases, repositories mayenter into collaborative partnerships
* One example isthe Data Preservation Alliance, for the Social Sciences or Data-PASS
* Data-PASS partners have a formalagreement to take on stewardship of a partner's collection,should that organization become defunct
* A common protection against physicallosses from disasters is storing copies of digital content ingeographically distributed locations
* Some repositories employee the LOCKSSsystem, Lots of Copies Keep Stuff Safe
* Which stores copies of content on partner servers acrossgeographically diverse regions
* Economics sustainability for long term preservation is an ongoingconcern in the field of data archiving because the cost of long termpreservation are still largely unclear
* Regardless, a trustworthy repository hasin place both short-term and long-term business plans for sustainability withtransparent accounting practices
* They also analyze anddocument financial risks, investments and expenditures to anticipate costs andprepare necessary budgets
* As you can see archiving dataproperly is no trivial undertaking
* From receiving file submissionsfrom data producers, to making data filesaccessible to the public
* Trustworthy data repositories makea verifiable commitment to archiving data
* They expend significant amounts of labor,funding, research and assessment to safeguard data
* This is why it is important to makedata repositories an integral part of your data management planning
* Trust them to take care of your datawhile you take care of your research
* [MUSIC]


--- SKIP ---: 01_why-is-archiving-data-important.en.srt


--- SKIP ---: 01_why-is-archiving-data-important.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_why-is-archiving-data-important.en_SENTbySENT.txt
* [MUSIC] You know even though I don't think thatmany researchers think of preservation as the first thing [LAUGH] whenthey think of designing a study
* But if you think of, well that even foryourself, if you think, I want to be able to find and reusethat data after a few years from now
* That's already a good goal to[LAUGH] put into yourself
* And by doing the right things duringyour research process would allow to, not only while making it available foryourself, but also for others
* >> The value of preservationrises over time
* In real time, people feel like, oh we don't really need to do preservationbecause I only want to make it available
* I'm only interested in access
* If you're interested in long term access, the investment in producing these wellformed packages pays off again and again and again over time because youcan go back to the archival package and re-present it in any kind oftechnology that comes up
* >> Long-term access to stuff is providing long-term access,providing preservation
* That's communicating with the future
* [MUSIC] That's essentially what it is
* It's being able to communicatewith people after we're gone
* And I think that the scholarly record, that the scientific evidence base,is an important enough thing that the futurewill want to know about it
* >> It's very important to be part ofthe process where if people near want information, records, data that they canget it, and that we can be part of that
* We can do it well,we can do it better than we could before, we can incorporate technologiesinto doing it better
* And making things more andmore accessible to whoever is interested
* And I think that part of that has to dowith, as we get into open access data, it means that it's not necessarily a veryfocused, constrained set of researchers
* It's anybody who wants toknow more about that thing
* And I really like the notion of openaccess to anyone who's interested in it
* >> Well, archiving data is atthe core of sharing data effectively
* It places the data in a centralrepository where researchers all over the world can gain access to it
* It provides a legacy to that data assoftware changes or technologies change
* Archives can preserve data and make it accessible beyondthose changes in technology, is really provides a much more robustway of sharing data and recording and documenting what it is we do as weadvance our scientific communities
* These
* So, archiving's absolutely essential
* It's a living,breathing way to make the scientific enterprise open to everyone who wants toparticipate in the scientific enterprise
* >> If any of the items that are in digitalform will be needed in the future, they have to start managing integrity
* You can not trust any desk drive,you can not trust any vendor
* Eventually, this technology willeither fail or become obsolete
* So you need a way to migrate yourdata from the prior type of storage to the next cheaper type of storagethat's coming in the future
* >> I teach students in just myepidemiology courses, cause I'll have a session on data management and partof that is were you going to archive data
* And I tell war stories fromnational data collection in Australia that was archived on five anda quarter inch floppy disks
* Now, I'll leave it to you to explainto the audience what a five and a quarter inch floppy disk isbecause I expect most people who might watch this video wouldhave no idea what I'm talking about
* But it's a magnetic medium that youwould have to feed into a drive, into an old desktop computer
* And it would have a whirring machinethat would read this disc and you cannot find devices toread those discs anymore
* And that the was the repository fora national data collection of oral health
* And I've spoken to colleagues who havemagnetic tapes that had to be scraped because they got oxidized
* And they would scrape the tapes andI saw bits of metal coming off it, some magnetic stuff coming of a tapethat hopefully it's oxidization, not data, right, butthat is scraping tape
* So, the good people youwork with realize that in certainly in 20 years now, and certainlyin 50 years to now, people will be doing the equivalent of scraping data cloudsthat we now regard as being permanent
* And it's fun to work with peoplelike that who have that vision, because they are creating something forthey future, and they realize the future is morethan just a thumb drive or a cloud
* [MUSIC]


--- SKIP ---: 02_why-is-digital-preservation-important.en.srt


--- SKIP ---: 02_why-is-digital-preservation-important.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_why-is-digital-preservation-important.en_SENTbySENT.txt
* [MUSIC] Digital preservation is importantbecause it's not immediately obvious to most people
* Researchers are busy with focuson the research they're doing and the important content of what they'restudying and it's up to people like me, like data librarians, to remind themto keep the data safe in the long term
* And also by doing that they're making itavailable to themselves in the future
* Because, although it's veryknown to you at this point, you'll forget the detailsabout it in the future
* So you need to do the documentation andeverything to be able to share it and also for your own self
* >> I think digital preservationis very important
* I come from the scientific world,and in the scientific world researchers build on the resultsthat were published by others
* So, keeping these data is paramountbecause if you don't take care of the adequate digital preservation ofthe data, there is no possibility for later researchers to reuse these data andto build on these results
* But it's not only important for academia
* Also outside of academia theseresearch data can be used
* So digital preservation should beat the top of all of our lists
* >> Well digital preservationis important because, most of the output of research fromthe academy is now digital and there isn't an analog form of that,in many cases
* So preserving that output servesthe same function as libraries and archives have in the past
* If we don't preserve this digitalinformation it's really in danger of being lost
* And that's a loss to the entire community
* And that creates a situation whereresearch cannot be validated, or can be reproduced
* And that's a serious problem forthe entire academic endeavor
* >> Digital preservation as an extensionof preservation of anything else is important because it allows usto take resources which inspire and inform to be transmittedthrough time to those who, in the future,who'll want to better understand and learn what has meaning to thosewho have gone before them
* So preservation is important to do this,both for our analog materials, but also for our digital
* Which inherently, we cannot discernwithout that proactive effort to preserve
* >> Digital preservationis important because it helps to unleash the valuein digital objects
* We create a lot of digital contentevery day and some of it we save or set aside for preservation purposes
* That value remains a potential, like a latent value in these objects andwe release when we use the objects again
* In order to be able to use those objects, we need to be able topreserve them in between
* So preservation is a stagein the value chain that takes the value ofobjects through time
* >> Digital preservation is importantbecause it allows us to capture the knowledge needed to apply and recreatethe data sets that are being archived
* This in turn allows us tomanage reproducible research
* Where a second researcher canreproduce the results of the original researcher using the same data sets andthe same analysis mechanism
* So preservation is the mechanism bywhich we capture the knowledge required to do that
* >> It's important because our culturalheritage is being saved in digital formats now and it used to be that history wassaved by what didn't get thrown away
* And that's not a strategy that worksanymore because if we leave our digital stuff just on the ground in the hopesthat it will manage to live for 100 years, it won't
* >> I think libraries which are drawninto digital preservation for whatever reason, I think,into a great social service because they are making the really available data,information for scholastic research
* So this is another actuallyhelping the society to evolve and also grow from the idea ofscholarly information which otherwise would not have been available
* [MUSIC]


--- SKIP ---: 01_conclusion.en.srt


--- SKIP ---: 01_conclusion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_conclusion.en_SENTbySENT.txt
* We have covered a lot in this course
* And as we have discussed,data can come in many different forms
* But despite the heterogeneity of data,there are some basic data management best practices that can helpresearchers do better research
* We hope that this course was helpful notonly to researchers who are needing to actively manage their data andshare it at the end of a project but also for information professionalwho are supporting researchers
* As we have covered in this course,research data management is most effective when it takes place throughoutthe research data life cycle, and the first step should includewriting a data management plan
* As we discussed,writing a DMP is not only best practice, but it is increasinglyrequired by funding agencies
* After discussing DMPs andsome useful DMP tools, the folks at the University of Edinburghcovered some best practices related to organizing data, file formats andtransformations, and storage and security that can help when researchersare actively working with their data
* We also discuss the benefitsof sharing data, including promoting new research andcollaborations
* Allowing for the verification andreplication of original results and enhancing the visibilityof research projects
* These are just a few of the benefits, and while the benefits can be numerouswe also covered various challenges to sharing data from the effort ittakes to prepare data for sharing, to the lack of incentives for sharingdata within the current academic culture
* Finally, we went over the role oftrusted repositories in curating, archiving and preserving data tomake sure it remains accessible, and understandable for the long term
* All of the Cradle team would like to thankyou for participating in this course
* We would also like to thank the Instituteof Museum and Library Services for sponsoring the creation of this mook
* And finally we would like to thank SarahJones from the Digital Curation Center, Adina and The Data Library atthe University of Edinburgh for their contributions
* If you would like to continue your datamanagement education, we would encourage you to check out the programs offeredat The School of Information and Library Science here at UNC, including ourpost master certificate in data curation
* And our forth coming professionalscience masters in digital curation
* Likewise, the Odum Institute at UNCprovides data management services to researchers that can help ease theirburden as well as training information professionals and researchers in datamanagement and curation best practices
* Check out the resources for additionalinformation on other data management training and education opportunities
* Bye and thanks for participating
* [MUSIC]


--- SKIP ---: 01_1-1-introduction.en.srt


--- SKIP ---: 01_1-1-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-1-introduction.en_SENTbySENT.txt
* [SOUND]
* Hi, welcome to Lesson 1 of Creative Programming for Digital Media and Mobile Apps
* I'm Mick, and this is Matt and Marco
* And we're going to take you through six individual lessons starting with this week, which is all about the basics of drawing and the basics of sound
* So, first of all, we need to know how to manipulate graphics and draw them to the screen and we also need to know how images are represented on the screen
* Marco is going to take you through that, and he's also going to give you a introduction on how to use processing for making desktop applications
* Matt's going to take you through how to control sound and how to find and play back sounds from the internet
* He's also going to talk a little bit about manipulating sound, and how sound is represented in the computer
* In addition, he's going to show you a little about how to run applications that we develop on Android phones
* And then, I'm going to take you through the basics of using Apple devices
* And after that, I'm going to show you how to make a basic app with simple interactions, like mouse and touch interaction
* That plays back different sounds in different ways
* And also changes the way that certain types of images are drawn
* So, that's really what this lesson is about
* It's kind of easing you in to the whole idea of making creative applications
* And if you've got any questions, you can check the forums
* We'll be looking out for any of you who have particular issues
* It's always a bit difficult getting started running software for the first time
* So, we've got a whole load of examples that you can download from the Coursera website
* We're going to be referring to them throughout the next six weeks starting this week
* So, make sure that before you ask questions, you have a look on the documentation that we've put on the website
* There's a lot there
* There are also people who are going to be on the forums, expecting you to ask good, relevant questions
* And hopefully, if you are stuck, then we'll be able to sort that out
* So I think we're going to start off with Marco
* I think he's going to do some graphics, and then move on to Matt, and then I'll be seeing you later on
* [MUSIC].


--- SKIP ---: 04_1-2-processing.en.srt


--- SKIP ---: 04_1-2-processing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_1-2-processing.en_SENTbySENT.txt
* [MUSIC]
* For this course, we'll be using a programming environment called Processing, developed at MIT
* It's a fantastic environment to learn to program in, but in particular it's a fantastic environment in which to create a program in, because it makes it very simple from the very beginning to do highly graphical, audio-based, and interactive software
* This is the Processing window in which you run the Processing program
* The first thing you'll notice is there's a nice Play button
* If we hit Play, we get a program
* It's not a very instant program, it's a very small window and it doesn't really do anything
* That's not surprising, we haven't written anything to put in the code
* This main editor window is where we write codes and I'm going to give an example of some codes that you might want to write
* So I'm going to Set the size of the screen with two numbers and set the background color
* I'll come back later to exactly what these things mean
* But for now we need to know that we've changed the size of the screen, made it bigger
* And we've gone and changed the background to red
* Over the next couple of weeks, we'll be looking at some much more complicated programs that really use the full power of processing, but for now, I wanted to show you how to write a very simple program
* An important part of this course is that it's not just about writing processing programs for the desktop, but processing can be used on mobile devices, android devices, iOS devices, and on the Web
* And in a minute, Mathew and Mick are going to show you how to do that
* And Mick is going to go through a more complex example that we're going to explain throughout the course of this weeks lecture
* The last thing I want to say is that if you're used to programming and have had some experience in Java you'll find processing very familiar because it's based on Java
* But even if you have programmed before in say JavaScript or PHP it won't be too hard to learn
* If you've never done any programming before don't worry
* But have a look at some of the additional lectures I've posted that will introduce programming from the very beginning [MUSIC].


--- SKIP ---: 06_1-25-install-javascript-mode-instructions.en.srt


--- SKIP ---: 06_1-25-install-javascript-mode-instructions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_1-25-install-javascript-mode-instructions.en_SENTbySENT.txt
* Okay
* Just quick video to show you how toinstall JavaScript mode in processing
* So if you look on this menu here, you're going to click Java when you first installit
* So you click add mode, select JavaScript mode, hit the install button, downloadsand installs
* We're done
* Now we need to quit processing
* [BLANK_AUDIO] Revamp processing
* And there it is
* We can now go to JavaScript mode.


--- SKIP ---: 09_1-3-graphics-and-drawing.en.srt


--- SKIP ---: 09_1-3-graphics-and-drawing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_1-3-graphics-and-drawing.en_SENTbySENT.txt
* [SOUND]
* So today I'm going to introduce the basics of how to write computer programs that draw pictures and that you can interact with
* The first thing you need to do when you want to write, draw an image with a computer program is turn your image into a set of numbers
* Because at a certain level, numbers are what computers understand
* If you think about a computer screen, it's composed of millions of pixels
* These are picture elements
* These are tiny little squares, each of which has their own color
* And you can think of the screen as a large grid of pixels
* As you can see on my slides here
* The first thing you need to know when you're drawing something to screen is which particular pixel you're drawing to or collection of pixels, and you need to be able to express that as a number
* So, how do we do that
* The first thing we do is we have a number that represents how many pixels across you are
* That's the horizontal position or what we call the x value
* We also need to know how many pixels down you are
* The vertical position or y value
* These two numbers give us a position of a pixel
* For example 8, 6 gives us this pixel here shown in red
* So, with two numbers we can get a single pixel value
* So let's have a look at that in practical program
* So this is the program, I showed you earlier
* We've got the size
* We've got the background, and we can draw a point at a certain position
* Say 100, 100
* Now you probably cant even see the point, it's actually here, if you see my mouse position where I'm clicking
* Why cant you see it
* Because pixels are tiny, let's do something else before we proceed and make the point a little bit bigger
* We use this command called stroke weight
* Which gives you the width of lines you draw or the size of the points
* Now set that to six and we're going to get something a little bit bigger
* And there we go we can clearly see a single point on the screen
* Now, creating images out of individual points is going to be hard work
* So, let's look at how to make some more basic shapes
* Okay, so here we have our pixel of position 8, 6, with another point given by another two numbers, say, 4, 3
* We can draw a line
* So, with four numbers, x and y at the start position, and the x and y of the n position, we can draw a line
* Similarly with another full numbers we can go further and draw a rectangle, and the only difference being that the first two positions are the top left position of the rectangle and the other two numbers are not a position on the rectangle, they are the height and width
* So let's have another look at trying to draw more complex..
* If, instead here, of point, we use the command line, we can draw a line to 200, 300 and see what that looks like
* There we have a line
* Similarly, the rect command gives us a rectangle
* And here instead of a, the end position of the line for the second two points, it's the height and width of the rectangle
* So I'm making a square, which has equal height and width
* So there we are
* Let's have a quick look at what I've just done
* So here we are, these are two commands I've written
* Size commands
* What is the size command
* I showed that in my introduction lecture to processing, but I didn't really talk about it
* Well, in size, you're passing in 2 numbers
* The first number is the x, is the width, of the processing window you're creating
* The second number is the height, the y value
* Similarly with a line The first number is the x position, the horizontal position is the start point
* Then the hot vertical position, the y position is, is the start point, and then the x and y positions of the end point of the line
* So very simple, with four numbers, you can draw a line
* And from there, you can get Many more complex shapes
* The next thing you might want to look at is colors
* So up to now we've been drawing black lines
* How do we represent color as numbers
* Well, if we start with black and white
* The color coming off a computer monitor is really the amount of light that is being emitted by each pixel on the screen
* So we can think of the brightness of the of a particular pixel, as being a value that we can measure
* and we can measure that brightness at some maximum value, which is white and 0, which is no color coming off, which is black
* And if you look here, 0 is black
* And then we can use the value 255 as why?
* Why 255
* Well, that happens to be the largest value you can fit in 8 bits
* So 8 ones and 0s on, in computer memory
* Any value in between those two will give you gray lighter, or darker gray
* So you can have shay, any shades or variations of gray value between those two values
* Fine, that's brightness, but what about real color
* Well, when to talk about colors, we need to think about primary colors, and if you
* At a very young age at school, you will have learned that you can make any color by mixing three colors of paint together
* We're not actually working with paint
* We're working with light, and that's slightly different
* The primary colors are different, but the concept is same, and the primary colors we have are green, blue and red
* And any color can be made up with these three, three basic colors
* Why is that
* It's not a fundamental property of light, but it's a fundamental property of our eye
* we have three types of receptor in our eye, that are sensitive to green, red, and blue parts of the spectrum
* And, if the light comes between those colors, it will trigger
* a mixture of say, the red and green components receptors on our eye
* Therefore we can fool our eye by, instead of having a color that's between green and red, sending both green and red at the same time will look like a mix of green and red, which is yellow
* Similarly, green and blue is cyan Red and blue is magenta, and any other color can be mixed from those basic primary colors
* That's great from a computer graphics point of view, because we only need three numbers to represent any color, a red value, a green value and a blue value
* So how do we use colors
* Well, there's a number of ways in which you can use colors
* If we look here we've got a basic rectangle and what can we change about that rectangle
* Well, the first that we can change about the rectangle is the border of the rectangle and we use the stroke commands
* Stroke means the color of the line that we use to draw lines on screen
* We can also change the center of the rectangle using the fill command
* Fill is the color that is used to draw the center of any shape, the middle of any shape, that we're drawing on screen
* We've already seen the background command, and I'll show you that again which has the, changes the background color of the screen
* The last command that I've already shown you that is connected is stroke weight that doesn't specify color, but it specifies the width of any lines you're drawing on the screen
* So let's have a look at that in code
* So we've already used background, and we can see here that we've used backgrounds 25500, so that's 255 red, 0 green, 0 blue
* And as we see, that came out as a bright red
* If we were to change that to 255 zero, 150, we would mix a little blue in and we'd get a different colot
* Sort of more purpley color
* Let's try changing these, the colors of this rectangle, so if we use stroke, we can set the color of the border of the rectangle, let's set it to a bright green
* Sorry, just made a mistake there
* And we can use fill to set the sensor color
* maybe we can use a light blue
* We mix in light blue by having quite a lot of red and green
* So it's quite bright
* There's a lot of whiteness in there, but more blue
* And there we go quite a light blue, we could make it bluer by turning down the red and green
* So that's, we've got some quite garish colors here
* I wouldn't actually make an application with these colors, but it shows you sort of how you can mix, mix some basic colors
* The one last thing I want to show you is that once you'll called stroke and fill, those values continue for everything else you draw, so if I draw another rectangle eh, then they will be the same colors
* So by putting in a second fill command, I can change the color of my second vector
* Okay, there's one last thing I'd like to say about color, which is to talk about transparency
* Sometimes when you're specifying colors as well as red, green, and blue, you'll get a fourth number
* This is the opacity
* Often called alpha
* Opacity controls how transparent something is
* It's actually the opposite of transparency
* So when The opacity is 255, it means it's not transparent at all, and when it's 0, it's completely transparent
* So, to get colors which are partially transparent, you need an alpha value between 0 and 255
* So, for example, 255, 0, 0, 128 is half transparent red
* And we can see this in code here, by setting the alpha of this rectangle to 128, and move it slightly so that it overlaps the original, the original rectangle
* we don't want it to completely overlap
* And you can see it is partially transparent
* Its color is affecting what's beneath it, but not completely
* And Mick will show you some nice examples of how you can use transparency to get some really nice visual effects
* So, with what I've shown you so far, you can make some nice drawings
* With computer codes, and that's cool as far as it goes
* But it's not really a computer program yet because all it's doing is drawing a picture
* When you think of a computer program you want to interact with it
* It has to do things independently
* So if we look at what our program is doing up to now
* We're pressing play, it's running its code
* And when it finish, it will draw a picture and we can look at it
* But that's not how we, you complete a program 1, we want to be able to interact with that code
* so we can do this by splitting a code into news and number bit
* First off, we we have some stuff that should never change
* For example, the size of the screen, the background color
* They should always stay
* [INAUDIBLE] And that's what we call the setup part of our program
* And then there's stuff that should change, so for example, the things that we're drawing, like the lines, they should move around based on what we're doing
* That's the drawing part of our program
* And we put them in two different blocks of code
* The first one we put in a block of code called setup I won't get into full details of what everything means here
* If you're familiar with Java, you will understand it
* If not, look at some of my additional lectures
* But void setup is what's called a function, and that contains all the code that we do at the beginning of the program and it happens only once
* The important thing to note here are these curly brackets
* They say they tell you where the start and end of the setup code is
* Similarly, we can have functions which happen times the response to certain events
* So for example, I can have alpha function mouseDragged
* What mouseDragged does is that it happens every time you move the mouse while the mouse button is held hold down
* A very useful function for interaction
* So what happens now is I move the mouse, I give some input, mouse drag responds and I play and then it paints a picture and I can see that
* That's fine, but if you look at the code as it is now, every time I call mouse dragged, it's drawing the same line because the numbers in there aren't changing
* I need to put in different numbers to my line in order to change the interaction I'm getting and make it truly interactive, to make it respond to my mouse movements
* And this is how I can do it
* Rather than putting a number in there, I'm putting in The value mouse x mouse y pmouse x pmouse y
* Now what are these things
* Well these are variables their names stand for numbers if you're not familiar with the term variable
* But if you're not then you should look at my additional lectures
* And mouse x and mouse y are automatically set to the current position of the mouse
* So this is your mouse position as an x and y value
* pmouse and X and pmouseY are useful values
* They give you the previous position of the mouse and that's what enables us to do some, some smooth drawing
* I'll show you that in a minute
* So let's look at some code that does this
* So this is about the most basic interactive code you can get in processing
* We have a setup function that sets the size of the screen and the background color, and a mouse drag function that draws a point that the position is the mouse
* So let's see what that does
* We've got a nice little drawing
* That's nice, but, when I draw, I'd like to actually sort of draw continuous lines, and we can do that with the code I just showed you, because we can draw a line from the previous mouse position to the current mouse position
* [NOISE] And there we are, some nice continuous lines drawn
* Now, we've got a nice bit of interaction but it doesn't look great, there's a lot we can do with this aesthetically to make
* In a few minutes we'll talk to you about that
* but for now, that's most of want to say, what, what I'm going to say
* I just want to show you one little trick
* about the background function
* So at the moment it's not
* Every time I draw, it's drawing on top of what I've already drawn
* And sometimes that's what we want
* Sometimes what, that's what we don't
* not what we want
* If I move the function background into mouse dragged as well as setting the background color what background does is it clears the screen
* So if I move it into mouse dragged it's, it's clearing the screen so I've no longer accumulated all the drawings I've ever done
* And I just get this tiny little try off the mouse
* Maybe not exactly what we want now
* But there's lots of situations where it is exactly what we want
* And next week we'll show you that in detail
* So, so far what we've got is the ability to draw some basic energies to screen
* Some basic shapes and interact with that by responding to mouse position
* There's a lot more we, you can do while you're drawing, and I would recommend that you look at the the processing website, processing.org
* There's a link to it from the from our our call server site, and particularly look at the processing reference and look at some of the examples for shapes
* A good example is to look at the ellipse command So far we've looked at lines, and rectangles
* Ellipse shows you how to draw ellipses, and circles, and, and with that, that's already part of your repertoire, but it will already, it will also start you learning how to use the reference for, for processing, and pick up, and use new commands that will enable you to do more complex drawing
* So I'll leave you here and Matthew will talk a bit about how to do audio processing in processing and then Mick will show you more complex examples using the basis, basic code that we've learned here..
* [MUSIC]


--- SKIP ---: 10_1-35-setup-draw-and-mouse-interaction.en.srt


--- SKIP ---: 10_1-35-setup-draw-and-mouse-interaction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_1-35-setup-draw-and-mouse-interaction.en_SENTbySENT.txt
* In this video I'm goingto look at five things
* But don't worry,it's not going to take me too long
* First of all, I'm just going to havea quick chat about what is a function
* Then we're going to lookat the setup function and the draw function in processing
* We're going to find out how we can makeanimation by looking at mouse interaction
* Then we're going to look at how we canuse mouse interaction in another way, using the mouseDragged function
* So, first of all, what is a function
* Well a function is simply a way of creating a block of code whichwe're going to run later in time
* Okay, so instead of just somethinglike this, where we call background
* Actually, background is a function, right
* And we're calling background, butwe're not defining what background is, we're just telling it how to run
* And so what we're going to do in thisvideo is actually define some functions
* And the functions we're going todefine are called setup and draw, and they are specialfunctions in processing
* Because they are run automatically
* Okay, so whereas,think about that background function
* It wasn't being run automatically
* It was being run because we told it to,by writing background
* But setup is actually goingto be run automatically
* The only difference is we have to tellit what to do in that setup function
* So the normal thing you would do inthat setup function is set the size of the window
* So remember size,you've got the width, height
* Just to remind me that that'sthe width and that's the height
* And then what you typically do inthe draw function is do your drawing, hence the name
* So you set things up in the setup functionand you draw things in the draw function
* So before we do any drawingI'm just going to sort of just really illustrate what'sgoing on with these functions
* Hello from setup, okay, andhere I'm going to say, this is, if you like the simplest wayto illustrate what's going on
* So, all it's going to do isset the size of the window and then print that and then draw is justgoing to print out hello from draw
* So let's play it and see what happens
* So this area down here is calledthe console and whenever you call print things go out into there andit's really useful for debugging
* So if you want to test what a value is orsomething like that
* So let's just whiz up to the topof what's come out in the console
* And you've probably noticedalready that draw is just being obviously run lots of times
* Whereas set up, you see it's onlycalling the setup code once
* So, setup gets called once atthe beginning when the sketch runs
* Draw is being automaticallycalled repeatedly
* And that's the trick to doing animations
* So, if you think about animation, it's basically a series of frameswith different stuff in and that's exactly what draw allows usto do each time draw gets called
* We can draw a differentframe of our animation, or update the picture that's on the screen
* Okay, so let's try that
* And what I'm going to do is bring in thatother idea, the idea of mouse movement
* And I'm going to use the mouseto actually draw something
* So we've seen before this rect function
* So remember x, y, width and height
* Those are the four variables, the four numbers that weparse into the rect function
* So if I put it at 0,0,it goes to the top left of the screen
* And let's say I want a width andheight of 25, 25
* So let's just run that
* That's not very interesting, but whatyou can imagine it's doing is basically redrawing the rectangle on top ofitself again and again and again
* Little bit boring
* But what happens if instead ofsetting x and y to just always be 0, what if we set x andy to be the mouse position
* mouseX and mouseY
* So these two special variables here give us access to the positionof the mouse currently
* And as you imagine, if you movethe mouse around, they'll change
* So if draw gets called again,it'll update
* So let's try that
* So if I move my mouse around, you can see the rectangle appearsto be following it and because because draw just draws on top ofthe previous canvas that was there, it doesn't wipe it each time, you cansee that whatever it's drawn before is being kept which makes fora nice kind of drawing effect here
* Now of course, if we did want to wipe it, we could just callthe background functions
* Now remember, background fills the entirebackground in a certain color, so I'm going to fill it with the color black,which is a quick way of doing it is zero
* That means every time draw getscalled the first thing it does, it wipes everything overwith a black background
* Then we hit play
* And you can see that now,the square is just following the mouse, and it's wiping out thattrail of other squares
* I kind of preferredthe previous one to be honest
* Okay.Now, the final thing I wanted to show you is the mouse track function
* So this is another functionthat gets called automatically
* By processing
* But this one doesn't just called again andagain like draw does
* It actually gets called whenthe mouse is being dragged
* So the mouse is being dragged whenyou basically click in the sketch and move the mouse around
* So let's just illustrate that
* So there's the whole sketch there
* There's not much to it
* I've got rid of the codefrom the draw function and I'm just doing my drawinginside mouseDragged now
* So let's see what this one does
* You'll notice right nowit's not doing any drawing
* If I click on the Window and startmoving my mouse, then I can draw a line
* Then I can draw another one
* So it's a bit like a kind ofpaint program with this nice, almost fake,3-D effect on the lines there
* Okay, so what have we done
* We've just found out about the setupfunction which gets called once every time your sketch runs
* The draw function,which gets called repeatedly and how to use mouse interactionto do animation in draw
* And how to use mouse interactionbasically responding to the user clicking into the window anddragging the mouse around
* [BLANK AUDIO]


--- SKIP ---: 12_1-4-running-apps-on-ios-and-android.en.srt


--- SKIP ---: 12_1-4-running-apps-on-ios-and-android.en_SENTbySENT.rtf


--- PROCESSING FILE --- 12_1-4-running-apps-on-ios-and-android.en_SENTbySENT.txt
* [SOUND]
* Okay, so one of the first things we have to learn how to do is to run applications on mobile devices
* now Matt will have already shown you how to run stuff on Android, and Marco will have shown you how to run stuff off the desktop
* I'm going to show you how you can run the same application, using our code that we've prepared for you, in the download pack which is off, which is from Coursera
* So that you can do exactly the same code, write the same code, and have it run on all three devices, specifically on, on iOS device
* Now, crucially, the way we're doing this as part of this program, is we're running all of the iOS-specific code as JavaScript
* So, when you finish making your application, you press Go and it builds a webpage specifically for our iOS mobile device
* There's a couple of little tricky things that we need to get right the first time we do it, and I'm going to talk you through those right now
* But firstly, we start with a straightforward sketch
* Now, I'm going to use a sketch that we're, we're going to talk about later on in lesson one, called Sonic Painter
* And this is just a basic I'll sketch
* It also runs on the desktop, and it also runs on Android in exactly the same way
* So, I'm going to start by creating a running version on my desktop, so you can see
* Just to give you a, a reminder of how that works
* But we're using JavaScript
* So, I'm just hovering over with the mouse, over the little bit that says JavaScript
* When you click in the top right, right-hand corner of the processing IDE, you can see it says Java, Andriod, Javascript, Experimental
* I don't really know what Experimental means
* We're not going to try it out today
* But we're going to try the JavaScript version
* When you run it, when you press this Play icon as Mark already shown you, it launches your web browser
* And I think we're recommending you use Google Chrome for this
* Now, you should be able to hear, [SOUND]
* And see the app
* And that's the app we're going to look at later on in more detail
* But crucially, what we need to know is what the web address is
* Now, before you start, you need to make sure that you're on the same wireless network as your desktop on your iOS device
* Most people do this all the time
* When you're in your house, you've got one wireless network
* And you connect your computer to that wireless network and you also connect all your devices to the same network
* But you really need to do that, because if you don't do that, development can be a bit tricky to get started with
* Okay
* So, I recommend you do that first
* If you haven't done that, do it now
* So, the next thing we need to know is, what the IP address of this desktop is, because the desktop is actually serving the app at the moment
* Later on in the course, you'll be serving the app from a web server, and even storing it locally on your device
* I'll show you how to do that in a moment, but for now, we really need to know the IP address
* Now, on a Windows machine you can do this by going to the command line terminal and typing IP config, and it will give you the IP address of your advice
* On a Macintosh device, we can do the same thing
* We can go to a terminal
* If I type ifconfig, it gives me a list, and you should be able to see that now, it gives me a list of what looks like ridiculous numbers
* But there's a number here, inet 192.168.0.108, that's the IP address of this machine on this network
* I've got an iPad here
* I'm going to launch Safari
* And I'm going to go to the IP address
* Http://192.168.0.108
* Now, that's not enough, we also need a colon, and the port number
* The port number here is 55523, I know this all seems like crazy garbage, but it, I promise you, is nearly over
* Here you go, and it's gone straight to the Solid Painter app
* And once it's loaded in, [SOUND], there you go
* It's running on my iOS device
* Simple as that
* It's running over the network
* Really simple
* And now, I can continue to edit that app live and just refresh this page
* So, I can change an aspect of it, go back to the code type something else in, and then refresh the page and it will then come up
* One final thing though which is useful to know, if you want to embed this on your home screen whilest you're developing, you can hit this little sharing icon and choose add to home screen
* And if you do that, it'll actually make it a proper bundled app
* We'll be talking more about that later on towards the end of the course
* But that, more or less, is how you get it running on your iOS device
* And I just want to point out that our template, which we've prepared for you, is downloadable from the Coursera site
* And that should look identical on a iOS device whether it's an iPad, an iPhone 5 or an iPhone 4.


--- SKIP ---: 14_1-5-introduction-to-audio.en.srt


--- SKIP ---: 14_1-5-introduction-to-audio.en_SENTbySENT.rtf


--- PROCESSING FILE --- 14_1-5-introduction-to-audio.en_SENTbySENT.txt
* [SOUND]
* [MUSIC]
* Okay
* So you've done some graphics
* And now you're ready to do some sound
* So I'm going to begin by showing you how to obtain some sounds
* [INAUDIBLE] you get get sounds from pretty much anywhere
* for example, you can record them yourself or you can obtain them from a website
* Freesound.org is a really useful website for obtaining sounds
* They have a wide selection of different sound effects, ambient sounds, and music
* What I'm going to do is, I'm going to quickly make a sound myself by recording it
* I'm going to use the open source audio editing software Audacity, which you can see here
* So, I start with an empty page, I hit Record
* [SOUND] I get my drumstick [NOISE] [SOUND]
* So this is the bit of the sound that I'm interested in, so I copy that
* Paste it into a new sound
* Now because, because we're operating in mono here, we're, we're trying to keep the audio library as simple as possible
* So we operate in mono
* So I'm going to record my sound, like this, in stereo, but then bounce it to mono
* So I go into the track menu, stereo track to mono
* Now I'm ready to export
* I'm going to store it into the data folder of the sketch
* So you'll notice when you create a sketch like this one and save it that it puts data folder for you
* So my sketch is called Android Start, and you can see I have a data folder in there
* If it's not there, when you've just saved your sketch, you can just create it
* The data folder is for additional files that you want to use in your sketch
* In this case, audio files
* So I'm going to save this audio file I just recorded into the data folder of the sketch
* [SOUND] And I'm going to call it uh, [SOUND] ping.wav
* [SOUND] Okay
* So we've recorded our own sound
* And now we're ready to see if we can get it to play on the mobile device
* We're going to play a sound on the mobile device
* In order to do this, we need to write in some, some lines of code to initialize the audio environment
* The audio environment in this case is called Maxin/?
* This is our custom audio library
* [SOUND] So Maxim, so I created a variable called Maxim, which has the type Maxim
* We'll worry more about the details of types later on in the course
* Then, I need an audio player
* Audio player, so that's the type, and I'll call it Player
* So I've two variables ready to store these two object which I'm now going to create
* So maxim equals new maxim, that creates a new, a new audio environment
* You only ever need to create a single audio environment for your whole sketch, and everything operates within that single environment
* Following that, I'm going to ask maxim to create my audio platform, player equals maxim .LoadFile, and I pass it the name of the file I just saved, ping.wav
* Okay
* And so, remember, ping.wav is the name of the file you just created, and it needs to be saved in the Data folder, so that the, so that Maxim can see it
* because otherwise it, you can only access files in that Data folder
* Okay, and finally, [SOUND] I'm going to set up an event, so that when they click on the screen or tap on the screen, they will be able to hear the sounds
* So I'll just say player.play in there
* So let's just try this out
* So I've written my really simple sketch here
* Let's just [UNKNOWN] go through that code again
* We've got these two variables, one of which is the maxim, that's the audio environment that all of the, that deals with all of the audio processing
* Audio player represents a single player which can play an audio file
* [SOUND] Maxim is being created there in the setup function, and the player has been created, too
* When they click the mouse, this function gets called, mouse pressed during the case of the touch screen device when they tap on the screen, and it will trigger play on the player object, which will cause the sound to play
* I'm now going to run the sketch
* Okay the sketch has launched on the device, so I tap the screen
* [SOUND]
* Okay, so you can now hear me hitting the table, playing from my Android device
* So to exit the sketch, you need only press the Back button
* Like that, and now it's stopped
* Now, you noticed that it kept playing the sound
* Because the default setting for the player is to loop the sound
* So, for example, if you put a drum beat in there, it will loop it
* And that's really useful for drum beats
* But for for a sound effect like this you might not want it to loop
* But before we look at that, let's just see what it sounds like when you play a drum beat in there
* So I've already, I've already prepared a drum beat called mybeat.wav
* Okay
* So let's just see if we can play that on the, the device as well
* So mybeat.wav
* So I've just changed the, the file
* Now remember that file
* Oops, that, that file needs to be in the data folder
* As you can see it's in the data folder of my sketch there
* So I hit play again, and it will build the sketch again and send it over to the device
* And then, when I hit the mouse button, you'll be able to hear the break beat
* Okay, the device is ready
* [MUSIC] So remember because it's looping, it's going to keep playing until you tell it to stop
* So what've we done here
* So we've created an audio file by recording it, but you can also obtain audio files from this FreeSound website
* And I didn't exactly show you that
* But if you don't want to freeze out, you can see, so you want it to find a break beat of your own
* You can type break beat into there, into the search box, and you'll have to create an account before you can search and, and download files, but you can, it's pretty easy to do
* You just do it by clicking on the account creation button at the top
* Okay
* So I've searched for Break Beat, and I've been given all of these files
* And when you go into the file, you'll see that there's a download button
* So if you want to get your own Break Beat into there, instead of using my one you can, you can download there
* But you will need to load into Audacity, and exporters of monoware, as I showed you before, with my recorded sound
* [SOUND]
* So, we've, we've obtained some sounds, and we've learned about different types of sounds
* And, we've set up the audio assistant to play a sound
* And, we've had a little look of what, what looping is about
* But you can actually control the looping properties of the, the audio player like this
* So if I go into here, back again, I can tell it not to loop the files, so if I go back to my ping thing, which we didn't want to repeat, we just wanted it to play once, then I just do player.set looping, and set it to false, which says don't loop
* Just play once
* The thing is, I now need, you'll see that plays once, if I, if I do that
* But if I wanted to play it again, I'll need to call Queue, because that will rewind it, back again
* So once it's played, it's like a tape that's played to the end
* You have to rewind it again to trigger it again
* So what I'm going to do is I'm going to play it
* And, in fact, I'm going to put it the other way around
* So I'll queue it up to zero, then I'll play it
* So I'm just going to run this sketch, and we'll see what it does
* [SOUND] So it's ready
* So we're going to hit the mouse button
* [SOUND] You can hear it plays at once
* If we hit it again
* [SOUND] Can you hear it plays again
* It's not looping because I told it not to
* [SOUND]
* Next week you're going to find out more about the details of how audio is represented in the computer's memory
* But for now that gives you the basic tools that you need to create audio files and play them and control that playback
* In your sketches
* [MUSIC]


--- SKIP ---: 16_1-6-sonic-painter.en.srt


--- SKIP ---: 16_1-6-sonic-painter.en_SENTbySENT.rtf


--- PROCESSING FILE --- 16_1-6-sonic-painter.en_SENTbySENT.txt
* Okay so, Lesson one has been all about getting started understanding graphics and sound and then try to make some very, very basic program by manipulating them
* And I want to extend that idea so that we've got to our first-stage application, our Week 1 application
* And if you had a look at the intro video for running an app on your iOS device you've seen a little bit of this already
* So it's called Sonic Painter
* The application just allows you to draw on the screen and it makes a series of shapes and at the same time you can manipulate some sounds using very, very basic functions
* So it's quite a simple application
* Having said that, there are a number of applications that are available on the Web that people pay to use, that aren't that much more complicated than this
* The key to making it look nice is about having really, really good sound and image integration, so that people really feel that it's interactive
* And, also mapping information from one domain to the other, we're going to talk a little bit about how to do that
* So the basic idea is that we draw shapes on the screen, and they slowly rub each other around
* and we have different brushes as well, which I'm going to talk about
* And as you make a gesture to draw a shape, it plays back and manipulates a sound
* And that's the idea behind Sonic Painter
* So how do we map information from the mouse to control different aspects of graphics
* Well, we need to think about graphics parameters specifically
* The whole plan is to make something that looks much better than just someone wheeling around it with their mouse
* But essentially, it's someone just wheeling around a mouse with their finger
* It's up to the programmer to try and make it look more interesting than that
* There are a couple of techniques which you can use, which make that much easier
* The first one is mapping information
* So we start with the map command and we're using it to adjust the color
* And you can see, the idea is we take the mouseX position and we map it between 0, which is x equals 0, which is right at the leftmost part of the screen
* And the width, so the idea of that is that the user moves their finger from here to here, we get a number which is representative of either 0 or the width
* And then we map that down to a scale between 0 and 255, and as Marco's already explained, that's the range, the parameter range for a color
* Now, we're doing this by using this width command, which always tells us how wide the application is currently and then we're mapping it in
* So let's have a look at that in action
* I'm going to make this really simple by changing the brush to the most simple brush, in fact, it's just going to be a line
* Here's a line and I need to be sure that I'm actually deleting the right line there, okay, yeah
* Let me just try and run this again
* Now, what you'll find is, if I refresh this, it will pick up the changes I've just made without me having to mess with it too much
* And we should find, yeah
* [MUSIC] There's a single line
* I'm just going to mute it for a second so you can't hear, you can just see
* I'm just drawing with a single line and you'll be able to see that on the desktop version as well if I refresh this
* A single line is being drawn
* So let's go back to the code and see how that works
* We're basically setting here, we're, we're going to talk about the audio in a bit more detail later on
* But as Matt's already explained we can load a sound and we can play it back
* So playing back the sound, and then we're getting the red channel from mouseX
* And we're mapping the, from 0 to the width to a range of 0 to 255
* And then we're getting the blue, and we're mapping mouseY, which is up and down from 0 to width to a range of 0 and 255
* So that gives us our red and the blue
* We've also got a green
* Now, let's have a look at the green and what it does
* So it's more green on the edges and less green in the middle
* How do we do that
* Well, we can get the distance from the center
* The dist function in processing allows us to get the distance
* From any particular point to another point, and it uses, quite fabulous to do this basically just, it makes a triangle and figures out what the hypotenuse of the triangle is
* So the hypotenuse is, if you have a right angle triangle, it's the bit that is the longest item aside
* And that's the bit we want to work out, with this being one point and this being the other point
* Now, the dist function does that for us
* We just give it an xy coordinate as a starting point and an xy coordinate as an ending point
* It tells us what the distance is
* And we can use that to work out what the green color ought to be
* So dist does this for us
* We get the mouseX and mouseY, which is the, where the mouse or where the finger is on the iPod or the iPad or iPhone
* And then we see how far that is from the center which is width divided by 2, height divided by 2
* So, let's just see again how that works
* So we have this, what we do is we're using that to adjust the green
* And if we have a look at the app itself, you can see we're greener as we get away from the center, and likewise here
* Just the same here
* All right
* So we've got a nice mixture of red, green and blue across the entire range, across the entire screen
* We also want to know, well, let's see what else we can do
* We can get the speed
* If we get the speed, we can use the distance between the previous last position and the current last position, and that's a good measure of speed, because it's halfway traveled, right, with the finger
* So we get that distance, and that tells us how fast we're moving
* Simple as that
* We can also change the alpha
* We can use the speed value that we've got to set how bright the alpha is, so how transparent the drawing is
* So the faster we go, the more transparent, sorry, the less transparent it is, and the slower we go, the more transparent it is
* We can also set another variable called line width, and we can use the speed to do that
* You can see on the screen here
* That if I go very slowly, it's a fat line, and if I go fast, it's a thin line
* Also, I might want to constrain the line width so that it doesn't go over a certain width
* Otherwise, I can end up with a really big, fat lines, when I don't want them, simply because I'm going very, very slowly
* So here, what we're doing is using a function called constrain, and we're saying that we want to constrain the line width, which is this variable here to between this value and this value
* Between 0 and 10, so the maximum line width is always going to be 10
* Okay
* So, using these techniques, we can map parameters from mouse interaction to color
* We can get distances from the mouse pointer to different different parts of the screen and use that to control other aspects of the drawing
* we can also constrain certain elements and certain variables that we've created such as a speed variable, which tells us how far we've traveled between two frames
* And we can make sure that they don't cause massive changes in our program
* So we can also have different brushes
* Now, I've included some brushes for you to have a look at
* These are quite complicated
* It's up to you to spend more time looking at them
* They're not too complicated
* In fact, sometimes, there'll be over, a little bit over edge, but they're all right and they're just to get you started
* But what makes a really good visual app is really, really good brushes
* You'll know that when you use Photoshop, it's one thing just to be drawing a line on the screen
* It's another thing to be able to draw a very, very pretty pattern
* So your brush can even be an image which you load
* Well, in this case what I'm doing is I'm just using the, the basic shapes, because it's lesson one
* The basic shapes that comes with processing, circles and rectangles and lines
* Just to give you an indication of some cool things you can do with very, very limited material, and it's up to you to expand on that, really
* We've done the color, this is about shape
* So, let me show you some of these brushes
* And I'll quickly demonstrate a few of them
* So brush1 here, all I have to do is make it is on comment brush1, and then refresh my apps
* So I can just refresh
* Wait for it to finish loading
* You can see on an iPad or an iPhone, there's a little icon
* There you go
* So this is drawing a circle
* And you'll notice that the faster I go, if you can see that, the faster I go, the bigger the circle
* And that's a very simple idea of a brush, so now, I'm going quite slowly and I've got very small circles but the lines are still quite thick
* And the curls are more or less the same
* I've also got this one, which draws squares instead, so it's the same thing, but it's using rectangles
* It's just loading up here, you can see there's a little icon spinning around
* There you go
* And this one produces a, not just one square, but a whole bunch of squares
* I think that's something which is really important to understand, just because you've only got one input, doesn't mean you should only have those one inputs
* You can have more
* So you can take one input and map it to lots of others
* I'll show you how we do that in a minute and then I'll expand on that
* brush3 is a random selection of lines
* So, when I draw on the iPad screen, we can see, we have what looks like, I guess it looks like kind of very bad tinsel
* As I say these are just examples to get you started
* And they get varied with thickness depending on the speed and you get the color variation
* There's a few more of these
* You should have a look at them
* But, this one is a bit more interesting
* And this introduces another idea
* Symmetry
* Now, you can use symmetry to easily create order out of something which doesn't necessarily look like ordered
* And in this example, all I'm doing is I'm getting the mouse position and drawing the line the same way that I did in the very, very first approach that I showed you
* But I'm also drawing a line on the opposite side in the x-axis
* So anything I do is mirrored, and when you do that, it gives the illusion that it's somehow intentional or more intentional than it was
* So if you have a look, I can just do this and it looks like I have a symmetrical pattern, and I do
* But that's because my single, my single interaction is now two interactions that mirror each other, I've got in sort of lateral symmetry
* And this symmetry is one of the methods that you can start to make stuff that looks very random, look very ordered
* Symmetry is a cheap way of getting something beautiful
* And the more layers of symmetry that you add, often, the more attractive people find things
* Not always, because it depends on their personal taste, but it's one of those things you should explore if you're interested in making, for example, concentric patterns or any kind of abstract patterns or flower type shapes and arrangements
* It's used all the time in lots of different forms of art and it's a very important aspect to computer graphics
* It's a very important way of taking something very simple and making it very complicated
* So I want to show you a more advanced version of that symmetry sample with perhaps eight order of symmetry
* That's with circles, let me just make sure that it's right
* That's, no it's it was actually the next one
* I should have known
* Yeah, so this is the same, but it has eight borders of symmetry
* And you'll notice now, we get something that looks, that has a kind of religious appeal
* And if I turn the audio up, we can see how this is going to work
* [MUSIC] And I'm randomly drawing, it doesn't matter where I draw, I get symmetrical patterns
* I'm literally, I'm paying no attention to what I'm doing
* But it's, it's just coming up with interesting stuff
* That's because I've got so many different reflections
* As if I'm looking into mirrors upon mirrors upon mirrors upon mirrors
* Cheap trick, but powerful
* Okay
* The last thing I want to talk about is sound
* I'll do this as quick as I can, because I know you want to get on
* It's really easy to have more than one sound, you can hear, we've got two
* We've got the bells and we've also got the ambient wash
* So I'm loading two sounds in exactly the same way that Matt was showing you
* [MUSIC] Let me mute this while I quickly show you
* What we have is a separate AudioPlayer, AudioPlayer 2
* And player2 loads the following exactly the same way
* So we have one maxim context, but we have two players
* player2 is loaded here
* We set the new ping to true, and we're also balancing the first time I'm loading, which is what I must warn is a lot louder than the bells
* So I'm using the volume command to turn the volume down for the first one
* And then, I'm playing them both in this mouse drag method
* So when I, when the mouse is dragged, it starts to play the sounds before that it's silent
* I'm also doing a couple of other cool things, which I'm going to talk about in more detail in the next lesson, and that's sound manipulation
* And this is just a taste of [UNKNOWN]
* The two things I'm doing to make it more interesting is I'm altering the speed, as you can see here, but I'm also altering the filter
* Now, the speed Is a really simple equation which I'm going to quickly show you now
* player2 speed here is the mouseX divided by the width divided by 2
* So wherever that I am, from x, so from 0 to width x divided by width times 2, that is how fast I want it to go
* And that's why we get these lovely sounds, these lovely sounds
* [MUSIC] There we go
* So I can slow that right down
* Also, I've got a filter on the ambient wash, which means the further down the screen I am, the brighter the ambient wash is
* [MUSIC] And I'm going to explain that in more detail next week
* So, I think it'll be a great idea for you to take this example and pick it apart, add your own sounds, add your own brushes
* Try and make something which just helps you understand the different aspects of graphics and sound to give you a better indication of how you might move forward and create an application of this type for your uses
* [MUSIC].


--- SKIP ---: 18_1-7-outro.en.srt


--- SKIP ---: 18_1-7-outro.en_SENTbySENT.rtf


--- PROCESSING FILE --- 18_1-7-outro.en_SENTbySENT.txt
* Okay, so that's the end of Week one
* And a little kind of easy way in
* And yeah, that was okay
* It seemed to it seemed to all work
* But if you've got any questions, we've actually got a forum which you can use
* And they should use the forum
* Right
* Because, there's a lot of our students on the forum
* Aren't there
*  >> Yes, so students here at DOLSMITH have been doing several years of this kind of work
* And we'll also be on there from time to time, if there are some important questions we'll be answering them
*  >> Yeah, so they, they're a creative bunch as well
* Aren't they
* We got sta, people from our creative computing program, and also from people we know work with you know, our colleagues in the art department, and also on our Masters program too
* So it's worth you checking out the forums and asking questions
* But what are kind of things can we encourage people to do in the coming week, before week two
* What's a good thing to do
*  >> You might have a look at some of the pr-, the capabilities of processing
* Look at the processing reference
* I got a link, a link up there on the Coursera website
* >> What about sound-wise, what's a good thing
* >> Well, you just gotta get out there, and record some sounds
* Get out, get out, get out away from the computer
* Go out and, and record some sounds
*  >> Yeah
* >> And load them in, and just play around with those parameters we've already shown you
* We've shown you how to slow things down, and speed things up
*  >> Yeah
* >> You can, there's so much detail in, in the recorded sound, that you can really have a lot of fun just exploring that
* >> Yeah, and if you start filtering and stuff like that, it kind of really comes alive
*  >> Exactly
* >> And there's loads of different ways you can do some interaction, and stuff like that
* So okay, that sounds good
* So that's what we're going to do
* there's some stuff that you can do, you have to do, and there's some assessment type behavior and things you can look out for
* But we're going to see you next week
* Next week we're going to be doing a DJ/VJ type app
* And there's a lot more sound and a lot more graphic and direction and specifically video
* So we'll see you there
* [BLANK_AUDIO]


--- SKIP ---: 01_additional-lecture-introduction-to-programming.en.srt


--- SKIP ---: 01_additional-lecture-introduction-to-programming.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_additional-lecture-introduction-to-programming.en_SENTbySENT.txt
* This is the first of our lectures for people who are doing this course but are new to programming
* If you've got no programming experience you're probably going to have to work a little bit harder in this course
* It will be a little bit more challenging though we will guide you through it, and this, these lectures will explain the major concepts
* And we're also going to put up a bunch of other materials that can support you
* before we talk about programming we need to think a little bit about what a computer is, in order to understand how to program
* this is a computer, the inside of a PC, I, I just got off flickr
* and you can see it's messy
* There's lots of microchips, there's sort of motherboards, wires everywhere
* But actually we don't really, to program, we don't need to know what a computer is in all it's complexity
* Actually all we need to know is some very simple things, and And really we just need to know two things that make up a computer
* This is the processor
* It's not actually a processor, it's a fan, but underneath that fan is the processor
* The processor is the thing that does calculations
* It does actions
* It really is the core computer
* And the other main that we need to know about is memory
* This is where we store data
* And anything that is, you know, any form of data that we are processing in the computer must go through memory
* And really what a computer does and what a computer program does is
* The processor does actions on memory, memory is composed of very very simple output, so it's, what we call bits
* Each bit can, is like a switch
* It can be on or off
* And we normally represent that as a zero and a one
* So, really memory is along Series
* And the processor, what that does is very simple operations on memory
* It can add two elements of memory together, multiply those mathematical operations, very simple ones, and it can move things around in memory
* And that's It's a little bit more compelx than that, but really not much at all, it's, you know, what, it's only these very simple things
* So, why are computers so powerful, if all they can do is, is, move around and add together zeroes and ones
* Well, the reason is, because memory is very, very big
* So it's measured in gigabytes, that's billions, American billions of, of bytes
* A byte is eight of these bits
* So there's a lot similarly processes summations in gigahurtz which essentially billions of these very simple instructions per second
* so a computer program is really about doing a simple things
* But very, very fast and lots
* Luckily we don't have to think in terms of the very, very simple operations that can, that processors we can do when we want the computer to programs
* We turn them into what we call high level languages, that have, that combine lot's and lot's of these, very simple operations into bigger ones
* this still may not look very readable to someone that's new in programming
* But you can see that, at least we've got much higher level concepts like Backgrounds, in the background color of the screen, rotating things around, drawing images, stuff that's, that's at least a bit more in the, the realm of what we think about as humans
* Similarly those, those ones and zeroes in memory, we can interpret them in many, many ways to create many complex forms of data
* A single bit can't tell us much, but it can tell us if something is true or false
* It can be this kind of binary division
* But normally you would combine bits together into more complex things, the basic level with calculating numbers
* Whole numbers or fractional numbers, we actually leaps rather differently I'll come back to that in a later lecture
* Text, and then much more complicated things like images or sound waves
* All of these things are essentially longer and longer strings of ones and zeros and this course will cover a little bit about how the last two represent when the main merges
* Okay so let's try writing a simple program
* This is processing
* it's a piece of software
* it's a program language and also it's a piece of software for writing programs in that language
* We have this area here where we can type the text of our program
* But let's start by playing with, pressing the Play button to run our program
* And here we are
* We've got a program, it's a very small window, it doesn't do very much, but that's not really surprising
* We haven't actually written any program text
* At least even with writing nothing there, we do get a program
* Now I can close my program in the normal way with the close button, or I can also press stop to stop it running, and then we can actually try writing something
* Okay
* I'm going to first write this command size 640x480
* And let's see what that does
* There we go, we've got a much bigger window
* and I've, what has happened here
* Well I've called a command size and that, what that does, size is the named command
* And it changes the size of the screen
* And you need two numbers in order to change the size of the screen
* And one of these numbers is the width, 640, the other is the height, 480
* And These numbers are put in brackets, so every time you're calling command you need brackets
* There are commands which don't need, any, numbers
* What we call parameters, parsed in
* But we still need brackets
* Empty ones, which show that we're not parsing anything in
* The commands are separated by commas
* And at the end of everything we have a semicolon
* Now the first thing to really notice when we're writing new programs when you're new to programming is that grammar and punctuation are vital, what we call the syntax of the program
* So computers, in many ways, are very, very stupid so they don't understand things very well, unless you've got very, very precise punctuations to tell them what to do
* It needs these brackets, so that it knows we're calling a command, and it knows where all the values we're passing into the command, what we call parameters are know, needs those, the begin and end brackets to know when these parameters stop
* It needs a comma to know when, parameter has ended and the next one has started
* It needs a semi-colon to know when one, when each command has stopped
* Don't have those things it will get you [INAUDIBLE] out/g
* For example, if I leave off the setting [UNKNOWN] it gives me unexpected token null
* It doesn't, it's something it hasn't understood
* And often these errors can be quite hard to understand
* so it's important to be quite careful
* Okay, let's try doing another thing with background 255, 0, 0, and there we have arrange background
* I will do, while it's slightly not the program that draws a pointed screen, I will show this in more detail in me main lecture, might want to take a look at but I can do that to set position and give it a certain width
* Otherwise we're not going to be able to see it very effectively
* And if you do that some [INAUDIBLE] stroke weight length
* so this is a typical thing, I did it accidentally, but I've written the name of the command wrong
* It didn't understand it
* The function stroke width does not exist
* I made an error, it told me that it wouldn't work
* Very common easy mistake to make um,
* It was completely accidental in my [INAUDIBLE], in my case but I'm going to leave this in the video because it helps you see exactly the kind of areas you get, and what happens when you get that, you get this little red bar coming out and you know something is wrong
* And it gives you some information which can be used for the function strokewidth does not exists
* [INAUDIBLE] What's one of them, stroke width and then [INAUDIBLE] points
* I'll go over these commands in the main page
* And there we are, we've got a dot on the screen
* There are two other things that I want to show you that can be useful
* Firstly we sometimes want to write notes in our programs, if we want to sort of explain them
* So maybe I want to explain them so even
* Explain it to somebody else using your program or simply if you're going back to your program later it's useful to have notes to remind yourself what's going on
* We call these comments and we create a comment by putting these 2 slashes in front of the line and anything else on that line is ignored
* I could do it at the end of a line a well
* [SOUND] And sometimes if I want to get rid of a line of code temporarily as I'm testing what I'm doing I can comment it out like this, so I can put a comment, turn it into a comment and all of these comments are going to get ignored
* And as we'll see now, the stroke weight is no longer being called and my dot is very tiny you may not even be able to see it
* The other thing I'd like to do, show you, is another very useful thing when you can, you're, when you're programming, is that you can also print stuff out
* If you do print ln, that stands for print line, and some text
* Like that, it will print it out
* Note that I'm putting all the text values in these double quotes
* You need double quotes so that the program knows this isn't the name of a function or anything, this is actual text you want to use
* So you need to have that in double quotes
* And when I'm on my program, it will print heavily down here at the bottom of the screen
* That's useful for you, we'll see in the future, as a way of getting information about the program when it's running, and some debugging
* Okay, so let's recap that a little bit
* The core of writing a program is the number of commans
* Each command has a name
* It has parameters, these are values that we pass to the command to change how it works
* For example, the size command takes a width and a height
* These parameters are inside brackets and we need commas to separate them
* And then we need a semicolon on the end of the line
* All this punctuation is very important, and you mustn't forget
* We can use comments to get the computer to ignore certain bits
* Okay, so the last thing is, I showed you, is this println command, and its for using to print things out
* Print out text, you can also print out different values like numbers and variables which we'll come to in the future
* And you can use the plus to combine together text and values, so that'll be quite useful in a number of ways later on That way, we keep blocking our programs
* Okay
* So that's a very brief introduction to the basics of programming and I'll do a couple of extra lectures this week on specific topics and will be covering various topics next, next couple of weeks to explain some of the concepts we use in the main languages.


--- SKIP ---: 02_additional-lecture-variables.en.srt


--- SKIP ---: 02_additional-lecture-variables.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_additional-lecture-variables.en_SENTbySENT.txt
* Welcome to the second lecture on introductory programming for those of you doing the course we need for programming
* So in this session I'd like to talk about variables, but before we start let's have an example
* So let's write a simple processing program, Correct the size of the screen, set as background, which I might if you haven't looked at our main videos yet, you'll find out why number 255 is right in there
* And let's draw points, let's set stroke rate say see the point and then draw, draw a point, position 100, 100 say
* That's a fairly basic processing program
* And now we gave, it's just a point
* Where ever you want to draw a point in the middle of the screen
* Well, we can do something like this
* The middle of the screen is half the width and half the height, and we can do width divided by 2, height divided by 2
* And there we go to the point in the middle of the screen
* Now, what exactly have I done there
* So we're quite used to, where the last session we saw, we saw how we could call a command like point, using numbers
* But now we've used that's something different we've called point with width divided by 2 height divided by 2
* And so what is width
* It's a, it, behind the scenes, it's a number, a number that gives us the width of the screen
* And in the case of the example, it was 640
* But here it's a name that stands for that number, and I can use that name in the program Instead of using a number and I can do calculations with it I've divided by 2
* That slash sign as we'll com to later is is division in the program, because we don't have an easy like divide symbol in the, in the in the keyboard
* So That's a new element
* And it's something that's called a variable
* A variable is essentially a name that can stand for a number
* It's called a variable because not only can it stand for a number, it can change the number it stands for
* It can change
* so what does that mean
* And what if we want to create own own variable
* And we'll see in future examples, it's very useful to have a, a name by which to refer to a particular number
* So, this is how we create a variable, and I'll go through this in detail
* If we're creating a known variable, it will look something like this
* we're correcting a variable that is a number that starts off equal to 0
* We first, we need to go back to our example of what a computer is, you can think about what really is happening
* So this is our computer, it's got a processor and a memory, variables, astute memory
* And what happens
* What a variable is, is a little box in memory
* And, inside that little box of memory you can put memory or different things
* The first part of the of this command to, create a variable, int We'll come back to exactly what that means but it's basically saying this is a number
* So create new box big enough to hold the number
* Next thing we do is give it a name
* Call is pos X, for example
* That's just the name of the value
* Call it anything, alright
* Call it John, call it Mark
* In this example, I'm representing the X position of something
* So I'm going to call it posX
* And then we set it equal to a, to 0
* That means we're putting in the number 0 inside our little box, in memory [INAUDIBLE]
* So what we do in a case of variable is, a variable is basically a box in memory
* It has a name
* And then can have values in
* those values can be numbers They can be other things
* So let's go back to what we were talking about in our
* Previous lecture about how memory is composed of a whole lot of 1s and 0s
* And think about 1s and 0s, what we said is that we can create lots of different things after these 1s and 0s, interpret them in different ways
* So we could have basically true, false, very simple one bit
* There is [INAUDIBLE] one bit in reality but think of it as 1 bit
* You can have numbers as we saw we can have whole numbers, factional numbers, we can have text, we can have really complex things like images and audio wave forms
* And each of these we can have variables to represent any of these things
* But the key thing is that they take different amounts of memory
* So a number, a whole number is actually [INAUDIBLE] different need from a fractional number
* And both of those things need a lot less memory than text and certainly than an, than an image
* So when we're creating that little box in memory for a variable, we need to know roughly how big it is and what kind of thing we're going to put in it
* And for that reason, we give names to all these different types of data
* And that this we call the different types, types and There's a tight Boolean, which can be true or false, and that's it
* A tight int, that means integer, which is a mathematical word for whole number
* Float, a floating point number
* Means a fractional number, sort of decimal number
* the reason it's called flight is slightly complicated, but it's due to the representation of the number in the computer
* String is a word for a text, so it's this little string of characters
* And then there are complex types of PImage and AudioBuffer that are specific to processing [UNKNOWN] Not, not yet
* Come back to those in a minute
* We've also got a special type void
* Which we will come back to in a fu, future lecture, which represents nothing
* Come back to why we might want trips in life
* So that's, comes back to our little int in there
* That int And that posX represents the fact that posX is a number
* A whole number
* So we can we know exactly what the computer knows, exactly what kind of thing you want to put in
* That's why we can put zero in there, we can put a word like thread
* We can in turn say float instead of int and that will give us a factual number or string if you want to put text in there
* So, let's look at something else we might do with the variable, setting its value
* So this is saying that our variable when setting in X position
* Becomes equal to a number 34
* Now, let's just go back
* Becomes equal to, that's an important thing
* Equal, those equal, that equal sign's, in programming is what's called an assignment operator
* Takes one value on the left side of it, and sets it to be the new value
* So it changes the value of posX
* It's not saying that they're equal to begin with, but once you've done posX equals 34, after that posX is now 34
* That equal sign is how you change the values
* You can set a variable to equal to another variable
* So pos X is now going to have be equal to the width of the screen
* Or a function, certain functions do calculations and
* Can give you back numbers, or other values
* Up to now, the functions we've seen just do stuff like drawing
* But sometimes we have a function like random, a very useful function, which generates a random number
* So this call is going to give us a random number between zero and 100
* But he's going to set posX to be equal to that random number
* So after that posX is a random value
* And we'll see in the main lecture how we can use a number of these functions to do calculations and then give us back a value that we put in the variable
* So we're giving numbers to, this random function, we're giving it zero and a 100
* That controls How it works
* Basically, for say, 0 and 100, the random, it will give us a number between 0 and 100
* If I say 0 and 10, it'll give us a number between 0 and 10, and then it gives us back a number if you present posX to there
* Some functions return And return strings, texts, Boolean variable values, images, it can return any kind of type, but something that we, can be put in a variable
* We can also do calculations and put the results in a variable
* So we can take a value, which in this case
* It is another there
* For mouseX
* MouseX is a variable which represents the position of the mouse
* The X position of the mouse
* And we add something to it
* We add 1
* That gives us a new number
* Whatever mouse X is plus 1 set for mouse X
* It's 100
* It's 101 If you can do basic math
* And we take that value and put it in posX
* 
* and we can do something else
* We can take the value and change it based on it's own old value
* So we can take posX, make it equal to
* Itself but the old value of posX plus 1
* So if posX is 30, we add 1 to 31 and set posX to that
* That's a way of changing a variable as we use it
* in in future lessons we'll see how we can use that to animate things
* By every time changing the value of the variable, if that position, variable is a position or something similar, we can make things move around
* This is such a common thing to do, there's this little shorthand for it
* PosX plus equals one means posX equals posX plus 1
* It means exactly the same thing
* It's a way of adding a value to itself
* posX plus, plus is an even shorter shorthand when the, you know the value of adding is 1
* posX plus, plus just means add one
* PosX
* PosX plus equals means add a number to it
* All these three expressions are showing you, these three lines of code, are the exact same thing
* But in the first two, I could change the value of 1 and add 2 instead
* The last one is always been adding 1
* So, let's look at some of the, things you can do with calculations
* You can do some basic maths
* We've seen how to add; you use the plus sign
* Straightforwardly, to add two things you'd do plus equals
* If you want to add something to a variable And plus, plus if you want to add one to a variable, could do exactly the same with subtract, minus signs, take two numbers and subtract them, minus equals subtract number from a variable, minus, minus, subtract one
* Star is asterisk, is used for multiplication, because there's no sort of multiply sign on the standard keyboard
* And we can do star equals to multiply the value of err by something that no equivalent to plus, plus
* The slash is the divide symbol, star's the multiply
* So those are some basic math, there're more operations
* That's it for now
* another thing you need to think about in terms of calculations is brackets
* If you want to do multiple calculations on one line and combine them together, you can put brackets 'round them as you would in standard maths to constrain which happens first
* So, this stuff in the inner brackets is done first
* You calculate the first brackets, and then use the results of that calculation in the outer brackets
* So you'll, what's happening here is you're multiplying x by 3 and you're adding 1 to the result
* Okay, so let's get back to various types
* We've talked a lot about Variables now and how we can have different types of boolean, int, float, string
* it mostly talked about numbers because that's mostly what we're going to be using in graphics
* In the future we will talk about boolean
* But now I want to talk basically about things like PImage and AudioPlayer, because they're actually much more complex than something like a number
* Obviously a, a whole audio file is more complex than a number, but even the way the variable works is slightly different
* So this week Matthew's going to talk about AudioPlayer; let's have a look at it
* So just as we did int pause x, we get the type of the variable and the name
* Here we give the title variable audio player, and the name, is player
* You can give it any name you like
* if it's a high hat we can call it high hat, if it's a violin sound we can call it violin
* We can call it anything we like
* so that's essentially the same thing
* and Minim is another aud type we use in audio
* Matthew will talk about exactly what all that's used for, but here is how we create Minim objects
* So, just as we set the value
* Of our int variable to 0
* You can set the value of an object, and so I didn't use the term, but these complex types are called objects
* Our object's called Minim
* Now, we need an extra bit in here, because there's no easy way of saying Right
* We can just write three, if you want a new variable, a new number
* But there's no quite so easy way of doing that
* We need a new command called new, and what new does is create a new object
* And it does it by calling a function
* Called a constructor
* This is like a command but it has the same name as the type, as the object
* And it's used to create any value of those objects
* They're new in the constructor
* By the name of the type combine together to create a new value of the objects
* And you can [INAUDIBLE] pass parameters in just like any other command
* Matthew will explain this, but this essentially means, the, it's something that wraps into programming, you don't have to worry about it too much
* But it's an example of passing something in, so that can be used in creating an object
* So, In an audio file, you might pass in the file name
* In an image, you might pass in how, the width and height of the image
* There's lots of things you could pass
* And then there's another important thing, big difference between types like numbers and objects
* A number Is just a number you can do some calculations on
* In a, in an object, as well as having its value, you can call a function on that object
* What that means is, if you're calling a function play, but that's not a generic function, that doesn't apply everywhere, you know, you can't just play
* You're playing a particular audio file
* 'Kay, meaning to play an audio file
* And that's why we do this little bit of style of code where we're doing player.play
* Recalling play On a specific object
* [INAUDIBLE] specific audio file, not general audio file just one particular item
* And we're using this little dot
* What a dot does is links the function you're calling to things have been called
* So you do, player.play Cause of function one specific object
* A very useful capability
* So this is something that Mathew's going to use and that Nick and I are going to use in the examples a bit later in this lesson
* So that was a very brief introduction to variables
* You'll see a lot of examples in the main lessons
* And and hopefully that will help you understand these concepts that we build on programming
* If you need some more help we've provided a bunch of links relating to programming on the main site.


--- SKIP ---: 03_2-1-intro.en.srt


--- SKIP ---: 03_2-1-intro.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_2-1-intro.en_SENTbySENT.txt
* [MUSIC]
* Hi, and welcome to week 2 of Creative Programming for Digital Media and Mobile Applications
* I'm Mick
* This is Matt and Marco
* Say hello
* So last week, we learned how to do the basics of graphics and sound
* This week, we're going to be a little bit more advanced
* We're going to create an application called DJ Tube
* it's really basic, but it does run on all your mobile devices
* So, it runs on your iphone and an on your ipad and it runs on your android device as well
* But, we're going to make these a bit more advanced
* We're going to learn how to play more than one sound at once, and manipulate the sound by changing the pitch and the speed, and also by maybe doing a bit of filtering
* We're also going to learn how to create image sequences
* So, for example, making editable videos for live VJ interaction
* And also image sequences for doing basic animations
* Mark is going to take you through all the graphic stuff as usual
* Matt's going to take you through the basics of the audio
* And then I'm going to pull it together and show you the final thing
* And in the final piece, the DJ tube app, there's a lot of mouse interaction, and you can start and stop different tracks and synch them up together
* so you'll be learning how to synchronize different audio tracks as well, and play them back so they're all tightly synchronized and connected to the vision
* so yeah, okay, we'll start with Marco [SOUND] [MUSIC].


--- SKIP ---: 04_2-2-images.en.srt


--- SKIP ---: 04_2-2-images.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_2-2-images.en_SENTbySENT.txt
* [SOUND]
* This week, I'm going to talk about images and how to display them in processing
* in later weeks, I'm going to go into a lot more detail about how images are represented, but for today it's mostly about laying images out and then we'll look at how to create animations with sequence of images
* So if you look on my slides here, we've got an image taken from a sequence that Mick has prepared for his DJ App, DJ App, and I'm going to show you how you would display this kind of image in processing
* So, Matthew, last week, talked you through loading up sound files and playing them
* In many ways, loading up images is very similar
* You have something called a PImage object uh,which represents the image and you load that into file
* So what you do is you create a variable of type PImage and you Load that in based on the file name of that image
* And as Matthew noted last week, that should go in the data folder of your processing sketch
* just as like, just like the audio files that Matthew talked about
* So once you've got the PImage there, then displaying it is very simple, you use the image command
* So the image command, what that does is it draws the image that you've loaded in, and you can call that in your draw method
* You normally load the file in your setup
* So the main parameter the image command takes is obviously the image you're going to display
* But you can see here that it takes two other images
* to other parameters
* Those are two numbers that give the position at which you want to draw the image
* In fact you can pass yet another two numbers, which is the size of the image
* By default it draws the image as its actual size in pixels
* But you can adjust that to any size you want by passing in a width and a height
* So, I've just said that you can give the position of an image, but what does that actually mean, because an image is a big thing what does it mean for an image to be asked to take a pick
* And it turns out you can actually define what that means in a number of ways..
* The default, is an image mode called corner
* So, here I'm showing you the command, image mode, which specifies how you draw an image
* And by default that's set to corner
* And what that means is that the position of the image is the top left
* Off the image
* Sign on the red dot here
* So if I were to call a image with position 0 0 the top left of the image will be at the point 0 0 on the screen
* You can also use imagemode center
* Which means that You must position the image based on the middle of the image, and often that's more convenient
* It's often more intuitive to think of it, the center of the image as its position, so in this case, if I were to now call image zero zero the center of the image would be at zero, zero, which is the top left of the screen
* Which is probably not even what you want
* but if you would set, to set the position to something else you could get an you could position it well
* So I'm going to talk a little bit more about positioning images
* but first let's have a look at an example of this working in practice
* So this is a very simple processing sketch that involves loading and displaying an image
* I'm creating at the top of the sketch here a p image variable
* I'm loading that in from file
* I'm here, I'm doing something clever, I'm setting the size of the screen to be exactly the same as the size of the image
* So I'm using the image width and the imadge dot height, to find the width and height of the screen and down here I'm just drawing the image at position 0,0
* And there we are with displaying an image
* I can move the image about by changing the positions I'm parsing in
* I can change its size and I'm going to show you here that you have to be a little bit careful because if I set its size to 100 and 100, I'm not maintaining the aspect ratio
* Of the image, so I'm squishing it down
* So the, you've gotta be careful to make sure you're always keeping the same ratio of the width and the height, otherwise you're going to get a squished or stretched image
* one nice way of doing that is, is this, I'm [NOISE] So here I'm, so here I'm calculating a height
* Of the image that maintains the aspect ratio based on the width
* I'm setting the width to 100
* And what I'm doing is, I'm taking that width of 100 and multiplying it by the height, and dividing the height of the image and dividing by the width of the image
* Doing that multiply by height and divide by width Maintains the ratio between the width and the heights of the image
* So this image height is the right height
* So that's the image is of width 100
* And it isn't washed or stretched
* Okay the last thing I showed you was image mode So I can set imageMode corner
* ImageMode corner doesn't change anything
* So if I do it there, it's exactly the same
* I am going to leave it down a little bit to make it clear what I am doing
* But if I move image mode sensor it would be different
* Actually let's, let's draw it at the mouse position, and it will be very clear what's happening
* So I'm now drawing the image at the position of the mouse, and the center of the image is at the mouse position
* If I do it at the corner
* The top left of the image is at the mouse position
* Okay, let's have a look a little bit more about how to lay images out nicely, and how to use these commands to get the right sort of layout feeling, which is
* So getting a correct layout for your, for your screen is really an important part of getting your app to look nice
* So you need to think about it a little bit
* And maybe we'll talk about this a little more
* In his lesson today
* But let's look about how to do this
* So, this is an example
* So, If we look at this big rectangle is the processing window, we can draw an image at the point of our box
* Now, one of the most basic things you might want to do
* Is sent to your image in screen either right in the middle or it's centered in 1,1 dimension often sent to it horizontally
* And that's what we're doing here
* So I'm using image mode center, and I'm drawing the position at
* Of the box at width divided by two
* Width divided by two is half the width of the screen
* So, it's halfway across the screen
* So, I'm going to send to it horizontally but I want it near the top vertically, but not at the top
* So, I don't want it at zero
* I'm going to add a little margin
* So, margin is two of that small value, 1020 pixels
* That moves it down to, adds a little edge between the top of the screen and the window
* How about some other examples
* So what if I want to lay things out in columns
* Well, here we're still relative to the middle of the screen
* so we want to position it relative to the middle of the screen, but we want to put it One side of the the middle of the screen
* So, we want it moved from the middle of the screen in by a certain margin
* Again we add a little margin
* And then by the mid, in, the width of the image divided by 2
* So the width of the image divided by 2 is half the width of the image
* That's half the center of the image
* And we're essentially moving the image in from the center by first the margin and then half it's width
* So it's now half way into, so it's the, it's In from the center by amount given by the margin
* And we can do exactly the same thing vertically
* We can move it down by half the height, so it's half way down the screen, add a margin, and again add image.height divided by 2 to move it down by half the height
* If we were, that image.height by two is only there because we're doing image mid comma, so we're specifying where the center of the image is
* So, that's the kind of thing you might want to do, when you're looking at positioning images, you need to think relative to points on the screen, like the halfway point on the screen, width divided by two, height divided by two
* You want to add a little bit of a margin just to sort of give a bit of space to your layout, and then you may want to shift it around by the size of the image, or half the size of the image
* And Mick will show you a number of examples of that
* So now we're going to look about, at how to create animations for the sequence of images
* So what is an animation
* An animation is essentially something that moves over time
* But when we're looking at film or computer animation, we're really talking about a sequence of frames over time
* So it's not true movement, it's just a, a sequence of individual images that present one after another
* And this goes back to the glory days of Disney animation
* And form then until now animation has always been placed as a number of images along a timeline
* and so we can always think of this as image 1
* This is image 2, this is image 3, and each of those has a moment in time
* when we're talking about real images, it looks something like this
* We have a sequence of images
* in real animation we have many more of these to make sure we have smooth movements, but I'm showing this as an example
* And we lay these out in order so we have, and then we play them sequentially one after the other
* And if we play them fast enough, that gives us the illusion of movement
* So at a technical level in processing, what we need to do is to be able to collect together a large number of images and then play them one after the other very quickly
* Now,that's doing something a little bit different from what we were doing last week, so last week, we created a program where we sort of set it running
* And then we interacted with it, we we did mouse drag, mouse movements, and those most mouse movements resulted in changes to the state of the program, changes to what was drawn, that we could then see
* But when we're playing in animation, we want stuff to happen independently of whether we're drawing stuff or not
* We want it to just play along
* So, we're not responding to mouse drag or mouse pressed events
* We need the program to do its own thing independently
* And, what we use is a method called draw, and this is a really fundamental part of processing, this is, a method that is called every frame up to 60 times a second
* And is used to draw a new image time after time after time
* And as we're changing those images slightly each time we get the illusion of animation
* So in the draw method, we're going to draw our image, and then we're then the draw method automatically repeats and repeats and repeats
* so that we get that illusion of animation
* But we can't obviously be drawing the same image every time
* We need a lot of images
* To represent a large number of images, we use a data structure called an array
* Now, if you're already familiar with programming, you're probably familiar with arrays
* But if you're not familiar with them, please look at the additional lecture I've put about arrays
* Okay, we create an array and an array is a large block of memory that has a numbered sequence of elements
* So we've got an array of images
* So we've got a bunch of images Each of which has it's number in the order and [SOUND] because of the way arrays work we start at 0
* So you have 0s
* Image 0, image 1, image 2, image 3
* The other thing we need is to be able to keep track of where we are in the image sequence
* Which, which image we can't reclaim
* And to do that, we keep in variable which is the number of the current image
* It's an int because it has be a whole number to be that, that image sequence
* So we got this variable current image which is keeping track of where we are, and then when we, we draw a frame
* So when we, in our draw method
* We just draw the current image
* We use the image command, anim currentimage, and hold the position in there that we've put a position in there
* And that will draw the image we are currently playing
* So, that's doing the basics of what we need to do
* The only thing now is that we're not actually animating because nothing is changing
* So the core to animation is that every frame when we do something, something has to change
* So that we get a new image
* And in this case it's very simple
* All we need to do is move on to the next image
* And how we do that is simply add one to our current image available
* So that our image steps onto the next one
* You'll note I'm going to use this syntax current image plus equals 1 that just means adding 1 if you're not familiar with price signal Java syntax
* So, each time draw is called, so every frame, up 60 times a second, we're adding one to our current image
* So I'm moving on to the next image, and displaying that one
* Moving on to the next image, displaying that one, and the next one
* And carry on
* To large number of images in our examples we'll be looking at, sort of, over a hundred images
* So, this is an example of what our program would look like in setup
* We, we create our, our our array of images, and we start our current image at zero
* In draw, we draw the current image.That gives us the currentimage
* And then we add 1 to it
* And then we can still use things, like mousePressed and mouseDragged to control the playback
* For example, when we press the mouse we could set current image to zero
* Which would reset playing from the very beginning
* Before I show you and example, I want to go over one last thin, which is looping
* so it's fine adding one to the current position
* But what happens when we get to the end of our array
* When we run out of images
* If we try to access an image that's not in your way
* So that's, so we're getting a current position which is more than the number of images we've got
* We'll get an error, your program will crash
* So we need to do something about that
* We could just stop the animation, but a common thing we might want to do is loop
* So, this is just an example of some codes
* If we just check if the current Position is more than the length of the image and if it is, we set the current Position back to zero so we reset it back to zero
* So, let's have a look at that in practice so here is our animation sketch, I have written a little example
* Function that loads images
* you can have that in your example pack
* You don't have to rewrite that
* We load the images, passing in an im, image format
* So this is the name will look like this, movie then the number then JPG, and this is the number of images
* Then we Each frame will display and image
* We add one to it, and we go back to the beginning and leave
* And mouse press will just reset to 0
* So, and the mouse press function, where we set it to 0, when the mouse gets first
* So I can restart it when the mouse button's pressed but otherwise it will play in a loop, the animation
* There's one last thing I'd like to cover, which is playing and pausing an animation
* So sometimes you want to stop the animation temporarilty and restart it
* And to do that, we use what's called a boolean variable So that's a variable that can only take two values, true and false
* And it acts like an on-off switch, so, when playing is true, it means it's on
* We are playing
* When playing is false, it means we're not playing
* we can use this boolean variable as the input as an if statement like this
* We can use, if playing
* And that just means if playing is true then we move on the currentImage
* If playing is not true, then we're doing nothing
* So this is what is controlling playing
* and then we can turn playing on and off in mousePressed, and I am using some clever here, it's called the not operator And that, what that does is it takes a Boolean variable, and it does the opposite of it
* So it switches, we're taking playing here and we're switching it, accessing it to the opposite of playing
* So if playing is false, it will become true
* If playing is true, it will become false
* And I will show you How that works in practice, here
* So we've got a, a processing sketch which again, loads images, but we have a Boolean variable here, and we've wrapped our playing code in an in an if statement and in [UNKNOWN] we're just toggling so we're turning playing from true to flase or flase to true
* And I can just click it to turn it on and off like this
* Okay, so Matthew's going to tell you a little bit about Doing some work in audio that we need today's lesson and then we'll, Mick will show you an example how to use all this to create a VJR [MUSIC]


--- SKIP ---: 06_2-3-controlling-audio-speed.en.srt


--- SKIP ---: 06_2-3-controlling-audio-speed.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_2-3-controlling-audio-speed.en_SENTbySENT.txt
* [MUSIC]
* Right in this weeks audio class we're going to learn about how we can get more control over the audio
* You've already had a bit of a preview of that last week where towards the end of the exercises you would have got into the depths of controlling audio and using the various functions
* What we're going to do this week is look at a bit more detail about how audio is represented in the computer's memory Wha-what's this thing we're telling it to play
* Wha-what's in there and what's it, what's happening
* So we're trying to, pick a few of those details
* And then we'll look at some more, control methods, for, for controlling audio playback using RAPI
* So here's a, here's a starter slide showing you how Computers represent sound
* So what have we got
* We've got this, two blocks here
* So, the, the block, the, the has the number zero through seven
* So imagine that's a short snippet of sound
* Only seven, seven little snapshots of sound
* that would last a very, very short time
* Because sound in a, in a machine is typically represented with a lot of numbers
* So it's, it's very similar to, something that you might be more familiar with, which is the idea of, of a video, and, and film being chopped into frames
* We do the same thing with sound in a computer
* We slice it into frames, called samples, and then we just play those out through the sound card in sequence
* Now, if we, if we look at those frames, what's actually in them, it's slightly different from the video
* So in the, in the case of audio, there are a lot of frames, there could be up to, well, a typical sample, right say, for a good quality audio, would be 44,100 of these frames, of these samples per second, which is a lot of data
* So this is, this is way compressed audio formats exists like mp3 because it makes it possible to reduce the amount of data required to store the audio but maintain the quality
* But in this example we're going to be working with uncompressed data, which is just the raw numbers that represent that audio signal
* So let's have a look
* So in the first box here, you can see, I've illustrated what the real contents of a, of a single sample might be in the computer's memory
* So I've represented it with the binary number, which, which converts to 27 in base ten
* Those of you, in, in the numbers you'll be more familiar with
* So you don't need to worry too much about that conversion
* But it's just to show you that the computer's memory is taking up 16 of these zeros and ones to represent one of those samples
* Sometimes it might take 24 if it's a higher quality audio
* But in the examples we're working with here, typically it's going to be 16
* So we use 16 zeros and ones to represent one single snapshot of sand
* And, we use say, 44,100 of those snapshots to represent one second of sound
* Okay, so what I've, I've, I've shown you here is that, that chunk of memory which is represented by those boxes can extend to you know, many thousands of, of spaces in the memory So we talk about the sample rate which is the number of those samples that are used to represent the signal per second
* The higher the sample rate the more accurate the representation of the sound, the wider range of sounds we can represent
* the bit depth is another property which is as I said earlier the number of 0s and 1s that I use to represent each of those
* Snapshots
* So if we have a very low bit depth, what happens is the samples are very inaccurate
* Because they don't have enough range to represent all the possible values that sample might have
* But if you have a higher bit depth
* then you can, you can store a much more accurate representation of sound
* Now I've got a, an animation which shows that
* Perhaps more clearly
* So the first animation I'm going to show illustrates what happens if you increase the sample rate
* So we'll start with a very low sample rate and we'll see what a typical smooth signal looks like
* Now, it will start off very blocky and then get much smoother as it goes
* So let's have a look at the animation now
* So, as the, as the pointer moves across the screen, the sample rate increases
* So, you can see the signal is, kind of, getting smoother and smoother
* And the smoother the signal, the more accurate It is in, as a representation of the original sound
* So remember, earlier, I was recording myself hitting something
* And and when I play that back, I want to hear an accurate recording of that
* I don't just want to hear a really rough inaccurate recording of it
* So, having a high sample rate allows that
* So, on the next slide, we're going to see what the, what the representation looks like, as we increase the bit depth, is a kind of similar effect, in that it becomes less blocky as you increase the bit depth, but it's totally different
* Okay
* What we might say is that increasing the bit depth increases the vertical resolution, the resolution from top to bottom on the y axis, which represents how loud the signal was at any given time
* Whereas increasing the sample rate changes the horizontal resolution, which is, if you like, how precise it is in time
* So the sample rate represents the, the precision in time
* Whereas the bit depth represents the precision in, in the actual measurements that we're taking
* Okay
* So that's the end of the theory section
* We're now going to look at how we can get more control over this, this sound
* And, and, and to, to understand what, what we're doing when we're changing those controls
* So the first thing we're going to try and do It's to create an interactive speed slider which allows us to vary the speed of the playback
* So you can see in this code here that I'm first calculating a ratio
* So now I'm going to demonstrate how you can vary the speed of the sample playback
* So remember the speed, relates to the sample rate if you like
* So it's the speed of playback is how quickly we're flinging those numbers at the sound card
* So, if you increase the speed, it's going to zip through that, that, that section of memory that, that's storing the sound faster
* So if we double the speed, it should get through twice as fast
* So let's just remind ourselves by playing it at normal speed
* So player, speed, one
* Let's just run this app and see how it sounds
* So I'm running it now
* So it's now building for the Android device
* [SOUND] So that's, that's speed one, that's, that sounds very similar to how it did when I actually played it in the real world
* What happens if I double the speed
* Speed [NOISE] It's the 2
* [MUSIC] So that you can see that it sounds higher
* [MUSIC] So what's doing it, it's scanning through those [UNKNOWN] twice as fast as sending them out to the sound card
* Obviously, it's really boring, having to continue, edit, and then run it on the device
* It'd be much nicer if we could experiment with the speed in an interactive way
* So what we're going to do is make a simple, if you like, slider that allows us to slide the mouse pointer across the screen, or a finger across the screen, and
* Increase the speed
* Now speed is, is useful so in the range zero to two
* So that gives us an interesting range
* 'Kay, we just heard what it sounds like if you play at speed two
* Speed zero, it doesn't play at all, and then and so on, up to two
* So let, let's just listen to that by making interactive slider
* So what I'm going to do Is, in the draw function I'm going to continually calculate a new speed for the player
* So I'm going to calculate, first of all, the ratio of the position of the mouse to the width of the screen
* And you'll see all this, these float, things there
* I'll explain what they are, they're for
* So, I do float ratio.Now remember, float is a number that is not a whole number, it's areal number, so we can have say, 0.5 or 0.6
* And in this casewe want to, because we've only got the range 0 to 2 for the speed in this examplewe want to be able to specify that very precisely
* So I'm going to take the floating point version of the mouse position and floating point version of the width,and that, that would cause it to do the calculation with these accurate numbers
* If I didn't do this, it would do it in whole numbers and I wouldn't get my accurate ratio
* So that's the ratio of the MouseX to the width
* What that means is, when they're on the far left of the screen it'll be zero and when they're on the far right it'll be one
* Now I'm just going to scale that up by two, so that's in the range zero to two
* And then, I'll just call it player.speed with that value
* Okay
* So that should mean I can now, change the speed dynamically
* What I might do, when I tap it should queue it back to the beginning again
* We'll set it to loop
* We'll set looping to true so that it's kind of You can continue to hear what's going on
* So let's play this sketch now, let's just review that before we do it actually
* So I'm just going to review what I just typed
* Player set looping is set to true, so that it continually plays the sound
* I've calculated the ratio of the position of the mouse or the, or the finger tap on the screen
* Across the screen, scout it by two, and then sent into, for the speed, so I will be setting a speed to a range from zero to two, so the idea is that when it's on the far left of the screen you should play it slowly, when it's on the far right of the screen it should play quickly
* Let's see what it does..
* [SOUND] Okay, so what you heard there was me moving my finger around and varying the speed of the playback, as, as it was playing the sample
* Now if you do that with, with the break beat, just as, by comparison, you'll see that it has a slightly different effect
* [MUSIC] Okay, so then you're getting towards more of a musical deejaying experience where you can slow the sound down and then speed it back up again
* And it has a more performance feel to it rather than playing with the sound
* [MUSIC].


--- SKIP ---: 08_2-4-controlling-audio-stop-start.en.srt


--- SKIP ---: 08_2-4-controlling-audio-stop-start.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_2-4-controlling-audio-stop-start.en_SENTbySENT.txt
* [SOUND]
* [MUSIC]
* Okay so we've created a slider which allows us to vary the speed of the playback, and you saw that there's immediately some quite pleasing creative effects you can achieve with that
* What we want to do now is add another control which is to play and stop the sound, so we can completely switch it off..
* And switch it back on again
* It's a little bit more complicated, you're going to do it with a button
* So we'll basically make the top part of the screen into a button which can switch the play back on and off
* And then we'll make the bottom part of the screen into the slider that we used earlier
* Here's the sketch with the slider
* So first of all I'm going to go to trigger this code
* If the mouse Y position is greater than the height of 2
* Okay so if we're in the bottom half of the screen, we'e in the bottom half of the screen it'll operate the speed slider
* Now what I'm also going to do to make it obvious That that's, that's what we're doing there
* I'm going to draw a rectangle in the bottom half of the screen, which has the color of the current speed
* Let's leave grayscale for now, because I'm not working too much on the graphics in this session
* So we'll just do a grayscale color
* So you remember, color is in the range 0 to 255 We've got this ratio, which isn't 0 to 2
* So, we can just do something like, ratio times, 128
* Now approximately, give us, a gray scale based on, on the, the range of the slider
* So the rectangle needs to be at position It takes up half of the, the bottom half of the screen
* So we go zero zero and height over two, so it starts at the far left of the screen, halfway down, and it goes to the far right of the screen
* Therefore the size of it is the width of the screen and the height is the height of the screen over two
* So remember that's the x and y position
* That's the width of the square, and that's the height
* So let's just double check that, that's working before we carry on
* Okay, so I've got, cannot find symbol
* Let's see if we can debug that
* So I'm referring to a variable called ratio
* Where did ratio get defined
* Well, it's inside the if statement
* So that means that ratio, because I've declared it there with float ratio, that that variable is local to the if function
* So it's not okay for me to then use it outside the if function
* So what I can do is take it out like that and, so now I'm declaring it above the if statement, and I am then using it outside the if statement that's fine
* Okay, so now I have a problem here, where I've forgotten to put a t there
* Okay, See that, see that it's highlighting the line that has the problem
* It's quite communicative about the, the errors in your code
* [MUSIC] SSS Okay
* So now you can see the slide is now displaying a color, which represents the speed
* So I now need to quickly add a bottom and top of the screen, which deals with, which deals with the stopping and starting
* First of all, I am going to draw the button
* So I will do, and I'll choose whether to draw it red or green, based on the state of a boolean
* So we create a boolean called buttonOn, and we start off with buttonOn equals false
* So the button starts off being off
* Now if button on, so we'll represent my button as having a state of being on or off
* It's just a switch so I use a Boolean which can be a true or a false
* and Boolean's are used quite extensively in controlling the state of programs
* Way things can either be on or off
* So it the button is on, I'll set the fill color to
* Red
* Otherwise, I'll set it to
* Green
* Can you guess
* Okay
* So, then I draw my rectangle
* this one starts at 0
* This one starts at 0,0 and goes to, and the size is the same size as the other one so it's width, height over 2
* Okay, then I need to manage it
* If they press mouse, if the mouse is pressed, I need to now update this data that button
* So I need to check where it is if Mouse Y is less than the height over 2
* In other words if they're in the top half of the screen, which is where about I'm going to be, then I set, I toggle value to bottom button on equals
* And this is how to toggle a Boolean [SOUND], I'll use this operator here, the exclamation mark
* That'll switch button on to whatever the opposite state is
* So if it's true it'll switch it to false
* If it's false it'll switch it to true
* And then, I'm going to change the state of the player
* So if the button is on I want the player to play
* Remove that line
* Otherwise, I want the player to stop
* Okay, let's just clean that up a bit
* Remember, you can always do the Also format
* Ctrl+T, Apple+T, depending on what you're using
* Okay
* So, basically, if they are in the region of the button, which is the top half of the screen, then we switch the state of the button, and then we look at what the current state of the button is now, and update the player to either stop or, or play, based on that
* And then we draw the button with either red or green depending on the states in the draw function
* So let's roll that
* Okay, I can't spell button
* It's bu
* So again it highlighted the line a little examination of that line showed that I mistyped the name of the variable
* [MUSIC] There's my button, switching it on and off
* [MUSIC] So even a DJ could operate this interface
* [MUSIC] [MUSIC] I'm not a DJ, as you can tell
* There you go
* So there's a simple interface which allows you to control the speed and the playback state of an audio player
* [MUSIC] [MUSIC]


--- SKIP ---: 10_2-5-djtube.en.srt


--- SKIP ---: 10_2-5-djtube.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_2-5-djtube.en_SENTbySENT.txt
* [MUSIC] Okay, so we've heard Marco explain inmore detail how you access lots of different images and arrange them andput them on the screen
* And we've heard Matt tell you a lot moredetail about how sound is organized, how to get sounds, andhow to do things with them
* We've got an example that we've preparedfor you, for you to munge around with and play with called DJ Tube andit's like a really basic example DJVJ app that you can expand on anddevelop yourself
* Now to start with, before you can really make interesting audio visual apps,you have to have some good graphics
* You can make these yourself,and I'm sure many of you will
* But a lot of you might just want to getstarted without having to have all that hassle andjust be able to drop something in
* You'll find in the example,the DJ Tube example, there's a sample movie whichMarco will show you some frames of just a tube train, I want toshow you where I got that from and how you prepare it for use in this app
* So normally if I'm bored, I'm looking forimages and I don't want to have to pay huge amounts of royalties,I go to the Internet Archive
* If you've never been tothe Internet Archive, have you ever been on the Internet
* I don't know if that isprobably the best or one of the best sites on the Internet andone of the longest standing
* You can do some cool thingson the Internet Archive
* You can look up websites andsee the way they were in 1994
* I don't know if that interests you or not
* I guess it's of limited interest,but you can also get access to a huge arrayof copyright-free video
* And that's great, sowe're going to start there
* The first thing I want to dois I'm going to type VJ loops, which is about as easy as it gets
* You'll see there I've got VJ loops,quickly followed by VJ loops George Bush, although there aren't any George Bush VJloops so you'll have to upload your own
* That's the thing about the InternetArchive, if you do make some cool video, you can always upload it there andit's a nice place for it to be stored andit's a nice way of giving back
* But you should be able touse most of this stuff and you'll see that there are loads and loadsand loads of VJ loops for you to use
* So for example,here's a bunch of video stuff, and this is mainly, I think people dancingin a club, put through a red filter
* Now you could probably do that yourself,or if you're at home and don't happen to be in a club,you can just go to the archive
* because there's shed loads of stuffthere that you can try and use
* Once you've got a video,you can manipulate it, you can treat it using iMovie,or Adobe Premier, or any other kind of editingsoftware that you like
* A lot of people use Final Cut Pro
* We're not going to show youany of that stuff today
* It's up to you
* What you really need to be able to dobefore you can make it work inside a mobile app is you need to be ableto cut it into individual frames
* Why, why is that
* Well, I'll tell you why
* That's because most mobile devices,when they play back video, that's fine, they've got no problem playing back video
* The problem they have is in allowing youto manipulate that video effectively, i.e., change the speed of playback orskip from one frame to another
* These are the sorts of things that whenyou're making any kind of multimedia app, you want to be able to do with video
* It's not enough just to be ableto play a video file back
* That's really simple
* What we want to show you how to do ishow to make something which you can edit in real time, in time to music,that's what our DJ Tube app does
* So we need to split itinto individual frames
* And we've written a piece of software foryou to allow you to do that
* So you download a video andthen when you've downloaded the video, you can run a piece of softwarethat we've prepared for you
* I'm going to just locate it now
* It will be in your Lesson 2 document,so go to your Lesson 2 documents
* I'm just going there now
* Bear with me while I look slightly mad
* Here we are
* It's in Coursera > Lessons > Lesson2> Week2 and it's called ImageSaver
* Now, ImageSaver You might find it'sactually got a bunch of frames in it
* So I'm going to remove those frames,and I'm going to launch it, and it's a processing sketch
* It asks you for a QuickTime movie
* And it creates a seriesof individual frames, so, I've got here a movie which is, I think we recordedstraight from the Internet
* Let me just see if I can find it
* Oh yeah, here we go
* So here it is,this one's from the Internet Archive
* And it runs through the video and makes it into a series ofindividual frames, like so
* When that's done, click stop andgo to the Data directory
* Actually, you just go to the directorywhere your ImageSaver application is, the one I just showed you about, andyou'll see we've got movie0, movie1, movie2, movie3, movie4, movie5
* Now, all film is made up of individualframes as you probably know
* And each frame containsthe same scene often, but with some elements of the scene moved
* So by stringing these frames together,we can control that motion
* Now, I'm going to copy thisstuff into my directory here
* I've got DJTube, here it is,my data folder > Animation_data, and I'm going to paste it in
* There it is, neatly pasted in
* And when I run this,let's close the ImageSaver, you'll see, I've got exactly the same code thatMarco has been telling us about
* Animation_data, movie is the name of theactual movie, and then we've got a number
* We know there's a 134 images because Iknow that's the biggest number on any of those images
* Let's just check that's true
* Yeah, 134, so that's the last imagein the sequence, and we load it in
* Now, if we run that, you can see it here
* I'm just going to show you howthat works on the iPad because I think I have it prepared
* Here we go
* Let's have some audio andwhen I start, it plays it back
* [MUSIC] And I can also change it
* [MUSIC] And you'll notice that when Ichange the speed of the app, it's not just the image that slows down,it's the audio that slows down
* So it'll synchronizes all thoseimage frames with the audio frames
* And I can also get two loops at once
* [MUSIC] That's all right
* [MUSIC] And scratch them
* [MUSIC] So let's have a look at how that works
* So, actually,before we go on to see how that works, you'll notice there'salso this black record
* This record is spinning round and changingspeed based on how fast it's playing back
* Now I've cheated
* I could do it in two ways
* I could do it by getting one image androtating it, or I could use the same techniquethat Marco introduced to you, which we've just gonethrough with our video
* We can make a series of framesof a record deck rotating, and we can just animate them in as a sequence
* So that's what we've done in this case
* If I show you in the data folder,you'll see we've got black-record.png, andyou'll notice it's a PNG
* The main reason it's a PNG is thatwe can have a transparency which means that we don't see a squareimage with a round thing inside it
* It's a PNG file, a PNG file, and that means it can havea transparent background
* Actually, PNG files can havetransparent insides as well, so you can have holes in them
* We have an example of that just here,I'll show you
* We have a TV
* If I show you the TV image,it's actually transparent on the inside
* So we have the TV in our application,and we place the video behind it, and the TV sits on top of it
* But the black record,we've got a different position
* If I cycle through all of these images, we got a different position foreach of the different rotations and we rotate around, and that's how wecreate the illusion of it moving
* And we update this image basedon the speed of playback
* So let's quickly havea look at how we do that
* You can see here, we load those images in, we've loaded allthe images from the movie
* We've loaded in the black-recordas a sequence of images
* We've loaded in the TV
* They're the only images that we have
* We've loaded in our sounds in the sameway that we did with last week's session
* And then we're doing exactlywhat Marcos described to position all the elements on the screen
* And then you'll see thatwe can change the frame, the current frame,based on the speed, okay
* So every time we go throughthe draw loop we can add 1 to the currentFrame number andmultiply by the current speed
* And what that does is it justtries to go from one part of the image sequence to the nextpart of the image sequence
* But because it's multiplied by the givenspeed, it can slow it down or speed it up
* I'll look again at thatin a bit more detail, but this value currentFrame tells uswhat the current frame should be
* And we use that to accessthe current record
* Okay, so moving on, how do we know whenwe've actually selected a specific record
* What we want to happen is we want totouch the middle of the record or anywhere around the record and we wantit to start playing when we do that
* And then when we touch it again,we want it to stop
* So here's a bit of code that does that
* Basically, it's the dist method again andwe get the distance from the current mouse positionto the center of the record
* And if that's less thanthe width of the record player, then we basically say it's a hit andwe play back the sound
* Now there's two of these methods,one for each record deck, and that means that we can independently knowwhether the user has touched one record or the other andplay back the appropriate sound
* And it's all aboutgetting the distance and checking whether it's less than the width
* So what we're basically saying is ifthe mouseX and mouseY position are within the range of the entire graphic, thenthat means the user's pressed the record
* And we have one of these methods forboth records as I've said
* I've also got another mouse interactionwhich is a drag interaction, and this changes the speed adjustment
* So how do we synchronize the two loops
* [MUSIC] Now, they're not actually the same speed
* What they are, are two loops trimmed inthe same way that Matt was showing you
* So that they have the same number ofpauses, the same number of actual pauses, but that doesn't mean they'rethe same length in time
* They could be entirely different speeds
* So, there's an easy way ofsynchronizing these two loops together
* One loop acts as the master, andthe other acts as the slave
* If we know the length of each loop, we can synchronize the masterloop to the slave loop
* So, the speed of the second recordplayer is basically a ratio
* So if it was a one, it would be,the speed ration of one, which means the current speed
* If it's naught 0.5, it would be a speedratio of one half, so it's half the speed
* If it's two,it's a speed ratio of twice the speed
* Now if we get the length ofthe second player in milliseconds and we divide it by the length ofthe first player in milliseconds
* So we take the first loop,we get the length in milliseconds, and we divide it by the length
* Sorry, we get the second loop, we get thelength of the second loop in milliseconds, and we divide it bythe length of the first loop
* Then that gives us a ratio, which tells us how fast the secondrecord player should go
* And that's what this is doing here
* player2.speed is player2.getLengthMsdivided by player1.getLengthMs
* And that gives us our actual speed ratio
* So player2's speed is foundby dividing it's length by the length of the master loop
* And in this case,player1 is the master loop
* But as I've already described, we can change the speed usingthe speedAdjust variable
* And basically, the mouse and touchinteraction changes the multiplier, and you can see there's a bit ofcode here that handles that
* player1.speed is always going to beequal to the same speed adjustment
* So if I've got my mouse over here,that's the master loop and that's the speed for it
* [MUSIC] Player2's speed is as I've just described,it's the length of player2 divided by the length of player1multiplied by the speed adjustment
* And then the current frame, which is theframe of the video, is current frame plus one times the speed adjustment and that'swhat gives us this nice interaction
* [MUSIC] So they're both really fast andthen they're both really slow and the video stays in synch
* [MUSIC] I think I like it whenit's like this the best
* [MUSIC] Out of time and really slow
* [MUSIC]


--- SKIP ---: 12_2-6-outro.en.srt


--- SKIP ---: 12_2-6-outro.en_SENTbySENT.rtf


--- PROCESSING FILE --- 12_2-6-outro.en_SENTbySENT.txt
* [SOUND]
* [MUSIC]
* Well, that's the end of week two
* and I hope that was interesting, and useful
* A bit more complicated than last week, don't you think
*  >> Yeah, for sure
* so we're really trying to combine these different elements, and, and work with a lot of different data here
* So you, so you figured out how to work with sequences, and images, and how to play two sounds at the same time
* >> Mm
*  >> So you're really making, these, these applications more complex
* And also I hope a lot more fun to, to interact with
* So what can you do
* I'll put these apps in, in your friend's hands and get them to play with them
* >> Whacka, whacka
* Yeah, yeah, and maybe make some YouTube videos and stuff
* That's always fun
* make a video with some terrible techno o VJ behavior
* What about, yeah maybe try to play more than one sound at once, as well
* [CROSSTALK]
*  >> Work with images
* >> Yeah
*  >> Work with images because, ye, well now you've got images in there, you've got a much richer visual feel, much more varied than you can
*  >> Mm
* >> I mean, the Drawing command's impressing and really powerful, but once you've got images, there's the, it's the richness of the real world that you can bring into it
*  >> And you can get loads of images, can't you
*  >> Yeah
* >> Off stuff like the internet archive, and things like that
* And again you should use the forums if you want, if you got any questions
* We have our students on there
* Students who are on degree programs in creative computing, students who, you know, doing various kind of ghost less type stuff, you know, very creative, very energetic, good engineers as well, good programmers
*  >> Technically they know their stuff
* >> Yeah
*  >> Also they've got lots of experience in audio visual work so they, they know, a lot about exact kind of things
* >> We're doing this course
*  >> That's right, so if you get and, if you get stuck, post some questions, and if anything gets really tough field to us to and we'll be there as well
* So we'll see you next week for week three where we'll be making audio visualizations
* So, stuff to make your music players look better
* So, I'll see you then
* [MUSIC] [MUSIC]


--- SKIP ---: 01_additional-lecture-arrays.en.srt


--- SKIP ---: 01_additional-lecture-arrays.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_additional-lecture-arrays.en_SENTbySENT.txt
* This week's additional programming lecture is on arrays
* So last week we talked about variables
* And I talked about how a variable is a place in memory or a box in memory where you can put some data
* and that's obviously very useful for storing most types of data, and being able to access it via name
* But it's really suitable only for one particular item of data, a single number, a single image
* Now part of the benefit of using a computer, is that you can compute lots and lots of data
* and we'll see in this week's lecture, how we can use lots and lots of images to create an animation
* But to do that you need, a way of storing all of those images in a convenient way, and not having a hundred variables, if you have a hundred images in one dimension
* And, that is where you have we use something called an array
* Now an array variable is created very much like any other variable, except you have these two little square brackets
* makes it look a little like a box, but I'll come to exactly what those mean in a minute
* But we just put between the type of the variable, int, and the variable name plus X
* We put these square brackets in that, it tells us that it's an array variable, which is to, stor, study, storing one int, can store many integers
* And if we see down here at the bottom in memory, rather than a single box, it's a lot of boxes, each with their own value of memory and number
* And you can access with a single name, posX with this, all of those boxes together
* It's a single variable, we can have lots of different bits of data
* So how do you access an individual item of data
* You access it with a number, and you use these square brackets, this is where the square brackets come in
* There the way you get access to a particular item of the array, and inside the square brackets, you put a number
* So each of those boxes has a number, and this is the way you get box number three, and you would get an item out that
* one thing to note, very importantly, is that it starts at 0, so the first element in an array is element 0
* you would naturally think it's element 1
* It is not, it's 0
* And that will influence how you do everything right
* It's very important to be clear on that
* And that means if you've got a number element with 10 elements in and an array with 10 elements in, the first element is on 0, and the last one is over 9, it is not over 10, because it starts with 0
* It can be a little bit confusing
* Unfortunate, that's just the way it works, and you will get used to it very quickly
* So this is how you set an element to the array, just like you would set a variable to be, using the equals command
* You can set element 3 here, again using equals, but we have to use the square brackets to get hold of that value
* It's just like any ordin, ordinary variable
* This is how you create an array, one way of creating an array
* in the example we'll actually use a function to create an array, but we declare a new variable
* there many type of create box in memory, to do this you say the type It's a, called a floating point
* When we have the square brackets, those square brackets tell us it's not just one floating value, it's an array
* Give it a name, like any other variable
* And then you create an array
* And this is, these curly brackets and a list of numbers
* That gives you an array
* But we'll see in the actual example, we'll do a different, use a different mechanism, and next week we'll use yet another mechanism
* but, but here is an example of creating a very simple array, and then you can use element zero
* And you can use this syntax with the square brackets, the name of the array, square brackets and number, to get any element
* And once you've got that element, you can use it in any way you'd use any other variable, by any way you'd use a number
* So it can just print it out, or you can use it as inputs to do any command you like
* So you could do translate vals at zero, rotate, wrecked, any of these commands that you're familiar with
* So we can use rectval zero, we could use fill vals zero, any of the commands you're used to
* Wherever you would use a normal variable, you could use an array variable, plus squared brackets and a number
* And that would just give you a number value, like any other value
* Very simple, and we'll in the main example how you can use them with images, to create an animation.


--- SKIP ---: 02_additional-lecture-conditionals.en.srt


--- SKIP ---: 02_additional-lecture-conditionals.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_additional-lecture-conditionals.en_SENTbySENT.txt
* This lecture I'll talk about conditionals
* which statements, which of the mechanisms we use in programs to make decisions
* So, up to now, our programs have been responding to use an input in various ways, but always kind of doing the same thing
* Sometimes we want to do different things, depending on whether the user does different stuff, or different conditions happen in our program
* So, we want to do a different thing when the mouse button is down from when it's up
* we've seen some ways of doing that for the mouse button being up and down
* We used the dragging mouse, mouse dragging method
* And we'll look at a very general way for making that kind of decision in programming
* So let's look at an example
* So this is a very simple program that does roughly what we've done before
* it draws points at the mouse position
* This is not very different from the programs we've looked at last week except for
* This draw method
* Rather than doing it in mouse drags, so when the mouse was moved, we're doing it in draw, and that means it's happening every front
* that's a useful thing
* We'll talk about it this week in terms of doing animations, where rather than simply responding to input from the user, we're
* We're proactively animating the stuff
* We need to do, do drawing actions and do animation actions constantly
* Not just when there's user input
* That's why [INAUDIBLE] So what's happening is every frame we're drawing a point and, for the moment this doesn't get us very much but uh, [UNKNOWN] But we'll see there are other things we can do and draw in todays lecture
* But in particular I'd like to look at copying the kind of functionality we had with mouse dragged using this draw method
* Now the main difference here is that when we use mouse dragged it would only work when the mouse is down, now it's working when the, both when the mouse is up and when it's down
* If we do it this way, how would we go about, only drawing the point, when the mouse is pressed
* So, we need to only draw the point, if the mouse is pressed
* We need to make that decision, if the mouse is pressed, draw a point
* If not, don't draw it
* And the way we do that is use a method called an if statement
* So we say, if mouse is pressed
* Draw a point [INAUDIBLE] this
* If I drag the mouse pointer around The window, without the mouse pressed does nothing, the minute I press the mouse we start drawing
* So that's really nice
* Now, I'm going to go back my slides to explain that
* So this is roughly what we saw, I'm using an elipse rather than mouse points but Pretty much is the same code of what if
* and something inside the if, which is mousePressed, it's a variable
* and this is a variable which takes on two values, it's either true, or it's false
* I'll come back to that in more detail
* And then, depending on whether it's true or false it does different things
* So what that if does is if, the thing inside the brackets, the variable inside the brackets, in this case mousePressed is true, then we do that line that comes after it
* Good
* We draw the, we draw the ellipse to the point
* And then we carry on and do the rest of the program
* If this thing inside the brackets is false, is not true - mousePressed is not true, so the mouse isn't pressed (no period) We don't do the line after each statement we just carry on straight ahead
* So this if allows us to make a decision based on whether something is true or false
* Wherever in this case, when the mouse is pressed or not, we do different things
* If the mouse is pressed, we draw the ellipse
* If it isn't pressed, don't
* We can do more complicated things
* So the first thing is, well what if I want to do something special when the mouse isn't pressed
* This is another example
* If the mouse is pressed, if mousePressed is true, we draw a white background
* Then we do whatever else we want
* But in this case, we've also got something different
* We've got, as long as the if, we've got this thing, else
* What this means what happens when the if bit isn't true
* So when mousePressed is false
* We do this other line, background zero, we do the bit that's attached to else
* So we have an else, if which happens when it's true and and else which happens when it's false
* We draw the background and then we carry on and do the rest of the [UNKNOWN]
* Note that I've indented the two bits Of code that controlled by the if and the else
* That's not necessary, it's not a, a crucial part of the program
* The program won't complain if you don't do that
* But it makes it a lot clearer to understand your code if every time you do an if, you indent it a bit
* And that's just telling you
* O so you better move it in a bit
* And that tells you that this bit is controlled by the if statement
* So this bit, is part of the code that's controlled by the if statement
* Another thing you can do, is you can have multiple commands from a single if statement
* By combining them in these special curly brackets
* You saw those curly brackets before, at the start and end of setup and draw, and mousePressed this is another instance
* And they're really, curly brackets are always used to glue bits of code together
* So that they can be used as if they were a single line of code instead of context
* In this context, they're grouping them together, so they're all controlled by the mousePressed, and in this context, your, or both these lines of code will only happen if mousePressed is true
* [NOISE] So let's look
* What is mousePressed
* Well, I've shown you the slide a number of times now
* There's lots of different types of data that could be, you know represents on the computer
* mousePressed is a variable that can only take on two values, true and false
* It's what we call a Boolean variable
* It's named after the magician George Bool, who developed a system of mathematical logic based on values true and false
* We can create a Boolean variable just like any other variable
* We give it a title, we need to give the title to the variable
* That is Boolean
* And when we set a value, we have to set it either to false or to true
* So if we want to, can have a variable which says whether the, background is black, we can set that to true or false
* We can change the value of that variable just like any other variable and this is like a clever trick to do that
* The exclamation mark means not
* What that means is it means the opposite
* So not black is the opposite of black
* So if black is true, not black is false
* Black is false, not black is true
* So it inverts it
* And by setting black equals not black, we switch it to its opposite
* So it's like, just like a little switch, light switch If we, if black is true and we hit not black, black equals not black then becomes false
* If it is false, it becomes true
* This is very useful because we can for example when we click, we can have put a line of code like this in mouse clicks
* And, as we as we turn that varlible, variable on and off, whenever it's, mouse is clicked we can switch the value of one of our variables
* And maybe we can see that as an example
* So, let's first give an exam, a different example of using the example I gave with the else, [UNKNOWN] background
* [SOUND] Just going to swap things round
* So now we're using both an if bit and an else bit
* So that something different will happen in either case if the mouse is pressed
* Or the mouse is, to code the in background
* And I'm not holding the mouse button down
* And the background is white
* The minute I do it turns black
* Okay, let's try creating our own reading variable
* Our own version of mousePressed
* And we can make that bo, be created boolean variable
* Give, give it type boolean
* Set it, call it black
* And set it initially to false
* [NOISE] And we can use the variable black in this if statement and, and, when you run the program, it's not going to do anything in interesting because black is always false, you can't change it
* So let's change it when we click the mouse
* [NOISE] So you put it in the mousePressed, and we did, black equals not black, exactly what I showed you
* And every time I click the mouse The value of our black Boolean variable switches, and the color of this, the window changes
* Now, we can do other useful things
* We don't just have to use Boolean variables
* what's happening here
* Well, this is what's called a Boolean expression
* So we, we can use expressions as well as variables, and a boolean expression is a bit of maths that is a literal false
* This boolean expression is checking the value of a key
* Has been pressed on keyboard
* What it's saying, if this key expression is equal to the character bits so I'll press the B key
* Now you notice I'm using two equal signs
* That's because a single equal sign as we saw last week, means becomes equal to
* So, we're setting the value of the variable
* Two equals signs, we're not setting the value of the variable key doesn't become b, we're checking if it is b
* We're, we're checking the value of a variable
* So, we have to remember the difference between these two equals signs, and that's an common thing to trip up on
* It's easy to forget when there's single equals and when there's double equals
* If you're using inside an if statement, you should always be using a double equals
* just to let you know, just, the single quotation marks means I'm working with a single character
* Double quotes means I'm working with words and not strings of characters
* [SOUND] So we've got a bunch of specials, we've seen a double equals and that's our first boolean expression
* So if we have two values, a variable or a value, we can check if they are equal to each other And that's true if they're the same, false if otherwise
* We can also test out things like we can test whether one value is less than another value
* So this little arrow here is true if the thing on the left of it is less than the thing on the right of it
* You've got a variant of that called less than or equals
* The straight less than is false if the two are the same
* Less than or equals is true if they're the same, and if they're, if the thing on the left is less than the thing on the right
* Same goes for the greater than, the thing on the left is more than the thing on the right, or more than or equal to it
* We've already seen not, that means the opposite of a Boolean value, and we also have not equal to, so we can check if something is worth checking they are the same, we can check if they are different
* [NOISE] So we can think of, look at some more complicated examples
* For example, what if we want the position of the mouse to change the background color
* And this is a boolean expression which checks if the mouse position Is less than half the width of the screen, so the mouse position is less than the middle of the screen the mouse x, so the mouse is on the left of the screen
* So if we look here we have mouse position there, where the red circle is
* Well, mouse x is going to be less than half the width
* That's going to be true
* You're going to draw the background in black
* If the mouse pointer is there on, where the other circle is
* Mouse actually is going to be more than the width of the screen
* So it's going to hit the else part
* Which is going to About them once
* We can even combine these things
* So we can have an if statement inside an if statement
* So we can check if the mouseX is less than the width divided by 2 and inside that, we can check even further down, divide this screen up again check this
* More than the width divided by 4
* So we can create a little line down the middle of the screen
* So, if we look at the red point there, that's less than half the width
* That's true
* It's more than a quarter of the width
* So that's true
* So we draw the background in black
* Put a point there
* Then it's still less than half, half the width but it's more than a quarter of the width
* So it's less than a quarter of the width
* So that the second if statement is false
* And we can engage down to this else bit
* Which is the else bit that the e no if statement
* The secondary statement
* [UNKNOWN] in white
* The point's all the way over there
* The first if statement is false
* We never get to the second if statement because the second if statement is inside the first one
* We just get to the else part of the if statement and it draws the screen white
* [SOUND] We can also combine together boolean expressions in other ways
* So if you have two boolean expressions A, A and B, we can combine them together with this double ampersand here which says If A, both A and B are true, so both of these things are true, do something
* Or we could do it the other way around and do these two lines, which say if A is true or B is true, or both are true, so only one of them have to be true and [INAUDIBLE]
* Together
* Let's have a look at this example
* This is a, an easier way of writing what I've just done
* Doing this line
* So what that double-edge statement I showed you a couple of slides back did, was check basically if the mouseX is on the left or the middle of the screen And on the right is a line that's a quarter of the way across the screen
* Instead of doing 2 if statements, we can use an and
* Which checks, this expression
* If this point it's true
* Checks that expression, which is also true
* For the total expression here both of them have to be true 'cause I'm using that double and, what we call and, and because they're both true we do the true part of the if statements
* If we move here, the first part is still true, but the second part is false
* They're not both true so we'll move down to the else part
* Assuming over there they're both false, neither of them are true, use the else
* Now if we change from and to or we have a different effect, so we're looking this time if MouseX is more than the width over two or less than width divided by four, so we're doing kind of the opposite
* We're looking at, you know, the side of that little bar down the middle of the screen
* So if we look at this one here, it's not more than the width divided by two, but it is less than width divided by four
* So that's true
* So one of them is true, so only one of those needs to be true to, for the whole all statement to be true, if we're using all
* So we do the true part of the if statement
* If we look there, well, mouse x greater than width is still false, it's still not true
* And this time, but it's no longer less than width divided by 4, so that part's also false
* They're both false, so we get the else
* If you look over here, well, mouseX is more than width, that's true
* The other part is not true, it's still false
* So we've, but one of them is still true, so we go to the if path, because we use them all
* So, that's the end of my lecture on conditionals, if statements and we'll be using some examples of if statements in the main lectures
* Thank you very much.


--- SKIP ---: 01_3-introduction.en.srt


--- SKIP ---: 01_3-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-introduction.en_SENTbySENT.txt
* [SOUND]
* Hello and welcome to week 3 of creative programming for digital media and mobile apps
* This week we're going to be looking at audio visualization
* So that means algorithmic drawing in comptuer graphics
* So ways of making abstract shapes
* More complex shapes with translations and rotations and different kinds of geometry
* And audio analysis
* So, what that really means is, understanding what's being played back in a sound and turning it into numbers which are useful for changing the way that something's drawn
* So, there's quite a big chunk of graphics to do with translation, and rotation, and transformations, and there's a nice chunk of analysis
* If you're interested in audio, and you have a background in audio, I think there's a lot of good stuff for you there
* but then I'll be doing a kind of putting it together bit at the end
* Stuff I always do
* just literally showing you how we combine analysis and combine graphics to make something which you might find alongside something like, I don't know, iTunes or the Xbox audio player
* So, there's a market for visualizers but there's a market for the techniques of visualization
* It's not just about making something that works with I tunes although there's a lot of money to be made in that market
* It's also about how to how to analyze audio and there's an increasing amount of applications that really need to do that including stuff like shazam which is a really useful application
* So, we're going to start to be thinking about all these things and how to put them together
* [MUSIC]


--- SKIP ---: 04_3-1-transforms-part-1.en.srt


--- SKIP ---: 04_3-1-transforms-part-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_3-1-transforms-part-1.en_SENTbySENT.txt
* [MUSIC]
* Today we're going to talk a bit more about moving things around in graphics
* So in the first week we talked about how to draw stuff and there we could position objects and then like rectangles, by giving the pixel positions.And for example the white command and the ellipse command
* And, and that's fine, we can do that
* And last week we talked about doing animation, but animation with image sequences where we're playing lots of different images all in the same position
* Today I'm going to talk about more powerful ways of moving objects around beyond what you can do simply by putting positions into the x y coordinates to say say, a rectangle
* These techniques accord transforms, and there are three of them
* The first transform is translate, which is a basic movement
* Not too different from what you could do by putting an X-Y position into, the position of a rectangle, so
* And that is a command for translate and you pass in an x and a y which is the position you're moving whatever object too and it's a separate command to whatever command drawing you're doing this
* So you can apply single translate to multiple objects
* And group objects together and move them around and I'll talk a little bit more in detail about how you do that
* And the basic premise to translate an x and a y which gives you the position for which you'll translate
* So very similar to what we've done before
* The second one is a scale that's getting things bigger and smaller and that just basically takes a number That is how much of scaling apply
* If that number's one you're not scaling it at all
* If it's less than one it's getting smaller
* If it's more than one it's getting bigger
* One quite useful thing about scale is you can also give it two parameters which means you can scale separately about the x and the y
* So, you can make something wider While making it sort of the same time, having high x scale and a small y scale
* So the rotate command is used to spin objects around
* And it takes an angle as its parameter
* So that's how much you want to spin it by
* the normal way we talk about angles is in degrees 0, 360 degrees
* But in computer programming we often work with another way of dealing with angles called radians
* Now the units we shall explain in a minute and you have to pass in that value and radiance through a take command
* If you don't want to get involved in radians, there's a very simple command radians, that takes an angle in degrees and converts it to radians
* So I can just put radians 90 degrees, and it will do it all for me
* But if you want to know what radians are, this is it
* So radians work in terms of a circle
* And we can think of an angle as cutting out a chunk of a circle
* So, like a, a, a slice of the pie
* now, if we make the circle of radius one
* So, each of these two straight edges is linked one
* Then we can measure the angle by taking the length of the arc, along the way just to be certain, so that's how much of the edge of the circle is being cut out by my angle
* And that is a perfectly good measure of, of, of angles, and that's what's called radians
* A few things you need to know
* it's useful to know particular angles in radians, if you ever use them
* The, 360 degrees is the entire circumference of the circle, and if you remember from school maths And the circumference of a circle is two pi times the radius
* Because the radius is 1, the arc length of 360 degrees is two pi
* 180 degrees is half that, pi
* And 90 degrees is pi divided by two
* So that, that's a useful way
* Thinking about, angles, you can use, put values in terms of pi directly into the rotate command
* But if you're not, if you don't want to get involved in that, you can also the radians command I just showed you to convert that to degrees
* So what are transforms doing
* I said
* That transforms can apply to multiple objects and they're independent of the objects
* But how does a transform know to actually move an object, if it's a separate command from do, doing so, drawing a rectangle or an ellipse
* Well what a transform does is in a way not move just the object, but move the entire coordinate system
* Sort of
* The, the screen
* What does that mean
* Well I taught, told you a couple weeks ago about how we can represent any point on screen by an x and a y
* How we do that is that we need to know which direction is x and which direction is y and that's normally horizontal and vertical
* We can change that
* But also, we need a starting point, we need to know where 0, X and 0 Y are and normally, that is top left of the screen
* But what a translation does, is move that, so that anything after the translate
* The zero-zero point
* If I do Translate 20,100, I move my zero-zero point to 20,100
* So, if I draw an ellipse at point say, 20,30, if I've done a transform on that, Then that's 20, 30, relative to the new zero, zero points
* So if I've transformed my 20 100s, it's 20, 30 relative to 20, 100
* Which is 20 plus 20, 40, 100 plus 30, 130, relative
* To the top left of the screen
* So I'm drawing, changing the way you draw everything
* It changes the meaning of the numbers you're putting into your rect command and direct command .And what that means is that if you draw both an ellipse and a rectangle they're both affect the same way
* So you can draw as many shapes as you like
* You can draw really complicated drawings, and then put a translate in front of it, and they'll all move together
* Exactly the same thing with scale, but this time, rather than changing the 0,0 point, you're changing how much one unit of x or one unit of y means, so If you scale up by two, each one unit you leave in x counts for double
* So each time you move one in x, you're moving two in the original screen used
* And finally the rotation, what that does is it actually What takes the x and y axis
* So, it changes the direction of x and the direction of y
* So, they're pointing in different directions
* So, if I've done this translation you're seeing on, rotation you're seeing on the screen then when I move across an x I'm no longer moving Just horizontal and moving diagonal down the screen
* So these transforms are very powerful because they give you new ways of deforming and changing shapes
* But also because they can apply universally to multiple shapes
*  [MUSIC]
* [MUSIC]


--- SKIP ---: 06_3-1-transforms-part-2.en.srt


--- SKIP ---: 06_3-1-transforms-part-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_3-1-transforms-part-2.en_SENTbySENT.txt
* [SOUND]
* So transforms are great because
* And in fact everything if we do a transloate it will move everything we draw after but what if we do one translate after another like this
* Well the most obvious thing that happens is that we move and move again
* But what exactly is happening there
* When we call the translate command
* Everything after the call back command is affected by the translate including any other translates we do
* So, if we look at the second the second translate that's a movement of any object that have
* But that is also affected by the first translate, the first translate and its, and its mean to the first translate will happen to the second translate and the starting point is 0 by 0 point of the second translate will be affected that of the first translate
* So
* What happens is that you, the effect of the fir, of the first translator is applied to the second translator
* Which, kind of feels more naturally like saying that well The second translate is actually happening first
* Instead of happening to the object, and then it's going to be translated by the, by the [UNKNOWN] first translate
* We often think of translates, transforms happening in the opposite order
* So what happens if we do a translate followed by a rotate
* Well, the rotate spins around, that's fine
* But if we've got a translate happening before that rotates
* Then we're going to have a movement applies to the 0, o point of our rotate
* So the 0-0 point of the rotate is going to be moved
* in much the same way as we just saw with the 2 translates
* They're applying one after the other
* And it's kind of like they're playing backwards
* But what if we do it the other way around
* Well, we put a translate and movement
* And then put a rotate applies to the zero zero point of that translate
* What happens is that the zero zero of the translate
* Is rotated relatively to the 0 0 point of the screen
* So actually we're it's like, I'm taking an object arms length and translate it and then I spin it around
* So it's spinning from the starting point of the translate
* Not through the center of the object
* So doing those two transforms in different orders has a radically different effect
* If I or for example this bottle of water, if I apply the translate first rotate second which basically means the other way around
* I would take and I would translate Well, I would take something and then I translate
* I move out
* But if I do it the other way around, then I translate first and then I rotate
* And I'm making, the rotate isn't just a simply spinning around the center of the object
* It's actually a big movement in space
* So the first thing to remember is that you kind of think of them in the opposite order if you have to think about transforms it makes more sense to think they're happening backwards but the other thing to think about is is well, what if I want to move 2 objects
* Well, if you want to move them together, that's easy, we can translate
* But what if you got to move them separately
* very often you'll have two objects, the same two cars, two crates, whatever and you just want, want to move one [UNKNOWN] to move the other
* If I'm applying a translate
* Then, everything that happens after that translation is going to be affected by it
* So I translate the first object the circle here then the square is also going to get affect but if I want to move it independeantly
* Well we use a command a called push matrix and pop matrix I won't go into the mathematical details, but transforms are implemented using a bit of maths called a matrix And when it call upon the pushMatrix, we're basically creating a new matrix that we're adding all our new transforms to
* When we call popMatrix, any transforms that we've added since we added push, pushMatrix
* [INAUDIBLE] will get canceled, because we're removing that matrix
* So push matrix and pop matrix are a way of limiting the effect of transforms
* Any, in fact, transforms that happen after push matrix will automatically be removed, once you call pop matrix
* that [INAUDIBLE] gives you a nice way
* Of independently moving objects
* You pushmatrix, you do whatever transforms you like, you draw the object and then you pop matrix
* Then the next object, you do exactly the same thing, pushmatrix, transform it, draw it and then pop matrix
* [MUSIC] [MUSIC]


--- SKIP ---: 08_3-2-trigonometry.en.srt


--- SKIP ---: 10_3-3-accessing-accelerometer-data.en.srt


--- SKIP ---: 10_3-3-accessing-accelerometer-data.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_3-3-accessing-accelerometer-data.en_SENTbySENT.txt
* [SOUND]
* Hello
* In this lesson I'm going to teach you how to access accelerometer data from your mobile device
* most mobile devices have an accelerometer in which essentially it allows you to figure out what angle the device is being held at
* And of course, we're going to use this for creative purposes, to control sound and visualization
* The accelerometer will give you three values which relate to the various angles from the phone, so it can be twisted like this or like this, or like this
* So lets have a look at those
* So, here's some code which will, will create an accelerometer and print out some data from it
* So, let's run this on the phone, and see what comes out
* First of all, I'm going to type it in, so we need at the top, we create a global variable
* And the type of the variable is accelerometer
* And this is a built-in class for those of you who've done a bit more programming
* Which comes with our audio and graphics API
* Let's call, I'm going to call it XL
* So in set-up
* As usually we create teh variable XY equals new acceleromter
* Okay so that's
* What we're going to do and now I can quere that accel to now get some information
* So lets just for example print out the X value
* Okay so I has an X Y and Z value
* Well we put them all out actually and we'll do X is Y is, and Z is
* Okay
* And I just need to edit this
* So that is getX, getY, and getZ
* So I've got 3 lines in my draw method there
* So every time draw gets called it's going to ask the accelerometer, what is your current X position
* What's your current Y position
* What's your current Z position
* Okay, so let's run that on the device, and we're going to just look at the console to see the numbers that are coming out
* Right, there are the numbers coming out of the device
* That's telling me the current position of the device
* Now if I pick it up
* And start moving it around
* You can see depending on which angle I'm changing at different numbers are produced
* And basically the range is from minus ten through to ten
* So when you're at the most extreme angle the numbers will go up to ten
* And, when you're at the opposite extreme they'll get a minus ten
* So the values that come out from the accelerator are in the range minus ten to ten depending on the different angles you're holding the phone at
* So how can we use this creatively
* Well, first of all let's just see if we can use it to set the color of the background
* So we're going to do this
* So we'll create some variables, which are going to be our red, green and blue
* And we can set the red value using the accelerometer data
* And then the green, and blue
* Right
* But remember, these values are in the range minus 10 to 10
* And the range, the range that we need for, colors is 0 to 255
* So well done if you've spotted that already now what can I do here so to get into the range 0 to 255 so I add 10
* Okay that puts it in the range 0 to 20
* And then, I can just
* Do an approximation here and just times it by 10
* So it goes up to 0 to 200
* Okay
* That's near enough
* You can calculate that accurately by dividing 10 by 255 by 10
* sorry, 255 by 20
* so we could do that
* We could do 255 by 20 to do it really accurately
* [SOUND]
* Okay
* So let's do that with the other ones as well
* [SOUND]
* Right
* And then, now this, remember that these that come out are things like 0.15 or -9.3 which are floating point numbers
* But I've declared my RGB's as integers
* So what I need to do is then cast it, convert it to an integer before I can use it
* Finally, I'm going to set my background color using these values R, G, B
* Okay so, we've used the accelerometer data to set up some red green and blue value and then we're going to use that to set up the background color so lets hit play
* And see what happens to the background color of the screen as we move the device around
* [SOUND]
* Okay
* So we pick up the device
* And as I move it around, you can see the background color changes
* Now it, it seems to be changing kind of slowly, so it kind of jumps from one color to the next
* That's because the accelerometer data updates quite slowly
* So remember, for example, the audio, what we did with audio data, that updates very fast
* so you know, that's very smooth and very rapid, but it's, other types of data are slower
* So, for example, the frame rate in processing, which is the number of times a second it cause a draw function is, is, the default is 60
* Whereas the number of samples a second is 44,100 when you're dealing with audio
* So there's all these different rates of, of data flow
* So what we're dealing with is a flow of data from a sensor in the phone which is coming in at certain rate
* that's not very high rate in this case
* Okay so that, that's dealing with accelerometer data and sending it to the background color
* In the next section, I'm going to talk about how we can map that accelerometer data to a playback control
* So there's a line here which if you're quick you're going to
* Pause the video and quickly go and type it in, see what it does
* So lets just lets just put the extra code we need to be able to do this line here
* OK
* So back to here
* So now I need to create an audio player and I want to control the speed with the accelorometer
* So I can twist the phone around and it will slow down and speed up the, the playback of the audio
* So we do the usual thing, create the maxim variable, create an Audio Player variable, and then initialize it, maxim equals new, maxim
* This should be familiar by now
* Oops
* And audio so player equals maxim.loadFile, and the name of the file
* So, I'm going to use the, the beat we've been using
* Okay, so thats the player
* So in the draw method, we just make sure the player is playing
* In fact we can
* So we do player play
* If the player is already playing we would just ignore that
* Just make sure its playing
* then, what we're going to do is say, player, and set the speed
* Now, let's, let's do a calculation here
* We're going to do this as a float, because remember speed so if we pass in a speed of two, then it will playback the audio twice as fast, so its going to skip through all those samples twice as quickly
* If we, if we set the speed to one it will play back at the normal speed so it will sound as it was originally recorded
* now, so, the kind of, an interesting range for speed, as we've seen with the DJVJ
* It might be zero through to two
* So we need to get that accelerometer data, and scale it to the range, zero to two
* Just an organizational note, that I've just placed these variables from the middle of the code up to the top of the method
* Now, everyone has their own way of doing things when it comes to programming
* There's many ways to, to program and to organize your code
* For me, I quite like to put my variables at the top of the method so that it's really clear
* All of the variables I'm going to use in that method
* its a, its a neater way to do it in my mind
* So, so I've just placed those at the top there
* Now, the speed
* Remember, I said an interesting range for the speed was, say, zero to two
* So what we're going to do is take that accelerometer data like, this, okay
* And we're going to scale it to the range, zero to two
* So we're going to do add ten
* So that puts it in the range zero to 20 again
* And then we can just divide it by 10 and that will put it in the range 0 to 2
* So then we use that set the speed
* So lets see how that goes
* I'm using X so that's me twisting the phone like this
* So hopefully what this is going to do is is if you like replace what we did last week which is the having to touch the screen to change the speed now we can actually just move the phone to change the speed
* So it becomes maybe a more embodied experience
* More like a real instrument where you move around and it changes the sound
* So lets lets run that
* [MUSIC] Okay so I pick the phone up and you can hear the speed's already changing now if I tip it that way, [SOUND] you can see it's
* >> [MUSIC] It's now going really fast
* And I'll twist it back around
* I can take it to a stop
* So let's just try and play with that a bit
* [SOUND] So, you can see it becomes a really fun thing to do and, and once you, if you got a few sounds going, you can start really jerking the phone around and getting quite creative with the way you perform with that thing
* So it becomes like a rather than it being, if you like
* An interface that you tap on becomes an instrument that you can, you can really try to perform with
* I would recommend that you try some different sounds in there
* Try just record tones, try recording anything really and sticking in there and see if you can map different properties of the sound to the tellurometer data there
* [MUSIC]


--- SKIP ---: 12_3-4-audio-analysis.en.srt


--- SKIP ---: 12_3-4-audio-analysis.en_SENTbySENT.rtf


--- PROCESSING FILE --- 12_3-4-audio-analysis.en_SENTbySENT.txt
* [SOUND]
* In the next section I am going to talk about how to use audio in analysis to get some information about the sound that's currently playing
* Now, you can see in this code here, that I've got a player and I'm telling the player to do, to start analyzing by calling the set analysis
* Set analyzing method and setting it to true
* What that will do is that will cause the player to, to begin, not just playing back, but also listening to itself playing and doing some analysis on there
* But the type of analysis we're going to do, is, is called extracting in the, spectrum
* So we're going to extract from the power spectrum of the sound
* Now what does that mean
* Well, the basic idea is that when you listen to a sound, there are different components in that sound
* For example, if you listen to very heavy, bass-y music like Reggae or something like that
* There's a lot of really low frequency sound in there, a lot of bass
* So maybe bass is a more familiar term than low frequency, right
* So if we talk about base that's in the low frequencies we can also talk about treble which is what makes a sound bright and treble the opposite end to bass in the description of the sound
* So we talk about treble and midrange is more, things, so speech happens a lot in, in the mid-range and hmm, but it has lot of trouble bits as well
* For example, if I go [SOUND] that's a lot of, there is a lot of trouble in that
* Okay, so the idea is that with this analysis we can actually get some information about what, how much basis in that, how much trouble is in there and so on and also we know what is the average, of, of the level of the sound
* And as I said the method we said to do this is the fast Fourier transform, the FFT
* And we can get the data out of that and turn it into what we call a power spectrum, which really is just telling us how much power this is in those different frequency bands
* So is there, how much bass is there, but not just how much bass and how much different bands of bass so low bass and medium bass
* Okay
* And so what we're going to do first is just take an average of all of those difference frequencies
* And see if we can use that to, plot a signal meter, which will show us what's going on in the sound currently
* So you can see here, I'm pulling out this float called Pow, which is the average power in, in the spectrum
* So that's looking at all of those bands, bass, treble, mid, and taking an average of all that
* And then I'm going to set a color using that, and following that I'm going to draw a rectangle where the size is set by the, by the power as well
* So let's just code that up and see what it looks like
* So I'm going to have to first deactivate a bit of this accelerometer code
* So I'm going to add another float up here
* Float power okay
* Remember I have to say player.set analyzing so apologies if you're used to American English spelling, and you're used to S's instead of zed zeds instead of S's
* But for obvious reasons, we're using Ss
* okay now
* So that will tell it to start doing that analysis
* So extracting that, that, that spectrum
* So that I can then ask for it later
* So, let's do that
* We'll leave this speed and in fact I'm going to delete all of that code, okay
* So, lets pull out the power
* Power equal player get average power
* Okay, that's what I need to do to pull out the average power
* The player calculates it all for me and then I'm going to set a fill color using that
* So I'm going to use the red now and the power value actually has been set up so it comes in the range zero to one
* Which makes it a little bit easier to deal with in the accelorameter data we looked at
* So its in the range zero to one so I could just use it directly at that
* So that's the red component
* OK so its just going to set the red and then I'm going to draw a rectangle with a width which is set by the power
* So again, I just use it as a ratio if you like
* Power times width
* So if it's full power, the bar should go all the way across
* If it's, if it's, as it, as it gets lower, it goes less and less across
* You'll see what that does in a minute
* The basic idea is that it will be like a bouncing bar
* And height will be the complete height of the screen
* Right
* So now let's run this on the device and see what our new volume or power meter looks like
* [MUSIC] [MUSIC]
* Okay
* So, it's a bit difficult to see
* Because the red, maybe, is a little bit, dim
* So what I'm going to do
* And also, I'm not filling in the background color as I go
* Let's just fill in the background color
* because it wipes out, wipes the background
* [MUSIC] So I made a few edits to the code just to make it so that the background is set at, is, is clear every time and the power, it should be clearer now
* [MUSIC] Okay
* So that's, okay, that's a bit better
* [mmm] So there's quite a lot going on in that sound
* So it's not necessarily very clear what, what's going on from power there
* You can see when there are stronger, bursts in sound
* You can see the power bouncing
* Let's just try it with a different sound
* So you can, you can see from that there are the volume meter bounces
* The power meter bounces, but maybe we can use a better sound to illustrate it
* So we actually have this sound we created previously
* called ping, as I remember
* And so let's just run it with the ping sound
* And it might be a bit clearer what's going on
* [SOUND] Perhaps that's a bit clearer
* You can see that hmm, the parameter is bouncing every time the ping happens
* So we have covered how you can extract some information about the spectrum, but it's quite, it's quite low-resolution if you like
* It's not telling us a lot of information about what's going on
* We just looked at the average power which was looking at all the frequency bands and taking the average power, which is basic, kind of like, you know, how loud is it right now
* if you like, which allowed us to draw a volume meter
* Now, if you want to get into more detail You can actually access not just the average power, but you can look at each, individual band so you can tell how much bass there is, how much mid range there is, and how much treble there is
* So I've got some code on the next slide which just shows you the basics of how to do that
* But I'm going to do a more interesting example in the editor
* So let's just look at that code first So at the top of your code you can create a float array called spec
* Now what's a float array
* Well remember that float is just a single variable which can store a number, which is something like 1.7 or you has a has a decimal place if you like
* Its an accurate number think of it that way and float away, you can see we've got those square brackets can basically store lots of floats
* Now, that makes sense because we don't, we want to, we don't just want to store, so the average power, we want to store the power in every band
* So we need some place where we can store, lots of numbers so that's why we've got an array there
* Markers covered arrays in a previous lesson and also you can look in his additional programming lectures to find out more
* Now in the code below so we asked the player, we're assuming you've got a player created and we ask it to do the analysis and then In a draw method, we, exp-, We, we ask for the power spectrum from the player
* Which will give us the current snapshot of whatever the power spectrum is
* And then, if we get something valid
* So we check if it's null
* So we check if we get something valid back
* and then, if we do, we iterate that spectrum using a four loop
* Again, four loops are covered in more detail in
* Markers additional programming lectures
* So we've basically stepped through every number in that spectrum and we set a fill color using that and draw a rectangle based on it
* Now as I said earlier that's a basic example I want to do a more interesting works example where what we're going to do is plot that spectrum over time
* So you can kind of see a map of these sounds you've been hearing over time
* So how we do that is like this
* So we've got an audio player and in draw method, we can play as usual
* And that will, that won't effect it, it'll only cause it to play if it's not playing already
* So it's okay to just keep calling it And, we going to try to extract the spectrum so first of all we add the float spectrum we'll expect so I can target slightly more rapidly and here we going to say if
* So spec equals
* Player get power spectrum, like that
* And if spec is not input is no so we got a valid got something plot, the we type in a for loop
* So we set a variable i to not
* I has to be smaller than spec dot link so and i plus plus so that's going to go from zero up to whatever, how many numbers there are in that spectrum we've just been given
* Okay, and what I'm going to do is I'm going plot the spectrum using differently colored dots
* So if the If that, if the power band is, is powerful, then it will do a brightly colored dot
* So I'm going to do that using the stroke, and I'm going to stroke color is 255, which if, if it's just 255 it will give us a white color, but 255 times the value of the spectrum at I, so As it goes through, it will start with the base at the, the, the top end of the spectrum
* That is, the top end of the array
* And work through the array, and get to the treble at the other end
* Okay
* And then I'm going to draw a point
* now, the x and y position, the point
* Well, the x position, I'm going to just, I'm going to use a variable actually, because what I want to do is, I want to, each time I plot this, this spectrum, I'm going to move along so that I can plot it slightly further along the next time
* Which will allow me to, if you like, draw a map of that spectrum over time
* So I'm going to create an integer called xPos
* And set it to naught, in set up so it starts at zero
* My x position is just going to be x pause, and my y position will be just i
* So, as i increases it draws, it will draw a line, it will draw these dots down the screen where each dot has a different color based on the power of that element
* So next time I'm going to draw, I want x pause to go up by four
* So it moves along by four
* And since I'm moving along four
* So imagine I'm drawing these kind of dotted lines down-screen
* I want to, I can also make my stroke weight to four
* So that the dots are drawing, also, are four pixels wide
* Okay
* So that should plot my, my sound over time across the screen
* So let's just
* Let's run that on the device now
* [SOUND] [MUSIC] Okay, so you can see it's, it's drawn, let's just stop that and I'll explain it, so you can see what it's drawn there is But looks like a kind of, a bunch of white plotting gray scale plot of some sort
* Now the top of that screen wherever the bass frequencies and the lower down the screen it gets the higher pitches so that's how that works
* And you'll notice there are if you like bands, looks like there was more going on
* And those bits were signifying when there was a bass drum playing, or a snare drum
* So that the, the, the break beat kind of has a bass, snare, bass, snare sound
* And you can see that pattern in, in the spectrum
* Now, what I want to do is just
* The problem is that x pause eventually gets higher than the width of the screen
* So it starts plotting off of the edge of the screen
* So you can't see it anymore
* So what I'll do just to make a final change is if X pos is greater than width in other words if I've moved off the edge of the screen
* So go back to the other side of the screen and wipe it ready to re draw the new spectrum okay so set X so it will move across the screen
* Drawing the spectrum and when you get to the end we go back to the beginning
* So let's run that on a device now
* We should see when it gets to the edge of the screen it, it returns to the other side and starts plotting there again
* [SOUND] So you can see the double base drum there
* Dun, dun, dun, that sound
* [MUSIC] Right
* So that's the spectrum
* So you can see it's quite dense at the top
* Quite dense
* That means there's plenty of bass going on in it
* And there's, and it sort thins out towards the top end
* So you can definitely see the bass drums having a kind of denser sound [MUSIC] so let's stop that
* Now, I encourage you try and load some different sounds into there and record yourself and load back into there and just trying plotting some different sounds and you see what's going on and also the layer in the spectrum is perhaps more interesting so, you might want to plot the first
* So 50 things in that array and just plot them across the whole screen so you can really explore what's going on in that spectrum so try some different sounds explore the spectrum have fun and if you can make something more interesting
* You can also add interactivity so that they can slow down the sound speed up and see how the spectrum changes so that's what I would advise you to go and do
* And to, to explore this topic further
*  [MUSIC]


--- SKIP ---: 14_3-5-building-audio-visualisers.en.srt


--- SKIP ---: 14_3-5-building-audio-visualisers.en_SENTbySENT.rtf


--- PROCESSING FILE --- 14_3-5-building-audio-visualisers.en_SENTbySENT.txt
* [SOUND]
* Okay, so we've had Marco explain to you about rotation and translation and other types of methods for changing the display of certain types of graphics and characteristics of graphics on the screen
* And we've had Matt explaining to you, explaining really how we analyze audio among other things
* Now what we going to do is we're going to try and combine those two things together
* We're going to do a little bit of what we call graphical synthesis to create algorithmic graphics
* And we're going to do a little bit of audio analysis and combine that to make an audio visualizer
* Audio visualizers are really popular and you find them all over the place remarkably so in pretty much every media player and every major console
* So for example in the xbox Jeff Minter's audio visualizer is the main visualizer when you see when you put a CD in
* although other visual artist like I think it's flight 404, their visualizer used for iTunes, so there is a whole range of people who just make computer graphics, abstract computer graphics
* And their work is a major part of everybody's listening experience
* the audo analysis aspect of doing audio-visualization is quite good to understand and is quite nice to know how to do some of those tricks
* I'm going to take you through basic analysis and how we use it to change graphic parameters
* And I'm also going to give you a really quick introduction to beat detection
* so let's start at the beginning
* Building an audio visualiser
* So, the first thing we need to learn is how to do algorithmic drawings
* There are so many different ways to doing this and so many different methods and different algorithms you can apply
* I'm going to teach you how to do some really simple stuff that uses rotation and translation, and we're going to start with rotation
* Now, fundamentally the key to almost all algorithmic drawing is a for loop
* And Marco will explain that to you if you're not sure what for loops are you should go back and check the programming lectures that Marco supplied for you in case you're a little rusty
* It's actually really, really easy to understand the for loop and I'm sure you'll be fine with it
* But all you really need to know is this is a method for drawing lots and lots of things in different ways on the screen
* Let me give you an example
* Here's a basic rotation sketch which we can look at
* You can see this would run fine on an iPad or an iPhone
* We've got a bunch of rectangles and they're all spinning round
* You'll notice that when they spin round, they seem to, line up at certain points
* Like just then
* Also you'll notice if you're looking, that you get four, a group of four, then a group of five, then a group of three, and then it spins out into one long arm and goes all the way around
* Now the reason this works is because every individual shape I'm drawing is spinning
* Based on its position in a system of a certain number of object
* So if I want, If I had 20 objects and I was spinning them all, and I was spinning an object in the middle, I, I would be spinning it 20 times slower than the object on the object on the edge
* And when you do that, you get this interesting symmetrical pattern
* This has been used by lots of artists over the years and it's an interesting way of getting feedback type effects that are really symmetrical
* Let's have a quick look at how it works
* So it doesn't use any trigonometry although we are going to look at some basic trig real soon
* But what we do have is a so it doesn't use any trigonometry, but what we do have is a simple rotation
* And I'm going to show you how that works
* This is the sketch
* So ther's no sine, there's no cosine, there's no tangents or stuff, and there's no pi
* We'll be looking at pi a little bit later
* Young blah etc
* But it has a similar effect, I'll just used a variable called time
* This variable is initialized at zero at the top of the sketch
* Let's have a quick look at what's going on underneath here if we go back
* So we have time and time is this value where we're incrementing bit by bit
* Every, every time that we ask the computer to draw a frame that increments
* And then what we do is we say okay, here's a for loop
* basically I want to do this 20 times times, and it uses this variable i, which is an integer, to do it 20 times
* We're going to rotate given the current time so as time progresses and as time is incremented by this value of 0.01, it's going to change the rotation
* And then what we're going to do is we're going to draw a rectangle based on its position, i, it's position in the system, whichever one it is
* And then we're also going to change the signs based on their position
* and that's what we have here and that's what gives us this spinning set of squares
* So you can see here the normal sort processing stuff size and frame rate, we set the background to white
* We translated everything to the middle of the screen so that zero and zero the 0x and 0y is right in the center
* This is useful, and for all the sketches I'm doing today, that why, that's how I'm working
* I've turned the fill of and then here's the bit we just looked at
* I'm incrementing time
* I've got 20 of these and then I'm just spinning them around
* Each one is being spun around differently based on what the time is
* And then I'm drawing it but the join functions been parameterized with the number i
* The number i represents the number in the system, so remember what I said before
* So if I'm spinning the one in the center around, I was spinning it 20 times slower than the one on the edge
* So as I count each one out rectangle here, rectangle here, rectangle here this one spins like this and this one spins like this
* So this one for every single rotation this one does this one does 20 rotations, the one on the other end
* Okay, so that's the basic idea
* Let's try something a bit more complicated
* Let's do a for loop with rotation and a bit of trigonometry
* It's a really, really simple algorithmic process
* This one, I always use, I always used this example when I'm explaining about algorithmic drawing because it's a really good algorithm to start with because it's one of the earliest computer graphics algorithms we're creating
* animations and it was used by John Whitney, Sr to produce a range of really famous abstract animated pieces
* He also used a similar technique for generating what's called Lissajous figures for doing the title sequence to Vertigo
* Which I think there's just been a, in fact the day we're recording this there's a Google doodle which gives you an indication of when we're recording this
* There's a Google doodle which celebrates the work of Saul Bass and on that there's quite a lot of stuff about John Whitney because Saul Bass went with John Whitney to do the vertigo type of sequence using exactly this algorithm
* And it's one of the earliest pieces of computer graphics that Whitney did on a computer that he built himself, in fact
* So get this to work, we need to use some trigonometry, and we need some elements
* We've got some variables and some elements
* The elements is the number of objects that we want to draw and the variables are the way we want to draw them
* And we change these all inside the loop
* So we have a variable float spacing a variable called rotation a variable called radius and a variable called magnify
* And the we have int the number of elements
* So in the for loop we say
* As many elements as we've got, we keep looping around until we've drawn them all
* That's what it says int i equals 0, i less than element i plus plus
* And then we're using pushMatrix and popMatrix, which Marco will have explained to you about already
* Now what we do is instead of rotating given our time value, we rotate given spacing, i and rotation
* So there are three numbers that we use to calculate what the current rotation's going to be
* So we have the spacing, which is the distance between all the objects
* We have i, which is the number of the object in the system
* And we have rotation, which is how much rotation there currently is, how much we're rotating into our system
* And then what we do is we're translating it as well at the same time
* So that's the main difference
* Although we're parametrizing rotate differently, we're still just rotating it
* The key thing is here we're translating at the same time
* Which means It doesn't just spin round, it goes in and out
* And we are using sine to do this which is a trigonometric function which squeezes all the, all the shapes in and out
* Now, let's have a quick look
* Basically, we're drawing an ellipse every time we do this
* I'm going to show you what that looks like
* So this is the basic rotation with sine
* Now, as always with these examples, they're accessible in week three, lesson three of the coursera documents that you should have
* and here we have it
* So this is this is the algorithm that I was just talking about
* It's useful for all sorts of things
* And, it's neat so I'll pair, I'll parametrize it with mouseX and mouseY so you can see I'm just exploring with the mouse at the moment
* you'll notice that while I'm just traveling down the diagonal, we'll always have it well it always gives us circles
* But if I move in the y dimension, it rotates and if I move in the x dimension, it translates
* And you see we get these interesting symmetries
* Let's have a, a kind of closer look at that
* I'm going to go back to here
* So how are we doing that
* Well, we're mapping the radius and the rotation, given mouseX and mouseY, exactly as I'm showing you on this slide
* So, we're going, okay
* Well, we'll take the mouseX as input
* And we presume that's from zero, which is the leftmost side of the screen, to the width of the screen
* And then we're mapping that to values between 0 and 10
* And we're doing the same for the rotation
* So, because of the way we've organized these elements to be drawn, radius and rotation are in the same range
* The other thing, the other variable which we introduced in the last slide which we're using to make this Whitney algorithm, is, spacing
* Now spacing is how far apart, as I've said, how far apart the different elements are drawn
* And this is really about how far around a circle it is
* So in this case, we're getting TWO_PI
* Now TWO_PI is basically how we measure around a circle
* So we start here zero pi and we measure around and we get to, TWO_PI
* Okay
* So Marco will have explained a little bit about pi
* We're using pi divided by elements to figure out how we get, say we have 1000 elements
* We're dividing TWO_PI by 1000
* And we're saying that's how far apart all the, all the different elements are
* So it's a bit like saying, well, you know, I've got a box which is one meter long
* And I want to get ten sandwiches in it
* So I'm going to stick each one in at a tenth of a meter, apart
* That's basically what we're doing
* Although they're not sandwiches
* There's no box
* It's just a circle and some graphics
* So radius and rotation, they're the two variables which are how far around it's going, and how far away from the center it is, and spacing is how far apart we are around the circle
* So quickly let's have a look at this
* So here they are
* We're in the draw loop
* We set the background to black
* We've mapped mouseX to ray x
* We've mapped mouseY to rotation
* We've created spacing which is TWO_PI elements
* We translated the center of the screen which is what we're doing for all these sketches
* I've explained that to you before
* We turn fill off and then what we do is we say for every element pick a color
* I'll be talking about a color in a minute
* PushMatrix just like Marco said we needed to
* Now rotate based on how far apart they're supposed to be, which element and system they are and what the rotation currently is
* And then translate but when we translating we're getting the sine of the spacing which is how far apart they are
* The i which is the number which particular element it is and the radius which is how far from the center it is
* So we get the sine of that and then we magnify it
* Now this is what creates that squeezing, cause the, what sine produces is this waveform like this
* And because we're running those values into a sine wave and then magnifying them out, then we're basically not just going around the circle, we're going through the circle as well
* As we are squeezing the radius to and from the centerfold
* And that's how it works
* Then we draw our circles
* Now, you'll see, if I show you the sketch, all the circles are the same size
* I can do some interesting things quite fast just by times-ing them by i
* Let's try again
* And you'll notice that immediately I've got a very very different sketch with, which looks a lot more interesting
* You see, I've got, I think they're far too big so I should probably change the size
* Let's just make them, I just, I'll say i times 10 instead of 20, cause they're a bit off the screen
* let's try that again
* Yeah, that's a bit more like it
* So you can see I've got a lot more control, and you get this weird sort of pseudo 3D effect
* And it's worrying as all the different circles interact, exactly like they did in the first sketch
* You get this kind of weird mesh
* Now, when I'm all the way over here, it looks a bit messy
* But really when both the values are quite near to zero, you get some quite nice effects, nice 3D effects
* Also what we can do is we can change the number of circles
* So if I change the number of elements to something a bit ridiculous, like 1,000 is a lot
* Let's try 256, just double them, I wonder if it can handle that
* Yeah, there you go, well that's 256 and you see that immediately
* It's starting to look a lot more interesting, and all we've done is taken a few of the variables and parameterized them okay
* So we're going to use this, in a bit to show you the final example
* But lets move on
* I want to talk a bit about hue and rotation and then I'm going to talk about how we organize, so we do color and then I'm going to talk about how we organize sound and beat detection
* So instead of using red, green, and blue colors like we normally do I'm using hue saturation and brightness, HSB
* Sometimes called HSV color where the V stands for Value instead of brightness
* Sometimes called HSL, where it stands for Luminance
* So basically, hue is the color tone
* Rather than having a mixture of red, green and blue, we can say, well, I want the color tone, whether it's red, blue or yellow to be one number
* And that's normally expressed between zero and 360 degrees
* And it's, it's as if it was going around a circle
* saturation is the color depth which is how strong the color is
* And brightness is self explanatory, it's how bright it is
* So bright it is if so if saturation is zero
* The color is, is either you know, is a shade of gray
* And if brightness is zero, it's black
* And you can see by this triangle, how it works
* Now so what we do here in processing, in order to make this work is we change the color mode to HSB
* And then we can control what we would normally like the Fill command, or the Stroke command to set the hue saturation and brightness
* And in that example I was showing you, you saw that the color was going through a range of different colors from one circle to the other
* Because in my Stroke command in my fit, yeah, it was the Stroke command
* In that Stroke command I was setting it based on the number of the elements in the system
* So it went around the hue circle, you can see the hue circle here, which is on the top of this, on the bottom of this cone
* It went round and round and round that cone, based on which number in the graphical system we were drawing
* So, if we use that hue saturation and brightness, and then we do some analysis, we can create some interesting visuals
* I'm going to start with a really simple visualizer, based on analyzing sound
* Exactly what Matt said
* We get, we analyze the audio by getting a float value called power in this example
* And that's that's done by using the audio method, get average power
* So, we go float power equals plat pow Float power equals player.getAveragePower and then we use the variable power to change the animation
* I've got an example that I want to show you
* Which is really, really simple
* what it does is, it's, uses HSV, as I've already said, and it produces
* The form, it produces it, you load the sound, you analyze the sound, and then we just change the color
* You can see I'm changing the color here, before it draws this circle
* And it looks like this
* And we should get some [MUSIC] and just to prove that I'm actually analyzing it if I change the speed you see that a hue rotation changes speed too
* So, I'm clicking and dragging, [SOUND] clicking and dragging to change the speed and you gotta be a bit careful with this cause if you stare at it to long it can give you a funny feeling
* I guess I better move on
* So, if I show you a bit of that code, it's really simple
* We have another for loop with a number of elements which is exactly the same as before
* I'm literally just drawing 20 circles, and those 20 circles are spaced in the screen from the outside in, just as if I was laying sugar paper circles one on top of the other
* And then, what I'm doing, is I'm using the hue and I'm rotating the hue based on the power, and also the also then the number of the element that we're currently in
* So, the outer circle is a different hue to the inner circle
* Which is why it seems to cycle from the outside to in
* That's basic color cycling
* Okay
* So, we're just to go through that again, we're changing the color of the elements depending on the power
* We get the float value power from the getAveragePower method
* We also have another float called Go which
* Go is basically how much energy we have
* So we keep adding the extra power and I've got a multiplier plus 50 which you can change
* Have a mess with that
* See how it effects how fast it moves
* So Go is a value which we use to keep cycling through, through all the different color values
* So, it's the, It's the additive power as we keep going
* And it's kind of a number that keeps getting bigger and bigger
* Now, I'm using Modulo here to make sure that whatever that value is, it's constrained to between 0 and 255
* And we go, basically we have a fill command, i plus go, modulo 255
* And that's the hue, power times 512, that's the saturation, and 255 is the brightness, so it's always very bright
* And then we draw our ellipses, and the size of the ellipse is dependent on which circle we're actually drawing
* So the circle go from the outside in
* So that's the most simple kind of audio visualiser
* Let's take another look at it because it's good for the eyes [MUSIC]
* Really simple and really effective
* Now let's say you want to do something more complicated, we can control the visualizer with sound through beat detection
* Beat detection is something which is useful when you're doing visualizers
* And I've got a simple example here
* Let me show you the example
* I'll tell you how it works
* As I've said before, all of these can be found in the materials which you should have week three
* So um, [MUSIC] we've got the same track here and you'll notice we've got circle in the middle, which is showing us the average power
* And then there's a square appearing whenever it, it detects a beat, and the square is appearing in the top left hand corner
* Let me show you how I did that
* So how did I do that
* Basically, what I'm doing is I'm getting the average power, I'm running a beat detector
* Let me talk you through how the beat detector works
* So quickly, what we do is we need to have two variables for beat detector
* In addition to power, we need to have threshold, and we need to have wait
* So the threshold is what the power needs to be for us to detect that there's been a beat
* It's basically a level that we set and if it goes over that level, we call it a beat
* And then wait, tells us to wait a certain amount of time before we go looking for more beats
* Now, so we have a little method here, in each statement
* Power, if the power is greater than the threshold, and also weight is less than zero so if we finished waiting and the power is over the threshold then we can do something to change the animation
* So in the case that I just showed you we're just drawing a rectangle on the screen but we could also do something else
* We could get this value go or our other value, we'll call it amplitude for example and we can add the power to that amplitude to create a running graph of the current amplitude
* And then what we do is we add ten to the wait value
* So we wait for another ten frames before we detect another beat
* And then immediately we close that bracket we do wait minus minus which starts the countdown
* So every drawing frame we count down and we're counting down until wait is less than zero again and then we go okay we can look for another beat
* And that's basically how it works
* Let me just show it working again so you can see
* [MUSIC] And you can see that [MUSIC] you should actually be able to see the numbers flashing on as it detects a beat here
* You've got the average here and the square is being drawn when we get a beat
* [NOISE] So that's really simple
* Okay so this is the last example I'm showing you, it's just a way of showing you how we put all those things together
* it's not a fully In a worked example you cold do a lot
* So for example, I'm, I'm not really using the color cycling
* And also I've only done a little bit to change the animation
* I just made it look slightly nice
* But I'm drawing lines instead of drawing circles
* also I'm not changing the visualizer through out
* You could have a number of different drawing methods and change them based on
* How many beats are being detected or any number of different ideas
* So let me just show you a bit what that looks like and then you should take this away as a starting point with all of the other examples and try and build your own
* So this is what it ends up looking like
* [MUSIC] You can see that we've got the position of the lines changes based on [MUSIC] the beat's being protected, but they're also rotating based on the energy, so they're really closely linked to the music
* Also, because the lines are all being rotated
* They're being rotated twice, once around the origin and then again given a separate value, and you'll see sometimes we get nice symmetries, and sometimes we get more noisy output
* [MUSIC] I'm also using a hue to rotate all of the different colors, and so that's it
* So in summary, what we've done is we're created a simple visualizer, a really basic one
* We could do a lot more by using alpha blending, by doing more color cycling
* But essentially we are taking some algorithmic approaches to drawing
* We are parameterizing them so that we can control them in various ways
* We're analyzing the audio and we're taking the output of the audio analysis and plugging it into the sound, into the graphics parameters
* So the sounds being plugged straight into the graphics as if we were taking a Jack plug out of a guitar and sticking it in
* In fact it's more complex than that because we're doing spectral analysis and we're doing weighted average spectral analysis
* So this is a really good way a good method of generating visual material and generating interesting visual applications [MUSIC]


--- SKIP ---: 15_3-6-outro.en.srt


--- SKIP ---: 15_3-6-outro.en_SENTbySENT.rtf


--- PROCESSING FILE --- 15_3-6-outro.en_SENTbySENT.txt
* [NOISE]
* What did we do this week Mick
* What do we do
* We built some audio visualizers
* So yeah we did some [UNKNOWN] graphics and we did some sound analysis
* So how did that go
* >> : Well I mean the sound analysis basically you're just trying to get some numbers out of some other numbers
*  >> [LAUGH] :That's the most annoying thing in the world
* Its quite a kind of dark art, isn't it
* It's a dark art and understanding what those numbers mean is what it's all about
*  >> Yeah
* >> So I don't really emphasize that some numbers tell you about the different aspects of the sounds so is it bassy, is it trebly and it's really important once you've got an understanding of those numbers to try and put those in to the rest of your applications so that's where Marco came in trying to explain
* The parameterization of graphics
*  >> Actually yeah, there's a thing about that Marco we used a really basic visualization technique this week but there's lot different types of approaches you can take
* What's a good way for people to go and find out better methods for drawing stuff
*  >> We'll got you know there's Pricing's a really powerful tool set you'll expanding your knowledge of Pricing/g, so there's a lot to play with
* But I would say the best place to go for ideas is the open processing website
* It's where people go to post their work they've done in processing really created people or doing exciting work and it's a fantastic source of idea and you can get the code there
* Some of it might be a little advanced for you at the moment but you can also get a lot ideas not only what people can do, but how they did it
* Yeah and it's good as well because those sorts of techniques they show you a lot you can learn really fast by looking at other peoples code and it's nice vital community
* But speaking of communities, you should check the forums out if you have any questions and you know you should be at the stage now where you should be able to help each other
* And but ask students is there students in more courses and if you've got anymore questions you can always ask
*  >> That's it for this week
* We'll see you next week where we're going to be doing a game
* Aren't we
*  >> Yes
* [CROSSTALK] That's right
*  >> We are
* So, we'll see you for week four next week
*  [SOUND]


--- SKIP ---: 01_4-introduction.en.srt


--- SKIP ---: 01_4-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_4-introduction.en_SENTbySENT.txt
* [SOUND] [MUSIC] Hi, and welcome to week four, of Creative Programming for Digital Media and Mobile Applications
* I'm Mick, and this is Marco and Matt
* Today we're going to be looking at making a basic game
* But we're going to focus on a certain type of game
* A physics-based game that you can run on a mobile device
* These are really, really popular casual games, and they're, I think for two reasons
* Firstly because it's nice to be able to run something which uses physics on your phone
* But in addition to that, it's something which has got us a dynamic game play
* So, when you use physics in a game, you can never be quite sure what's going to happen and it, very, very small changes in the way that you use the game can have a big effect on your game world
* so this is the first time we've done a game, and it's going to, I think, take a step up in the intensity
* In the, complexity of some of the programming that we're doing
* Mark has got a big chunk of stuff to tell you about physics
* He's built his own physics engine, which, integrates Java and Javascript in a really neat way, and works entirely in processing
* And then, Matt's going to use that to do some interesting stuff triggering sound effects and actually generating and triggering that sound effects entirely based on collisions that happen in the game world
* So there is a lot of interesting stuff this week, there is also a little demo of an app that we have built for you called, Angry Droids, which I can tell you has absolutely nothing to do with any other 2D physics based games that you might of played
* fine so without further ado, I think we're going to start with Marco
* [MUSIC]


--- SKIP ---: 04_4-1-physics.en.srt


--- SKIP ---: 04_4-1-physics.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_4-1-physics.en_SENTbySENT.txt
* [SOUND]
* This week I'm going to talk about Physics Engines
* Now, physics engines have a really powerful tool to get animation into action in in, in interactive programs
* The great things about physics engines is that they use mathematics, physics, to simulate the movement of objects
* So you can get objects that move just like they do in the real world
* And really if you've got a physic sense you don't have to write much of the code at all for that animation, because the physics engine will handle a lot of it for you
* They're very hard code to write yourself, but once you've got all that mass encapsulated
* You can just create objects and they will behave much as they would in the real world
* You're going to work with a physics engine called Box2D, which does everything in two dimensions
* So, it's just slightly simpler than a three dimensional physics engine
* And it suits our, our needs very well because it's, we're all writing 2D 2D programs, in this course
* It's been used very extensively
* Probably most famously in the game Angry Birds which, you've probably heard of
* Considering it's one of the most successful video games of all time, by now, I expect
* so, what is a physics engine
* A physics engine works with objects, and it moves objects around
* So here we have a circle and rectangle, and these objects are moved by forces
* So as in the physical world, forces are types of objects and that causes them to move around
* We'll talk in detail about both of these things in this lecture
* But first I need to sort of talk a bit about how the whole world is represented
* Now, you actually need to have an explicit representation of the physics world as well as the objects in it
* And I'll come back to how you create it
* But before I say that there's something a little different about how the physics world is represented than what we've done up until now
* Up to now we've upcentered everything in terms of pixels on the screen, and that's fine
* That's, we're dealing with the screen
* We can work all our distances can be our pixels
* But this is the real world isn't broken up into squares
* And if you really want to simulate the real world properly
* You have to seem like there's a continuous world, things don't change that much
* You just get rid of the grid
* But you're still using x and y position
* these are no longer whole numbers., they can be fractional
* but the x and y are still our fundamental representation of positions and directions to the work
* But I'll talk a little bit about how to discuss x and y but deeper mathematically
* Because that will help a little bit when discussing physics engines
* I won't get heavily mathematical, I'll just prepare you with a few things
* X and y aren't really separate things
* They, they were just a way of representing a position of an object on the screen
* And we can combine them together into a single thing we call a vector represented by this line in this diagram
* So here we have a vector
* Well it's showing now like v
* We can think of it as an x and a y, that's our position
* And we can also think of it has having direction and a length
* It looks like an arrow, it has it's pointing in a certain direction and it looks align, it has a certain length
* We called the length align filled with two hallow bars, across it, we might need that notation for much
* And once we've got vectors, they're not just the representations the x and y's
* Mathematically vectors also include a bunch mathematical operations we can do with them, some of which are quite powerful
* So, for example if we negate a vector, do minus v, which is just minus x minus y, it points in the opposite direction
* If we multiple the vector by a number, say the vector multipled by 1.5 is 1.5 times x, 1.5 times y
* We change the length of the vector gets longer in this case and then we can go further now
* If we've got a vector representing a position, we've got another vector
* And we put that vector at starting at the end points of the end point of the original one p, except v starts at the end point of p
* We can take it, it can take us to a new position
* And that position is actually the resulting of taking p, taking v and adding them together
* So we can add a vector v to vector p and get a new vector p2, and if we do that, we can do the opposite and subtract it off
* So if P is px, py, p2 is p2x, p2y And we know from what we just done that p2 is equal to p plus v
* Well that means that v is equal to p2 minus v
* And so we can subtract off p, p for p2 again, by subtracting p2, p2 from P2x
* And that, if you look at the diagram here, V is the vector that goes from point p to point p2
* So by subtracting one, the vector of one point from the vector of another point we get the vector that goes between those two
* And I use that in a couple of slides to do a calculation
* So back to our physics engine, [COUGH], as I said, we've got objects
* We've got forces applied to them, and they exist in world
* Let's look first at the objects
* So we've got a physics object and this is a simplified representation of an object
* It has a shape, a simple shape
* Or say that we mostly deal with circles and rectangle and occasionally we'll deal with some more complex objects
* But I think for the example I think just in circles and rectangles
* It's got a position, it's got an angle, it's going to take [UNKNOWN]
* And it's got a mass, which is a physical quantity which is how much it resists forces
* So you need for, if it's got a high mass, you'll need more force to push it
* So these are the things that define physics objects
* Physics object exist within a world
* So, this is how you create a world
* Create a new physics world by, it's an object, you have available physics equals new physics
* And you give it the size of the world, which is the width and height of the, of the, the window normally
* And we use this, which, basically this is a representation of your program
* So by passing, putting, passing this into your physics world, you're linking it to your program
* Then, the, the next thing we do to the physics world is set the density
* That's quite important because it's used to set the mass of objects, so
* You don't need to set the mass of an object explicitly
* It will just calculate from how big the object is based on the density, so the bigger an object, the more mass it's going to be
* But the density is going to control how how massive each of your objects is
* So if you increase the density, then objects are going to resist movement more, you're going to need bigger forces, they're going to move a bit less
* The exception to that is if you set density to zero
* If you set density to zero, then you're obviously not going to get affected by any forces
* so they'r not going to move, they're going to be static and in the physics implementation
* You automatically it creates for you static objects at the sides of the screen, so things bounce off the sides of the screen
* So now we've seen created that physics world, we can start creating objects
* And that's a little bit like drawing objects in, in processing
* We've got a function of physics .createRect, so it's the physics object that's creating the rectangle
* We're creating a rectangular object
* And just as in processing, to create a rectangle we need four numbers, but it's a little bit different, like in placing the first two numbers at the top left
* But the next two numbers are the bottom right of the rectangle, not the height and width, so that' something to remember
* Is that it's the top left and bottom right rather than the top left weidth and height
* We can also create circule objects
* Again a different function creates circle
* That's three parameters, x and y positioned at the center of the circle
* And the radius of the circle, how big the circle is
* And the great thing is, once we've created these physics objects, they will just be part of the simulation
* The physics world will just carry on simulating and you don't really need to do much at all
* And you'll already get some quiet compelling interaction
* The only problem is, it's just the physics world, there's nothing graphical on screen
* So, for, for your physics objects you also need to create a graphical object
* Now a graphics objects is much what we, is what we're used to
* They've complex shapes, they've got colors
* They could be images, so this is exactly what we're drawing
* Now, we're not necessarily going to have a representation of an object in there
* but we're just going to use all the same drawing trechniques that we've been using up to now
* And I'll show you an example of how to do that
* The most important thing you need to do is link your physics to your graphics
* So you need to get the precision and rotation of your of your physics bodies
* And then apply that to whatever graphics you're going to do
* So, first we get the object's position, body.getWorldCenter
* So that's the center of the object in world's coordinates
* So if you remember I went back we've got the pixel coordinates that we use on screen
* And we've got a set of vector coordinates that we're using behind the scenes in the physics engine
* And sometimes you want those to be different
* In fact, most of the time you're likely to want it you're having one unit per pixel is a bit small
* roughly the physics world works in meter
* So one unit is a meter in terms of physical simulation
* So having one meter per pixel seems really small, so you might want 10 or even 100
* So, to get those coordinates back into pixels, you call physics.worldToScreen, so world coordinates to screen coordinates, screen coordinates to pixels
* The result of that is a vector, of the Vec2 type, so it's a variable of Vec2, which is a vector, and it has a position
* You can also get the angle of the object, physics.getAngle, and you pass in the object itself
* And then you can use these for translate and rotate, just as we saw last week
* so, you need to get out the x and y positions of the vector, plus .x, plus .y, and put them in the translate, and then you rotate by the angle
* I've converted that in to radiance, again as we saw last week
* So we don't, as the original angles and degrees, and I've putting in a minus sign because the directions
* In the physics world, it's different from directions in the, in the screen worlds
* but just put that in, and then we can do whatever we like to do
* In this case, I'm drawing an image
* And you must remember to put pressure pot matrix around those to make sure that your objects move independently
* [MUSIC].


--- SKIP ---: 06_4-2-forces.en.srt


--- SKIP ---: 06_4-2-forces.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_4-2-forces.en_SENTbySENT.txt
* [NOISE] So, we've talked about objects
* The, the things that affect objects may move other forces
* I'm going to talk about a couple forces that we'll work with
* The first force is the pervasive gravity
* Basically we're always going to have force downwards that pulls objects down
* Doesn't have to be downwards you can actually set gravity to move to the left or even 0 if you want a space world
* But most of the time you're going to have a force pulling things downwards
* And that's automatically built into the worlds
* So, you don't have to do anything to get gravity
* You can use the Set Gravity commands to change the gravity force
* It's a vector
* So you can have, at the moment, gravity is something like 0, minus 10
* 0x minus 10y so it's, vertical, but you can have horizontal gravity if you give it a, an x value
* Another kind of force is an impulse
* That's basically a force that's applied at a particular moment in time
* So, sometimes you just want to push an object in a certain direction to get it moving and applying impulses is a good way of doing it
* It's just applied for one moment, just like kicking an object
* This is how you do it
* An impulse is a vector
* You create a new vector with whatever values you want so that you'd call new Vec2
* That's a vector type
* And you pass in the x and y coordinates of that vector
* It's actually a direction
* Say 2, 4 where we mostly vertical, we mostly downwards with a bit across
* And then you call the Apply impulse command on the box
* So you do box.applyimpluse and that applies impluse to that box
* You pass in you have to say where the impulse is acting on
* So you can apply an impulse to different bits of the box
* Often you just want to apply to the center of the box so it's not going to spin around
* But if you apply it to the edge of the box, you, bo-, box won't just move, it will also spin around
* And then you obviously have to apply past the impulse into that function
* I'm going to show a bit more of a complex example that Mick will be following up later and in, in, in the code he's going to show you
* [COUGH] Of how to implement a catapult
* So we've got a ball that's on a piece of elastic and when we pull that ball, the further back we pull it, when we release it, it will fly in the direction that we've been pulling back
* So the two things we need to know will fly in the direction of the elastic
* But, the more we pull the elastic back the further it will fly
* So, it depends on both the distance and the direction from the catapult to the ball and what it produces is an impulse that's applied to the ball
* So that impulse, if you remember what I was saying about vectors earlier
* Is based on the vector that goes from the ball to the catapult
* It's in that direction, then the more that the growth of distance is, the bigger the force is going to be
* That's fine, because that vector includes that
* So the vector from the ball to the catapult is simply catapult minus ball
* The catapult is the vector position of the catapult
* Ball is the vector position of the ball and we multiply that by constant c
* just so, you know, just so we've got a bit more control about how big that impulse is
* So we can vary that to make it a bigger force or, or a lesser force and just tweak it again
* When you, when you're working with physics again there's a lot of tweaking to do to make sure that all the densities and the, the, these constants are right
* Just get the right feel that it's moving at the right dynamically enough without things going all over the place
* So, if we look here how we do the calculation we create first an impulse vector
* That's a vector
* We set its value to be equal to the position of the catapult
* Then we subtract off the position of the ball
* And finally, we multiply by a constant, in this case, 200, quite a big number to get a quite a dynamic move
* And we'll see that later in the example that Mick's going to show you
* The final kind of force, and maybe the most important one for physics engine is collisions
* A lot of what a physics engine does is handle when objects collide at each other and bounce off
* And gets that, those collisions absolutely physically correct
* And, you see in example, we've got objects bouncing off crates, and then objects bouncing off the sides of the screen, stuff bouncing everywhere and that's all handled by the physics engine
* Um, [COUGH] in a, in a sense, you don't really need to do anything
* to handle collisions the physics engine will do everything for you
* But sometimes you want to know when a collision's happening
* so, for example, you might want to, increase your score whenever a collision happens
* And as, as Matthew would show you, you may want to you may want to play a sound whenever you have a collision
* So you need to know when there's a collision
* In the first extension we're using, we do this in a very simple way
* You just create a function in your program called collision
* That has to look exactly like this
* It has to have collision
* Takes three parameters
* body 1 body 2 and the impulse
* So the body 1 and body 2 are the 2 objects that are colliding with each other
* And the impulse parameter is how big the force or the impulse of the collision was
* So that's really useful
* You can find out which objects are colliding
* So, depending on which objects there are, you can make different sounds
* And you can make use of how big the collision was
* So maybe if the collision was very small, you don't make a sound
* Maybe with a bigger collision, you make a bigger sound
* So, With those three parameters you can really control exactly what happens in your program when different collisions happen
* And the next, Matthew will talk about how to create a sound engine which can produce different results, based on different objects and with, varying parameters of the sound, which is exactly what we need to change the sound whenever an impulse is played
* Once he's done that, Mick will show you full example that has physics objects colliding all over the place and audio being triggered by those physics objects
* [MUSIC] [MUSIC]


--- SKIP ---: 08_4-3-preparing-and-playing-sound-fx.en.srt


--- SKIP ---: 08_4-3-preparing-and-playing-sound-fx.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_4-3-preparing-and-playing-sound-fx.en_SENTbySENT.txt
* [SOUND]
* [MUSIC]
* Hello
* Today in this lesson, I'm going to show you how to create some simple sound effects for, for a collision-based game that we're going to develop later in the lessons this week
* And I'm then going to show you how to import those into your, your project quickly which, which is revision, you've already seen how to do that, but will just do it do the workflow again, just to show you that
* I now want you to get really creative with these sound effects
* You know collisions are great fun to make
* I am just going to demonstrate some quick examples of how to do that but I want you to go for make your own sounds and once we got those collision sound effects into the application, what we going to do is figure out how to trigger them
* But not just play them as they are, we want to play them with a bit more a bit of dynamic range on them
* So what we'll do is, is parameterize the playback, so that depending on the number that comes in they might be played back in a different way
* So let's make some sound effects
* So I've already loaded up audacity which is a simple open-source
* Audio editor and I'm just going to record straight into this, and my laptop mic
* Of course you could record with much higher quality microphones if you like, and you'll get a better sound, but this will do just for demonstration purposes
* So, I hit record, and then I'm going to make my sound effects
* [MUSIC] Okay so I've now recorded a few sound effects lets just listen to those they're not quite healthy on the wave form display
* [SOUND] Okay there fine
* I quite like that
* That's a good one
* That's a quite nice one
* And
* [SOUND] There's one
* So I'm going to take these uh, [SOUND] these three sounds and use these
* Okay, so, first of all, I'll do, I'll convert to mono
* So, it's track, stereo track to mono
* Okay and then I will trim them down
* So, it's good if you want to, if you want to, cause they're sound effects, you want them to trigger very accurately
* So, it's best if you trim them right down
* Okay, so, let's get the whole thing
* That'll do
* Copy that, paste it into a new one, then export and I'm going to put it into, I'm going to create a folder sound effects
* And this one's going to be ping one dot wav
* Okay
* [SOUND] Close that
* Then I've got the next ping
* Zoom in
* Make sure we've got a nice trim on it so that it's right up against the start the sound
* And you can even duck into the sound a bit because they're sound effects, they're a little bit of a click
* It's not too much of a problem
* So, Edit, I can actually export directly from my selection
* ping2.wav
* [SOUND] Then I'm going to get [INAUDIBLE]
* What have I got here
* I'm just going to use this rumble sound here [NOISE]
* Okay and export that file, export selection and rumble
* Don't laugh
* Okay
* Get rid of that
* Now I'm going to import these into my sketch
* So my s-, I need to find the data folder for my sketch and it's called Android sound effects
* There's the data folder
* I've put all these into this folder called fx, so I'll copy those
* Paste them into there
* So I've got ping1, ping2 and rumble
* you m-, yeah, remember that all the files that you put in the data folder will be included in your sketch
* So you might want to just trim it down to just the ones that you need
* so let's just get rid of The ones we don't need
* Alright so we just got ping1, ping2 and rumble
* So we've got all our files they're all ready to go just need to import, need to load them up so I'm going to have three players
* play 1, you might because they're sound effects you might want to call them call the players something more sensible like, that relates to the sound they might make
* So I've got ping one ping two and rumble, okay
* That, that will make it easier to read the codes, know which one you're triggering
* Okay
* Now, so then I load them in
* Ping one
* Ping 2, then rumble
* I wouldn't [UNKNOWN] here these sounds playing on my phone
* That's why I'm talking so fast
* So rumble, ping 1 Ping 2
* So what I'll do quickly is I'll just test them So I'll do
* let's just do a quick test to, to listen to the sounds
* So, if the mouse, when the mouse is pressed
* If mouseX [SOUND] is greater than uh, [SOUND] well, let's just trigger them, actually, one by one
* So ping [SOUND] ping1.play, [SOUND] ping2.play, [SOUND] and rumble.play, just to make sure there's no problems there
* Okay
* So we've got all, we've loaded up the sounds, and we are playing like that
* Now, because they're sound effects, I don't want them to loop
* So I'm just going to tell them not to loop
* Ping one set looping, so that's false
* Okay
* Now do that to the other two as well
* Ping two set looping false
* Rumble
* Right
* That's saved
* Now I'm ready to run it on the device, so let's just tap the screen to wake it up and we hit play
* If I don't have any syntax errors they'll build that app and push it onto the phone and hopefully when I tap the mouse button I should hear all three sounds playing at the same time
* [SOUND] There they are
* That's my sounds
* Now
* Now, as I said earlier, I'm going to parametrize these sounds
* So I don't want them to be the same sound every time I play them
* So I won't at, to, to set up, a perimeter I see
* So I'll create a new function, could play sound
* and, so, the, it's going to take an integer which is what sound I want to play and, it's going to take another integer, which is That's where I float, which is going to be the speed
* When in fact I can just randomly generate the speed
* so if sound equals 1, ping 1 dot play
* Then I'll do a random number
* Random between 0.1 and 2
* So that will play sorry
* Speed and then ping 1 dot play
* Okay, so it sets the speed to a random number between 0.1 and 2
* And it triggers play
* And so I'm just going to copy that block and, and Activated for the other sound
* So if they, if they pass it at number 2, then we play ping two
* If we pass a number 3, we play rumble
* Rumble
* All right
* So now, I'm going to just say h, if the mouse is pressed, play sound
* And I pass in, Again I'm going to do it random, choose at random which sound I want to play
* So, it's going to be in the range, one, two, three
* Okay
* And I'm going to
* Cast that to an integer, because random normally gives you values which have floating points
* Right, so, what have I done
* I've got my three sounds
* They're not, they're not looping
* And when I, that's what we call one shot, as well as loop, or one shot is when it plays once
* call play sound when they press the mouse and choose a random sound
* And then actually I'm going to put that up to four, so that it can potentially go up to three, because it will round it down
* And then finally I'm going to trigger the sound and depending which id comes in I'll choose which sound
* To play
* And I'm setting the speed on the sound up to random
* So every time I tap it should show a different sound rather than parameters
* OK
* So now, I'm now ready to run my code on the phone
* Now notice I had a little error there which I put an l instead of an i
* So I'll just change that
* So hopefully it should be ready to go
* Okay, so again, we get the same error, run again
* That's pushing onto the phone now
* [SOUND] There's 1 more thing I might add to that, which is I'm going to cue the sound so that they go back to the start before playing
* So, cue it back to 0, that rewind it
* That's ready to play ping2.cue
* [SOUND] To note and ping3.cue to p, sorry it's not called ping3, it's called rumble
* Rumble cue to note
* So that rewind the sound before I trigger it
* So let's just run that on, on the phone and that's our last step
* [BLANK_AUDIO] [SOUND] [MUSIC]
* Okay, so that's a little bit of musique concrete for you at the end there
* Have fun playing with this
* You can obviously make all, all kinds of interesting sounds yourself
* And you might think of other ways of maybe hooking, hooking interactivity into that function
* So you might add another variable which controls the pitch so maybe it could be pitched in different ways depending on where the mouse is or the accelerometer data
* And you can really make a fun little instrument which, you know, depending on what you're doing with the phone it can trigger all different samples with different Dynamics
* So do play around with that one and we need to make a music [INAUDIBLE] instrument with that
* What we're going to do based on that is, is develop a, set of dynamic sound effect for a game
* [MUSIC]


--- SKIP ---: 10_4-4-integrating-audio-and-physics.en.srt


--- SKIP ---: 12_4-5-group-discussion.en.srt


--- SKIP ---: 12_4-5-group-discussion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 12_4-5-group-discussion.en_SENTbySENT.txt
* [SOUND]
* Hi so we've heard Matt explain to you the wonders of audio recording and sound effects and how to synchronize it with collisions generated by physics engine
* We've had Marco explain the physic engine in which we're using that works in iOS devices and also Android and on the desk what we've done is we've tried to create a framework app
* Which is a basic physics game, 2D physics game
* And they're really, really popular on handheld devices
* Really popular amongst casual gamers
* So our template just gives you the bare bones for it you want to make a game
* It gives you a physics engine
* It gives you a mechanism for loading sound effects, and a mechanism for loading artwork
* And you can easily make a game that, you can easily make a game with those components which is somewhat like Angry Birds, Angry Birds being the most famous physics-based 2D platformer on mobile devices, I should think
* >> Which actually uses Box2D, which is the same library we've been using
* >> Yeah
*  >> So you're using exactly the same physics engine, almost exactly the same physics engine that Edward Burns is using Yeah
* Except you're using the one that we've hacked together, which may or may not be a good thing
* with certain improvements
*  >> Yes, there's been some improvements made Cross-platform and it should be relatively easy for you to use
* So we've got this example
* We're want to talk you through it
* so you see it when [INAUDIBLE]
* This is it running on an iOS device
* So you can see it's basically the same
* You've got our little hero here
* Who is a he's basically tux, he's what Linux users refer to as Tux who is the symbol of Linux
* He's a penguin
* He's not normally a really ugly penguin which does reveal a lot about Linux
* And he's wearing a little android head
* And he's fighting [LAUGH] I can see [UNKNOWN] he's fighting these little boxes, he's trying to hit the boxes inside the crate with a bunch of apples, you can't see those that's more of a [UNKNOWN] thing
* so it runs fine on the ipad device and it runs fine on your iphone
* So Let's have a look at this desktop version, this is it running on the desktop, it's basically the same
* we hit the boxes, and we're off
* So, we've got some artwork assets here, and then we've got a physics engine that's implemented that has a lot of complicated stuff that I'm going to talk about and also were going to talk about you know how the whole thing's put together so lets start with the art work assets
* That will just take a small amount of time
* You'll find in your coursera folder in week 4
*  >> The basis of our game it's called Angry Drawings which we thought was funny
* >> [COUGH] At the time
*  >> At the time
* So yeah, basically, you can see in the data folder there's a bunch of different aspects
* We have a ball which we're not currently using, we have a crate which is our mythical apple crate
* and then we have this, these scrapyard backgrounds
* And then we have our tux droid
* And you'll notice he's a PNG file, so he's got transparent background, and that means that although he's a rectangle, when we draw him on the screen as you can see here, he's just the shape of a fluffy penguin
* With an Android [INAUDIBLE]
* So we don't have any of those nasty rectangular issues, that's why he is a PNG
* The background isn't a PNG, the background is just a JPEG so it's a compressed image
* We've got two backgrounds, we've got this one which is nice and bleak
* I don't know if you can see that
* The bleak background, which you might want to throw in if you feel depressive
* And then we've got the scrap yard
* Now in order to produce the kind of align the way you can place all of the objects
* Part of the scrap yard image has been grayed out and has been made a bit more muted in color
* And then we've got a more colorful kind of ground area where we would place all the objects ideally
* so we haven't actually got that many assets
* We could easily introduce more assets
* But that's enough for us to have a basic level
* And you know, the dynamics of the game are you spring back, tucked, and you fire them at the boxes and then every time it hits a box, you score a point
* [COUGH] That's a long way from a complete game
* It's just to get you started
* So in order to understand what's going on here let me talk you through this code
* I'm going to ask some questions and Marco's going to fill us in and then Matt's going to fill us in on some other bits, too
* Fundamentally we've got a a base of code which works the same way on Android as it does on iOS desktop
* So, we've got some stuff in here that's specific to one or the other platform
* So here you can see we've got a bunch of import statements, and what these are doing is importing Box2D, which is the library you were talking about before, Marco, is that right
* >> Yeah, that's right, so we're using an external library in order to implement physics engine and on Java and Android we need to import that live v using that code there
* And with code you're running on Javascript, that code just gets ignored
* Instead what happens is you'll see that on the other tabs we have a copy of ox td
* We have a copy pf physics.js, which is my little wraparound /q ox td
* >> And the collision doctor detected objects which handles collisions and gives you a nice interface to create just a simple collision function that gets called whenever something collides
*  >> So that's entirely running all of the physics that we see on the
*  >> [INAUDIBLE] Yeah, okay
* All right, so as usual, what we've got here is a maxim audio context and then some audio players
* These audio players are for the sound effects
* Right, Matt
* >> That's right
* So, we have one audio player for Tux
* So if Tux hits anything he has his own sound
* and then we have another sound for the wall
* >> So, if Anything hits a wall, then we trigger a wall
* It's kind of a metallic sound
* The Tux sound's a kind of ee sound, so I thought that was appropriate
*  >> So, did you do that yourself
* >> I did it myself, and
*  >> Very good
* >> And, finally we've actually got something a bit more complicated for the crates
* Now when we're, we're playing around with, with one audio player just for, for all the crates
* So we never have Crate collided with something
* We triggered the audio file but we found it was a problem because if there were several crates colliding at the same time, then they would keep retriggering the sound so you would only ever hear one sound
* So I decided to create an array of players
* One for each crate instead
*  >> So what happens now is depending which crates collide though
* They have their own sound player per crate
* And I'll trigger it individually
* >> Cool
* And then, we also have a new object, which is called physics
* And it's of type physics
* So this is the main physics handler
*  >> and this is basically what we're using to control well, what's making all of the physics This controls work, is that right
* This is doing all the work
* >> Yeah, that's right as I explained in my lecture the physics object is [INAUDIBLE] the whole physics world and it contains things like gravity and all that
* You need to create it
* You're going to need to create one physics world
* A bit like you only need to create one maxim
* >> But you can create several bodies [CROSSTALK] So we call a body called boid, who's our droid
* Our angry droid, in fact
* >> Yes, our [CROSSTALK] droid Yep
*  >> And, it's the [INAUDIBLE] and then we got a whole, array of other bodies which crates will [UNKNOWN] interacts
* >> So having an array you could just have lights with crates and crate hole
* >> And then we have a vector which is the start point, which we use to, set with a catapult is
*  >> so that's the start point for when s, bring back, talks in the guy room, is that right
* >> Yeah, that's right, that's where the catapult is
* >> Okay, and then we have a collision detector, called detector, in which the, a, detection responds to collisions
*  >> So that's basically what, a, detects the collisions and then calls the collision method
* >> that we'll see later
*  >> Right, then we have some initializers for these variables
* Crate size, which you can change if you want a massive crate bolt size
* and then we have a bunch of images which we then pass into the physics engine and it then draws
* we'll explain about how that works in a second
* >> Score is initialized to zero and then we're currently not dragging What is that marker
*  >> Can you [CROSSTALK] That's just I need to keep track of when you're dragging the mouse because it's drawing a line that's sent to the catapult elastic
* So whenever you're actually dragging with the mouse, you're dragging the [INAUDIBLE] will follow you around and you're pulling on the elastic and you need to see that elastic
* That's all that's doing
*  >> There are some really terrible jokes in this
* I think, yeah, we'll just have to pretend
* That they're funny
* So you can see here that we have a size command
* Because this is the one that we're using for the iPad predominantly at the moment
* This is 1024 by 768
* But what we can do is set this to the size of an iPhone screen
* Which would be 480 by 320
* Or if it's on Android it we just comment it out
* We're at 60 frames a second
* And we load our images
* The scrap yard is the background
* The crate is the grate
* The tux droid is our hero
* Image mode center, you know what that means
* Now, we get our physics objects and we initialize it with a width and a height, which basically says what the bounds of the world are
*  >> So in this case, it's the same as the bounds of the actual screen
*  >> I'd like to just say that I've put some comments after it, which gives another example of how you might want to do a more complex initialization where you can pass in values for gravity and here width over width times 2 height times 2
* That's the overall world size
* It's going to be bigger than the size of the, of the screen
* and so you could have this more complex initialization which sets more values
* Most of the time you're not going to need that
*  >> Most of the time you should do This version
*  >> So if you have a world size which is greater than the size of the screen you can have off screen objects which can float into the screen
*  >> Exactly
* So objects can go off screen and not instantly sort of stop being stimulated
* The world size, if something goes outside of the world size it stops being part of the physics simulation
*  >> And then also you can have custom gravitiy so that you can
*  >> Yeah
* >>  >> Have high gravity or have gravity that goes upwards [CROSSTALK] So the things can suddenly go up or suddenly go down
*  >> Yeah
* >> I always love it when that happens
* Well that's actually what happens in that kind of space version of that very famous physics game that we already mentioned far too much
* Okay
* >> So we've got a custom rendering method which I'll talk a little bit about this
* This is something special about this sort of the way the physics engine works
* Now you can actually, if you don't do that, if you comment that line out, it will draw itself
* It had it's own sort of renderer which will draw boxes for all the boxes and all that
* Which is quite useful when youР Р†Р вЂљРІвЂћСћre debugging or if you donР Р†Р вЂљРІвЂћСћt, havenР Р†Р вЂљРІвЂћСћt got your graphics in yet
* But once youР Р†Р вЂљРІвЂћСћve got your graphics in, you want to be able to control the rendering of all the physics objects
* And rather than calling that in the draw method, the physics engine sets up a custom rendering method, which is the function myCustomRenderer
* which we'll see later on, [UNKNOWN] does all the drawing of the [UNKNOWN]
*  >> And that basically draws tucks, and it draws all the cranes
*  >> Yeah, that's right
* >> Right, okay
* So instead of having to draw methods, we've just got our own method, which is a wearable and a physical object
* Okay, great
* And then we've got set density, which is how stupid I've
*  >> [INAUDIBLE] No
* >> Okay
* How, what is that [INAUDIBLE]
* >> [LAUGH] It's it's basically, ti controls the mass of the object, so the density is mass divided by area, and that will, so the, the mass of an object, [INAUDIBLE]
* how much it resists forces, how much force you need to actually push an object
* Is determined by how big it is but also the density
* So if you set really high density, with quite a high density then the objects on is going to, are going to be quite massive
* It's going to be a bit hard for me to move them around
* If you set a really low density they're going to be floating around more
* If you set the density to zero, can create objects that don't move
* And that's quite useful
* So if you want objects that don't, that don't move, set density equals zero, and then after that set density equals one, and you can create objects that do move
* So you can change the density as you go, as you create different objects
*  >> All right, so then we create seven new bodies, which are all our crates and then these are accessed as arrays, And then we create a [COUGH] rectangular body
* and it has a position, which is its start position
* A height a width
* And what's this last one
* >> So that's, that is the, that's the y position
* X position, y position
*  >> Y position
* >> Width and height
*  >> And I'm just using height Because
* >> Oh yeah, x1
*  >> It's at the bottom of the screen, so it's just moving up from the height [INAUDIBLE] from the bottom of the screen
*  >> Okay
* >> So it's actually x position, y poition, the top left, x position, y position the bottom right
* Not width and height like like a rectangle
*  >> Yeah, so fundamentally, it would be much better if this was all done relatively to the screen width and the screen height in as in our week two example
* >> Yeah
* Yeah
* >> That, we'll leave that up to you
* so, yeah
* So this basically sets up where the, all the boxes are at the beginning
* It gives them an initial position
* And then the start point, which is where, that's where The tux is connected to [INAUDIBLE] stuff
* See I [INAUDIBLE] [INAUDIBLE] .And this is just where we put it
* And then we just put that in a physics word
* Yeah so I'm converting to a physics coordinates
* As I said in my lecture, we've got a different set of coordinates for the world, the simulation than you would for the screen and we want the start point in physics coordinates
* So, the boid is circle rather than a rectangle
* When we created the [UNKNOWN], those bodies, we used this rect, but for the Android for the kind of angry droid we're using a circle
* Why's that
* >> Well, because, well, first to say this is the example of the fact that you use simpler shapes for your physics than you would for drawings
* So [INAUDIBLE] is quite a complex object
* For the crates, the crated boxes, it's fine to use a box for the physics and for the graphics
* But for [INAUDIBLE] it's a fairly complex object
* >> But you wouldn't want to simulate all the physics of his exact shape, because that would be
*  >> Yeah
* >> Very [UNKNOWN] expensive
* It would take a lot of time
* So you have a simplified object, and you take the physics in that
* So we're simplifying him down, he's quite rounds, we're simplifying him down to a circle from the point of view physics, and you see him as something a bit different from, in the actual graphics
* So then we set up our collision detector
* Which is standard
* We pass it to the phy, the physics word basically gets the collision detector
* Then we have our maxim context, which we've seen before
* We load in our boid sounds, which is the sounds of Tux hitting something
* The wall sound
* then we set them looping, all the stuff you've seen before
* And then we have this for loop which loads over create sounds in
* And that's the big array full of sounds, right
* Let you describe the array now
*  >> That's correct
* Yes
*  >> Okay
* And then we're moving to the draw method
*  >> So whoo, we start our game, our first level of our game, That was quite intense, now
* >> Just a second, great thing about using a physics engine is once you set it up, it will just run
*  >> Yeah, that is true
* >> And actually the biggest thing is you just set up the world, and it just does everything for you
*  >> Yep, that is good
* And so you don't actually have to process any of your own collisions, you don't actually have to know what the velocity of any of your objects are or compute them
* The physics engine does it all for you
* This is what most people who are developing games do
* Then we learn from search engine in order to do those those calculations
* Some people insist on watching learn from search engines from scratch
* [COUGH] I think that's actually a good idea if you like doing that sort of thing, but if you don't you should probably [INAUDIBLE]
* so, the draw method is surprisingly small, in this case, because as Mark has already mentioned
* The physics engine is doing the drawing for the foreground objects that are moving around
* This is because it knows where everything is because it's calculating the velocity
* In other words it's calculating all the x and y positions
* but we still need to have the image of the tip, which is the backdrop, which I already explained
* And we also have to have the score
* Which, at the moment, There's no objective
* One thing you might do for an objective is say, you know what, let's have each session last 20 seconds
* And get the highest score you can in 20 seconds
* And then have a second, in other words, each session lasts, each game level lasts 15 seconds
* And then the next level lasts 10 seconds
* And you just have to get the highest score that you can
* This provides an objective
* It's up to you to kind of think of an objective
* The whole point of designing a game is to have something people want to do
* we're just giving you a framework
* So it'll be great to see what you come up with
* All right
* Now, [COUGH], as a few of the standard methods mouse-dragged, which basically sets the position of tucks
* Who is basically the boid object
* And we've got these 'screenToWorld' coordinates
* We parse in the Mousex and the Mousey values, add a two-dimensional vector to our physics world, and that sets the position so that when we click on the screen we can make sure that that's where our [UNKNOWN] is going to be
* And then we just demo that
*  >> That's why when I click on the screen Turks appears more or less where I leave him, and I can just fly him around
* Okay
* mouse release there's a bit more stuff going on
* Dragging is set to false
* So this means that we're no longer fixing the position of Turks and we have this thing called an impulse and now that's probably best if Marco explains this
* >> So basically, when you release the catapults touch will start flying off, the reason is that force is instantly applied to touch
* It's an impulse; I talked about this in my lecture
* So what we're doing is we're calculating the appropriate impulse direction and magnitude of the impulse based on where you're pulling back
* The elastic catapult
* I've gone through the details of this calculation in my lecture, but it's using vector subtraction and multiplying the impulse by a certain constant to get it at about the right value, just as Matthew was saying a bit about the audio sometimes you just need to play around to get the right number, to get the right feel for it and then we apply the impulse to tux and from then on the physics just handle how it moves
* >> So that constant in this case is 5000
* >> And then, yeah, we apply the impulse to, to him and then he's given the impulse just as if you've smacked him in the face with a big stick
* which yeah, I think penguins, you know, they're probably used to that
* Okay, so the last thing we want to talk about in the terms of this demo app is the my custom rendered
* Which is I'll substitute for the draw function where all the drawing and the physics end and so the first thing to note here is that we set the stoke to 0 and we get the start point and use it draw to a line and that's as you can see in the example this line is
* >> The pole that Tux is suspended from and that we use to fire him off
* That's his kind of starting point in the world
* Boing
* Okay, and then following that we have to draw all the other stuff
* So Marco, do you just want to talk us through that
*  >> Yeah, sure
* Just to make a note this is, this is what I described in my lecture
* We're getting into position of and the angle of the each of our physics objects in this case void we have to convert from world coordinates to screen coordinates
* Just as we did we have to do up here
* And then we can use whatever processing drawing code we like using those coordinates
* They're just values they're just numbers we can do whatever we like with them
* I'm doing a fairly obvious thing, I'm translating, imitating by those two values and then drawing an image
*  >> So most of the time you are going to want to get the positions and the angle translate by position take by the angle and then draw whatever you want, in this case we're going to draw the images we got and the code for crate is exactly the same where we've got a four loop over all the crates but we're just doing pretty much the same thing just drawing a different image
*  >> And it's just because it's an array of crates
*  >> Yeah
* >> So doing each one at a time
* Okay so the final, final thing in addition to the other final thing we going to talk about is just how the collisions work
*  >> Now, the main the method for doing collisions is, it's all in collision detector dot JS
* So we just have to use that collision detector, pass in the positions and it will work out where a collision has happened and will let us know
* so the main method for that, well this is basically here boid collision
* So the collision dysfunction is caused by the collision detector, and you've got, as I said in my lecture, two bodies that are colliding in the impulse
* So you can use that, for example, I'm checking here if the impulse is more than one, so it's a proper impulse
* I'm increasing the score, so the score's going up
* That's how we did in scoring
* But we're going to do a few things so we can, we can, because we got the bodies we can check which particular body it is
* And we need to make sure that there's two things
* There's, we need ju-, the, it's the actual tux that's colliding so we're checking if one of the bodies, b1 or b2, is, is void
* And the other thing we're doing here is we're checking the mass of the other objects
* Why are we doing that
* Because you might notice that cut bouncing off the screen that's because they're physics objects at the edges of the screen that automically created
* Those have 0 mass which means they don't move they're static objects
* but we don't want to get [UNKNOWN] when we bounce off the walls so we'er just checking that the objects have more than 0 mass which means they're not one of the static objects, they're one of the crates
* so we can do that test similarly [UNKNOWN] whether you talk through a bunch of code is easiest to crate the audio
*  >> And to create audio to respond to collisions
* And that stuff's just here, and it's the same
*  >> That's right
* >> Okay, great
* So fundamentally that's the basic set example
*  >> It shows you how to create a physical world, how to put objects in that world, and then how to Interact with them, and have them interact with each other, it also shows you how to draw the different artwork that you need, the best way of preparing the artwork, and it's up to you to put in for example decent artwork, game play, mechanics that sort of thing, or the kinds of scoring mechanisms and different kind of ideas
* So you can use it as a starting point, and you can develop it and try to build on something that's a much more developed project
* >> And, and that's it
*  >> Have fun
* [MUSIC].


--- SKIP ---: 14_4-6-outro.en.srt


--- SKIP ---: 14_4-6-outro.en_SENTbySENT.rtf


--- PROCESSING FILE --- 14_4-6-outro.en_SENTbySENT.txt
* [SOUND]
* so that was week four
* And you've seen how to use a physics engine to make a basic game
* And how the use of physics can really bring richness to the game play and strong interactivity
* And there's a mass of games out there on mobile platforms
* Maybe you want to talk a little bit about
* >> Well
*  >> The potential
* >> Well there is a lot of potential because you can use those kind of techniques to easily make a casual game
* And casual gaming is the it's one of the big up and coming genres in markets
* So you can here, it's the sort of game which you can play when you're on the bus or you're on the train
* And it's really engaging
* Because really, really small changes in the way that you use and massive impact
* And you know you, you cant, it's quite difficult to get exactly the same thing each time although it's always deterministic
* So it's always the same if you get the same thing
* So yeah it's a really useful thing for making games
* But also we did a little bit of some sound [INAUDIBLE], and collision didn't we
* >> Yeah so, so as usual we try to get creative with the sounds as well as the graphics, so, so, so we were, we were looking at how
* This way we're sort of working from the opposite direction to how we did last week
* So we were kind of parameterizing the audio from what was going on in the graphics
* So we were kind of sending back impacts velocities from, from the physics engine and using that to control the playback
*  >> Yeah, that worked really well
* So there's a lot more you could do
* As always, its just a thing to get you started
* It's a jumping off point
* >> I mean, I think you can, there's, you can look at the game you already play and see all the games on the the android and iPhone markets
* And loads of them use physics and you could probably start figuring out how they're built and trying to build your own versions
* >> [INAUDIBLE] Yeah
*  >> Or coming out with your own games
* >> that's right
*  >> [INAUDIBLE] It's not as if it's going to go away
* It's a genre which is going to be around for a long time
* And it's something which is easy enough for you to build in 2D with any source of engaging
* So yeah you don't have to make big 3D monstrosities to be making, to be big in the games market
* Next week we're going to be doing something which is a bit more complicated
* We're going a bit deeper
* It's Facebook integration and also using stuff like the camera from your mobile device
* So that's going to be an interesting week
* There's a lot of new stuff there
* A lot of people are interested in social media and integration and that
* We're really kind of covering that all over then
* So and remember to check the forums, and to talk to our students who are there who are able to, you know
* Who are going to respond to you and any questions that you have
* And we'll see you next week
*  >> [MUSIC]


--- SKIP ---: 01_additional-lecture-functions.en.srt


--- SKIP ---: 01_additional-lecture-functions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_additional-lecture-functions.en_SENTbySENT.txt
* Welcome to another additional lecture about programming
* And so, this week I'm going to talk about functions
* Now, we've actually seen functions before
* In fact, we've seen them in two different contexts and at the time they have seemed like very different things but they're actually the same thing and I"m going to slide a detail what they are and how you can work with them
* So this is the first time we have seen functions
* Where we called above the surface line of code we have to write size brackets 400, 600
* That is a function
* That is a call to a function, size of the function, and by we're calling that function in order to get its functionalities [UNKNOWN] change the size of the screen
* So, this line of code is what we call a functional call
* We're using a function that somebody else has created
* Let's look again in a little bit more detail what this line [INAUDIBLE] does
* It's got a name, size, the name of the function
* It's got parameters
* These are numbers that we are passing in to the function
* Giving to the function, in order to change the way it works
* And you've got these little bits of of, of punctuation
* The parameters of a function always have brackets around them, and they're always separated by a comma
* And that's an important part of what makes a function and a function call
* And then we have a semi-colon on the end of the line, as we normally do
* This is the other context in which we've seen a function
* Void draw
* Void draw is, we've seen it before, it's, last week
* It's where, it's a container in which we put code that we want to be run every time the screen is refreshed
* Every time the screen [UNKNOWN]
* So its a way of grouping k together and have it happen at a set time but its also a function and this is a function definition
* On the last slide, we're looking at size, where we're using an existing function
* Here, we are creating a function that's processing the use
* So processing calls the draw function when it's ready to redraw a screen
* So these are two sides of the same thing
* This is what it looks like when we create a function so lets look again a little bit more detail what happens
* Got the name of the function and the name will be the same name we'll be using in the function call
* The function has some content, the code deduction happens when the function is called
* It has the beginning, and an end and they're defined by this curly bracket
* And I will come back to this later
* In the previous lecture, I said come back in a few, feature we will come back to them very soon to explain what they are
* But just now to imagine that really all that's happening when we were on the previous slide we talked about size, when size is called, is that when we call size, it's a function that contains a lot of bunch of codes just like the draw function contains code
* And that code as well, so that code happened
* So when line is, draw is called here, the line command will happen
* Which is itself another function, of course
* Okay
* So, [SOUND] what can we do with that
* Well, the great thing is, we can create our own functions
* We created our own function when we created draw
* But we can create new functions that all I've got to rewrite call them, and then we can call those functions later
* So, at the top of the screen here we've created a function called updateBall, and it has two lines of code in it, so what it's doing is not terribly important but we've got one variable and we're adding another variable to it
* That is our function and its pretty much the types of things we've seen in void draw or mouse pressed or set up
* All the things that we've used already but draw setup, mouse press, mouse drag, these are all built in things to processing
* Their names have special meaning whereas update ball that could be anything I just created that's my function I can call it whatever I want
* And I call whatever I want because it's me that's going to call it
* And I'm jsut going to the use the name I call it and the button here and draw that's what I'm doing
* We've got update ball is being called
* And, as we can see, the name of the function is the same as the update ball function, up here, and that's how processing knows that I'm referring to this bit of code up here
* And we've got those brackets in there, which we always need
* Well we've got a function
* Now this function has not parameters, I'm not passing any parameters, but we still need the brackets, so processing those that I'm calling a function
* Even if they're empty, there's no parameters, we still need the brackets
* Okay
* Good
* So, what does this give us
* Why is it useful
* Well it helps us in a number of ways the first way is that it can break up your code a little bit if you've got very complicated code it become very difficult to read
* And if you divide up your code so, if you have hundreds and hundreds of lines of code in draw you wouldn't know where anything was
* So if you divide that into functions that can get called and draw it simplifies things
* We'll see another benefit of that system in a minute
* Let's look at another example
* So, here's a slightly more complex example
* So, this time UpdateBall has two parameters
* Here we are
* This is how you create a function which has parameters
* So it's all function, calling functions with parameters like size, we've done that quite a lot
* You're passing numbers in that gets you to the function
* But this is how you actually create that kind of function
* And it looks a lot like, well, it looks a lot like a call in that You've got brackets
* And inside those brackets are the two parameters
* And they're separated by commas
* And that explains why we have brackets after void draw
* Because it's a function
* And though it, and [INAUDIBLE], though it doesn't have, take parameters
* Other functions do take parameters, and functions and no parameters still have the brackets to show that they're functions
* It looks a like a variable definettion because it's got a type and a name jsut as variables have types and names and in fact it is a variable you're creating a variable
* And it's a variable that you can use inside your function just like any other variable
* So we're using it here
* SpeedX is used inside the function
* it only exists inside the function
* So you can't use it outside the function
* But within the function it's just like any other variable
* If its like a variable where do we get the value
* We don't, we're not doing float of speedX equals to a, as we would if you are creating a variable
* So where does the value come from
* Well, the value comes when we passing a [INAUDIBLE] to it
* So when we call update ball
* If we pass a value in ball speed Y but it could be a number it could just be 3
* That value is copied into the varible that is that parameter in this case speed Y
* Which can then be used inside the function so that's how
* Parameters work
* So if you think when we're passing the width, somewhere where size is created there's a there's a parameter that says float width and inside the size function that float width variable gets used
* So To summarize, we define a parameter with a type and name just like a variable, we can use it just liek a variable but the value of that variable comes when we're passing a parameter in as we call the function
* Okay so that's functions with parameters
* One last thing, as well as parameter all these functions we've had to far have got void
* This one's got somethign different in there
* It's got float
* What does it mean to have float there
* Well sometimes as well as passing values into a function you can get values back out of the function
* And this is called the return value
* And by putting a float there, we're saying the type of what is returned by the function
* We're saying the return to float
* It means we can get a float value back out of that function
* So if we're doing a calculation, we can get a value back out
* Up to now, it's been void
* And void literally means nothing
* It means there is no value coming out of this function
* It just does its stuff, but it doesn't give anything back to you
* By saying float before update ball it's saying, I'm going to give a float to you after I'm done with my stuff
* And the thing that..
* At she does that giving back is the return command, return keyword
* What that does is hmm, it says what value to give back so when I say return the function stops and gives back the value and after the return statement
* Just after return, I put whatever value I wanted to give back
* So in this case, I'm returning the value of the variable newBall ballX
* And what happens
* Well, when I make a call like this, ballPosX equals updateBall, once the function finishes
* I copied ballpos the value that's returned new ball pos for X into my variable ballpos X, so ballpos X is now equal to whatever new ball X is
* I'm copying one into another
* So if we think of, of that whole process
* As I toss my parameters in they're copied into variables in my function and can be used in whatever way I like to do whatever calculations or functionality I want
* And then if I want I can have a resulting calculation that ends up with a value that I want to pop back In this case newBallX and that gets copied back out of the function
* So value is going to come back out of the function copied into variables at the point which we call the function outside the function
* So we can get two way flow of information
* From the, from the function inside in and out of the function, which is where it's useful in multi contents
* So, this is a classic example, a function to add 2 numbers together
* It's going to name add
* It's got a content which does some calculations
* A beginning and an end with those code brackets
* It's got parameters to floating point numbers a and b, they get added together, and the
* That calculation produces the result, which is the return type to pass the [INAUDIBLE] and the return value is c, this variable that I have created by adding a and b together
* So I can pass values into this function, doing calculations that pass them back out and that's probably about the simplicity
* And you can do the dozen of those things
* Okay, one last example
* So, don't bother, worry about what all this code means, apart from that the fact that we've got a complicated function collideWithPaddle that has two parameters
* Now the great thing about function is that, because you've got a bit of code that change, does different things depending on different parameters there are there, you could call it multiple times with different parameters
* So, I can call collide paddle once
* With details of one paddel this comes from a palm game where the paddle is basically a tennis racket
* I can one set of parameters and pass them in and do as functionality once
* And I can call an exactly same
* Function with another two sets of parameters to do something different
* So, if I've got a tennis game, with two paddles, the tennis rackets
* If I call it once with one with the X and Y of one paddle, and once with the X and Y of the other paddle, I only need one bit of code
* But I'm handling [UNKNOWN] paddles
* And that's part of the benefit of doing, sort of, a little bit more advanced programming, because you can work how, actually you can save a lot of time and effort by realizing, well, I'm doing one type of thing on lots of different types of data, lots of different types of data
* Doing one action for lots of data
* One action for lots of objects
* If you can put that one action into a function, then you can just record, recall it multiple times with different parameters
* And you don't have to rewrite much other than that one line function
* It simplifies your code a lot, saves you a lot of work, saves you a lot of errors
* You can miscopy the code, or if there's an error in one bit of code, you can forget to copy the fix into another code
* If it's all in a function, it becomes a lot simpler [INAUDIBLE]
* Okay
* Thanks a lot
* That's all I want to say on function.


--- SKIP ---: 02_additional-lecture-loops.en.srt


--- SKIP ---: 02_additional-lecture-loops.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_additional-lecture-loops.en_SENTbySENT.txt
* Welcome to my last additional video, which is about doing things many,many times
* This is something called a loop
* Before we get to loops, let's talk aboutwhy we want to do things many, many times
* Simplest reason is that we might want todraw lots of things that are very similar
* A bunch of concentric circles, a set of lines forming a grid,these are the examples I'm going to use
* But also, things get much,much more complex than that
* I mean, you might have a game withlots of enemies you want to draw
* Or in the case of this week's example,we're creating complex shapes made out of many similar simple shapes
* And, in a sense, a grid or concentriccircles is a good starting point
* Here, this is a sketch that gives us,draws a bunch of lines across the screen
* How does it work
* Well, every time we call a drawwe're calling the line command
* But we're using a variable here which ischanging every frame, so if you watch, let's draw gets called everytime a draw gets called, another online gets to have it
* I'll actually set the frameworks, so this command sets how oftendraw is called essentially
* Just typed in ten times a second,slow it down a little bit so that you can see itdrawing very gradually
* And that's kind of what we want to do
* We want to draw one line after another,after another, after another
* And we'll see how that works
* So this is the code I just showed to you
* And I will go into quitea lot of detail how it works
* First we create and set up a variable forthe position of the line starting at zero
* We've seen variables last week
* We know how they work
* It's a number
* Its value is zero
* Then we use the current values of O todraw a line, when we start off at zero
* So we're drawing a line at zero, and the next one is always zero,then zero, then height
* So we make use of the variablehere inside the blank
* The reason we're using pos twice isbecause, we want both the start x position and end x position of the line to be zero,because we want a vertical line
* We don't want the line tobe at all horizontal, so the starting x and the end x position
* But all that's important here is thatwe're using this variable to do something, in this case draw a line
* But the really importantbit is this next one
* We're changing,we're updating the value of the variable
* So once we've drawn the line,we add 20 to it
* So the next time we draw a line,it's going to be in a different position
* And the reason that works is becauseonce we've done all that, it repeats
* And it repeats because drawis called many, many times
* It's called one time after another,each rate that's drawn
* Let's go back through that,because it's really important
* We need to understand this tounderstand what's happening next
* We setup a variable
* That variable is going tocontrol our drawing
* We use the value of the variable,we update the value of the variable so that the next time we use it,it's different, and we repeat
* While we're repeating, we're doingexactly the same thing we just did, but with a different value the variables sothe effect is going to be different
* We're going just do that and then times
* Okay, one small but important point next, before we get to the nextbit is that k never stops
* It's going to carry on going,even though we're off the screen
* We kind of like, probably doesn'tmake a difference if we don't see stuff going off the screen,but to my mind anyway, it seems a little bit inelegant to carryon drawing when we no longer see stuff
* So we want to stop when wereach the end of the screen
* And this is how we do it
* Again, we setup the variable,but before we do anything we use an if statement to checkthe value of the variable
* So we check is the position,is pos less than the width
* If it's less than the width,we'll have to carry on drawing, because we haven't reachedthe end of the screen
* If it's more than the width, we stop soonly if we less than the width do we do the drawing,the updating and the repeating
* If we've reached the end, if it was more than the width,we'd stop updating, we'd stop drawing
* We finish doing what we're doing,then we finish that drawing
* So, small thing not vitalin this particular example, but actually very important withsay knowing when to stop, and in this case we are doingwith an if statement, but the important thing is if wego back to the beginning
* We're doing this statement thatcompares our variable to some end condition, to some of the end condition
* So we know that we end whenposition reaches width
* So as long as the position is lessthan the width, we carry on going
* So let's briefly seethat to check it works
* So I'm putting in an if statement,we're checking the value of the position
* You won't really see if it worksbecause we can't tell the difference between big widths or not but we can ifsay, we only want drawn to the halfway across the screen, and there it stopped
* So, we can make it stop
* Not only can we carry on doing stuff,but we can also have it stopped
* So are we done yet
* No, because what if we want todo everything at the same time
* If we run this together, What that does is it gradually draws a set of linesacross the screen, one after the other
* What if we just want a setof lines on our screen
* How do we do that
* In order to do things, many things all atonce, we need something called a loop
* If we get to live up, we cut this codebecause it's essentially the same ideas
* What it does, sets up a variable,checks the value of that variable
* Values still okay,since we haven't reached the end
* We use the current value available
* We update the value, and we repeat
* This is what's called a for loop
* It does exactly the same thing, but it does it one afterthe other until it finishes
* Sets up a variable, checks the value of the variable,uses the current value of the variable
* Updates it and repeats
* But the important thing is,it repeats inside draw
* So it's not repeating once per draw, it's doing all the repetitionsevery time you call draw
* So that to you, to the viewer,it looks like it's all done, all at once, and what you get is a much lines
* And the important thing isit's this four structure
* Let's look at that in a lot more
* Once more I'm going to repeat
* We set up a variable,we check the value of the variable
* But instead of having these all separate, they're all inside these brackets forthis command for
* It's a little bit like an if statement
* In an if statement you have if bracketsinside there, you have the condition
* But rather than just having a condition,we actually have, we have all the things we'redoing with this there
* We're having, setting it up,comparing it and updating it
* And the forloop does the repeating for us
* So let's look at that again
* A for loop has three things
* An initial condition,a test that checks the variable
* So the initial value of the variable,the 10 check on the variable, the increment, soincreasing the value of the variable
* Here I'm just adding one or20 that's very, very common
* Just add one at a time
* The previous one was a littleunusual in that we were making
* And we've got a body,where we're actually using our variable
* And that repeats
* The initial condition test and increment are all inside brackets and they're separated by semicolons
* It's a little bit surprising
* Other times when you'vegot a function call, we expect to see brackets,and inside them commas
* Here it's semi-colons, this is how you know it's somethinga bit different from a function call
* Here they're semi-colons, you justhave to know that that's how it works
* Just like the end of eachline has a semicolon, each bit of the for loop has a semicolon
* Just have to know that, put it in, it'spart of the punctuation and grammar that, as I've said before,is very important to programming
* If you get that right,it will [INAUDIBLE] work
* Okay, now I want to look at another use of loops and a very useful one
* Let's recap, what is an array
* An array is like a variable but,while a variable has one value, an array has many values
* An array variable is what we see here
* posX is a little box that points toanother whole load of other boxes In memory, each of which can bethought of as its own variable
* So it's pointing toa large block of memory
* So when we've got a single variable,like an int variable we just create, how we create it, is you createa box in memory, give it a name, posX, And put a value in it, zero
* There it goes
* When you create an array, it's a littlebit, creating a memory box, sure
* Give it a name, sure
* Create an array
* And put that away in a box, orrather, put a reference to that away
* So make that box point to an array
* I won't go into detail on that
* It's not sampled right now
* Reportedly now we've gota whole bunch of empty boxes because we haven't put stuff in the boxes
* So we need put values in each of thesearray boxes one after the other
* So I put one value in after another,after another, after another
* How do we do that kind of thing
* How do we do one thing after another,after another
* It's what we've just seen, it's a
* And this is how we mightgo about doing it
* First create a memory box
* Give it a name
* So creating an array then
* Create your array itself
* So now we've got 10 boxes in memory
* Put a pointer, so make that posXvariable point to that memory
* Then we need to go through andput a value in each array box
* That's what we're doing with a link
* Let's look at that in more detail
* What we need to do is start atthe first element in the array
* As we said last week the first timethrough is not one, it's zero
* So we start off at int i=0,set up our variable i stands for our position in the array
* Set it to zero
* We need to test to check the variable from what we need to make sure is itis not more than the length
* It hasn't gone over the way
* So as long as i is less thanthe length of the array, you're okay
* As to be less than, less than andequal because it starts at zero, the value of the array lengthis on the entity length
* This is very like what we saw last week inthe animation, then we went to stop and loop the animation
* But, again, this time aroundwe're doing it many times
* Rather than doing it every frame,we're doing it all at the same time
* So we're going until we'vereached the end of the array
* Go one by one, add one
* ++, if you remember, means add one
* Each frame.And then we Put the value into array on the top
* So we're kind of stepping througheach element from zero, one, two, three to the length of the array,cutting up value
* In this case a random value
* Into that [INAUDIBLE]
* [SOUND] Recap, set up,start, start position, first element through a always 0
* Until the last element, always less thanor equal to the length of the array
* We get that with a reigning .length
* That's how you getthe length of the array
* Go one by one,always add one to put something in
* Whenever you're dealing with arrays, it's really useful to dothis all over the place
* This is a really, really common thing
* You've got an array,do a loop through, and the array, the loop always looks the same
* Always starts at zero, goes the lengthof the array as one doesn't
* In fact, as well as putting stuff intothe array, you can do stuff to the array
* This is an example of how you might draw apoint based on the positions in the array
* We've got two arrays
* And the array of x positions, and the array of y position willbe drawing a point each of those
* This assumes that the size, the position of y is exactlythe same as the position of x
* And it's exactly the same
* So the first element starts at zerountil the last element, array.length
* Go one by one, plus plus,add one, and use element i
* And you can use this todraw elements in the array, to create elements in the array,to do various updates
* I could be adding something tothe position of each array
* I could do whatever I want,just like any other variable
* Except this time,because I've got lots of them in an array, rather than just using one line of code,I'm using a loop to do that one line of code many,many times in one time for each array
* It's a very,very common pattern that whenever you're working with arrays you use
* It was very, very unusual that last week
* Okay, so that's the end of thisadditional programming lecture
* And that's our last additionalprogramming lecture for this course
* So I think I've covered allthe programming topics you're going to need for the rest of the courseYou can't learn to program just by watching a few of my lectures
* You have to go and do it, and I recommendyou do it by trying the exercises, looking at the examples we've shownyou in the rest of the course
* Go and look at the documentation,just try to write programs
* That's the way to learn
* There's a kind of myth that's,to be a programmer you've got to have some special aptitude andsome people can do it, some people can't
* They did a load of research about what
* Which people were able to succeed atprogramming in the university and not do that properly, and who didn't
* The only thing that made a difference ishow much time people spent programming
* You've really got to do it, and the best way to do it is findsomething you're passionate about
* I think anyone in this course are creativepeople, do something creative with your code, and use that to motivateyourself to go out and do it
* If you do spend loads of time programmingand practicing and practicing and practicing, you will do it
* The best way to practice is to dosomething that you're really into, you're really passionate about
* Something creative, something interesting
* I hope we have provided inthe course a bunch of examples, a bunch of exercises whichwill make you able to do that
* Okay, thank you very much,enjoy the rest of your course and good luck learning to program.


--- SKIP ---: 01_5-intro.en.srt


--- SKIP ---: 01_5-intro.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-intro.en_SENTbySENT.txt
* [NOISE]
* Hi and welcome to the final week of Creative Programming for Digital Media and Mobile Applications
* This week's a bit special because it's the last week, but also we're going to do something that's a bit more fun and for our specialist audience and our specialist market
* We are going to build a synthesizor and a drum machine that works on mobile devices and on desktop devices entirely using browser technology
* So yeah, we've been working quite hard to get this together for you
* Although, it's very, very simple for you to interact with and you should be able to, from this example that we're going to show you, go ahead and build a lot of your own music synthesizers and sequences
* And I think this is a nice way to end because it shows you how we can use a GUI and quite complex audio ideas, sound ideas, and music ideas to put something together that's very usable for people who don't necessarily have a lot of musical skills
* But then allows the to produce something which does sound musical..
* Although, having said that, it's me that's playing it so, you know, my goal whenever I try and write music software is to make something which I can play when I'm really drunk
* so that's been my vision for this week
* we've got Marco, who's going to be telling you a little bit of how to set up sliders
* Particularly, sliders so you can change the parameters for the synthesizer
* And then we've got Matt
* And Matt is going to tell you that some of the specifics about creating a sequencer using processing
* Now, it's gotta be said, processing is not the best language to be doing sound in of any kind
* So the fact that this works at all is you know, is I think very useful for a lot of people that are interested in making music
* So, we'll take you through step by step as always, and this week we're going to start with Matt, and he's going to talk you through basic, building a basic drum machine
* So Matt, how does it work?


--- SKIP ---: 03_5-1-basic-drum-sequencer.en.srt


--- SKIP ---: 03_5-1-basic-drum-sequencer.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_5-1-basic-drum-sequencer.en_SENTbySENT.txt
* [SOUND]
* Wow, what's this
* It's a drum machine
* So what, what, how does a drum machine work
* Well, let's figure it out
* So, a drum machine has a pattern, pattern which specifies what rhythm it's going to play
* And the way that you, you, you input that pattern is using these colored buttons at the bottom, okay, so this is, this is a tra2a, it's the classic drum machine
* And you can see, you've got 16 buttons on the bottom there
* So if you, if you press a button, and a light comes on, and that means that on that beat you're going to trigger a sound
* And then, a clock will step it through the beats, and if it sees that the button is on, it will play a sound
* So, what we're going to try and do is emulate that kind of behavior
* What we call step sequencing inside processing
* So, we're going to have to figure out how we're going to represent that sequence int he memory, we're going to have to figure out how to do the clock and various other things
* but it's really nice because if you do it at this low level you have complete control over how the sequencer works
* And that means you have a much wider range of possibilities to get creative
* So, let's get into some code
* So, I've got a basic starter code here
* And you can see I've got the usual maxim object
* And I've got an audio player, which I'm calling snare
* Which will be obvious why shortly
* And then, so I create my maxim
* And I create my snare
* So, I'm loading in wav files
* So, this is I believe it's a sample from the Roland TR-909 drum machine
* but you can obviously use any samples you'd like
* But certainly for a drum machine you probably want to be using short samples
* So, that's my snare sample
* And then, my frame rate, I'm setting to 30
* that could be, that could be set to anything
* But I'm just setting it to 30, so it's really explicit how the timing is working
* Okay
* Then, I've got this variable called playHead, which I'm setting to 0
* And playHead is, is how I'm going to figure out when, when to trigger events
* Okay
* So, when draw gets called, which happens repeatedly
* Remember, draw is just being called all the time
* The playHead is going to go up by one
* And then, I'm going to check if the playHead, how far the playhead has gone, and if it's gone up to 30, in other words if I, if I take the remainder of the playHead in 30 then, and it's 0, that means that it must have got through three calls to draw, sorry, 30 calls to draw
* So, that means because it's 30 frames a second that means one second has passed
* So, this little if statement here, checks if a second has passed, okay
* And so, when one second passes, I queue up the snare drum sound and I play it
* So, the, the sound we expect to hear from this is a snare drum being triggered once a second
* [SOUND]
* Okay, there you have it
* Now, that's not really the best rhythm I've ever heard
* so, I think quite a few songs aren't that far from that rhythmically, but we can, we can do better
* So, what we need to do now is, is address that problem I mentioned earlier which is how to represent a sequence in the memory
* So, the way I'm going to do it is I'm going to take a Boolean array and call it snare, snSeq, like that, so I'm giving it a kind of short variable name so I don't have to keep typing it in, okay
* So, snare sequence
* Now yes just to reiterate it's a Boolean, so that's going to contain trues and false values
* Because the idea is that it, remember with the buttons on that drum machine we saw at the beginning they're either on or off
* So, Boolean is fine
* And it's an array so that means you can install several Booleans in one place, which makes it more convenient
* So, let's initialize it
* snare sequence equals new boolean
* And I'm going to put four slots in it, and then I'm going to put a rhythm in
* Equals true
* So, it's going to play a snare on the first beat, let's put four beats in, one, two, three, and this, they're going to miss it on the second beat and it's going to trigger it on the and then two, it's going to do two
* So, the idea with this rhythm, it's true false true true
* So, it's going to be like this
* [SOUND]
* Okay
* So, we get three in a row, and then a, and then a gap
* Right, so let's, so the problem is I now, I now need to look into that array as my, as my, my ticking clock, you know, my playHead
* Every time playHead gets to zero, I need to figure out where I am in the array
* So, I'm going to need another variable which is it's going to be called snSeqPos, okay
* So, snSeqPos is going to start off at 0, okay
* Now I'm going to, want to do is every time the the playHead tells me it's time to, to, to play a sound, I'm going to increase my, my sequence of position by one
* Right, and then, I'm going to check if its gone too fast, snSeqPos
* So, I'll do a check
* If, snSeqPos is equivalent to snSeq.length, so in other words, if I've got up to four which is a remember from Marco's lectures about arrays that arrays are zero index
* So, we don't want our index to go up over four and this is our index
* so, so we check if it's gone that far
* If it's gone that far then we reset it
* Okay, so that, that code there is, if you like, a simple thing which steps through from zero to three then goes back to zero again
* So, we can just check that code by, by testing, so let's print line position
* And let's print it out, snSeqPos
* Okay, so we should see it going zero, one, two, three, zero, one, two, three
* So, let's run that
* Save and run
* [SOUND]
* Okay, so you can see that's going, that's counting zero, one, two, three, and back to zero again
* Okay
* So, we've got our in, so we can now use that to index into the array
* So, we go snSeq
* And so, what we're going to do is basically if there's a true value in the in out sequence there, then we trigger the sound
* So, snare sequence, seq snSeqPos
* this is equivalent to true, but we can actually, we don't need the equivalent true because we can just put it directly
* because remember in an if statement you can put a Boolean directly in there
* But let's make it really explicit
* And there's different styles of coding, some more explicit than others, so let's be really explicit
* and just check if it's true, then we're going to play the snare
* So, remember that beat I mentioned earlier
* So, it was one, two, three, gap, one, two, three, gap
* Okay
* So let's see if we can get that -- that going now
* So, I'm going to run it
* [SOUND]
* So, you can hear it's got that gap, but it's too slow so I'm going to speed it right up
* So, I'm actually going to just double my frame rate and that should speed it up
* Okay, let's save
* [SOUND]
* Okay, so the, the rhythm's a little bit irregular
* That's because I'm doing a screen capture at the same time
* So, if you're just running this in a normal browser it should be fine
* And okay, so, so we defined a basic sequencer which we can we can use to trigger different sounds
* So sounds at different times
* Now so the programmer can edit the sequence and make it longer and so on and you can make a really elaborate rhythm sequence
* And it's obvious that you can also add another Boolean array
* And then you need another another position counter, and then you an add more and more tracks
* So, that will allow you to build a full multitrack drum machine
* And I'll leave you to go and have a go at doing that, and, and we'll show you a kind of fully worked example later
* [MUSIC].


--- SKIP ---: 05_5-2-slider-widget.en.srt


--- SKIP ---: 05_5-2-slider-widget.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_5-2-slider-widget.en_SENTbySENT.txt
* So last week we introduced user interfaces, and I introduced you to the user interface library that I have
* now this week we're going to continue using that to make music machine, but we're going to introduce one other feature of that library, which is sliders
* so, a slider looks like this
* It's a horizontal bar that you can click on and it moves across the screen, and as usual we can make that effect
* What's going out things in the program, in this case you set the screen cover
* So, let's just see how that works
* Now a slider works pretty similar, in a pretty similar way to the buttons that we saw last week
* You can create a slider, give it a name
* And this is a new thing, you need to set the minimum or maximum values of the slider
* Those are the minimum and maximum values that you can get out of a slider
* So, the slider will have a certain size, just as any other user interface element
* And it will go from the, the left of that slider to the right of that slider
* And left of that slider will give you a minimum value, in this case zero
* And the right of that slider will give you a maximum value
* These are the values we're using to control color, which go between zero and 255
* If you were to control something else, like audio volume, you would need another range of, of values
* This is quite similar to the map examples we used earlier
* And we have the initial value of the slider
* So you might want to start it at 0, but sometimes you want to start it at another value
* Here I'm starting it at 20
* These other bits are pretty much the same as the button
* You give it a position, X, Y, and a size, width, and height
* And this last this last parameter is the orientation of the slider, whether it's a horizontal slider or a vertical slider
* You can see how we can change that
* sliders pretty much work as, in the same way as buttons
* You need to draw them in the display method, in the draw method, and you need to do, you need to check whether they have been clicked on in the mouse released method, but I'll show you the one other thing you need to do is get the value of the slider
* So you need to know what, what the value of that slider is, and we can use the function get, the slider.get
* We'll return you a floating point value, a number, between the minimum value and the maximum value, and then you can use that simple code
* So let's see an example of doing that
* So this is the program I ran earlier
* We've got a slider variable, just as we had button variables
* This is where we creating the slider
* Can you remember these are the minimum and maximum values, and that's the initial value, we display it in the, in the draw method, and we call, slide it up mouse released
* In the mouse released method, and this is where we actually make it interact with the rest of our program
* We get the value of the slider and use that as input to our background's color, and let's just remind ourselves what that does
* So we're getting the value of the slider, it's a value between 0 and 255 because that's what we set it to, and, and that's changing the background color
* We can change your initial value
* We can change our minimum value so that it's never going to get too dark, even right at the bottom it's still quite grey, our maximum value similarly so to stop it whiting out as it does
* And the other thing we might want to change is the orientation of it, so currently it's drawn horizontally across the screen, but we can draw it vertically as well
* but, I need to remember to change these values because
* it's going to be a very short, fat vertical slider, if I draw the same size as the, the horizontal slider
* So if I'm drawing a vertical slider, I need to make it's it's thin but long, as opposed to wide but short
* So I'm swapping the width and height and there we have our vertical slider
* Now with a button it's fine just to respond to clicks, but actually with a slider it's quite satisfying to drag around and you can't do it
* Input the code as it is now, but doing it is very simple
* We just create a mouse drag method and call s.mousedrag
* And then we can drag very smoothly and smoothly change all the values so for you can just call any of mouse press, mouse release, mouse drags and our user interface for each will have equivalents
* Now let's show you one last example of how to use multiple sliders together
* Last week you saw how to create radio buttons which is a combination of different buttons, a series of buttons
* You can do something very similar with sliders where you have a set of different sliders that, that you can interact with, and it looks something like this
* So I can now set each of the color channels with my background individually so I can make it less red
* And again, it works in a quite similar way
* We have multi slider available
* We create the multi sliders
* Just like with radio buttons, we have to give it the number of sliders you want
* In this case, we're taking it from the length of this string of this array of names, and again just like radio buttons we can set the names
* and then we display it and then we do, mouse release to capture events, and in here we're getting there's no longer single gets
* We can get the value of each individual slider, and we pass in the number of that slider, so it's get zero
* We'll get the first slider, get one, second get two, we'll get third
* So, that's how it works
* So, get zero we'll get the value of this slider as I click on it [MUSIC].


--- SKIP ---: 07_5-3-part-1-music-machine-discussion-with-martin-roth-from-rjdj.en.srt


--- SKIP ---: 07_5-3-part-1-music-machine-discussion-with-martin-roth-from-rjdj.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_5-3-part-1-music-machine-discussion-with-martin-roth-from-rjdj.en_SENTbySENT.txt
* [SOUND]So it's week six
* And as you know we'redoing audio applications
* The thing about music and interactive music is it's much moreaccessible than it's ever been
* And now it's really quite good fun makinginteractive music applications that run on your iPhone, your iPad oryour Android devices
* Because there's somany people who want to use them
* And I thought as well as showingyou a really easy way of making a very,very cool scent, which iswhat we're going to do in a moment, and incorporating some of the stuff thatMatt's been talking about I thought it'd be really good if I gotwant to my friends Martin
* So come and talk to you soyeah basically this is Martin Roth, and he's director of researchat a company called RJDJ
* So RJDJ specialize in interactiveaudio applications on mobile devices
* So yeah Martin can you tell us a littlebit about some of the applications that you guys have made
* >> Absolutely Mick thank you
* Well our first app was back in 2008 andwe started off with the original RJDJ app
* And that was really one of the first timesanyone on a mass scale had been able to interact with their music
* You were able to downloadwhat we call the seen
* It was basically an interactiveuser track onto you iPhone
* And then interact with it either throughthe microphone or by tilting the phone around or the accelerometer wouldinfluence what you were listening to
* Or perhaps, we can use the internetto find out things about what, what was going on around you forinstance what the was like
* >> Mm-hm>> So, you can imagine that you were walking down the street
* And the music that you were listening to, would change tempo,according to how fast you were moving
* So if you were moving slowly then themusic might be, you know might also have a relatively low tempo, it might bea little bit relaxed, little chill
* But then if you started running notonly would the tempo pick up, but you could also changethe energy in the music and it would become much more energetic,much more exciting, much more thrilling
* >> So what kind of stuff did you do
* Because I've seen some ofthe earlier apps as well
* >> Yeah.>> But you've obviously done some quite large scale appsthat have movie tie-ins
* >> Yeah, that's right
* One of the first movie tie-in apps thatwe did was called Inception, and that came out a the end of 2010, along with,alongside the DVD release of the film
* The Inception app workedextremely well with the film, because the film is all about dreams, itwas about going to dreams within dreams, and then losing yourself a bit in this,in the dream environment
* And certainly one thing that the kinds of,the kinds of music that we were making at the time, one thing that it lentitself very well to, was a kind of dream, psychedelic experience
* Worked incredibly well
* Some people were in fact really worriedthat if they went to sleep with this thing on then theywould never wake up
* [LAUGH] It was a real customer complaint
* [COUGH]
* >> Yeah, certainly
* But since then we have also doneother movie tie-ins such as with the Dark Knight, and there are even somenew ones coming on down the pipe line
* >> That is really cool
* So, so that's what main stream thatinteractive and reactive music there
* >> Yeah, absolutely and I think it's something that willbecome even more mainstream in, in the coming years
* The philosophy behind RJDJis always been that for the last year many decadesmusic has been frozen
* We record music, we import it to some medium, whether itbe vinyl, cassette, cd or these days mp3
* But once you've made the recordingof that music, it's done, it stays like that forever
* And every time that you go back and listen to that piece of music,it's exactly the same
* But with the technology that we havein the palm of our hands today, we can do so much more
* Not only can we allow the,the musician to give their fans all of the different variations that theyhave in mind for a piece of music, but we can allow the fans to explore all ofthose different variations themselves
* >> Right
* >> For instance,you can imagine as with video games, where you can go and you are drivingthe plot, you are driving what happens and you can go and explore the scene of the
* The video game developers have created
* We would like to be able to givethe same opportunity to musicians
* >> Yeah right
* It's interesting as well becausethe landscapes changing isn't it a little bit from a developmentParticularly in terms of audio
* Because of the web audio API, so we'reusing it as part of this Coursera program instead of doing native coding foraudio on the, on our devices
* When you think about it,you think it's a good step forward
* >> Oh,absolutely I love the web audio API
* In the past we've doneeverything natively of course
* We needed the performance
* But now, that the web audio API's comingalong and it's been standardized to some degree, and it certainly seen supportacross not only desk top browsers but also mobile browsers
* >> Mm-hm.>> It gives it gives the developer the opportunity todevelop their audio experience once
* And truly be able to deliver it to manyplatforms without having to do a lot of work in order to adapt your codewhether your experienced to any one particular platform
* >> Yeah, and so I think we've found itreally useful for delivering this program
* >> Mm-hm.>> But also I think we've gotta kind of of there's an instinct aboutwhat's going to happen
* Now that the web audio API is there
* You can just sense this hugeamount of music interactive music, and reactive music andmusic instruments on the web
* This huge kind of number ofapplications just about to spill over >> Oh for sure
* >> it's almost as if [INAUDIBLE] yeah
* >> I would say right now peopleare really experimenting, they're trying to figure out what'spossible like through this course
* >> Mm.>> Once people become more comfortable with the technology, once theyunderstand, what can they do with it
* What are the limits
* And then once they start pushingthose limits, I'm extremely excited
* >> Yeah.>> Extremely excited
* >> Well, that's great
* I really appreciate you coming down andtalking to us
* I know that you're very busy,and you got to shoot off now and talk to some other music types
* But yeah.We are going to go through some of our some of our web audio API kind ofbased synthesis stuff now, and, and yeah, I just kind of of,we're just going to give you a quick burst of what it sounds like andthen kind of, you know
* Yeah, this is the one
* So this is the app that we'regoing to be talking about
* [MUSIC] So you get the picture
* [MUSIC] So that's what we're working on today
* >> Mick, thank you very much forinviting me
* >> That's great.>> You're a true musician, gentleman and scholar
* >> [LAUGH] Yeah, well,that's what they all say
* [MUSIC]


--- SKIP ---: 08_5-3-part-2-music-machine.en.srt


--- SKIP ---: 08_5-3-part-2-music-machine.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_5-3-part-2-music-machine.en_SENTbySENT.txt
* [SOUND]
* Okay
* So as you know, we were just talking to Martin, and he was telling us a bit about RJDJ
* We've heard from Marko
* Marko's been telling us about how to use sliders
* and we've also done some stuff last week on sliders and building them and stuff
* And, you know, Matt's been doing this stuff with you about, playing back sounds in rhythm to a sequence
* So, what I'm doing is I'm going to show you an application that we developed, I just briefly touched upon with Martin
* I'm just going to I'm going to set it running again for you
* But I want you to just kind of pay attention to the little things I do
* As I'm doing them, I'm going to briefly explain what they are, then I'm going to go through the whole application in detail
* Explain how it works
* Then we're going to discuss it with me and Marco and Matt at the end just so that we can make sure we've got everything covered
* This is like a fully fledged music application
* It's sonically quite advanced
* It's just bare minimum on the user interface, it just has the interaction, so you could use quite a lot of the techniques that are in this to make your own thing
* But let's just see what it sounds like again and see where we, we are with it
* [MUSIC] Okay, here we are
* So you can hear we've got a drum machine
* Let's just turn the two synths down, so we can hear these these, these drums here
* We've got a bass drum, we got a snare drum and you can see, I'm pointing at a snare drum hit
* [MUSIC] That one and that one
* And there's a blue line that tracks across telling us where in a drum beat we are
* The second line in the drum, in the drum machine is this
* You hear that
* That's the [INAUDIBLE] the clap
* So the claps going on the in between beats in between the base and the snares
* You got a classic techno feel
* And as Matt was saying all of the sounds we're using come straight from your standard kind of 808 or 909 drum machine and thereof [MUSIC] So, what else can it do
* Well, we've got two synthesizers
* We can play these [INAUDIBLE] synthesizers individually, and we can vary a whole range of parameters for them
* They're fully fledged synthesizers
* We can write waveforms for them
* If you're interested in synthesis and you know a little about it I think you'll find this one interesting
* But if you don't, it's still really usable and I need you to get your head around it
* We can write waveforms, we can add a filter, we can change the quality of the filter
* Now let's just have a listen to the filters, I'm want to turn one of them up
* [MUSIC] So here's one of the synths
* I'm going to change the filter
* [MUSIC] [MUSIC] I've also got this resonance
* And this filter out
* We could also change the release and the attack
* So we're giving it an envelope
* And it creates that kind of acid techno feel
* If I change the attack actually with something like this
* [MUSIC] Just makes it quieter
* We can transpose any of the channels
* So I'll change the key of the entire sequence
* And then again
* And then if I want [MUSIC]
* You just go back to where you were, more or less
* and also, I can add some delay
* [MUSIC] And I've got a second one here as well
* Now, the beat that I'm altering at the moment is the actual [MUSIC] [INAUDIBLE] sequence of notes that it plays
* Now, I can select a sequence of high notes, like this, or a sequence of low notes
* And just like in the example that Matt was showing you [INAUDIBLE] [MUSIC] Drum machine
* There's 16 steps, so I can change two of the notes
* There you go
* I've got the fill trap as well and I'll do this stuff
* [MUSIC]
* That's quite pleasant
* We have resonance
* [MUSIC] That's distorting quite a lot
* I don't really mind
* I can add some more delay
* [MUSIC] Add a few claps
* [MUSIC] And some more snares
* Maybe a cymbal
* [MUSIC] You gotta take, So that's a basic music machine
* [MUSIC] It's a common thing that you can easily sell on the upstart for, I don't know, actually music apps
* Let's talk about this for a minute
* Music apps go for quite a lot more money than other kind of apps
* You can sell an app like this for much more than three quid on the [INAUDIBLE] on the IOS app store
* You can probably sell it for five to six pounds or more
* Or if you're in America, that would be dollars
* I imagine that like $8 or $9 out of [INAUDIBLE], what is, what are pounds and dollars anyway
* Who cares
* Anyway, they're much more expensive and they're much more specialist but they're still they're still really useful
* And I think something like this, I mean as something really famous, well, there's a really famous [UNKNOWN] app which is built on, based on a and old-fashioned TV R3 synthesizer and a nice [INAUDIBLE] drum machine in which still sells in it's droves
* And all the people do is complain about how unusable it is
* So I'm not that worried that ours is knocked out quite quickly
* It is knocked out quite quickly, but it is powerful, and you can build on it to do more interesting things
* And you could use some of the other stuff we've done to play some loops
* By there are some complexities to this and I want to show that you know, what they are, so I'm going to quit this temporarily and just go back to the basic version before I continue with that
* Just see you can see in the most simple possible way what it is that we're doing
* So you go all this stuff for free as I was describing before
* as I've said every week, you know, you can just go to your lessons
* but this time we're in week six
* Week six has got a bunch of small tests in it
* It's got a small drum machine, and t's got this thing called synth test
* So, we're going to have a quick look at this synth test
* Just because it's a easier code to, to look at
* It's got the gooey code in it
* it doesn't have the drum machine it just has one synthesizer
* and yeah
* There you go
* It's just one of the synths
* [MUSIC] [MUSIC] Now, [COUGH] so you can see here it's the same, and it basically allows me to set the pitch, change the filter, change the resonance
* Same old same old
* Let's have a look at it
* So we start off as we normally start off by declaring a maxim context
* If I can just make this a little bigger so you can see
* so this is what's happening on the audio
* Behind it, as, you know when Martin was here we were talking about the web audio api
* So, behind this is all web audio
* And the maxim js, the maxim js file, which is here has got all of this stuff in the background
* Now, if you're interested in this sort of stuff, and you want to learn more about how we built Max and JS
* You can always post questions on the forums
* And the TAs will manage those and any really important questions where we feel we've got some material we can really help you with we can point you towards a good answer
* And also there are lots of other places like musicdsp.com and other sites like that can help you understand what it is that's gone into building this
* But you don't really need to if you just want to get started
* We just have to have a context, and Maxim provides the context
* Also, we've got an audio file player
* Actually, we're not using that here, so that's not going to matter
* Instead of using the audio file player, which is what we've been using most of the time, we're using a synth
* So, Maxim can have a synth and I've called this Synth waveform
* Now, the thing about a synth that makes it different to an audio file player is you can write in an array of values between minus 1 and 1
* And that will define the texture of the sound which you're creating
* Now, most synthesizers have a number of different wave forms
* And there's lot of different approaches to creating wave forms
* Um, [COUGH] and in one of the other examples that we've got in this folder there's a really easy way of gyrating wave forms but essentially, you're just writing numbers between minus 1 and 1 into an array which is of a particular length
* So we'll be talking about how to do that in a moment
* So we have our synth
* It's called waveform, and we're writing a waveform into it, which is what makes the sound
* we've got a play head
* Now, the play head, as Matt was describing, is, it's literally the thing which tells us how many, how many frames there have been
* And we use that to work out whether we should trigger a new beat
* Okay
* So we've also got, this array called notes, which is an integer array
* And it holds MIDI notes
* If you know about music, then you'll know what MIDI is
* If you don't really know about music and music technology, you've probably never heard of it
* It's called Musical Instrument Digital Interface
* It's a specification
* For a numbering system that relates to musical notes and musical information
* So these MIDI notes normally what they represent are all the keys on the keyboard
* they're 7-bit numbers, which means that they go for a range of 0 to 127
* There's 128 independent values, the lower, the number, the lower, The note
* So, I'm right down the bottom end of the piano, as you can see
* With all these numbers, zero, zero, zero
* 12, 12, 12, whatever
* okay
* So, then we've got some float variables
* Fc, which is filter cutoff, resonance, attack, and release
* And these are variables which I'm using to control the filter cutoff resonance, attack and release of my synth
* This is my wave table
* Excuse me
* This is my wave table
* Its an array and of float variables
* Like I said its going to be between minus one and one and its got four five hundred and fourteen elements
* Now the reason its got 514 elements its kind of complicated but its because of something called interpolate
* Very briefly what we need to do when we create that way-, when we create a waveform, is we need to make sure that that waveform can playback at various different frequencies
* So it's sound is made up of lots and lots of different frequencies and we measure those frequencies in repetitions per second
* Or cycles per second, and the measurement value we use for that is Hertz
* So for example, if I take a sound, a very small snippet of sound and I repeat it more than 20 times a second we actually hear it as a pitched note, because it's repeating so fast
* And that's what we think of, we think of music
* Most people just think about pitched notes
* So, in order to be able to have a, a wav form which can be played back at 20 hertz, or at the oth- -- at the other end of the scale 20,000 hertz, which is about the highest, frequency that we can hear; in fact, I can't hear 20,000 hertz
* What -- who'm I tryin' to kid
* As you get older, you can't really hear up there
* I probably can hear about 18,000 hertz or, if I'm on a good day, with a good wind
* So, in order to be able to do that, to go between a very low frequency sound and a very high frequency sound, we need to interpolate
* To make the interpolation work, i.e
* to make up the numbers that we need
* because that's what interpolation means
* It means we're making up numbers that aren't there
* What, because we changed the playback rate or the waveform, to make up those numbers, we need some spare numbers on the end
* So it's, normally you have a 512 point buffer, it's called a 512 point buffer because it's, it's, that's the number of points that you run through to make the sound
* But where you've got a couple of extra points on the end, and we're using those for interpolation
* So that's the reason why it's 514
* Okay, so there are out setup options sorry, they're not our setup options, they, they are basically our declarations
* We are declaring all the objects that we need in order to make this program work
* and then what I'm doing is I'm going into the setup function
* I'm just declaring a size
* I'm creating a, I'm calling new on my maxim object, and that means I'm setting up my context
* and then I've gone [COUGH] done, done the same thing to my wave form objects
* I'm, I'm creating new synth
* So the synth is got a, a waveform in it, which is waiting to be populated with something with numbers
* And it's also got all the other stuff that we need delays, filters and that kind of malarkey
* Then we're setting up my sliders
* This is the same as the way Marko showed you to do his
* I've got this, which is delayed time that's dt, dg, which is delayed amount or delayed game
* A, which is attack
* R, which is released
* F, which is the filter cut off
* And q, which is the filter q, which is the resonance, which is what makes it sound, sort of acidy
* so, there are the sliders that we need
* And then I have another multi-slider, which I'm using to enter the notes
* So you can see here, Mark has explained to you how the multi-slider works
* SEQ is also, that's a sequence
* It's a, basically it takes an array
* It takes the array notes
* And then it, it fills that array whenever I interact with the multislider
* Okay
* So I then, I'm loading a file which I'm not using
* So actually [SOUND] we don't need that
* Frame rate is 30
* the frame rate is roughly the speed of the tick rate
* Just like Matt explained
* But instead of running through those ticks, and using them to trigger drum sounds, although we do that in the more advanced example
* In this example, we're just going to use it to select A note from our note array and use it to set a frequency for our waveform generator
* Okay
* So, before we do any of that, we're still in Setup
* And you see the section here that I'm highlighting
* This is me generating a waveform
* So we know that our buffer is 414 points long so
* We want to fill the array, which is 414 elements long with a bunch of numbers between minus one and one
* [COUGH] Now, I'm going for a sorptive wave here so, I actually want the waveform to be 512 points, as I've explained, but with a couple of extra points for good measure
* So, what I'm doing is I'm taking the value, I, and I'm dividing it by 512 to make a value between zero and one
* And then I'm subtracting 0.5 to make a value between negative 0.5 and 0.5
* Now what actually happens when I do that is I, I make a ramp, you know, it's as if, if you imagine that's my array, the ramp goes up like this, so it's kind of an inverted sawtooth wave
* And as it repeats, it drops down, goes back to the beginning, goes up again, and this produces a nice harmonic spectrum that we can filter
* It's a very simple waveform, but it creates all these harmonics And, it pretty much creates every harmonic that we need
* And then, we filter those harmonics out, and add the resonance for that acid sound
* but the values, the actual amplitude is only for minus, naught .5 to 5
* That's absolutely fine
* It's, it's absolutely fine
* We could double it, but then we'd get more distortion
* And you can hear that You know I'd have to do more work balancing this out so it's just to keep the sound within a reaonable range
* So then I make the, the waveform and then I add it to my synth which is called ironically enough or confusingly enough waveform
* So I can set the wave table size I could set it to any amount I like that we've already discussed it's going to be 514
* And then I load my wave table
* In
* Wave form load wave table wave table
* And then it's wave form dot play
* So, that means I've initialized my synthesiser
* I've loaded a wave form
* I can change that at any time, any way that I like
* So you could have 10 different wave forms
* You could have really long wave forms
* You could take a picture of your face, analyze all the pixels, and then use that as a The waveform it's entirely up to you it's just an array of numbers
* So you know be creative and then I'm pressing play what that really means is it's on
* So ready to rock
* In the door method we're doing the same stuff that Marco explained
* We are [COUGH] setting up our sliders Then we get our slider information in the draw method
* So, if f get, basically if we get something from the frequency slider, we set the filter that belongs to the wave form object
* and if we get delay time, then we set the delay time
* Yes unless I'm munging I'm dividing it by fifty just to get it into a decent range
* The same thing to delay gang get and to the huge get
* A get and R get
* Lot's of good gets
* Because we are in the draw method that's a good place to set the display
* So we display everything
* And then we do the business end, which is ticking through the array, which has the notes in, and using that to set the frequencies
* So, playhead ++, every time we enter the draw loop, we iterate the playhead
* So the tick rate is different to the rate of actual playback
* The tick rate Is quite fast, it's 30 frames a second
* We could have 60 or 120
* it can be quite fast
* And a tick rate's normally much much higher than the rate of the rhythm
* So what I've done is I've just said, okay
* Well, every four ticks
* We'll say that's a semi quaver, which is a
* Small chunk of a beat, it's a quarter of a beat, so f play had modular four equals equals zero just the same way Matthews already showed you
* Wave form.ramp, we ramped a [COUGH] knot.5 which is going to be our volume given the attack time..
* Yet
* And what that does is it means that, if the attack time's long, it'll be a slow ramp
* And if the attack time, attack time is fast, it will be a short ramp
* And then, following a ramp, we set the frequency
* Wave form set frequency
* Now, we're using this thing, m2f
* Now what this does is it takes midi notes and turns it into frequency information
* And this is just looking up an array, which is a maxim j s here
* So it's saying okay, if I get a, a number zero, that's going to be a midi note of zero
* if I get a number one, a midi note of one, that's going to be a frequency of 8.661957, which we'll never hear
* But I generated this with an algorithm
* And I just pasted it in, because it saves you having to worry about it
* Okay
* Then we access notes
* We get the play head modulo 4
* Sorry, play head divided by 4, modulo 16
* That's basically saying, okay
* We've had ticks, that's fine
* But this is the note we actually want
* And then we're adding 30, which is a constant, which is just, so if it was zero, then it would actually be 30
* So finally what we do is the next ti, tick we release
* So immediately we release before we then Retriever
* So if player head module [INAUDIBLE] equals equals one we trigger the release, and then we're off
* There are better ways of doing this, but not using processing
* Okay, so as you can see, we've triggered our sound, we've set the note for this particular tick and we've released it
* For the following notes, the following tig
* So the next thing to do is to sort out the interaction
* When mouse pressed, what we do is, we just get the user interface stuff, and that handles all our mouse pressed GUI
* Dt mouse pressed, dt mouse pressed, blah
* Same thing in mouse drags so that's useful for mouse devices
* And in mouse release we we just check one thing
* We check to see if the notes have changed in the array that holds all the notes
* And if they have, then we just populate the sequence sorry, we populate the notes array with the new sequence that's in our sequence similty slider
* And that's what this does, so notes I, which is the current note from 0 to 15, so there's 16 different steps, we flaw this value basically
* So we get the sequencing value
* And then there's a bit of [UNKNOWN] to make sure that it's the right value and we stick it in there, make, we basically convert it from the slider value to a mini value
* We could have used the map function to do that, which would have been easier to read
* But instead of using map, I'm just doing it with standard mathematical operators
* Right
* Now that actually is that, is that first test
* So let's just go back and have a look
* [MUSIC]
* Yeah, that's nice
* And here's the delay time again
* [MUSIC]
* [SOUND] I wanted to just talk briefly about the filter because the filter is quite is, I don't know, it's nice to think about what the filter actually does
* I've already explained that we have a wave form and it goes at a certain rate
* It give us lots of harmonics
* And then we use the filter to block them
* But how that process occurs is kind of interesting
* Basically what the filter does [SOUND] is it, it lets everything through [SOUND]
* Let's just get a single note [SOUND]
* It lets everything through when it's wide open
* [MUSIC] And as we drop it, what it's actually doing [MUSIC] Is this preventing the weight form from moving very quickly
* The filter basically is averaging smoothing out the weight form/g
* The weight form remember is like that
* And it's going really really fast
* Lets say it's going a thousand times a second
* And it's producing all of these harmonics which are
* Two thousand, three thousand, four thousand, five thousand, six thousand, seven thousand, eight thousand, et cetera, times per second, with an altitude drop-off
* And that's making a very bright sound
* That's making that buzz, that nice, buzzing sound that we, we like
* Well, I'm assuming you like that
* If you don't like that [MUSIC]
* That then tough, 'cuz that's the sound it makes
* but the thing is that when we repeat it over and over and over again., we're, actually, when we get to the end of the route, and we drop down again
* That's actually quite a fast move
* And that's what creates all the harmonics
* If we smooth that, it prevents the harmonics from being generated, and it smoothes Filters out that sound, so what we're actually doing is we're averaging the signal as it goes up, kind of
* and that's fine because it's a slow increase, but then when we get that sudden drop, we smooth it in the same way we might blur an image
* And that's more or less how we turn high frequencies down
* So, it's really simple and if you're interested in that process
* There's a number of filters that come bundled with the course air package that we've put together for you
* and they run nicely on Android as well, so you want to have a look at those, they're in the Android package and there's 4 or 5 of them
* And you can actually see the algorithms if you're interested, you can have a look at them
* Alright, so that's how the synthesiser works
* Now, finally, what I want to do is go back to our, A more complex example that combines all the bits together and just talk about how that tinal thing wor, works
* Just a few little things that make it a bit more useable
* so I'm going to go back to our music machine example which is here and I'm going to run it and what's going to happen is
* [MUSIC] It started up straight away [COUGH] and it's distorting beautifully really not bad
* There's very little I have to do now all of it [MUSIC] Make music
* Let's have some bass drums
* I do like a bit of bass drum, can you hear the bass drum
* You can just about, let me knock this one out
* Okay, that's good
* It's quite hard to use that
* You could have a nicer keyboard setting or something like that
* [MUSIC] So let's have a look at what we've done to put the main application together
* So, we've got two synthesizers
* now there's a clever way to do this and there's a stupid way of doing this and just to make your life easier, I've done it the stupid way
* instead of creating an object or a class which is a synth although I've already done that behind the scenes anyway
* But instead of doing that, just so it's clear and you can see how it's done, I've just duplicated all of the codes
* There was actually two sets
* A brighter, cleverer, more engineering savvy method is to make another class that encapsulates all of the sliders
* And then just to create one of those objects and to say where you want Where to put it, so that's something we should have a look at
* There's a good example in all of the current examples that we've given you, there are good examples of classes, and you should have a look at that those
* But I didn't want to do that and find that no-, that some of you didn't really understand that whole process
* So I've just gone through and I've duplicated all of that code
* So basic stuff is I thought well I want it to look slightly better than it currently looks so I've created a brushed metal background
* I've positioned all the sliders on the screen and then I've created this brushed metal background and you see that this is a good tip
* If you can avoid havong to draw Non-animated information
* via algorithmic methods, i.e
* if you can avoid having to apply the interface graphics, do avoid it
* Make a Photoshop image that has your interface
* So I've got a slightly embossed area here and here which these are the panels that hold the information and if I spent more time on that I can make them look really nice and I've fake knobs and switches that I copied and pasted of the Internet
* Or I could photograph my something from my set connection and then put those on them instead
* but I guess what I'm trying to say is you can do an awful lot by preparing your images in Photoshop just like we did last week with the instaspan for the overlay
* It's the same sort of thing
* put the effort in there if it's not going to animate
* Put the effort in in Photoshop, make it look sweet, and then draw it
* I must admit I've not really put the effort in here, but there's a back, there's a basic starting point
* You can see where the panels are; they're sort of lined up
* Another thing you can do is you can put your interactive graphic elements Onto your screen so that you do that problematically then you screenshot it the right size and move that into your Photoshop application and then you can draw on top of it
* I guess it's what I'm saying is do the work in Photoshop is you're not going to have to animate it make it look nice there
* We did exactly did the same thing with angry droids as well we just Do a bit of support work there
* So that's the basic idea, and you can get away with a lot there
* also it's nice to add custom graphics to your sliders, and you can do that too
* So, we've done that
* And then we've loaded it in here
* And then we've done the same thing, exact same thing that Matt did for the drum track
* We created four Boolean arrays
* Track, 1, 2, 3, and 4
* These are for our four drum sounds that were in our drum machine, which is a kick, a snare, a handclap, and a cymbal
* Ideally, I'd have a hi hat
* There is a hi hat knocking around in one of the, folders on the Coursera pack that you've got
* And you can see here, exactly as I said, I just duplicated everything
* So there's the floats that you've already seen
* Except we've added another function, filter attack, which is what gives it that sort of TB 303 baseline sound
* [LAUGH] allegedly
* And then we've got, some transpose functions as well, which allows us to move it around
* We've got a second wave table for the second object
* You can see we've got two syns waveform and waveform two
* And now these are all basically everything that has a two after it is for the second waveform
* We create a bunch of secondary slide and sliders and multi-sliders to hold all the separate information and then we load in some samples
* And then we set up a sliders, so we have twice as many sliders
* But they have slightly different numbers in to re, to represent the fact that they're going to be drawn somewhere else
* Now as I said, you would draw them, screen shot it, import it into Photoshop, do your background, and then just load the background
* Now so we load the background where do I load the background
* Into the bottom of this
* that's the wavetable, exactly the same way as I described in the first example
* Okay the background is loaded, there it is, brushed metal, that's my brushed metal background
* and then here, what I do is I set up the drum tracks in the same way that Matt's already explained
* I just create these boolean arrays, they're either true or false
* And I set them all to false, so they're all off
* Okay, and then we get all the information in exactly the same way, as we did before
* And then we use the same playHead information to get the frequency content for both synthesizers
* And then we use another variable, current b, so we could use playHead if we're using current b too
* It doesn't really matter, it's the same
* To find out whether it's if it's true basically, then what we do is [COUGH] we play that drum sound back
* the mass press stuff is exactly the same, if you click there it sets it And, you've set it to play
* in both mouse press and mouse drags
* And other than that, it's exactly the same as the two examples you've seen
* The basic synth example, and the drum example
* And that's how you end up with this
* [MUSIC]
* [MUSIC]


--- SKIP ---: 10_5-4-outro.en.srt


--- SKIP ---: 10_5-4-outro.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_5-4-outro.en_SENTbySENT.txt
* [BLANK AUDIO]
* [SOUND]
* I have to say that sounds really good
* I'm the one here who isn't a musician, so I can't say much about it, but Matt what is it about that synth that makes it sound well
*  >> He doesn't care
* >> He doesn't care
*  >> He doesn't care, he's playing
* I'm not going to, you know, I'm not going to say anything
* >> I just love this mate, I think it's amazing
* >> Cool
*  >> so we've given you something great here
* You, you really need to, to, to work on this, and, and make it into something individual to put your own sounds in there
* To, to see if you can experiment with, with the length of the sequences
*  >> Yeah
* And you can stick your own waveforms in
* You can change all the sequence lengths
* You could do a proper GUI rather than that bleak affair
* I quite like it bleak
* It's all post-nuclear TV 303
* >> You might, you might try and make it like like a vintage drum machine
* You could get, get an image of a vintage drum machine as you saw in my slides and you could put that behind it, put the buttons on top
* There's all kinds of stuff you can do, you know, you can really get creative with this
*  >> Remember you can use images for the buttons, so that's an easy thing to do
*  >> Yeah, the I quite like the filter, the thing about the web audio equalizer, it has a really, really nice filter
* And I want us to get in
*  >> Okay, come on then
* So, this is really taking me back
* I mean it's, you know
* >> [LAUGH]
* It's that kind of where's it gone
* Where's the sound gone
*  >> It's right here
* It's right here
*  >> Oh, there we go
* Yeah
* [SOUND]
* It's just that filter cut off thing, and with the envelope
* Well, that's neat
*  >> We can really, we can really dig around and get into that kind of [UNKOWN]
* >> So, that's it for Digital Media and Mobile Applications
* And we've been teaching you how to do creative programming
* We've tried to make it as easy for you to get started as possible, regardless of your background
* And give you lots of opportunities to develop your skills both creatively and also technically
* You know, we've created a bunch of programming, languages and libraries
* Well, not languages as such, just libraries that make it easier for you to do the things that you want to do
* and I think that's been quite good
* It's been successful
* They've got a physics engine, they've got a music engine, they've got, what else have they got
* They've got Facebook stuff
* All this different stuff
* And you can just go away
* And if you're interested in following this up and doing some more, but you feel like you want to do some if you, well, let's say you want to be more creative, at [UNKNOWN]
* We run a digital loss computing program which is a combination with the arts department
* that's [UNKNOWN] art department so that program is kicking off right now and you apply for that more or less in the next couple of months
*  >> we also have a Master's program in Computational Arts, and a Master's in Fine Art and Computational Arts, if you're more creative
* We also have a BSC in Creative Computing as well, don't we, Marco
*  >> Yeah
* That's running in London, but it's also running internationally as part of the University of London International Programs
* >> Yes
*  >> So, wherever you are, you can actually take that program
*  >> Yeah, and this is a good starting off point plan
*  >> Yeah
* >> Yeah, yeah
*  >> And that's really what it's been about
* Thank you very much for still being here through all of the coding help
* And but, actually, you know what
* It's exciting when it works and that's what makes it worthwhile
* >> Yeah, and this is so much great stuff, just combine together all of the stuff we have shown you like mix it up, figure out what new things you can do with all the taught we have given you
*  >> And then, send it to us, because we want to see
*  >> Yeah
* >> We really want to see what you're doing
* >> We'd love to see what you're doing
* And we want to hear some more music
* Matt, do you got anything
*  >> Yeah, music
* [MUSIC]
* Matt's actually very, very good at synth stuff
* I built this for you, it's true
*  >> I just love this, it's brilliant, brilliant work
* Have fun
* [MUSIC].


--- SKIP ---: 01_introduction.en.srt


--- SKIP ---: 01_introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction.en_SENTbySENT.txt
* [MUSIC] Hello and welcome to this course onembedded hardware and operating systems
* My name is Marco Ramirez andI will be your lecturer during the course
* Welcome to the University of Turku
* Well, let's get started
* [SOUND] [MUSIC] Cyber physical systems operate at the edgebetween the cyber and the real world and compromise of computational networking andphysical components
* The importance of such systemsis difficult to overestimate
* They are literally everywhere fromthe smartphone to space station
* Hardware is an integral componentof a cyber physical system
* This is figuratively speaking,a foundation of the system
* Therefore, it is important tochoose the hardware correctly
* This choice should be system oriented
* Meaning that the hardware shouldfulfill the requirements of the cyber physical system
* At the same time, the resourcesprovided by the chosen hardware should not be excessive for the system
* Unlike hardware design fora specific purpose, embedded systems require software tofunction and accomplish their work goal
* However, writing this softwarefrom the ground up for every type of hardware is not practical
* The most common approachis to use operating systems to handle the basic task ofmanaging the hardware resources and provide great services foruser applications
* In this course, we will talkabout two components of a cyber physical system namely,hardware and operating systems
* We will give you hints on how to makea proper choice of those components
* I hope this knowledge will boost yourinterest in cyber physical systems and help you to implementyour ideas more quickly
* Good luck
* [MUSIC]


--- SKIP ---: 01_introduction-to-embedded-systems.en.srt


--- SKIP ---: 01_introduction-to-embedded-systems.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction-to-embedded-systems.en_SENTbySENT.txt
* [MUSIC] Hello and welcome to the firstlecture of the course
* This course if called embeddedhardware and operating systems
* This course is a practice oriented guideon how to build an embedded system
* Nowadays, computersare literally everywhere
* They run engines, they encode voice, andconstruct radio signals to use them for mobile communication
* They even control your microwave
* This non-visible computers that make itall possible are called embedded systems
* Although embedded system have receivedmuch attention from researcher in the past,the community has just recently recognized that new approaches are neededto develop and analyze them
* Mainly because they are oneof the most rapidly growing fields in the computer industry
* Considering the transient technology, we can say that such kind of systems willsoon be integrated into more things
* Computer will be everywhere informationwill be available anytime, any where
* As an example of embedded systems,we can think of airplanes
* An airplane is full ofembedded computers in it
* Seats have entertainment systems withvideo, audio and gaming capabilities
* There is an air conditioning systemadjusting the temperature and pressure of the cabin
* On the other hand, the flight management system is heavilyequipped with embedded systems
* There are plenty of different sensorsreporting the situation to the pilot
* Location, weather, altitude, speed, orientation,all these values are constantly monitored
* The autopilot system significantlyreduces the pilot workload
* Wings, jet engines,landing gear, brakes, and so on are controlled electronicallyfrom the cockpit
* So as we see,an airplane is full of computers embedded in different locationswith different functionalities and purposes andwith different requirements too
* What are the main characteristics and constraints of an embeddedsystem used in airplanes
* Well first and the most important one,they have to be reliable
* Sensors should reportcorrect values all the time
* The control system should not make anymistake under any circumstances and must react according to deadlines
* Wings, brakes, landing gear, and so on should follow exactlywhat the pilot demands
* If any of these reliabilityrequirements are not fulfilled, then a catastrophe can easily happen
* What do we mean by reliability,and how to measure it
* Anyway, we will discussit in future lessons
* On the other hand,embedded systems should be secure
* No one must be able to breakin to the control system or the airplane andoverride the sensors and command data
* What else can we think of
* Well another important concern is the realtime behavior of the airplane's systems both in the passenger cabins andin the cockpit
* Passenger expects to watch smoothmovies with no interruption or jitter
* The pilots commands should takeeffect at the right time, and the autopilot system mustnot make late decisions
* Another good example that reflectsthe idea that computing will be everywhere is the Internet of Things
* Indeed, the aim is to spreadnodes around the world
* A node, it's the small embedded systemconnected to sensors and activators
* Nodes will collect data of any kind
* It may be temperature measurements oracceleration
* The data then will be pre-processed inthe fog layer an sent to the Cloud
* There are many problemsto tackle in this field
* Nodes may be located in remote areas, and it is desirable to make the nodes work forlonger
* So energy efficiency is one of the issuesthat the Internet of Things pulls out
* Another issue is makingthe gathered data meaningful
* In other words, it is about gettinginformation out from the messy data
* Here machine learning iscoming into the picture
* So Internet of Things will provide peoplewith a lot of data, which can be used, for example, to optimize processes
* There are many other examples ofembedded systems that are applied in different fields of industry,from home appliances to aerospace
* Now that you probably have a basicidea of what an embedded system is, let's talk about how wecan describe such system
* Well an embedded systemis typically reactive
* This means that such system is constantlyinteracting with its environment and executes with that environment say so
* Reactive systems being in somestate is waiting for an input, performs computations, produces an output,and transits to a new state
* Thus such systems canbe modeled as Automata
* In other words, it is a set of states,inputs, and outputs
* So the abstract model of an embeddedsystem consists of inputs, outputs, a unit to perform computations,and communication interfaces to exchangedata with other embedded systems
* Inputs provide the computationunit with data
* Sensors can play the role of inputs
* Sensors can convert physicalquantities into numbers
* Actuators for example,electrical moderators can be outputs
* In between inputs and outputs thereis a unit called processing element that makes computations on the input andproduces output
* A persisting elementis the digital device
* During the course, we will talk abouttwo types of processing elements and better processors and FPGA's
* In the course, we will talk aboutwhat a processing element is, and how to pick an appropriate one forcertain applications
* We will discuss how embeddedprocessors and FPGA's are built, and how to deal with them
* We also will cover most popular embeddedplatforms, this will be of great interest for those who want to get hands onexperience on building an embedded system
* We will also talk about sensors andactuators, and how to interface with them
* Embedded hardware worksguided by software
* That's why embedded operating systemswill also be covered in the course
* Indeed, the right choice of embeddedoperating system may not only simplify the development, but alsoaffect crucial parameters of the system, such as energy consumption,or computational performance
* This course is intended for those who want to obtain knowledgeon how to build an embedded system
* This is,selecting the appropriate components, based on the requirements you have foryour application
* To ease the process of selection,it maybe important to know how those components work andwhat their main characteristics are
* After selecting those components,they are assembled together, program may have needed and used
* All these steps from selection to assemblyare going to be covered during the course
* So if you want to designyour own embedded system, this course is a good starting point forthat
* [MUSIC]


--- SKIP ---: 02_design-characteristics-and-challenges.en.srt


--- SKIP ---: 02_design-characteristics-and-challenges.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_design-characteristics-and-challenges.en_SENTbySENT.txt
* [MUSIC] Hello and welcome back
* By now hopefully, you have a generalpicture of what an embedded system is
* However, in order to giveyou a better insight, in this video we're going to talk aboutthe characteristics of an embedded system
* We will also discuss the challenges youmay face when developing embedded systems as well as possible design flowsto tackle those challenges
* Any embedded system is built fora certain application, thus the system should fulfillthe requirements of the application
* These requirements dictate thecharacteristics of the embedded system
* In general, we can distinguish several of them thatcan be applied to any embedded system
* In the video,we will highlight some of them
* We will talk about dependability,efficiency, and real-time constraints
* These characteristics are crucial sincethey influence the way the system works
* A lot of embedded systems are safetycritical and so they must be dependable
* A good example of a system whicheveryone would agree should be dependable is nuclear power plants
* They are of course many otherexamples such as airplanes or cars
* Why should these systems be dependable
* The main reason is they are directlyconnected to the environment and if something goes wrong they willhave an immediate impact on it
* Dependability can be split intoseveral sub-characteristics
* The system is considered dependable ifall those characteristics are fulfilled
* An important issue is thatinitially the developers should not focus only onthe functionality of the system assuming that the dependabilitycan be brought in on later stages
* In fact, this approach does not work, because design decisions might not allowachieving dependability afterwards
* For example, if the wrong componentsare chosen for an application, let's say there is not enoughcomputational performance to execute critical tasks on time, It will be verydifficult to deal with it in later stages
* So dependability should be consideredduring the initial stages of the system design
* Efficiency is another issue
* The importance of thischaracteristic comes from the fact that the amount of resourcesis always limited
* Resources can be representedin the form of energy or memory space if it's an embedded system oras money if it's a customer
* Nowadays, small resource constraineddevices such as wearables or Internet of Things nodesare becoming more and more popular
* These devices do not haveconstant power supply
* However, they should last longer toprovide costumers with proper services
* Therefore, energy efficiency ismuch relevant to embedded systems
* How can these characteristicsbe estimated
* In general, Energy Efficiency can beestimated based on the amount of work done by the system consideringthe amount of spent energy
* For example, forprocessors energy efficiency can be estimated based on the numberof instructions per joule
* It is probably obvious that the numberof operations per joule is increasing as technology advances
* If we make a quick comparisonof the current technologies, we can conclude that the moreapplication specific the components are that the moreefficient the application is
* According to that, processors offerthe least energy efficient solutions
* Whereas, application specificintegrated-circuits are the most efficient ones
* In an embedded system, hardware andsoftware play equally important roles
* If the running software does notexclude the underlying hardware at its full potential Thenrun-time efficiency will be poor
* Inefficiencies cost by poor mappingof the application to platforms should be avoided
* For instance, compilers shouldnot bring in overhead which will eventually leavetwo of wasted energy
* Code size is another issue that needs tobe addressed when it comes to efficiency
* Devices capable of loading additionalcode dynamically are still rare
* Usually an embedded systems codeis stored within the device
* Therefore, it should occupyas less space as possible
* The physical appearance ofthe system is not less important
* Portable devices should be lightweight soto be more attractive to customers
* The last but not the last parameter thatinfluences the overall efficiency is cost
* The system should be built usingas little components as possible to implement the required functionality
* Embedded systems shouldmeet real-time constraints
* If computations are not finished in time, the quality of the solutionmight decrease
* Sometimes, violating real-timeconstraints may actually lead to more serious consequences, which willmake the system less dependable
* Of course, not all embedded systemsshare the mentioned characteristics, but the majority still do
* However, since embedded systems lie inthe intersection of different fields of a study
* There is some haziness in the definitionof what these systems are, and therefore,the set of characteristics may vary
* Considering the above listedcharacteristics of embedded systems, we can think of challengesthat developers might face
* The dependability level of embeddedsystems goes beyond the level for PC-like systems
* A real life example of the effectsan undependable system can have is what happened in Southern Californiaback in 2004
* When due to technical problems,the air traffic control center could not operate andmany airliners were held to the ground
* This s the kind of situations thatobviously everybody would like to avoid
* To make a system efficient, software can not be developedindependently of the underlying hardware
* This means that during the initialdesign steps, both software and hardware should be taken into account
* This actually requirescollaboration between the fields of electrical engineering andcomputer science
* The best energy efficiency can be achievedby building application specific hardware
* However, there are downsidesto hardware implementation, it doesn't provide high flexibility
* It is also expensive andrequires long design times
* Embedded systems development is aboutfinding the right balance between efficiency and flexibility
* Embedded systems interactwith the physical world
* This fact has additional implications
* For instance, developers must checkif real-time constraints are met
* It should be also considered,that real systems are concurrent
* Managing concurrency isanother important challenge
* Embedded systems may consist of manycomponents, such as processing elements, input-output devices, andcommunications units
* This means that the impact of combiningthese components should be studied and considered
* For instance, it is desirable to know how one componentmight influence the other components
* In order to makethe design process easier, it should be broken intoseveral soft tests
* These self tests should beperformed sequentially and some of them can be repeated
* Also, it is important that all solutionsand methods are reused whenever possible
* Designing starts from an idea which shouldbe converted into a design specification
* Special repository should be created where the relevant designingformation will be stored
* The repository will lead the developer'sto keep tract of the design
* It is also good if the repository providesversion control to make it possible to roll back to previous versionof the design at each iteration, the repository should be updated
* During the design process, applicationsare mapped to the platform iteratively
* In each iteration,new design information is generated
* The information comprises the mappingof operations to hardware or software
* Computation andscaling in each step the design should be evaluated considering perimeterssuch as dependability, performance, energy consumption and others
* During the intermediate steps there is nowarranty that the design will be correct that's why the design shouldbe validated in each step
* As it was mentioned before, the system should be efficient,that's why optimization is important
* To ease the design process, you might beinterested in different design models
* These models clearly show the differentsteps that must be performed
* For example, the waterfall modelis a sequential design process where development proceedsfrom the top to the bottom from obtaining the requirementsto the maintenance
* In order to use this model, the designprocess should be thought through very well because after the factchanges are very costly
* The iterative model doesn't havedimension drawback since before deployment the design goesthrough testing, evolution, implementation every as many timesas needed to meet the requirements
* Well, this is all for this video
* We discussed the main characteristics andchallenges of embedded systems
* In the next videos,we will go into interesting details and we will discuss moreabout embedded systems
* [MUSIC]


--- SKIP ---: 01_input-output-devices.en.srt


--- SKIP ---: 01_input-output-devices.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_input-output-devices.en_SENTbySENT.txt
* [SOUND] Hello and welcome back to the course
* In this video, we're going to talk abouthow to get data into the processing element as well as how to transferthe data from the processing element
* A processing element is a digital device,which makes computations
* The computationsare performed on some data, which is stored in memorywithin the processing element
* However, initially the memory is empty,so where to get the data from
* I would like to introduce heretwo concepts, input and output
* As you may guess, the input comprisesthe whole set of devices or units through which the data can bedelivered to make computations on
* On the other hand an output is a device orunit that help to transfer processed data from a processingelement to other devices
* Input/output devices sharesome characteristics
* However, let's talkabout the inputs first
* Input devices are meant fordelivering data to the processing element
* In some cases, the microcontrollers havedifferent peripheral units that play the role of inputs, for example,communication units such as UART or SPI
* An analog to digital converter canalso be considered as an input device
* These peripheral units might be locatedinside of the microcontroller and exposed to the user through external pins
* By the way,general purpose input/output pins, as you might guess from their name,can also be used as an input, regardless of any peripheralunit being attached to them
* There are many ways to classifya microcontroller's inputs
* However, among all of them,I would like to mention the one which separates inputs into two categories,serial and parallel
* As an example you can think of serialperipheral interface and GPIOs
* Inputs can also be classified accordingto the type of signal they handle
* This way an input may be digital,for example SPI interface, or analog, such as an analogto digital converter
* The next question I would like to cover is how to actually readthe data from those inputs
* The details of how to dothat may be quite different depending on the inputunit you want to use
* Let's consider an SPI interface and an ADC, which are clearly verydifferent kinds of units
* The first one is meant to communication, whereas the second one convertsanalog signals into a digital form
* Because of their fundamental differences,we can expect their operation details to differ very much as well asthe methods for reading data from them
* However, from a higher abstraction level,we can distinguish two ways for doing this
* The first one is to readthe input every once in a while, let's say once every 100milliseconds interval
* In this case, the read operationis initiated by the software
* Therefore, we need write a pieceof code that gets the data from the input unit atthe chosen interval
* In our case, the interval is 100milliseconds, but it can be adjusted
* Now, let's think about the following case
* What if we are interested in knowingthe time when an event happens
* For example, we need to know whenthe voltage level on some pin rises from logic zero to logic one
* What time interval do we choosein order to catch such event
* You can make an assumptionthat the shorter the interval, the more frequently we check the input,and therefore the less the probabilitythat we will miss the event
* This is of course true
* However, if we think of the amount oftime the processing element will spend on checking if the event has occurred,we will conclude that such approach is not efficient since a lot ofcomputational power will be wasted
* Luckily, there is anotherway of catching fast events
* If the first method wassoftware initiated, the second way is hardware initiated
* It is based on interrupts
* When an event occurs,it causes an interrupt, which in turn breaks the flow ofthe main program and reads the input
* The second method is more reliablein the sense that it is less likely to miss the event
* To make sense of the received data, the communications unit used as inputmust be compatible with the sender
* This compatibility shouldbe at the protocol level
* This means that signalsused follow the same rules
* For example,if SPI communication protocol is used, the sender and the receiver shouldwork according to this protocol
* It is also important toconsider voltage compatibility
* The signals should be preferablyused the same voltage, let's say either 3.3 volts or 5 volts
* With outputs,the picture is pretty much the same
* Peripheral units can be used as output
* The interaction with the outerworld is done via external pins
* The classification is also similar,serial, parallel, analog, digital
* An example of an analog output isa digital to analog converter, which converts a numberto a voltage signal
* Communication units, such as UART orSPI, are examples of digital outputs
* Sending and receiving data can besoftware or hardware-initiated
* Let's make an example ofhardware-initiated transfer
* For example, we need to build an analogsignal using a microcontroller
* In this case, we will needa digital-to-analog converter
* The shape of the required signalshould be, for example, sinusoidal
* For that we will keep samples,which are just numbers, of one of the periods ofthe sinusoidal in memory
* What we need to do is to read thosesamples at the right intervals to send them to the DAC
* The right intervals of timeare measured using a timer
* Now, if we want to keepthe shape of a signal stable, we need to rely on hardware
* It can be done in the following way
* A timer marks the right moment andinstructs the Direct Memory Access unit to transfer one sample fromthe memory to the DAC
* After the DAC convertsthe sample to voltage, everything is set to be donewithout the influence of software
* As for inputs, output units shouldbe compatible with the receiver regarding their protocol andvoltage level used
* So in this video we discussed the wayson how an embedded system can exchange the data with outer world, and what are the requirements that should beexpected to make such exchange correct
* [SOUND]


--- SKIP ---: 03_wire-communication-adc-dac.en.srt


--- SKIP ---: 03_wire-communication-adc-dac.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_wire-communication-adc-dac.en_SENTbySENT.txt
* [MUSIC] Hello, and welcome back to the course
* In this video, we are going totalk about wired communication and we will also cover ADCs and DACs
* Since these units convert analoguevalues that are fundamental in our world to a digital form andvice versa
* Let's start with wired communication
* The definition is quite simple
* And as you might guess, wired communication isthe transmission of data over wires
* Wire-based communication
* Communication, regardlesswhether it is wired or wireless, is guided by certain rules
* The set of such rules is calleda communication protocol
* Two devices can communicate with eachother if they use the same protocol
* The analogy that you can think of is twopeople who try to talk to each other
* They successfully understand eachother if they use the same language
* There are many communication protocols
* Some of them are parallel, whichenables high data rate communication
* And some of them are serial like USB
* Which is resource efficient
* If we think of the number ofphysical connections needed to enable the communication
* For embedded systems where we dealwith resource constrained devices, communication is mostlydone via serial protocols
* Such as USB, SPI, UART, and others
* Apart from serial-paralleltype of classification, the communication protocols canbe synchronous or asynchronous
* Synchronous communication protocols utilize common clock betweenthe receiver and the transmitter
* The upside is higher throughput sinceno synchronization data is needed
* Asynchronous protocols donot use a common clock
* Instead, synchronizationbetween the receiver and the transmitter is doneusing synchronization data
* For example, start and stop bits in RS-232protocol are for synchronization purposes
* A good analogy might betwo speaking people
* The listener starts listening attentivelyonly when the speaker starts speaking
* In this case, the first two words ofthe speaker are for synchronization
* They make the listener startreceiving the verbal information
* The upside of asynchronous communicationprotocols is that there is no need of an additional wire or a common clock
* However, such communicationprotocols are slower because some part of the transmitteddata is used for synchronization
* Full duplex, half duplex
* You might have come across such wordsif you have read about communication protocols
* What do they mean
* Full duplex communication isa bidirectional communication that can operate in bothways at the same time
* A mobile phone is an exampleof full duplex communication
* You and your interlocutorcan speak at the same time
* You may not understand anything butstill you will hear your partner and your partner will hear you
* However, half duplex communicationallows only one side to talk
* It is either you or your partner
* A good example of these type ofcommunications are walkie-talkies
* For instance, USB versions 1 and2 are half duplex prodigals, whereas USB 3 has twoadditional pairs of wires
* And this enables fullduplex data transfers
* Now that we mentioned USB, let's give moredetails about this communication protocol
* USB stands for universal serial bus
* In the beginning,USB was using only four wires
* As the protocol evolved,some additional wires were added
* For example, USB 3.0,apart from the mentioned four wires, uses two additional twisted pairs
* As mentioned before, these additional wires introducefull duplex capabilities to USB
* Data rates also varyquite significantly if we compare the initial versionsof the protocol and the later ones,from 1.5 Mbit/s to 10 Gbit/s
* The structure of a USBnetwork is a tire star
* It consists of one or more USB devices
* One or more hubs and host or controller
* Only one host exists in the network
* The hubs are the nodes to whichdevices and other hubs can connect to
* The host polls the hubs forchanges in the network
* Thus, if a new deviceappears in the network, or if the device is unplugged,hubs will notify the host about that
* All devices that can use USBare grouped into several categories
* Each category represents the functionalitythat the device can provide to the host
* So what is a structureof the protocol itself
* Data is sent using transfers
* Transfers consist of packets
* There are four main types oftransfers in USB protocol, control, bulk, isochronous, andan interrupt transfer
* Each packet consists of bytes, andeach byte serves for a certain purpose
* For example, sync byte is used forsynchronization
* And PID byte contains the packet id
* The packets can alsobe of different types, token, data, handshaking, or a descriptor
* SPI is another communication protocolwidely used in embedded systems
* SPI stands forSerial Peripheral Interface and uses four wires for its operation
* The protocol can operate with onemaster and one or several slaves
* The data is being shifted bit by bitfrom the master to the the slave
* As well as from the slave to the master
* Shift registers are connectedinto a circle in a way that when a bit is shifted in a slave register,a bit from the other end of the register is shifted out andshifted into the master's register
* There is also a possibility to connectslave devices in a daisy chain manner
* In this case, the shift register of,let's say, slave 0, will be connected withthe shift register of slave 1
* In order to make a processing elementdeal with the outer physical world, the physical values which represent,for example, the amount of light or pressure, temperature, orvoltage should be converted to numbers
* And all the way around, they shouldbe a possibility to convert a number into a physical value,let's say a voltage level
* Luckily there are special kinds ofconverters which can solve this problem
* They are analog to digital converters anddigital to analog converters
* Their main objective is to convertvoltage levels to a number, and back from a number to a voltage level
* Among the large variety of parameterswhich describe these units, let's emphasize some of them
* Resolution is the minimal deviation of thevoltage that can be detected by an ADC
* Or, if we reformulate the definition for a DAC, the resolution of the DACis the minimal difference of an input number that yetleads to a different voltage level
* The resolution is the quantityof digits in a number
* Which is the result ofa conversion from an ADC or the initial value of a conversion fora DAC
* Thus, if we have 8-bit resolution, ADC, that means that the resultcan take 256 possible values
* Other parameters are the conversionrate which defines the number of conversions that the ADC orDAC can make in one second
* And the conversion time which specifiestime needed for a single conversion
* How does the conversion actually happen
* There are several methods and one of them I will elaborate on,is successive approximation
* An ADC which exploits thismethod has a DAC inside
* It works using binary search
* Initially, we apply an inputvoltage level to the ADC
* And we set the most significantbit of the resulting number to 1
* Then this number is convertedby the DAC to voltage
* If the obtained voltage ishigher than the input voltage, then the most significant bit stays 1,or else it should be set to 0
* Then we shift to the next bit, set itto 1, convert the number to a voltage, compare the resultingvoltage to the input voltage
* And if the resulting voltage ishigher than the input voltage, then the bit remains 1
* Otherwise, it resets to 0
* Thus, we go through each bituntil we obtain the final number
* For DAC, one of the methods iscalled pulse-width modulator
* The input number definesa Duty cycle/Period ratio of the generated pulse signal
* The generated signal is fedto a low-pass filter, and at the output,we have a constant voltage level
* ADCs and DACs can be eitherpart of bigger divisors, for example, microcontrollers, orthey can work as a stand alone unit
* Particles, we also explain howanalog to digital conversion and digital to analog conversion work
* Thanks for watching, andI'll see you in the next video
* [MUSIC]


--- SKIP ---: 05_sensors-actuators-interrupts-vs-polling.en.srt


--- SKIP ---: 05_sensors-actuators-interrupts-vs-polling.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_sensors-actuators-interrupts-vs-polling.en_SENTbySENT.txt
* [MUSIC] Hello and welcome back to the course
* In this video we will elaborateon sensors and actuators
* You will get an insighton where they are used
* We also will discuss what obstaclesyou might encounter on the way while working with them
* And in the end, I will talk abouttwo ways on how to read input data, namely polling and interrupts
* Embedded systems deal withthe real physical world
* Physical quantities of the real worldcan either be used as input for the embedded system orthey can be altered by such systems
* Sensors are meant formeasuring physical quantities
* In a sense, sensors help to converta physical quantity, such as, for example, temperature, pressure, oracceleration into a number
* So sensors map a physicalvalue to a number
* There are examples of sensors
* A temperature sensor convertstemperature to voltage
* An accelermator converts accelerationto voltage and many others
* Sensors can have a processingelement on board
* So they can have a digital output
* Actuators are used to alterthe physical quantity
* In contrast to sensors,which are driven by the physical quantity, actuators are driven by a processingelement or in other words, by a number
* Electric motors are a goodexample of actuators
* A sensor's work range is limited
* For example, a temperature sensor canoperate in the range from -20 degrees Celsius to 50 degrees Celsius
* Obviously, this should be taken intoconsideration, when using such sensors
* If the sensor is used out of its range,then saturation might occur
* It means that the mentioned temperaturesensor will show the temperature 50 degrees, when the real temperature is,let's say 60 degrees
* To be used by processing elements, themeasure of quantity should be quantized
* What does this mean
* During the process of quantization,the quantity is being mapped to a number
* It happens with some error becausethe number of values is limited
* For example, there are only 8bits to be used for quantization
* So in total we have 256 numbers
* This means that our initial quantity willbe mapped to one of those 256 numbers
* The quantity will be mappedto the closest number
* Thus quantization is done with some error, which is the difference between the realvalue and its quantized representation
* For some applications, it may benot enough to have just 256 values to represent the whole rangeof changes of some quantity
* In this case, the number of bits or in other words the resolution shouldbe increased to 9, 10 bits or more
* Sometimes the only way to increasethe resolution is to change the hardware
* At this pont, you can think of the cases where thequantization error will be the largest
* Another issue that needs to be consideredwhen dealing with sensors is noise
* Measurements alwayshave a noise component
* We can say that a measurement is the sumof the real value and the noise
* If you think of an accelerometer, then the noise can be causedby some random vibration
* The influence of noise can bereduced when processing the results
* Filtering is one of the examplesof how the noise can be reduced
* We talked about quantization, however the quantization processis done at some moments of time
* The quantization in timeis called sampling
* Sampling is done with some period T
* It may be obvious that the smaller the T,the higher the sampling frequency and therefore the more datawe will have per second
* However, it is not always necessaryto increase the sampling frequency
* We will not go deep into the details, although I would like to mention that itwas proven by Nyquist that the sampling frequency should be at least twice thehighest frequency contained in the signal
* If the signal is sampledat a lower frequency, we may get wrong informationabout the signal
* However this is only relevant ifthe shape of the signal matters to us
* In many other cases, especiallywhen the signal changes slowly, for example temperature under normalconditions does not change fast
* Might not been necessary touse a high sampling frequency
* A processing element can read datafrom a sensor once in a while
* Let's say we use a timerof the micro controller which marks off 100 millisecond intervals
* Thus we can obtain dataevery 100 milliseconds
* This approach is good enough fora slow processes, however when there is need to catch a fast event andwe don't know when exactly it will occur
* This method is not a good choice
* We can adjust the intervalbetween two successive reads, for example, we can make it smaller
* In this case, the probabilityof missing the event decreases
* This approach is called polling
* So when polling, the processing element checks if the eventhas occurred within some time interval
* The interval can be adjusted
* So what are the downsidesof this approach
* The main drawback is that the approachdoesn't allow to catch fast random events
* Another disadvantage is that a processingelement spends its time polling
* And the smaller the interval,the more time is spent
* Here, this means thatcomputation power is wasted
* So is there a way tocatch fast random events
* Let's consider that we havea microcontroller as a tool for that
* With the power of interrupts,it is possible to catch fast events, and what is more, to estimate atthe time when the event occurred
* An interrupt is a hardware based wayto break the main flow of the program, which means this method is fast in the sense that the hardwarereacts quickly to the event
* Furthermore, it gives control tosoftware to process the event
* So what are the off sites of interrupts
* First, when we use interrupts,the processing element does not spend computation power to actuallycheck if the event occurred
* An interrupt happens almost at the sametime when the physical event occurs
* Micro-controllers have one orseveral external interrupt pins, which gives a developer the possibilityto process the incoming event
* A raise or fall of voltage onthe corresponding pin can be an event
* An interrupt might also happen when forexample, the ADC conversion has finished, or when some data has come tothe receive buffer of the UART register, which is very convenient
* What is left for the developer is just totake their result of the ADC conversion, or their received UART data, and use it
* An interrupt service routine canbe used to process an interrupt
* It can be written by a developer
* It is good practice to makeinterrupt service routines fast
* Because they break tha main program flow,and might block other interrupts, or the execution of other tasks
* In the video we talk about sensors andactuators as the ways the processing elementcommunicate with the physical world
* We also discussed the ways on howthe input data can be obtained
* So thanks for watching
* I hope this module has beeninteresting for you and I look forward seeingyou in the next module
* [MUSIC]


--- SKIP ---: 01_embedded-processors-and-fpgas.en.srt


--- SKIP ---: 01_embedded-processors-and-fpgas.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_embedded-processors-and-fpgas.en_SENTbySENT.txt
* [MUSIC] Hello, I hope by now you havea general idea about embedded systems, the challenges that lie in this field,and their main characteristics
* In this lecture, we will go into details of what componentsthe embedded systems consist of
* We are going to start bydiscussing on processing elements
* In the course,we will cover embedded processors and field program level gate arrays, FPGAs
* So in the end of the course,you are capable of selecting a proper processing elementto implement your own ideas
* So here, I would like to startby giving you some ideas on what embedded processors andNetFPGAs are
* Well, we discuss embeddedprocessors first
* So what is a processor
* It is an electronic devicethat works sequentially
* This means that a processor makescomputations in a serial manner, one after another
* Any computation,no matter how difficult it is, can be split into simpler,let's say sub-computations
* Those sub-computations mightbe split even further
* An elementary piece of computationthat cannot be split anymore is called an instruction
* Any piece of computation, given by let'ssay by our programmer, in order to be executed on a processor, should besplit into a sequence of instructions
* Different kinds of processors canhave different instruction sets
* They are different for example,in the number of instructions or let's say in how complex simpleinstructions are in the sets
* So what is good about this approach
* And there should be oboisily somethinggood in it since nowadays processors are widely used
* The good thing is it's flexibility
* Nearly, any piece of computation can berepresented as a sequence of instructions and therefore executed on a processor
* That means we change the behaviorof an embedded system just by changing the sequence ofinstructions it's processor executes
* In other words,we only change the software
* There is no need to changethe architecture of the processor
* The generality of such approach is thereason why it is used massively nowadays
* Let's just think about the huge numberof applications that can be run on, let's say, Cortex processors,which are present in smartphones, servers and many other devices
* One metric for processors, as mentionedbefore, is the instruction set, which actually defines the innerstructure of a processor
* If we compared reduced instruction setcomputers and complex instruction set computers, we will notice thatCISC instruction set is larger
* And it has more complex instructions, so how does it influencethe complexity of hardware
* We are not going to godeeply into the details, but at least we can concludethat the piece of hardware that the codes instructionsshould be more complex for CISC
* One of the most prominent representativeof Sisk is Intel's X86 processors
* Though in this course, we are not targeting this kindof big general processors
* I could not not mention a more kind of embeddable processors are forexample RISC micro controllers
* If we look at Atmel's AVR family wewill find a large variety of options for embedded applications
* Advanced RISC, arm processors, as was mentioned beforeare widely spread nowadays
* They've arrived from Cortex M toCortex A family which are meant for different application domains interms of competition out performance, energy efficiency and others
* In further lectures, we will give moredetails about processors in general and microcontrollers in particular
* So just how instructions are executed,what peripherals are used, what platforms exist, so stay in
* Now that you have an insight on whatthe nature of an embedded processor is we can move to the secondrepresentative of processing elements
* Field-programmable gate arrays, or FPGAs
* Well, it is of coursean electronic device, but unlike a processor it is meant formore application specific designs
* So what does it mean
* First, let's have a quicklook at what an FPGA is
* FPGA has reconfigured a logic with them
* To make a simple example,let's say we have two input and gates
* What kind of logic can we implement
* We can for example use only one gate andimplement a simple logic and function
* However, we can implement a more complexcircuit if we use both and gates and connected the output of the first gatesto one of the inputs of the other gate
* So, if a certain application demandsthe use of two gates, we can use both
* This is a simplified way to explainwhat can be done with an FPGA
* An FPGA has many logic blocks in sight,and when needed, these blocks can be connectedtogether to build complex circuits
* These connections, the inner structureof the FPGA has to be configured according to the application'srequirements before the execution
* So, when we deal with an FPGA,we make changes on a hardware level and FPGAs hardware design is meant forcertain applications
* You can see now that thereis no such flexibility for FPGAs as there is for processors
* We need to change the hardware design for an FPGA every time thereis a new application
* There is no flexibility
* The reasonable questionis why then use an FPGA
* Flexibility comes at the cost ofperformance, and energy consumption
* Indeed, in most cases, the sameapplication implemented on an FPGA, executes faster and consumes less energythan if implemented on a processor
* There is one more thing which one needsto consider when working with an FPGA
* An FPGA design is parallel in a sensethat there is no sequence of operations
* Things happen in parallel
* A good example is a four loop
* If the loop is executed on a processor, itwill be run one iteration after another
* However, if the loop isimplemented on FPGA, a separate surrogate foreach iteration will be generated
* In a sense, iterations exist in parallel
* Now you can probably concludethat a FPGA is meant for computationally heavy applications
* Such as for example,image processing or big data analytics
* It is also interesting that an embeddedprocessor can be implemented on an FPGA
* In this case,a processor is the application itself
* There are several FPGA vendorsavailable in the market
* The living one is Xilinx, which has a wide variety of deviceswith different characteristics
* We will discuss the main ones as wellas the inner structure of an FPGA in the following lectures, sothere are interesting things ahead
* Well, to sum up the video, I wouldlike to emphasize the main differences between a processor and an FPGA
* Because these differences will impact thechoice when selecting a proper platform to work with
* A processor has a sequential natureat its core and provides flexibility
* Whereas, an FPGA is more applicationoriented and provides hydro performance
* If the main goal is efficiency, thenan FPGA would probably be a good choice
* On the other hand, if we needto build a generic platform, and we have either no specific application or many applications in mind, thena processor would be a suitable solution
* And also it is worth mentioningthat sometimes the optimal solution lies between two limits
* So a combination of a processor withan FPGA may be a powerful tool
* Thank you for watching, andsee you in the next video
* [SOUND]


--- SKIP ---: 02_main-features-of-embedded-processors.en.srt


--- SKIP ---: 02_main-features-of-embedded-processors.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_main-features-of-embedded-processors.en_SENTbySENT.txt
* [SOUND] Hello, and good to see you back
* Let me make a small recapabout the previous lecture
* In the previous lecture,we went more technical, and gave a general definition of a processor,and an FPGA
* We also made a comparison between thesetwo types of processing elements
* I hope you remember the main differencebetween them, which is sequential nature of a processor,versus the parallel nature of an FPGA
* I hope now you have some basic intuitionon what a processor and FPGAs are
* In this lecture, more details onan embedded processor will be given
* And we will also discuss the mainfeatures of an embedded processor
* First of all, a processor is an electronicdevice that executes instructions
* The processor does notunderstand anything but numbers, and can work with andmanipulate only numbers
* So instructions are not an exception
* They are numbers
* However, unfortunately, humans are notas fast with numbers as processors
* So instructions are described with wordsto make them comprehensible for people
* All the instructions are stored in memory
* And they are fetched from the memory,one by one, to be executed
* Obviously, there is a wide rangeof different applications that can be run on a processor
* And it is clear that one type of processor cannot deal with this range ofapplications in an equally efficient way
* So it makes sense to have severaltypes of embedded processors, which are dedicated to certaintypes of applications
* To make an example, let's thinkabout signal processing techniques, which are used for image processing
* Signal processing has different, basiclinear algebra routines in it's core
* DSP Processors are designedspecifically for signal processing, which have dedicated units that dealwith those routines efficiently
* During our course we will mostly talkabout Microcontrollers, or MC use
* And here I want to mention thatMicrocontrollers are meant for general purpose applications, and most ofthem are resource constrained devices, which are not meant forcomputationally intensive tasks
* There are also GPUs with thousandsof cores within, which are meant for extremely computationally demandingtasks like graphics rendering
* Of course it is sometimes challengingto choose in a specific type of embedded processor
* Therefore, we have severalmetrics to make such choice
* Some of them, performance,energy consumption, versatility, and cost
* As it was said a bit earlier, it is not possible to cover all the typesof embedded processors in this course
* However, we are going toelaborate on microcontrollers
* I am going to shortly explain each of themain characteristics of a microcontroller
* A microcontroller has inits architecture a CPU, which is in charge of fetching,decoding, and executing instructions
* The arithmetic logic unit is the unitthat actually performs the computations
* Data is loaded into the CPU'sregisters from the data memory using special instructions
* In the same way, the result ofcomputations can be stored in memory
* The program is stored in a programmemory as a sequence of instructions
* In order to keep track of wherethe execution is in this sequence, there is a program counter
* There is also RAM memoryavailable in microcontrollers and some kinds of non-volatile memory,such as EEPROM
* Microcontrollers include different kindsof peripherals such as communication units, timers, ADCs, DACs, etcetera
* If we think about the instruction'sexecution, the question that arises is, when is it time to actuallyexecute an instruction
* The answer is thatthe execution is clocked, so it happens according to a clock frequency
* Each instruction takes on one orseveral clock cycles to complete
* From this, you can conclude that the executiontime depends on the clock frequency
* The clock frequency ofmicrocontrollers can derive from several megahertz to severalhundreds of megahertz
* There's a special dedicated unit called Clock Control unit that it'sresponsible for managing clocking
* For example, this unit can scaledown an input reference frequency or multiply it to obtaina higher club frequency
* A microcontroller may have severalsources of clock frequency
* One of them is an internal RC oscillator
* However, the stability of this kindof oscillators is low, that's why external clock sources such as an externalquartz resonator, might be used
* It is important to introducethe notion of an interrupt, since it is a powerful toolto handle real-time events
* An interrupt isa hardware-generated signal
* Indeed, interrupts are meant to breakthe execution flow of a program when some external event happens
* For example, assume we havesome communication unit, and we want to check if there isnew data in our receive buffer
* One way to do it would beto write a piece of code that checks the inputbuffer once in a while
* However, this approach doesnot allow to know precisely the time when the data arrive
* So there is an alternativeway to manage this task
* We can adjust the microcontroller ina way so the execution of the main program is interrupted preciselywhen the data comes into the buffer
* Moreover, when a certain interrupt occurs,the program counter jumps to a specific location in a programmemory assigned to this interrupt
* An interrupt service routine,written by a programmer, can reside in this memory location
* Once the interrupt serviceroutine is finished, the program counter jumpsback to the main program
* Each interrupt can have a priority
* If two interrupts happen at the same time, the one with the higher prioritywill be processed first
* A standalone CPU is useless ifit is not supplied with data
* Peripherals are exactly for this purpose,to give a CPU data to work with
* Peripherals can be classifiedinto several groups
* First, communication units such as SPI,I2C, UART, Ethernet, and others
* All these units work basedon specific protocols
* Next, there are analog unitswhich deal with analog signals
* There are ADCs for convertinga voltage level to a number, and DACs forconverting a number to a voltage level
* Timers constitute another group
* They are powerful tools when it comes todealing with clocking and timing issues
* With the help of timers,PWM can be generator, or they can be used tomeasure time intervals
* There are units to manage memory
* One of them is DMA, which it stands forDirect Memory Access
* This unit can transfer data fromone location of memory to another without the CPU's intervention
* Energy efficiency isan important issue nowadays, and microcontrollers offer flexiblealternatives to address it
* Modern MCUs have multiple powermodes that provide developers with fine grain control over the powerconsumption of their applications
* This way it is possible to power offthe CPU, the peripherals, or both of them
* Microcontrollers have differentprogramming and debugging interfaces
* One of the most widely used ones is JTAG
* JTAG programmer is a convenient tool,especially when it comes to debugging
* However, a debugger is not cheap to buy
* A bootloader can be a solution to this
* A bootloader is a program whichresides inside of a microcontroller
* The bootloader receives a program byteby byte via any communication protocol, and writes it into a programmemory of a microcontroller
* Even though a bootloader doesnot allow to debug code, it is a free of charge way toprogram a microcontroller
* This is all I have for this video
* I hope now you have a more in-depthknowledge about embedded processors and microcontrollers
* In the next video we willcover MCU platforms, and we will also describe some realindustrial projects, powered by MCUs
* [SOUND]


--- SKIP ---: 01_use-cases-of-micro-controller-platforms.en.srt


--- SKIP ---: 01_use-cases-of-micro-controller-platforms.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_use-cases-of-micro-controller-platforms.en_SENTbySENT.txt
* [MUSIC] Hello, I'm good to seeyou back in our course
* Before we start with this video, let me remind you what has beencovered in earlier videos
* By now, you should have an idea of whatan embedded processor is and how it works
* You should also be familiar withthe features of an embedded processor
* I must remind you again, that in this course we makeemphasis on microcontrollers
* Therefore, the large fieldof embedded processors is now reduced to only microcontrollers
* After you learn about microcontrollers,the next step would be to somehow put your hands on them andstart actually working with them
* One way to do sois to buy a microcontroller breadboard, set of resistors, capacitors, wires, andwhatever else is necessary to build proper electrical circuits and assemble all thecircuits by yourself on the breadboard
* Well, it doesn't sound coolbecause it's a long process
* And you know there is always one resistorthat you need that is missing, and in the end there will be little motivationto continue playing with microcontrollers
* Luckily, there is another optionto buy a ready made platform with a mounted microcontroller andto start working with it immediately
* And in this video we're goingto talk about these platforms
* Let's start with Arduino
* Arduino is a widely known platform forfast prototyping
* The platform uses Atmelmicrocontrollers at its core
* Overall there are about24 boards available
* On the website, you can find themorganized according to application areas, such as Internet of Things,wearable, and others
* Besides the boards, there are manyshields built specifically for our Arduino devices
* The functionality ofthese shields vary a lot
* For example, with an MP3 shield you canbuild your own MP3 player if you need one
* A Wi-Fi shield is a greattool to build applications let's say in the domainof Internet of things
* And a joystick shield is suitable forcontrol purposes
* So if you want to extendthe functionality of the board and your application,you can plug in a shield
* Luckily it can easily be done thanksto the sockets installed in Arduino
* Arduino also provides its own integrateddevelopment environment for software development, which is easy to use andreally speeds up the development process
* The second platform that I would liketo mention is the STM Nucleo platform
* At its core there are STX complexCortex M microcontrollers from M0 to M4
* So we can choose here between speed andenergy consumption
* The boards also have extension connectors,and the connectors are compatible withArduino shields which is very convenient
* And also there is the so-called Morphoconnector for other kind of shields
* A very convenient feature of this platform is that the programmer/debuggeris mounted on the board
* There in an online ID available for this platform as well as a whole setof tools including operating system, tools, and developer ecosystem forbuilding Internet of Things solutions
* Offline IDEs are also available
* They are more complex than Arduino's one,but they give you morefreedom to the developer
* I would say that this platform is formore experienced users
* Here I mentioned two kindsof general purpose platforms that can be extended with the help ofshields to target some specific areas
* There are, of course,more platforms available on the market
* Some of them target one specific area andmight not be extensible
* So there is a legitquestion you might have
* How do I select a certainplatform from this diversity
* First of all, the choice obviouslyshould be application-oriented
* For example, if you want to dosome digital signal processing, you might want to use microcontrollerthat supports some DSP operations
* If you need high computational power,then cortex M4 or cortex M3 microcontrollers would suit youwell since they have the highest clock frequency among the previousmentioned MCUs
* Therefore your choice would be eitherArduino Due or STM Nuclear Cortex M4 M3
* If the small size is crucial for you andthere is no need of high performance, then you probably wantto check Arduino micro
* It is also important to consider thatplatforms are interchangeable in the sense that the same application can beimplemented on two different platforms
* Something I would like to emphasizeis that a community is crucial when it comes to choosing a platform
* The bigger the community is, the morelikely the problems you might face have already been solved by someone else,in which case you can probably find the answer in the Internet
* Now I would like to show you a realproject that was implemented using microcontrollers
* It is a metering system
* Imagine that we have a tube, and there issome liquid flowing through that tube
* The goal of the system is tomeasure the liquid's flow speed
* Since we know the size of the tube, we need to calculate the volume ofthe liquid during that time interval
* And finally, we need to storethose measurements in a memory
* What is more, the device should haveuser interface, like a keyboard and a small screen
* So, where to start
* Well, we start by dividingthe tasks in two components, the metering unit and the control unit
* The next thing to do would be to decidehow to measure liquid flow speed
* This can be done using ultrasound
* We need to emit an ultrasonic sound,receive it back, and do some spectral analysis toestimate the liquid flow speed
* Don't worry if you don't understandwhat a spectral analysis is
* Here what I want to showyou is the approach
* So we need to do some digital signalprocessing to get the liquid flow speed
* After we get those measurements,we do some simple averaging, and finally we store thoseprocessed measurements
* Okay, so we have a set of tasks,signal processing, averaging, storing, and the user interface
* It would make sense to map the setof tasks onto two microcontrollers
* Let's say signal processingwill be done on MCU 1, and we will call this part the metering unit
* The other tasks will run on the controlunit, which will be implemented on MCU2
* Both parts will be connectedtogether using a UART interface
* Since MCU1 does spectral analysis, Cortex M4 microcontroller would suit well,since it has DSP extensions
* And we will also need an ADC tosample the ultrasonic signal
* On the other hand, MCU2 does notneed to support DSP operations
* But it need to be fast enoughto communicate with a screen and a keyboard while doingthe averaging at the same time
* It should have enough pins towork with a keyboard and at least two UART units to work with the screen andto communicate with the metering unit
* Cortex M3 would fit well
* It is useful to leave some room forexpansion
* This means you might want to have someextra functionality to the device in the future
* Therefore, the selected microcontrollers should have enough resources interms of performance and memory
* Finally, it is important to noticethat the system can be implemented in many other ways
* In this video we discussedthe ways on how to actually start working withmicrocontrollers using platforms
* Hopefully, now you have an idea of howto pick an appropriate platform for your application
* Good luck
* [SOUND]


--- SKIP ---: 02_reconfigurable-platforms-fpgas.en.srt


--- SKIP ---: 02_reconfigurable-platforms-fpgas.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_reconfigurable-platforms-fpgas.en_SENTbySENT.txt
* [MUSIC] Hello and welcome back
* In this video, I'm going to explainwhat a reconfigurable architecture is, and I will also talk about the mainfeatures of field programmable gate arrays as an example ofreconfigurable architectures
* Several FPGA platforms would be introducedto you as well as their main features
* The most efficient approach interms of energy consumption and performance to implement an embeddedsystem is to develop an application, a specific integrated circuit
* However, one of the main drawbacksof this approach is the cost
* Indeed, ASIC development costis much higher than let's say, software development for a processor
* On the other hand, a processor is muchcheaper option to be then embedded system on, but it does not give youa good energy performance trade off
* ASICs processors are in a way, twoextremes, but what do we have in between
* The configurable architecturesare a good compromise here
* These devices can be almost as fastas the special purpose hardware and at the same time, their inner architecture can be changedwhich brings some degree of flexibility
* Field programmable gate arrays are anexample of reconfigurable architectures, that we are going to focus on
* An FPGA is a semiconductor device which can be configured toimplement different algorithms
* I would like to emphasizethat an FPGA implementation is a hardware base approachto realize a certain task
* Meaning that hardware changes,whereas if you use a processor, the underlying hardware stays the same,but the software can be changed
* So what is the inner structure ofan FPGA that allows these devices to reconfigure its hardware
* Its core compromisesa matrix of logic blocks, which can be connected to eachother via special interconnects
* As mentioned before, an FPGA should be configured torealize a certain application
* For that it can be programmedwith a new design
* Program availability wise,FPGAs can be one time programmable
* These type of FPGA's is not meant for applications where in fieldreprogrammability is needed
* On the other hand, reprogram levelFPGAs can be reconfigured by our user many times withoutusing any special equipment
* Now let's go deeper in to the detailsabout the inner structure of FPGAs
* The logic block plays the central role and it can be considered asthe building block of an FPGA
* The features of theseblock might be different depending on certain types of an FPGA
* But it usually hascombinational logic inside which is represented by look up tables
* The lookup table style of the logic was chosen because it makes easy to derivethe functionality of the logic block
* Additionally, the logic block containsa register to implement sequential logic, which introduces clocking andsynchronization into the design and it's a fundamentalcomponent of digital logic
* There are also multiplexersinside of the logic block, which allow to select either the lookuptable or the flip flop output
* Although the logic block is flexibleobviously with only one logic block, it is impossible to implementany kind of logic function
* Complex designs will require manylogic blocks to be connected together
* The special interconnects insideof an FPGA serve this purpose
* These interconnects are an important andone of the most complex aspects of an FPGA since wiring is a globalproperty of a logical designer
* Note that the interconnection betweenlogic elements might be very complex
* And therefore, not only connectionsbetween logic elements are required but also between wires themselves
* An SRAM based FPGA uses a SRAMto hold the information used to program the interconnects
* In a design,it is often necessary to source some data
* For this purpose,there are ground blocks available, these blocks use the same storage thatis used for the look up table function
* The majority of FPGAsnowadays are SRAM based
* SRAM based FPGAs store the configurationdata in static memory
* The drawback of SRAM isthat it is volatile and can't keep the data without power source
* Because of that such FPGAs must beprogrammed or configured upon start
* There are two basic waysof programming an FPGA
* It can be either done in a master modewhen the FPGA gets the configuration data from an external source for example, fromexternal flash memory or in a slave mode
* When FPGA is configured byan external master device
* For example, a processor
* This can be done via dedicatedprogramming interfaces
* It is also worth mentioningthat some types of FPGA support partial reconfiguration, andthere are two types of it
* First of them is dynamic partialreconfiguration, that allows you to change the part of the design whilethe rest of an FPGA is running
* Another one is the staticpartial reconfiguration when the FPGA is not runningduring the reconfiguration
* Before we continue,let's mention the upsides and the downsides of FPGA implementation
* So compared to software solutions,an FPGA implementation is faster and more efficient in termsof energy consumption
* On the other hand, FPGAs lose inmany aspects such as performance and energy consumption to ASICs
* However, FPGA design developmentis much cheaper than ASIC designs
* In other words FPGAs provide a toolthat lies in between fully software and fully hardware implementations
* Due to their reconfigurable nature FPGAsare good for different applications and markets because of the highcost of ASIC manufacturing, it is important to modelthe design before then
* Therefore, ASIC prototyping isone of the application areas for FPGAs which allows accurate modeling andverification as well as rapid software and firmware development andreduces the risk of design errors
* The wide domain of digital signalprocessing can also benefit from FPGAs
* Indeed, FPGAs provide high computationalthroughput by using parallel architectures
* Their ability to reconfigurethe inner hardware enables designers to develop customized architectures forideal implementation of their algorithms
* FPGAs provide cheaper solutions andfaster time to markets for low to medium volume productions
* Compared to ASICs which usuallyrequire a lot of money and time to get the first device
* So you can buy FPGA platformsdirectly from the FPGA vendors
* The biggest FPGA manufacturers are Xilnx,Altera, and Actel
* On their websites, you can find a lotof information about their FPGA chips as well as about the platforms they sell
* It is sensible to make the platform choice based on the application thatyou would like to implement
* However, if you are in the phaseof discovering what FPGA is, the choice can be donebased on other parameters
* For example, the platform can bepicked according to performance or overall amount of resources it has
* Another way to select the properdevice is to choose it based on the field where you like to apply it in
* I will introduce you FPGAplatforms based on Xilinx FPGAs
* Xilinx separates its chips into families
* There are four of them
* Low end devices, 7 devices,UltraScale and UltraScale+
* All families are different from each otherdepending on the amount of available resources, performance andapplication area
* For example, Spartan-6 based platforms arethe most cost optimized solutions, whereas UltraScale+ family provides the highestperformance and integration capabilities
* Here, I would like to introduce youto Spartan-6 based FPGA platform
* This platform is a good developmentenvironment for discovering and evaluating a spartan 6 FPGA family
* The evolution kit has all the basiccomponents for system development, and also provides some example designs tospeed up the discovery of the features such as integrated memory interface core
* So such development platform is a goodstarting point to discover FPGAs
* In this video, we covered importantaspects of recomforial architectures, take a FPGA as an example
* We covered the main building blocksof FPGAs and discussed the platform which might serve as a good start pointfor you if you want to discover FPGAs
* [MUSIC]


--- SKIP ---: 04_embedded-processors-vs-fpgas.en.srt


--- SKIP ---: 04_embedded-processors-vs-fpgas.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_embedded-processors-vs-fpgas.en_SENTbySENT.txt
* [MUSIC] Hello and welcome back to the course
* By now,I hope you know about microcontrollers and NetFPGAs as well as about their features
* In this video, we will show the steps youneed to follow to make them actually work this sequence of steps iscalled a design of work flow
* Obviously, design flows formicrocontrollers and SPGAs are different
* We will start with microcontrollers, so after the application that youwant to implement is selected
* And the choice of the appropriatemicrocontroller platform is done, it is time to actually startbuilding the solution
* First, you may want to selecta programming language that you will use
* There are three popularprogramming languages for microcontrollers, assembler, C, and C++
* Sometimes developers use the languagewhich they know the best or the choice may be dictatedby the project itself
* If, for example,the project is built using C and it will cause less trouble if a projectextension will be done on C as well
* However, the solution can benefit fromeach programming language differently
* Assembler is a very efficientway to build a solution where the generated code is fast andtakes less memory
* Also, assembler lets you investigatethe inner structure of the hardware
* But unluckily, it is less convenient for humans to read a programwritten in assembler
* What is more,the larger the solution becomes, the more difficult it is to maintain anddebug assembly code
* Fortunately, memory cost is low and micro controllers nowadaysare cheaper than they used to be
* This fact enables the use of morehuman friendly programming languages, such as C or C++
* These languages allowdevelopers to build vigor and more complex solutions,which are easier to maintain and extend
* Though, it is still possibleto write assembly code for critical parts of the program,combining C and assembler
* Even though all required tools,such as compilers, linkers, can be used manually, to buildan executable for a microcontroller
* It is often more convenient, to build a solution in an integrateddevelopment environment
* Some vendors develop their own IDs
* For example, Admil, has Admil Studio butthere, of course, more options
* Eclipse IDE is one of them
* This is a free IDE for our range ofplatforms and programming languages
* Usually vendors release supplementarylibraries to ease the use of their devices and speed up the design process
* After the code is written and anexecutable file is built, the firmware can be loaded via programming interface suchas or be a bootloader if it is installed
* The next steps will be to executethe solution, verify it and refine the program if needed
* The design flow forFPGAs comprises design entry, design synthesis, designimplementation and device programming
* Design entry creation includescreating a project and adding it to the project design files
* Those files include the actual descriptionof the hardware that you want to have in one of the hardware description languagessuch as for example, VHDL or Verilog
* Also the design entry might include pinassignment and area constraint files
* In a simplified way an FPGAdesign can be represented as module that has inputs and outputs
* The top module can include many othersmaller modules connected together
* BHDL which is a widely used for outdoor development supports suchmodular style of development
* To make a simple example, let's see how abasic OR gate can be implemented in BHDO
* The description consists of two parts,entity and architecture
* Entity declares inputs and outputs aswell as their types In later stages, this inputs and outputs can be mappedto certain physical pings of an FPGA
* The architecture describesthe actual implementation
* In other words, in the architecturesection inputs are mapped to outputs
* A certain entity may have severalarchitectures before the design synthesis, it is important to verify the designentry by running simulations
* Simulation allows to check if thefunctionality of the design is correct
* During the design synthesis stage,the code syntax will be checked
* The hierarchy of the designwill also be analyzed, which ensures that the design isoptimized for the chosen architecture
* The result of this stage is a Netlist, which is a textual representation ofa circuit diagram or a schematic
* Design implementationconsists of four phases
* They are translate, map,place and route, and program
* During the translate phase,all the input netlists generated by synthesis are merged togetherwith design constraints
* The output of this phaseis a database file which describes the logicaldesign reduced to primitives
* During the map phase,the logic defined by the database file is mapped into the FPGAelements such as logic blocks
* The output of this phase is a circuitdescription file which contains a fiscal representation of the design,map to the components of the FPGA
* Place and route process takesthe circuit description file, places and routes the design andproduces another circuit description file that will be used as input forthe bit stream generation
* Finally, during the last phasefo programming file generation, the actual file that will be used to beuploaded to the hardware is generated
* Now I hope you have an insight ofwhere and how to apply a processor and FPGAs, as well as you knowthe application areas
* As it very often happens, the optimalsolution, lies between extremes
* In a sense, It is also true in our case, where we choose between a processor andan FPGA
* But how to find a solution that isflexible, energy efficient, and fast at the same time
* This is where hybrid platforms, orsystems on chips, come into the picture
* An SoC is a microchipcircuit that integrates all the necessary components fora system into a single chip
* An SoC might leverage advantages ofembedded processors and an FPGA
* Indeed, an embedded processor,surrounded by programmable logic, is a powerful tool forbuilding complex, flexible solutions
* When comparing an SoC implementation with another one where allthe components are not in a single chip
* But let's say spread overthe printed circuit board, the SoC will provide a lower costsolution that benefits from fast data transfers Higher speeds,smaller sizes, and is more reliable
* As an example of an SOC let's takea look at the Xilinx Zynq-7000 chip
* The Zynq-7000 is a hybridplatform that has dual ARM cortex A9 processors and or programmable logic
* An AXI bus serves as a messenger betweena processor and the programmable logic
* The design flow for hybrid platformscomprises both hardware and software development and testing, as wellas system integration as the final step
* There are several representativesof Zynq-7000 family
* They are different in many parameterssuch as the maximum speed of the hardcore processor, amount of available FPG logic,RAM size, etc
* There are also several Zynq-7000-basedplatforms on the market
* They've arrived in the amountavailable resources, sizes and costs
* From PicoZed, that is the smallest andthe cheapest option, to Zynq Mini-ITX that is the samesize as the standard PC mother board
* There are obviously many moreplatforms available in the market than the ones that wementioned in the course
* Each one of them with differentfeatures,platforms are just tools to build on application
* Although the tool itself is important, thepurpose it serves is even more important
* In other words, when selecting a tool,the approach should be application based
* This is all I have for this lesson
* In this video,we discussed the possible design flows for microcontrollers and FPGAs
* We also covered hybrid platforms whichcan provide a more flexible solution for certain applications
* This lesson is also the lastone of this morning but I hope to see you in the next one
* Thank you for watching.


--- SKIP ---: 01_linux-kernel-functions-and-advantages.en.srt


--- SKIP ---: 01_linux-kernel-functions-and-advantages.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_linux-kernel-functions-and-advantages.en_SENTbySENT.txt
* [MUSIC] Hello
* It is good to see you back forthis lesson
* In previous videos we explored,with a bird's eye view, what operating systems are andhow they execute their tasks
* Now we will take a lookinto the Linux Kernel to discuss some of its characteristics
* At the end of the lesson you shouldunderstand the main Linux Kernel functions and it's advantages
* Let's begin with some questions
* What is a Linux process
* How does a process operate
* And how many processes are there
* In order to deal with these questions,we first define what are Linux processes
* A process is one of the fundamentalabstractions in Linux
* In short it can be considereda program in execution
* A process encompasses a set ofresources such as processor state, address space, threats and data section
* The Linux Kernel implements a processmanager to keep track of each process
* It does so using processesscriptors which store information such as run state of the process,address space, list of open files, process priority, etc
* A process can be in oneof four possible states
* A running state means the process isalready running or it is ready to run
* The waiting state is used forprocesses waiting for an event or a particular resource
* There are two types of waiting, including interruptible waiting anduninterruptible waiting
* A process is in a stopped state whenit's not eligible for running anymore
* Often, as a result ofreceiving a system signal
* However, in some cases a processthat is being debugged can be in the stopped state
* Finally, a zombie stateis a process occurs when the process is terminated but theKernel has not removed its resources yet
* Next we will focus on memorymanagement in the Linux Kernel
* Actually the memory management system inthe Kernel is a virtual memory system
* This means that all memoryaddresses as seen by user processes are not the physical addressesused by the hardware
* To give you a better idea ofmemory management in Linux, I will discuss its main features
* First is large address spaces
* This means the Kernel allows runningprograms to allocate more virtual memory than the system's physical memory
* The Kernel also providesmemory protection
* This way every process has itsown virtual addressed space
* Virtual addresses spaces are completelyseparated unless a result process running concurrentlydo not effect one another
* Next is memory mapping, which is used for mapping the image of data filesto a process addresses space
* This way, the content of a file is directly linkedto a process virtual addresses space
* Linux also has a mechanism forfair physical memory allocation
* Which ensures that runningprocesses receive a fair share of the system's physical memory
* And last but not least,there is a shared virtual memory
* As mentioned before, each process hasa separate virtual address space
* However, in some cases,a shared virtual memory is necessary
* Let's take a look at an example
* When many processors run, a VAS come in shell instead ofreplicating many copies of VAS
* It is better to have only onecopy in physical memory and those processes can share it
* Now, let's talk aboutscheduling in the Linux Kernel
* Scheduling is very important, since it defines the policyon when a process can run
* This is which process runs first andwhich one runs later
* The Linux scheduler isa priority scheduler
* Meaning, it's policy is basedon the priority of processes
* Every time the scheduler runs, the priority of all processesin the wrong cue is analyzed
* And the process with the highestpriority is allowed to run next
* In systems with many processors,each processor has a separate run queue
* And each processor selectsprocesses only from it's own queue
* However, there may be the case thata processor has along waiting queue
* When compared to other processors
* In this case the Linux scheduler willmove processors from the long queue to the shorter queues
* Does getting a balancedworkload as a result
* In previous videos we define an interruptas an event generated by a hardware component that causes change inthe sequence of executed instructions
* Interrupts can be classified intwo categories, synchronous and asynchronous interrupts
* Synchronous interrupts are producedby the CPU control unit while executing instructions
* They are called synchronousbecause the control unit issues them only after terminatingthe execution of an instruction
* On the other hand,asynchronous interrupts are generated by other hardware devices at arbitrarytimes regarding the CPU clock signals
* The Linux Kernel handles interruptsignals using interrupt handlers, also called interrupt service routines
* The main difference betweeninterrupt handlers and other functions in the Kernelis that an interrupt handler is executed in a special contextnamed Interrupt Context
* To finalize today's talk, I will listsome of the advantages of Linux Kernel
* The Linux Kernel is open source andanyone can contribute to it's code base
* Individuals and organizations alike
* As a result of this
* There is a large community that providessupport and has produced large quantities of documentation, most of itfreely available in the Internet
* The Linux Kernel can be easily customized
* Therefore, there is wide varietyof computer architectures where you can use it
* From small sized microcontrollers tofull fledged minicore processors
* The Linux Kernel is a verycomplex piece of software
* Unfortunately, many of its detailswere not covered in this video due to lack of time
* Functions such as input-outputdevice management
* Interprocess communication
* Security and protectionmanagement are now describe here
* However, to get a comprehensive viewof them, I recommend you to read the Linux Kernel Development bookthird edition written by Robert Love
* Thanks for watching andsee you again in the coming lectures
* [MUSIC]


--- SKIP ---: 02_the-microkernel.en.srt


--- SKIP ---: 02_the-microkernel.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_the-microkernel.en_SENTbySENT.txt
* [MUSIC] Welcome
* It is good to see you back forthis lesson
* In previous videos, we exploreda monolithic kernel and its main features
* Now, we will move into anotherkind of kernel, the Microkernel
* In this video, we will coverthe definition of microkernel, how it compares to the monolithic kernel,and its advantages and disadvantages
* Let's begin with someinteresting questions
* What is microkernel, and what is the main difference betweena monolithic kernel and the microkernel
* Before answering these questions, let's go back briefly to ourlesson monolithic Linux Kernel
* In a monolithic kernel, all importantfunctions and services of the operating system, such as file system and devicedrivers, are executed in kernel mode
* As a result, the kernel is very largewith millions of lines of code inside
* In contrast, in a Microkernel,almost all functions and services are removed from the kernelmode and relocated into the user mode
* As a result, the kernel size is minimal
* At this point, there may bea question raising in your mind
* What is the main function of the kernel,and what does it do if almost allfunctions are removed out of it
* When comparing a Microkernel basedsystem with a conventional one, the main difference is that mostof the operating systems code runs as a separate process,mostly outside the kernel
* Then, the tasks left forthe kernel are only interrupt handling, low-level process management andmessage passing handling
* Now, let's talk about interprocesscommunication in Microkernels
* A common communication method inMicrokernels is message passing
* To better understand it,we must address three issues
* What is interprocess communication
* What is a message, andhow does message passing work
* Interprocess communication, or IPC for short, refers to the mechanism thatan operating system provides for exchanging information amongprocesses a message is simply the data that is transferred fromone process to another using IPC
* In a Microkernel, messagesare passed using message registers
* This is a sending process,writes a message to the register of the receiving process, and only thenthe receiving process can read the data
* Sometimes the data to be sent can belarger than the receiver's register, in which case,the message contains a reference to a shared memory regionwhere the data is stored
* IPC is synchronous, meaning that when a message issent from one process to another, both processes must callthe corresponding IPC operation
* A sender will log until eitherthe receiver has performed the IPC call, or a specified time ofinterval has lapsed
* It is important to mention that IPCdoes not use intermediate buffers
* Therefore, improving efficiency andreducing the complexity of the operation
* Let's move on to the advantagesof Microkernels
* One of the main advantages ofa Microkernel is that its code is minimal
* It is often the case thatthe less code is written, the less probabilitythat an error can occur
* Other benefits, due to a minimal kernelare small trusted computing base and suitability for verification
* Trusted computing baseis related to security
* In computer security terminology, the trusted computing base is the setof all hardware, software and procedural components thatenforce the security policy
* This means that in orderto break security, an attacker must subvert one ormore of them
* Regarding verification, the benefitof a small quote size is obvious
* The less code we have,the simpler it is verifying it
* Finally, due to the modularityof Microkernel, it is easy to add software to the system,thus making it scalable and extensible
* We have already talked aboutthe advantages of Microkernels, but what are their drawbacks
* Why didn't Microkernelactually win the race
* Although they seemed tobe a better idea in 1992
* To answer this question, let's go througha simple example like creating a file
* In order to create a filein a monolithic kernel, It is necessary to performa context to switch only two times
* The first one occurs when the systemswitches from the application to the kernel, sothe file operation can be executed
* The second one occurs when the kernelgives control back to the calling process
* Now, in the case of a Microkernel, how expensive is the file operationin terms of context switching
* Well, it turns out it takes a lot morecontext switching between kernel and the user process
* The reason for this is that now it is necessary toswitch among multiple processors
* Each one controlling a small function
* In this particular example, one processmay be in charge of the file system while another handles the device driver
* As a result, the overall systemresponse becomes slower
* This overhead is not limitedto input-output operations
* Other kernel services, such inter-processcommunication, are also affected
* In this video, we'll describe the mostimportant features of Microkernels
* However, to get a deeperunderstanding of its details, I recommend you go throughthe suggested materials
* Thanks for watching, andsee you in coming videos
* [SOUND]


--- SKIP ---: 04_the-modular-kernel.en.srt


--- SKIP ---: 04_the-modular-kernel.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_the-modular-kernel.en_SENTbySENT.txt
* [MUSIC] Hello, it is good to see you back forthis lesson
* Previously, we explored withan eagle's eye what Linux kernel is and why it is important
* Now, we will look intoanother type of kernel to discover it's detailedcharacteristics and advantages
* At the end of the lesson, you shouldunderstand the differences between all three types of kernel andtheir features
* As a result, you will be able toutilize a specific kernel type for a particular application requirements
* Let's begin describing whatthe modular kernel is
* A modular kernel It's a sort of hybridbetween a monolithic kernel and a microkernel
* it aims to get the best featuresof both types of architectures
* So in concrete,a modular kernel can perform tasks as good as a monolithic kernel while the stabilityis similar as a microkernel
* As a result, we obtain a kernel withvery efficient memory utilization and good overall performance at the same time
* A modular kernel comprisesa multitude of modules, each one dedicated toa specific system task
* A key feature of these systemsis that modules are loaded only when the functionality is needed
* For example,a particular device driver is loaded only if there is a process thatneeds access to that device
* Loading a module does nottake a large amount of time
* However, this strategy couldgenerate a severe overhead if multiple modules are constantlyloaded and unloaded
* The system would have spent mostof the time managing the modules instead of executing actual work, andthus yielding very poor performance
* To address this issue, once a module is loaded it will remain inthe kernel until it is explicitly removed
* In most cases, a module is requiredby only one particular process
* However, it is possible that severalprocesses require the same module
* In which case,the colonel creates multiple copies of it
* The main reason fordoing this is to prevent the overhead cost by constantly loading andunloading modules
* In other kernel architectureswhen new functionality is added, the kernel must be revealed
* However, this is not the case formodular kernels, where new models can be easily addedwithout recompiling thus saving time
* Filing and fixing bugs in a monolithickernel is a very hard task
* It is time consuming anddemands a lot of effort
* For example, a bug in a devicedriver which is bound to the kernel may prevent the system from booting
* In this situation, it is hard to say whatpart of the kernel is causing the problem
* This situation can easily be avoided whena device driver is a loadable module
* Since the kernel must bootbefore loading any module
* In case the system does notperform correctly after the kernel is successfully booted,it's simple to find the fault module
* As we discussed before, the kernelloads modules only when necessary
* Therefore, the system's memorycan be efficiently managed
* Due to these advantagesof modular kernels, we can conclude thatwith the modular kernel, the overall system performance increasesand the kernel size is not large
* Although a modular system providesa multitude of advantages, it still has some drawbacks
* As mentioned before, the modular kernelinherits stability from microkernel
* However, this stability cannot bewarranted in cases of fragmentation
* Another disadvantage is thatsecurity may be vulnerable when many interspaces are passed through
* Finally, it is not easy tomaintain a large number of modules when they are created byseveral third parties
* This is the end of our lesson today
* Hopefully by now, you have a betteridea of what a modular kernel is, what makes it different from otherkernels and what it's advantages are
* In the next video, we will discusshow a modular kernel is implemented
* Thank you for watching and see you again
* [MUSIC]


--- SKIP ---: 01_introduction-to-contiki.en.srt


--- SKIP ---: 01_introduction-to-contiki.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction-to-contiki.en_SENTbySENT.txt
* [MUSIC] Hello, it is good to see you back
* In previous videos,we explored several kernel architectures, such as monolithic,microkernel, and modular
* Now, we're going to focus on an embeddedoperating system intended for IoT devices named Contiki
* Contiki is a good example ofa modular kernel, and in this video, we will discuss it'smost important features
* Contiki was originallycreated by Adam Dunkels in 2002 as an open sourceembedded operating system
* Contiki is designed for networked andmemory constraint systems
* It's main focus is a low powerwireless sensor systems and Internet-of-Things devices
* Therefore, Contiki always islightweight enough to fulfill the requirements of an embedded deviceequipped with a low end micro controller, small memory and battery powered
* A good example of this isContiki's code foot print, which only needs about 10 kilobytesof ram and 30 kilobytes of rom
* Currently there are a lot of companies anduniversities involved in Contiki's development, such asTexas Instruments Atmel, ETA Surik, Oxford University, and others
* After this introduction, let's take a lookat the most important features of Contiki
* Contiki uses protothreads,software flow control
* But, what is a protothread
* For now, it suffices to say thatprotothreats is a mechanism that mixes an event-driven model and threats to provide sequential flow controlwithout using complex state machines
* Protothreats are an extensive topic thatwe will cover in depth in another video
* As we mentioned earlier, Contiki isbuilt for embedded network systems
* Therefore, it provides powerful,low power Internet communication stack that includes Internet standards IPv6 and IPv4 along with the recentlow power wireless standards, such as 6LoWPAN, RPL and CoAP
* In addition,due to the limited power supply and resource constraints inembedded network system, Contiki provides mechanisms forefficient memory allocation
* Furthermore, Contiki is based on a modularkernel that supports dynamic loading and linking at
* As a result,software modules are loaded only when the system requires theirparticular functionality
* It is an advantage forsystem administrators and users to know forhow long a system has been running, or the system's working hours whena particular power supply is used
* In order to address this issue,Contiki provides a mechanism for estimating the system's power consumption
* Contiki can run in different typesof embedded networked drives, such as and other arm based devices
* These hardware are popular andeasy to buy with low prices
* In addition, it is possible to port Contiki tonew hardware with a little effort
* As we all know, it is not easy toset up a large wireless network
* It requires a lot of time andeffort to debug and deploy devices
* To address this issue, Contikiprovides the Cooja Network Simulator
* Cooja allows simulator largescale networks comprising 10s of nodes running on fullyemulated hardware devices
* Using Contiki's examples isthe easiest way to implement simple or complicated applications in a short time
* Some examples show how todevelop application code, while others demonstrate system features
* In addition, there is a common line shell,suitable for debugging operations
* Shell commands can be combined inpowerful ways using Unix style pipelines
* It is also possible for an application to define its own shell commands thatwork together with the existing ones
* There are other interestingfeatures of Contiki that it was not possibleto cover in these lessons
* Therefore we strongly encourage youto read the recommended materials
* Before ending this video,I would like to show you how to implement the classichello world example in Contiki
* If you run this code,the phrase hello world, will be printed tothe terminal of the device
* To get the details on howto write a program and drawn an application in Contiki
* You should come back to our lectureswho have more detail be use
* Thank you for watching andsee in next videos
* [MUSIC]


--- SKIP ---: 03_introduction-to-tinyos.en.srt


--- SKIP ---: 03_introduction-to-tinyos.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_introduction-to-tinyos.en_SENTbySENT.txt
* [MUSIC] Hello, good to see you back forthis lesson
* In previous videos, we explored Contiki, a popular IoT embedded OS,its features, and advantages
* Now, we're going to anotherflavor of IoT embedded OS
* Tiny OS, which can be seen asan example of a monolithic kernel
* First of all, I will give youan introduction to Tiny OS, followed by its features and advantages
* Tiny OS is an open sourceembedded operating system
* It is designed for network andmemory constrained systems
* It mainly focuses on low powerwireless sensor network systems and Internet-of-Things devices
* Consequently, Tiny OSis lightweight enough to satisfy their requirements ofan embedded device with not so powerful micro-controller with a smallmemory, and that operates on battery
* Tiny OS was created atBerkeley University in 1999, and later developed by many companies anduniversities
* Tiny OS andits applications are written using nesC
* NesC is a structure componentbased extension of the C language
* Now we will discuss the fivebasic concepts of NesC
* The first one is the separationof construction and composition
* This is achieved by the factthat all programs in Tiny OS are built as components, and then theyare assembled to form a whole program
* Components have internalconcurrency in the form of tasks
* A component may be calledvia its interfaces
* Second is the specification of componentbehavior using a set of interfaces
* This means, in other words,the provided interface is just for representing the functionalityof a particular component
* The third one is regardingbidirectional interfaces
* This implies that interfacesdefine functions, which can be implemented byboth commands and events
* This provides the benefitthat a single interface can represent a complexinteraction between components
* Four, is the static linking of componentswith each other and via their interfaces
* This enhances run time efficiency,promotes robust design and allows forbetter static analysis of program code
* Finally, a whole program compiler
* In NesC, code is generated by wholeprogram compilers instead of blocks
* Therefore, it is better forcode generation and analysis
* After this introduction,I hope you have main ideas of Tiny OS
* Now, we go into the internals ofTiny OS features and advantages
* Absolute size, compared to other popularembedded wireless sensor networks, Tiny OS requires minimal RAM andROM for performing a basic task
* It needs less than one kilobyte of RAM andfour kilobytes of ROM
* Now, you may wonder how it can happen
* Previously, I mentioned the wholeprogram compiler in NesC
* It is used to remove dead code andapplies cross-component optimization to remove redundant operations andminimize the overhead of module crosses
* In Tiny OS, context switchoverhead corresponds to both, the cost of test scheduling andinterrupt handling overheads
* The interrupt overheads consistsof both switching overhead and function overhead of the handler, whichvaries with the number of saved registers
* In contrast to the other traditionalmultimedia applications, sensor network applications are differentin terms of time and criticality of work
* Instead of chorusing a priority scheme toallow the correct ordering of the task, Tiny OS uses a simple scheduler toschedule based on a set of deadlines
* Tiny OS with NesC compilersupport debugging and helps to detect race conditions
* In order to do this, synchronous and asynchronous codesare considered in Tiny OS
* In order to give you a betterunderstanding of this process, synchronous andasynchronous code will be explained
* Synchronous Code or SC is a codethat is only reachable from tasks, while Asynchronous Code or AC is a code that is reachable fromat least one interrupt handler
* The primary goal of Tiny OS is toallow developers build responsive and concurrent data structures that cansafely share data between AC and SC
* So components often have a mix of SC andAC code
* As a result,there are potential causes of races
* It is clear that non-preemption almosteliminates races between tasks
* However, there are some cases ofpotential races between AC and SC or between AC and AC
* There are two optionsto avoiding such cases
* The first one is to convert allthe conflicting code to tasks only for SC
* The second option is to use atomicsections to update the shared state
* Next, I will discuss about activemessages, which can be considered as the main communicationabstraction model of Tiny OS
* Active messages are small packets
* About 36 bytes also sharedwith one byte handler ID
* Now you may wonder howactive messages work
* Let us see
* A node dispatches a messageusing an event to one or more handlers that are reducerto receive messages
* Handler registration is carriedout using static wiring and a parameterized interface
* Moreover, single holddatagram protocol and unified communicationinterface are provided by AM
* Higher level protocols providingmulti-hub communication, are readily built on the topof the AM interface
* Now we continue to discussTiny OS flexibility
* To give you a comprehensiveunderstanding of this feature, I will explain characteristics whichjustify the flexibility of Tiny OS
* First, Tiny OS supportsfine-grained components
* This implies that a complex applicationis composed from a large number or very fine grain components
* For example, the main code ofTiny OS consists of 401 components
* In addition, other 42 applications in thesource tree use about 74 components each
* A component is built witha small number of modules
* And each module is from sevento around 2,000 lines of code
* Second, Tiny OS providesconcurrent components
* As I mentioned early, any componentcan be the source of concurrency
* Events can be automatically generatedby any component via by directional interfaces
* In addition,concurrency bugs can be removed with the help of a staticraise detection of NesC
* Third, Tiny OS supports hardware andsoftware transparency
* Basically, the idea behind is to replacesoftware components with more efficient hardware implementations toreduce energy consumption
* For example, using a single chip whichconsists of microcontroller, memory, radio transceiver and radio acceleration,consumes around 100 microamps, while the standard server radiostack consumes 3.6 milliamps
* Last but not least is interposition
* One aspect of flexibility is the abilityto insert components between other components
* Whenever a component provides and uses the same interface type, it canbe inserted or removed transparently
* Another feature of Tiny OS is support forlow power operation
* To give you a comprehensive view of thisproperty, we discuss three concepts
* These are CPU power usage,power management interfaces and hardware software transparencies
* First, in order to achievelow CPU power consumption, Tiny OS has a sleep mode to whichit transitions when it is idle
* Tiny OS tries to sleep as long aspossible to minimize power consumption
* For example,when listening to incoming packets, the power consumption of the CPUis about 4.6 milliamps and 2.4 milliamps in active andidle state respectively
* Second, it is difficult tosave energy in cases of long-term wireless sensornetwork applications
* In order to perform the taskssuccessfully, Tiny OS provides power management interfaces to allow selfsystems to be put in low power idle state
* For example, by powering down hardware ordisabling periodic tasks, power consumption can bedramatically reduced
* This job can be done via set ofcommands provide by Tiny OS
* Finally, Tiny OS supportsHardware/Software Transparency which is already discussed above
* There are many interestingfeatures of Tiny OS
* However, we cannotdiscuss all of them here
* In order to cover all these features andadvantages of Tiny OS in detail, I suggest that you go throughdocumentations in the suggested materials
* Before ending this section, we're going to take a look at the classicHelloworld example for Tiny OS
* In this example, Helloworld will beprinted out the terminal of the device
* To learn details on how to writea program and run application in Tiny OS, you should come back later to ourlectures, which have more detailed videos
* Thank you for watching
* [MUSIC]


--- SKIP ---: 05_introduction-to-riot-os.en.srt


--- SKIP ---: 05_introduction-to-riot-os.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_introduction-to-riot-os.en_SENTbySENT.txt
* [MUSIC] Hello, it is good to see you back forthis lesson
* In previous videos we explored Kontiki andTanjores, their features and advantages
* Now we're going to addressanother type of IOT embedded OS
* Right, which can be seen as an exampleof a micro current of design
* First of all I will give youan introduction to Riot and then I will discuss its features andadvantages
* Riot is an open sourceembedded operating system
* It is designed for networked andmemory constrained embedded systems
* Its primary focus is on low-powerwireless sensor network systems and Internet of Things devices
* As a result of this,it is made lightweight enough to satisfy the requirements of embedded deviceshaving limited processing capacity, small main memory and storage,and powered by battery
* The kernel of Riot was first developed byseveral European academic institutions in 1999, and later by various companies,individuals and universities
* Riot andits applications are written in ANSI C
* Riot implements a microkernel ofarchitecture, inherited from Fire Kernal
* In addition to Fire Kernel's originalfeatures, powerful C++ libraries such as, the Wise Leaf algorithm framework andtcpip network stack are added in to riot
* As primly mentioned, Riot is built fornetworked and memory constrained systems
* Therefore it needs to save memory andreduce the size of it's can
* In order to address this,Riot is designed in a modular way
* It also tries to limit dependenciesbetween the modules as small as possible
* In addition, the configuration ofthe system can be customized to meet a particular specification,thereby minimizing the size of the kernel
* For instance, a Riot kernel can require assmall as a few hundred bytes of RAM and program storage
* Another benefit of modularity is the effect of bugs islimited in the module itself
* Similar to Kontiki a bug in a modulecannot mess up with the whole system
* In contrast to many other operatingsystems, write a scheduler works without periodic events andit's consider a tickles scheduler
* One benefit of this is, to switch to idlethreat, when there are no pending tests
* In addition, the idle threat containsa function to decide this looping duration of a device, or system
* This decision is made, based onthe peripheral devices in use, this gives the advantage that the system canstay in sleep state as long as possible
* Subsequently, energy consumptioncan be significantly minimized
* Only interrupts wake the systemup from the idle state
* Moreover, all kernel functionsare kept as small as possible thus allowing the kernel to run even on asmall systems with very low clock speeds
* The scheduler is the sign to minimizethe occurrences of threats which thereby reducing the overhead by switch questions related to interrupts mayhave popped out in your main software
* For instance, how do interruptsawaken the system from a sleep state
* How this would get handled
* In order to give you answers for such questions, I'm going toexplain interrupt handling in Riot
* Interrupt handling is an importantpart of Riot because failure to handle interrupts well has a serious impacton the performance of the system
* It is known that most device drivers forcommon real time and wireless network are designedto directly use interrupts
* However using interruptsis not straightforward
* For example,in a pre-emptively scheduled system, interrupt is passed through kernel andcontext switching must be carried out
* Before switching to the interrupt, thecontext of the running task must be saved as you can see,it is complicated to work with
* In order to help programmersachieve this easily, Riot provides an API which is similarto common sensor net programming model
* In addition, Riot is builttargeting the lowest possible interrupt latencies so that realtime requirements can be fulfilled
* Similar to other embedded wirelessnetwork operating systems, Riot supports various types of hardware such as16 bit MSP430 or 32 bit ARM server
* One of the benefits of Riotis it's small footprint
* It only requires less thanfive kilobytes of ROM and two kilobytes of RAM to run a basicwireless sensor network application
* Compare to Contiki, Riot is betterin terms of required minimum RAM and ROM for a basic task
* Another advantage of Riotrelated to portability is in using advancefeatures of processors
* For instance,ARM processors are powerful and provide many complex featureslike vector interrupt controller
* These features may not be suitable forother embedded network OSs
* However, Riot utilizes,by virtue of separation of CPU code from the kernel implementationRiot's kernel is built in the target of achieving maximum reliability andstrong realtime characteristics
* Therefore, Riot supports multithreadingwith zero-latency interrupt handlers and minimum context-switching times
* In order to assist system developerstake advantage of really easily
* Riot provides a developer friendly API
* Another advantage of Riot is that is allows developers to createas many threads as possible
* In addition, distributed systemscan be easily implemented using the kernel messaging API
* The maximum number of threads is onlylimited by the available memory and the size of the stack for threads,while the computational and memory overhead is minimum
* Similar to other embeddednetwork operating systems, Riot supports differentnetwork protocols for resource constrains systemsSuch as 6LoWPAN and RPL
* In addition, IPv4, IPv6, UDP andTCP are also fully supported
* Similar to Kontiki,network stack in Riot is also modular
* This gives the flexibility to exchangeprotocol layers at any hierarchy
* In addition,an adaptation layer is provided that offers an IEEE 802.15.4complete interface
* There are many interesting things of Riot
* Unfortunately we cannotdiscuss them all here
* In order to cover more features,advantages of Riot and learn to program for it in detail, i suggest you to go through thecommentation in the suggested materials
* Before ending this section, we're going to take a look atthe classic Helloworld example in Riot
* In this example, 'Hello World' will beprinted out to the terminal of the device
* In order to know the detailson how to write a program and run applications in Riot,please come back to our lecture
* Who have more detailed videos
* With this lesson, we concludedthe embedded operation systems model
* I hope you enjoyed watching.


--- SKIP ---: 01_contiki-and-cooja-simulation.en.srt


--- SKIP ---: 01_contiki-and-cooja-simulation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_contiki-and-cooja-simulation.en_SENTbySENT.txt
* [MUSIC] Hello, I am glad to see you back forthis lesson
* In previous modules, we explored differenttypes of embedded IoT operating systems
* Now we will look intothe details of Contiki and discover certain detailed behaviors
* At the end of the lesson,you will be able to understand some of the challenges in developingIoT applications for Contiki
* First of all, let's elaboratethe title of today's lesson, Contiki, a hybrid operating system
* Remember our discussion in previous moduleon operating system kernel designs
* We discussed contiki as an exampleof a modular kernel design, combining features from monolithic andmicrokernel
* This allows it to inherit someadvantages of both systems
* Contiki implements a hybrid modelthrough an event driven kernel
* In Contiki, preemptive multi-threading isimplemented as an application library
* This is optionallylinked with the program, if the program requiresmulti-threading features
* There are two key benefits whenbuilding a system like this
* First, concurrency can be providedwithout the need of per-thread stacks or locking mechanisms
* This benefit is evident by looking at whyper-thread stacks are not suitable for embedded devices
* Per-thread stack approachallocates a stack for each thread
* It is hard to specify howmuch a thread requires
* In addition,when a thread is created the memory for stack must be assign or allocated
* This creates a problem,because memory assigned for specific task cannot be useby other concurrent test
* The second benefit is that event drivenmodel with the state driven programming are difficult for programmers to manage
* In addition, not all programs canbe expressed as state machines
* Let's take an example of a purelyevent driven operating system
* In such a system, a task couldconsume the full CPU time completely
* When the task is complex and require a long CPU time, the system cannotrespond to external events sometime
* A preemptive multi-threaded systemovercomes the problem in such situation
* Hence, a hybrid system can beconsidered as the most suitable for such kind of problems
* As I mentioned earlier,Contiki inheritance advantages from microperable design, and henceseparates from the kernel from processors
* This helps to reduce the kernelsize as small as possible and consequently the probability ofbulks can be dramatically reduce
* Similar to microkernel design,Contiki also uses messaging mechanism for communication between services andthe kernel
* However, instead of using the peermessages discussed in micro kernel lesson, Contiki uses posting events
* The only difference between pure messagesand event posting is formatting
* There is no hardware abstraction layer orHAL in Contiki
* Therefore, the bias drivers and applications communicatedirectly with the hardware
* In order to give you a betterunderstanding of the pros and cons of removing hardwareobstruction layer in Contiki, I will first discuss aboutthe hardware obstruction layer
* The hardware abstraction layer is a layerbetween application, component code, and hardware
* In other words, HAL allows operatingsystems to interact with devices at an abstract level ratherthan a detailed hardware level
* The main purposes of halt is to helpthe OS access hardware simply and portably via abstract API's regardlessof the type of underlying hardware
* Therefore, HAL has many advantages
* For example,first it enables switching hardware
* It is possible to switchto another hardware, such as a different microcontrollerduring development
* As a result, there is less of a riskdue to choosing suitable tools
* Second, it allows cross development
* It is not possible to develop applicationand components more conveniently
* As a result,the development speed can be fast
* In addition, a large-scalesimulation environment can be built
* Third, it results in less effort andless bugs
* This enables a significant reduction inlines of code, which leads to less bugs
* The final benefit is forautomated unit testing
* It is possible to run embeddedsoftware on a computer platform, extending the concept of continuousintegration with automated unit tests
* Although HAL has many advantages,it also has several drawbacks
* Let's look at some of them
* First, HAL cannot completely cover all available features of a particularhardware, such as a microcontroller
* As a result, it limits somefunctionalities of the hardware
* Possible conflict with other frameworks,libraries and components is the second drawback of HAL
* The third problem is that it is hard or even possible to maintain the hold,especially in cleaning HALs mess
* Finally, a number of lines ofcode increase dramatically when integrated into the OS
* Currently, HAL is deprecated indifferent Linux distributions
* Since Contiki is built forwireless sensor networks and embedded IoT devices,it is better off without HAL
* Because of this, device drivers and applications communicatedirectly with the hardware
* Based on a modular kernel approach,Contiki has the ability to load and unload models at run time
* This allows Contiki to loadonly the necessary services, consequently allowing it tohave a reduced kernel size
* Almost all abstractions are implementedas libraries and services, except for CPU multiplexing, which is the onlyobstruction provided by the core system
* The implementation is almost similarto a scheduler of microkernel
* Looking at this implementation,Contiki is developed in C language, and it's applications are also written in C
* Therefore, its is easy to developapplication, reprogram, and replace services
* Last but not least,Contiki is easily portable
* This implies that it possible to run iton various microcontroller architectures such as the CC2538, CC2650, SensorTek, AdmilABR, and the MSP430, and so on
* It is easy to add support for new microcontrollers using the built-inlibraries and existing Contiki platform
* For example, a programmer can easilyport Contiki to their own board by creating configuration files forthe specific microcontroller and edit existing generalconfiguration files of Contiki
* However, it is rare for a programmer to add a newmicrocontroller to the Contiki platform
* As Contiki supports all popular microcontrollers and embedded devices
* This is all for the lesson about Contiki,a hybrid system
* I hope that you got the important featuresof Contiki's kernel, and the hybrid model
* We also discussed unique characteristicsof Contiki, and its kernel
* I hope to see you in the next video, which will further explain manyadvanced features of Contiki.


--- SKIP ---: 02_the-contiki-system.en.srt


--- SKIP ---: 02_the-contiki-system.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_the-contiki-system.en_SENTbySENT.txt
* [MUSIC] Welcome
* It is good to see you back forthis lesson
* Previously, we exploredContiki as a hybrid system
* Now we will look into moredetails of the operating system to discover othercharacteristics in depth
* At the end of this lesson, you will beable to understand what benefits and challenges Contiki presents whendeveloping iOT applications
* First of all, let's discussthe main components of Contiki
* A Contiki system includes the kernel,libraries and applications or services, of which applications andservices are implemented as modules
* They are only loaded whenan application requires them
* As discussed before, this is one of themain positive characteristics of Contiki
* If you do not remember details about this,I recommend you go back to other videos, we let it to modular kernel design andContiki
* In Contiki, it is possible to dynamicallyreplace all processes at run-time, thus helping to save resources
* Processes in this case can be eitherservices or application programs
* So far in our discussion,we haven't addressed what applications and services are and their differences
* From the point of view of Contiki, they are all modules whichare loaded when needed
* However, from the point of view ofa programmer, a service is implemented to provide a functionality which is used workfor one or more application processes
* All communication between processesare done through the kernel
* We mentioned in the previous lesson that there is no hardwareobstruction layer in Contiki
* As a result of this, device drivers and applications communicatedirectly with the hardware
* If you don't know or remember why Contiki does not providea hardware abstraction layer, I suggest you to go back to the previewslesson titled Contiki, a hybrid system
* All processes share the same address andspace and all run in the same protection domain
* This enables Contiki to run inmemory constrained devices
* In order to give you a deeperunderstanding of this idea, we will have a lesson threads andmulti-threading
* In that lesson, you will get an ideaof why and how Contiki achieves it
* But let's now examine how a processis created and treated in Contiki
* A process is a piece of program codewhich is executed by Contiki's system
* A process is started in two ways
* The first is when Contiki starts, andthe second when the module loaded
* A process runs when an eventrelated to the process occurs, such as a timer event or an external one
* For example, consider an application that prints helloworld to the terminal every second
* This application process runs whenever atimer event is triggered at every second
* It means that a counter of the timerwill count down every second, and when it reaches zero,the event is triggered
* Countdown frequency is based onthe particular type of timer event used
* In order to have a closerview of a timer event, I recommend that you stay with me forthe upcoming videos
* In those videos,different types of time or events, and other types of eventswill be deeply discussed
* There are two types ofexecution modes in Contiki
* These are cooperative andpreemptive modes
* Cooperative process code runssequentially in a queue
* This means that the first processhas the right to use the CPU, while other processors wait fortheir right to access the CPU
* After the process whichoccupied the CPU is finished, then the next waiting process inthe queue gets the right to use the CPU
* In contrast, preemptive modehandles process differently
* In the preemptive context, a runningprocess can be stopped by an interrupt, and the higher priority test immediatelytakes over the right to use the CPU
* After finishing its job, it returns the right to accessthe CPU to the interrupted process
* A process is defined byan event handler function and an optional poll handler function
* In order to give you a better view ofa process, and how it is defining Contiki, we're going to look at the internalstructure of a Contiki process
* The Contiki process is a combinationof two different parts
* These are process control block andthe process threat
* In this lesson, we only focus onContiki System and Contiki Processes
* Therefore a process thread willbe discussed in following videos
* The process control blog is composed ofinformation about each process such as the state of the process, the pointer tothe next process, name of the process, a pointer to a process thread, the stateof the proto thread and internal flags
* The slide shows a structureof a process in Contiki
* The structure is writtenin a standard C language
* The process, Control Block,is only used by the kernel
* Therefore, users do not have any rightto access the Control Block directly
* This helps the systemprotect the process and avoid unexpected mistakes orbugs caused by programmers
* Actually, the kernel only keepsa pointer to the process of state which is health inthe process' private memory
* This means that every processhas its own state, and the state cannot be accessedby other processes
* As you can see in this slide, the ProcessControl Block's structure is quite simple, and it does not containcomplex information
* Therefore, it is lightweight, andit just occupies a few bytes of memory
* In Contiki, a Process Control Blockcannot be declared or defined directly
* The block is definedvia the process macro
* In order to give youa better view of this macro, I am going to take an exampleof hello world processing
* As you can see,the process macro has two parameters, the name of the Process Control Block andthe textural description
* The variable name of the Process ControlBlock is used for accessing the process, while the description text of the processis used by programmers for debugging
* As mentioned in previous videos,Contiki uses posting events for interprocess communication
* This mechanism is also similar to the messaging mechanism inMicrokernel described before
* Contiki's system ispartitioned in two parts
* The first part is the core, andthe second is the loaded program section
* The partitioning is made at compiled time,and it's specific to the deploymentin which Contiki is used
* Typically, the core consists ofContiki kernel, the program loader, most commonly used parts of the languagerun-time, support libraries, and a communication stack with devicedrivers for the communication hardware
* The core is compiled intoa single binary image that is stored in the deploy devices
* It is generally notmodified after deployment
* Although it is possible to overwrite orpatch the core by a special boot loader
* Programs are loaded intothe system by the program loader
* Which gets the program binaries byusing directly attached storage, or using the communications tech
* Typically, programs to beloaded into the system are first stored in the EEPROM beforethey are moved into the code memory
* This is all for this lesson onContiki System and Contiki processes
* I hope that you have now a betterunderstanding of Contiki System's structure and how it works
* I hope to see you in the next videos,which will explain many other advanced features of Contiki, such as Contiki'skernel architecture and threats
* [SOUND]


--- SKIP ---: 03_contikis-kernel-architecture.en.srt


--- SKIP ---: 03_contikis-kernel-architecture.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_contikis-kernel-architecture.en_SENTbySENT.txt
* [MUSIC] Welcome
* It is good to see you back forthis lesson
* In the previous module,we explored the Contiki operating system
* Now, we will take a look atContiki's kernel architecture and explore the details ofits characteristics
* By the end of the lesson,you should understand the benefits and challenges faced when developingapplications in Contiki
* Let's start with Contiki'skernel architecture
* As we know from previous videos, Contikiis based on a modular kernel architecture
* Therefore, the kernel is minimal
* Due to this reason, the kernel comprises only a few linesof code that perform vital functions
* For example,the kernel consists of an event scheduler, which is light in terms of code size
* In Contiki,all program execution is triggered either through the polling mechanism orby events which are sent by the kernel
* In Contiki, the kernel supports two typesof events, synchronous and asynchronous
* Asynchronous events are notdelivered to the receiving process immediately after being posted
* Instead, they are storedin an event queue
* The events in the queue are deliveredto the receiving process by the kernel
* The kernel delivers an event fromthe event queue by looping through it
* The receiver of an asynchronous eventcan be either a specific process or all running processes
* When the receiver is a specific process, the kernel invokes thisprocess to deliver the event
* When the receiver of an event isset to be processes in the system, the kernel delivers the same eventto all processes sequentially
* This is one after another
* The process post function is used forposting an asynchronous event
* Actually this function is very simple
* First, the size of the event queue isevaluated and if there is room for the new event,then the event is added to the queue
* Otherwise, the function will return zero
* Synchronous events work differentlyfrom asynchronous events
* In the sense that whena synchronous event is dispatched, it is delivered to the receivingprocess immediately
* Another differencebetween asynchronous and synchronous events isthe type of receiver
* While asynchronous events can be receivedeither by a specific process or all running processes, a synchronous event canonly be received by a specific process
* The mechanism for invoking a synchronousreceiver is similar to calling a function
* A synchronous receiver is called,so it performs it's task, after which it returns controlto the posting process
* Besides events,the kernel supports a polling mechanism
* In short, the polling mechanismbehaves as high priority events that are scheduled betweenasynchronous events
* Typically, processes operating closeto the hardware level use polling for evaluating hardware status
* When a poll is scheduled, all processesthat implement a poll handler are called sequentiallyaccording to their priority
* In a similar way toevent posting functions, Contiki also provides a processpoll function for posting a poll
* Posting a poll has a similareffect as an interrupt
* It causes the receiving process tobe scheduled as soon as possible
* Contiki's kernel uses a single sharedstack for all process execution
* The use of asynchronousevents reduce a stack's space requirements as the stack is rewoundbetween each invocation of event handlers
* At this point, you may have questions regardingevents such as is an event unique
* Or how are we best identify it
* To answer these questions,let's talk about event identifiers
* An event identifier is an 8-bit numberused as a unique identifier for an event
* When a process receives an event It uses the event identifier todetermine the actions to perform
* There are several event identifiersreserved by the Contiki kernel to handle process control, inter-processcommunication, and peripheral access
* To get better acquainted withthe available identifiers, I suggest you go throughthe suggested materials
* Now, let's take a look at the wayContiki implements the scheduling
* Contiki schedules all events usinga single level hierarchy, and events cannot be preemptedby other events
* The only way to preemptan event is using interrupts
* It is important to noticethe interrupt must be supported by an underlying real-time executive
* Correspondingly, interrupthandlers cannot post any event
* The reason behind this policy isto avoid possible race conditions in the event handler
* Instead, a polling flag isused to request a poll event
* This flag provides interrupt handlerswith a way to request immediate polling
* Next, we are going to discuss aboutloadable programs in Contiki
* To implement loadable programs,Contiki uses a binary format that includes relocation information anda run-time relocation function
* But, how does a loadable program work
* When a program is loaded,the loader uses the relocation information provided by the binaryformat to allocate memory
* In case that there is not enough memory,the loading is aborted
* In case of successful loading,the function for initialization is called forstarting or replacing other processes
* Finally, we're going to lookat power saving in Contiki
* In general, power can be saved byputting inactive nodes to sleep
* In some cases, choosing appropriate level protocolsmay also reduce power consumption
* Contiki also provides a mechanism for reducing power consumption even thoughthere is no explicit abstraction for it
* The mechanism works by checkingthe size of the systems event queue
* If the event queue is empty, the micro-controller goes into a sleepmode until it's woken up by an interrupt
* This is all for the lesson aboutContiki kernel architecture
* I hope now you have a better insight onhow Contiki's kernel is structured and how it works
* Thanks for watching andsee you in the next video
* [MUSIC]


--- SKIP ---: 04_contiki-services-and-libraries.en.srt


--- SKIP ---: 04_contiki-services-and-libraries.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_contiki-services-and-libraries.en_SENTbySENT.txt
* [MUSIC] Hello, I am glad to see you back forthis lesson
* In previous lessons,we explored Contiki's kernel architecture
* Now we will look into the details ofContiki's services and libraries
* By the end of the lesson,you should understand the benefits and challenges of using and developingservices and libraries in Contiki
* First of all,I will go directly to a question
* What is a service in Contiki
* As we mentioned before,services are implemented as modules
* So when a particular service is requiredthe corresponding module is loaded thus making Contiki run efficiently
* From a certain point of view, a service isdifferent from other application programs since a service can be used byseveral application programs In other words,a service is a type of shared library
* One of the benefits of Contiki Services is that they can bedynamically replaced at random
* As mentioned before, with this strategy Contiki minimizes the number of modulesto be loaded during booting time
* As a result, memory researchescan be used more efficiently
* As an example, some popular andhag intensive use services in Kentucky are communication stacks andsensor device drivers
* These kind of services will bediscussed in depth in coming videos
* After this short introduction, I assume that you already havea basic idea of Contiki Services
* Now, we are going to take a look underthe skin of Contiki Services and other components related to Services
* In every operating system, each serviceshould have a unique identifier, defined by the system or users
* The format of the identifiercan write depending on a particular operating system
* In Contiki, a service identifier is a textual string that describesthe functionality of the service Identifiers are used when applicationprograms invoke a service
* When a service is requested, the servicelayer uses ordinary string matching for querying the installed services
* You may now be wondering,what is a service layer
* The surface layer is a component locatedbetween the kernel and services
* When a process wants to call a service,it posts an event to the colonial, which in turn sends a command and information related to their requestedservice to the service leader
* This layer uses this data forquerying a matching services
* Instead of searchingservices in the kernel, the searching job will bedoing by the service layer
* Everything we have discussed so far does not unveiled the actualstructure of a service in Contiki
* Therefore, now we are going toexplore the structure of a service
* A service includes a service interface anda process
* A service interfaceprovides an entry point that an application uses to accessthe functionality exposed by the service
* The service interfaceincludes a version number and a list of functions with pointers to thefunctions that implement the interface
* Services and application programsuse a stub library to communicate
* How does a stub library work
* A stub library that has been linkedwith an application utilizes the service layer for the purpose offinding the corresponding service process
* After a service has been located,the service is stopped, gets the process identifier,which will be used for later requests
* By using a stub library an applicationdoes not need to know the exact location in memory of the service, orthe implementation details of the service
* When a service is called forthe first time the stub library queries the service layer for searching forthe necessary service
* As a result, if there is an instanceof the service in the system, the service layer will returna pointer to the service interface
* After this, the version numberin the service interface will be compared to the stubinterface's number
* If they are identical, the implementation of the requestedservice will be delivered
* Next, I am going to explainabout service replacement
* What is service replacement in Contiki
* As we know, services in Contiki canbe dynamically loaded and replaced
* However, it would become unmanageable ifthe process identifier would be changed
* Therefore, in order to avoid this issue, the service identifier must remainthe same even if the process is replaced
* A reasonable question would be,why is the process replaced but the process identifier is still kept
* To answer this question, we are going to explore the mechanismthat performs this task in Contiki
* When a service is about to be replaced,a special event is sent from the kernel to the service process to inform the runningversion of the service about the changes
* Accordingly, the service isautomatically removed from the system
* However, there are somecases that many services have internal stage that may need tobe transferred to the new process
* In order to deal with those cases,a pointer and a stage description are used forpassing to the new service process
* In short, this stage description,which is stored as a shared memory, is a tag with the motionnumber of the service
* The reason for this is to avoid that an incorrectversion of this same service is loaded
* Now let's talk about libraries in Contiki
* As we know, the kernel in Contikiis minimal and only performs vital functions such as event handlingfeatures and CPU multipliers
* The rest of the systemis build as a library
* When the program needs to usea function provided by a library It can link with a library thatimplements the required function
* There are three types of linkingbetween an application and a library
* The first one is a static linkbetween an application and libraries which are part of the core
* The second one Is a static linkbetween an application and libraries which are partof loadable program
* The last one is the application can call the service thatimplements a specific library
* As a result of the last method, the library implemented as servicescan be replaced at random
* What is the differencebetween these linking types
* Libraries are part of the core
* This means that when the systemis booted or rebooted, these libraries are always automaticallyloaded along with the system
* Other type of libraries are loadableprogram libraries, these libraries are only loaded when a programapplication requires their functions
* These libraries are rarely used, orare very application-specific libraries
* The last term is runtime libraries,which are implemented as services
* This runtime libraries can be replacedwhen the system is running and these libraries are frequently used
* To give you a morecomprehensive understanding of different types of libraries,I will discuss some examples
* Let's discuss two functions commonly usedin Contiki applications memcpy and atoi
* The memcpy function is used forcopying data between two memory regions, while atoi function is used forconverting strings into integers
* Memcpy is frequently used in Contiki, therefor it is consideredas a part of the core
* Whereas atoi is less frequently used, and therefore it is not includedin the system core
* It is implemented inloadable program libraries
* This is all forthe lesson about Contiki service, service replacement, and libraries
* I hope by now you have a good ideaabout how these Contiki features work
* Thanks for watching
* [MUSIC]


--- SKIP ---: 05_communication-in-contiki-i.en.srt


--- SKIP ---: 05_communication-in-contiki-i.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_communication-in-contiki-i.en_SENTbySENT.txt
* [SOUND]
* Welcome, I am glad to see you back forthis lesson
* In this video we will discussthe details of how Contiki implements network communication
* By the end of the lesson you shouldunderstand the structure and functioning of Contiki'scommunications stack
* But perhaps the best questionto start this lecture with is, what is communication in Contiki
* Before answering this question, we are going to talk about communicationin wireless sensor networks
* Communication plays an essential rolein any wireless sensor network system
* Basically, communication in a wirelesssensor network architecture includes three parts
* Sensor nodes, a gateway,and the backend system
* Sensors collect data andsend it to the gateway wirelessly
* Depending on the network characteristics, a particular communicationprotocol is used
* For example, Wi-Fi orBluetooth can be used for sending data from sensornodes to a getaway
* Then the data is forward viathe internet and reach the cloud
* Finally end-users can access data oruse services offered by the cloud
* In this lecture, we will focus on communicationbetween sensor nodes and the gateway
* In other words, the communicationbetween devices using Contiki
* In Contiki,communication is implemented as a service
* Therefore it has all the featuresof Contiki services, such as run time replacement
* As a result, it allows to simultaneouslyload multiple communication stacks
* This helps to reduce the latencyof loading modules one by one
* In addition, this feature can be used for comparing differentcommunication protocols
* To have a better understandingof such protocols, we will explore them indepth later in this video
* But now, we are going to focus onthe loosely coupled communication stack in Contiki
* Communication in Contiki may bedivided into different services
* The communication stackuses synchronous events to communicate with a program application
* Here, an interesting question is, why using synchronous events insteadof asynchronous events, or polling
* The answer is that it is possibleto use a single buffer for all communication processing, since it is necessary that synchronousevent handlers run to completion
* This approach ensures that there is noneed to copy data to intermediate buffers
* The bias drivers operate betweenthe communication stack and the hardware
* Device drivers would in come in packets,place them into the communication buffer and then callthe upper layer's communication service
* When the communication service is awaken,it inspects the packet in the buffer
* Based on the content of the packet header,the service searches for the application which isthe destination of the packet
* When it finds the exact application, it posts a synchronous eventto that application program
* After receiving the event generatedby the communication stack, the application programproceeds to process the packet
* In some cases, it is necessary forthe application program to replay by posting some data to the communicationstack before returning the control to it
* Then, when the communication stacktakes control, it places the reply in the communication buffer andappends its header to the outgoing packet
* Finally, it gives controlto the device driver, so that the packet can be transmitted
* After understanding the big pictureof Contiki's communication stack, let's examine itsstructure with more detail
* There are two types of communicationstacks in Contiki, Micro IP and Rime
* In this lesson, we will only discuss Rimeand leave micro IP for the next video
* What is the Rime communication stack
* Rime is a lightweight communicationstack with a layered design where the more complex communicationprotocols can reuse the simpler ones
* When using Rime there is no rulethat compels an application to go through all the layers ofthe stack in order to communicate
* Instead it can use any primitive orprotocol that it requires
* Both single hop andmulti-hop communication primitives are fully supported inContiki's Rime communication stack
* However there is no packet routing inthe multihub communication primitives
* This task is specified by the applicationor the upper layer protocol
* One of the benefits of Rime stack is thatusers can implement all their protocols, which do not belong toRime on the top of it
* So now let's take a look at some ofthe primitives available in the set of communication abstractions in glide
* First is single-hop broadcast
* Where the sender's address isadded to the outgoing packet before sending it to alllocal area neighbors
* Then we have single-hop unicast, which is used to send packetsto a specific destination
* The reliable unicast is anothertype of single-hop unicast that repeatedly sends a packet to a particulardestination while waiting for an acknowledgement packetfrom the receiver
* Finally, the multi-hop unicastprimitive is used for sending packets to an identified node in the networkwhich is located several hops away
* In this case, a rooting function mustbe provided by the application or protocol to choosethe next hop destination
* This is the end for the lesson about Contiki communication andground communication stack
* By now, I hope you have a deeperunderstanding on the way Contiki's communication is structured andhow it works
* See you in the next video
* [SOUND]


--- SKIP ---: 06_communication-in-contiki-ii.en.srt


--- SKIP ---: 06_communication-in-contiki-ii.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_communication-in-contiki-ii.en_SENTbySENT.txt
* [MUSIC] Hello
* I am glad to see you back for this lesson
* This time we will explore the detailsof micro IP communication and stacking Contiki
* By the end of the lesson,you should understand the benefits and challenges of using Contiki'smicro IP communication stack
* The micro IP stack is a communicationlibrary provided in Contiki for supporting TCP/IP protocolson small micro-controllers
* Some of the benefits of using microIP stack are its small code size and that it requires only a fewhundred of bytes of RAM
* Although it is lightweight, it isimportant to notice that the necessary RFC requirements affecting host tohost communication are fulfilled
* However, some complicated communicationmechanisms have been removed from micro IP in order to make it suitable forembedded systems
* For example,the soft error reporting mechanism and the dynamically configurable type ofservice bids for TCP connections
* Are not present since thesemechanisms are not required in most wireless sensornetwork applications
* It is important to noticethat removing these services does not affect the quality of service
* The micro IP stack can beexecuted either as a task in a multitasking system or as the mainprogram in a single task system
* In multitasking implementations,it is common to implement two tests
* The first one is constantly checking forincoming packets
* Whereas the second one is verifyingthe occurrence of a periodic timeout
* Once a packet arrives,the micro IP input function is called
* Then the receiving application maycreate a message for replying
* Periodic timeouts play important rolesin TCP because many activities and functions require this information forperforming their task
* For example, retransmission and round triptime estimation requires periodic timers
* Instead of using explicit dynamic memory,micro IP uses a single global buffer for restoring incoming packets and a fixedtable for holding connection state
* The size of the global buffer is designedto fit the maximum size of a packet
* When a message reaches to a destination, the message is stored in the globalbuffer and wait for a TCP/IP stack
* In cases where the packet contains data,the TCP/IP stack will notify the appropriateapplication to process the data
* The application which the incomingpacket is targeted to can immediately process the data or copy it toanother buffer for future processing
* The global buffer is used forboth incoming and outgoing packets, as well as for headers
* Therefore, this tech can use the partof the buffer that is not reserved for headers as a temporary memory for dealingwith applications sending dynamic data
* The memory footprint for implementing micro IP varies dramaticallydepending on the application
* For example, there are less requirementsin terms of memory usage for a simple Telnet server
* Than for other complex applicationswhich perform very complicated tasks
* It is possible to implement microIP with a very low memory overhead
* As for example, with the memorysize of less than 300 bytes
* However, this implementation will affectother features or reduce service quality
* To interact with the micro IP stack,an application program interface or API is used
* The API comprises a set of software and functions to make applicationdevelopment easier
* Currently, the BSD socket API seems tobe one of the most popular APIs for TCP/IP, since it is used in many Unix andLinux systems
* However, the BSD API is not suitable for micro IPs tech due to its requirementsof support from an underlying multi-tasking operating system andthe overhead of memory usage
* Instead of using a BSD API,Contiki provides two simple APIs that include proto-sockets and a simplerversion of BSD with low overhead
* Similar to Rhyme Stack, the micro IPstack is designed in ledgered fashion, where each functionality will beperformed by a particular protocol
* While interactions between the protocollayers are strictly defined
* Using the layerds structure for designingprotocols and stacks is a good approach
* However, it is not ideal forimplementing them
* In micro IP, the protocol implementations are tightlycoupled in order to save code space
* This is the end of the lesson aboutContiki's micro IP communication stack
* I hope by now you have a good idea aboutthe structure of Contiki's micro IP stack and how it works
* Thanks for watching
* [MUSIC]


--- SKIP ---: 07_protothread-multithreading-and-code-sizes.en.srt


--- SKIP ---: 07_protothread-multithreading-and-code-sizes.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_protothread-multithreading-and-code-sizes.en_SENTbySENT.txt
* [MUSIC] Welcome
* In our previous videos, we examinethe many structure of Contiki core and other features
* Now, we are going to discuss one ofthe most important features of Contiki that is Contiki protothreads
* In order to provide sequential flow ofcontrol, Contiki provides protothreads instead of using complex state machines orfull multi-threading
* Protothreads are lightweight and stand as stackless threads with onlytwo bytes of memory per thread
* One of the benefits of usingContiki's protothreads is that systems overhead can be smallcompared to other kernels
* This comes as a result of sharingthe stack by old protothreads
* This has the additional benefit thatcontext switching can be done easily by stack rewinding
* It is more efficient to implement Contikiprotothreads than applying traditional ways of multithreading on wirelesssensor network applications
* Contiki's protothreadsare extremely lightweight
* Similar to other modules and processes in Contiki, protothreadsare completely written in standard C
* This avoids any extra requirement forusing and compiling protothreads
* Now you have some idea ofthe structure of protothreads, you may wonder how they really work
* A protothread basically workswithin a single function and cannot span over other functions
* It is possible fora protothread to call another function, however it cannot plug the flowinside the called function
* Some of the popular applications usingprotothreads are memory constraint systems, event driven protocol stacks, deeply embedded systems andsensor network nodes
* In order to give you a completeview of Contiki protothreads, we are going to discusshow they are implemented
* Protothreads are implemented usinglocal continuations, which are used to present the current execution stateof a program at the specific places
* A local continuation can be implementedusing one of the following three ways
* These are machine specific assembler code, standard C constructs,or compiler extensions
* The first way can be done by saving and restoring the processor state,except for the stack pointers
* As a result, each proto-thread usesaround 16 to 32 bytes of memory
* The second way of using a standard C for implementation requires only 2 bytesof state information per protothread
* Although this approach has slower memoryoverhead it still has some challenges and restrictions
* The last method is touse certain C compilers which have a specific C extensions forimplementing protothreads
* For example, a GCC version supporting label pointerscan be a good candidate to perform this
* As a result, only four bytes ofRAM per protothread are required
* Now, I will show you an example of sealedcode of protothreads in this slide
* Please take your time andlook at the construct in detail
* We are now going to explore anotherimportant concept supported in Contiki, that is preemptive multi-threading
* Instead of implementing multi-threadingin the core, Kontiki implements multi-threading as a library onthe top of the event based kernel
* This gives the advantage thatthe library is only linked with applications built with the need formulti-threading support
* Multi-threading is implementedby using timer interrupts
* The implementation isdivided in two parts
* A platform specific part anda platform independent part
* Unlike a conventional Contikiprocesses discussed previously, each thread in multi-threadingrequires a separate stack
* They run in separate threads until theyyield explicitly or get preempted
* The multi-threading library providesa set of API's for easy interaction
* Some example methods of multi-threadingAPI are shown in this slide
* Have you ever heard ofOver-the-air programming
* Over-the-air programming isa simple Contiki protocol to program the entire network of sensors
* Basically, the protocol sends a singleprogram binary to a destination node or concentrate node viapoint-to-point communication
* Their received binary is stored in first
* When the whole programis completely received, the protocol continues to propagate thebinary program to other neighboring nodes
* In cases of packet loss, negative acknowledgment issent to the concentrate node
* Then the node starts torepair data packets
* It is convenient to use the protocolto upgrade the whole network of sensors quickly
* Let's start to analyzethe code size of Contiki
* To see how large it is and to do codesize comparisons between Contiki and other embedded OSs,there are some strict requirements for an operating system of embeddedwireless sensor network devices
* These requirements arise dueto resource constraints
* Memory, which is one of the mostprecious resources of embedded devices, must be considered whenchoosing a suitable OS
* Let's examine the minimum RAM and ROM required to run a simplewireless sensor network application
* Note that RAM and ROM usage varydepending on the actual application
* For instance, a simple wirelesssensor network application takes less than 2 kilobytes and30 kilobytes respectively
* Please take your time to see this slidewhich shows detailed compile code size and RAM usage of a Contiki always compile fortwo architectures
* The Texas Instruments MSP430 andthe Atmel AVR
* So this brings us to the end of the video
* I hope that you got a good understandingof Contiki protothreads and multi-threading
* Thank you for participating andI hope to see you in upcoming videos
* [SOUND]


--- SKIP ---: 01_cooja-simulation.en.srt


--- SKIP ---: 01_cooja-simulation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_cooja-simulation.en_SENTbySENT.txt
* [SOUND]>> Hello and welcome to the lastlecture of this module
* In previous videos, we studied the mainstructures of Contiki Core, and other important features
* We are now going to cover the last piece,the Cooja simulator
* Cooja is a simulation software forwireless sensor network applications
* It works with Kontiki seamlessly
* By using Cooja simulator,wireless sensor network applications running in Kontiki can beported to different platforms, such as TI 2258, SECUduino,and sit one mode
* The simulator allows several libraries tobe loaded in the same Cooja simulation
* For example, a large wireless sensornetwork application can be formed from heterogeneous sensor nodes,which vary in terms of hardware platform
* In addition, Cooja providesseveral features for analyzing and controlling a Contiki system
* Cooja can be used for different OSs,including Windows, Linux, and even Mac OS
* The Cooja simulator is located in thetools folder of your Contiki distribution
* For convenience, I will continuethe discussion with the latest version, which is Contiki 3.0
* However, please note that all steps and commands performed hereare similar in Contiki 2.7
* You start the Cooja simulator with thefollowing commands shown in this slide
* If the simulator does not startafter the second command and shows an error, don't panic
* The problem is that in the newest version,Contiki 3.0, the folder mspsim is empty
* In order to fix this issue,you have to download MSP from this link, and then follow the shown steps
* Once Cooja opens,you create a new simulation by choosing File > New simulation
* This opens a window to create a newsimulation, as shown in the slide
* There are several boxes that allowyou to fine tune your simulation
* They have default values, but you canalso set your application's requirements
* For most applications,unit disc graph medium, UDGM
* Distance loss is suitable forradio medium
* The delay to start a mode isset in Mode startup delay(ms)
* Final setting is the seed forrandom number generator in Random seed
* When you finish the settings, click on create butter to have your newsimulation open as shown in this light
* The interface has five windows
* These are: the network window in the upper left corner showsthe network's physical layout
* The Simulation Control windowin the middle top part is used to control the simulation
* You can stop, start, andreload the simulation
* The Mote Output window at the center showsany serial output generated by all motes
* The Timeline window at the bottom
* Shows events that occur on each modeover the timeline of the simulation
* And finally the Notes windowin the right side for temporary notes in the simulation
* Let's now start to setup a wholenetwork of a single RPL border router
* We start by adding single border router
* To do this, go to Motes then Add Motes followed by Create New Mote Type,and select sky mote
* In this example we work with the sky mote
* You can choose any types of mote dependingon your application's requirements
* Remember to give the motetype a useful description
* Create border router and several nodes Now the slide shows a form forcreating a new mode type
* Now, we will need to fill all the boxes
* The first one is the mode name
* In this case,we set the name as border router
* In the second box, we providethe path to the source of the node
* There are two types ofsources we can provide here
* The first one is the source file in C,and the second one is a compiled file
* In this example, we did notcompile any source for a sky node
* Therefore we provide a c sourcefile of the RPL for the router
* Now, we can compile the source fileby clicking the compile button
* It is recommended that youclick clean before compiling
* When the compilation is successful, you can create a border routerby selecting the Create button
* Now, a new window appears
* You must fill all the empty boxes
* It is also fine to leavethe default settings here
* The only box that you must fill or edit isthe box labeled as number of new nodes
* In our network we only need oneborder router, so the value is one
* After choosing av node, a single borderrouter node appears in the network window
* We need to repeat these samesteps to create additional nodes
* The only two differences are the sourcefor the nodes and the number of nodes
* In this case, we provideCaesar's file from the directory, which you can find on the slide
* Please follow the detailed stepsin the slide to add more notes
* Once everything is successfullydone you will see a total of six randomly placed notes onthe network window as shown in the slide
* Out of the six nodes,node one is the border router
* And the rest are the nodes whichwill execute unicasts sender code
* Note that you can click, drag nodes, and locate them at your preferred location,to create your own network topology
* When you click on a node, it also showsthe radio environment in green and grey color
* Please note that to haveradio enviornment and network traffic displayed, you mustchoose these options in the View menu
* Even though the networklayout is now set up
* It is not jet complete
* Before starting the simulation a bridgewith the rpl network must be created
* The bridge is responsible for the connection of the localnetwork with the internet
* It means that bridging helpsthe border router become connective with the outside world
* Subsequently IP address ofthe border router can be pinged
* We create the bridge usingthe command shown on the slide
* And the results should be similarto those shown on the bottom
* We verify this using a web browser toconnect to the router using this address
* If you also get a results similar tothe one shown here congratulations, you have successfullycreated an RPL network
* I hope that after this video you cansimulate your own one application with and use it for a capstone project
* With this video we conclude the module
* I hope you enjoyed watching
* [MUSIC]


--- SKIP ---: 01_course-preview.en.srt


--- SKIP ---: 01_course-preview.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_course-preview.en_SENTbySENT.txt
* [SOUND] Welcome to our course on Interactive Computer Graphics
* In this course we will learn design andimplementation of interactive tools for visual problem solving
* Visual problem solving appearseveryday in our daily life
* Medical doctors plan surgical operations
* Coaches teach how to play sports
* Engineers andarchitects design products and buildings
* And fashion designers design garments
* Scientists try to understand nature
* All these activities involveintensive visual problem solving
* And our goal is to have theseactivities with computation tools
* And they have
* First, computers can help youunderstand incoming visual information
* And the second, computers can help you come up with newsolutions based on this information
* And finally, computers can help youcommunicate these results to other people
* In this course, we will introduce varioustools we developed in our groups
* As example cases, topics include,graphical user interfaces, [SOUND] 2D Drawings, and [SOUND] 3Dmodeling, and [SOUND] Fabrication, and Computer-Aided Design, and[SOUND] Real world interactions
* And then we'll show five demonstrationson described implementation details
* Stay tuned
* I'm looking forward to seeing you
* Thank you
* [MUSIC]


--- SKIP ---: 02_introduction.en.srt


--- SKIP ---: 02_introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_introduction.en_SENTbySENT.txt
* [SOUND] Welcome to our course on interactive computer graphics
* This is our course introduction
* Let me first describe, what we mean byinteractive computer graphics
* First this is not about real time rendering, this course is aboutinteraction [NOISE] and specifically we discussinteractive techniques and systems for visual problemsolving
* So not
* Let me describe what we mean by visualproblem solving
* So visual problem solving we mean, visual,all visual aspects of human intelligence
* And I think visual problems consist ofthree parts
* First you have to understand incominginformation, and then you have to come up with a solution about the problem and then youhave to communicate the idea to the otherpeople
* And this kind of visual problem solving appears everywhere in most professionaland daily activities
* Such as, for example, medical doctors plansurgical operations, or coaches teach how to playsports
* And product designers, architects, designproducts and buildings
* And costume designers design garments
* And then a scientist trying to understandnature
* And all these activities involve intensivevisual problem solving
* And our goal is to make these processes more efficient, productive and pleasantusing computer technique
* Technologies
* Leveraging interactive computer,interactive computing
* Let me know describe what we mean byinteractive computing
* So let me compare interactive computingwith old style command based interaction
* So old style interaction is command based,so user gives command to a system and then system does atask
* And then user sees a result
* And this is kind of asking a computer, dosomething
* But Interactive Computing we mean morelike an augmentation of human activities, likethis
* So user continuously walks on a program, and then system continuousprovides feedback
* So this is the kind of walking stair wewant to emphasize in this course
* So Interactive Computing is to augmenthuman intelligence by providing rich feedback in very rapidlyand very fast
* And so it continuously sup providefeedback
* And the, it accepts intuitive input, andthen provide intuitive feedback
* And then behind the scenes, it should,tries to do some intelligent computation
* And in this course, the students will nowknow how to do, using an IOS system
* So let me explain the course in thebroader context of computer science
* The computer science field is roughlydivided into 2 fields
* Theoretical field
* And the applied view
* And among the applied view, our course isrelated to sub-fields called graphics and visualization, and human-computerinteraction
* And, so this course can be seen as an introduction to these computerscience sub-fields
* And let me show you a couple topics wediscuss in this course
* So first we will discuss influence touh,to additional graphical user interface
* So we will describe how to implement window operations, scrolling, iconmanipulation and so on
* And then we me, move on to 2D drawings
* So, we, we'll have you how to draw restorations and then also how to movethem
* And then next week is 3D modeling
* So, we will describe how to create 3Dobjects using 2 dimensional input devices
* And then we would discuss how to handledeformation and animation objects such as closing andlobes and also flexible
* [COUGH]rebs object
* And then in the last three weeks we, wemove out of the screen space and then go to thereal world
* So we first discuss how to create physical object out of a three-dimensional model ina computer
* And then we will discuss how to leverage physical simulation to producefunctional products
* And then finally we will describeintroduction techniques that work with our computers or systems interacting inthe real world such as robots
* And this course is basically a case-based learning so each lecture introduce exampleor systems
* And then, exercise help you obtain deeper,lasting, understanding about the topic
* But of course these are just sample examples among many, many infinitepossibilities
* And they are just studying points forfurther exploration
* So at the end of each topic, I will show information and the point is forfurther research
* Further study by yourself
* So in this course throughout theseexamples students learn what we can do and also how we can do it withinteractive computing.


--- SKIP ---: 01_1-1-scrolling-interface.en.srt


--- SKIP ---: 01_1-1-scrolling-interface.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-1-scrolling-interface.en_SENTbySENT.txt
* Hello this is Interactive ComputerGraphics week 1
* The topic we discuss this week isGraphical User Interfaces
* Graphical user interface is windows,icons, menus and so on, and it turns computer controlled programinto visual problem solving
* So whenever you interact with computers oryour smart phone you always have to solve some videoproblem solving
* Visual problem
* In this lecture, this week we introducefive attempts to improve current graphical userinterface operations
* And here the list of topics we discusshere in this week
* The first is scrolling interfaces
* The second is manipulation of desktopicons
* And then pointing by mouse cursor
* And then handling of digital ink
* And then finally we will introduce atechnique for voice interaction
* The first one is scroll interface
* The work we introduce here is called speed dependent automatic zooming forbrowsing large documents
* And the problem we want to address here,is that a navigation of a large document isdifficult
* currently, dominant techniques isscrolling and zooming
* So scrolling usually use a scroll bar
* However, it can be tedious sometimes tocontrol very small knob
* And you can also use light based speeddepending scrolling
* But it's very hard to control when you aremoving too fast
* Typical approach is to use zoominginterfaces to largen [UNKNOWN] documents, but we have tocombine scrolling and zooming
* And can be confusing
* Let me describe with specific examples
* So here is an example
* Okay, so here you have a very longdocument
* And then, if you want to scroll, if youfirst acquire a very small knob
* And then you start logging
* However, if the document is very long, very small mouse movement, causes a bigjump
* And can be difficult
* And also one difficult, important problemis that this kind of chapter structure, is notvisible
* So, if you want to go to, for example,chapter 9
* And it 's very time consuming to findchapter 9
* And another possible interface is writebased scrolling or speed dependent scrolling, so you presswheel of a mouse and you get this the widget and then you can start scrolling withoutcontrolling speed
* And it's okay when you're moving slowly,but as soon as you move too fast
* You know, you have no idea of what's goingon
* It, it's very difficult to navigate
* For example, if you want to go to Chapter6, you know it's very hard to do it usingthis interface
* [SOUND] And The similar program happens in asoperate, applications
* This is an example of map navigation
* And again if you are moving slowly it'sfine
* But as you start moving faster and faster, it's very hard to understand what's goingon
* So typical approach is to manually zoomout
* And acquire target and move, and zoom in,and move, and zoom in
* But you have to switch, go back and forth,between scrolling and zooming
* And it can be very inefficient andtedious
* And now
* So what we propose here is toautomatically zoom in and zoom out depending on yourspeed
* So
* If you're moving, you start from slowly,and then moving fast, and then slow down
* And as you change the speed in this way, system automatically changes thescale of the screen
* So in this way, is the user can navigate through large information space,just by controlling speed
* So, let me show you a demo again [SOUND]So here the same program, but here we enabled automaticzooming
* So when you are moving slowly, nothinghappens
* But as you move faster and faster, systemautomatically changes scale
* So here
* Your speed in the information space isvery fast now
* But thanks to the zooming, the peak cellflow speed is consistent, constant
* And you move faster, and then acquiretarget and slow down
* So in this way, you can navigate through a large information space very smoothly,and efficiently
* Just by controlling speed
* And you can do the same thing with a webbrowsing
* Again, without zooming, if you move fast, it's very hard to understand what's goingon
* With automatic zooming, when you're movingfaster
* System starts to shrink, so here, yourspeed is already very fast
* So it can be difficult to understandwhat's going on without zooming
* But thanks to zooming, pixel flow remainsconstant, constant, and you can keep track of what's going on
* And in addition, the system makes chapterstructures visible
* So it's very easy to
* Go to specific chapter, using thisinterface
* Like chapter 4
* And these techniques can be very useful,[INAUDIBLE] as our applications too
* So this is an image browser
* And again, without zooming, it's very hardto understand what's going on
* So, neighbouring adjacents, snapshot, andthen, next, and then two blocks
* It's [UNKNOWN] to understand what's goingon
* But with zooming, you know, system automatically zoom out, depending onspeed
* And it's very easy to understand, what'sgoing on
* Next image, and then two image, after thisone
* So this is like reading a very bignewspaper
* You know, when you are reading here, andmoving to the next, you go to see the entire overview, andthen go to the next
* And this interface naturally [UNKNOWN],represent this kind of interaction
* So that's a demonstration
* And let me briefly describe, discuss someimplementation issues behind the scene
* So, the basic algorithm is very, verysimple
* This is a governing equation, basicequation
* So a scale, multiplied by speed, remainsconstant
* So which means, if your speed is faster,speed is larger
* Scale get's smaller and then speed issmaller
* And then scale gets larger
* So it's so simple, and easy to implement
* So, this ensures that the perceptualscrolling space, speed, on the screen remainsconstant
* However this naive implementation has someproblems
* So, two problems, sudden zoom-out at thebeginning of scrolling, and then also abrupt swellingat turning the directions
* Let me describe one by one, the first one is sudden zoom-out, so let me describehere
* So naive implementation of this techniqueis fast
* We said speed, proportional to mousemovement
* As in stand out like they're scrolling
* And then scale is calculated based on theequation 1
* So here's a diagram
* So you change the mouse position and thenspeed, linearly increases
* Based on this equation
* Speed equals constant by [SOUND] dy, mouseposition
* And you get speed
* And then based on the equation 1, you getthis speed
* However, look at here
* As soon as you start zooming, scalesuddenly drops
* So this sudden drop is very very annoying, if you're actually interactingwith a system
* So but thinking about zooming, zoomingshould be exponential
* As you move your mouse, scale should be
* Multiplied with the same ratio each time
* For example, as the mouse move here andthen scale [UNKNOWN] half, and now they move faster and the scale[UNKNOWN] in a half again
* So revised implementation, is scale isexponential to mouse movement first, and then speed iscalculated based on equation first
* So, here's a diagram
* So as soon as you start scaling, then scale is exponential function ofmouse position
* Like, like this
* So this will show very constant, smoothscaling
* Then after that, you compute speed, basedon the equation 1
* As a
* You know, inverse proportional
* And then in this way, you will get a very smooth introduction, as shown in mydemonstration
* And then, second problem is abruptswelling at turning
* Suppose you are moving downwards fast
* And then, you moved a mouse upwards
* And then you change the directions, andthen go up
* And then do this
* On here, you know, as you change the direction, velocity and [UNKNOWN] temp,temp, temporarily becomes zero
* Which means
* That scale, equals suddenly zero
* Which means that as you change directionin a screen abruptly it gets larger
* Which is very very annoying
* So one possible solution is like this
* So we introduce delay, in scale change
* So as you change the direction, then zooming scale changes slowly, and thenwhen, when you go back to the ori, originalspeed, and then scale will be recovered
* So this way, you will get a smootherinteraction
* So that's a brief description of the paperwe published at the UIST 2000
* Title, speed, speed-dependent automaticzooming for browsing large documents
* And here is a couple of pointers forsources of study
* Further study
* So one is zooming interface
* Zooming interface is very interesting
* A popular topic in user interface andcomputer graphic research fields
* Original paper was published as an, atSIGGRAPH 93 by Ken Perlin
* And you can still see demos here
* And then there are also many follow upstudies and techniques
* And also this work is One, one example of a research project with the information visualizationtechniques
* And information visualization itself is alarge research field, and you can learn many more from resourcesavailable on the net
* And also there's a very popular textbookby Edward Tufte called The Visual Display ofQuantitative Information
* And I recommend you to take a look at thatbook
* That`s it in this video
* Thank you.


--- SKIP ---: 03_1-2-desktop-icons.en.srt


--- SKIP ---: 03_1-2-desktop-icons.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_1-2-desktop-icons.en_SENTbySENT.txt
* Okay, our next topic is Desktop Icons
* And what we will introduce here is calledBubble Clusters
* So the topic we discuss here, is amanagement of desktop icons
* So, suppose you have a desktop and the onepossible way, the organized desktop is viewedspecial aggregation or special clusters
* So, you put system icons here andshortcuts here and some documents here and documents onother topic here
* So, this way people can manage, variousinformation in limited space
* However, a program is at this kind ofvisual cluster
* Is not comprehensible from a computer
* So they're just icons for a computer'spoint of view
* So, whenever you have, you walk on thiskind of a layout, you have to explicitly selectgroup of objects
* So, that's one problem
* Another problem is that you have to, ifyou put too many icons in a same location, it cancause a cluster
* And if you want to grab one icon hidden, behind these icons, you have to move othericons away
* So that's a problem we want to address
* Let me describe the program
* So here, you be, clearly see four groupshere
* However, system does not understand thesekind of clusters
* So, you have to manually select and move around and then you should get a newgroup
* Then you again, you have to manuallyselect
* Though, this can be very tedious
* Also, if you have, a big cluster, likethis and there you have to pick up, icon hiddenit
* Hidden behind it
* You have to manually move out and thenpick one object
* So, this is very tedious
* So, what we propose is, Bubble Clusters
* So, Bubble Clusters is automatic groupingof nearby icons
* And then visualization of them as in abubble
* And also, additionally, we introduceautomatic spreading of cluster to pick up on hidden icon
* So let me go back to the demonstration
* So here, you have three grids, and if youenable Bubble Clusters, you will see the threebubbles, and then if you grab a bubble, you can drag themaround by, just by grabbing a bubble, withoutmanually selecting a group
* [SOUND] And bubble, is automaticallycomputed, as soon as you place these two iconsnearby
* And there's a little bit very smalldetails but interesting details
* Here, these two and these two, are in thesame distance, however you know, if these two icons arepreviously separated
* They will resist to be merged fast
* But as soon as they are merged, then theystart to resist to be splitted
* So, this is, kind of history resist and itis very useful
* And then you can, you know, move aroundand pick up many icons
* And then, if you have a hidden icon, likethis
* Then you can double click here, and thenyou would temporarily spread icons and then you grab icon and the system goback to the original state
* So, this is a bubble causal technique
* And a bubble clusters technique, and thensame idea can be applicable to this kind of digitalink
* So, if we were walking on digital inksystem
* You know, you probably do not want tomanipulate individual strokes
* Rather than that, each cluster has ameaning grouping
* And then, whenever you draw strokes, the system automatically groups nearbystrokes together
* And you can move around these strokes, bygrabbing blue area
* And if you connect together, it'll be oneobject, and then you can draw line and you will splitthem, so this is very useful for a discussion ora discussion on whiteboard or digital inksbecause that's a demonstration
* Let me briefly describe the essence ofimplementation
* So, we, I will first describe clusteringalgorithm
* So, we use very, very simple pair-wisedistance threshold
* So, for all objects on the screen, firstwe assign each object to one cluster
* So, cluster of object is like this
* And then, for all object pairs, oi on theoj
* If the distance is smaller than threshold
* Then they will merge to object
* Here's a view
* So for each paper, each pair, we check thedistance, against the one threshold
* And if it is smaller, we merge them
* And interesting part is here, thethreshold
* So, if the, if previously, in the previousframe, if the object in the different cluster, then thethreshold becomes very small
* So, difficult to merge together
* And then, if the two objects are from thesame cluster, in the previous step, then it becomes larger,which means very easier to merge together
* And after having a cluster, we regeneratea visualization of the bubble
* And here, what technology we use here, is2D Implicit Surface
* So, Implicit Surface, is, to computepotential field
* Field around each element, and then placeiso-surface over the field
* So, suppose you have one, two, three,four, five object and then we generate this kind of potential fieldaround it, kind of height field
* And then we aggregate them together andthen compute iso-surface
* And here is a visualization
* [SOUND] So, if you have this kind oficons
* And then this will, this one showingspotential field
* As you see, if you aggregate more and more object it becomes brighter which meanshigh potential field
* And after that, we just trace
* lines, with the same height, heights
* And, however, it's very time-consuming, toprocess individual pixels
* So, we compute potential field values atgrid cells, like this
* And after computing potential fields atthe grid cells, then we, out of, we, extract iso-surface by a techniquecalled Marching Cubes
* So, here's a summary of this video
* So, the program we discuss here, is a management of spatially organizedmini-icons on desktop
* And then solution here
* What we propose here, is automaticclustering of nearby icons as a bubble
* And here's a pointers for furtherlearning
* So, original paper was published as aBubble Cluster, Clusters: An Interface for ManipulatingSpacial Aggregation of Graphical Objects
* And the technique we use here, is calledImplicit Surfaces
* And Implicit Surfaces are very populartechnique in computer graphics, to represent liquidsand [INAUDIBLE] object
* And the first publication was at SIGGRAPH82 by Jim Blinn
* And then also, iso-surface extractiontechnique, called Marching Cubes was published at1987
* And this is a very basic literature, and Irecommend that, to take a look at them
* Thank you.


--- SKIP ---: 05_1-3-pointing.en.srt


--- SKIP ---: 05_1-3-pointing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_1-3-pointing.en_SENTbySENT.txt
* Okay
* So, next topic is pointing
* And so, what we introduce here is calledthe Ninja Cursors
* A problem we address here, is that it'svery, very difficult to point to a long-distanceobject very far away
* So, today, the screen resolution is getshigher and higher
* And then the screen gets bigger and biggerand you can even have multiple monitors
* So in, in such a situation it's very hardto get a point, a very distant target withthe mouse you have to you know, move the mouse manytimes to get the target, so this is the problem we'regoing to address
* And then we propose a message to addressthis problem
* Let me show you what we do
* So, yeah, from here we discuss pointingwith the mouse cursor
* But this can be very tedious if some,target is far away like this way
* So you have to clutch marks many times
* [BLANK_AUDIO] So in the [UNKNOWN] program, we propose touse multiple cursors covering the screen
* So here, we have so, four cursors
* And we, if we have multiple cursors on thescreen, you can just use a mouse cursor near thetarget object
* So this can save time for pointing adistance target, that's the technique we propose inthis paper
* But the problem is that, ambiguity, so ifyou have multiple cursors and multiple objectsin the screen
* Then it's possible that, multiple pointerspoint to different targets at a time
* So this is very problematic
* [SOUND] So to address this problem weallow only one cursor to point some object at atime
* So when a mouse cursor is in some other
* Some object
* Then another, other cursor needs to wait until the cursor moves out from thetarget
* So here, the user moves the mouse pointerto the right continuously
* And then, this one goes out
* And, this one goes in
* And the next one becomes in waiting state
* So as you see pointing
* [INAUDIBLE] pointers in a queue
* When tries to, when trying to point toobject
* So, yeah let me describe again
* So the basic idea of Ninja Cursors is tocover the screen with multiple syncronizedlymoving cursors, like this way
* And the user just use the nearest cursorto the target object
* And this one effectively reduce thedistance of the target
* So it reduces average distance from thenearest cursor
* It comes from D
* To D divided by square n
* So n means the number of cursors
* And this one, this help you to point adistant, distant target
* By the way, this is a little bit ofbackground knowledge about pointing
* So pointing is a very popular topic in HCAfield
* And then pointing performer this models bythis kind of equation, and its called Fitt'slaw
* So suppose you have mouse cursor here, andthen you try to point a target with distance D, and suppose that thetarget size is W
* And then, here we consider only onedimensional motion
* And in this situation target acquisition,or pointing time is model like this
* Time equals a plus b log b and then insidethe log is 1 plus D divided by W
* So which means, if the distance is longer,longer, then time gets longer and longer with thelogarithmic function
* And however, the we, width is, is, getbigger then time will be reduced
* So that's equation
* And Ninja Cursors, our techniqueeffectively reduces this D
* [BLANK_AUDIO] And as we have already discussed in thevideo there is a ambiguity problem
* If multiple cursors point to multipleobjects at a time, this can be a problem
* So to address this problem we allow onlyone cursor point to a target
* And others are blocked and in the waitingqueue
* So here green cursor points to this objectand then this red one in the waiting queue, and then ouruser continuously moves a mouse cursor to the down, and thengreen one goes out, and then the red one goes intothe object
* And we provide a visual feedback Normal cursor, Pointing cursor and Blockedcursor
* And also, we also provide visual feedbackabout the waiting time
* So, yeah, that's it and here's thesummary
* So we discussed the problem of pointing a distant target on a very large highresolution displays
* And then our solution is to show multiplecursors and use the nearest one
* And we also describe how to addressambiguity problems
* So original paper was published as NinjaCursors, Using Multiple Cursors to Assist TargetAcquisition on Large Screens
* And pointing is a very, very popular topicin your field
* In many publications
* And here is a couple of interesting recentpapers
* One is bubbled cursors
* And this mean, this bubble cursortechnique changes the mouse size, depending with the targetdensity
* So if the target is dense, the mousecursor gets smaller
* But the target is vast, the mouse cursorgets larger
* So it's a very interesting technique
* Another is called drag and pop, pop anddrag and pick
* So as you see here, as you start to locatean object, then related icons jumps to near the cursor position tohelp you point
* To help you do drag and drop efficiently
* So that's it
* Thank you.


--- SKIP ---: 07_1-4-digital-ink.en.srt


--- SKIP ---: 07_1-4-digital-ink.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_1-4-digital-ink.en_SENTbySENT.txt
* Our next topic is digital ink
* And so what we introduce here is calledFlatland
* And the research goal here is designcomputational augmented office whiteboard
* So, in, work, in many workplaces there isa whiteboard, near the desk, or near thewalking meeting space
* And then you got people take variousnotes
* So we try to provide computationalsupport
* This kind of computational this kind ofwhiteboard
* And this work started with an ob,observation that office whiteboards are used for informer, informal product, pre-productionactivities
* So examples are note taking while you areon a phone
* Or organizing to do list
* Or sketching paper outlines, or discussionwith other office mate
* So this kind offi offline informaldiscussions is what we want to support
* And so this was it was, this was fromusers point of view
* From system design's point of view, whatwe try to do is to design a computational system thatcomplements client desktop computers
* So suppose we have desktop computers, andthen whiteboards
* And these very complementary
* For example the tasks on the desktopcomputer is very goal oriented
* You have a space for goal, preparedocument, prepare presentation make a email and soon
* However works, activities on a white boardis very informal and very pre-productive
* There is no space for goal in many cases
* And then, operation on desktop computerscan be very tedious or complicated because youhave to satisfy many constraints however, white board isvery easy, just pick up a pen, and then write down
* So its very lightweight, simple and easy
* And then finally visual representation ondesktop computers are very formal and typed you see typed text, but however visuals on disc of white boards are very, veryinformal
* So these are the differences and then wetry to support these kind of activities
* And, so, the system we proposed has threefeatures
* And one, is a way to manage space
* The other is to applications running on this surfaces, and also historymanagement
* So let me show you a demo
* [SOUND] So suppose you have a whiteboardand you pick up a pen, and [INAUDIBLE] do writinghere
* So I use mouse here, but please assumethat I'm using a pen on a whiteboard
* And then you can take various notes, suchas like a phone number or you may want to take a note or about aschedule
* [SOUND] Or you maybe just like drawings,or you may want to draw a map
* And as you see, system starts to cluster
* Nearby [UNKNOWN] automatically
* And then you can grab a cluster, and thenmove around
* So, this is very convenient
* You do not need [UNKNOWN] to get that oneup
* Or you can manually spread
* To grab clusters away and so
* And one important program seen here isthat visibility is very important
* If you have desktop Windows, Windowsstarts to overlap each other soon
* But however, visibility is important hereso, you should be able to see all information, all thetime
* So, as you start dragging and if itcollides with other segment, it starts the pushother segments away
* So, in this way, system pretty bends,overlapping
* And if no more space available, it startsto shrink
* So, in this way
* You can still see the content of the[INAUDIBLE], but you can use limited screen space veryefficiently
* And you can just click and start drawing,and click and start drawing
* We also support [UNKNOWN] to other seats,like this way
* So this is kind of infinite screenconnected by horizontally infinite screen space
* So this is the screen management
* And the next feature is applications
* So here is a [UNKNOWN]application we support here
* Like we have to sleep or you may want toeat, and you also need to work
* And then you can change priorities, or youcan delete them
* So here we can use visceral interactionusing pen gestures
* And then another application is mapdrawings
* So you can do a line, and you can get a map or you can erase and you can get amap
* So you just, just draw a single strokes,the system automatically makes them a map
* And one important feature here is thatapplication can be removable
* Here it becomes to view a simple plaindrawing and you can add other operationapplications like this one
* This is a beautification of your
* Informal handwriting
* [SOUND] Look at this
* [SOUND] So another example is [UNKNOWN]
* You draw numbers here and you draw linesand then you look at the result
* We also implemented 3D drawing
* And you draw something, and you canrotate, and you can cut, and then you can rotate
* And if you remove this guy, then you candraw notations and so
* And finally the last feature is historymanagement
* So system remains, remembers everythingyou do on this whiteboard, and then you can getprevious state
* For example, if you draw many many lines,for a long time, then you erase, the system recordseverything in the database
* And then if you get slider here
* You can go back to any previous state, inthe history
* And then can go jump, to a previous state
* And as our feature is context spacesearch
* So, as I said, system remembers allactivity on whiteboard, and later you can search them, just by time or usedbehaviors, or size, or colors, and so on
* And here's an example
* The system searches for the previousdrawings activities, on this whiteboard
* And you can get these instantly
* So that's a demo
* [SOUND] Yeah, yeah, here's an example ofcontext-based search
* So let me describe the videos here
* So user input here consists of two kinds
* One is primary input is given by standardink strokes, mouse left button, and it isalways ink strokes
* And secondary input like the other side ofpen or pen down is bottom down is always acontrol strokes and then input strokes is always inking so itsalways up growing on the screen and then control stroke isfor controlling applications
* So it can be a eraser, or can be dragging or existing object orsplitting over segment
* Or a pie and the marking menu
* A pie and marking menu is a laterallyarranged menus
* And let me briefly describe thearchitecture behind the system
* So this can be seen as a kind of penversion
* Standard graphical user interface Windowsystem
* So here a comparison, so we have StandardGraphical User Interface and our Flatland
* So Standard Graphical User Interface use amouse, but here we use a pen, and then Standard GUI use widgets and pixels andhere everything in strokes
* And Graphical User Interface use Windowsbut here we use more informal segments, and then GraphicalUser Interface applications corresponds behaviors and the important thing here isthat in GUI Windows and applications are very, how to say consis,persistent object
* And application is tightly connected toWindows, but here, segments can be merged or split
* And also, behaviors can be flexiblyattached or removed compared to the Windows andapplications
* And here's a structure in StandardGraphical User Interface Windows system
* You know, data is, and handled byapplications
* Application encapsulates internal data,and then take mouse input, and then generates displayoutput
* Using various, rejects
* In contrast, in our case
* You know, behaviors outside of the strokesand then it opens up the strokes on the board and then add strokesand removes strokes and so on
* So, behavior works as an attached serviceto the whiteboard
* [SOUND] yeah, here is a little bit moredetails
* So here's a code example of a behavior
* So this is PlainDrawingBehavior
* So this one takes inputstroke, and thenjust put in the stroke
* And the code looks like this
* So, addInputStroke, handle's InputStroke
* And then just put, painted stroke to thesegment
* So it's plain drawing behavior
* And in the case of map behavior, it takes[INAUDIBLE] stroke and then two sided street, the codelooks like this
* So for add input stroke event, the input stroke is divided into left and rightstroke
* And then these are individually added tothe segment
* So, yeah here's a summary, the program wewant to address is management of multipleinformal tasks on a electronic whiteboard system and then wepresented kind of window system for this link with very,very flexible structures
* And here's further reading
* The original work was published as Flatland, New Dimensions in OfficeWhiteboards
* And if you learn more about gesture recognition, there are a couple pointershere
* The Rubine, specifying gestures by exampleis a very original work on example based gesture recognition,which was published in 91
* And the reason to why is one examplereason to why is gesture without libraries, toolkits or training a $1recognizer for user interface prototypes
* And also I showed pie menu and markingmenu here
* And this is interesting widget, popular inpen computing
* And you, I also recommend that you take alook into this literature
* Thank you.


--- SKIP ---: 09_1-5-voice-interaction.en.srt


--- SKIP ---: 09_1-5-voice-interaction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_1-5-voice-interaction.en_SENTbySENT.txt
* Hello, our topic here is voiceinteraction, and the work we introduce here is voice andsound
* So here the background motivation, we seethere are two aspects in our voice
* So one is verbal information
* And the other is non-verbal information
* And typical speech interactions use verbalinformation such as they convert your speech into recognizablecommand and then do something
* But however, on the other hand, our voicealso contains non verbal information such as pitch,volume, speed, and so on
* So these are non-verbal information has been ignored in traditional speechrecognition
* But here, what we want to do is leverage, leverage these non-verbalinformation in your voice
* And here is a kind of concept
* So, interaction turn-around is very long in traditional voice or speechrecognition
* So you say something, and then computertries to understand it, and then you say something, and the systemtries to do something
* And this is, this is very, very, verytime-consuming
* And it's very discontinuous
* On the other hand
* For example if you are working on a,mouse, if you grab an object, you continuously move your mousecursor and then the system continuously providesfeedback
* So this kind of direct manipulationexperience is what we want to achieve, as in computer
* So we, in our technique, the usercontinuously produce makes your voice, and then system continuouslyprovides feedback to your vocal input
* So let me show you a video
* So, here, we introduce three techniques
* The first one is more simple
* On/off button
* So here, your voice works as on/offbutton
* So if you say nothing, it's off
* So if you say something continuously itmeans you press button
* Here's an example
* So here, typical approach is voicerecognition
* So if you want to move this node, say, maybe you say 30 degree, and you getresult here
* And so, 90 degree, you get result here
* But again if you use voice recognition,interaction can be very discontinuous
* Here your voice is a switch, so if youmake voice this one starts moving, as you, as soon as you stopspeeching, speaking it will stop
* So you can continuously see the visualfeedback [SOUND]
* So as you see, you can continuously getfeedback, so if you get a satisfact result, satisfactory result, you just stopspeech and you get a result
* And if the voice is very annoying ordifficult to produce you can make any noise, so you can use abreath
* To control a system
* >> Down
* >> And if you combine this withtraditional speed recognition, you can do somethinglike this
* [SOUND] Again, traditional approach is to say, like, 100 meter
* Away, or one kilometer away, and so on
* But it's kind of difficult to understandwhat's going on
* But here, you just speech, and then stopspeaking
* And this especially useful for zooming
* You know, zooming 1.2 is very difficult toimagine
* But here, you just see it
* >> Bike
* Zoom out
* Out
* Up
* Up
* >> Okay so that was a fast technique andhere is the second one
* Second one is addition to on and off, youcontrol, control a parameter using a voice, using a pitch of yourvoice, so you let me see
* [NOISE] So you control a slider with thepitch of your voice
* [NOISE] It's very, very st, stable, that'sa most important part [NOISE]
* >> Up
* Down
* Down
* >> So, here, in addition to controllingthe distance, you can also control a speed of thescrolling
* >> Up
* Right
* Up
* >> [NOISE] Again, higher the voice, the faster you move
* So, so far, I showed very continuouscontrol parameters, but here, the last one is discontinuousDiscrete Control by Tonguing
* So suppose you want to change TV channel,or something like that
* >> [SOUND] down
* [UNKNOWN] Left
* [UNKNOWN] up
* [UNKNOWN] right
* [UNKNOWN] down [UNKNOWN]
* >> So here we use very, very basic signalprocessing, so you can do any noise, so you can also clap yourhands to control it
* >> Down
* [SOUND] Right
* Right
* [SOUND]
* [BLANK_AUDIO]
* So those three techniques we introduced
* And then next we, I will show you a couple entertainment applications ofthese techniques
* The first, okay, the first one is jumping game using yourvoice
* Up, up, up, up, up, up, up, down
* >> So next one is using pitch control to control thevertical position of this fish
* [INAUDIBLE] So last one is, like punching game usingyour voice
* [UNKNOWN]
* [SOUND] So that, that's it and let me goback to the slide
* So let me briefly describe theimplementation of this kind of system
* First, where we use a signal processingtechniques
* And we use existing
* A fourier transform library
* So it transforms input voice signal datainto frequency domain
* And then application is control'simplemented in Java
* And the first technique, on and offcontrol is very, very nice
* Implement this and we use
* It just checks total volume, total power
* Or was the input signal
* And if it's, we check whether the total volume is larger than the threshold ornot
* One implementation detail is that weignore low frequency part to subtract, separatebackground noise
* An important part is pitch detection, so
* We con, we use voice pitch to controlparameter up and down but this needs to be very, verystable
* A naive approach is to use identifyabsolute pitch for each voice
* So here's an input signal and then try toidentify the dominant pitch
* However this is very very difficult
* It's very ambiguous, noisy, and unstable
* Please imagine that at this kind offrequency signal, is changing all the time and then it is very difficult toidentify a peak
* So some t, at some point this is thehighest
* But at nex,next moment this one getshighest, so it's very unstable
* So this naive approach is not works verywell
* So our approach is to just all checks slightly up or slightly down of eachframe
* So in this way the result is very stable
* So we only check whether the pitch isgetting high or lower, a little bit
* So here's a detailed algorithm
* Suppose you have this kind of spectrum oftime t0
* So the vertical, horizontal axis isfrequency, low frequency to high frequency, and for each frequencyyou get amplitude
* And then you get another thing now of t0plus dt
* And then your task is to detect whether this frequency signal is shiftingdownwards or upwards
* So in order to do it, we get this we aggregate this signal into a vector,and then in the next time
* For the next fray, we get a vector for the shifted upwards and also shifteddownwards, so you have three vectors
* And then we just compute dot productsbetween them
* So this one is dot product between v and vminus
* And then you compute also v and v plus
* So if v minus is higher, then v minus ismore closer to v, so which means that the pitchis shifted over
* And then if this thought product of v plusis higher than v minus, which means that v plus is closer to v, which meansthe spectrum is, gets higher
* So this very, very simple implementation
* Returns a very, very stable result
* So here's a summary
* So we discussed problem of controllingobject continuously, using your voice, usingnon-verbal features
* And then our approach is to use anon-verbal aspect of your voice
* And the original paper was published asVoice as Sound, Non-verbal Voice Input forInteractive Control
* And multi-modal interface using gestureand voice is also a very popular topic in your field, and very original paper wascalled Put, Put That There so you say, put and then say that,showing some object
* And then again say there
* And they're showing another object usingyour gesture
* And then you get the task
* And the video is available on the YouTube
* So I recommend you to take a look at it
* And also there are a couple of interestingvoice based interaction techniques
* And one recommendation for you is speechcompletion
* And this one tries to complete
* Your speech in the middle
* And also video is available, so Irecommend you too take a look at it
* Thank you
* So this is the end of week one
* Some topic we discuss in this week wasgraphical user interfaces
* And then we discuss scrolling interfaces,the manageable desktop icons
* Pointing techniques on the large screen
* And management of digital ink
* And then finally, we discuss voiceinteraction
* Thank you.


--- SKIP ---: 01_2-1-diagram-beautification.en.srt


--- SKIP ---: 01_2-1-diagram-beautification.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-1-diagram-beautification.en_SENTbySENT.txt
* [SOUND]
* [BLANK_AUDIO] hello, this is week two of interactivecomputer graphics
* And the topic of this week is, 2D Drawingsand Animations
* And here's a list of topics, we discuss inthis week
* The Diagram Beautification, Pen-and-inktextures, Shape Manipulation, and then DynamicIllustrations
* The first one, is Diagram Beautification
* The work we introduce here, is calledPegasus
* And the problem we discuss here, is adrawing of this kind of geometric drawings, and it's very tedious to draw this kind of diagram, using traditionaldrawing systems
* For example, if you want to draw, this kind of symmetric diagram, you have todraw first half draw, draw half of it and duplicate it, and then flip it and moveit
* So, you have to combine three, two orthree commands to do a symmetric drawing
* If you do something like, like this, like symmetric, perpendicular, and the same gapand connect it
* And then, it becomes too difficult to doit, with combining appropriate commands
* So, what we propose is to automatically,have the system automatically take care of thesekind of constraints
* Here is our demonstration
* So, this is again designed for pencomputing
* So, you directly draw a line on the whiteboard, and the systemautomatically provides feedback
* So here, you draw a line, and then thesystem automatically beautifies it
* And if you draw a line, systemautomatically beautifies it
* So, this point is automatically aligned tothis point
* And then you draw a line here
* And the system automatically beautifiesit
* And if you do a line here, this is almostperpendicular to the slope
* The system makes it perfectlyperpendicular
* So, in this way, you just draw freeformlines
* And then you will get this kind ofdiagram
* Traditional, in, in traditional systems,you have to draw rectangle separately and then move it, rotate,connect, and so on
* So, it can be very tedious
* But here, you just draw six lines and thesystem automatically beautifies it
* And you can do many more things
* For example, if you draw, almost symmetricline
* System makes it, perfect mirror image
* And you just draw three more strokes andthen you'll get this diagram
* And if you draw right here, this isidentical, very similar to the previous one, and the assistant makes itan exact copy, of the previous stroke
* So again, you draw three lines
* And you'll get, you will get a copywithout using Copy or Duplicate command and wealso provide equal distance between lines, so in this way, you can get thiswizard specifying grid, before hand and also, you can dosomething like this
* System automatically makes the distance,between two lines are identical
* So traditionally, you have to draw twolines duplicate it, rotate it and trim it, so it can be verytedious
* And one important aspect of this kind of automatic system is that, user input canbe ambiguous
* So, if you draw a line here, this isambiguous, right
* So, user may want to draw a mirror imagehere or you may want to connect these points or usermay want to do this
* So, system automatically infers multiplecandidates and then presents a user and you can choose one of them later, and thisis very important to handle ambiguity
* And that's beautification
* And we also implemented a prediction in,in this system
* So, suppose, you have this kind of illustration already and you draw a linehere
* So, here, system knows that this redsegment is identical to this one
* So, system automatically predicts orinfers that, now that, you draw the same thing, you probably, want to draw thesame thing around it
* So, here's a prediction
* And if you like one of them, just clickit, and the next prediction appears
* So, as long as the prediction is correct,you complete drawing just by successive clicking, and if youprediction is not use, useful, you can just ignore them and youdraw it by yourself, and you again, activateprediction and then click and draw
* Yeah
* And this prediction is very useful for multiple purposes, like drawingrepetitive illustration
* Then you can again click here and then type, touch, [UNKNOWN] segment, and[UNKNOWN]
* So, this very useful for repetitivedrawing
* And this is also useful for symmetricdrawing like this one
* So, you can tap, and then predictionappears
* And then tap, tap, tap
* And then you will get this kind of symmetry doing, just by drawing andprediction
* So, that's the demonstration
* Let me briefly describe the algorithmbehind it
* The beautification algorithm andprediction onwards
* So beautification, works this way
* So far, user input is this red one
* And then, looking at this input, system first the first, learns constraintinference engine
* And then, getting segment coordinatespositions
* And then, infer multiple constraints
* So, in this case, the system infers thatthis should be connected, this should be perpendicular, this shouldbe, horizontally aligned and so on
* Given this possible geometric constraints,then constraint solver, tries to combine them and then solve ithere
* An interesting point here, is that these constraints can be, contradictoryfeatures
* So, constraint solver needs to find validcombinations and after having multiple candidate system, evaluate them, in whichis most closer to the user input and then pick some more,plausible one as a first candidate and then return it tothe user
* And let me, more describe constraintsolvability more
* So, Constraint Solver, as I said, takesmultiple infer for the constraints, and then identified by the combination, and then returns the result, for eachcombination
* And, the details, let me describe thedetails using one example
* Suppose you have these four constraints
* x equal 1, y equal 2, x minus y equal 0, xplus y equal 2
* So, suppose you have these fourconstraints and then tries to find valid combinations
* One combination, is one and two
* So, if you combine these two, you wouldget one and two and it's here
* And if you combine this first and thirdone, x equals 1, and y equals 1 and you get this
* However, you cannot combine these threebecause it's contradictory, so that's what we try to dohere
* And in the system, the algorithm works asfollows
* For each constraint you apply, you make up[INAUDIBLE] We have a set of intermediate valuationslike this, so far as no valuation is given
* And then for x first constraint, you applyit or not apply it
* So, if you do not apply it same thing
* If you apply it, you get one and notvaluated
* So, in this way, you just kind ofbasically binary tree and you can sort of
* Intermediate valuations growsexponentially
* However, in some cases
* Variations can be the same
* For example, this variation combining fastone and this other one, is identical to combining this one andthis one
* So, some solutions are merged together
* So, this is a kind of thing happeningbehind the consonant solver
* And let me briefly describe the predictionalgorithm
* Prediction works as follows, so you havethese kind of existing segments and you get the newinput segments
* At first, system searches for identical segments, identical to the new inputsegment
* And after identifying the matched existingsegment
* Then system collect, aggregate, nearbysegment to the different stroke and they copy them to the new,segment
* And the addition to that, we add verticaland horizontal flip, over the predictions
* So, that's the way, the prediction work,works
* So, that's a,a system and its originalpaper was published as Interactive Beautification, a technique for rapidgeometric design in 97
* Constraint based drawing, is a populartopic
* An original paper was published asSketchpad and this is, a very old paper published in 1963, butthis is still
* Very powerful tool
* And I recommend you to take a look at thevideo
* This was a very fast computer graphics and also very fast interactive computergraphics
* And if you want to see the recent one I'd recommend you to take a look theCinderella system
* This is this kind of constraint-based,geometric drawing system
* And this is very useful for mathematicaleducation and so on
* Thank you.


--- SKIP ---: 03_2-2-pen-and-ink-textures.en.srt


--- SKIP ---: 03_2-2-pen-and-ink-textures.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_2-2-pen-and-ink-textures.en_SENTbySENT.txt
* Our next topic is pen and ink restorationsand pen and ink textures and the work we introduce here istitled Vignette
* The problem we want to address here is it is tedious to draw detailed patterns,manually
* So if you want to draw these kind ofpatterns using your pen, you have to do every detailswhich is very tedious
* And one possible approach is to copy andpaste, to repeat, generally repeated pattern but therepetition is visible and looks too unnatural
* So our approach is to use example based texture synthesis technic publishedin 2011
* So using this technique and combininginteraction technique, you can draw this kind of repeated pattern veryquickly and efficiently
* Let me show you a video demo
* So, if you pick a standard pen
* This is just a standard inking system
* However you can also generate patternslike this way, so you suppose you can draw this kind of,pattern
* And then after you get this, you canextend it this way
* And also this way, so after i, identify pattern you can draw many instances justby drawing
* [BLANK_AUDIO] And another example is this one, so you specify a region first, and then you drawpatterns
* [BLANK_AUDIO] Then after having a pattern, you canrepeat it like this way and then you would just getpattern automatically
* And another interesting feature is likethis, so you select a region
* And then you paint and use your elements,like this
* Suppose you have bricks in this way
* [BLANK_AUDIO] Maybe enough
* And then you can get
* Patterns like this way, and after that,you can tilt it, like this kind of 3D effect
* So this is, i, operation only happensinside this region
* But in this way, you can get, kind of three di, three dimensional effect,within the region
* Another possible operation is hatching
* So, you first select a region
* And then you draw example strokes likethis way, this way and this way, and so on
* And then you, select these two
* And then you get this kind of, matchingpart of it
* And then you can also draw in differentdirections and then you'll get this kind of hatchingpattern very easy
* So let me show you a video
* So here, so you draw example sketches andthen you draw a line
* And the system will automaticallysynthesize it, so it's same pattern
* And you can repeat it many times
* And again, you paint an example, and thensystem requests the desired path, and the systemsynthesizes the same stroke
* So in this way, I use and can paint many, many strokes, without drawingindividual strokes
* And the most important part here is the seamless integration of examplegeneration, and then synthesis spot
* [BLANK_AUDIO] And here's another example
* So you, draw a few example, and the systemsynthesizes a list
* And after the synthesis, you can go back,to the picture that I made
* You can get, you can add more details and these are automatically applied to thesynthesis result
* And you can also change the density, andalso you can change the curve shape later
* [BLANK_AUDIO] The next part example is flood fillsynthesis
* Again, you draw a very few elements, anexample, and then system automatically synthesize, the same textureto fill the region
* And after that, if you want, you canchange the flow orientation, just by drawing the strokes, and then picture will be modified to flo, flow, to flowdirection
* And again, you can change the detailslater [BLANK_AUDIO] And here's an example of hatching
* You draw a few e, e, examples, and thensystem predicts it
* And after that, it will auto provide threedimensional effect, you can use a tilting tool,tilting tool, and then take, given the two dimensionaldrawing you can add, kind of, perspective effect, forindividual regions
* And here is a couple of exampleoperations, so you paint this
* And then you can get many, many hairs,just by sketching
* And the auto-fill can be useful for thebackground
* [BLANK_AUDIO] And, here is the result
* Here's another example
* See, you draw examples and then, fill theregion
* And then, you can use a perspectivetilting to give a more, like, a three dimensionaleffect
* And then background can be painted usingthe picture synthesis
* [BLANK_AUDIO] Now, here is the result
* So that's our video
* And here's a couple of results painted bytest users
* So you can get this kind of eh, sketcheswith many, many repetitions using this kind ofautomatic texture synthesis
* So this is one example and this isanother
* You can get detail, very detailed hairs and very detailed background and hatching,so on
* And you can also get this
* So I think 3D effect is used here andhere
* And the technique we did, use here iscalled discrete element texture synthesis
* And so their technique takes input layout,example layout
* And then it automatically senses a new,larger layout
* Automatically
* Without explicit repetitions
* And what they do, is basically, iter,iteratively refine it
* Let's start with just simple repetitions
* Patch on the copy, repeated patterns
* But gradually improves it
* And then you finally get a very beautifulresult
* And for each step we do this
* So, each step we repeat this
* So first, for each element in thesynthesized image
* For each element in the synthesized image
* We look for the element in the source image with similar neighbor fill orsimilar context
* So, suppose you have an element here, andyou have, you know, circle and bro, circle and boxin this arrangement
* You try to find the most similararrangement
* So that a matching phase
* After identifying a match, then youcompare the context
* So this a synthesized context and this isoriginal context
* And then you compare these two and then try to find ideal position for the,surrounding object
* For example, this box should be more tothe left to be similar to the source
* So in this way, you compute ideal, ideal positions, or target positions forindividual element
* For each pot, match
* And individual element belongs to multiplematches
* We simply take average of all the relatedideal or target positions
* And then move the object to the targetposition
* So by repeating them, then you will getthis kind of a result
* So starting from simple multi-copies
* And then you'll get seamless patches
* Okay so that's a brief description of thesystem called Vignette
* Our original paper was published as ainteractive texture designed migration with freeformgestures for pen-an-ink illustration
* And the technique we used is calledElement Texture Synthesis
* And, it was introduced in SIGGRAPH of2011
* Thank you.


--- SKIP ---: 05_2-3-shape-manipulation.en.srt


--- SKIP ---: 05_2-3-shape-manipulation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_2-3-shape-manipulation.en_SENTbySENT.txt
* So next topic is shape manipulation
* And the method we introduce here is called, As-Rigid-As-Possible ShapeManipulation
* The goal of this work is to move anddeform 2D shapes on the screen, as if manipulating realobject
* So in the real world, you can pick up anobject, with your both hands, and you can manipulate it, moving around, rotate, and pull, orsquash
* And also you can, you know, shake his heador wave his hand and so on
* So you can do many things to interact withit, using your hands on the real world
* That's what we do, on a computer
* And there are a couple of previous works shape, manipulation shape deformation, butthey have couple problems
* The most popular approach is space walk,using a simple function you can can deform the space, and then you can deform theimages in, in embedded in the space
* So this is very efficient for compute
* However, the resulting deformation is likeswapping space and the result is not veryrealistic
* And the other possibility is use physics, or simply meant mass spring water andothers
* And this is a kind of simulation with realworld, so can be very realistic
* While this is very slow to converge andcan be very unstable, and also cannot handlecontradictory configuration
* So, let me show you what we do
* So, again let me fast describe of thecurrent state of the art
* So, this is typical drawing generator
* So you can, do the basic things
* You can, draw something and then you can select an object
* And then move it around
* So, you can do it
* And you can rotate, and you can also scalethem
* However, [UNKNOWN] if you want to, like,shake his head or swing his arm, it's suddenly become very difficult and you have to redraweverything, basically
* And, here is a system we implemented
* So basically the same, you draw threedimensional illustration, however, after you finish drawing you canuse push pin tool, so you put pin here, and then you can manipulatethem, by using these pins
* So, if you pull this, you can pull his,his ears
* Or you can you can, you know, shake hishead, or make him run this way
* So you can, deform the illustration very[UNKNOWN]
* And this is very useful for makinganimation
* Example if you draw this kind ofcharacter
* And then again, this is just twodimensional nothing special drawing
* But as soon as I put push pin, then you,you can make them deform, as if this is aphysical object
* And then, you can also press leg hold,[SOUND] to make motion
* And then, in this way
* So you can easily make him run
* And also you can drag him around, and you can get an interesting animation veryquickly
* Traditionally, if you want to make thiskind of animation, you have to draw many, manydrawings
* But here you can just draw something, and they're moving around, and you will get ananimation
* And here's an example
* Again, nothing special
* Just 2D drawing
* But we can press push pin, and pressrecord, and then you can get this kind ofanimation
* A kick, a kick
* And then you can draw something else here,[SOUND] and press record
* And you can get this kind of animation
* So of course, this is not designed forprofessional animations, but we can quickly generate interestingstories with this kind of technique
* Let me show you one more example
* So, suppose you have a is here, have aworm here
* And then that's a frog fill
* And then let's and then let's put pushpins, and then for a select code, and one andtwo
* [SOUND] So in this way you can make a crawling worm very easily
* And then of course, it's a computer so youcan multiply the main very quickly, and you can make anarmy of worms
* And so far, I only used hand drawings
* But [UNKNOWN] is basically just a shape toformation
* And you can apply the same technique forimages, so this is again just a two dimensionalimage, photograph
* But if you put push pins, then it startsto move as if there is a physical 3D object here, and then you're going togenerate interesting animations
* [SOUND] And so far, I have been showingjust mouse operations, but if you have two hands, youcan do more
* For example here, you have two handedmouse, and then, two handed mice, so, then you can grab screen with your two hands and then moving around a little bit anddeform
* And if you have a multi touch device, herewe use Sony computer science research laboratoriessmartskin system, and it can detect your fingertips
* And you can directly grab object on thescreen, and manipulating them as if you have a,physical object
* So, this is very new way of making andeformable object animations
* [BLANK_AUDIO] So you can use both hands
* Also, two people can work together
* [SOUND] And a little bit more
* So, so far, I showed the deformation of alesion but shape but you can also apply the same technique forthe deformation of a car
* So suppose, you have a cob this way andyou can grab a cob and then deform it thisway
* And if you pull more and more, and you geta larger region will be deformed
* And then you pull more, and you can deformthe entire shape
* [SOUND] And finally, this is not very essential, but we, another convenientoperation is
* smoothing
* So this smoothing will remove small noise,and then after you rubbing, then you will eventually geta very beautiful shape
* So by combining this pulling andsmoothing, you will get a very professional looking smooth illustration,just by starting from a rough sketch
* [SOUND] So okay
* So now, let me briefly describe thealgorithm behind this technique
* So here this is our input
* And then this is output
* A traditional approach is as I said isphysical stimulation
* So, moving the handles, when it tries todeform
* Say a little bit by little, by convertingfours
* In acceleration
* And so, for this kind of a step by stepcomputation and it can be very slow
* Here what we propose is a kind of instantcomputation
* Or final results from this kind of inputinformation
* So input information is initial lets theshape
* And handle positions
* [SOUND] And then target locations ofhandles
* And then we compute the final result
* And what we do is minimize shapedistortion, satisfying constraints
* So let me describe a little bit more
* So again, input is coordinates of handlesand new handle positions
* And they output this coordinated meshvertices or free vertices
* So these as I input on the system copiesall these other vertices
* And what we do is we minimize thedistortion of triangles
* So there are many possible mesh particlepositions
* But one particular shape, minimizedistortion of individual triangle
* Here, in this blue, blue triangle,corresponds to this triangle, and then we try to find the shapes that minimize the deformation ordistortion of these triangles, so that's a problem we want tosolve
* And mathematically, this is defined likethis
* So what rate is to minimize, thisfunction, so this function is what is triangle t, we compute theformation
* For distortion, depending on the given bya products position
* And then we aggregate [UNKNOWN]distortions
* And then, we try to find mesh [UNKNOWN]positions that minimize this energy
* And what we want is energy function
* Specific definition of it that holds nocost
* For translation and rotation
* Translation means moving around, androtation is rotation
* So these are called alleged deformationbecause there is no deformation to this guy
* And in this kind of alleged deformation,there should be no energy
* However, if you scale, make bigger orsmaller
* Or stretch or press here, if you causethis kind deformation to triangle, it should be acause of energy
* So we need very particular energy or cost function or distortion [UNKNOWN] thatsatisfies this [UNKNOWN]
* Another important requirement is that E
* Energy, or cost, should be quadra,quadratic in you
* Which means if u, if this energy is a quadratic to u, then its derivative islinear
* So you can solve instantly by solving si,simultaneous linear equations
* So that's what we want
* So okay, ideally we want the [UNKNOWN]functional, and that causes zero energy for translation or rotation, but [UNKNOWN]energy for scale, stretch or shear
* Unfortunately, we don't [UNKNOWN]
* So there's no such energy in this worldfor quadratic energy
* So we therefore combine two complementarysub-optimal energies
* So here's a description
* So ideally, we want to have this
* But in this world, what we have is only
* Two kinds, so E1 and E2
* So E1 is basically, similarity transform
* It supports translation and rotation, butalso scales and then causes no energy but it can detect stretchand shear, so this is kind of lose energy
* And another E2 is more strict energy
* It only allows translations, no rotation,no scaling, no stretch, no shear
* And then we can have quadratic function
* So E1 is a little bit too relaxed
* E2 is to a little bit strict
* So we combine these two
* So what we do is fast apply E1
* And their scale is wrong and they'rewaiting www E2 to fix the scale
* So, here's what we want
* So as far as the input positions, we fast obtain intermediate result, like this one,by using another E1
* And, in this case E1
* Appropriate handles minimize the, shearingand scaling and scaling [ and stretching, but scaling isallowed
* So you get this kind of inflation in this,you know left arm
* And then after step 1, we
* Correct size or individual triangle andthen we use energy two, to get the correct answer
* So that's the algorithm and, refer to thepaper for the details of these energies
* [SOUND] So original paper is published is As-Rigid-As-Possible ShapeManipulation, [UNKNOWN] file
* And they [UNKNOWN] serious paper to seethe details of the energy definition
* And as I said, previous existing techniqueis popular [UNKNOWN] space walk
* And representative work is called featurebased image metamorphosis
* Published was published in 1992
* And our technique is using segregation oftriangular elements
* And this work is inspired by As-Rigids-Possible Shape interpolationtechnique published in 2000
* And also, our work is related to recentworks on shape deformation
* And I recommend that you to take a look at this [UNKNOWN] paper called on linearvariational surface deformation methods
* Published in, 2008
* [INAUDIBLE]


--- SKIP ---: 07_2-4-dynamic-illustrations.en.srt


--- SKIP ---: 07_2-4-dynamic-illustrations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_2-4-dynamic-illustrations.en_SENTbySENT.txt
* Our next topic is Dynamic Illustrations
* And the work we introduce here, is called sketch based dynamic illustrationof fluid systems
* And the program we want to address here, is that it is tedious to illustrate fluidflow
* Suppose you have a engineering system orarchitecture
* Or organic shapes or a liver system
* There is a lot of fluid systems, and youmay want to describe how the fluid flow in thesekind of systems
* And then you want to get these kinds ofresults
* And it's very tedious to draw themmanually
* So, our idea is to use automatic flowsimulation to automatically synthesize this kind ofdata for illustrations
* So here, the simulation is not used forprediction, but this is used for a niche [UNKNOWN]illustration
* So let me show you a video [BLANK_AUDIO] So this is basically a drawing system
* You draw something, and the system continuously runs fluid simulation behindthe scenes
* And they add fluid flow visualizationsautomatically
* So you draw something, a region
* And then you draw pipes
* And then as soon as you finish drawing a system, system starts flow simulationbehind the scene
* So it visualize a, a detail flow, and alsoshows the result of fluid mixtures
* [BLANK_AUDIO] So this tool is very useful for explainingfluid phenomenons
* [BLANK_AUDIO] So you can interactively edit the shape bydeformation tools
* [BLANK_AUDIO] Okay
* So an, our [UNKNOWN] example is here [BLANK_AUDIO] So here we use these two for explainingsurgical operations for a defected heart
* So here is an example
* So here this heart has very specificconfiguration
* And not very ideal
* And here ideally blue blood come from thebody, should directly go to the lung, and then from the lung,fresh blood, red blood comes into the heart, and then redone should go through the body, however here blue blood is mixed togetherwith red one
* And then purple one go to the body
* So, doctors will perform a surgicaloperation to fix this
* However, before they that, they need toexplain what they do to their patients, or theirpatients' parents
* However, it's very difficult to do thatwith standard tools, currently, they usestandard pen and ink
* Black and white illustration to describethem, however, it's very difficult to understandit
* But preparing this kind of beautifulillustration using computer system, is too time consuming, and moreimportantly, this kind of heart disease has differentconfiguration for each patient, so it's not possible to prepare a templatebefore hand
* So, this kind of tool can be very useful
* To explain and understand complicated flowphenomenon
* And then let me show you how it works
* So first, the operation start with connecting thelocations, and then they will change the configurationhere
* So doctor cuts here and then connect them
* So, as soon as the configuration changes, the fluid simulation changes the flow,prediction
* [BLANK_AUDIO] So next one is the most important one
* The doctor stops here, cut here, and thenconnect here
* And therefore, blood suddenly changes
* [BLANK_AUDIO] And finally, in closing this hole and then let blood directly go to the body, beingred
* [BLANK_AUDIO] And this kind of technique can be veryuseful for various fluid phenomena inside of your body, likeblood circulation and others
* [BLANK_AUDIO] And also this technique is, can be usedfor engineering systems
* Like this one
* [BLANK_AUDIO] And this is another example in [UNKNOWN]so you can see how cold air and le warm air mix togetherand flow
* And you can test many differentconfigurations
* [BLANK_AUDIO] And this tool can be also used for, for explanation of pollution of rivers,and so
* And so now let me describe the otherregion briefly
* So what we use is a hybrid fluidsimulation system
* So user draws global network with localregions
* And we apply different simulation[UNKNOWN] for different scale
* Because single scale simulation can bevery slow
* So, for a global network simulation, weuse simple hydraulic simulation
* And therefore, individual local region, weuse hydrodynamic simulations
* And so, to use a [UNKNOWN] node inflow,and there forms a global network structure, hydraulicscompute it's pipe flow and the node pressure, and then from this nodepipe flow and node pressure, hydrodynamics computes a detailed, computes detailedflow, inside of this region
* So this is a little bit in too involved,but let me describe the way
* The first line is hydraulics simulationfor a global network
* Here, input is node inflow Qn, so how muchflow comes in from the node
* And then what we compute is pipe flow fromnode inflow
* And hydraulics is a simplifiedcomputational method directly computed from compute from node inflow, and to geta pipe flow
* And after pipe flow, we can compute apressure, pressure drop at this pipe
* And then from pipe pressure drop, we can compute the node pressure inside of eachnode
* And you can get these all information bysolving a linear global system once
* It's very fast and it's very efficient
* And after computing pressure node, and[UNKNOWN] pipe flow, we now switch to our regional [INAUDIBLE] sofor each local region
* We compute we divide into a lots of gridcells like this one, and for each grade cell, wecompute pressure and velocity, and in order the computeindividual pressure and velocity, we use a very standard established fluidequation called Navier-Stokes Equation
* So this one is a little bit complicated,but essentially this just explains therelationship with fluid velocity and fluid pressure, you know, if there's ahuge difference in fluid pressure, and itcauses velocity, and so
* And this step basically just solved thisequation times step, each time step on this grid cellsinside each region, to get an animation
* So so original paper was published as sketch based dynamic illus, illustrationof fluid systems
* And if you want to learn more about fluid animation, I recommend you to read sometext books
* One example is Fluid Simulation forComputer Graphics by Bridson
* And this work is an example of illustrative animation for facilitatingunderstanding
* And interesting early dated work is, MathPad, which takes mathematical[INAUDIBLE] expression, and they automaticallygenerates animation, based on the mathematicalexpression
* So that's, this is the end of our second week of this Interactive ComputerGraphics course
* We described dia, diagram beautification
* And [INAUDIBLE] shape manipulation, andalso dynamic illustration with a fluidsimulation
* Thank you.


--- SKIP ---: 01_3-1-suggestive-interface.en.srt


--- SKIP ---: 01_3-1-suggestive-interface.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-1-suggestive-interface.en_SENTbySENT.txt
* [SOUND] Hi, this is Interactive Computer Graphics, week three
* The topic we discuss here is 3D geometricmodeling
* So the challenge behind this is userinterface is still mostly two-dimensional
* So, the question is how to compliment inmissing information
* So, mainly depths here
* So use [UNKNOWN] 2D and how to get 3D from2D
* There's lots of problem with our progresshere
* Our solution, in general, is a user interface, an automatic inferenceleveraging domain specific knowledge
* So if you do not know what you do, it'salmost impossible to infer dips, but if you know what you want to do, if you limit the domain and you can getreasonable results
* That's the basic idea behind the works Iwill introduce here
* And here are the topics that we willdiscuss in this week
* So first one is suggestive user interfacefor modeling of architectural models
* And then there's sketch-based modeling oflarger and stuffed things
* And then we discuss shape control bycurves, and then flower modeling, and thenvolumetric texture synthesis
* The first one is suggestive interface
* So, the work was published as Chateau, asuggestive interface for 3D modeling
* The motivation is here
* So current graphical user interface isdominated through these many buttons, menus, and even more,nested menus
* It's very hard to find design command[UNKNOWN]
* [UNKNOWN]About the operation on what you want to do on the main screen, themain field
* So if we were working on 3D modeling andif you want to do related to these three elements in the scene you can justhighlight these three, which hints the computer to inferthe request
* And then computer looks at the hints, and then provides proposal, for the dataoperations
* In this case, the system proposes a box,and those are our two possibilities
* So, in other words, review the first givenarguments for the command, and then systemautomatically infer the command
* So let me show you a demo
* So here is a three-dimensional modelingsystem with a 3D space inside, and then you can sketchlines in this way
* But here, instead of using many commandson the menu
* We simply allow the user to highlightlines
* And then, for these highlights or hints,system pro, pro presents some suggestions
* Well, why is drawing a plane and anotheris drawing triangle, the other is drawing aleft angle
* And you can also ignore them and thencreate more
* And then given the in-sweep of [UNKNOWN]lines, system predicts, or suggests to make a rectangle,a box
* And then, again, if you do a line here, then given this hint, system suggests tocut a box
* You can also go back and then add morelines
* And then given this hint, system suggeststo cut a corner
* So in this way, user provides the hints to the system and then the system presentssuggestions
* So, this way, user does not really quietthe space [UNKNOWN] one, in the huge command [UNKNOWN], And then you canforecast the visual content of the task
* And if you highlight this, then the systempredicts, or suggests drawing plane, and the user draws forexample rectangle, triangle here
* And if you highlight these three, systemsuggests to make a face inside
* And then if you highlight one more, thesystem suggests extrusion
* And one interesting operation is like thisone
* If you highlight these two and also oneline here, about a third
* And this is, it was exactly dividing tothe three
* We use again also the line somewhere here,and this is [UNKNOWN] divided into four
* So in this way a user can generate this kind of diagram just by, computingoperations
* [BLANK_AUDIO] And after some time operations, you canget these kinds of results
* And this kind of operation is very usefulfor repetitions, and also some symmetricstructures and so on
* Now, let me describe, briefly describe,the implementation behind the, system
* So, this is the input scene
* So highlighted elements and then nohighlighted elements
* So, taking this example input scene then system is equipped with multiplesuggestion engines, they kind of parallel engines workingindependently and then each engine consists of twoparts
* One is examination part and one other isgenerator
* And the examiner examines the scene, andthen tests whether the scene matches withexpected rule
* And then if it passes examination, and then the generator generates the resultingscene
* So this is a very hardcoded program,program module provided the programmer
* But they all works in parallel
* And then specific engine and the act ofspecific input configuration
* And here's our list of suggestion engines
* We input method in this application
* One is [UNKNOWN] given a hint
* System generator [UNKNOWN] passing throughthe hint
* And also if you highlight closed roof, itsuggest polygon, perpendicular two lines suggest rectangle, [UNKNOWN] suggest abox, and system suggest extrusion and pyramidshape
* Now these are resizing and bridges,connecting two, two polygons and the extrusion and this isa cutting out and also corner cutting and trimming andintersection, duplication, repetition, mirror image andso on
* And the philosophy or concept is definedas this
* Standard user interface is like this
* So the user provides very explicit command or very explicit instruction to thecomputer
* And then the computer just blindly, simplyfollows the instruction
* However, what we provide is more friendly,human to human like interactions
* So the user is working on the visual taskdirectly, and then computer implicitly observes the action and thenprovides help and solution, and I think this kind of walkingstyle can be useful
* One possible application is like this, soin your PowerPoint or in any presentation, youhave alignment show
* Alignment to is hidden somewhere in themenu, and it's not easy to find
* For example, in this PowerPoint, you canget there from some way around
* Home, and somewhere, I don't know [LAUGH]height, alignment, and somewhere
* But it's not easy to find
* However, if you highlight these fouralmost aligned element, I think it's pretty reasonable,and also useful for the system suggest particularalignment, in align left or align center, and suggest to theuser
* And if the user likes it, then it justcreate it, and it gets the result
* And this can be a very powerful help forthe user
* So that's it and the original paper waspublished in 2001
* And this work, our work is stronglyinspired by a previous system called the SKETCHsystem
* So this SKETCH system takes twodimensional gestures and the system will automatically generate thiskind of three dimensional scene
* So what they do is very interesting
* So you input this 2D and you need to infer3D position
* To do it the system uses a [UNKNOWN] ofevery object that has to be put on top of everyobject
* In this way, the computer computes 3Ddepths and measures
* Showing multiple candidates for values tochoose is also presented before, the presented work is called DesignGalleries and published in 1997
* I also recommend you to take a look atthis work
* Thank you.


--- SKIP ---: 03_3-2-sketch-based-modeling.en.srt


--- SKIP ---: 03_3-2-sketch-based-modeling.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_3-2-sketch-based-modeling.en_SENTbySENT.txt
* Okay, our next topic is sketch-basedmodeling
* And the work we introduce here is calledTeddy
* And the problem we want to address here isthat 3D modeling is difficult, especially modelingof motion 3D organic shape is difficult
* So a typical user interface is like this
* So typically, you have three views
* And then you have above view, front view,left view and then you put many body sees and you put many edgesand create many faces
* And then you have to combine many, manycommands
* And nest with many and those are manyparameters
* And this can be very useful an idea for a professional production for movies or t.vshows, cars and products
* However, if you want to use this kind of system for communication this is way toodifficult to to
* However on the other hand, if you have a pen and a paper you can quickly drawsomething, something meaningful and more importantly if youlook at this kind of image you can infer some geometricinformation for example
* Probably, this face is, you know, kind oflozenge-shaped, then also hands should not be a bit larger head orsomething like that
* You can get general idea
* So our idea is to implement this kind ofvisual intelligence into a computer to make auseful 3D modeling tool
* So that's the idea
* And let me show you a demo
* So again you get the brown canvas and youpick up a pen, and you try and draw a line on thiscanvas
* And then here you draw something here
* And then as soon as you finished drawing
* System mathematical inflated, and then youget this 3D shape, so now, this is already 3D, so you can see itfrom front or top, or you can also rotate through it,so you get a full 3D shape here, and you can also cutthis object
* You can also paint it and cut it and youcan also add a bump, so in this way you can generate reasonable 3D object just bydrawing outline of the intended shape and internally this isstandard 3D object presentation
* So if you use traditional tools, you haveto combine many commands and also you have to manipulate manyvisual elements, can be very tedious
* And let me describe some, little bitindividual operations
* First operation is creations
* From the blank canvas, you draw closedregion
* And this is the inflated
* So if you draw circle and you get asphere
* And if you get long bar or you get bar or it's you can generate this kind ofsnake shape
* And so, in other words, it is basicallylike this
* So if you have a large region systemincrease a lot and if you get a narrower region, to sustainfor it a little
* In this way, you get always get a crosssection
* Looks almost half, half of a crosssection
* So that's the idea, and let me turn offthe sound
* And so this is very powerful
* So, for example, you can gt this kind of shape or you can also get this kind ofshape
* So again, input is just simple two bestrong
* In this image there is some reasonableshape from two d sketch
* And after having 3D geometry, you caninteract with it
* First, you can paint on it
* Your stroke is projected onto the 3Dsurface
* And you can also erase the pastscribbling
* And then, if your input is inside of theobject it will be projected and painted
* However, if you sort of comes outside onthe inside on the side, it will cut the object by, you know,projecting the line
* And then this useful for our intersectionthat I did in this shape or you can make a mouth likethis way
* So that's a cut operation
* And the next operation is extrusion orbump operation
* So if you want to add a bump
* And you do a closed region, and rotate,and then do a second stroke
* So this is two, two stroke operations
* First stroke defines a domain, and the second operation stroke defines asilhouette
* So, this is basically a sweep or extrudeoperation
* So this the imput it's first throw, secondthrow, and you will get this
* And this is very flexible
* Example, if you draw this kind of shapeyou get a snowman kind of shape and you can also make a mushroomkind of shape this way
* And if you draw outside, it will generatea bump
* But you can also draw inside, and you will get cavity and you can get a structurethis way
* Another example is a same plate likeshape
* So, if you draw this domain, and if youdraw this shape you get a in a wing shape
* And again, you will draw this shape, andthen this shape and you'll get the wing
* See
* This way, you can generate, kind of abird
* And after having some objects, you maywant to deform or edit it
* In order to do so, we also providesketch-based operations
* So it's called this bend button
* So this take two strokes
* First one is a left hand stroke
* The second one is target stroke
* So let's do a left hand stroke, and thendo a target stroke
* So what system tries to do to form a shapeso that lead deforms into groove
* And you will get this result
* So, in this way you can get reasonablesolid shape by sketching, and this deformationto a loose form
* So again press bending and left is input,defines and then moves target
* And then you will get this, this kind ofshape
* And you can also refine some of the output[UNKNOWN]
* So by combining these operation you canget a shape something like this
* [BLANK_AUDIO] Let me show you a couple of 3D models'painted results
* [BLANK_AUDIO] So, all these models are created usingthis technique and they're painted usingtraditional, painting interfaces
* And you can see one can generate areasonable 3D object using this technique
* [BLANK_AUDIO] So let me describe its algorithm a littlebit
* So here's a overview of its algorithm or[UNKNOWN]
* So this is two-dimensional user input
* And then last thing the computer do isfast
* Identify an axis of skeleton thatdiscloses the domain
* So, center line
* On the after computing, this center line,your axis, we lift it, we raise them, in this way
* An important point here is that the amountof lifting
* Depends on proportional, to the distanceto the silhouette
* For example, here, the distance is verylarge, so it gets higher
* However, here, the distance is very short,so it's not to get higher
* So, in this way, you get visible shape and after that, the remaining task is justsimple
* We just put an overall shape along the axis and the silhouette to get finalresult
* So this is overview
* Now let me describe step-by-step
* So input is two-dimensional, polygon orpolyline
* And then, after that, we apply,constrained Delaunay triangulation
* This is very simple computation or generalto the operations, just triangulate them
* And then after that we compute an axis byconnecting mid-points
* Well this is, again, very simpleoperation, but very powerful tool for analyzing theshape
* And this one, this technique is publishedcould use by a person in 97
* And after connecting the mid-points, youget, three kinds of triangles
* One is this, conjunction triangles, withno external edges
* And another is sleeve triangles, with oneexternal edges
* And also, terminal triangles, with twoexternal edges
* And having this, the next topic istrimming
* So before trimming and after trimming
* So in order to in flight or lift central axis we have to remove 3DL edges like thisone
* Now, let me describe how to do thistrimming operations
* So trimming starts from the end of theaxis and remove it one by one
* So it works like this, so if you get thissituation starting from each terminal, we pick terminal edge and draw a circle,half circle
* And if all edges, all peaks are inside ofthe hemicircle, you go inwards, like this
* And again, do a hemicircle, half circle,and check everything is inside
* If everything is inside, go farther
* And now, if vertices are, some verticesoutside of circle, then we stop the trimming operation, andthen you will get, this terminal triangles
* So that's a trimming operation
* And after our previous operation, you getthis idea or shape
* And this is where we stand
* After you get the center shape
* You just lift up the center axisproportional to the distance here
* So, if you look up here, you have serratedline and center line
* And you lift it up in this way, and this length is a bridge of the surroundingedges
* And after that, you just put quarter of acircle in this way and in this way and then juststitch them together
* And the application of this system is forenhancing communications
* You know this technique is not good for production of movies or TV shows and soon
* Or car design
* But this technique is very used for faceto face communication with somebody in frontof white board
* Let me show you a couple of examples
* So one possible application is education
* For example, in a biology class, theteacher may say this is a bacteria
* And then internal select shows it likethis
* And the students can understand the kindof three-dimensional concept
* And then there's the possible applicationin medical applications
* For example, doctor may want to say, thisis your stomach
* And there you have a serious problem here
* And then doctor can say, you know, let'sfix it, and so on
* And or a dentist may say this your tooth,and that there you have a serious problem here and there, and that you needto remove them, and so on
* And one particular interesting applicationwe want to show is teaching of geography
* You know, geography is the concept ofmountains and valleys and rivers or lot of three dimensionalideas, which can be very difficult to understand sometimesusing two dimensional whiteboard, but here if you have a 3D sketching it can be veryuseful
* As an example we want to use a teaching ofcontour lines
* As in you may know it's contour lines, youknow, in the two dimensional map, you see lots oflines indicating heights
* But it can be difficult to understand whatthat means
* Well here, the teacher can say, now, youhave some mountain here, some mountain side view, front view,and top view
* So you have one mountain here
* And now, let me draw lines indicatingequal height, say this is ten meter high, 20 meters, 30meters, 40 meters
* So these lines indicate equal height
* And then this is side view and the frontview
* And if you look, then, from the top, nowyou see that this is a contour line
* And there you can allow many things, likesparse contour lines indicates, you know, gentle slope, and dense contourlines indicate sharp slope, and so
* So, yeah
* So this is a main application we are thinking of this kind of sketch-basedmodeling
* Okay, so to learn more, first I recommendyou to look at the original paper
* It describes the detail of the algorithm
* Not only creation but also extrusion andcutting
* And the technique we use is a chordalaxis
* And it was called morphological analysisof shapes
* And this is very useful to for shapes
* And we introduced polygons mesh basedinformation, another possible approach is usingimplicit surfaces
* So it masters and generates smooth shapes like this one so it generates smoothconnection
* On these, I can also change theconfiguration later
* And this one is called ShapeShop andpublished in 2005
* And I think application is also available
* So I recommend you to try them, too
* Thank you.


--- SKIP ---: 05_3-3-shape-control-by-curves.en.srt


--- SKIP ---: 05_3-3-shape-control-by-curves.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_3-3-shape-control-by-curves.en_SENTbySENT.txt
* Our next topic is Shape Control by Curves
* And what we introduce here is calledFiberMesh
* And what we propose is an extension of the previous technique, which calledsketch 3D modeling
* The difference is that original sketchstays and works as a handle
* So here, the input is very similar
* You draw something and you get 3D shape
* However, unlike previous system, thiscurve stays on the surface, and then you can graph them and move them around andthen they form the shape
* Let me show you a demo
* So again, input is very similar
* Here's a just draw a line, and the systeminflates it
* However, as you see, your input strokestays there and this serves as a handle
* So you can grab them, and move upwards
* And then, soft continuously changes
* You can see it from the top, and then youcan pull it sideways to see the shape
* In this way, you can get more control, andyou can get more smooth shapes, which was not possiblein the polygon based system
* And you can also add more contour curvesin this way
* And then you can grab this thing, tochange the shape
* And then like previously same you can alsoadd an arm
* And from the sideways, you can pull itdown to change the shape
* And here, as you see, we have two kinds ofcurves
* The blue curves is a kind of smoothconstraint, and the red curve is, as you see, a sharpconstraint
* And of course, you can change thecategories
* For example, if you change them to a blue,you know, as you see
* You will get a smooth rendition and, ifyou want you can also erase them to remove anyconstraint
* And you will get a very smooth shape
* As an example is here
* You draw a shape here, and then you draw a shape here
* And here this is to literally to motion
* And if you want, you can make them sharp, and then you're going to get this kind ofshape
* All right
* Let me show you a couple more examples
* Here you get this shape, and then you cutit here like this way
* And then you get the shops, shapes
* And then if you erase these parts, you can get shape
* So here, you know, smooth shape,discontinuity here, but so this part is going around
* And then again, you meet at a sharpcrease
* This is not easy to do compared to otherapproaches
* You can use [INAUDIBLE] it's alwayssmooth, if you use this they are continuous boundaries and this isnot easy
* And after combining these operations, youcan get these and other good shapes likethese
* You can make this kind of mask or a humanbody
* Or arms and so on
* And the point here is that, traditionalmethods require the user to design
* Is models by manipulating individualcontrol body, but here I use a control over a curves
* And then we hope that this is a moreintuitive and more efficient
* And let me describe the algorithm behindthe scene
* So basic idea behind it is a user controlsa curve
* And the curves define the boundary, andthe system automatically generates the smoothsurface based on the curves by running a continuousoptimization, trying to make a smooth surface as defined by thecurves
* So that's the basic idea
* Now let me describe the details
* So curve deformation takes handle positionas the input, and then generates curve geometry,updated curve geometry
* And the surface optimization takes curvegeometry as the input, and then generates a smoothsurface
* And let me describe the curve deformationfirst
* So curve deformation works like this way
* So you have this shape
* Input save, and then each segment hasthree dimensional coordinate frames
* Then, if you pull one point upwards, and then an assistant will define the entirecurve
* Then, as you pull upwards, all coordinateframes also rotate together
* What we do is simultaneously updates itsposition, its rings, and also quotation coordinate frame for individualsegments, curve segments
* This is a quick overview
* Please refer to paper for the details
* Minimize these functional, right, moving around quadrics positions and digitalrotations
* So we try to find very good more smooth quadric position and edgy digitalrotations and minimize this
* And what we minimizes here, is thatdifference
* So this is this is a small laplacian which means, difference observed current position fromthe surrounding position, and then the current difference is rotatedand it is compared to the current updatedlaplacian
* And this preserves the local details
* And this one tries to minimize thedifference between neighboring rotations
* So this tries to achieve smootherrotations
* And then this one is tries to minimizedifference between current position and the position of this line positions, thenearby positions
* So, each one is a smooth position
* this, try to minimize the difference between original position and updatedposition
* Similarly, this one tries to minimize previous current rotation and updatedrotation
* So by solving this system, system tries tofind a smooth deformation
* Next one is Surface Optimization
* And surface optimization takes as input acurve geometry and a mesh topology
* And this is the input
* And then system will automaticallygenerate smooth surface
* To do so system basically tries tominimize variation of curvature
* You know, curvature is how curved thesurface is
* And then by minimizing the variation of curvature, system tries to generate asmooth surface
* In a mathematical representation, it lookslike this
* So, Kn is a curvature, and then Knderivative in both [INAUDIBLE] axis and second axis,and then this represents curvature, and then curvature variations,and then we try to minimize this
* And now fortunately this is no linear program
* It's not easy to, or efficient to compute
* So we approximate this by couple stepwiselinear computations like this
* A little bit complicated, but luckily wehave two parts
* Two passes
* So one is cover up, so left flow computescurvatures
* So we first computer curvatures which is ascale of values, and then by blending or smoothing out weget target curvatures
* So as you see, originally curvature hasmany variations
* But by smoothing out, you get a moreuniform target curvature values
* So we tried to obtain these curvaturevalues
* And from these curvature values,multiplied by a surface normal, you get target laplacianvertices, vectors
* So we try to obtain this lapracianvectors
* In parallel, we also compute edge lengths
* So free for us to compute current edgelengths
* And then we compute target edge lengths,by blending or smoothing out
* And then, multiply this target edgelengths with current edge vectors, you get target edgevectors
* And by combining these target laplacianvectors and target edge vectors, we solve earliest square problemand you updated geometry
* And the way you repeat multiple times, andthen you get optimized smooth shape
* So original paper was called FiberMesh designing free-form surfaces with 3Dcurves
* And similar technique that he's trying to gradually changing the safe consideringlocal details was originally a presented at sketched based interface fordetail-preserving mesh editing
* And also our technique is kind of alsolearning surface fairing continuously
* And it was inspired by work by geometricfairing or or irregular meshes for three, forfree-from surface design
* And we recommend to take a look at theseworks.


--- SKIP ---: 07_3-4-flower-modeling.en.srt


--- SKIP ---: 07_3-4-flower-modeling.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_3-4-flower-modeling.en_SENTbySENT.txt
* And next topic is flower modeling
* This is an example of very domain specificmodeling operations
* And the work we introduce here is calledfloral diagrams and inflorescences
* The program we present here, discuss hereis flower modeling, and the flower modelingis very difficult
* It has very complicated geometry
* With you know, petals and [UNKNOWN], and also, at the same time, complicatedstructure
* So, again, each element has complicatedshape, and also we have a very complicated arrangement ofinterior elements
* So that's a program we want to address
* And our approach is like this, forcomplicated geometry we use very specialized sketchinginterfaces for all our elements
* For hunting a complicated structure we again, provide a very specializedstructure editor
* By combing a very specialized system wecan make it very much easier for the user to design variouskinds of flowers
* Let me show you a video
* So here's a program we would try toaddress
* You know, this kind of flower diagram, aflower more that it consists of many smallelements obligated together
* And then we have complete skeletonstructure like this one, I like this one
* [BLANK_AUDIO] And then what we do is use a traditionalart of presentation called floral diagrams, and inflorescences as aninterface for designing our flowers in the computer
* [BLANK_AUDIO] So floral diagram, defines arrangements ofelements for individual flower
* [BLANK_AUDIO] Inflorescences defines an arrangement or group of flowers in this model
* And you see the user interactivityoperates the diagram, and then you continuously see this updatedto your directory [BLANK_AUDIO] And the modeling process start with thedefining of a floral diagram
* So in the flower base you arrangeindividual elements, and then you can see a 3-D measure previewhere
* [BLANK_AUDIO] So as you see, this is a very specialized dedicated weatheringsystem for flower arrangements
* [BLANK_AUDIO] After our getting a diagram, now, the userdefines a geometry
* As you see, we provide a very, very simplesketching interface for defining a shape
* But here, system will carry [UNKNOWN] offa resolution
* And for each, for our element, our system provides a various indicatedsketching apparatus
* So this is why in is initiating a pulse
* [BLANK_AUDIO] And then this is texture modeling, so youdraw three lines
* And then you get this after you get the3-D model
* And from the side view the user draws aline, and you get a different shape
* So with just only four strokes, you willget a very huge form of flower element
* And you can continuously add more and morestrokes, to get more detailed shape
* And then after having drawn a diagram and 3D components, you establishcorrespondences, or associations, and then with someinformation assistance, start to generate anaggregated composition
* And then you will get, beautiful shape
* Now we assemble them together into a,structure using infrared tendencies
* You get this template, and then you changethe shape, and then you label the shape
* And now we define axis, center axis bysketching
* This is an interesting part, so you drawtwo dimensional stroke to define axis, and then system generates 3Dminimum axis that we see
* This is the last stroke, and then as the user draw, system would generate 3Ddimensional axis
* And sometimes you finish drawing you canrotate and you will get the reasonable 3D shape
* [BLANK_AUDIO] Yeah, so here's a little bit more description about 2D input to 3D stalkpart
* So without depth assignment if you projectyour input onto a flat surface it looks unnatural, a veryflat shape
* However, with our algorithm
* User draws a stroke, two-dimensionalstroke, and the system automatically assigns anatural, naturally looking depth variation, so if you look from, look from a sideway, it looksnatural
* So to do this, what we do is assume that three-dimensional curvature is alwaysconstant in 3-D space
* Is this assumption we can look into thecomputer depths
* And then her are a couple results
* I think it is very tedious andtime-consuming to generate these types of models using traditional 3Dgeneral purpose modeling systems
* But with our system, it's very, much, muchfaster
* Of course, it takes certain time, but it'smuch faster than using creation method
* And you can easily modify them
* [BLANK_AUDIO] Yup, that's it
* And then, here are a couple examples
* These are 3D shapes and these are thestructure editors
* And then here let me briefly describe theother [UNKNOWN] 2D stroke to 3D shape
* So as I said the basic assumption
* The main idea is to assume constantcurvature in 3-D space
* Which means second derivatives, expositionof second derivative of zed, z positions by y value, is theconstant
* Y is a growth direction
* See here again, this is two-dimensionalinput on X-Y plane
* Y is a growth direction, and x is sidewaysvectors and then we compute, we try to compute zvalues in this way
* So you don't have passed the projectstroke onto x y plane and resample
* So we put the sample points here, and then we suppose that 3D curvature isconstant so
* Second derivative of X along Y and secondderivative zero Y equal constant
* And we know this volume by this shape
* We also will assume this constant body by maximum of this volume, we summarizedhere
* Maximum curvature
* And here
* The curvature in X-Y plane gets smallerhere
* But instead we at, assign large valuehere, which means large curvature in threedirections, and here
* So this is given value, and this is givenvalue, and you get this value
* And after get this values secondary letterZ, just integrate twice, and then you will get the variable, sothat is the algorithm
* So to learn more, the original paper canbe found in SIGGRAPH 2005 titled FloralDiagrams and Inflorescences
* Interacting from our modeling using ourbotanical structure research
* Now, interactive modeling has a longhistory of research, and one famous book is calledThe Algorithmic Beauty of Plants, and this onediscusses some really interesting techniques usingmodel based systems
* So here is a, one, example, you draw thiskind of synthesis, and you will get this kind of very complicated structure, and this is very beautifulmathematical system
* However, it is a little bit unintuitivefor our artists to design more of them
* So this, this entry people use this kindof graphical rule editor to generate a 3Dshape like this
* And this, and this paper about the paper titled, Modeling Methods and UserInterface for Creating Plants, was currently available as a modeling systemcalled XFrog
* This is a very popular tool
* If you are interested in this modeling Isuggest you take a look at these systems


--- SKIP ---: 09_3-5-volumetric-textures.en.srt


--- SKIP ---: 09_3-5-volumetric-textures.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_3-5-volumetric-textures.en_SENTbySENT.txt
* The last topic of this week is volumetrictextures
* The work we introduce here is volumetric illustrations, designing 3D model withinternal textures
* So motivation is here
* So we can see carefully designed three dimensional illustration that showscomplicated internal structure
* And this kinds illustration is verydifficult to generate, and also, it is especiallydifficult to make it possible to interactively draw thiskind of illustration as you cut an object, so that's a goal
* The goal is to design cuttable 3D models
* You have 3D geometry, and whenever youcut, you will get beautiful cross section, that isthe goal
* And the program is very difficult to do
* Traditional, standard 3D models there isnothing inside, if you cut it is empty
* If you want internal structure, youprobably need body metric information However, body metricinformation is very difficult to generate
* You, essentially you have to paintindividual pixel box in x, y, g space one by one
* Especially if you want colors
* It's very, too complicated
* You can also use CD scanners or MRI toscan but they just give you intensive valuesand there's no beautiful colors assigned and that's aproblem we address and the base guide here is to use picturesynthesis technique
* So as soon as you cut the marrow,[UNKNOWN] there is nothing inside
* But in the modeling phase, the designerspecifies which texture elements to use to generatecross section
* Using this information or hint system in the real time synthesizes the realtexture
* So from the users point of view, it lookslike there is an existing texture inside
* That's the idea
* I'm going to show you a video
* [BLANK_AUDIO] So here's the system overview
* So you provide input image and then assoon as a user cut a 3D model
* Make sure it's empty
* But system synthesis cross section automatically using texture synthesistechnique
* So let me fast show you the user interfacefor browsing
* So here's an input solidity shape, and theuser cut the shape and the system synthesizes the crosssection and then you get this result
* And if you cut in different way, you getdifferent texture
* So from users point of view, it looks likeit has three dimensional textures
* But from the systems point of view, itjust paints the cross section
* Here's a cucumber, when you cut it, youget cross section everywhere
* So it was browsing interface and now we show the modelinginterface
* So the modeling starts with the given 3D surface model, nothing inside justsurface
* And the way we'll teach how to synthesizeinternal texture to the system, so user fast cut, example cross section, and theycut and see the inside
* And they user specifies, which texturetype you use, isotopic, orientation or layered,or oriented
* Then if the user chooses layered texture,the system asks the user to specify exampletextures
* Say drop image here and the user drag anddrop meat photograph
* And the user teaches which particles orimage to use
* This is the outside, this is the insideand you'll get this
* And then also, user specify of there is a difference in volume and inside andoutside
* And you teach which part of the sodiummodel is inside or outside
* It is these correspondences, now thesystem has enough information, and then synthesizes the picture, usingthe 3D modeling
* Now given this information, now we areable to use our cut in different locations, the systemssynthesizes it in the appropriate picture
* [BLANK_AUDIO] In this system we supported three types,three types
* So, first one is Isotropic, so there's anorientation
* So, it's the easiest one, Like [UNKNOWN]or sponge, potato and others
* You just pick a type and then log on witha single texture, or orientation
* And then since this is automaticallystarts, like this
* The second one is layered structure, such as,carrots, or cakes, and others
* And this is also a layered structure
* And here is a select the layer picture,and then get an image, another set as we've already seen, use thespace files inside or outside
* Or top and bottom and you also need to space away the same thing for the 3D eh,geometry
* Top and bottom
* And now we know the correspondence betweendifference images and the 3D geometry, and then system starts to synthesize the texture of our chocolatecake
* The same thing for carrot, you can specify inside, outside and the inside, outsidefor 3D shape
* And the system synthesizes the shape,texture
* The final one is oriented textures, like this bamboo shape
* Bamboo fibers have a specific orientation
* So in that case user needs to specify theorientation of fibers
* So user input is two dimensional textureof a horizontal cut and then you get three dimensionalvolume difference, and then user specifies theorientation
* So here, user draws lines here and thenorientation of hair is automatically generated, and the system synthesizes thetexture along with orientation
* [BLANK_AUDIO] Sorry it's a little bit difficult to seein this presentation, but I hope you see, for example, more lines here andlots of dots here, and so
* And here is an example, modeling example, so you have a three dimensional toothmodel
* First there is nothing inside, then you pick up a photograph of the insulation and then you put, specified additions and then you will get the body metric texture for a tooth
* That's it
* And here's a couple of results, likecucumber, or a donut, or bamboo, or tooth
* And, as I said, modelling phase, you use aspecified how to paste the image to the 3D model from the closed section, byspecifying outside, inside, and so on
* Another way is like this
* So for the reference image, use a spaceslice inside and outside and then you compute the control mark, kind ofdiffusion over the distance from inside
* And then also you get the same control mapfor the cross-section
* For the information or notation given tothe 3-D shape
* And then, given this to information systemgenerates a synthesize cross section using texturessynthesis algorithm
* And let me briefly describe the texturesynthesis algorithm
* Texture synthesis is a very populartechnique in computer graphics
* And it generates a larger texture frominput smaller texture
* And when our original paper was publishedin 99, and the basic idea is very, verysimple
* So, for synthesising a new texture fromeach individual pixel, you just searches for the similarcontext pixel in the left virus
* And of you find a more similar one, justget a color or the more similar pixel just tocut into the frame
* So, just by repeating this many timesstarting from a [UNKNOWN] you get very, veryrealistic texture
* And this technique is very frequently used and recently, already used in commercialproducts
* So yeah, so original paper was published in 2004 as Volumetric Illustrations andTexture Synthesis, a lot of papers, but originalpaper was Texture Synthesis in ICCV, '99
* And if you want to now the recent ones, afamous one is PatchMatch
* Published in 2009, and this is currentlyused in Photoshop, and those applications
* There are a couple more, recent 3D picturein solid texture and not solid textures .And so these may beinteresting for you
* Thank you
* Okay so this is the end of 3D Modeling
* We introduced suggestive interface,sketch-based modeling, shape control by curves, and volumetric textures and let mego back to the initial discussion
* So the challenge in 3D modeling is how to compliment missing information, mainlydepth or z bodies
* An approach is to user a design user interface, an automatic inferenceleveraging domain specific knowledge
* So, in the examples we show today, youknow, for architecture modeling we use hard-codedrules for design for architecture models
* And for [UNKNOWN] organic shapes, we usethe inflation algorithms, elimination[UNKNOWN] sets, so target is smooth
* And for all our modeling, we deduct very specialized structure and zooming inthe editors
* And for cross sections, we use texturesynthesis outwards
* yeah, thank you.


--- SKIP ---: 01_4-1-clothing-manipulations.en.srt


--- SKIP ---: 01_4-1-clothing-manipulations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_4-1-clothing-manipulations.en_SENTbySENT.txt
* [SOUND] [BLANK_AUDIO] hello
* This is Week 4 of Interactive ComputerGraphics Course
* The topic of this week is Deformation andAnimation
* So, last week we discussed the moving of3D shapes
* They are kind of rigid shapes, there is nodeformation there is not motion
* In this we discuss how to make them move,how to make them form
* One way to change the pose of articulatedcharacter, our frog
* And the other possibility is, is to deformthe objects consistent with deformed object like frogsor robes or jellyfish [UNKNOWN]
* And this as you see this is much moredifficult because there are lots more information there the timesequence for the articles positions
* And then we will discuss [INAUDIBLE]toughest to control so many information
* So these are the topics we discussed here
* The first one is Clothing Manipulations,so putting garment on the character
* And the next one is Layer Operations for controlling stacked clothes or robes, andso on
* And then, we will describe Spatial KeyFraming technique to animate character
* And then also, the Procedural Deformationtechnique for animating jellyfish and other [UNKNOWN]and so on
* And then, finally we will describe a method to handle large motion capturedata
* The first one is Clothing Manipulation
* So this is work titled as ClothingManipulation and published in 2002
* The problem we want to address here isthat clothing manipulation is difficult
* Many people are working on clothessimulation, but I thought that not so many people working on manipulationor control of the clothing
* So this is, these are a popular techniquesin the field
* The one poss, popular approach is to putrigid clothes pieces along the body and then start simulation and theclothes will snap to the body
* This is very popular with clothes
* However, from users point of view it'svery tedious to place piece of clothing around the body with 3Drotation and 3D position control
* And the other popular demonstration isthis kind of real-time simulation of clothesmaterial
* But from user interest point of view, it's like manipulating a handkerchiefusing a chopstick
* It's not very good for putting clothing onthat character
* So what we want to do here, is a way tomake it easy to put clothes on a character in avery flex way, flexible way
* You know, there are so many different waysto put clothing on a character
* And we want to develop technique to makeit easy to test many variations
* Okay let me show you, a video
* So we introduce two techniques here,wrapping and then dragging, the first one iswrapping
* [BLANK_AUDIO] So here you have a 3D character here, and then we try to put clothing on this 3Dcharacter
* And on the right hand you have a garmenteditor
* And then, you design a garment here as a2D pattern
* So you will, you design a 2D shape, andthen put this garment onto this character
* And I just said, keep options to push andpull, each individual body, allowing this 3D body, it can bevery timing consuming and difficult
* So our approach is to use paintinginterface
* So user [UNKNOWN] specify which partshould go where
* So this line, these three lines should gohere, then here, and then here
* And then with this thing, the system triesto put the clothing on the character so that thesepainted marks matches together
* So just press the wrap button
* [BLANK_AUDIO] And then you will instantly get the finalshape
* And I think much more faster and efficientthan standard dragging operations
* [BLANK_AUDIO] So here's another example
* Here we tried to make our [UNKNOWN] andthen we tried to put this garment on thischaracter
* So you draw lines here
* And then there is also a line here,corresponding lines on this character
* And then just press wrap, and you suddenlyget [UNKNOWN] on this character
* And here is a little bit more complicatedexample
* So you would paint four strokes and then also corresponding strokes on thecharacter
* So in this way you can get a specific wayof putting the garment on the character [BLANK_AUDIO] Now here's a little bit more complicatedexample
* So you can quickly design this kind oft-shirt and then a shirt and then you can put in thisgarment
* Again, if you use traditional drag-ons[INAUDIBLE] operations it can be very tedious to control this
* [BLANK_AUDIO] So this [UNKNOWN]
* So instead of moving around the garment,the system actually grows a garment on thischaracter
* So next operation, is Surface dragging
* So after putting a garment on a character you may want to relocate or adjust theposition
* And this is technique
* [BLANK_AUDIO] So here basically idea, so typicaldragging real time clothes simulation is just movesingle objects
* And then rely on physics to move aroundthe other vertices
* However, this is not convenient for makinga drastic, a large deform, large motion around thebody surface
* [BLANK_AUDIO] So this here is an example of traditionalsingle vertex dragging
* So it can make a very local shape change, but it's very hard to make a globalchange
* So what people propose is called surfacedragging
* So as you drag a single vertex, the the system dies, propogates motionallowing the [UNKNOWN]
* It allows a small motion, all bodies aregoing to move together, so you can make a big changewith a single drag
* [BLANK_AUDIO] So here's an example
* So you can easily up or down or even you can rotate the skirt around the bodysurface
* And this kind of dynamic fast motion is not possible with standard single vertexsimulation method
* So you can move this cloth along the bodysurface
* [BLANK_AUDIO] And the system also takes care of thebasic physics, so there is no penetration, and then alsosome gravity effect
* And you can get further control by puttingpushpins on the body surface
* So you can put pushpins and then youconstrain the position
* And after putting pushpin it's a fix, thelocation is fixed and than you can get furthercontrol
* Yeah again, by pushing we can changelengths, by propagation, so you can just move one partof the garment
* [BLANK_AUDIO] We can also use, some painting interfacefor changing the position after putting the garment onthe character
* So this is useful to make discontinuous[UNKNOWN] change, like this one, so you can suddenly jump part of the clothto the arm
* [BLANK_AUDIO] So here is a couple of examples of 3Dmodels created using the technique
* So here is an octopus, a mommy octopus
* So you can put long garment, clothes onthe octopus
* And again, I think this is very tedious todo using standard the dragging operation
* [BLANK_AUDIO] And this is something we wanted to dousing the interface, is can put clothing on herhead
* And you can play around with this
* [BLANK_AUDIO] Okay, so that's video
* So as I said what we propose is surfacedragging
* So traditional approach is single vertexdragging, or rigid dragging moves all the vertices into thesame direction
* But here, what we propose is propagationof moving vector allowing to body to move slightlythis way
* Okay so let me briefly describe the implementation of these techniques, sowrapping and dragging
* And then, past experience wrapping alwayswins
* So wrapping is, as I said, instead ofmoving entire integrated entire clothes to the body, we actually glue thecloth on the body surface
* That's the basic idea
* In this way, we can operate discardclothing detection and so on
* So here is a look at [UNKNOWN]
* That's the beginning system fast computerdependency graph or propagation graph
* Starting from the painted triangle to theother triangles
* So this is a directive graph
* And then, according to the directivegraph, dependence graph, we grows the cloth to the bodysurface
* So first, we transplant, 2D clothes to 3Dsurface
* And then we paste, a new triangles, one byone, on the body surface, using, according tothe dependency graph
* An interesting question here is how togrow the surface
* Please consider there are two possibleapproaches
* One is you paste, triangle one by one,pasting on, directly on the body
* And another possibility is, instead ofdirectly painting, it's a kind of more straight a, along the clothsurface
* And we actually implemented the first one,as [UNKNOWN] approach
* However, we found it problematic and wethen switched to this planar growth, let me describe it alittle more
* So if you stick to the body you can have aproblem if you have a, like a sleeve
* You know, if you start to make a sleevefrom both sides, if you stick the body here, thereare so many
* It causes many many folds, you know,around here
* So we find it problematic
* If you use a planar growth, then it worksthis way, and then afterwards physics will stitch togetherand then you will get a reasonable result
* And here's another example, if you usestick to body, then if you start growing here it goesaround the body
* And it is not very desirable
* So we decided to use planar growth for theruffle
* Okay, so now let me move on to ourdragging implementation
* So as I said, dragging is to propagate themotion along the body and then all the vertices movetogether along the body surface
* And at the beginning as, as soon as youclick down and start dragging, system fast the compute this again dependency graph or propagationgraph
* Starting from [UNKNOWN] vertices, vertexand to the rest of the vertices
* Then again, there are two, twopossibilities
* One is to propagate cloth's, along theclothР Р†Р вЂљРІвЂћСћs surface
* And then, you know, as you see the vector
* You know vector changes along, acrosssurface
* The other possibility is changes the vector direction according to the bodysurface
* And then, we again tested the poles
* And then the [UNKNOWN] naive approach was this changing vector along the body,up-close surface
* However, it turned out to be very ,very unstable because he shape changes all thetime
* However, if we switch to body based propagation, the body shape doesn'tchange
* It is very stable
* We found that this is very much better
* So in summary, in this video we discussedclothing manipulation methods
* So we introduced our our paintinginterface for wrapping and also our dragging along the wholesurface dragging
* And the following implementation, wrappingis achieved by growing or pasting triangles one by one on thebody surface
* And for the dragging we propagate somemotion along the body surface
* So to allow more the technique itself ispublished as clothing manipulation
* And if you want to know more about clothes simulation, yeah, there are somany information
* But I just want to point to a very famous, good paper called Large Steps inCloth Simulation
* It's a little bit old paper, but I thinkstill very popular and a good starting point forfurther study
* Thank you.


--- SKIP ---: 03_4-2-layer-operations.en.srt


--- SKIP ---: 03_4-2-layer-operations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_4-2-layer-operations.en_SENTbySENT.txt
* The next topic is Layer Operations
* So this work is titled, Apparent Layer Operations for the Manipulation ofDeformable Objects
* The problem we discussed discussed here is that interaction with deformable objectsis very difficult
* And by deformed object we may hear, thiskind of interrelated stacked closed and also lobs,and so on
* Now typical approach is to round,continuously, physical assimilation
* And then user moves one vortex and thenrely on physics
* This is always physically possibly
* But this is kind of a little bitinflexible
* You know, you can not penetrate pass anobject and so on
* So it's always needs to be physicallybodied
* And this can be inflexible in somesituations for modeling purposes
* And besides a possibility, it's thedirectory control all the vertices one by one
* In this way you can do what ever you want
* However, it can be very, very, tedious,right
* And you have too many, many control ofvertices
* So what we introduce here is one exampleof semantic-level operations
* By semantics like, layers and so on
* So if you look at the physical configuration, here's some want to do sumoperations
* But these some operations in some meaningfor operation for the user; like changes order or layers ofthis comment
* However, from computer to, point of view, this is just a collection of vortexcoordinates
* So many, many, numerical values
* So additionally we're asked to controlthese numerical valued directory
* But here we tried to allow the user towork on this 3D model with semantic-level
* Now specifically we want to, we introducehere is layer a operations for 3D modeling, and I think you know thethree layer operations
* So in 2D drawing systems you can alwayshave a layer ordering
* So you can say, go to front or go to backand so
* For example in PowerPoint you can say youcan say go to back and then you will get thisresult
* And then, go to front and then you willget this result
* So we want to get this kind of operationfor the comments, for the cloth to go front, or front toback and so on
* So so we specifically we introduced two newtechniques here
* One is layer swap
* So you just click here and then the systemchanges the layer ordering
* And then the other is, you drag one piece,and then you can go up, and down, depending on theuser control
* So let me show you a demonstration
* So you have a three dimensional clothplaced on the floor, like this one
* And then, you can deform it just bypulling, and pushing, and so on
* And here this is just a standard physicsbased dragging
* So it's always physically bodied
* However, for example, if you want to tryto change the layer ordering of this part and this part, itcan be, it suddenly becomes very tedious
* You have to move it away
* And then move it here, and it comes back
* But this takes a lot of steps and thenglobal configuration changes
* And so if you want to swap this blue andthis green, now it's almost impossible
* But here what we propose is just a singleclick operation to do it
* So if you want to swap this layer just, just, click here and the system willautomatically swaps
* So it's very subtle but internally thesystem do a lot of things
* And if you click here, just swap, andthere you will get this instantly
* And this operation can be very, verytedious, if you use standard rigging operation orrobotics space control
* Let me show you a couple more examples
* So here's an example, so you have green,purple and blue here
* And for example if you try to swap green and purple blue if you click here user want the system toswap green and blue
* But if you, the system do it naively, thenthere can be a penetration or intersectionbetween part one blue
* So system automatically analyze it thesame and then try to abort invalidconfigurations
* So if you click here instead of puttingblue somewhere the system decided to bring the green to thefront to abort intersection
* again, the same thing, so if you clickblue, if you want to swap blue and purple, if you just do it, if the purple is on top of green, there'll be a intersectionhere, right
* So in, in order to prevent anintersection, or penetration when the user clicks here, the system should push thepurple one all the way to the bottom
* And that's what we do here
* If you click here, the systemautomatically pushes the purple one all the way back
* And here is a folded pocket handkerchief
* If you click here you still do, you know,outward penetration and the system will automatically decide to movethe top layer all the way to the bottom
* Then you will get this shape
* And if you click here the direction of aspiral completely swaps
* And also if you have this one for exampleyou can do something like this very quickly, just by a successivebreaking, and then you will get the same
* So this way of changing the way of makinga knot can be very difficult due to ourtraditional approaches
* And this is our most complicated case, anecktie
* So we created this shape by many, manyclicks here
* And the same operation can be applicablefor a knot or ropes
* So if you click here you can swap thelayers and you can quickly change theconfiguration of a knot
* And then here the same thing you canchange the whole direction of a twist or you can change the configurationof a net, like this one
* [BLANK_AUDIO] Okay, so that's how layer's work
* And next operation I will show is layerhardware dragging
* So, in standard dragging, you know, it's a dragged object always on top of existingone
* However, if you press shift key down,during dragging it will automatically goes belowthe colliding clothing
* So by combining shift up and shift down,you go up and then go down and so on
* So this is very useful for making a knothere, so you go up without shift and shift down, and then shift up, andthen shift down, and shift up
* So in this way, you can generate a three dimensional knot just by twodimensional dragging
* Okay
* So that's a demonstration and let me briefly describe the algorithm behindthis
* So layer swap
* So, this is a before the layer swap andthen the after the layer swap
* Suppose I use a click somewhere here
* I use to try to swap yellow with blue
* And in order to do the system willactually do a lot of same inside the box
* So first, the system project, 3Dconfiguration onto the screen space
* And then analyze the configuration, andthen, generate a structure for the list graph
* List graph is, each subregion represents alayered structure and then system maintainsadjacency graph of the, regions
* And then, depending, starting from thiscurrent configuration
* Depending on the user input, system swapslayers, in this 2.5D representation
* The layer is a list graph representation
* And then after that, system takes this twodimensional input configuration, and thenautomatically synthesize it, a 3D shape
* And then offer a physical acquisition toget the final, solid shape
* So that's what we do
* The first step is the project, projection,and analysis
* So projection is from 3D, to 2D vectorrepresentation and the similar technique was presented byEisemann is 2009
* And then after getting to thetwo-dimensional vector, 2.5D representation, we construct a listgraph presentation
* And this technique was inspired by a locallayering technique proposed in 2009 here
* So in this one call, represents local layering structure and then also adjacencygraph
* Okay, so given this list graph you know, 2.5D layer structure, the system updatesthe list graph
* So this, this is before configuration andthen gets a new configuration
* So what it actually do is to change theordering of this local layers
* However, the important thing is to, toavoid invalid configurations
* So here's an example of invalidconfiguration
* So type one, invalid configuration is likethis one
* So you see the two sub-regions here andhere
* And then in the top region about thisregion here, blue is on top of purple, and here purple is ontop of blue
* So if this kind of configuration happensthen there will be an intersection of penetrationhere which means undefinable, so this is type 1 error ortype one invalid configuration, so anotherinvalid configuration is like this
* So this is not so obvious but suppose thisis folded, you know, this is dark blue and the light blue is folded andconnected, and then, and then it's connected layer shouldbe adjacent
* Otherwise, you know, there will be apenetration, so that's a problem
* So what we do is to consider all possiblepermutations of layer orders in each region and then tries to findvalid configuration
* And to do this we actually do kind of an exhaustive search of all thecombinations in this space
* And then after it gets having the updatedlist graph, what we do is reconstruct the 3D geometryfrom it
* And this is two step operation
* So first operation is to get geometric reconstruction, so there is no gravity,there's no physics, just reconstructthree-dimensional layered structure, just tied up to the computer depths from 2D layer
* And then after that, we apply physics you know, apply gravity to get the finaldeducted shape
* So, in summary, we introduced the layeroperations for cloth and ropes
* And them specifically we need to do today a swap single group and change layerordering and then change the layer dragging, you can goabove and then go down using a shift key
* Then the algorithm for what we do is projection 2.5D representation calledthe list graph
* So project the order and synthesize goback to 3D
* To learn more, the original paper was published as Apparent Layer Operations forthe Manipulation of Deformable Objects, and 2Dlayer operations was introduced as LocalLayering in 2009
* So our work is inspired by this work
* And also if you want to more about 3D to2D projection, I recommend you take a look at this Visibility algorithmfor converting 3D meshes into editable 2dvector graphics
* So this one enables to combine from 3Dgraphics to 2D vector installations
* Thank you.


--- SKIP ---: 05_4-3-spatial-key-framing.en.srt


--- SKIP ---: 05_4-3-spatial-key-framing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_4-3-spatial-key-framing.en_SENTbySENT.txt
* Next topic we discuss is, Spatial KeyFraming for character animation
* And, the work we introduce here was published Spatial Key Framing forPerformance-driven Animation
* So the motivation here is, creation of character animation is tedious anddifficult
* So here's a list of, popular techniques, so Key framing, Motion capture, Physicsand Scripting
* Keyframe is by the way the most populartechnique
* So you set key bodies of each time frame
* So, as a program we want to address here is the creation of character animation istedious and difficult
* Here are a list of current populartechniques of Key framing, Motion capture, Physics,and Scripting
* So by ways the most popular technique iskey framing
* So you get a character and for each timeyou place a pose like time zero, this pose, time one, thispose, time two, this pose
* So individual key framing
* But however, this is very difficult to do
* Especially, for now we use to get a smoothanimation using this key framing
* If you do it poorly, it's like a roboticmotion
* And the another popular technique ismotion capture
* You can directly record body motion usingthe tracking systems
* However this one requires special device,special space, and also scale, skilled actors which isdifficult
* The physics simulation is also used for but not good for designing characteranimation
* And scripting is also used for a robotic motion, like change angle this to changethis angle
* However, this is not good for expressivecharacter animation
* So what we want to do is easily sketch or create, you know dynamic form motionsor character
* So the basic idea is very simple
* We believe that the best, easiest way isto directly manipulate a character in frontof the camera
* And then press record, and thenmanipulate, and then stop and play back and do the same thing
* So direct recording of performers shouldbe the best way to do it
* One problem here is that the typical inputdevice is very limited degree of freedom
* So for example, if you use a mouse, you only have X and Y inputs, two dimensionalinputs
* However, character usually has a highdegree of freedom
* So each joint has three degrees of rotation freedom, and you have many manyjoints
* So you have to control many joints withsingle mouse, which can be very difficult for aperformance-based recording
* So our proposal is to use spatial key-framing, so user or designer firstspecifies or prepares key poses in the 3D space and then blend them, depending on the controlhandle
* So let me show you a demo
* So, here is a character in the 3D space and then we make an animation of thischaracter
* And as I said, difficult project is keyframing
* You know, this time, this pose, next time,this pose, next time, this pose and so on
* And it's very, very tedious to do this fora long animation sequence
* So, our process is to directly record amotion
* Particularly, if but, if you use one byone, it's very tedious
* In this you can only head, arm, or leg, but you cannot manipulate all of themtogether
* So our approach is to use a predefined keyframe
* So you say, this pose is associated withthis position, and then next pause isassociated with this position
* And then, so you have two key frames
* So, standard key frames associate withtimeline
* But here, key frames are associated withspatial locations
* And by clicking you can jump to the key frames and by dragging you can plan thesetoo
* So now, you can only control three jointsby a single mass
* An interesting point here, is that you canadd more, and more key poses very easily
* So, you know have three key poses
* And they blend together, and then you geta reasonably interesting motion already
* And you can add more, and more operationof key poses, like a kick and kick and so on
* All right, let me show you a couple moreexamples
* So, so here, again, individual poses are not socomplicated
* However, if you hide, and then startmoving around the ball, now you can make this teddy bear doing the juggling,just by using a two-dimensional mouse
* And then another example is this one
* So again, each individual coordinates arenot so expressive
* However, as you start moving them around,you can make him dance like this way
* So here you know, your hand motion isdirectly appears in the character motion, so thatthe resulting motion is very expressive
* So of course, you can let go of thismotion: you know, one, two, one, two, mm
* So now you can get this animation and thennow you get a motion
* So you can see it from many differentlocations
* Okay
* Now let me show you a couple moreexamples
* So here is a kicking motion
* So you have many, many couple of keyposes
* And then by dragging this lead ball youcan make the teddy bear make a high kick, as well as alow kick
* And this is a mushroom, jumping, so youhave five or six key bodies and then by directly manipulating thatball you can make this animation
* [BLANK_AUDIO] And this is a teddy bear in trouble, Ithink six key poses
* And then, you know, he says no first, andthey get idea, and be happy
* So, you can make this kind of expressiveemotion by using your hand motion integrated intothe final
* [BLANK_AUDIO] Here this eyeballs also have a separatejoint so you can control their rotation
* [BLANK_AUDIO] Okay, so let me briefly describe thealgorithm to do this
* So input to this system is handlecoordinates
* So, you have 2D mouse, and then you control the lead ball position using amouse
* And the output is the orientation of eachjoint
* So, you have many in rotation angles
* So, the question here is how to representorientation angle, rotation joint angle
* And there are a couple ways to representjoint angles like euler angles or quaternions but here we use arotation matrix, so nine elements
* Like this way, so each joint has a threeby three matrix for these represents also on ouraxis for each joint
* And then what we need to control thesenine parameters for each joint depending on theuser input
* So let's take this joint
* So, this joint has suppose we have threespecial key frames, and then each key frame has this nineparameters for each joint
* And then as user specifies the new handleposition and then we need to compute three by three matrix forthis position for this joint
* To do this we basically blend these nearbythree key poses
* So you won't have to do this
* Let's take, we compute interpretation forindividual elements or individual entry of these three bythree matrix
* So this is just a simple skeletal bodyinterpolation and here we use a technique called radialbasis function interpolation
* So this is a scattered data interpolationusing radial basis functions
* This is a kind of stand out technique and you can use as a possibleinterpolation techniques
* This is very easy to implement, very easyto use
* The idea is very simple
* So for a supposed example you have threeskeletal bodies with special location
* And then for each location, we have akernel function
* Kernel function, and then we eh, compute most appropriate waiting or coefficientsfor each kernels
* And then just by adding them together, you will get a very smooth, interpolatingfunction
* And if you want to know more, you can, I recommend you to take out paper by Turk in2002
* So after computing this up line, thisskeletal body interpolation for individual elements, you have nine elements in athree by three matrix
* But unfortunately, if you apply ourinterpolation independently to these entries in resulting matrix, is notnecessarily orthonormal, you know
* Rotation matrix needs to be, orthonormal
* And also perpendicular to each other and also the directions should be equal toone
* So after that we apply orthonomalizationoperation to these three by three matrix to get thisone
* I always skip details of this orthonormalization but there's a standardapproach
* Okay, so here's a summary
* So we introduce spatial key-framing for creating character animation quickly andeasily
* As a user defines key poses in the screen space, and then the system automaticallyblends nearby key poses
* In order to do so, we use rotation matrixand then we use radial basis function interpolationfor each element in the matrix
* So to learn more, original paper was published as Spatial Keyframing forPerformance-driven Animation, and if you want to learn more about interpolation by radial basisfunctions
* There's a paper titled Modeling withimplicit surfaces that interpolate
* Here's an example
* So use a space prior positions in 3Dspace
* And then this technique generates a very beautiful smooth surfaceinterpolating these points
* And interpolation of 3D angles is populartopic discussion in graphics community
* And the popular technique used isQuaternion interpretation
* And then I recommend you take a lot oforiginal paper published in SIGGRAPH 85
* Thank you.


--- SKIP ---: 07_4-4-procedural-deformation.en.srt


--- SKIP ---: 07_4-4-procedural-deformation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_4-4-procedural-deformation.en_SENTbySENT.txt
* Our next topic is procedural deformation
* So, that what we introduce here is called ProcDef or Local-to-global Deformation forSkeleton-free Character Animation
* So the goal here is design a flexiblecharacter animation such as jelly fish or worm, or intestine,like a heart
* So important point here is that they arefull body in motion
* You know, entire body, every detail ismoving, and also there is a dynamic
* You know, it, it's not, how to say freezedry animation
* They act as a dynamic
* If you push, then the formation changes,and so on
* So there are traditional methods
* These are the traditional methods
* One is skeleton-based
* This is most popular skeleton-basedcontrol, like a joint angle control, just we showed in the lastvideo
* This is, technique is useful for characteranimation like a human or animals
* But you know, if there is no obvious skeleton structure, like a jellyfish, thistechnique doesn't work
* And [INAUDIBLE] possible approach iskeyframe-based
* So, for each timeframe, you specify the shape individually and the system just[INAUDIBLE] them
* However, in order to do this, you have tospecify many, many key poses manually by pushing, allowing,many vertices, which is very tedious
* But more importantly, this kind of keyframe-based cannot calc, handledynamics, you know
* The motion is kind of fixed animation and it cannot respond to the forces from theenvironment
* So our approach is the procedure approach
* So the user specifies how local regions ofa h, entire body stretch or shrink
* And then by assembling them togethersystem generates a global motion
* And the user also designs the patterns ofthe local deformations
* Like, this is time sequence, you know, stretch, shrink, stretch, shrink,very quickly
* Or slowly, or fast stretch and slowlyshrink, something like that
* So let me show you a video
* [BLANK_AUDIO] Hm, yes
* [BLANK_AUDIO] So here is our result
* So this kind of animation is our goal, the full body animation of a flexible bodycharacters
* So the first task is design orientationfield
* So given as already said, user first specifies an orientation field
* [BLANK_AUDIO] So the the user specifies a layerstructure here actually, so the red layers are intact inside and theblue is outside
* So in this way, user specified the layerstructure
* And you will see it like this
* So after user paints red inside, blueoutside, system interpolates them to compute acontinuous layers
* And after specifyinf layers, userspecifies orientation of extra field on the layer surface
* So in here you can specify, user specifiesrotational flow field
* So this is a flow field
* So now, we have a flow field along this layer surface, and then layer surfacedirectional vectors, gradient vector
* And then you can get the cross-border appto get a free frame field
* So, in this way, you get the globalrepresentation field, inside of an object
* Next we define how each individual elementdeforms depending on the time
* [BLANK_AUDIO] So, in this example we have three fields, this primary direction and seconddirection, and third direction
* And for each direction, we specify thepattern, motion pattern
* So the top one specifies a change in thelengths direction and then you [INAUDIBLE] longerand shorter, longer and shorter
* [BLANK_AUDIO] So, yeah, in this way the user specifies achange in their open shape and then global shape is obtained as aresult of the smaller motions
* [BLANK_AUDIO] You can easily represent this kind ofsquashing operations as well
* So, the previous example, all elementsmove simultaneously in the same way
* But in order to make it more interesting eh, motion, you can specify it's amplitudefield
* So here red and blue has a
* We'll put its direction or put itamplitude
* So in this way, if the blue stretches, redshrinks, and red stretches, blue shrinks
* So in this way, you can get this kind ofbending motion
* And the previous one is a fixed body forthe entire body
* But the next one is propagation
* So in this way you can introduce delay
* So the formation starts from here and thenslowly [UNKNOWN] slightly data, the formation propagateshere and later and later
* So there's a delay in the propagation andthen you will get this kind of, of motion
* Propagation of motion
* So by combining this kind of phase shiftand amplitude, and orientation field you can get leechinfor, leech animations
* So here is a couple results
* So this is a worm walking around
* And the important thing here is that thisis dynamically computing
* Dynamically computed considered inphysics, so as I use [INAUDIBLE] with it, the system continues animation with the formation, but also responding to theenvironment
* This is not animational pre-programmerfixed animation
* This is different way of making motion
* [BLANK_AUDIO] So, there's another [UNKNOWN] as you see we have a collision of [UNKNOWN]continuously running
* So they're in division and moving around,but also collide with each other and then animationchanges, depending on the collision
* And this demonstration is to demonstratehow fast the algorithm is
* [BLANK_AUDIO] And here's another example of a responseto user input
* So as the user touches, and then deformation propagates starting from theuser instruction
* So you can get this kind of interestingmotion
* Yeah, this is a propagation
* This an example of heart animation
* The user manipulates it
* But this is orientation field
* [BLANK_AUDIO] And then you can get the heart works as apump
* [BLANK_AUDIO] So that's it
* So as I said, deformation design consistsof two phases
* One is the design of the orientationfields
* You have space for a layer structure and aspace for an orientation field
* And the after space finds orientation, the user specifies for each orie, eachdirection
* User specifies a stretch and shrinkpattern, time sequence pattern
* So now we will, I will discuss algorithmsseen as global motion from a speci,user-specified local motions
* And in the preprocess is the algorismconsists of the preprocessing part and the animationseen as process
* In the preprocessing, the user inputs,input is a tetrahedral volumetric mesh
* And having the tetrahedral mesh forindividual vertix, individual vertix and we compute a localregion, N
* Like this one for individual vertix byconnecting a one beam
* One beam is a connection of vertices nextand neighboring to each individual vertex
* And after having this local regions in theanimation process, we define local region N depend, depending on the orientationfield and also the timing chart, you know the orientation field defines theorientation of the stretch squash and then times sequence chart defines, timessequence pattern defines whether to stretch orshrink
* So in this way, you first deform the individual regions, one by one, stretch orshrink
* And after that, the system assembled themtogether to get a robot shape
* So that's the basic form
* Let me describe in a little bit moredetail
* So this is original rest shape
* And then this is the current form of theshape in physical assimilation
* And then the task is to define the motionof the next time frame, starting from thiscurrent time frame shape
* So let me describe how to do it
* So the original shape, you first computethe local regions in the free computation
* And for each local region, we compute the next time step local regional targetshape
* Some part should be shrinked, some partswill be squa, stretched, and so
* So this is deformed local shape
* And after that, what the system do isshape matching
* This is the most important part
* Shape matching
* For each local region, we try to find themost, best matching position
* You know, if you get these three, it tries to match these three by rotating like thisway
* So, shape matching applied to find the best matching position now changed,rotation and translation
* And after matching, you know the currentposition and desired position
* So a system applies force from the currentposition to the much desired position
* Defined by deformed local shape
* And then applied force
* After that this is just the standardphysical assimilation
* Applied force will [UNKNOWN] applied forcemoves towards the position
* So here's a summary
* So I just introduced animation ofdeformable characters like jellyfish, a worm, and soon
* And [UNKNOWN] is a local to globalapproach, so user specifies orientation field andthen the deformation pattern, and then each local regionchanges accordingly, and then global motion appears as a result ofapplication
* And inside we use a shape matchingdynamics, because it's very fast and stable, fastand stable
* So to learn more, the original paper waspublished as processional deformation ProDef,Local-to-global Deformation for Skeleton-free CharacterAnimation
* And design of orientation is actuallydiscussing a separate paper called Lapped Solid Textures: Filling aModel with Anisotropic Textures
* So, they used an orientation field to put,paste textures inside of an object
* And that, dynamic simulation we use iscalled shape matching
* And this is very popular technique ingraphic community, because it's, it's not necessarily physicallyaccurate, but it's very, very stable
* Depending [UNKNOWN] put this very eh,contradictory, and so on
* And I recommend to take a look at thesepapers, because they can be very useful
* Thank you.


--- SKIP ---: 09_4-5-motion-database.en.srt


--- SKIP ---: 09_4-5-motion-database.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_4-5-motion-database.en_SENTbySENT.txt
* Okay
* So next task, next topic is motiondatabase
* So the work we introduce here is aretrieval on visualization of human motion data viastick figures
* The motivation here is there is a large capture database, motion capturedatabase available
* So you have loads of human motioncaptured, lot's of them
* So by combining them you can
* Create interesting animation very easily
* However, the problem is that it's very,very difficult to find desired motion
* Two problems, it's very difficult to seewhat's in the database already, so browsing canbe difficult
* Another problem is that it's verydifficult to search
* You may want to search for specific motion, but specifying desired emotion isnot easy
* So thatР Р†Р вЂљРІвЂћСћs a problem
* Our approach is to use comic visualizationof stick figure representation
* Stick figures for comic visualization andsearch, enabling us to use the image or motion capture data in this kindof comic strip like representation
* So in this way you can get emotion just bywatching a static representation and then you getthe idea of the motion
* And then another is a sketch based search
* So you quickly sketch a desired emotion and then the system automatically deliversit
* And what's interesting here is that notonly user draws a pose
* But user can also specify the motion,trajectory, or give a joint to find the target motion,efficiently
* So, let me show you a video
* So here is a representation, taken this 3Dmotion as input
* The system creates this motion asrepresentation
* By looking at this comic you canunderstand the concept of motion
* And this is stick figure sketch basedsearch
* On the left you draw a query and the system continuously shows thesearch result given this new input
* So fast we show the generation of stickfigure comic strip from motion
* So this is input, animation
* And then we analyze the speed, and then weget the key poses, this way
* And then we select the most effective viewing angle, and then render theresults
* And that is all
* You get a very inventive presentation
* Here is a couple of examples
* Here it is in relation to the pose itself, the system also shows the most dynamic,most projectory
* To provide more of the information
* [BLANK_AUDIO] So this is an example of databasebrowsing
* So usually in order to browse this kind ofdata base, you have to watch and then you draw the motionone by one
* But here you can quickly see what's goingon by looking at the go about view
* So our next part of the search
* So, on the left side you draw, sketch thedesired shape of the stick figure
* So head, and leg, and body, and as you see the system continuously providesfeedback of a matching result
* [BLANK_AUDIO] Now interesting here is that in additionto the pose itself you then can control this kind of projectspeed, speed line
* So this specifies our movement direction
* So here in this way you can move the, identify the shape that waves the handthis way
* So this can filter out motion from top todown
* And here is the opposite motion
* So we have found that this kind of speed runs is very useful for this[unintelligible] specific motion
* [BLANK_AUDIO] User can retrieve longer sequence bysketching multiple sequences like fast kick, nextpunch
* And then do something next, then you gotthe system searches for a motion clip thatsatisfies this request
* Okay, so let me briefly describe thealgorithm
* So first is visualization, and next issearch
* So visualizations, the one question toanswer is what, which pose to use
* You know, you have long sequence, so manyposes, and they have to pick couple of importantkey poses
* So here in this system, we've used a scenewhere the character changes it's motion, movementdirection or when the motion is stopped
* But here, you uses, here the directionsuddenly changes, so we pick it as the [UNKNOWN]pose
* And after picking the [UNKNOWN] poses nextquestion is which viewing angle to use
* There are many ways to lend specificallythe shape
* In 2D, so you don't have to identify amost effective view, we use a perpendicular, it's a new direction which is perpendicular to the movementdirection
* So here an example, when the, thischaracter is making a kicking motion, we believethat this motion, side view, is better than frontview because you can see the motion of the leg
* So we compute the trajectory of the joint,most moving joint, and then we get a direction mostperpendicular to the prominent motion
* And search
* So for search, one key observation we gotis, joint, specific XY coordinator, jointlocations are not very accurate
* Because in user's former sketch, you know,joint [UNKNOWN] changes so much, and is sounstable
* So we cannot rely on joint location, sobasic positions
* However, we [UNKNOWN] orientation of jointangle, is relatively stable
* [UNKNOWN] in former user sketch
* So we, we decided to use a 2D direction,orientation of each joint, or each bone, as a key for thesearch
* Another important thing is that there aremultiple matching possibilities, so we consider allpossibilities in the search
* For example, you now, if you a sketch,this kind of character
* The user draws only one arm and one leg
* So there are so many possibilities
* This can represent left leg or right leg
* And this can represent left arm or rightarm
* So we just consider all the possibilitiesand then we turn over and watch the result of thesepriorities
* Okay
* So here is a summary
* So we presented a efficient access tolarge motion capsule database
* So we presented comic base visualization,and sketch base search
* And we discussed iden, identificationkeyboard's is and during directions
* And those are we, the measurements that weuse bone direction for the search
* So to learn more, original paper is calledRetrieval and Visualization of Human Motion Data by,via stick figures
* And the comic-strip presentation, we getidea from a Comic Chat system, which takes a chatcommunication sequence
* And the [INAUDIBLE] generates comic stripsrepresenting the chat conversation
* And also there's a paper on 3D shape retrieval, using sketching as input, andthis is called search engine for 3D models andthis can be interesting little paper to lookat
* And finally, posing
* Character posing by stick figure wasalready explored in a paper called sketching interface forarticulated figure animation
* So they take 2D stick figure illustrationand then generate smooth 3D animation by doingmultiple, stick figures
* But they did not use motion capture
* Okay, so this is a summary fo this week
* So in this week we discussed the formationand animation
* So instead of taking care of a rigid 3Dshape
* We we discussed how to control articulatedcharacter and also the form of our shapes
* And we discussed clothing manipulation,how to put clothing on that character
* And the layer operations, how to store uplayers in stacked clothing or ropes
* And we discussed special key frames to make smooth animation of our articulatedcharacters
* And procedure deformation means togenerate animation of jelly fishes and wild
* And then find the way we discussed how to efficiently access motioncalculator database
* So, thank you.


--- SKIP ---: 01_5-1-plush-toys.en.srt


--- SKIP ---: 01_5-1-plush-toys.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-1-plush-toys.en_SENTbySENT.txt
* hello, this is week 5 ofinteractive computer graphics
* A topic we discuss here is fabrication
* So, so far, we have been working on,introduced, discussed computer graphics
* So display imagery on the screen
* Everything was on the computerscreen inside of a computer
* So this week, we discussed trying togoing out of the computer screen and then try to work on the physical object we cantouch and manipulate in the real world
* And the background motivation is here,so you know there are so many possible publication machinesgetting available, getting cheaper
* So if you have a 3D model insidea computer, you can easily directly print
* 3D models are the physical objects
* For example, if you have a 3D printer,you can get a 3D model
* Similarly, milling machinesautomatically mills, material and then you get the 3D model
* And so you have, 3D dimensional patterns
* You can easily send it to the lasercutter, our cutting machine and you will get nice three,two dimensional shapes out of the box
* So, here's the list oftopics we discussed here
* We discussed design with plush toys and design with beadworks and chairs andalso discussed soft folding or crossing materials, andalso interactive packing, packing method
* So first one is a plush toy design
* So this one is called Plushie
* So the program is address is that itis very difficult for non experts, for us to design 2D pattern whoare stuck [INAUDIBLE] appropriately
* You know
* You want to get a three-dimensionalstuffed animal, you need to designtwo-dimensional clothes patterns
* For experts, it may be easy tounderstand the relationship, but for novice users or no-experience people, it's very difficult to go back on coursebetween 2D to 3D and then 3D to 2D
* So, for the sketch-based 3D modeling andautomatic close pattern generation
* So this is extension ofteddy system we introduced
* So you just sketch desired shape, and the system generates a three dimensional,geometry
* But at the same time, system also generatesa corresponding 2D cloth pattern
* So if the user print them, cut them,stitch together, and it's ready
* And then you'll get the 3D,physical 3D shape
* So that's the idea
* Let me show you a video
* So here's the overview
* The user input is three-dimensionalsketching input on computer screen
* And then, giving the user input systemautomatically generate a 3D shape and then corresponding 2D equals patterns
* And then after having closing patterns,the user sew together and then you get the physical stuffed animal
* There are operational
* The user interface is very similarto the original Teddy system
* User just get his outline,and the system But at the same time you geta two-dimensional cross pattern, and what's happening here inside is that welearn a simple physical simulation inside
* So the system predicts what happensif you stitch them together and it
* And the system showsa predicted 3D geometry here
* And after having some geometry,you can interact and edit it
* Like like any system, you can cut objectand the system automatically gets 3D shape and as well hasa two-dimensional close pattern
* So user continuously edits the shape, and the system continuously presentsa two-dimensional shape
* This is a operation
* So here we generate twopossible operations
* So one is like this one
* So last base are these holes and also, we also support [INAUDIBLE] thisis useful for making an ear
* We also implemented a cover of editingoperations such as pulling the shape
* So here the system concurrently edits, modifies the 3D shape andalso two-dimensional patterns
* Now this is in, in, interesting soyou can actively add or erase a seams on top of a colored pattern
* So this is interesting I think
* So, now you have, we have three pieces anda single 3D object
* But if,here the user tries to erase the seam, which means that these twoparties will be merged together
* So you will end up having two parties
* Our system outlines thiscomputation in real time
* So as user erases a patch boundary, thesystem merges the two patches together, and then you will have now a two,patches, and the system also applies the physicalsimulation to the result
* So user can also operatedirectly on the 2D pattern, and then you will get a modified 3D shape
* So you can easily directlyworking on 3D shape, or you can work,directly working on 2D pattern
* So this two way agentcan be very flexible
* And this is an exampleof modeling sequence
* So use a fast generator base shape, and then you operate cut operationto get more control
* So basically by repeatingsimple sketching, editing operations, you can generatereasonably complicated shape
* Here we, we did not show in this video,but in the actual printout, system also gives, hints or information, which,which edge to be connected with which end
* So, the construction is also guided bythe computer generated annotations
* So after having this 3D model,the user print this pattern into paper or cloth and then you will manuallycreate 3D stuff animal
* So this is 3D model, and then this isa generated real physical stuffed animal
* So you take four orfive hours to get this
* Yeah, you can also create a bigone by using, you know, inflation
* So this is a big balloon,like two meter size, a big balloon
* So traditionally this kind of balloon isdesigned by professional designers, and it requires many testing andtrials and the prototyping
* But here, the computer can take careof the prototyping or simulation
* So even any inexperienced people candesign it, so, his or her own balloons
* So we learned our simple study
* So, we asked kids to designtheir own stuffed animal
* So traditionally,these people can buy existing pattern and they create, the stuffed animal
* It was almost impossible to design neworiginal character, stuffed animal
* But here, you know, even students,kids can design their own stuffed animal
* And after finishing the design, you knowprint then cut and then stitch together, and then you will get a final 3D model,oh no, no, final press toy
* So, you can design theirown original model
* Yep
* So, let me briefly,describe the algorithm
* For the inflation algorithm, forthe inflation simulation, we use a very, very simple, basic mass-spring method
* So, close 3D model mesh verticesmove outward over the time by air pressure or cotton pressure
* So it tries to inflate
* But at the same time the systemtries to pull them back, depending on the edge length
* If edge length is too longthen it will pull back
* And then we repeat these two processes,and then at the end you willget a stable result
* We must say that this simulation is notaccurate simulation of real physics
* There will be more other bonds physicalsimulation methods, but you can get more accurate result by using more accuratemethods but it is also interesting to see that you can get basic resultwith basic simple simulation method
* And another interesting issue is thatadjustment to the sha, to the patterns
* So, so, algorithm first takes user inputs,this red one and then direct to the,use it as a 2D pattern
* However, if you start with 2D pattern andinflate it, you know,inflated you inflate in Z direction but if you pull in D direction then X Yframe become's get's smaller right
* So in order to prevent it, the system tries to adjust the shapeto compensate this difference
* So after, after the initial configuration, system tries to graduallyinflate the 2D pattern so that the resulting 3D inflation resultmatches exactly to the 2D input sketch
* So that's, you know,inflation algorithm you saw in the video
* So this shape adjustmentis very important
* You know, if user draw let,box, as a input, and if you dive to use thisbox as a 2D cross pattern, then if you generate a 3D shape or2D shape, you will get shape
* So resulting shape is notexactly match this rectangle
* But if we apply the shapeadjustment maths algorithm, then system automaticallyinflates the input to the shape
* Then physical result will,publication result matches, more closer to the rectangle
* So, yeah, this is interesting
* So if you want to have a rectangular,pillow, you should start with this kindof pattern, not start from here
* So, to learn more,original paper was published as Plushie, an Interactive Design System forPlush Toys
* And this work, it was strongly inspiredby previous work on paper craft model
* So this work making the papercraft toys from meshes using strip based approximate for unfolding
* So this one starts from giving 3D model, and then automatically generatesa 2D paper craft pattern
* So you can generate interesting,3D shapes just by using a paper craft
* We use a surface flattening methodto generate moving from 3D to 2D
* And surface flattening is also a verypopular topic in computer graphics
* It's been used to compute a texture mapco-ordinates, and if you learn more, one starting point would be thismesh parameterization method and the applications
* So that's [INAUDIBLE] this week andthis video.


--- SKIP ---: 03_5-2-beadworks.en.srt


--- SKIP ---: 03_5-2-beadworks.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_5-2-beadworks.en_SENTbySENT.txt
* Okay, next topic is beadwork design
* So the work we introduce here is a beady
* Interactive beadwork design andconstruction
* The program here is beadwork design
* so, bead work is add orconnecting beads together by wires
* So, this is an example
* So you have a 3D structure by connectingsmall pieces connected by a single wire
* And construction is given, supplies givenlike this kind of two dimensional figure
* So people are lookingat this instruction and then put piece togetherone by one using a wire
* And to design or construct design and construction of this kind of 3D beadwork is extremely difficult and hard
* Suppose you have this kind of shape andthen tries to, want to make this head bigger,or this arm longer
* In order to do it you cannot inserta bead at art arbitrary location
* You know?This is very hard, complicated, hard,heavily constrained program
* So this is a program we want to address
* So how to design this shape and how toguide the user to construct the shape
* And our approach is two ways
* So one is an interactive and design,an interactive design and construction
* So, a user designs this in, interestingbead work design shapes by gestural, same photo-gestural interaction, andthat system automatically constructs appropriate beadwork structure andalso system provides interactive guide to generate a physically construct,physical beadwork
* On the inside, we, the system appliesa wire path planning algorithm to compute most efficient and also easyto create the wire path structure
* So, let me show you a demo
* Okay, here's our demonstration system, andthe modeling starts with a base shape
* So you, we prepared a couple base shapes,let's use this one
* And then, after having this shape,you already have a simple shape
* So here, the left one, sothis one is a structure design mesh, so it called design mesh
* So you work on this structurelevel to design a mesh
* So this represents,basic core structure of a final bead work
* On the right hand sideis a simulation result
* Result, or actual bead work model
* So individual, shape is represent here
* And the system shows what wegenerated from this design, to this, the other result
* And we provide gesture operation
* I click here, andthen you add another primitive
* And then you instantly get more structure
* And the system is internally learningcontinuously simple physical simulation so that, that the resultingshape is always valid
* And then we implemented a couple simplegestures like this is extrusion, and then you'll get extruded shape
* An Extrusion, and the extruded shape
* And then you can crop the vertices,and then crop vertices
* And then you will get this shape
* And then you can also split edge andthe connect edge
* So essentially, the user is editingthe topology of the mesh, and then physical simulation automaticallycompute the geometry of the shape
* Because what user can specify is just wirestructure, connection between this and the final shape is automaticallydefined by physics, by putting these piece together
* And then you can alsoput this kind of shape
* So in this way, you can generatereasonably interesting shape just by editing the topology with simple,very simple gesture operations
* And the system computes the 3D shape
* And then you'll get the wire structure
* And then after that you can paint them
* For example you put eyes here, and so
* And the after having this character,the system computes the, you should press this Plan button
* System automaticallycomputes wire plus and then the system startsto giving instructions
* So this, now this is an instruction
* So, here you can see the total steps andthen your current position
* And then system also provides feedbackabout the lengths of the wires
* And then this is the instruction
* This says that, please puta single bead in a long wire here
* And then press next andthe system shows how to place next bead
* Then next and next
* So of course, construction isto be done manually by you
* So you put these one by one
* And after each step, you press next andthe system shows a visualize that is out
* So yeah memorizing 3D graphicsit's much more easy to associate current physical bead in yourhand with, graphics on the screen
* So the, watching this instruction,you put bead one by one, and then you will eventuallyget the final result
* And let me show you a video
* So, again, this is overview of the system
* So, the system allows the user to generatemore than by simple gesture operations
* And then the system providesconstruction guide
* And then you will get the final beadwork model, and the physical bead work
* So, yeah, geometric modeling isa process I just demonstrated now
* So let me skip these processes
* So after that system it shows a step bystep construction guide like this one
* So this is a situationof a real construction
* So use a piece one by one into the wireaccording to the instruction shown on the screen
* Now let me skip, so I'll go here now
* And let me show you a couple of results
* So yeah, we created a couple bead works,original designs
* And traditionally, I think designcompleted in your bead work is so difficult so when you go, we actually visit couplestores selling these bead works
* But many, many stores sellsexactly the same designs
* And but here, you know,you can design your own things
* So, this can be a very interestinggift for your friends
* So, yeah, here's an example, like penguinsor lizards or mouse or a teddy bear, so
* So, let me briefly describethe core algorithm
* So, here's a view
* So this is your design mesh
* So you design this a mesh, using gestures
* And then, after this design mesh,we convert this to a big work model
* The first step is like this
* So each edge is actually a single bead
* So the reason why we consideredusing a vertices outside the edge, but actually, you know, a bead,it has a wire passing through
* So it actually correspond to it on a edge
* So edge becomes a bead
* And then bead is connected by wire,to the neighboring beads, like this way
* So, first step is combine single input, combine design polyhedron to a morecomplicated structure model
* And then, next task is to put a wire seat
* And then this wire is given as a EulerianCircuit on this structure graph you know
* Eulerian Circuit is visitindividual how to say
* In this case,basic individual edge, one by one
* So, yeah, here's a briefoverview computing wire paths
* But, however, one problem isthat arbitrary Euler cycle, or Euler socket is not stable
* Stable is, this, this is difficult to explain but,suppose you have this structure
* Yeah?You have five faces and then you have this red path goes throughand then blue path goes through
* And by connecting these inthe final configuration, you will get final stable shape
* But in the, in the middle,while you are creating, you have, also, an intermediate shape
* But in this intermediate shape,all beads are moving around
* It's very difficult to manually construct
* So in order to be, make it easier to manually construct,the process should be like this
* The individual, the wire should closeone by one, based on individual faces
* So, in, what they were in the intermediatestatus, faces are closed one by one
* So you won't have to do this
* The system actually firstcomputes a face strip, on the design mesh and then computea wire, place wires along this face strip
* And this face strip computationis given as a Hamiltonian path on the graph consisting of faces
* So, yeah,this is a result of stripification, or computed Hamiltonian path
* So, this path visits faces one by one,and then we then put wires, so that wires completes thesefaces in this order
* So, yeah, that's it and the original paperwas called BD and published in 2012
* And the step by step in,instruction used in our work, was inspired by a previous method designedfor instructions, step by step for the furniture,core selection like this one
* And also our method alsocontains a conversion of 3D, existing 3D mesh model toa simple bead work mesh
* And this work is in, in this partis related to mesh simplification
* And then good one example paper is thisone: Variational shape of approximation
* So getting very detailed 3D mesh and these simplification methods bedone the very simplified mesh
* And this may be interestingthing to learn
* Thank you.


--- SKIP ---: 05_5-3-chairs.en.srt


--- SKIP ---: 05_5-3-chairs.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_5-3-chairs.en_SENTbySENT.txt
* Our next topic is Chair Design
* And the work we introducehere is called SketchChair
* So the problem to address here is thatdesign and construction of original chair
* Suppose you want to design your own chair, instead of buyingsomething from the store
* And there're somany issues to consider, you know
* You know that to work as a functionalchair you need to be physically valid
* It should be stable andit should not break if you sit down
* And also it should be easyto manually construct
* So we present our designsystem specialized for chairs
* So the design can be doneby easy sketching and the system automatically checksits balance, or stability
* And also system automaticallygenerates a construction plan
* So let me show you a demo
* So, yeah, here's the system
* And then you design your own chair
* For example, you have a chairlike this with a long back, and we have a leg like this
* So, I just draw three strokes, and now you already have a 3D chairmoving like this one, and then by pushing a print button thatyou will get two dimensional pattern
* So after that, you can just print thisinto, send this data to a laser cutter, and then the cutter automaticallycuts physical wood material and then you can get a physical chair
* So after having this designed,you can also learn its physical validity
* So, we also have some additional features
* So if you press play button here, systemtries to push this guy on this chair
* So here, it's fine
* You know, you can put down ona character on this chair
* However, if you,you create unstable chair
* So let me show youintentionally unstable chair
* For example, if you have a chairlike this and then if you put leg in appropriate positions,if you press Play, and then you know, this is not very good, and then you,you see that this is problematic
* So this is very simplistic,this is just a starting point but you see that physical validity checkingis possible, and then can be useful
* And let me show you a video
* So yeah
* I already showed a simple video,a demonstration already, but user draws a sketch, and then draw a leg,and then you will get the 3D shape
* And then you can also additionallyedit the shape profile by dragging to adjust the shape
* And we can also adjust the leg
* So if you spend more time,you're going to get more control
* You can also, you know, edit individuallayer to get more three dimensional shape
* So then you can progressively move onto a more detailed design if you want
* Yeah as we see we also providethe polygon tool and also tool and also you can changethe spacing between the layers
* So, yeah, as I said the simulation, soyou can take the stability of the chair, And also you gain stability of the chair,rocking chair
* Yeah, as we see, you can change the design while runninga physical summation if you want
* Now we also implemented a coupleof features to assist molding
* So this one is using of thiskind of accessory object
* So you can see this kind of objecthas a difference to design, here
* So use as designing a piano chair,so you can see the size
* And it's not shown here, but it's, you can also change the proportionof the human figure if you want
* So this feature allows a userto test many variations
* So after designing this one,it's a previous one was hibernated
* So you can temporarily pan off on the,you can test different one, and then go back andforth between different designs
* Okay, after our finish design,then you can get this profile and then you can send this to a printer
* So fast easiest way is to usea cutting program with a paper cutter
* So you can send this to a paper cutter,and then you can cut the paper
* And then you can get the paper chairs
* And this is cheapest way, soyou can generate many designs
* You can do many designs studiesusing this paper chair first
* Yeah.After having a paper chair, you can actually generate a bigone by using a laser cutter
* Laser cutter is very handy too
* So it's exactly like a printing machine
* You just send two dimensional data
* But then you will get this kind ofwood material cut by according to the diagram and you get this
* And by putting cushionsaround the surface, and then you'll get a more realistic chair
* So here is some results
* So these are the variationof paper chairs
* A rocking chair we just saw
* And then full sized chairs, like these
* And this is a piano chairs
* Yep, so, that's it
* Here's a couple of examples,and so this is the big chair
* Yeah so we, this is a big chair,I just saw, and then soI have a small chair like this one
* This is
* This can be a very goodsitting form placer
* Okay so we use physical simulation here
* We use an open source physicsengine rigid body simulation
* So we, we currently use bullet engine
* But there are many other possibilities
* So these physics engine is usuallyused for games, you know, 3D games and there are objects moving around,bumping each other, but these are now very popular, easy to use
* So you can pick any simulation engine intoyour code and you can play along with it
* And I think this work is a very goodexample of a new way of design seating
* We call it Meta-design
* So traditionally,designers design final product directly
* Go through designers, design chair, sodesigner just physical shape of a chair
* But here, in the future,I think designers will not only just use their physical shape, but also designersneeds to design, design processes
* So here in this project, designer orus, we actually design a process
* And we de, define a process, and theninside with this process and the user will sketch and then system automaticallygenerates us, these number of 3D chair
* Depending, taking user input, but alsoaccording to the designer's intention
* And I think this kind of metadesign process can be more and more important in the future
* So, to learn more,original paper was published as SketchChair: An All-in-one chairDesign System for End-users
* And rigid-body simulation,if you now want to know the technique on implementation details,if you want to implement by yourself, recommended reading is Rigid-BodySimulations, SIGGRAPH Course 1992
* But if you want to just use it,there are many you know, packages
* And as for the furniture design,I recommend you, I recommend you to take a look at YouTubevideo from Front Sketch Furniture
* So this is interesting artwork
* So user can try to sketchfurniture in this 3D space, and then you will get physicalobject using a 3D printer
* So, thank you.


--- SKIP ---: 07_5-4-soft-folding.en.srt


--- SKIP ---: 07_5-4-soft-folding.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_5-4-soft-folding.en_SENTbySENT.txt
* Our next topic is soft folding
* This is a work we published in 2013
* So as a program, we want to address isthe design of softly folded shapes
* So origami and others, paper foldingis always sharp, rigid folds
* But, many of the things like, thingsdesigned we've crafted from leather
* They have soft folds
* So our motivation here is to assist designof this kind of softly folded object
* And here's our approach
* So traditionally only the sharp foldwas used in the design of origami and folded shape, but here we allow the userto paint soft folds like this one
* You know, these thin,narrow strokes represent a sharp fold, and then also this big,wide stroke represents soft folds
* So this is the 2D user input
* And then given this 2D input,system automatically folds them, and then you will get the 3D shape
* So that's a basic workflow
* So user paints flow map
* Fold the map andthen use a system that has 3D folded view
* In addition to it, not just studyfrom 2D fold them up to 3D model, our system allows very fastfeedback as you change control, and thus change the properties of the fold
* So, the user interacts with,controls the magnitude
* Or it gives you a fold
* And the user can also changethe sharpness of individual folds, so you can smoothly go back and forth between sharp fold, smooth fold,sharp angle, no angle and so on
* So, let me show you
* So, yeah, here's the basic operation
* So
* So user specifies a sharp fold here,and then you change the angle
* Then you get this result
* So you see that as the user changethe fold angle system interactively, very quickly shows the folded result
* So this is far for now
* User is changing the softness of the fold
* So, as you, the user is movingfrom sharp fold to soft fold
* And then as again, the system continuouslyshows the simulation of folded result
* So this is a basic operations
* So by combining this,we can design multiple shapes
* So if you design curved line and thentries to then you will get this result
* And you can also controlthe softness of this curved fold
* Now a couple of examples
* So use our interactively drawing folds andthe system quickly provides feeder box so you can explore many differentdesigns using soft folds
* And this spear is most important
* You know, if you are [INAUDIBLE] physicalsimulation, you can [INAUDIBLE] dissolve, but standard physical simulationis too slow to do this
* Yeah, so use a space varietyas a very soft fold and then change the folding angle,and then you will get this shape
* So let me skip this
* So here is an, another example
* So use the sign the wide fold here,and the other fold, other fold, other fold
* And they start bending
* As you see, some contradictory force can be nicelyhandled as a result of computation
* So important point is thateverything is interactive, so you can incrementally add more folds,test many fold angles
* Looking at the 3D view itchanges configuration and so on
* So here's another example
* So user specifies sharp folds first
* And then specify a soft fold here
* And here you just specifythe connection between two corners and then you will get these connectedcorners in the 3D view
* Here's another example
* I think this sequence isshowing the creation of a mask
* Yep
* Okay, that's it
* So, yeah he has a couple more results,you know, this is sharp folds, and this is softfolds, and this is physical construction
* And here's our examples
* And here's a laser bag design ora shopping case or masks and shoes
* And so let me describe the details
* So user input is given as a fold map,sharp folds and soft folds
* And then the last one is 3D result
* But in the middle,a fast computer fold field
* So for the field computes gives the forthe orientation, for the magnitude, for the individual pixel
* So it has implementation
* So I use, I,input is given as 2D vector graphics and then after that we compute2-dimensional mesh
* And then once the two-dimensionalmesh vertices, we compute fold field one by one
* And they are codingthrough the fold field, which means we specify forwarding angle,and orientation, for individual vertices
* And then, by assembling this informationtogether, we get a global folding
* And then we would get a 3D result
* So, fold field generation works like this
* For each user-specified folds if you, first, the system generates a mesh sothat they align the fold curve's tangent
* And as for soft folds, we diffuse fold orientations inthe non-overlapping regions
* And then for the overlapped regions, weblend overlap fold orientations together
* So if you have this orientation folding, this orientation folding,you get in the middle
* So after getting a fold field, andthen system computes a global folding, so, which means assembling two-dimensionallocal folds, and then you get a 3D fold
* And most important thing here is thatwe do not use physical simulation here, because physics is very slow
* Instead we take a comparativegeometric approach
* So here is the overview
* So you get local folds, where individuallocal regions folded independently
* And then we basically stitch themtogether, to get global fold
* So in this 3D view,you get the local fold, one by one
* And they're stitched together
* And then, eventually,you get a large fold
* And the technique we used here isborrowed from our previous work on a linear rotational-ivariant coordinates
* So to learn more, original paper waspublished Soft Folding in 2013 and there are lots of discussionsabout developable surface control
* And one starting point to look at is Flexible Developable Surfacespublished in 2012
* And there are a couple of works onorigami folding, always has folds
* One example is origami planesimulator in the module space
* And also origami assembly has a lotof interesting assemblies behind it
* If you want more,I recommend you to take a look at the book titled Geometric Folding Algorithms,Linkages, Origami, and Polyhedra
* Thank you.


--- SKIP ---: 09_5-5-interactive-packing.en.srt


--- SKIP ---: 09_5-5-interactive-packing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_5-5-interactive-packing.en_SENTbySENT.txt
* Our next topic is interactive packing
* So, so far we've discussed designsystem but here it's not design
* It's a, assisting laser cutting
* So the title, this word is titledPacCam: Material Capture and Interactive 2D Packing for EfficientMaterial Usage on CNC Cutting Machines
* So as a program we want to address these, how to make an efficient layoutwithin a given material
* So if you have a laser cutter orcutting process it opens a case
* You cut out main materials andthen you get this kind of waste
* But you still see many useful regions,so this is a kind of waste
* So we try to address this program,introduce packing system
* So our approach is to developour overlap free layout that fits within the given material
* So you capture the material with holes andthen we apply overlap free layout
* And then you'll get moreefficient usage of the material
* So, let me show you a video
* So, first you capture the device,captures the material in this way
* And the system will get this image
* And after that, you put,your pattern here
* So this white is holes, hole,and the red is, pieces
* And the user interacts with andmanipulates it
* But the system automaticallyapplies collision detection, so there will be no overlap, all the time
* And after that, you send this data back to the lasercutter, and then you will get the result
* And then there is no more waste
* So yeah, this one shows a motivation
* So this is a capturing process,so we first need to calibrate
* So to do sowe put checkerboard patterns and then system knows the correspondencebetween the camera image
* And then your 3d your 2d coordinate
* And then after taking the picture, a system applies imageprocessing to detect silhouette
* And in order to developa packing user interface we first run observationalstudy to ask people to
* Take a look how they use it andthen we design our interactive system
* So, basic structure is like this
* Use a one by one moving around andthey do the layout
* So, you see here is temporarilyturning off the collision detection so you can get more flexibility andpure collision detection
* And we provided an operation to gatherpieces together, or push away on others
* So, here, we pull everything upwards
* And here is a couple of examples
* So this is also used for, for, as an arrangement of, materialconsisting of many different patterns
* So we proposed four techniques here
* The most single one is pushing
* So it's use a moving around and then collision detection willpush other materials away
* And second one is compress, soif you select the materials or select pieces and then do a simplepinch gesture and then you needed highlighted materials parts comestogether to have a pucked layout
* And then also we also implementeda tilting operation, so gather all of the pieces
* Move to one direction
* And one interesting operationis Collision Snapping
* As I said,as the system also temporarily turned off Collision Detection to get more freedom
* For example, if you want to pullthis blue one over to the other side of the red one, you cannot do this ifyou always running Collision Detection
* So in this case you know ifthe user is putting away in the system temporarily time of collisiondetection then go to other side
* A little bit more detailedexplanation how it work
* So first user moves to other piece andthey just follows it
* And if there's a collision thenthere's a collision force
* Again a reaction andthen it starts to rotate and after rotation you have two collisions andit stops there
* But as the user continually,continuously dragging farther away, then the system detects that there isno way of passing through, however, user still wants to do it
* So I, after passing some threshold thesystem will go into this floating mode
* In this floating mode, system temporarily turn off the collisiondetection physics simulation
* So this floating object justfollows the users dragging
* And, and after going back afterpassing through the almost and then the piece come back to the original,collision mode
* So this is a collision snapping system,So, again, we use an open source[INAUDIBLE] physics engine here
* Here, we only need a 2 dimensionalsimple collision detection So we use a box 2D physics engine
* So do a lot more,original paper was published as PacCAM and it was published in 2013
* And here we label it asmult-touch interaction
* And multi-touch interactionis very popular recently, and many people are proposingdifferent techniques
* Very early one was published in 2002
* It was called smart scape andI recommend you to take a look at it
* And also there are many interesting., There are a lot of interesting works
* Introduction with razor cutting machines
* And one example is and one interesting example is calledintroduction construction
* Interactive publication offunctional mechanical devices
* What they do is, the user uses a laser pointer on topof a razor copter to dial to the space where we have to caught on how to wearrange the target shapes on the material
* So, thank you and this is the endof the fabrication section
* So in this week,we introduced plush toy design, beadwork design chair design,and design of soft folding
* And we finally introducedinteractive packing methods to efficiently use the material
* Thank you.


--- SKIP ---: 01_6-1-cantilever.en.srt


--- SKIP ---: 01_6-1-cantilever.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-1-cantilever.en_SENTbySENT.txt
* [SOUND] Hello this is week six of Interactive Computer Graphics
* And the topic we'll discusshere is Computer-aided Design
* So, computer-aided design is a processof designing products using computers
* And today, almost all productsare designed using computers
* Starting from home electronics orgarments, or cars, and houses
* Everything is designed using a computer
* And physics,plays an important role in here, and physics simulation is alreadyheavily used in the design
* However, in most cases currently,physics analysis is done after modeling
* So a user or designers design a model andthe modelers calibrate model
* And only after that, the model istransported into the physical simulation system, and then, so people will analyzethe property like collision, friction, material property, gravity and so on
* And if there's a problem,go back to the design
* So, but this is useful fortesting the validity afterwards, but this is not very good for activelyuse physics into the design process
* So what we try to do here, is to integratereal-time physics into modeling
* So, so currently 3D model ignore physics
* Just specify x, y, z coordinates and shapes, buthere in the system we introduce here
* Are all integrates, 3D of physicalassimilation into the modeling process, so as user generates a model, of physicalassimilation automatically checks validity and then provides feedbacks
* So that's the basic idea
* And then we will show a coupleof example systems here
* So, this is a list of topicswe're discussing this week
* So one is cantilever design forarchitecture
* And design with music [INAUDIBLE]noble musical instruments and garment design, furniture design andfinally hobby glider design
* So the first one is cantilever design
* So this one is called responsive FEM,Finite Element Method, for aiding interactive geometric modeling
* So the program we want today, discuss here is design of a,physical with physical constraint
* Here, as an example isa cantilever design
* Suppose you have a vertical wall here
* And they have a horizontalsteel bar attached to the wall
* So originally,the steel bar is connected vertically com, completely horizontally,perpendicular to the wall
* But after construction,if you release your hand, support material,gravity pulls the steel downwards
* So, this is of course exaggerated
* But in reality,there's always a deformation
* So the goal is to find the shape that di, ended in a completely flat horizontalshape, after applying gravity
* So this is kind ofdifficult inverse problem
* A traditional approach is to runphysical simulation after modeling
* So, use a space for the rest shape and then physical simulationpredicts what happens
* Looking at the result, user go back to thedesign phrase, and adjusts the shape and they go to a simulation
* Now this kind of back andforth interaction is not very efficient
* So what we propose is to run physicalsimulation during modeling, specifically, while the user is dragging one by one
* System should continuouslyprovides feedback
* This way, you can just knowwhen to release dragging
* So let me show you a demonstration
* So here is a demonstration
* So left side is original rest shape
* Then right side is after the gravity,is applied
* And here, the simulation is continuous,as a user
* So this is so natural, so smooth, it'svery hard to see, but hard to appreciate
* But, as a user drags a system continuouslyphysical simulation and continuously presenting the deformed shape, afterphysical simulation, it's very, very fast
* So as a user change, the positionsystem continuously updates lines many, many simulations
* And the it shows a simulation result
* So it's so fast and so smooth, so user actually looking atthis simulation result, while dragging
* So simulation result is satisfactory,these are just stop dragging, and you'll get the desired result
* So, that's the result, and the other one that we use here isa standard finite element simulation
* So finite element simulation is to dividethe domain, shape into small regions
* In this case triangle regions
* And then compute physical equationson this matrix on these systems
* On the internally, this is a kind of many, many it's internallyessentially it solves
* Huge linear equations, andactually handling matrices
* And in order to accelerate thiscomputation in this kind of direct manipulation editing,what we use, what we use is here
* Reusing of intermediatecomputation results
* So, traditionally it's too slow to hm, run this kind of physi,simulation from scratch each, each frame
* But in this example,in this modeling task, you know, you have the previous step forsimulation result
* And compared to the previous simulationresult, [INAUDIBLE] only a slight change, you know
* Dragging single bar this,the change is very small
* So you can reuse most ofthe previous computation
* So that's a topic trick we use, we use
* Now, this is a little bit more details
* So, of course it's not possibleto explain everything, because we skipped the exponentialfinite element measure
* It's a little bit complicated
* But still, you can get the general idea
* So left hand side uses a coefficientmatrix a, reconditioned matrix x
* So, we do not describedetails about these other ma, matrix structure we use inthe computation of this simulation
* And also, matrix has a value list andtheir structure, and the body list, and structure
* So these informationare heavily used in the system
* And construction,of this information is time consuming
* So in the idle time, nothing happened, sowe can reuse old intermediate structure
* And in the during dragging, we dividedthe dragging depending with the distance
* When the dragging operation is very small,very small relocation, then what's the system is do justupdates the mash-mish vertices
* And almost all information will be used
* As a user drags more and more, then,simple vertex relocation doesn't work, so system tries the update,while it finds a topology
* But after a while, if the deformationstill rise, then simple relocation and simple topology changes nothing there,so system re, reconstructs So this is what is happening,behind the scene, in this example
* And internally,if the relocation is very small
* Then only, system only,recomputes a value list of its matrix A
* And if you change the topology,you have to refresh all the coe, coef, coefficient matrix A
* But you can reusethe pre-condition matrix B
* But after the reconstructioneverything is re-computed
* So this is equivalent to [INAUDIBLE]simulation from scratch
* But this happens very rarely
* So this is a very short section, but summary is to introduce cantilever designwith concurrent physical simulation
* So you can change the shape whilewatching a simulation result
* And internally, most important pointis that we apply multi-level reuse, of intermediate computation result
* More specifically internal large matrixes,matrices
* For efficient computation
* So original paper is availableas Responsive FEM for Aiding Interactive Geometric Modeling
* We discussed many otherexamples too there
* And finite element method is an est,established method and there are many textbooks
* One example is this one,the finite element method
* It's basis on the fundamentals
* And structural optimization is oftendiscussed in computer graphics
* One example is this one
* A procedure modeling of structurallysound masonry buildings
* So this one is the kind ofphysics aware 3D modeling
* However, there is also justautomatic optimization, and did not discuss interme not bringthe feedback to end user manipulation
* Thank you.


--- SKIP ---: 03_6-2-musical-instruments.en.srt


--- SKIP ---: 03_6-2-musical-instruments.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_6-2-musical-instruments.en_SENTbySENT.txt
* Okay.So, next topic is, the design of novel musical instruments,like a metallophone
* The title, we introduce, is a work of the,work, the work we introduce here is titled Designing Custom-made Metallophonewith Concurrent Eigenanalysis
* So the problem we want todiscuss in here is to, how to design an originalmusical instrument
* So, we pick metallophone, in this project
* And as you see, it is very difficult to find a propershape that produce appropriate sound
* You know, in order to function,as a musical instrument, they need to produce appropriate sound
* However, it's very difficult to predictwhat sound they produce when they're hit by a stick
* You know?So that's a very, again, very difficultconstrained design problem
* However, if you have a computer,computer can predict the sound
* And if you run it, continuously, andrapidly, it can be fairly useful
* So user edits the shape, of a bar, ofa Metallophone and the system continuously lands physical simulation to predict thefeedback or audio they produce, the tone
* And they user see, hear the sound
* And then, if it's too high, then it goes back to previous one, orit's too low, go to the other side
* So in this way, the user caninteractively explore, a body shape, while also searching foraesthetically pleasing shape
* So that's the idea
* Let me show you a video
* Okay, so here is a video
* In this example, the to- [BLEEP]
* >> So here, on the right side,you see a two denominational pattern, of a Metallophone you are designing
* So this is a standard, editing software
* You can change the shape by dragging
* And on the right side you seethat the simulation is out
* Just visualize what happens if youhit this metal bar, with your stick
* If your stake is a bar, it vibrates and it produces sound, andthis is a visualization of vibration
* Of course, this is exaggerated,but you see the result
* And then, in addition to itsystem also produce a sound, predicting its tone, or pitch
* So user can hear it, using your ears
* So while hearing your sound,you add it to save
* And so that you get interesting shape
* But also satisfies the desire of a sound
* >> Sound of a Metallophone is calculatedby a Eigenvalue analysis [BLEEP]
* As the user edits the Metallophoneshape in the left window, the system immediatelycomputes it's Eigenmode
* Show in the right window, which tells how the Metallophoneoscillating through this space
* It's tone is also updated with oralfeedback using beep sounds, and visual feedback in the status bar
* [BLEEP]
* Because the change of tone caused by theshape addict is very difficult to predict, we believe designing a Metallophonewith the desire shape and tone will be possible onlywith a responsive [INAUDIBLE]
* >> So, by the way, this visualizationis actually also useful when you, physically assemble the Metallophone
* You know Metallophone in order to, in order to make a Metallophone youhave to put this bar, onto the base
* However, it's a questionas to where to fix
* In this view, you can see thatthis part is vibrate a lot
* So this part should not be fixed
* But this part andthis part is not moving at all, so this is a good place to place it down
* [BLEEP]
* >> Here are, the designedMetallophone pieces by an artist
* [SOUND]
* And it's actual creation
* [SOUND]
* This shows that our analysissuccessfully simulates the real world
* [SOUND]
* Yeah.So, again, I think this kind of design's very,very difficult with assimilation or existing measured
* Only with continuous feedback, you canexplore many possibilities very rapidly, and you can design this kind ofinteresting shape, with appropriate sound
* So yeah, in other words, we,we briefly describe the algorithm
* Again, we use finite elements simulation,so we do not go to the details
* But I can give you an, a basic idea
* So the problem is to findthe frequency of vibration
* And here,the method we use is Eigenmode analysis
* Let me give a very,very brief abstract explanation
* So this a equationdefining this phenomenon
* So, this is basically likea very basic a spring system
* So u, u, means a displacement,or location
* And then, you,this one is acceleration or the position
* Which which is proportion to the force
* So this means that, the displacement is proportional tothe force, applied to the material
* So this is basically the same as a spring
* You know, if you spring, more, move- If you move more, than the po,force to putting back, it gets larger
* So this is a very basic andgoverning equations, for the system
* And then you, we represent u,we assume oscillation, vibration motion
* Which is presented as this one
* So, left side is amplitude field
* So amplitude is depending was X
* This is a view, you see in the rightside of the window, you know, amplitude
* So amount of vibration isdependent on the location
* Some part moves a lot,some part doesn't move a lot
* So this is the left side
* On the right side is just sine wave,in oscillating motion
* And we put this into here
* So amplitude is positional, and oscillation is depends on time,and very yeah cyclic motion
* And then if you put it here, andthen swap the equation and beautify it, you'll get it
* And this is very standardEigen value problem
* And you can solve using standardmatrix computation method
* And after solving this one, this w, staysdirectly associated with the frequency
* So after solving this Eigen value problem,you'll get the frequency
* This is the sound we, we produce
* The as a result of simulation
* So here's a summary
* So we presented Metallophone designwith cons, concurrent simulation and audio feedback
* And in, inside the system we ranstandard Eigen mode analysis
* We assume cyclic motion, andthen we tries to, to find the frequency
* So to learn more
* Original paper is published asDesigning Custom-made Metallophone with Concurrent Eigenanalysis
* And for if you want to know more ay, analysis one possible reading is,Dynamics of Structures
* This is old text book
* And also sound rendering
* So simulation of sound produced,production
* Sound synthesis and sound propagation isalso hot topic in computer graphics field
* So it's called sound rendering
* And one interesting paperto read is recent one, is Precomputed Acoustic Transfer
* Output-Sensitive, AccurateSound Generation for Geometrically Complex vibration
* So, these are the recommended readings,if you want to know more
* Thank you.


--- SKIP ---: 05_6-3-garments.en.srt


--- SKIP ---: 05_6-3-garments.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_6-3-garments.en_SENTbySENT.txt
* Our next topic is Garment design
* The work we introduce hereis sensitive couture for interactive garment editing and modeling
* So, the problem we want to address here, is a design of a newnovel original garment
* And again, this is very difficult forinexperienced people
* So, you have 2D cross pattern, and then you have threedimensional garment on the body
* it's, what you want isthree dimensional shape
* But what you have to controlis two dimensional shape
* And it's very difficult to imaginewhat 2D pattern you have to get to get the desired 3D shape
* So, that's a problem we what to address
* And our approach is the sameas the previous one
* So we learn continuous concurrentsimulation behind the scene
* So user continuously edits are saved2D pattern with mass operation and the system continuously appliesphysical draping across simulation
* So user can directly edit to decidewhile watching the clothing in the 3D configuration
* Well, that's the idea
* So the same as before, on the left side, you see 2D clothes patternsthe user is editing
* And on the ride si, on the right side yousee clothing, putting onto the 3D body
* And here the simulation is much moreaccurate than the one I showed for the stuffed animal design
* So you can actually predict details,wrinkles and so on
* So you can interactivelyedit the 2D pattern
* And the system interactively updatesclothing draping simulation results
* So you can actually seesome more wrinkles here
* And then you can edit the shape
* So as to reduce wrinkles if necessary
* So traditionally, if you want to do this,you have to actually physically cut paper or a cloth material, stitch together andput on the mannequin, physical mannequin
* And learn draping and see the result andthen go back to the pattern and cut it again
* It can be very, very long,long time, it's very slow
* And those are computer basedsimulations also available
* It's similar
* You have to move the simulation enginesimulation and then go back to the design
* That's a problem
* And also, technically, it's very, challenge to run physical simulations sorapidly
* Of course there are real time rapidcloth simulation existing already
* But they, these physical simulation is foranimation
* So they assume fixed clothes pattern
* So clothes geometry doesn't change
* And the system learns lotsof precomputation for efficient computation real-time
* And then just draping learn animation
* To learn simulation to create animation
* However, here, the system, the usercontinuously change the rest of shape
* Which is,violates assumption of standard animation, animation simulation [INAUDIBLE] sothat's a challenge we have to address
* So if you do not like a wrinkle here, thenyou can just interactively add dart here
* And then, you can immediately see howthe resulting clothing looks more natural
* Okay, so this is one example andhere's more examples
* So, yeah, so design of t-shirt or garment for human characteris not actually so difficult
* There are many standardways to design a garment
* However, if you wantto design a pajama for armadillo like here,it's a different program
* No one knows how todesign a character shirt
* And especially if you wanted tobuy a physically bodied garment, it's very difficult, and this kind ofdesign tool can be very, very useful
* So previously in computer graphics,garment of this character is a very cross mesh, there's no physics,just a polynomial mesh
* But recently, game engines are very fast,more efficient
* So we use, people starting to usephysical assimilation for these garments
* Now then, it's necessary todesign physical bodied garments
* So that's these are why youneed this kind of tools
* So here is a comparison with a real one
* The left side is a computer graphicsview in your simulation, and the right hand side is the physicalconstruction which we 3D printed
* This kind of character and also wephysically stitched together this garment
* And as you see, of course,it is not 100 millimeter size exact match
* However, you see the generalpattern like sleeve folds here and then you see full sleeve folds here
* So I think this is enough forour initial design
* And we also design realsize garments using system
* So this is just, just screen snapshot
* We're using track to edit to save
* And then you see continuouslysee the 3D result
* And then we print it into a larger format,real size print
* And then you put pattern into a cross and you stitch it together andthen you get a wearable results
* Okay
* So let me briefly describe algorithm
* So, again, so oh, complete implementationis beyond the scope of this short video
* But I can briefly describethe basic idea behind it
* How to make it faster
* So this is a fundamental equation
* Mathematical representation ofthe problem we trying solve here
* So we have 2D input pattern
* This is the input from the user
* So user specify 2D clothes pattern
* And then what we,ha want to compute is 3D cloth shape
* So, yeah
* So input these XY coordinate positions orwe input clothes, and the output is XYZ position or orwhen you give your body shape
* So 3D cloth shape,this is output you want to get
* And then we cover function,that represents an additional set of 2D cloth pattern input and3D cloth shape output
* And this function returns 0, if it is satisfy the physicality,body natural shape
* And this function is called the resi,residual
* So if the 3D cloth shapeis not in the desired, appropriate physically balanced shape
* This zero becomes bigger, larger
* And then we, we gradually,this residual are smaller
* They get more physicallyrealistic results
* So that's the problem we try to solve
* And visually,the situation looks like this
* So you have a space of varied designs
* And on this view, on this axis, you have many differenttwo dimensional cloth patterns
* So use the space forthat starts from this pattern and then moves to another pattern,and use the edit
* And for each shape,you have a single iso surface, or space-specific region, where R becomes 0
* So here, it's represented asa single line, single cloth line
* So, for the given 2D clothes pattern, we takea look at the region where the R equals 0
* And then look at the 3D shape, andthen you will get the proper 3D output
* So this is a, very very simplifiedview of what's going on internally
* The program is at, notice here
* So R, the residual is very highlynon-linear and very, very slow to compute
* So, yes, so R 0 is very curved andvery complicated
* When you change the pattern, you have torecompute R, which takes too much time
* So we,what we use is a kind of a stanadard
* But we use a linear appro,approximation around the current state
* So visually, it looks like this
* So, this a current design andthen you compute the linear appro, approximation of this residual function
* And this method called, called sensitivityanalysis in structural analysis
* And then after computing linearapproximation it's kind of easy, to predict the,compute from 2D input to 3D shape
* Just by solving our linear system
* Which is faster
* Of course,this is an approximation near this design
* So, if you go farther away,then it's, it becomes too different
* So and your system
* So single linearappropriate is nothing now
* Users who're walking faraway from the linear state
* It's a difference from the realphysically realistic result gets bigger
* So in that case, we compute anotherapproximation here right this way
* And then, so we cache multiple linear approximationsoccasionally and then blend them
* So, in this case,if you have two examples and if you blend these two, you get a very,very close approximation
* And this is still very fast to compute
* So that's what we do in internally
* So caching happens occasionally
* So, the user,the system continuously monitors
* Users the dragging operation
* And then when the users dragging gettingfar away, you create another cache
* Now you have two cache, and you move far away from these two caches,the system will generate another
* So in this way, the system incrementally,the more and more caches
* So this is a summary
* So we presented garment design withconcurrent physical simulation
* So we edit a 2D pattern
* And the system presents3D draping results
* And then we have uprising sensite, sensiivity analysis whichis linear approximation
* And those are multiple cachesbefore providing rapid feedback without randomsimulation each time
* So, to learn more the original paperwas published on Sensitive Couture for Interactive Garment Editing and Modeling
* And the garment design is also a hot,popular topic in graphics community
* And one example is Virtual Garments,A Fully Geometric Approach for Clothing Design
* So, in this project,they did not use any physical simulation
* Purely geometry approach, but the, but they can rapidly generatereasonable shapes this way
* Thank you.


--- SKIP ---: 07_6-4-furniture.en.srt


--- SKIP ---: 07_6-4-furniture.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_6-4-furniture.en_SENTbySENT.txt
* Our next topic is Furniture Design
* So the work we introduce here is a guidedexploration of physically valid shapes for furniture design
* So the motivation,the question we want to address here is
* How to design the valid furniturelike a shelf or a table
* So the problem we consideris robustness and stability
* Robustness means, means do not break
* This one example, is you have this kind ofshelf and you put the heavy object here, and this nail can be break, bent
* So this is a problem we have to avoid andalso if you get this shape and you put this heavy weight here,then this would probably topple
* So these are the problem we want to avoid
* However, in this simple case it'seasy to see but if you have a very complicated shape like this one, it's veryhard to see how to design valid furniture
* So that's a problem we want addressed andour approach is like previous systems we introduced so far, we providecontinuous structure simulation
* So given our user input,system applied physical analysis and they identify which is valid or invalid soyou can continuously be part of it
* The addition to it in this work wealso provide active guidance to maintain validity
* So in addition just telling you,you are invalid or you are valid
* System also guides the userto recover validity
* For example,if the user in this invalid region, you are design is invalid andnot only telling that you are bad
* It can also tell you how to fix it
* So the system is continuously provideactive feedback how to go back to the valid region
* So this is can be farther assist the userin the design process, so that's the idea
* And this is a specialtechnique we will introduce, is one annotation indicating valid range
* So here, in this angle,is not very good, not durable
* So, if you put weight here,then this nail will be broken
* However, if you rotate this,plank to vertical, then it becomes stable,robust, it doesn't break
* But if you go beyond farther thenagain it's not robust, durable
* So system compute valid range ofthe angle you are manipulating and the visualizing another annotation so internally system runs many simulationsand then finds the valid divisions
* So this is the stability analysis andannotation
* So the another is stability
* So here the system identifies thatthis configuration is not stable
* If you physically fabricate this,this will topple
* So this is a [INAUDIBLE] butin addition to providing this feedback, system also provides suggestionsshowing valid designs
* So when the user provide this, not onlytelling the user this is not stable, the system generates bodycandidates this way and the user just speaks long them andyou get the product design
* So let me show you a video
* [SOUND]
* So, this is a user interface, so user design the shape,with a simple logging operations
* Yeah.Nothing special so far
* So here,as a user start rotating this plank
* If the angle is too much,then this joint will collapse
* The system profile isnot durable feedback
* In addition, this not durable indicator,the system shows a valid lane
* So in this range it's okay
* Yeah, so this is a visualization
* So, this is much more helpful thanjust telling you are not durable
* You can, the system alsoprovides visual of feedback
* Yeah, this is the body domains forpreventing toppling Our system also provides balancein a number of positions
* If this is geometric analysis but ifit's not disconnected the system suggest multiple choices to fix discontinuity Andhere in this situation it will topple, so systemsuggest multiple candidates to fix it
* Yeah, in this case it's not durable so systems suggested lower it,remove the lower bar or other support
* Let me show you a little bitmore complicated example
* Yeah, so as the design gets more and more complicated it's very hard to see whereis the bottle neck and what is a body
* But this kind of system very helpful todesign physically bodied complicated shape like this one
* And then we also fabricated the L one soin this case we designed a chair [NOISE] Okay, so let me again very brieflydescribe what's going on inside
* So what we presenting is how to preventbreaking and how to prevent toppling
* So first one is robustness analysis
* So if analyze bend force of joints
* And also in prevent toppling we put, analyze force,contact force at the ground
* So let me explain one by one
* So okay let's ask how to, let me justclarify how to prevent breaking
* So, suppose we have this kind ofconfiguration, three planks and two nails
* And then we try to find the regionwhere the nail is placed
* And then in, to do this we consider a space spanned by,nail joint bending forces
* So we compute bending forceat this nail 1 on nail 2, and then we put designs,in the space spanned by these forces, applied bending forceup right to these sets
* For example, in this configuration,it is located here
* You know there's no,if there's no bending force, lambda 2 equal zero andlambda 1 is somewhere here
* So this is the best thing,so compute bending force and then you put current design in this spaceand after that we have bodied range
* Right, if the bending force is too light,too large, it's not durable
* So bending force should be smallerthan a specific threshold
* And it is end up witha kind of box region
* So if design is inside of this regionit's durable, it's safe, it's okay
* But if it's outside it'snot durable it's not okay
* So system needs to the suggestgoing back to this region
* So yeah, sovalue to design is somewhere here
* So the task is moving from here to there
* So that's the starting point andthen what we do is something like this
* So for our given current,no spin, non durable design we gradually change a parameter andthen we check the project tree
* You know, gradually change design andthen you rotate in this fourth space
* And then, you see a trajectory
* So if you change one thing,you get this trajectory, if you change another thing,you will get another trajectory
* So in the system,we test various trajectories, you know
* One point we try to change the angle here,in somewhere else, you try to position something else
* We try many different variety oroperations on the check trajectory
* And then, after checking trajectory, we pick the one just going with the saferegion and then show it, as a result
* So internally, systems learns a lotof physical simulation and we do not explain data here, but internally we aregiving you the same sensitivity analysis
* So it is a linear approximation
* So instead of computing individual one,we are approximating so these linear single line then you canarithmetically compute collision, safe collision faster andso that's what's going on
* Prevent toppling
* So this is also very similar
* So here we compute contact force betweenthe furniture leg and also the ground
* And this force should be in one direction,you know, force should be
* And the action force comesfrom floor to the furniture
* If the force is under the pointed side, then it means that the for the floor andit means that there is a problem
* So in the force space diagramlooks like this, so if
* So contact force shouldbe always positive
* You know?Contact force needs, needs to be positive, if negative,it means that the contact becomes fall apart; which means the furnituretopples over, stumbles
* So in, the task is to move the designback into this valid region
* So again, the same thing
* You compute the trajectory bychecking many variations and then to identify and find the good one
* Ok, so little bit, maybe too fast butthat's a brief summary
* So, we presented furniture design withdurability, and stability analysis
* So system continously checks whethercurrent design stable or durable
* And in addition to that, system actively guide the userto go back to the valid region
* So to do so, internally, we apply jointforce analysis in the force space
* So in the case of durability we computebending force and the force of stability we compute the contact force and then wetry to move back into the safe region
* So to learn more, original paper waspublished as Guided Exploration of Physically Valid Shapes forFurniture Design
* And the physically valid designof objects is popular for topic in this entry, and a couple ofinteresting works appear in this entry
* And one is Make it stand: Balancingshapes for 3D fabrication
* So this technique takes single 3D objectand then tries to adjust the shapes so that it actually stands, not topple
* So this is automatic optimization andthe another is, Stress relief: Improving structuralstrength of 3D printable objects
* So this one takes 3D object and print it
* However it also analyzes weakestbottle neck for example, this neck can easily break, so system identifies it,and then make it more stronger
* So this kind of conditionis heavily explored
* Our work is different because we try toguide the user through the modeling phase
* That's it, thank you.


--- SKIP ---: 09_6-5-gliders.en.srt


--- SKIP ---: 09_6-5-gliders.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_6-5-gliders.en_SENTbySENT.txt
* The last topic of thisweek is a glider design
* So the work we here, we introduce hereis a teromis, an interactive design and optimization of free form,free flight model airplanes
* As you see, this is a very latest work
* So motivation the question we hereis how to design a paper airplane or glider so you could fly the airplane,and then we hope it flies well
* However, it is not very easy for inexperienced people to designa glider that flies well
* You know, there are many designs, but this is the result of many,many experimentation
* It's not easy to designarbitrary shaped airplane
* So that's a problem we want to address
* And again, we ran concurrent simulation,but not only ran simulation to analyze it with as well,we also provide automatic optimization
* So given current designs this modelautomatic adjusts the shape so that it flies well
* So, this is similar tothe previous system
* Behind the scene is more interesting
* Here, we use a data driven approach forthe simulation
* So accurate analytic simulationof airflow is very difficult
* So here, we use many, many measured data
* So this is airplanes,we actually fabricated, created, flew together and measured
* We get this loads of data andwe infer many parameters
* And then we use it forthe physical analysis
* So that's the story
* So let me show you what we do
* Yeah, so this is a typicalexample of not flying airplane
* So if you design arbitrary wing shape,you know, it just drops, doesn't fly
* So our goal is to be ableto design arbitrary shape, this kind of strange shapeairplane by yourself that flies
* And then this is one example wecreated and it flies very well
* So, our approach is like this
* So first is offline precomputation
* So we took many,many airplane trajectories and analyze it
* So we flew these gliders, and then checkthe trajectory, flight trajectory
* And then we compare the simulation result,and then adjust the parameters so that simulation result fitswell with actual flight
* And this is the basis ofthe physical analysis
* And given this data, now you generate,you design your own airplane, and the system now can predictsoft flight trajectory
* On the, in addition to showing orpredicting the flight trajectory the set system runs automaticoptimization to make it flyable
* So the user can pause for edit, edit and simulation [INAUDIBLE] andthen you get desired shape
* So this is our user interface
* So similarly, to the previous systemwe use our edit to shape this kind of two dimensional view
* So you're moving along the vertices, and then system continuouslychange the 3D shape
* In addition to that, here,the bottom half is the simulation result
* So this predicts what happens
* In this case, the airplane goes upwards,and the [INAUDIBLE] goes down
* And as user edits a shape, systemcontinuously runs physical simulation, and tells whether the airplane flies well ornot
* The reason, why we have multipletrajectories is that, you know, the user's hand throw always changes
* Sometimes goes higher
* Sometimes goes lower
* So the system automatically predict,consider multiple possibilities, and then show general tendencies
* So that's a [INAUDIBLE]
* And now let me describethe optimization part
* So as you see,there is a magic make it fly button
* So this is where you press this button, system apprised automatic optimization,and to make this airplane fly
* So here, in this design, it doesn'tfly well, it doesn't pass this line
* It goes too up or too down orit doesn't fly well
* As soon as you press this button, system optimizer, say it carefully,it's kind of very subtle
* But I do not, nothing
* The video, shows the systemautomatically adjust the wing position
* So, let's see
* The user press this button,system adjust the wing position
* Yeah, here
* So, the front wing moved sideways,so this is not by the user, the system automatically adjuststhe shape so that it flies well
* So in this clip,the user edits the front wing and the system automatically adjusts theposition and orientation of the rear wing
* So as you see, user,moves around the front wing and then system automatically adjust,the rear wing
* Please note that simulation results[INAUDIBLE] drastically changes with just small change inthe reorientation of the position
* Which is very difficult to do forthe user, or people to do it, but the system can do it
* [SOUND] So again the important part is this kind of interactive exploration
* You can test many different things andthe system continuously provide feedback
* After having the design,you send the data to the laser cutter, and then you get a shape
* And results
* So, here's our results
* So important thing isit really flies well
* You know, it's kind of amazing for us too
* So this has a launcher andthey are starting from As you see, yeah, it flies way back,so it's very amazing
* Yeah, we have it here
* This dragon airplane, and this also flies
* You can also use other materials
* And this one
* Or this one
* Okay
* That's the video
* So, here's a summary ofthe algorithm that we use
* So, standard fluid simulationaerodynamics is too slow
* It's not, can be a real time
* So we use a traditional wing theory
* Wing theory is simplifiedmodel of our airplane
* So it computes lift force occurring eachwing, and then after computing the lift force and gravity and others, and thenyou can predict the flight trajectory
* So that's the theory we use
* So wing theory looks like this
* So given given a, a wing,shape, and then the force
* We compute, force up, close by the wing
* So it's the lift force, f,and the drag force, fd, and then rotation force in tau, tau
* And then it's a function of velocity andarea, you know
* It's faster and faster and then forcesgets bigger, and the area is bigger, and the forces gets bigger
* And the question is these parameters
* You know, these are the constant
* Defines the behavior of the wing
* And it depends on the angle of attack andalso depends on the shape of the wing
* And these parameters are,is what we want to know
* So to estimate this parameter, we take ourdata driven parameterization approach
* So we fly many airplanes and then measure the parameters andthen we try to fit the parameters
* So, you know, this Cd, Cl, Cm,are all depending on the angle of attack
* And then we plot it in a measure,we plot the measured data in the space and then we get the best approximation
* And also we then, we can estimate the force causedby each wing element in this way
* And then we aggregate forces causedby these small wing elements
* And then we computes approximate totalforce caused by the total entire wing
* So to learn more the original paper ispublished as Interactive Design and Optimization of Free-FormedFree-Flight Model Airplanes in 2014
* And flight simulation is alsodiscussed in graphics community
* One example is data-drivencontrollable flapping flight
* So it simulates the flappingflight of birds
* And data-driven simulationis also a popular topic
* So you, it is opens a case too slowto land, stand out a simulation
* So possible approach is to allow many,many simulations beforehand of flying
* And then in a long time just assemble, measure previous simulationresult to get a realistic result
* And one possible reading isData-driven simulation methods in computer graphics is published asa a Siggraph 12 course material
* So this is a summary of this week
* So we presented integration ofreal time physics into modeling
* So user continuously aid it to save, and then system continuously providesfeedback, running physical simulation
* On some systems, just provides[INAUDIBLE] simulation results
* But, also some system provides continuousguidance to design varied shapes
* So we introduce a fast,simple cantilever design, and also design, discuss musicalinstruments with model analysis
* Also also garment design,using linear approximation and furniture design with active guidanceusing joint force analysis, and finally glider design using wing theorywith data driven parameter feeding
* So, that's the end of this video
* Thank you


--- SKIP ---: 01_7-1-command-card-interface.en.srt


--- SKIP ---: 01_7-1-command-card-interface.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_7-1-command-card-interface.en_SENTbySENT.txt
* [NOISE] Hello, this is week seven of Interactive computer graphics course
* The topic we discuss hereis Real World Interaction
* [COUGH]So real world interaction, we mean a user interface for computingsystems, working in the real world
* So, so far, we have discussed userinterface between computer and the user
* So user do something, and then computer dosomething, and there's interaction here
* So through here,we extend this into the real world
* So some computers can be connected to realworld objects like a robot or appliances, home appliances so we discuss herethe interaction between this kind of computing systems working in the realworld robots or home appliances and so on
* So here's original topicswe discussed this week
* So we discussed command card interface forhome robots
* And Style-By Demonstration forteaching robot's behavior, and the Actuated Puppet Device, for posing a steady characters and the RoboticLight systems and the Fur Display
* So first topic, we discuss isCommand Card Interface, where this one is, this work was published as Magic Cards
* And question here is, how to commanda robot, walking robot in your home
* Now, typical approach isI think is two extremes
* One, it's very simplified, easy touse control with speech or gesture
* It's very abstract control
* However, in some cases,this is too abrupt, too simple
* You know, you cannot specify details withvery simple command like create here, or do it, or go there
* It's too abstract
* And also,these kind of commands are volatile
* You know, as soon as you saysomething it disappears
* It's kind of a difficult to confirmwhether you actually gave a command or the source
* And also you need to remember what commandis available when you speak or gesture
* The other extreme is direct control,using joystick or gampad or somthing
* So you continuously provide commandthe system continuously follows a command
* So you can do everything withthis control details, however
* In some cases,this is too little control, and it's very tedious to control continuously
* So what we try to do here is to hit somemiddle ground between these two extremes
* So this is a method we propose here
* We propose paper card interface forgiving command
* So in the, inter-environment the userleaves a command card giving instruction to the robot, such as clean here, ordeliver this object here, and so on
* And when she goes out, everything happens, and the robotdoes its task when she is going out
* So the user puts the instructioncard in the environment, and the robot does the jobwhile the user is out
* So that's the idea
* Let me show you a video
* So, first part of thisvideo is a futuristic view
* So this is a concept video,not to be implemented
* But I hope you get the ideafrom this sequence
* So suppose you have a house, messy room, messy kitchen,throw all trash bins is full
* So we need,I want robot system to take care of it
* So, she pulls out a command card set
* So this one is a combinatory list, of possible operations youcan give to the robot system
* Only you pick up appropriate commandcard and leaves it in the environment, like wash this kitchen, anddeliver this to the garbage or bin, take out this garbage,make bed, so, clean here
* So a good thing about this kindof paper card couple things
* So, first you can see a list of availablecommands just by looking is the cards set so you do not need toremember possible commands
* And also leaving a card isa very clear instruction and if you want to cancelyou just pick up a card
* And also a card is a very appropriate forspace time physical location
* Like clean here, deliver here andhere is very ambiguous, but color location exactlyspace wise location
* So that's a benefit
* And after she goes out a robotappears to do the task
* And again this is a concept videonot real implementations so again this case our robot appears andit does the job
* So, here what we try to dois mimic interaction with human human interaction you know a humancan give a message card to another human
* And then they can do the job
* So we try to do the sameas computer system
* So that's it
* And in the evening the user comes back andeverything is done
* So this is the kind ofenvisioned futuristic view
* And now let me show youactual implementation
* So, Current Implementation, not too fancy,but there is a basic saying
* We built a system using Roomba robots
* So we have a couple ofrobots working together
* And also, we put it in the environment, where everything is observedby the ceiling mounted camera
* And the system continues totrack the command card and also the lowered locations
* So yeah here's the system in the view inwhat, is it actually walking system so user give instruction like deliverthis box from here to there
* This location
* And the vacuum clean this spot
* And, also, remembers the task
* And then the user goes out andthe system starts walking
* And see it in camera capturesall of the command cards
* First, system picks up the command cards
* He is in this card pickup
* And after that,the system start to do the job
* First request was to deliver here,this to here
* So, pushing robot starts to walking andit push it over to the target location
* And next, using a grid systemto vacuum clean this spot
* So vacuum cleaner appears andthen clean it
* So, that's system and also, another interesting aspectis that reporting errors
* So, user gives instructions to robot,as a paper card
* And, but sometimes system alsoprovided feedback to the user
* For example, system makes an error, then system should presenterror report to the user
* An interesting point aboutthe system is that error report is also given as a paper cardleft in the environment
* Let's see it
* So if the robot fails,like the power is out
* And the small printer,mobile printer robot appears and then they have a printed message tothe user, such as, I'm sorry, I failed
* So this may disclose a loop, you know,user provides command on paper card and the system providesfeedback as a paper card
* In this way, user can interact withthe robotic system without touching any computer, just using paper card
* So yeah, as again the environments likethis we have ceiling mounted cameras and central computers andthen remotely controlled robots
* And we use visual tab using 2-dimensionalaugmented reality visual code
* And backside you see instruction forthe user
* So that's a system
* And here let me briefly describe pushingalgorithm developed for this system
* So this is a pushing algorithm for a nonpre, prehensile, which means no grabbing
* So yeah, so naive approach istwo binary state approach
* So first half your robot shouldgo behind the object, and after reaching the behind object the robot goingto the pushing state and initialize push
* But in the middle then robot's mo, may object may move sideways, andin that case robot go back to the behind
* And after reaching the behindgoes the pushing state
* So in reality the robotneeds to go back and
* Force between these two states
* And this is not very desirable
* So, this is unstable
* So, robot can, into an unstable status,between just go back and force between these states
* And also this requires verycareful parameter setting
* You know, you need some thresholddistinguish these two states
* And this parameter can be very sensitive
* So, what we propose it to avoid this
* We propose to use a dipole fieldto achieve pushing behavior
* So suppose you have object here, and you want to move this object to the,this direction
* So, given this object position and orientation, we computea dipole field at the center
* And that the object andthe oriented tower's target direction
* And after that, simply we close the lower,according to this dipole field
* There are a couple benefits
* First, there's no clear mode switching,going behind and pushing it smoothly emerge so there'sno sudden change between the two modes
* Another thing is that scale invariance
* So, as you see dipole field it doesn'tchange, even if you scale up or scale down
* Always the same shape depend,regardless of it's scale
* So which means you canapply the same allowances, the same parameters to the objectwith different scales
* So here's a little bit more details
* So you have object and pushing direction,desired pushing direction, direction and you first computelocal coordinate plane defined by the object position and orientation
* And then you compute the position
* Of the robot, relative to thisobject in this coordinate frame
* So, you get cos sin theta andsin theta, is a distance r
* After having this theta angle,the other one is very simple
* What you have to do is,just compute sin2 theta, sin2 theta
* It gives you the direction
* Where is it robot should look
* This is just a the finishing withright field, dipole field, and you can implement this kind of here
* Very, very few lines of cords
* So, let me show you a brief video
* So, yeah this is the basic idea
* And the system consists ofa seating camera and robots
* And then, this is a computed Dipole Field
* And then robot flows along the,flow field
* So in this examples,the robot pushes a very small cup
* And then the movement is very small
* There is no distinct two modes
* It's molds together
* And here the robot tries to push the largedish exactly using the same dipole field
* And you can apply the samealgorithm to the Roomba box, to push things on the floor
* By the way, this robot is veryeasy to control, from computer
* So, if you want to try robotic system,I recommend to try this system
* Another interesting thing is here,Cooperative pushing
* If the object is too heavy forone once to push, two robots should cooperate together
* Traditional approach is the power pushing,you know
* There's always that other two, alwaysact side by side, robot push together
* But here,we tested Single-line serial pushing
* So the other one was very simple,just apply two dipole fields
* Here, this robot tries to push thisbox this way, but it's too heavy
* Then this robot pushes this second,the fast robot
* The second robot pushes the fast robot,again, using a dipole field
* So by combining two [INAUDIBLE] then,you know, robots can push relatively heavy object
* And again motion is going to be smooth
* So that's it
* So, yeah, so we introduce command car based interactionand pushing outer wards in to achieve it
* And original paper was called Magic Cards,paper tag interface for implicit robot control
* And the paper ID we used is a popular one
* They are visual two dimensionalbar code to measure a dipoles, frequently used inaugmented reality systems
* Original paper was published in1998 by has metrics real time object identification andregistration method for augmented reality
* And if you want to use it and then there'sa popular toolkit called AR toolkit, and I recommend you to try it, if you want
* And for the pushing algorithm, wepublished a paper on the Dipole Field for Object Delivery by Pushingon a Flat Surface
* So if you want to look at the pushingalgorithm please take a look at this paper
* Thank you.


--- SKIP ---: 03_7-2-style-by-demonstration.en.srt


--- SKIP ---: 03_7-2-style-by-demonstration.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_7-2-style-by-demonstration.en_SENTbySENT.txt
* Our next topic is style-by-demonstration
* So, the what we do this here iscalled style by demonstration, teaching interactive movement,movement style to robots
* So the goal here is to teachinteractive behavior to robots
* The robot observes user behavior
* And the user do something andthe robot do something
* So we try to teach thiskind of interactive motion
* And you will have to do this, you know traditional programmingis require, you know
* User have to how to call, how to do it
* However, traditional textbased programming like C or Java is too difficult for designers
* So, our goal is to, do this, make itpossible for artists to design behavior
* And then, we take proble,programming by demonstration approach
* So the intertwining phase, user interactswith the robot, operated by an operator
* So, the designer actually operatesthis robot, interacting with the user
* And then, from this demonstrationresult training data, is a run time, systems automaticallysynthesizes robot motion, responding to the user input in the realtime and defaulting to the training data
* So that's the basic idea
* Let me show you a video
* So here this is a user andthis is a designer operator, and then here's a robot
* So, and this is a training phase
* In the training phase, operator is operating the robotto responding to the user
* After that, he leaves
* He disappears
* So I think he's teachingfollowing behavior
* So, in this case, the designeris teaching attacking behavior
* So, tries to push this user away fromthe lesion, so that's a behavior
* Oh, by the way, everything in trackedusing a motion capture system, so if the users positions, and robotposition is continuously tracked, and recorded, as a training data
* After the learning in the lab time, robot replays interactive motionadapting to the current situation
* So here is a robot who is reprisinga burglar attacking behavior
* So, I think it's very tedious to teachthis kind of motion using standard program language, taking user and robot positionas input, and then compute many geometric
* How to code motor motionis hard very difficult
* We also tested this kind of tabletopconfiguration for teaching
* So the user is manipulating,controlling the robot in this way following the characterfollowing the user
* I think here the user isteaching stalking behavior
* You know, following a personfrom the behind, hiding away
* So, this is the result
* So the system is learning automaticauto-resume based on the training data
* So this why he's following the person,like a stalking, with a certain distance
* So this is not just a replay, orpre-programmed, predefined motion
* It is adaptive to the current,current configuration
* Okay.So, that's, that's video
* So let me briefly describe the algorithm
* How to do it
* So, here's situation
* So, we have training data
* User motion data, position data,robot position data, and these are time sensitive data
* So, in the training data you have lotsof time series paired, traditional data, motion data
* And also, we have a runtime situation
* So use is suppose to show he'scontinuously interact and the robot motion is continuously interact
* So, now, this is the current time
* In the current time frame you have thehistory of user position, robot motion, and also user's current position
* And the task is how to computethe robot's next next desired position
* So that's a
* Tasks, so input is this old data,and the output is position
* Desire to position was lowered
* In order to do it, in order to sendsimilar motion to the training data, first task is searches forthe similar situation
* So, you compute the current configuration,we send you suppositions
* Recent user motions andrecent robot motions, and it searches for the similar situation in the data set
* You can make it faster byindexing it beforehand, but anyway what you do is search forthe similar situation
* And after identifyingthe most similar situation
* And the system basically just copies and pastes, takes the motion inthe training data to the current data
* Of course, this is a very, very simplified view, butthis describes the basic idea behind it
* And this kind of two-pair and two-pair synthesis is inspired by thistechnique so called image analogies
* This is the technique designed,developed for image filtering
* So what we, what they do is here,so A, A dash, and B is an input
* And the B dash is a result
* So, here the user triesto teach image filtering
* So this is a, A is an input image
* And A dash is output image of this one
* So this one is kind of water paintingfilter, so system takes image and then converts it to a kind of a waterpainted painting from the input
* So here the user providesan example as A and A dash, andit also provides B as a source image
* After the system learnsfiltering from A and A dash, and applies to B,and you get B as an output
* What happens internally is similarto the method we had just described
* For each pixel in B dash we searches forthe similar situation in A, A dash, and B, and then appliesthe result in A dash to B dash
* So that's what they do
* Okay.So, in this short video we describe how to teach interactive behaviorto a robot by demonstration
* So the, the designer operates a robot intraining time, and then know what behaves
* The based on the training data
* And internally what they do iswhat the lower do is searches for the similar data in the demonstration or training data, and then copiesthe previous motion to the current motion
* And then the algorithm isinspired by the image and the logistic developedthe image filtering
* To allow more art, original paper waspublished as Style by Demonstration, teaching interactivemovement style to robots
* And image analogies is at SIGGRAPH 2001
* And the general concept ofprogramming by demonstration, or programming by example,has been extensively studied in field
* And one represented reading is,recommended reading is titled book is Watch What I do:Programming by Demonstration
* So this book introduce manyinteresting techniques and examples of program,programming by demonstration
* Thank you.


--- SKIP ---: 05_7-3-actuated-puppet.en.srt


--- SKIP ---: 05_7-3-actuated-puppet.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_7-3-actuated-puppet.en_SENTbySENT.txt
* Our next topic is Actuated Puppet
* The what we introduce here is an ActuatedPhysical Puppet as an Input Device for Controlling a Digital Manikin
* The Motivation here is that 3Dcharacter posing is difficult
* So, suppose you have a characterthat you want to set the posing
* And the most popular approachI think is 3D widgets
* On the screen,you have a widget like this, and you use a mouse to controlindividual joy dongles
* However, this is very tedious tocontrol individual joint dongles
* For each joint, you have three angles,one by one, can take much time
* Another approach is the Motion capture
* You have a capture device and a unit
* However, you need dedicated environment,and that you also need a skilled actor, actor
* And also another possibility isto use Physical Input Device
* This is very convenient
* You can grab a Puppet andthen pose, and you get the 3D view
* So you can use bothhands can be very good
* However standard physicalinput devices very stiff
* You know if you, if it to relax,it cannot hold a pose
* And if its stiff enough to hold a pose,it's very hard to control
* And also you have to control,manually, space for all joint angles,which is inconvenient, in some cases
* So, our approach is to addseveral motors to each joint, so we get an Actuated Physical Puppet
* So we not only use Puppet as input device,but also the device reacts to the physicalbatch of data to provide active feedback
* And there are couple benefits to it
* First, it's easy to loadexisting pose into the robot, so you can start from existingpose to accelerate posing
* So it's one benefit
* Another is intelligentgravitational compensation
* Here's a little bit explanation
* As I said, if the joint is all free,it's easy to control
* But you know,the it cannot hold it's posture
* So it's inconvenient to And then another approach is alwaysapproach turn off the sabo motors
* Then it can be too stiff
* It can hold existing pose, like this legs
* However as a negative side it veryhard to control, change a pose
* So what we do is, adaptively do it,intelligent gravitational compensation
* So if you do not touch this arm,these legs, its con, fixed by a sabo motor by producinga power against grav, gravity
* However, if the user startto manipulating the joint, the system automatically detects it
* And then automatically turnsoff some sabo motors, so you can push a berry withvery light weight force
* So, that is intelligentgravitational compensation
* And then finally,we also implemented active guidance, using measured human data
* And this consist of joint coupling,and data driven inverse kinematics
* Let me describe a little bit more
* So joint coupling is twojoints work together
* What's easy to understand the exampleis this hip joint, and knee joint
* You know,as you know if you move your leg
* Upwards you if you control hip joint,then knee joint also follows, right
* It's very hard to keep the legsstraight as you rotate the hip joint
* So, if you rotate the hip joint, it's very natural to alsobend the knee joint together
* So, this is joint coupling
* And with actuation you can do it,you know, if you control the hip joint, the systemwill automatically rotate the knee joint
* This is joint coupling, which is very useful to generatevery natural human posture
* So this one automatically avoids,unnatural configuration
* The another is,data driven inverse kinematics
* If you just control position
* For example, suppose you controlthe fingertip, and they go downwards, and if you apply simple inversekinematics result is like this
* So it's mechanical value
* Geometric, geometrically bodied
* Finger tip follows the user control
* However, joint only rotates along the alo,along the arm
* And then, resulting pose is very strange,a unnatural force
* And instead of that, we use data
* We measure up, lots of naturalreaching gesture, over humour
* And the user synthesizeappropriate motion
* So here if the user pull downthe fingertip downwards, and then the character, the robot,automatically puppet moves making a very natural motion,using data
* So, let me show you a video
* So as I said Physical Puppet not onlycontrols a physical body of character, also body of character providesfeedback to the Physical Puppet to guide not to oppose anything
* [INAUDIBLE] To the eight degreesof freedom and connect to the PC
* Yeah so primarily it's an input device
* You control the pulse, and then yousink [INAUDIBLE] up the same pulse
* So this provides a very intuitive way,of controlling character posture
* This can be very tedious,if you use two dimensional mouse
* And one benefit of using sabo motors is, uploading pre defined posturesinto a robot, our puppet
* So, you can get pre-definedpostures in to the puppet
* So this is a very good starting point for design, andthen this is Gravitational Compensation
* You know, if the Torque is OFF to relaxthen it cannot hold a given posture, you know, if you release it goes down
* And on the other hand, if you to,always turn on the torque power, then it can hold the posture,but, very rigid, you know
* You need strong power
* To rotate
* And this is a result ofautomatic gravity compensation
* So as you start pushing
* The system turns off the power
* So, you can change the pose,with very light weight force
* But also,system can hold the posture after release
* And then,this is a result of Data-driven IK
* So, if the Data-driven IK is turned off
* The motion is very unnatural
* It's very robotic motion, because therobot doesn't change entire body shape
* However.If you turn on the inverse driven, Data-driven IK,then the resulting motion is vary natural
* So user control the fingertip, and thensystem automatically bend his legs and then move the head and other arm
* And this is a joint coupling
* The user is controlling the hip joint, and the system automaticallycontrols knee joint, so
* So, let me show you a coupleapplication scenarios
* So, suppose you design in car seat, andthen the visibility should be preserved
* So this, in this way, you can intuitively control the detailmonitoring in the car environment
* And you can check the here,is reachability
* So you can check whether this puppetcan meet specific target in the car
* So this one is load assessment
* So this led indicates where the poweris necessary to hold the posture
* So, this is useful foranalysis of environment
* And this is a Visibility analysis
* So by changing the posture of puppet, we can see which part ofthe environment the puppet can see
* So that's the idea
* So let be briefly describe the algorithm
* Specifically, I will briefly describe howto do Data-driven Inverse-Kinematics
* So as I said,Data-driven I case like this
* If you move a fingertip, then the puppetmakes a very natural human like motion
* In order to do so
* We get data
* But let me first describeInverse-Kinematics in general
* So in that Inverse-Kinematics,is a very fundamental program, in character animation oralso in robotics
* So suppose you have this kind of arc,you have a base here, and then you have joint one,joint two and joint three
* And you have each joint angles
* So, Forward Kinematicsis the standard way
* So, given joint angles,you get the position of the fingertip
* So, this is fairly deterministicsingle computation
* However, what people usually wantto do is to specify target x, y position of fingertip
* And then try to convertappropriate joint angles
* This is very infrequentlyoccurring problem to solve
* And then it looks like this, given x,y, you have gone to joint angles
* This is inverse problem,which is very difficult to solve
* For many solutions, many other And there are couplepossible ways like purely geometric
* So something like, minimize a changefrom the current configuration or physically most you know, physically mostplausible shape, or as a data-driven
* And Data-driven is a method we use
* So, we do some synaptics
* In the motion capture environment,we ask for the person to reach many places around his body, and then we measure allthe postures, to get always position
* So you get many data like this, x, y,z position, and joint angles, x, y, z position, and joint angles
* We get many data of these samples
* And after that user input istarget fingertip location
* And then we are identifythe nearby samples
* And then just blend them together
* And then you'll get,a desired joint angle
* So this is what we do inthe Data-driven Inverse-Kinematics
* So here's the summary
* So we presented, I presented actuatedpuppet device for character posing
* The user controls a virtual character,using physical puppet, and also gets feedback from the system
* And one important feature isintelligent gravity compensation, and active guidance from the system
* And we, I presentthe Data-driven Inverse Kinematics
* So, we take many snapshots, example for this, and then blend themtogether to get natural posture
* So, to learn more,original paper is titles, An Actuated Physical Puppet as an InputDevice for Controlling a Digital Manikin
* And if you want to know more aboutthe previous standard puppet devices, there's two papers
* Dinosaur Input Device
* And those of mice and donkeys, and specialize in the device for[INAUDIBLE] for the animations
* And Inverse Kinematics, as I said,lots of work on these topics
* So example base like is this one
* Artist Directed Inverse Kinematics usingGladiator basis function interpolation
* So this is an example ofa Data-driven Inverse ICAD
* And also there is a geometric approach
* So natural Motion, Animation SoluteConstraining, and Deconstraining at will
* So this one introducesa purely geometric approach, to get natural posturefrom finger tip positions
* That's it for this week
* I guess [INAUDIBLE].


--- SKIP ---: 07_7-4-robotic-light.en.srt


--- SKIP ---: 07_7-4-robotic-light.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_7-4-robotic-light.en_SENTbySENT.txt
* Next topic we discuss is controlof robotic lighting system
* The work we introduce here is titledLighty, A Painting Interface for Room Illumination by Robotic Light Array
* So as a program, we want to addresshere is that it is difficult to control many light, especiallywhen they can change orientations
* So here an example destination, so supposewe have many lights in the ceiling, and the individual lightscan change its orientation
* And this is a very hugecontrol parameter space, and it's very hard to controlappropriate parameters
* And typical userinterfaces look like this
* You have many sliders to changebrightness and orientation, and so on
* And this is not very useful for people to quickly sketchdesired lighting configuration
* So our approach is touse painting interface
* So configuration looks like this
* We have an environment, and we have many robotic lights, and theycan change brightness and orientation
* And we have a camera hereto capture our environment
* And then in this kind of view,there's a paint, desired lighting this up
* So this part should be bright,this should be, this part should be dark
* We just paint desired configuration
* And then the system learnsinverse relation, and then obtain desired parameter setting
* So that's the idea
* Let me show you a video
* So again, this is a system work view
* So you have actuated the light onthe ceiling and the UI in the environment
* And then you would attempt to controlthe light you pick up a tablet and they use these environment andthey paint on it
* So this is a prototypehardware we developed
* We the, we built a miniatureroom with miniature lights and miniature furniture andthis is a array of robotic lights
* So, they can changeorientation individually, and also can change brightness
* So, each light has threedegrees of freedom
* So if we have 12 light,which means 36 yeah, degrees of freedom
* So, here's a painting user interface
* So, given this screen,you're going to pick up a color and paint
* Yeah
* Okay.So here lots of things happening here
* So this view is always a real-timecapture of the camera view
* So you see camera view
* And as I use a paint, user's paint is actually feedbackis given as these quanta lines
* So this area bright,this area is a little bit dark
* And then given this control on userrequest, system continuously learns optimization to get desired parameters,and it's a real-time
* The environment conmoves around the light
* And then up, and you see the resultin real-time in this camera view
* So, there's a lots ofhappening behind the scene
* Yeah, so user paint system searches forthe, the parameter setting interactively
* And then you see the layoutresult immediately
* So, you always see the camera view
* Yeah.So, depending what the user input, system automatically computesthe parameters said and then derives the robotic system
* So, this is more rapid example
* So, if you touch down, and move around,it will actually paint uncommitted
* But, if you hover, you paint it ontop of the surface, you can still see the preview of the painting withoutactually committing the paint
* So this is a mimic of oh,simulation of traditional approach
* So you have 12 lights and then you individually controlbrightness and orientation
* So, and this a typical interface, and it's very tedious control one by one,to get the desired result
* So we compare this interfacewith our painting interface, and if you want to bright somewhere,if you want to illuminate somewhere, it's relatively easy
* You just turn on, you edit right,and then delete it
* However, if you want tomake some part dark, it suddenly turns out to be very difficultusing traditional interface because it involves control of many lights
* You know, you move like sideways,moving away, looking away and turn off
* But there's lots of interruptions behind,between multiple lights, so that's a difficulty
* Okay, so that's the video I think
* So all the benefit of oursystem is that in addition, make specific regions bright,you can also make specific regions dark
* This is kind of negative light
* So you ask a specific region toget darker, and the system do it, and looks like a negative light, andif you, figure it out from our user study, in the painting if the user asked tomake up a upper left corner dark, just paint a region darker andyou get this result
* However, if you use traditionaldirect controller, it takes time and it's very difficult toget this kind of result
* And let me briefly describe the algorithm,behind the scene
* So, this is what's happening
* So, this is the light parameters,so you have many parameters
* Light orientations, brightness and so on
* And then if you derive the light, andif you get this out, then you know, physics will happen andthen you will get this camera view
* And then, after that I use a paint,desired painting result
* So, system compares these two, andthen optimize the parameter setting and then we'll get it
* And in order to run optimization, you needto do this iteratively many times, so instead of using actually drivingphysical lights, we run simulation
* You know, what happens if thisparameter setting is given, and the system simulates the illuminationresult and then compare the result compare it to the user input, and then again lastsimulation and so, so that's the idea
* So the physical processagain is the process, physical process is too complicateto obtain analytic model
* So in order to do this simulation,we use a data-driven prediction method
* So we, so we capture many,many illumination results
* So you have many parameters,like lighting parameters
* So this light and brightness,the second right query orientation
* So you have many parameters and then this,you get many, many camera views
* So you capture many images
* And then based on this data, you predictthe resulting elimination results for a new given parameter set
* And in order to do this,we basically individually control the lighting parameter for individuallight, and then we add them together
* However, important point is naive summation of image datawhere pixel values does not work
* So suppose you have pixel A illuminationrays out here, no, suppose you have a illumination result over A here and thenillumination result over light B here
* But id you are tired of,to doing pixel values, it does not correspond to the result, eliminatedby light A and B simultaneously
* That is because of the non-linearradiation set between radiance
* So, physical physical value ofthe brightness is not directly linear
* Relate, linearly related to the pixelvalue, because there's a non-linearity
* So in order to handle this, you, we first need to convert pixelvalues into a radiance value
* So re-award brightness value
* After converting pixelvalue to radiance value you can accurately predict the summationof two light illumination
* Then after that we can again convert itto the pixel body to get the prediction
* So that's what you need to doto get this kind of system
* So in summary, we, I just shows Roboticlighting system with painting interface
* And I briefly discussed what you needto do, to implement this kind of thing
* So, you need to computea simulation in the radiance space, instead of pixel space,pixel brightness value space
* So the reason a paper waspublished as design and the enhancement of painting interface forroom lights
* And if you want to know moreabout Radiance Computation, one, one good starting point is this paper, recovering high dynamic range,dynamic radiance maps from photographs
* So this paper discuss, hot to computeoriginal radiance values from multiple photographs, over the same scene
* And also our lighting control withpainting interfaces, there are a couple experiments in 3D graphics, and oneexample is this one, lighting with paint
* So user paints desired lighting result,and the system computes, appropriatelighting for the computer graphics
* So what do we do is a realworld version of this one
* So that's it for this week


--- SKIP ---: 09_7-5-fur-display.en.srt


--- SKIP ---: 09_7-5-fur-display.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_7-5-fur-display.en_SENTbySENT.txt
* Last topic of this week is, fur display
* And the work we present here is titled, Graffiti Fur,Turning Your Carpet into Computer Display
* So, in special reason here,if you have a carpet or fur, using your finger you trace a line
* So, this is our inspiration andwe take this
* The phenomenon on the display device
* So let me show you a video
* Oh yeah, here is the inspiration
* You can trace a line in a fur with yourfinger, and you can quickly erase it
* And then we developeda computational devices to do this
* So, what is a Roller Type Device
* So this one consist of lotsof servomotors, moving, driving the rod, to raise the fur
* So, as the roller device roll alongthe surface, then it rotates
* On the Rotary Encoder it takes a rotation,and then moves pins up and down
* So if these rods or pins are down,it raise [INAUDIBLE]
* So as you drag it moves down, up anddown and then leaves a pattern and then you can create a patternusing pixel painting or
* Combines them from your photograph andothers
* And so,in order to paint with multiple nodes, then we provide a mark, tick mark here so you can easily align multipletraces using this tick mark
* And here is an example of drawinga large pattern, on large carpet
* So, the user preparesa bitmap image before hand, and then it's data to likethis handheld device
* So this is an interesting exampleof cooperative fabrication, of cooperative action with human androbot system
* So user is also doing something but also robot also doing somethingtogether with the user
* And another device we developedis the Pen Type Device
* So, this is a continuously rotating wheel
* And this wheel, with rubber,the rubber wheel raises the fur
* And the important thing is that, when you,you are using your finger, you can draw a line in one direction, but you cannotdraw a line in the opposite direction
* So this can be inconvenient, inconvenientif you draw arbitrary illustrations
* But here,the fan tip is always raising the fur
* So this we implemented orientationsensor inside of a pen
* So, regardless of your pen orientation,the system automatically rotates the pen tip sothat it can continuously raises the fur
* So as you see, as the pen is rotating, but the pen tip stays the same orientation,as is
* So, in whichever direction you move,you can always traces line, leaves a line
* Which is difficult with finger
* So you can draw arbitrarilypattern using this pen device
* You can also fix the patternby spraying this way, and then you get more robust shape
* So here's couple of examples,carpet drawing
* Playing along, a message
* Yeah, that's easy
* So let me brieflydescribe what's going on
* Kind of obvious, but So, in the flattenedfur, the lighting comes in and then, reflected by the fur surface
* However, if the strands are raised, then incoming light doesnot be reflected a lot
* So our raised and fattened furs, showdifferent reflectance property, you know
* And in gra, in graphics, this kind ofreflective property is modeled as, the BRDF,a bi-directional Distribution Function
* So it defines the amount of lighting, depending on the incoming light orientdirection, and outgoing light direction
* So this is actual measurementfrom our fur, fur material
* So you see blue dots representingthe data from the flattened surface, and the red dots represent the raised surface
* And if you like,take a look at this example, you know
* The if light is coming from here, and thenif you observe it from this direction, then, if it's a, on the flattened surface,it reflects a lot, so you say this bright
* But in the raised fur,then light go inside over the fur, so you do not reflection,you do not see much reflection
* So, I'll, in the result,these are see bright, bright pattern in the flattened si, region, andyou see dark texture in the raised region
* And then if you, light is,come from tro, front, then not so different viewed in this direction
* But still see a contrast from,viewed from this direction
* Interesting happens here
* So if the light is from this direction,so light is this direction
* So if you view from here the same thing,a flattened surface looks bright
* And a raised surface looks dark
* Up here if you
* Light is coming in from this direction andobserved from the similar direction, then actually raised region looks brighterand the flat region looks darker
* So there is a,a reverse result is observed
* So, this is a example ofa bi-directional Distribution Function, and this is often used in computergraphics to synthesize realistic images
* And if you want to know more, this is agood example document describing the idea
* So to learn more, is original whoone is available as Graffiti Fur, Turning Your Carpet into a ComputerDisplay at SIGGRAPH 2014 e-tech, emerging technologies
* And so this project is a goodexample of cooperative fabrication
* The user does the main action,but the system, robotic system, also works together totake care of the details
* And we got inspirate,inspiration from these two works
* The Y is positioned correcting tools for2D digital fabrication
* The user is moving alongthe cutting device
* And then that system or robotic systemadjusts the actual position of the blades so that you can get detailed shapeusing these hand-held cutting machines
* And they also are otherwise 3Dfreehand digital sculpting
* So the system using hand-held
* A meeting device, andthe user moving along
* But, the position of thisdevice is observed or tracked, and it will automatically turn onand turn off depending on the position
* So the user just randomly movingthe pen tip, but you eventually, you get very precise sculpture
* so, also this graphic Fire Walk isalso related to Physical Displays
* So instead of usingElectronic Standard Displays
* A couple of systems tries to you know, present information usingphysical materials
* And there are many works, butinteresting ones is a wooden Mirror, so there's lots of wooden pieceswith rotating devices, and then it reflects your facein front of the mirror
* And also,we also presented a Shader printer, so this one prints a patternremotely on a closed surface
* And the pattern stays after the printing
* So this is kind of re-writablethe re-writable display on the clothes material
* So that's it and this week wediscuss real world interaction
* So user interface for, with computingsystems that work in the real world
* And we introduce command card interfaces,style by demonstration for teaching interactive rote behavior, andactuated puppet device for controlling character postures, and then roboticlight system with painting interface
* And also fur display sothat is for this week.


--- SKIP ---: 01_concluding-remarks.en.srt


--- SKIP ---: 01_concluding-remarks.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_concluding-remarks.en_SENTbySENT.txt
* So here we briefly, I briefly concludethis course with some remarks
* So in this course I discussedinteractive techniques and systems for visual problem solving
* And interactive,I mean not fully automatic
* So instead of asking systemto do the everything
* Or we try to augment human activity
* So user do something, and then computertries to provide help or assistance
* And also this course wasabout visual problem solving
* And by visual problemsolving [COUGH] we try to
* Assist all the aspects of humanvisual problem solving, which means a comprehension owing input inputinformation and those are conceptions of a new solutions and the communicationwas a new idea to the others
* And we hope that the we presented here canbe helpful to assist these activities
* And just a recap
* So in this course wediscussed these topics
* We first discussed improvementsto graphical user interfaces
* And then we discussed how to make some2D drawings and how to animate them
* And then we discussedhow to create 3D models
* From architectural shapes,or organic shapes and so on
* And then we discuss how to deform it,change shape, and also make animate them along the timeline
* And then we, we move out to,go into the real world and then we discuss how to fabricate3D models as a real object
* And also we discuss how to leveragereal-time physical simulation for assistance, for assisting the design orphysically valid objects
* And then finally we discussinteraction techniques with computing systems workingin the real world
* And I think these are techniques and ideas, presented in this coursecan be applicable to many, many
* Areas are for medicine, sports, engineering,fashion and science and so on
* So I hope you apply what you learned here,to your own programs
* So that's basically it and here I want to address one frequentlyasked questions I got, after I giving
* Similar talks other places
* The question I get mostfrequently is like this
* How do you conceive theseinteresting new original ideas
* Well this is not exactlyrelated to this course topic, but I think this is a good opportunityto address this, discuss this thing
* And the obvious answer is of course,there is no easy answer, you know
* There's no easy solution,you have to work hard
* But still, there's a couple tipsthat I want to discuss here
* So what I want to present here,is three things
* In order to get new ideas, new solutions,you have to do three things
* You have to think hard
* You have to learn a lot,and you have to try a lot, and I think many people say the samething in many different context, but let me describe this in my own words here
* So first, you have to think hard
* As a student, you may have limitedexperience of thinking one program for a long time
* Maybe, thinking a program,ten minutes, one hour, few hours
* However, if we want to reallysolve a problem as a professional, you have to think long time, persistently
* Not one day, not few days, few weeks,even a few months, to solve a problem
* And sometimes, it takes few years orten years, to solve a problem
* And in some,if you think about the problem for long enough, at some point,you may come up with a new solution
* So you have to think hard
* And, you should not just think abse,absently
* You should focus on, on it,and systematically explore
* You have to consider option A, B, C and then within A again youhave sub options, A, B, C
* So you should think about the program,if it doesn't work, if it doesn't work, you have to move to the second prob,second possibilities, and so on, so you should be very systematic,like a playing a game, chess game
* And then, as I said,you should be persistent
* You should be,thinking about a particular problem for long time, but at the same time, youshould be not focused on a single topic
* You should, thinking aboutthe parallel problem simultaneously, then somewhere with the problem,you come up with a solution
* But you, it's very important to doit in parallel for a long time
* So next thing is learning
* You cannot get everything by yourself
* You should learn from others
* So oh, but the problem is thatlearning is easy because so many information is available
* The program is just too many information
* So there,it's very important to be efficient
* So you should not try tounderstand everything
* You should try to get the essence
* Efficiently
* And a good tip is to learn classics andalso recent ones
* And ignore in the middle
* So, any research topic, any topic hasa long history from the beginning, also intermediate experiences in the mid,in the past, and recent one
* And my recommendation is study theoriginal one, because it's very new, and it's very inspiring
* But and also, the recent one
* The recent one is a resultof long research history
* Long exploration
* So it contains the information,obtained in the long long days
* So I recommend you to take outthe beginning, the first one, and also the recent ones
* And also talk to experts
* It's tentative it's tentative, temptive to just learneverything through the Internet
* You can, it seems like you canget from everything from the net
* However, it's more efficient actually andmore productive just to talk to experts
* And then you can learn a lot moredirectly from from them, talking to them
* Meet people
* So finally, just thinking andjust learning is not enough
* You cannot get anything
* You should try
* So do it yourself
* So in computer science, what it meansis you should implement it and test it
* And even if the idea is not so promise, promising, if you implement it,you can get more ideas
* And more information
* So you can learn a lot and you can think,you can get more inspirations
* So yeah
* So this is basically a Rapid Prototyping
* So if you want to produce something new, you should prototype manyvariation systematically
* And you eventually get a,very sophisticated solution
* Okay
* So if you want to learnmore here's a tips
* So as I said,anything is available on the net
* You can get anything
* But you cannot learn everything
* So my recommendation is pick what ismost interesting for you, and master it
* You know, implement it,learn it, think about it
* So instead of trying tounderstand everything, very widely, you should focuson single thing, and then
* Last eight
* And I hope, this course helps youto find interesting topic for you
* Anything like fabrication, or2D graphics, 3D modeling, or maybe the other world interaction
* Something you, catches your heart and I hope help you explore it further,by yourself
* So if you want to know more good resourcesstarting is academic conferences
* So they are the best place to getthe latest most polished result
* So Walk, we introduce, I introduce inthis course are all first appeared as a publication in these conferences
* So if you want to knowwhat's going on recently, you should take a lookat these conferences
* Most resources like papers andvideos are available on the net
* And if you want to learn more,you can go to, to the conference and meet people and have discussion
* And finally I want to say thank youto all collaborators of the works I presented in this course
* So of course, we can,I cannot do everything by myself
* And the result, the project presented inthis course, was a result of hard work, of all these collaborators
* So I would like to,thank you to all of these people
* So, that's the end of this course,and thank you for joining us
* Bye.


--- SKIP ---: 01_introduction.en.srt


--- SKIP ---: 01_introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction.en_SENTbySENT.txt
* [MUSIC] Hello, welcome to this onlinecourse on web connectivity and security in cyber physical systems
* I'll be your lecturerin this online course
* My name is Juha Plosila and I teach embedded systems engineeringat the University of Turku
* Turku is a beautiful city atthe southwest coast of Finland
* A city next to 20,000 islands, and one that 35,000 higher educationstudents call their second home
* [MUSIC] So, lets talk aboutcyber physical systems
* [MUSIC] Cyber physical systems,are embedded devices that interact and control the real world
* You might not notice them,but they are everywhere
* Ever wondered how the stationary escalatorstarts moving when you get near them
* There are sensors that detect movement and a small computer that then controlsthe motors that run the escalators
* In other words,it's a combination of sensors and actuators that control the escalator,a physical entity
* It is a system where computation and control come together to improveefficiency of the real world
* And that is the philosophybehind cyber physical systems
* From controlling traffic to energytransmission to running factories
* Cyber physical systems help improvereal world efficiency and productivity
* Modern cars and airplanes are examplesof cyber physical systems
* Where electronic control units monitor and handle the different aspectsof these physical devices
* But these isolated systems, cyber physicalsystems generally do not work isolated
* Their impact is much higherwhen they are connected
* Take the example of a nationwidenetwork of cyber physical systems managing the electric grid
* Improving efficiency,providing configurability and reactiveness in cases of great failures orexcessive loads
* But what if we could connect our cyberphysical system to another already existing worldwide network
* The World Wide Web or WWW for short, thatis what we will talk about in this course
* Connecting cyber physicalsystems to the World Wide Web
* The course is divided into five modules
* In the first three modules, we'll talk about connectivityin cyber physical systems
* And go all the way to the advancedtopics of cloud and fog computing
* In the last two modules, we will teach you how to securethese systems against cyber threats
* If you want to build your understanding ofthe web, web connected embedded systems or Internet of Things, and their security,but don't know where to begin
* This is the course for you
* We will take you on a journey from thefundamentals of the internet to web and cloud connectivity
* And then towards building yourunderstanding of security in connected systems
* Join me on this journey as Istrengthen your foundations toward web connected cyber physical systems
* [MUSIC]


--- SKIP ---: 01_introduction-to-cps-web-connectivity.en.srt


--- SKIP ---: 01_introduction-to-cps-web-connectivity.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction-to-cps-web-connectivity.en_SENTbySENT.txt
* Welcome to the web connectivity andsecurity course
* In this course we will study different webconnectivity standards, solutions, and protocols
* We will also study the need forsecurity as well as protocols, methodologies and solutions that willhelp you mitigate security risks
* Before talking about web connectivityin cyber-physical systems, the first question that arises is, why then botherconnecting your embedded systems
* If there is a device that controlsthe settings on my microwave oven, what need does it have totalk to other devices
* This is a valid point
* Standalone embedded systems do exist and cater to a specific problem asin the case of a microwave oven
* Another example is an imageprocessor in a digital camera
* Whose purpose is handling the lightcapture from the sensor and to digitize, process, andstore that information as an image
* It performs that specific job anddoes it very well
* The reality is that devicesare getting more and more complex and that connection is needed
* The same digital camera now has wi-fi andGPS modules to offer seamless transfer of photos anda geopack then
* These wi-fi and GPS modules havetheir own baseline processors and for all of them to work seamlessly,you have to bring them together
* You have to connect them
* Any reasonably modern car canhave 25 to 50 onboard processors
* A modern 7-Series BMW hasup to a hundred processors
* All of these control differentfunctions of the car
* For example GPS navigation, entertainment, parking distance control,radar cruise control, and so on
* To make the car really function and provides a safer journey, the processorshave to communicate with each other
* A classic example is that of a car crash
* In case of a crash, your car will openthe door locks and deploy the air bag
* It may perform other emergencyfunctions like flashing the headlights ,and sending your locationcoordinates to an emergency service
* All of this is possiblebecause of the in-car network
* If you think this is too much,NVIDIA announced car computation platform that has a combinedperformance of 8 teraflops
* To put this in perspective,the world's 418th-ranked super computer in 2008 hada computational power of 9.1 teraflops andthat one had 4,096 processor cores
* So, soon your car will havethe same computation or capability as the super computers in 2008
* And here we only discuss theself-contained local networks within cars
* Soon cars will be able to communicatewith other cars on the road and with the traffic monitoring systems
* Thus, the future is connected and connectivity is not optional anymore,it's fundamental
* After establishing the case forconnectivity in cyber-physical or embedded systems, the next question wouldbe why do we need web connectivity
* Here we need to have a deeper look
* Let's first look intothe benefits of web connectivity
* The first andforemost benefit is ubiquity
* The web is everywhere, from your PC,to phones, to even smart watches
* You can access the world wideweb not only on smartphones but also on dumb phones from a decade ago
* All you need is a browser
* A browser like Opera Mini that caneven be bundled into embedded systems
* Scalability is another important point
* The World Wide Web isalready quite large and it can accommodate even moresources of information and users
* Web technologies can automatically scale, based on demand,with minimal user intervention
* They can scale to user needs,computational load, or network requirements
* The World Wide Web has been with us forwell more than two decades now
* That is enough time to test andoptimize the web-enabling technologies, HTML, http, andweb servers are fully understood
* There are highly optimized web serversavailable for small sensors that take less than seven kilobytes of space,which is an efficient use of memory
* One of the main features of webtechnologies is that they don't care about the underlying architecture ortechnologies
* One web-supported device can communicateeffectively with another one, irrespective of the system andcommunication infrastructure used
* Lastly, major future technologieswill reside on the web or heavily utilize the currentinternet technologies
* Let's take cloud computing whereyou are provided with on-demand computational power and services
* You can use these services forbig data analytics and then utilize these data insights forbetter decision-making
* Imagine gathering data fromhundreds of thousands of sensors, then transferring this data to the cloudfor storage and processing, and afterwards relaying this decision backto the nodes or an actuator to activate
* Despite the benefits of web connectivity,it also comes at a cost
* With web connectivity, you get to leveragethe cloud computing infrastructure, remote monitoring and assessment aswell as remote command and control
* However, the very first thing forpeople involved with design and development of connected embeddedsystems is an increase in complexity
* Compared to a stand alone setup,a network connected system requires extra effort In network design andconnectivity solutions, and in hardware and software designto enable that connectivity
* In later videos we'll discussmore on the choices you have when it comes to network connectivity
* Moreover, with web connectivity youinherit its security issues as well
* When you connect your cyber-physicalsystems through the internet, you open then to roughly the samelevel of security weaknesses and attacks as in otherInternet-connected networks
* Security can't be an afterthought anymore
* If you are building a connected system, security should be an inherentfeature right from the beginning
* In case of the car example, you havea network limited to the car's internals
* So, locking the doorwill effectively lock out most thieves from accessingthe computer systems
* But when you connectthat car to the internet, you can't rely on locking the doors only
* You have opened the car to attacksfrom anywhere in the world
* But be assured,we have technologies, protocols, and solutions that will helpmitigate these threats
* And we'll discuss them in later videos
* And lastly web connectivityis resource heavy
* For really small low power devices,memory and computational power are a limited resource, connectivityputs an extra burden on these resources
* Depending upon the connectivity solutions,solutions that you choose, you will have to addthe extra hardware and software layers to communicate and thattakes both memory and processing power
* Some solutions are moreresource hungry than others and we will discuss that further later on
* But nonetheless,connectivity adds an extra cost
* Additionally, if you decide toadd security, which you should, you'll need some sort of cryptographicalgorithm to secure your data
* Cryptographic computationsare processor-intensive, meaning that they put a lotof strain on the processor
* This can drive up the energyconsumption as well
* Let's discuss connectivityin cyber-physical systems in a general context
* Of course, it's nice to have an overviewof your home when you are on vacation or remote start your car in a freezingweather so, it's warm when you get inside
* Or to be able to assess what'swrong in the production plant without physically being there
* But, you will come across situationswhere you won't need web connectivity
* For our very daily life for example, do you really need to connect yourstand-alone coffee machine to your wi-fi
* Of course you might think,it's just a coffee machine
* What can go wrong ifhackers get access to it
* Over boil my coffee togive it a bitter taste
* The thing is that through your coffeemachine if its security is weak, hackers will get accessto your network and from there they can go to your system oranywhere
* In this case, the coffee machineis not the target itself but, another attack vector against your system
* So, yes, there are benefits to webconnectivity and there are the downsides
* What you will need to do is assess whetheryou really need web connectivity or not
* Once you decide on the former,you'll need a proper implementation
* That is where this course will help you
* By the end, you'll be moreinformed about the protocols and solutions available to you
* And you will be able to make informeddecisions when it comes to adding connectivity to your embedded solutions
* [MUSIC]


--- SKIP ---: 02_introduction-to-web-connectivity.en.srt


--- SKIP ---: 02_introduction-to-web-connectivity.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_introduction-to-web-connectivity.en_SENTbySENT.txt
* [SOUND] Welcome back to the videolectures on web connectivity and security in cyber-physical systems
* In this lecture, we'll go throughthe basics of the internet and web connectivity, including somebackground information on the internet and the nuts and bolts of its operation,especially the Internet protocol suite
* The basic communicationprotocol of the Internet and its layer design will be discussed
* Let's start with the Internet
* A group of connectedcomputers is a network
* A group of connected networks froma very large scale became the internet
* One way of understanding newtechnology is to look into its origins, why was it developed
* This is a technique we'llalso use in later videos when we learn different protocols
* So to understand why there is a hugenetwork of connected computers, let's look at its history
* The internet came out ofthe desire to have a robust, fault-tolerant network of computers
* There are two key takeaways here
* First, the network had to be robust and full tolerant, and second,it was for computers
* We see both in the modern internet
* We have a pocket base network whereeach pocket can take a different route to the destination
* And the effect of being designed forcomputers is that it's essentially not what we wouldcall lightweight and power efficient
* Take for example ethernet, designed for computers at a time whenpower was not a requirement
* It is one of the most power hungryconnectivity technologies for cyber-physical systems out of the onesthat we will discuss in this course
* We have been moving froman internet of connected computers to an internet of connected devices orthings
* This requires new technologies or changes to the current ones to suitthe needs of the new breed of systems
* The Internet is the network of computers,but what actually carries informationon top of this network
* One of the ways to carry anddisplay information over this network, and here we mean Internet,is the World Wide Web
* The World Wide Web is a way to organizeand present information for people
* This is a common distinction thatmany of us generally get wrong
* Internet connectivity means becominga part of this large worldwide network
* Web connectivity, on the other hand,means leveraging the web technologies to now shareinformation over this network
* At the heart of these webtechnologies are hypertext, the Hypertext Transfer Protocol orHTTP, a web server, and a browser
* We need internet connectivity for these web technologies to work, andtherefore, we will talk about both
* The technologies that enable us to connectour cyber-physical systems to the Internet and the technologies that enable usto access and share over the web
* Here is a short overview of the web andthe Internet
* The Internet enables the existenceof the World Wide Web
* The World Wide Web facilitates interactionand information sharing over the Internet
* If the Internet is a highway,the web is the moving cars
* Let's continue a bit with the analogyof the Internet being a highway and the web being the moving cars
* There can be more than just onetype of cars moving the highway
* For example, there can be buses,trucks, vans, and motor bikes
* Likewise, there is more than justweb traffic on the Internet
* There is e-mail, Usenet, File transferprotocol, peer-to-peer sharing, and so on
* But what enables all of theseto share the same network
* The technology that enables differenttypes of traffic to share and go through the same network is TCP/IP or Transmission ControlProtocol/Internet Protocol, or commonly known asthe Internet Protocol Suite
* A protocol is a set of rules and methods
* You can think of it asthe grammar of a spoken language
* These rules and methods facilitates a standard wayof communicating and interacting
* The TCP/IP protocol suite istherefore a set of standards and methods that allow different devices andsystems to communicate over the Internet
* Because of the standard, it doesn'tmatter what system, operating system, or application you have
* As long as it can say,speak TCP/IP language, it can communicate withothers on the internet
* TCP/IP is divided into layers forsimplicity and understanding
* As there are multiple technologies thatmake up TCP/IP, the classification into layers makes it easy tocomprehend this inherent diversity
* It also enables the decouplingof one technology from another
* Imagine having a wine glass witha detachable base and body
* You could change the base dependingon the surface you'll be using
* If you need grip, you would use rigid basewhile the body would remain the same
* And if you want to tastedifferent kinds of wine, you just change the body on the top
* In the same way with TCP/IP layersas you go from the top to bottom, you can decide which technologyto use from each of the layers, the technology that best suits your needs
* And if you develop your own technology, you can place it in the appropriatelayers for others to use
* There are four layers in the TCP/IP model, application, transport,internet, and link
* We will discuss them next
* Here is an overview of each ofthese layers and their functions
* We will discuss the protocolson each of these layers, and their specifications in detail later on
* The top-most layer isthe application layer
* If you are designinga protocol that allows different applications to communicate,it will be placed on this layer
* We are not talking about the specificapplication software but the methods thatthe application software will use to communicate with anotherapplication software over the network
* An example is one chat client sendinga message to another chat client
* If both these clients usethe chatting protocol at XMPP, it doesn't matter who designed the chatclient or what platform it is running on
* They will be able to send andreceive messages
* Here, the applicationlayer protocol is XMPP
* The layer beneath the applicationlayer is the transport layer
* Its purpose is to establish host-to-hostcommunication from one device to another
* It receives data from the applicationlayer, it doesn't care what this data is, and transmits the data to anotherprocess on another host computer
* Imagine you have three browsers,Chrome, Firefox, and Internet Explorer
* And on the first one you entered Google, on the second one you entered Yahoo,and Bing on the third one
* In this case, you send three HTTP requestsfrom three separate applications
* HTTP is an application layer protocol
* The responses for these requests are appropriatelyprovided to each application
* Chrome gets the Google page,Firefox gets the Yahoo page, and Internet Explorer gets the Bing page
* Now, all of them send similar requests,but the data didn't get mixed up
* Why
* The transport layer, which providesthe data to the application layer, is responsible for ensuring that eachprocess receives what was intended for it
* Moreover, this layer is responsible for reliability, congestion control,and multiplexing
* At the internet layer, which isthe next lower layer, the source and destination addresses are attached topackets coming from the higher layers
* This layer is responsible foraddressing and routing
* Also, when a packet is received,it is the internet layer's responsibility to forward it tothe appropriate transport layer protocol
* The link layer at the bottom of theprotocol stack specifies the standards and methods that handle the physical link
* These protocols reside on the local link, meaning that they are limited tothe scope of the local network
* For example, ARP, oraddress resolution protocol, is used to figure out the physical address,that is the media access control or MAC address against an Internetprotocol or IP address
* This is how your computer knowswhich local device an IP packet should be forwarded to
* A distinction to make here is that youneed a MAC address to send data in a local network and an IP addressto send data across networks
* Sending data across networks isan internet layer operation, and sending data within localnetwork is a blink layer operation
* The TCP/IP link layerdoesn't assume anything about the type of the physical medium andits issues
* It just assumes that an underlyingphysical link exists
* Therefore, the link layer representsany media access protocol, including wireless protocols suchas Wi-Fi, GSM, and bluetooth
* Here are some example protocols foreach layer
* As a recap, in this lesson, we lookedat the internet, the World Wide Web, and the basics of the TCP/IP model
* In later videos, we will have a moredetailed look at the different layers and their respective protocols
* [MUSIC]


--- SKIP ---: 01_application-layer-protocols.en.srt


--- SKIP ---: 01_application-layer-protocols.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_application-layer-protocols.en_SENTbySENT.txt
* [MUSIC] Welcome to the lesson onApplication Layer Protocols which is part of the web connectivitysegment of the course
* In the previous video lecture Ihave explained the basic function of the application layer, which isthe top layer in the TCP/IP model
* In this lesson, we will look into thebasics of application layer protocols and go through some of the protocolsthat enable the World Wide Web
* Let's start with understandingNetwork Applications
* First and foremost, not all applicationsthat you use have to be networked
* This was very true previously, butis gradually becoming uncommon
* Applications that don't requiredata exchange over the network and can work on their own are calledstand-alone applications
* For example, many video and image editors, word processors andCAP tools are such applications
* Currently also these applicationsare becoming connected, as there are, for example, photo editing applications that allowyou to share images over the Internet
* Soon we will probably haveno standalone applications, except in critical security systems andreal time systems
* Networked applications,unlike standalone applications, need to connect to otherapplications over the network
* There are some applicationsthat are inherently networked, such as e-mail, web browser andFTP tools for file transfer
* On the other hand, there are applications that we havemade connected because of their utility
* A good example is a wordprocessor which lets you collaborate with other authors around theglobe simultaneously on a shared document
* In order to communicate over the network, these applications need to follow certainrules so that there is consistency
* The combinations of rules andsuggestions are called protocols
* They can be different aspectsof these protocols, but some of the basic aspects thatevery application layer protocol should provide, include the typeof data or payload format
* That can be exchangeby these protocols and the way it should be formatted andpackaged
* The last thing you want in networkcommunications is that the applications don't understand each other's messages
* There can be different types ofmessages that are exchanged
* With a request message,an application asks for some data
* With a response message,an application provides some data
* With a control message,an application commands and controls a remote application
* These are just the three basic types
* They can be more as we will see later
* After defining the message type,the protocol should define the fields within the message,including their position and meaning
* The last important thing is to definecontrol and communication rules and regulations, addressing questionssuch as when and how can applications send messages, what happenswhen a response is received or is not received at all, orwhen an undesired response is received
* And how to react todifferent control messages
* The more such rules are specified, the more compatible two differentimplementations of the protocol will be
* But it will also increasethe complexity of the protocol
* To understand the applicationlayer protocols, we will take the technologies thatenable our web experience as an example
* The web is the most dominant way forhumans to exchange and consume information andmedia over the Internet
* The key technologies that enable thisexchange of information are the following
* HTML orthe Hypertext Markup Language that defines how the content orwebpages should be formatted
* A web browser, the applicationthat reads the HTML files and presents them in a humanunderstandable formats
* A URI or Uniform Resource Identifier, is a way to address pages andinformation on the web
* This is how you and the web browser know where to go tofind the next piece of information
* For example, www.google.com is a URI which tells you want to go for a Google search
* Finally, HTTP,the hypertext transfer protocol
* You have a browser that willaccess the information and URI, the location fromwhere to access it and HTML is the format of the information
* Now the question is how will the browsersend a request and receive the HTML pages
* That is where HTTP comes in
* It's the protocol via whichapplications communicate
* Is not the only one, butis the one you encounter the most
* Out of these technologies,the one that concerns us the most is HTTP
* So let's look at it in the light ofthe characteristics we defined for application layer protocols previously,namely payload formats, message types, message syntax and rules
* HTTP is the protocol via which your browser sends a request toremote server over the Internet
* It is inherently a stateless protocol, meaning that it keeps no informationabout the state of the connection
* Each subsequent request issent via a new TCP connection
* There is an HTTP propertycalled keep alive, which tells the server to keep theconnection open for subsequent requests
* As we are dealing with embeddedsystems that have limited memory and might not need tocommunicate that frequently, it is recommended to disablekeep-alive to save up memory
* A simple HTTP request has three sections
* First, method, which defines whattype of message you are sending, or for the sake of simplicity what type ofcommand you want the server to execute
* Second, URI at rest of the remote server, and third the protocol version
* There can be anothersection called headers, which gives extra informationabout the command
* Here's an example request foraccessing google.com
* Let's go through the response message
* 200 is a status code meaning okay, or that the command executed properly
* The content type headershows the type of data and the format in which the serverwill send the data
* In our case,it's a text file formatted using HTML and UTF-8 is the text encoding
* There is also information about the typeof the server that was running and the date, time and so on
* Let's look at another example
* This time we send another command tothe Google server, a POST command
* POST means that you want the server toaccept the data you are sending to it
* We see that the response code is now 405
* Meaning that you are notallowed to execute that specific command on the server
* The server sends you the list ofallowed commands as a response
* These examples demonstratedthe characteristics an application protocol should have
* Different message types,formatting options and control mechanisms that determinewhat happens when a desired or undesired request or action happens
* HTTP is a very mature protocol andhas response and control messages fora wide variety of situations
* The web is not composedof just text files
* There are other types of content as well
* For example, images
* HTTP supports transportinga different types of medium such as text,images, audio and video
* The receiving end or the client side should be able todisplay and process this data
* The content type header tells the clientwhat type of data was sent to it
* Depending upon your browser andtarget system, you are either able or unable to play the received contents
* Here are some of the common audio and video format supported across systems andbrowsers
* For audio, MP3 andAAC license dependent and therefore not supported bybrowsers like Opera and Firefox
* But if your operating systemhas the proper codex installed, Opera and Firefox will play these formats
* Ogg Vorbis on the other handis an open standard format and is supported by Firefox andOpera but not by Internet Explorer
* The WAV format is supportedby all modern browsers
* For video,H.264 is supported by all major browsers
* And there are hardwaredecoders available for it too
* It also offers good compression, butit might not be royalty free and requires a license
* Among free video codecs, VP8 and Theora are the formatssupported by the major browsers except for Internet Explorer
* There are different protocols thatallow you to stream media instead of merely downloading them in chunks
* Progressive downloads, meaningdownloading files in small chunks and streaming technically work the same way
* A large file is cut into small pieces andthen transferred
* However, when progressivelydownloading a video file, you might have to wait for the wholefile to download before you can play it
* Or you can play it right away but you can move forward past the portionthat has been already downloaded
* You need streaming protocols toachieve fast forward, rewind, and play, pause features
* The benefit of streamingmedia via HTTP is that the traffic goes through a portwhich is rarely blocked
* It is also an affordable solution asthe infrastructure is already available
* And HTTP streaming solutions can scaleaccording to the user's network
* That is, the bit rate can be increased or decreased based on the user'snetwork conditions
* A few examples of HTTP videostreaming protocols are HLS by Apple, MPEG-DASH developed under MPEG
* It has been an internationalstandard since 2012
* And then there isMicrosoft Smooth Streaming, supported by IIS, Microsoft's web server
* So as a short review, in thislecture we looked at some specifics of application layer protocols andused HTTP as an example
* Then we discussed briefly the typesof the web and streaming media
* In later lectures we will look intothe protocols that make the web and video audio stream possible
* More specifically, we will look attransport protocols like TCP and UDP
* [MUSIC]


--- SKIP ---: 02_transport-layer-protocols.en.srt


--- SKIP ---: 02_transport-layer-protocols.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_transport-layer-protocols.en_SENTbySENT.txt
* [MUSIC] Welcome to the lesson onTransport Layer Protocol
* Previously, we have looked atApplication Layer Protocols or protocols designed to help programs andservices understand each other
* In this lesson,we will look at transport layer protocols which take date fromapplication layer services and make sure they reach the service orprocess the destination end
* One thing that most of usare familiar with is an IP address
* An IP address is associatedwith a machine or host and it's a way to make your datareach that specific host
* They can be multiple processes runningon that machine, such as Outlook mail, Firefox browser, FTP server,Secure Shell, and Remote Desktop
* Now, the host got the data buthow do you make sure that each process receives the datathat was intended for it
* This is where transportlayer protocols come in
* They receive informationfrom lower layers and pass it up to the right userapplication or service
* In this way, you can have multipleservices and applications running on your machine, although you have only oneIP address and network interface
* Transport layer protocols doa lot more than just that
* They establish and manage theseconnections between processes, they divide the data from userapplications into chunks so that they are easier to transport
* Transport layer protocols canalso offer congestion control, they analyze the network andadjust the throughput
* Moreover, they can offer errorcorrection to detect and correct errors that occurredduring data transmission
* Some can also offer otherservices like reliability
* Making sure that allthe data is transferred and received in the orderit was initially sent
* Transport layer protocols do not dictatehow a packet is sent over the network
* They simply hand off data tothe lower Internet layer, and pick up data from the Internet layer
* In essence, they operate on the end nodes,not on the network itself
* And are therefore alsocalled end to end protocols
* So a short round up of these services thata transport layer protocol can provide
* They can establish, manage,and terminate the connections
* Handle the flow of data in casethe receiving end is slower or has smaller buffers
* Make sure all the packets are sent andare arrow free and avoid too much traffic on the network
* We will now look into two ofthe main transport layer protocols, mainly TCP and UDP
* Transmission Control Protocol isa connection oriented transport layer protocol
* In the Internet protocol suite TCP/IP,this is where the acronym TCP comes from,it's a fairly complex protocol
* Especially compared toits counterpart UDP, simply because of the multipleservices it provides
* Some of the distinctivefeatures of TCP are, TCP offers the ability to receiveexactly the same numbers of packets as will send andin the same order
* All TCP packets are thereforenumbered making it easier for the end system to re-group them in order
* For reliability TCP uses acknowledgements, each transmission isacknowledged by the receiver
* If the packet is not acknowledged ina certain time frame, it is retransmitted
* The receiver can also inform the sender ofthe specific packets it has not received
* TCP delays can sometimes be very high forthe upper layer application
* As TCP waits forall the data to be received, puts the data in order andthen forwards it to the upper layer
* Reliability is the reason why someapplication layer protocols do not offer their own reliable communicationstructures but rely on TCP instead
* TCP offers bidirectional communication,both parties can send and receive packets andthey can do it simultaneously
* TCP offers flow control,if the receiver buffers are small, TCP can reduce the rate of transmission inorder to avoid overflowing the end system
* If the receiver buffers are full,the receiver will start dropping packets, meaning the sender will notget any acknowledgements
* This lack of acknowledgmentsacts as an indicator for the sender to either slow down or stop
* Network congestion is the reductionof throughput because of too much traffic on the network
* TCP offers a mechanism called slow start,it starts transmitting lower number of packets and graduallyincreases until congestion occurs
* An indication of congestion isthe lack of acknowledgements
* That means either the senderhas reached the network's transmit capacity orthe receiver can't handle anymore packets
* In both cases it scales back, this is a method to prevent the hostfrom causing immediate congestion
* Finally, it's up to TCP how itorganizes and sends the data
* TCP sends data in streams of bytes
* It takes data from the application layer, let's say 1000 bytes,chops it into pieces
* For example, ten pieces of 100 bytes, and sends the pieces down to the network orInternet layer for transmission
* On the other hand it can take data inmultiple bytes from the application layer
* For example, ten pieces,each of 20 bytes, and send them as 100, 200 bytes packet
* TCP is slow due to itsreliability controls
* Another reason for TCP being slowis the three-way handshake it uses, the initiator sends a synchronized packet
* The receiver,upon reception of the synchronized packet, sends a synchronized acknowledge packet
* And lastly, the connection initiatorsends an acknowledge packet
* This is why we call TCPa connection oriented protocol, it first establishes a proper connection
* When we want to close a connection, then there is even morecomprehensive four way handshake
* Transport Layer Security, orTLS, is another transport layer protocol that securescommunication between two parties
* It's not a part of TCP but it relies on TCP,which is why we are mentioning it here
* This protocol will be discussed later on
* TCP is a reliable means ofcommunication and therefore, it can be used in any situationwhere a sure delivery is required
* This assured deliverycomes at the cost of time
* TCP is slow and delays can be very long asit will wait to reorder all the packets
* That's why it might not be the best optionfor very time dependent applications
* HTTP doesn't offer any built-inreliability mechanisms but, as it runs on top of TCP,TCP handles that for it
* The file transfer protocol, FTP, and the chatting protocol, XMPP, also use TCP
* XMPP is a chat protocol, soif you send a good night message or message with some expressionof love to someone via XMPP
* You don't want your message to getlost and never reach its destination
* TCP ensures that the receivergets your emotions, well maybe a little late,but she or he will get it
* TCP can handle that networks orcongestions
* In unreliable network situationsits better to use TCP
* Netflix uses TCP to senda movie to your device
* But you might say thatmovies are real time and TCP is slow, I don't want stuttering
* Well, avoiding that stutteringis the reason Netflix uses TCP
* First TCP's congestioncontrol mechanisms will probe the network and use all the availablebandwidth between you and Netflix
* Secondly, TCP uses buffers totemporarily store the received data
* And therefore, the local applicationcan prefetch data from Netflix servers
* Well, this was TCP,now we will look at UDP
* User Datagram Protocol orUDP is another transport layer protocol
* Unlike TCP,it doesn't offer congestion control, it's not reliable andit doesn't send data in packet streams
* It also doesn't assure in-order deliveryor care if you receive duplicates
* Also, there is no threeway handshake which is so far the only good thingwe have said about UDP
* So why does it exist andwhy would anyone use it
* First of all, because of all the thingsit doesn't do, it's very simple
* This makes it light andas it doesn't care about connections or handshakes, it's fast
* It is stateless, meaning it doesn'tmaintain session or connection state
* Each request is treated asa separate unique entity
* This also makes it suitable forsimple request response queries
* TCP sends numbered packet streams andthen reassembles them at the other end
* UDP treats each packet asan individual complete message
* It sends one complete message and receives one complete messagewith every sent receive request
* To show you the differencebetween the TCP and UDP formats, this is a 20-byte TCP header
* And this is an 8-byte UDP header
* This shows the relative size differencesbetween the two and the simplicity of UDP
* UDP has its own use cases,it is used for real time streaming, where timing is more importantthan in order delivery
* And where reliability is notthat important because one or two lost frames do not affectthe end user experience
* Therefore, UDP is suitable fortime sensitive applications such as Voice Over IP andmultiplayer online games
* The smaller header size of UDP compared to TCP makes UDP suitable forbandwidth constraint environments
* Also, it has a lower processingoverhead which is beneficial for very small low power devices
* Being connectionless, UDP's good for broadcasting as well,especially IPTV or streaming
* The server doesn't have tomaintain a separate state, and session information for each connection
* As it treats each message asan independent entity, UDP is generally good forsimple request response style operations
* Some protocols that employ and benefitfrom UDP are Domain Name Service, DNS
* Dynamic Host Configuration Protocol,DHCP, and Network Time Protocol, NTP
* In each of these, you send a query andreceive a response
* One message is sent,one message is received
* And there is DTLS orDatagram Transport Layer Security
* It is not part of UDP butit's used in conjunction with UDP
* This security of protocolwill be discussed later on
* In this lesson, we discussed the basicfunctionalities of the transport layer
* We also looked at the transportlayers protocols, TCP and UDP
* In another lesson,we will look into the Internet layer and see how data is moved fromthe host over the network
* So far, we have been dealing with datathat is still on the local machine
* [SOUND]


--- SKIP ---: 03_internet-link-layer-protocols.en.srt


--- SKIP ---: 03_internet-link-layer-protocols.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_internet-link-layer-protocols.en_SENTbySENT.txt
* [MUSIC] Welcome to the final lesson onthe basics of TCP IP suite
* So far we have looked into protocols thathelp applications understand each other and protocols that help applicationsbuild a communication link
* Tn this video lecture,we will look at the TCP IP layers and protocols that helps devices ormachines connect and exchange package
* We will look at how you get the datathat applications have generated and take it out of the local machine and carryit over the network to another device
* This is where the Internet, ornetwork layer and link layer come in
* First, the Internet layer
* This layer is responsible foraddressing, routing, error handling, and of course, managingdata flow to the layer beneath it
* The IP part in TCP/IP means the InternetProtocol which operates on this layer
* We will look in tothe Internet Protocol and see how it offers the functions thatthe internet layer is supposed to provide
* So, IP stands for the Internet Protocol
* And it's the protocol thateveryone in the TCP IP suite relies on to transmit datapackets over the network
* No matter what transport layerprotocol you use, whether TCP or UDP The data eventually is handled by IP
* Like UDP,it is a connection-less protocol meaning each data packet is considered unique andthere is no context maintained
* Sending the current packet has norelation to the previous or next packet
* It's not a reliable transport mechanism
* There is no guarantee that the packetwill be successfully delivered
* As there is no link establishmentin advance and no assured delivery, the packet can take any path overthe network to reach a destination
* This helps against link failures
* If a router or a physical link goes down, the back end just takesan alternative path
* The Internet Protocol isavailable in two versions
* IPV version 4 or IPv4
* And IP version 6 or IPv6
* Both offer the same service, butin a slightly different way
* The very basic differencebetween them is addressing
* We will look into this later on
* IP is also responsible for routing,meaning finding a path for a packet to move around the networksuntil it reaches the destination
* If the receiving node is on the samenetwork, the packet is delivered directly
* This is called local delivery
* If the receiver is on another network, then the protocol delivers the messageto a device called a router
* If the receiver is connected tothe router the message is passed to it
* Otherwise, it is sent to the nextrouter and then to the next and so on
* A jump from one router toanother is called a hop
* It is theorized that you can reachanywhere on the internet with a maximum of 64 hops, and reach more than99% of the internet using 32 hops
* Some protocols might havetheir own limitations
* For example, the routing informationprotocol, or RIP, has a limit of 15 hops
* Other routing protocols are, for example, open shortest path first, or OSPF andBorder Gateway Protocol or BGP
* The Internet Control Message Protocol,or ICMP, is used for reporting errors inthe delivery of IP packets
* It is part of the IP Suite
* Think of it running in parallelwith the normal IP functions
* Imagine running two networkcables between the nodes A and B, the first one carries data from A to B
* The second one carriesan error message from B to A
* Only if the path between A andB is blocked or unreachable
* In this example, the network cable betweenA and B represents standard IP packets and the network cable between B andA carrying error messages represents ICMP
* Whenever an IP packet can't be delivered,the router on that point generates an ICMP packet,and forwards it to the sender
* IP doesn't act on the error message, butsends it to the transport layer protocol, TCP or UDP
* And they can then decide whether toretransmit the lost data or not
* Another important protocolof the IP suite is IPSec
* IP Security is a set of protocols forsecuring communication between devices
* Unlike, TOS and DTLS mentioned earlier,this one operates in the internet layer
* It will be discussed furtherlater on in the course
* A little bit about the IP version 4
* This is the most common versionof the internet protocol
* The one you will most likely encounter
* It has a 32 bit address space and can have 4.29 billion unique addresses
* IPv4 address space is dividedinto different portions, each portion is reserved fora special purpose
* Have you ever wondered why the defaultIP address of every broadband router that you buy is 1.92.168.01
* That's because the range is reserved forprivate use
* To build your own home network forexample
* IPv4 addresses have a dotteddecimal notation and example at risk is shown here
* IPv version 6 is the new versionof the internet protocol suite
* The basic attributes andfunctionalities are the same as in IPv4
* But IPv6 has a 128 bit address space instead of 32,and twice the header size
* It's designed to replace IPv4
* One particular problem with IPv4is that there are more devices connected to the Internet then there areavailable at vertices that you can assign
* With IPv4, that unit is 4.29 billion
* With IPv6, it is, well, try to countthe number of zeros on the screen
* With more and more smart devicesconnected to the Internet, reaching 50 billion by 2020according to estimations
* You need a large address pool
* IPv6 provides youthe needed address space
* Here's an example of an IPv6 address
* Clearly it's not readable for human eyesin the same way as the IPv4 address
* Here you see the differencebetween the IPv4 and IPv6 headers
* The large address field of the IPv6header is instantly noticeable
* On the other hand the overall structureof the IPv6 header is simpler
* In the IPv4 header,the fields with great text, the IPv4 attributes thatwere not carried to IPv6
* Remember, IPv6 isdesigned to replace IPv4
* They are not interoperable
* This ends our discussionon the internet layer
* Now, we will have a quick layer ofthe TCP-IP model, the link layer
* So far, we have seen how data movesacross programs and networks
* And now, we will look into how it goesfrom one local network point to another
* The link layer is the lowestlayer in the TCPIP model
* It's responsible fortransmitting information from one point in the local network toanother point in the same network
* So, in theory,with the presence of this layer, you would be able to createa local area network
* Or be able to communicate locally even ifyou don't implement the internet layer
* The link layer acts as an interfacebetween the lower physical hardware implementation of the network andthe upper, more logical, software-focused implementationof the network
* The link layer has several functions
* First, it provides local addressing
* Let's look at ethernet, a system of connecting computersin a local area network
* Each ethernet adapter has a specific, unique address assigned bythe manufacturer called a MAC Address
* A MAC Address is how a network adapterknows who is who on the network
* The difference between a MAC address andan IP address is that MAC address are used foridentifying devices on the local network
* And IP address are used to identifydevices across networks even globally
* You can change your IPaddress several times but still the data packet intended foryour device reaches you, how
* Well, that's because of the MAC address
* A link layer protocol called ARP oraddress resolution protocol, has the job of identifying which IPaddress corresponds to which MAC address
* So when you change your IP address,ARP updates the local table and puts the new addressagainst your MAC address
* The link layer also provideslocal error detection of errors that could have been causedby noise on the network channels
* The most common method is addingcyclic redundancy check or CRC Codes
* When you take the data fromthe upper layers add the local MAC addresses of the destinationon yours add CRC codes for error detection and any other fieldsrequired by the local lead protocol
* This new packet of data is called a frame
* Frames are what you then sendover the physical medium
* Now, concerning the physical medium, there needs to be a way to handlecommunication on the local network
* To decide who has the right to usethe network cable for instance
* Who can talk and for how long
* And to assure there are nocollisions of signals
* All of this is called mediaaccess control, or MAC
* Yes, this is where the nameMAC at risk comes from
* Media Access Control includesdifferent methods to ensure successful communication, but these methodsare out of the scope of this lesson
* The actual transmission of the databits over the network takes place in the form of signals
* Electrical signals inthe case of ethernet and electromagnetic signalsin the case of WiFi
* This is not actually regulated ordescribed in the TCP/IP model
* The TCP/IP model doesn't careabout the physical characteristics of the network technology
* This however does presentan interesting problem
* What about standards like WiFi thatdefine both a physical layer and media access control
* Where would you put WiFiin the TCPIP model
* Well As already stated inanother video lecture, for the sake of simplicity we will putall the machine to machine, or M to M connectivity protocols like WiFi,Bluetooth, and ZigBee under the umbrellaof the link layer
* Here is an overview of whatwe studied in this module
* To your left is the TCP/IP Layered model,and to the right are some of the associatedprotocols at rest in the lectures
* I hope you have now a better understandingof all these layers and an idea of what the basic properties of a protocolare when it belongs to a specific layer
* In the next module, we will havea closer look at the protocols that we sign on the application and link layers
* [MUSIC]


--- SKIP ---: 01_m2m-connectivity-protocols.en.srt


--- SKIP ---: 01_m2m-connectivity-protocols.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_m2m-connectivity-protocols.en_SENTbySENT.txt
* [SOUND] Hello, welcome back tothe course on web connectivity and security in cyber-physical systems
* This lesson starts a module on linklayer connectivity protocols and application layer communication protocols
* In this video lecture, we'll talk aboutconnectivity solutions available for embedded systems
* In other words,we will focus on machine to machine or M2M connectivity protocols andtheir basic characteristics
* Machine to machine connectivityprotocols facilitate the establishment of a connection between two ormore devices
* Here we will be discussing the protocolsthat reside on the link layer of the TCP, IP model
* They establish a pathbetween two end points
* For our cyber-physical system case,the connectivity solutions can broadly be divided into two maincategories, wired and wireless
* Wired connection are the one's thatrequire a physical connection between endpoints
* While in wireless connections,we don't have any physical medium
* As we will see this classificationaffects the abilities of the protocols in many ways
* For example range, date rate,and power consumption
* Wired connections generally tendto have higher date rates and higher power consumption butthis is not always the case
* There are certain parametersthat help us defining and distinguishing connectivity protocols
* Mainly range, data rate,power consumption, topology, TCP/IP support, spectrum, estimated node support, approximate cost
* Well, each of these will bediscussed in this lecture
* The range defines how far away or to what distance the protocolcan offer connectivity
* Based on this definition of range,we divide the protocols broadly into four logical categories,PAN, LAN, MAN, and WAN
* PAN or personal area networkinterconnects devices within the personalspace of an individual
* The range is typically fromten centimeters to ten meters
* LAN or local area networkinterconnects devices within a limited area such as a home, office, or building
* It ranges typically from tenmeters to some hundreds of meters
* MAN or a metropolitan area networkinterconnects devices within a city or district covering several buildings,a large university network and a citywidemunicipal network are good examples
* The range is typically from 500meters to some tens of kilometers
* WAN, or wide area network, generally has no geographicalrestrictions on its location or size
* The WAN enables different LANsto connect to each other
* Although the distanceis not a limit as such, a WAN can be restricted toa specific country for example
* The data rate defines how muchdata per second you can transfer
* Or how much data the protocol cantheoretically transfer per second
* In wireless networks, the theoretical maximum is generallyquite different from actual results
* For cyber-physical systems, we divide the data rates into low,high and very high categories
* Low data rates transfer upto one megabits per second
* High data rates more than oneto two megabits per second
* And very high data rates morethan 50 megabits per second
* This classification doesn't applywhen thinking in terms of typical human usage of networks
* Remember that two megabits per second ofsustained throughput is pretty high for most embedded systems,because your smart energy meter or smart lighting system, like Philips Hue,doesn't watch Netflix
* Data transfers are typically periodicupdates which do not require high data rates
* Power consumptions gives youan idea about battery life and a data throughput of yourinterconnection protocol
* Generally, the lower the powerconsumption, the lower the data rate
* Higher rates mean the device is on forlonger periods of time and has to process more and faster,thereby increasing power consumption
* Here we divide power consumption intotwo categories, idle and active
* Idle power consumption is the power usedwhen the devices is in the state of rest
* Meaning, no communication is taking place
* Idle power is a significant factor,for example, in sensor networks
* Where sensors are mostlyidle communication wise
* Active power consumptionis the power used when a device is in the fullcommunication mode
* This will give youthe battery life of your node when the node is underfull communication load
* Another consideration is whetherthe connectivity protocol and modules offer different power profiles
* Such as idle state enabling profile,low data rate profile, receive only profile, andtransmit only profile
* Each of these save batterypower in its own way
* The topology refers to the interconnectionbetween different nodes in the network
* There are different ways a protocol mightallow devices to connect to each other
* The most common ordominant ones are the following
* In a bus topology there'sa central line or bus and each device is connected to that line
* So logically each device is directlyconnected to the other devices
* In a star topology we havea central node or server and each device connects to this server
* In a mesh topology,each device is connected via point to point links to two ormore other devices
* In a full mesh topology, each device is connected to allother devices in the network
* A tree topology is a mixture ofthe star and bus topologies
* In a tree network, two or more starnetworks are connected by a bus network
* An important question is, does the connectivity protocolsupport TCP/IP on the higher layers
* This is essential in two main ways
* First, supporting TCP/IPmeans easy aggressing and connectivity to existing internet orlegacy systems that are already deployed
* Second, it makes webconnectivity very easy
* In case there is no support for Internetconnectivity, a gateway can be used
* For example, a large set of smarttags can connect to a central server, which is connected to the Internet
* In this case, the central server is thegateway to the Internet for those tags
* Gateways have their benefits anddrawbacks
* For example,they add extra cost and complexity
* On the other hand, they can beused to offer extended functions
* A gateway could, for example,encrypt data coming from the tags before passing this data to the Internet
* Or it can manage authentication andlimited access to each tag
* By doing sothe gateway essentially extends and complements the services provided bythe connectivity protocols themselves
* It is important to know which partof the microwave spectrum a wireless connectivity protocol uses
* There might be regional restrictions onthe spectrum which is used by your device
* Or a device might be operatingin a commercial band requiring you to get a license to operate
* There are different bands but for simplicity we can divide them intotwo categories, free and commercial
* The free band is the portionof the wireless spectrum that doesn't require devicesto have operating licenses
* The most common one is the industry ofscientific and medical or ISM band
* The frequency ranges are vast butas an example Bluetooth and WiFi operate in the two pointfour gigahertz ISM band
* An example of the commercial band is 900and 1,800 megahertz range used by GSM
* Estimated node supportis simple to understand
* It means the number of clients thatcan be connected to each other, either directly or via gateway
* There might no theoretical limit onhow many devices can be connected
* But there comes a point wherethe performance get severely degraded when a lot of nodes are connectto a single gateway, for example in the case of a WiFi
* The last parameter is the cost
* When deploying a small set of devices a difference of some euros perdevice might not matter too much
* But when deploying hundredsof thousands of nodes even a few cents can affectthe overall price greatly
* In cyber-physical systems and censor networks, the number ofnodes is often large enough to make the price a decisive factor inselecting the connectivity protocol
* In this lecture, we have defined the basicproperties of connectivity protocols
* In the next video, we will have an overview of a setof popular connectivity protocols
* [SOUND]


--- SKIP ---: 02_connectivity-protocols.en.srt


--- SKIP ---: 02_connectivity-protocols.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_connectivity-protocols.en_SENTbySENT.txt
* [MUSIC] Hello, welcome to another lessonon connectivity protocols
* In an earlier video lecture, we talked about the differentproperties of connectivity protocols
* In this lesson, we will usethose properties to describe and differentiate some of the very common andimportant connectivity protocols
* The first, and the only wired protocolwe will discuss here, is ethernet
* The IEEE 802.3 working group definesthe specification for ethernet
* 100 megabyte and gigabyte ethernet can be commonly found in differentembedded development boards
* Specifications for data rates upto 100Gbps over coaxial cable and 400Gbps over fiber opticcable have been proposed
* Ethernet was designed in a time when powerconsumption was not a consideration
* And therefore,the modules consume a lot of power compared to the otherstandards discussed here
* It's cheap enough and is even available as part of low cost embeddeddevelopment boards
* Defined under the 802.11 umbrella of IEEE, Wi-Fi offers a wireless localarea network specification that has a standard range of about100 meters and data rate of 1Gbps
* The data rate varies from50Mbps to greater than 1Gbps, depending on the spectrum andtechnology used
* Power consumption variesbased on the module and manufacturer, butit's not a power friendly standard
* The number of devices connected toa single gateway depends on the available bandwidth, which will be dividedbetween the connected clients and the processing power andmemory of the system
* In simple home devices,there can be up to 253 connections
* WI-FI mainly operates inthe 2.4 gigahertz ISM band, although 5 gigahertz and newer 60 gigahertz standardshave been proposed
* A newer standard, 802.11 Has been proposed in the 900 megahertz band
* It will offer better range andpower consumption
* With the downside of lower bandwidth,this standard is targeted for the Internet of Things
* Bluetooth is a standard managed bythe Bluetooth Special Interest Group
* It's a short-range, low bandwidthpersonal area network protocol
* It operates in the unlicensed2.4 gigahertz ISM band and uses frequency hopping spread spectrum
* Older Bluetooth standards offeredup to 3Mbits/s data rates, while newer Bluetooth 4.0offers up to 34Mbits/s
* Bluetooth Smart, or Bluetooth Low Energy, or BLE is designed forvery low power consumption
* Despite the similar nameto the classic Bluetooth, it's a completely differentstandard all together
* Unlike the classic Bluetooth,BLE has the data rate of just 1Mbits/s
* It's designed forsending periodic chunks of data, and therefore it is not suitable forvoice calls or music streaming
* BLE offers up to 128 bit AESencryption for messages
* Here AES stands forthe Advance Encryption Standard
* With an approximate transmissionpower of 15 milliwatts, and 3 milliseconds per transaction,a BLE device can perform more than 20 million transactionswithin a small coin cell battery
* Moreover, unlike in the classic Bluetooth,there is no theoretical limits on how many nodes canconnect to one access point
* Mesh networking is not supported, but is being considered to bemade part of the standard
* ZigBee is a standard forlow power mesh networking nodes
* Although the range is up to a 100 meters, due to the mesh nature, it can offerconnectivity over longer distances
* On the physical or link layer,it uses the 802.15.4 standard defined by IEEE, andunlike other connectivity protocols, it also defines the network andapplication layer protocol
* All of this is part ofthe ZigBee protocol stack
* The simple way to understand this is thatin the ZigBee standard the connectivity or radio part is handled viaIEEE 802.15.4 specifications, but the remaining logicalparts like routing, security, data payload formats and profilingare done by the ZigBee alliance itself
* For this reason, ZigBee is notonly a connectivity protocol, but also a communication protocol
* We will learn more aboutcommunication protocols later
* RFID stands forradio frequency identification
* You can think of it as an advancedreplacement for bar codes
* Instead of a barcode on a product,there's a tag
* And instead of light as inthe case of a barcode reader, you use radio waves tointeract with the tag
* This means that you canhave a longer range, and the tag doesn't have tobe visible to be read
* It can be implanted anywherein the product, and as long as it's in the range ofthe reader, it can be tracked and read
* At a minimum, tags have a chip,some kilobytes of memory, and antennae
* Memories storesthe information on the tag
* The chip processes this data andperforms the transformation functions
* And the antenna is use to transmit andreceive the RF signals
* Tags can be passive or active
* Passive tags take their power from the RFsignals transmitted by the reader
* Active tags have a batterythat powers them
* That's why active tags have a higher cost,but a longer range
* A typical range for RFID usage is 1 meter
* Cellular technologies isa very broad term and encapsulates a wide range of technologies
* In simple terms, cellular technologiesare those where there are multiple small interconnected transmitters orcells instead of one main transmitter
* Another feature is frequency reuse, where one frequency is used by multiplecells to increase range and capacity
* But these cells, have to be geographyfar apart from each other, so that there is minimal to no interference
* The most common cellulartechnology is GSM
* Most of the world's mobilenetwork operators use GSM
* GSM also has multiplestandards classified as first, second, third generation and so on
* The data rates and number of users percell improves with each generation
* The current deployed generation is fourth,or 4G, while 5G is in development
* For every generation,you can have multiple competing standards
* For example, for 4G, we have twomain competitors, WiMax and LTE
* A competing standard to GSM is CDMA
* It's not used widely, andit's mostly limited to United States
* In any case,your choice of technology can be based on the range you need,CDMA offers a better range, data rate, LTE offers a better data rate,local availability, whichever network is deployedin your area or cost
* 6LoWPAN stands for IPv6 over low powerwireless personal area networks
* As the name suggests,it is a standard that enables the use of IPv6 on low power edge devices
* By natively communicating usingInternet Protocol, 6LoWPAN devices and networks don't require any specialgateways to connect to other IP networks, such as the Internet
* Therefore, 6LoWPAN offersinteroperability and simplicity in design compared to ZigBee orBluetooth
* Essentially, this standardenables IPv6 packets to be transmitted over IEEE 802.15.4, which is a standard for low data ratewireless personal area networks
* This makes 6LoWPAN ideal forcyber physical systems, where IP connectivity andlow power consumption are essential
* In this lesson, we discuss the basicsof some of the important M to M connectivity protocols or protocolsthat mainly reside on the link layer
* In later videos, we will look into communication protocolsthat reside on the application layer
* [SOUND]


--- SKIP ---: 03_m2m-communication-protocols.en.srt


--- SKIP ---: 03_m2m-communication-protocols.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_m2m-communication-protocols.en_SENTbySENT.txt
* [MUSIC] Hello, welcome to the lesson on Machine toMachine or M2M communication protocols
* What are they, andwhat are their basic characteristics, and which ones are the dominant ones
* M2M Communication Protocolsare application layer protocols that facilitate the transfer ofmessages between two devices
* An important distinction betweenconnectivity and communication protocols is that M2M connectivity protocolsfacilitated linking of the devices and reside on the link layer, while M2Mcommunication protocols facilitate messaging between devices andreside on the application layer
* These protocols allow devicesto interoperate with each other
* They do this by standardizing the keyaspects of naming, messaging, and controls
* Standardized naming means defininghow each device will be referred, recognized, or found
* Standard messaging determines howeach message is formatted, so that all the devices can understand it
* Standard controls enable the devicesto control the flow of communication or quality of service, orto define the type of a message
* Let's have a look at some of the basicfeatures of M2M communication protocols
* These features allow us todifferentiate the protocols, and to define their use cases
* Communication pattern refersto the communication model or paradigm the protocol follows
* An example of a communication patternis the request-response model
* In this model,the client node sends a request to the central server node toinitiate a connection, and the server responds in a predefinedpattern depending on the protocol
* Another communication patternis the publish-subscribe model, or pub-sub in short
* In this paradigm, all the clients duringor after connection establishment define what type of messages they are interestedin, generally called topics or classes
* Whenever a client,a publisher sends a message of a specific topic, the message isforwarded to all those clients or subscribers who have expressedinterest in the topic in question
* All application layer protocolsin the scope of this course assume an underlying transportprotocol to be present
* The choice of a transport protocol isimportant, as it effects the performance, bandwidth, and reliability ofthe M2M communication protocol
* The main contenders at TCP and UDP
* TCP is used in cases wherereliability is of key importance
* UDP being very simple and taking onlya few steps to form a connection is preferred if speed isthe most important factor
* Does the protocol offerany assurance of delivery
* Does it have mechanisms to ensurethe transmission of messages in uncertain circumstances orduring unreliable connections
* What mechanisms would the protocolwould rely on to achieve this
* The answers to these questionsdefine the level of dependability or reliability of the protocol
* A web connected cyber physicalsystem inherits the problems of the current internet andmost likely amplifies them, because of it's directconnection to the real world
* Two of these issues are security andprivacy
* Security is an important differentiatingfactor in the choice of a protocol
* Security aspects of systems are discussedin detail in later video lectures
* Distributed operations meansthat there is no central node to control operation andcommunication of the other nodes
* Instead, communication is one to one, where the communicatingnodes are on equal grounds
* Some protocols might request thatthe data goes first to a central point, a server or broker, from which it is thendistributed to the intended recipient
* Being able to know who andwhat is on the network is as important as the abilityto communicate with them
* The protocol may offer means by whichmachines can recognize peers or associated group members in the network
* Messages and payload support can bea decisive factor in selecting a protocol
* Knowing which protocol will easilyintegrate with the current systems is valuable andknowing the payload helps in this regard
* Current web services andtechnologies benefit from a protocol that offer support fortypical web payloads, such as HTML, plain text,UDF8 and coded text and XML
* Based on the features we defined, let'slook at the dominant protocols today
* The constraint application protocol or COAP is a standardizedrequest response protocol
* It's creators redesign functions from HTTP taking into consideration,the target device's CoAP will be used on
* That is embedded devices with limitedprocessing power, storage, and bandwidth
* It also supports publish-subscribe stylecommunication and resource discovery
* CoAP uses UDP as the transport protocoland has a dual layered structure
* The transactional layer takes care ofmessage handling between nodes, and the request response layer managesresources and transmits messages
* This enables efficient congestioncontrol and reliability over UDP Here you see a shortoverview of the protocol
* Hypertext Transport Protocol, HTTP,is the backbone of modern world wide web
* It is the defacto protocol for exchanginginformation between Internet connected nodes that communicate via hypertext, forexample, your browser and web server
* HTTP sets up the regulations on hownodes are going to communicate, and also specifies the content
* HTTP relies on TCP as the transportprotocol for packet transmission
* Here, you see a shortoverview of the protocol
* The Message Queuing Telemetry Transport,or MQTT, was invented by IBM and RCom to collect data from remotedevices to back up it's server
* It was introduced in 1999 by IBM, and it was standardized in 2014
* MQTT is meant for lightweight devices, which are constrained by bothprocessing power and memory
* Besides this, the protocol cantransmit data over low bandwidth and reliable connection
* The static header sizeof MQTT is just 2 bytes
* It is an open-source freeto use standard protocol
* MQTT relies on TCP asthe transport protocol
* MQTT is inherently a publishedsubscribe protocol
* Clients connect to a server to send and receive messages onthe channels of their interest
* The server is called a broker, senders arepublishers, and receivers are subscribers
* Here you see a shortoverview of the protocol
* The extensible messaging andpresence protocol or XMPP was originally a text-basedmessaging protocol for messaging between devices over a networkusing the XML document format
* XMPP is being explored forInternet of Things by the XMPP standards foundations foraccess control and censor data
* It's strong point is it's very familiardevice at server naming approach
* Besides this, it provides endto end security, provisioning, and publish subscribe style communication
* It is slow, but secure anduses TCP as the transport protocol
* Here you can see a shortoverview of the protocol
* The Data Distribution Service,or DDS, is a standardized, publish-subscribe protocol that enablesdevices to communicate in near real-time
* DDS has its own interoperabilityprotocol called Wire, which enables different implementationsof DDS to communicate and interoperate
* In a DDS environment, anyone can bea publisher, subscriber or both
* It also offers an extensive quality ofservice support allowing efficient and versatile implementations ofquality of service policies
* It can use either TCP orUDP as a transport protocol
* Here you see a shortoverview of the protocol
* The Advanced Message Queueing Protocol or AMQP has its roots inthe financial industry
* It relies on queues between senders andreceivers for reliability and in delivery of messages
* AMQP uses TCP as the transport protocol
* It allows a server to initiatea connection with the client
* Unlike HTTP in which the connectionhas to be initiated by a client
* ANQP is flexible
* It offers peer-to-peer, client-to-brokerand broker-to-broker communication
* Here is a short overview of the protocol
* In this lesson, we learned the basicfeatures of M2M communication protocols and studied briefly a set of popularreal world protocols in this category
* In the next lesson, we will learn aboutthe use cases for connectivity protocols
* [SOUND]


--- SKIP ---: 01_connectivity-protocol-users.en.srt


--- SKIP ---: 01_connectivity-protocol-users.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_connectivity-protocol-users.en_SENTbySENT.txt
* [MUSIC] Hello, welcome back
* In this lesson,we will talk about the parameters and use cases that will effect your selectionof an appropriate connectivity solution
* We will first define the criteria andthen classify the protocols based on that
* The very first thing you need todo is define your project's need
* Defining your need helps you inselecting a protocol that offers the right amount of compromisebetween you desired criteria
* Some of these have been discussedin detail in another video
* Let's look at some of the basic ones here
* Range defines the physical distance atwhich a protocol can offer connectivity
* If you want to build a citywide network, you need a solution thathas the longest range
* If you want a room base network, you needa solution that offers a shorter range
* Longer range generally comes at the costof power consumption and data rate
* This is not always the case, however
* There certain exceptions,as we will see later
* If a protocol supports mesh networking,you can create a long range network even if the range ofeach individual device is short
* Data rate is the amount of data, the protocol will allow youto transfer in one second
* Generally, you want to choosea protocol that offers data rate close to your needs as higher data ratesmeans more power consumption
* How much power does your protocol consume
* If your device is battery powered, you would want to choose the protocolthat has the lowest power consumption
* If your device is directlyconnected to the power grid, this might not be an issue at all
* Remote devices are generallybattery powered and require a solution that hasthe lowest power consumption
* Cost in terms of dollarsdefines how much the addition of a certain module will cost
* Complexity is definedhere in terms of time and resources that are required to makethe protocol functional in your design
* Base on the criteria we defined,let's classify the connectivity protocols
* GSM or cellular technologiesoffer the longest ranges for point to point communicationsafter several kilometers
* They also offer very high data ratesstarting from a few kilobytes per second, like Edge, enhanced data rates for GSM evolution to several megabytesper second, for example, 4G LTE
* This, of course, comes at a cost of higherprice, complexity and power consumption
* There are however, other technologiesthat offer long range are cheaper and very low power, butalso have a very low data rates
* They are categorized as LPWANsorLow-Power Wide-Area Networks
* Example of these are LoRa, Long RangeWireless Data Telemetry and SigFox
* On the other hand, we have short range technologies thatoffer both high and low data rates
* The difference between them is again,power consumption and cost
* Low data rate technologiesconsume significantly less power
* For example, Bluetooth,low energy and NFC or near-field communication andare cheaper and less complex to deploy
* High data rate ones like Wi-Fi and Ethernet are complex andpower inefficient
* The three very high data ratetechnologies that we have are cellular, Wi-Fi and Ethernet
* All of them offers speeds ofseveral megabytes per second
* Ethernets is fixed orwired while the other two are wireless
* Medium bandwidth technologies are Zigby, Bluetooth and Bluetooth Low Energy or BLE
* These have a short range,but a good battery life
* There are some technologies thatyou would use only for sensing or tagging as they offer short range,low data rates
* And generally,very low storage capacity on each node, just enough to identify the item
* For example, we could store the device ID,web link or a few bytes of text
* NFC and RFID are in this category
* Power consumption is a veryimportant factor in deciding a connectivity solution
* Most of the cyber-physicalsystems comprise devices or nodes that are links wirelessly andmay not have direct access to power like, for example, remotes sensing solutions
* In such a case, choosing the mostpower efficient solution is suggested
* This comes at the disadvantageof lower data rates
* Here on the screen,we have divided the technologies into two categories where the differentiatingfactor is range
* Power consumption anddata rates vary, but not that much
* Compared to Wi-Fi and Ethernet,protocols like NFC, LoRa and Bluetooth have significantlower power consumption
* Cost per dollar is a factor,if you are going to mass deploy a large set of devices orif you aim at commercial production
* As we discussed earlier,you have to define your need first
* That is what you essentiallyrequire from your system
* This requirement analysis will alsofacilitate determining the cost
* If your need is only a sensing solution,you can go with LoRa or ZigBee
* If it's identification only,you can use NFC, which is even cheaper
* If your systems require high data ratesand are stationary, use Ethernet
* The cost will depend onthe needs of the system
* Here we have an example case,please read it through
* What would your solution be
* There is actually no unique solution,because you could, in a way or another utilize any of thesetechnologies to accomplish the task, but we will look forthe most optimal solution
* First, we have to identify your needs
* In this case, you have three
* The range is one kilometer
* Update frequencies once per hour andit's only about weather
* So, the date is alreadyactually very low and you want to see the updates on your phone
* Taking these into account, we can see that Bluetooth offers the data rate,but not the range
* Wi-Fi doesn't offer the range either, although it offers internetconnectivity and ubiquity
* ZigBee offers the range andthe required data rate and power efficiency as an added bonus, but there is a higher probability that itwill not be supported by your phone and you will need a gateway to connectit to the internet, for example
* This will increase cost and complexity
* GSM orcellular technology offers the range, data rate andthe ability to be on the same network
* As a once an hour update schedule, it can get the weather as a text messagefrom the weather station to your phone
* So, this solution fulfills yourneeds in the least complex way
* And therefore,it is the best one for this case
* In this lesson, we learned how to choosethe right connectivity solution for a cyber-physical system
* In the next video, we will learn about choosingthe right M2M communication protocol
* [MUSIC]


--- SKIP ---: 02_choosing-the-right-m2m-communication-protocol.en.srt


--- SKIP ---: 02_choosing-the-right-m2m-communication-protocol.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_choosing-the-right-m2m-communication-protocol.en_SENTbySENT.txt
* [MUSIC] Hello, welcome back
* In earlier video lectures,we have discussed the key properties of the application layer M2Mcommunication protocols
* In this lessons, we will look at setof popular communication protocols with the goal to give some guidelines toselect the right protocol for your system
* One thing that alwaysneeds to be considered is that selection between anyprotocols is a matter of compromise
* It's rare to find a situationwhere a protocol fits perfectly
* Checking all the check marks
* In the light of this is alwaysa good idea to divide your criteria at least into two categories
* The absolutely necessarymust have features and the optional of good to have features
* Absolutely, necessarywill be the features that are critical to the project orthe operations performed
* Good to have features would be thosethat facilitate the operations further
* In this video lecture,we will describe and provide some of these criteria anduse cases for the considered protocols
* These criteria are Deployment Scenario
* The Deployment Scenario is one ofthe most important factors to look into
* In what kind of scenariowill a protocol be deployed
* Would be a real-time system,telemetry, security, messaging
* What kind of connection will be provided
* Is it a low power lossy network ora high throughput always on setup
* All of these cases require differentfeatures from the communication protocol
* Security
* You need to determine whatkind of security you need and then look into whether it is provided ornot by your candidate protocols
* With the current emergence of malware anddata breaches, it's very important to not only projectdata at rest, but also data in motion and this means the data that wouldbe carried by the protocol
* Communication Paradigm
* If your link layer connectivityproduct goal is mesh-based
* Meaning, there is no primary gateway orbroker
* It make sense to use an application layer, communication protocolthat has the same feature
* A protocol which offers directclient to client communication without a central server
* On the contrary, if you need toaggregate data from multiple sensors, it's better to use a protocol thathas a broker or central server
* In this case, there is by default,only one data point, the broker from which all the informationcan be collected and processed
* Payload Format
* The cyber-physical systemrarely works on its own
* Generally, it is part of a larger system,such as a control or monitoring system
* In this case, design time andcomplexity can be reduced by using a protocol that supports the payloadformat of the rest of the system
* Web connected system shouldutilize communication protocols that support webrelated formats, such as HDML, XML, even JSON orJavaScript object notation
* Strictly, machine to machinesystems should utilize protocols that provide support for JSON
* Compatibility with Existing Installation
* It is important to know what kind ofprotocols and systems are in use at the moment in the environment inwhich your system will be installed
* This should be the primary guideline foryour decision unless there are severe limitations in the current systems thatare going to be fixed with the new one
* Quality of Service
* Critical systems requirestrong quality of service
* Some protocols offer built-inquality of service features
* Some protocols do not, but rely onlow layer protocols to provide them
* Communication Performance
* Speed, throughput, cashing, complexity and quality of service are allfactors of performance
* How fast are the connections established
* How much throughput canthe protocol provide
* Does it for a cashing and resending
* What is the communication complexity andhow is quality of service handled
* All of these provide a measure of thecommunication performance of the protocol
* The first protocol to address is HTTP
* HTTP offers non-optimal performance,as it was designed for always on always reliableconnectivity platforms
* However, it offers the highest level offlexibility and ease of integration into current and future cloud systemswithout any gateways or translations
* It also offers the most comprehensivesupport for different payload formats
* And moreover, the newer standardHTTPS offers solid security features
* The downside of HTTP are low performanceand high energy consumption
* Also, it is a connection list protocol
* So new connections have to be established,frequently
* Consider CoAP,Constrained Application Protocol to be a cyber-physical systems andInternet of Things version of HTTP
* It offers what HTTP doesplus it is lightweight, has basic quality of service features and higher performance in terms ofprocessing power and memory consumption
* CoAP was designed in sucha way that it is easy to build a gateway between HTTP and CoAP
* And therefore, CoAP can be used,rather seamlessly in web-based scenarios
* MQTT or Message Queuing TelemetryTransport Protocol is good for telemetry applications, of course, because it wasoriginally designed for this purpose
* The main issue with MQTT is security
* It by itself doesn't provide any securityfeatures although it can used with lower-level security solutions,such as TLS, transport layer security
* MQTT is very lightweight
* It doesn't offer any specificpayload format support
* It just transmits everything has bias
* This makes its integration withcurrent systems, rather difficult
* Because of its qualityof service features, it can handle unreliable connectionsvery well and should be considered for applications where remote operations ormessaging plays the key role
* XMPP or Extensible Messaging and Presence Protocol is all about messaging,and security
* If your devices or notes requiremessaging between each other and this messaging should be done securely,XMPP used the protocol of choice
* XMPP supports both one to one andgroup oriented messaging
* Security alarm systems can use XMPPto alert users on their smartphones
* As most of the modern operatingsystems have some form of XMPP implementation already built-in
* Cities can use XMPP to alert usersabout traffic changes due to construction work ornatural disasters, for example
* XMPP suitable to mashingto mashing messaging and then relaying that informationto humans or controllers
* On the downside, it is heavy andnot very real-time
* DDS or Data Distribution Service protocolis about reliability and performance
* It has a comprehensive support forquality of service
* Each message will get delivered toits recipient even if the broker, which the recipient isconnected to goes offline
* This reliability featureis one of the key reasons why DDS is preferred inmilitary applications
* It also has a strong focus on security
* It's very scalable and can easilyaccommodate growing number of nodes
* In this module and the previous one, wehave discussed different communication and connectivity protocols and the underlyingarchitecture of the web and its protocols
* In the next module, we will move onto building webconnectivity into embedded systems
* [MUSIC]


--- SKIP ---: 01_embeddable-webservers.en.srt


--- SKIP ---: 01_embeddable-webservers.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_embeddable-webservers.en_SENTbySENT.txt
* [MUSIC] Hello
* Welcome back to the courseon web connectivity and security in cyber physical systems
* This lesson starts a module on websolutions for embedded systems
* In this video lecture,we will walk you through web servers that are inherently designed forlow power embedded systems
* We call them embeddable web servers
* But first of all, what is a web server
* If you have been followingthe lessons in this course, you might remember that in an earlierlecture we talked about the key technologies that enablethe World Wide Web
* These technologies are HTML,HTTP and Webservers
* HTTP has been discuss indetail in other lessons
* Today, we will look into web servers
* The protocol HTTP workson a client server model
* A client sends a request to a server andthe server responds
* Therefore, web serversare applications that accept, read and respond to the HTTP requests from clients
* One of the principles of a web server isthat it's always responds to a request
* The response can be some information thatthe user requested or an error message
* But the server will respond
* What if the server is toobusy to fulfill a request
* Then it will send an errormessage with a status code 503 indicating that it's temporarily busy
* The next question you might have is,okay, I now know that I have to request a web server, buthow do I identify and access one
* This is what URLs are for
* URL stands foruniform resource locator and as the name suggests, it is usedto identify resources on the web
* On the screen is an example URL
* It has three parts
* The first is the protocol,in our case, it is HTTP
* The second is the IP address of themachine where the web server is running
* And the third is the locationof the resource or file that we want toaccess on that machine
* So at the very least, a web server shouldbe able to understand HTTP and URLs
* Next, we will look into web serversdesigned for lightweight use
* When you are on your computer and you wantto access the web, you open a browser and type the URL of the web serverthat you want to access
* Similarly, if you wantyour embedded device or sensor to access the web,you don't need a web server
* All you need is a small client thatcan send and receive HTTP requests
* Simple enough
* But what if someone else on the web wantsto access your embedded device or sensor
* Then you will need a web server
* Remember, web servers comesin all sizes and shapes
* From resource heavy oneslike Apache to light-weight ones like [INAUDIBLE]and nginx
* But we are looking for web servers thatwill run on devices with a few megabytes, even kilobytes, of RAM andwith very limited processing power
* Web servers that are small enough thatyou can execute them as part of your standard application code
* We will look into two of these small, lightweight web servers,SMEWS and Mongoose
* SMEWS stands for Smart andMobile Embedded Web Server
* It is developed by researchersfrom Lille 1 University in France
* It can run on devices with aslow as 200 bytes of RAM and 8 kilobytes of flash memory
* It supports multiple connections and doesn't require any operating systemto be installed in the system
* It has its own TCP/IP stack
* This web server comes as a verycompact and complete package
* Mongoose is another embeddable web server
* It's open source andfree for non-commercial use
* Mongoose is more advanced andalso heavier than SMEWS
* The list of features that Mongoosesupports is on the screen
* It's constantly being developed andmore features are being added
* We have tested an implementation ofMongoose in our lab and it was able to handle up to 2,000 clients and 1 millionrequest in total on our test set up
* To show you how to use an embeddableweb server in your application, we will use Mongoose
* Let's look at an example scenario
* Imagine you have a temperaturesensor whose value you would like to access via your browser
* We will not go into too much detail butwe'll only explore the basic functions that we need to implementthe scenario we just defined
* First of all, include the Mongooseheader file into your C program
* Next we will use a functionfrom the Mongoose API or application programming interface, thatenables us to handle incoming requests
* In this function, we will specifywhat happens when a user access a specific URL oruniform resource locator
* If you look at the line number 10,we have defined that if the access URI or uniform resource identifier is /TEMP,the program should take three actions
* Call a function to check the temperature,send the temperature back andclose the connection
* The last step is to build the mainfunction and call the web server
* How that is done is shown on the screen
* And that's it
* In three simple functions youcan make your applications or devices respond to HTTP requests
* Now as a last step in this example,if you go to any browser and type the URL in the form shown on the screen,you will get the temperature as text
* To summarize
* In this lesson,we learned about basics of web servers and looked at an exampleweb server application
* In the next lecture, we will look at webservices and their dominant technologies
* [SOUND]


--- SKIP ---: 02_web-services.en.srt


--- SKIP ---: 02_web-services.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_web-services.en_SENTbySENT.txt
* [SOUND] Welcome back
* In this video lecture, we will lookinto the technologies that allow you to interact with the different web services
* The benefit of web connectivityis that you can utilize and interact with different web services
* Services developed andperfected by other vendors
* For example, if you want to build userauthentication into your product, you can just use Authy
* Authy is a web service thatprovides two factor authentication
* In another video, we discusseda temperature sensor with a web server
* If you want that temperature sensorto send you a tweet for every alert, you can just call Twitter's API orApplication Programming Interface service
* Are you running out of on-board storage
* Call the Amazon Web Services API and off load all the data toAmazon's data centers
* All of this is possible because we have standard ways to connectto these web services
* In this lesson, we will look into two of the major classesof such technologies, REST and soap
* But before we get into that, we will lookinto the data formats that they use
* Let's start with JSON
* JSON is a text-based dataserialization format
* It stands for JavaScript Object Notation
* JSON is made of two structures,objects and arrays
* Objects start and end with curly brackets
* Arrays start and end with square brackets
* The data is in name value pairs andone set or pair of data is separatedfrom another with a comma
* And this is pretty muchthe basics of JSON
* On the screen you seean example JSON object Plants
* The data is in name value pairs, the pairsare separated from each other with commas
* We also have an arraywith three objects in it
* In JSON, everything can be nested
* As you can see here that we have an arrayof objects that itself is a part of a larger object, Plants
* If we want to represent that samedata in XML, it will look like this
* XML stands for Extensible Markup Language
* It is another data encoding format
* And like JSON it is also text-based
* The chat protocol XMPP uses XML basedobjects to send and receive messages
* The example that you see onthe screen is pretty simple
* But XML is relatively complex
* Old Microsoft Office Word fileshad an extension of doc or d-o-c andthe newer ones have docx or d-o-c-x
* That last x in docx stands for XML
* This is because the whole structure of thenewer Word documents is formatted in XML
* And because XML is an open standard,other applications besides Microsoft Office can also accuratelyread and format docx files
* Now back to our web services
* We just describe twodata exchange formats
* And now we will describe two ofthe common specifications for implementing a web service
* REST stands for representation orstate transfer and lays out some ground rules onhow to design web services
* REST is not a protocol buta style of designing services
* It is also protocol independent,but is generally paired with HTTP
* Some salient features of RESTare shown on the screen
* We will discuss it in muchmore detail in a later video
* As this style of designing webservices can be easily translated into embedded systems
* In short, for every service,we have a URL and we interact with that service via HTTP andits methods
* Some of the basic principles of REST are, Keep your design limited toHTTP methods like get and put
* Each request should be independentof the previous or next one
* For each service you shouldhave a separate URI
* The data exchange format can be JSON,XML or both
* Generally, it is JSON
* SOAP stands forsimple object access protocol and is another method forinteracting with web services
* It relies on XML and like REST,it is protocol and platform independent
* The protocol has threemain characteristics
* Extensibility, meaning itsupports expansion and there are several extensions availablethat you can use with that SOAP
* Neutrality in this case meansis it protocol neutral
* Independence from the platform andprogramming language
* The developers can use anyprogramming model they see fit, whether it is object-oriented oragent-oriented or dataflow-based
* So, which one should you use
* Sometimes you don't really have a choice
* If you are interacting with a web service, you will have to use the technologythat they have used
* If you're building you're own web service,then you do have a choice
* The basic difference is between ourtwo candidates are outlined here
* REST is lighter than SOAP interms of network resources
* REST is more power efficient thanSOAP in small embedded systems
* It is also simpler
* On the other hand,SOAP offers better security
* It has many extensions and it is inherently protocol independent
* Also REST is protocol independent inprinciple, but is generally bound to HTTP
* In this lesson,we looked at the technologies and data formats that allow us tointeract with web services
* In the next video lecture, we will learnabout RESTful web services in detail
* [SOUND]


--- SKIP ---: 03_how-to-rest.en.srt


--- SKIP ---: 03_how-to-rest.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_how-to-rest.en_SENTbySENT.txt
* [MUSIC] Welcome to the lesson onRESTful web services
* In this video lecture,we will have a deep look at REST
* But what is REST, actually
* REST, or Representational State Transfer,is an architectural style
* A set of guidelines toserve network applications
* It specifies a set of constraintson developing web services, and if those constraints are metwe call that service RESTful
* The first constraint is the separationof the client and server functions and architectures
* The client doesn't care aboutthe task executed on the server
* For example, database access ormemory management
* And the server doesn't carehow the client operates
* This way they both can bedeveloped independently
* Clients can send multiple requests, but these requests should beindependent of each other
* Responses should be clearly identifiedas cacheable or non-cacheable
* This is more of a performance constraint
* Multiple clients might requestthe same resource, and in this case, caching will help in reducing responsetime and reducing a server load
* There should be a uniform way ofidentifying and accessing resources
* Each resource must have a URI andrepresentation
* The representation can be in JSON or XML
* The last constraint is thatan application can have multiple layers
* Layers between client and server,like cash servers and load balancers
* If there is a load balancerbetween a client and a server, the client shouldn't seebeyond the load balancer
* And the server shouldn't be concernedwith who the load balancer is talking to
* This restriction reduces complexity and makes it easy to add and remove layers
* As a design considerationrather than a constraint, there should be one to onemapping between CRUD operations
* That is create, read, update, and delete operations, andoperations provided by the server
* In light of these constraints,let's look at how HTTP fits REST
* HTTPs is stateless,it has a client-server model, it supports caches, anduses URLs to identify resources
* The last design considerationis mapping of craft operations
* This can be done by a HTTPmethods as shown in the table
* We see that it is simple to builda RESTful web service via HTTP
* But why should we use rest when exposingthe functionality of an embedded or cyber physical system to the web
* First of all,a central idea of rest is a resource
* A resource is a componentof an application that can be uniquely identified
* The same logic appliesto embedded systems
* We have resources inthe form of sensor and actuators, which need to beindividually identified and accessed
* Identification is achieved via URI's,and they're representation via JSON
* An access comes by a HTTPmethods like GET and POST
* In REST, we call for CRUD operations,create, read, update and delete
* In most cases, these are the onlyoperations that we need on our sensors
* Create the stages,update them, or shut them off
* REST and JSON, used together, create a lightweightrepresentation of resources
* Being lightweight makesit more power efficient
* The statelessness of REST means thatit is more memory efficient as a server doesn't store our main informationabout the state of the connection
* So, not only does rest fulfillour design considerations, but it also fulfills real-world considerationsrelated to limited power and memory
* We looked into REST, and its applicabilityto embed in systems in general
* Now we will talk about some best practices to follow when designingweb-enabled embedded systems
* First of all, identify the sensors orfunctionalities that are available to you, and then decide which ones youwould like to enable as a resource
* Each of these resourcesshould have a simple and focused URI to identify and access them
* And finally, what actions would you liketo allow on each of these resources
* To better understand, we will lookat an example development board
* On the screen, you see a TexasInstruments Smart RF06 Evaluation Board
* It has an accelerometer,light sensor, LCD display, an SD card slot, andsome push buttons and LEDs
* In this case,it is easy to identify our resources
* All of the mentionedcomponents are resources that can be uniquely identified andaccessed
* The next step is to assign eachone a unique and logical URI
* Here you see an example mappingof URIs against each resource
* The next step is to specify whichoperations you would allow on each resource
* So when you enter in a browser the URLof whichever sensor you want to access, the response will depend on whether thespecific HTTP method is allowed or not
* If it's allowed you willget an okay status message with the value of the sensor
* If the method is not allowed, you will getthe method not allowed status message
* On the screen you see an examplemapping of methods to resources
* As we will be only reading datafrom the accelerometer and licencer, the only methodwe can use is GET
* An LED can have a GET methodto tell us it status on or off anda PUT method to change that status
* And LCD can be updated to output certaininformation, and for that we need PUT
* If we are reading and writing to the SDcard, we can have all of these methods, create a file, update a file,read it, and delete it
* In this lesson, we looked at howthe REST style of designing web services is beneficial forcyber physical systems, and then we described an example mapping ofREST to an embedded development board
* Next we will learn about another typeof service called cloud computing
* [MUSIC]


--- SKIP ---: 01_cloud-and-cyber-physical-systems.en.srt


--- SKIP ---: 01_cloud-and-cyber-physical-systems.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_cloud-and-cyber-physical-systems.en_SENTbySENT.txt
* [MUSIC] Welcome to the lesson on cloudcomputing and cyber physical systems
* In this video lecture, we will look intothe relationship between cloud computing and the future of cyber physicalsystems or embedded systems in general
* Let's talk about cloud computing
* In the simplest form,cloud computing is about utilizing computational power as a utilitylike electricity or gas
* Instead of building your ownin-house computational capabilities, you rent them out from peoplewho have already designed them
* This model of renting out resources basedon one's needs has several benefits
* First, flexibility
* The resources you utilize like storage,computing capacity or network can scale up orscale down based on your needs
* Second, low maintenance
* As the servers are managedby your provider, you don't have to worry aboutmaintenance or software updates
* Third, paper use, you only pay forthe resources you use
* Fourth, security, cloud servicescan maintain better security and hire better professionals comparedto a small business or startup In the words of a researcherin the field of security, cloud is using somebody else's computer
* In another lesson, we talked aboutdifferent protocols like GSM, Bluetooth, and Zigby that enable us to connectour cyber physical systems
* We also pointed out the one's that supportGCPIP to enable IP based communication
* When you take a small embedded device andassign it an IP address, you can uniquely identify it,remotely access and control it andshare its data across the internet
* What you have done is that you havebuilt an Internet of Things device or IoT device
* You had a device, a thing, andyou made it a part of the internet
* Irrespective of all the hype andwell justified interest in the Internet of Things, at its very basic level,it is a very large number of embedded systems talking to eachother via IP networks
* If you look at it from this perspective,to an embedded systems engineer, IoT is more of an evolution of the technologiesthat were already available to him
* The reason we are talking aboutthe Internet of Things is that it shares a lot of similaritieswith cyber physical systems
* IoT is about monitoring or sensing thereal world with interconnected sensors
* Cyber physical systems are the same
* Any platform that billsitself as an IoT platform can also be cyber physicalsystems platform
* From now on, in this lesson,we will use the term IoT instead of cyber physicalsystems as most of the cloud platforms like to associatethemselves with the Internet of things
* Cloud computing andIoT compliment each other very well
* In the vision of Internet of Things, you have hundreds of thousandsof sensors generating data
* Cloud computing helps you store andprocess that data
* You can see an example of trackingpeople's fitness on the screen
* If you are an IoT device andnetwork provider, you can focus on your core competence,building and connecting sensors
* You don't have to worry aboutbuilding your own IT infrastructure
* Another problem is makingsense of all that data
* There are cloud computing toolsavailable that will help you analyze and generate actionableintelligence from your data
* If you are monitoring traffic flow or power consumption ina large housing society, or monitoring the air quality of a largecity, you need a strong IT infrastructure
* Cloud computing offers you that
* This growing interest incombining cloud computing and Internet of Things has createdon new field called cloud IoT
* Cloud IoT is providingon demand computational infrastructure designed specifically forthe Internet of Things
* Cloud IoT providers canoffer different services
* Here are some basic considerationsto look into when choosing one
* Do they offer support for the communication hardware andsoftware you will be using
* Do they support the communicationprotocols you are using in your solution
* Do they offer you remotenode management like controlling your device remotely, issuingcommands or upgrading its firmware
* Do they offer any data analytics
* If yes, is it according to your needs
* What kind of pricing model do they have
* Are they charging by the numberof nodes or sensors you have or by the number of resources you use
* Here is a short list of different cloudIOT platforms and service providers
* In this lesson, we looked atthe merging of cloud computing and the Internet of Things phenomenon
* The next video lecture, we will look at a phenomenon thatis opposite to cloud computing
* [SOUND]


--- SKIP ---: 02_fog-computing.en.srt


--- SKIP ---: 02_fog-computing.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_fog-computing.en_SENTbySENT.txt
* [MUSIC] Welcome back
* In this lesson, which concludes thismodule, we will look into the concept of fog computing, its basic ideas,and expected benefits
* So what is fog computing
* In another video lecture, we talked about Cloud computing whereyou transfer all the data generated by internet of things devices tothe back-end servers and analyze it there
* Each intelligence, or as Cisco calls it,fog computing is the opposite
* Fog computing suggests thatsome processing takes place at the end devices or gateways
* It's called Edge Intelligence because the computation takes place atthe edge of the network where the data is initially generated instead ofthe core where it is later transferred
* In this video lecture, we will look into basic concepts ofEdge Intelligence and fog computing
* There are few drivers forthe trend towards fog computing
* First, big data orthe large amounts of data generated by millions of tiny devices can be toodifficult to transfer around the networks
* Moving it from a service to a service or from a data center to another willconsume time, energy, and bandwidth
* Second, there is a paradigm, called theMoore-Nielsen Paradigm, stating that data gets accumulated at the edge is fasterthan the network can push into the core
* As an example, a jet engine produces 20terabytes of data for each flight hour
* It is not possible to transfer all ofthese data to the Cloud in a real time
* The third driver forfog computing Is the fact that storage and processing power are becoming very cheap
* So instead of dumb devices thatjust pump data back to the core, you can have intelligents, orsemi-intelligent ones, at the edges
* Lastly, you need fog computing orEdge Intelligence to filter through all these massive amount of databefore you can transfer it to the Cloud
* Here are some of the characteristics andbenefits of fog computing
* Fog computing will offer better latencyand improved location awareness
* Different types of nodes will cometogether to form fog deployments
* Fog computing will offerlocal analytics and intelligence at the edge of the network
* Distributed intelligencewill effectively cut down the amount of data that istransferred upwards to the Cloud
* As data is available locally,local operations can continue to perform, although in a limited capacity evenif the back-end connections are lost
* You won't have to move sensitive data,it will stay close to the source
* Think of patient's medical records beinganalyzed locally rather than sending them to the Cloud
* Here is a list of different fog IoTplatforms and service providers
* There are not that many providers yet asfog computing is a relatively new concept
* And here is the summary ofall things Edge Intelligence
* This ends the web connectivitypart of the course
* Let's walk through what we havelearned in our course so far
* We started with the basics of theinternet, and studied the TCP/IP model
* We then discussed connectivitysolutions for cyber-physical systems
* We also discussed some ofthe main communication protocols
* Examples of how to build webconnectivity into your design, and how to design RESTful embeddedweb services were presented
* Then we touched on two importanttopics in cyber-phyiscal systems or Internet of Things, Cloud,IoT, and fog computing
* In the next modules,we will talk about another major topic related to cyber-physical systems,namely security
* We will go through security protocols andalgorithms and help you understand some of the attacks against cyber-physical systemsand how to defend against these attacks
* [SOUND]


--- SKIP ---: 01_introduction-to-cps-security-and-privacy.en.srt


--- SKIP ---: 01_introduction-to-cps-security-and-privacy.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction-to-cps-security-and-privacy.en_SENTbySENT.txt
* [SOUND]
* Hi, welcome back to the videolectures on web connectivity and security in cyber-physical systems
* This lesson starts the secondpart of the course
* This part includes two modules, and it's dedicated to system securityissues and their solutions
* We will learn about differentsecurity technologies and methods and learn how to utilize these in securing and protecting cyber physicalsystems against cyber attacks
* In this video lecture, we will look into basic securityrequirements of cyber physical systems
* Several physical systems facilitatea wide range of solutions and services that help peoplein their daily lives
* However, providing these solutions andservices in a reliable safe and secure manner is not at all trivial
* On the contrary, there are many challenging issues thatneed to be appropriately addressed
* For example, dealing with sensitive orsafety-critical data, if this data is not properly protected,can lead to significant financial losses, loss of privacy or reputation,mental suffering or physical damage
* It could even endanger lives
* So, among issues andchallenges involved in design and deployment of cyber physical systems,security has a very important role
* Cyber physical systems have theirown specific security issues
* This is because of theirspecial characteristics
* First of all,as they are involving physical processes, they are tightly coupled withtheir physical environments
* So any changes in their environments, especially on expected changes thathaven't been considered at design time will affect them, and potentially makethem more vulnerable to security breaches
* This is true the other way around as well
* Security breaches incyber-physical systems can have serious influenceon their environments
* Second, cyber-physical systems can becomposed of a very large number of different devices with differentcomputing platforms and capabilities
* In general, most devices in cyber physicalsystems are resource constrained, meaning that they don'thave much processing, storage, or power capacity toexecute complex operations
* This poses challenges forapplying efficient security counter-measures that may requirea relatively high amount of resources
* Third, cyber-physical systems canbe massively networked systems
* They can use variouscommunication technologies between devices ranging fromsimple wired connections to different wireless technologies withdifferent ranges and characteristics
* So they can be highly complex and heterogeneous systems making itharder to find optimal solutions to ensure secure transmission ofdata everywhere in the system
* Finally, cyber physicalsystems are typically highly autonomous with embeddedintelligence controlling many operations
* This reduces the need formanual control and supervision
* Which on one hand is an advantage, becausethe risk for human error is reduced
* On the other hand, the user must beable to rely on the autonomous system to be protected against maliciousattacks that aim to secretly alter the behavior of the system, orto steal sensitive information
* In general, we can classifythe security requirements of cyber physical systems into several categories
* In a system, which interactswith a physical environment, validity andaccuracy of sensed data is very important
* So, proper protection of sensors and their data is of highimportance in such a system
* Data collected from multiple sensorsneeds to be store temporarily
* Malicious unauthorized modification ofthis stored data results in errors and is further processing andcan have serious consequences
* For this reason, the data whilein storage needs to be protected against any unauthorized access andmodification
* In some large cyber physical systems, the data may be collected froma very large group of sensors over some time period resulting in a verylarge set of data or beak data
* The more data you havethe more complex and difficult it is toproperly secure this data
* Many cyber physical systemsare networked and distributed
* Sensitive data is transmitted throughheterogeneous communication channels
* Communication security is neededwithin a system and between systems
* We will discuss different communicationsecurity protocols in other video lectures
* In a system which carries out autonomousoperations through its actuators, it is of key importance to make surethat all actuations are authorized and according to the latestpolicies of the system
* Feedback loops play an important rolein cyber physical system control
* A system's embedded intelligence and ability to learn are largely basedon feedback of its actuations
* Therefore the feedback data needs tobe appropriately protected against tampering attempts
* Finally, the system may have someapplication specific security requirements, depending on the nature ofthe applications running in the system
* Cyber physical systems have bothphysical and cyber aspects that need to be taken into account whendesigning security counter measures
* In developing security solutions forcyber physical systems, we need to keep in mind thatattacks can also be indirect meaning that they can aim toaffect the physical environment in such a way that data comingfrom sensors is corrupted and misleading resulting in unexpectedbehavior or even system failure
* The system needs to be designed todetect abnormal physical conditions, and act in a safe way in these situations
* Also, the system should always beprotected against physical tampering whenever possible
* Security counter measuresmust be considered in the design phase ofa cyber physical system
* Security by design meansdesigning the system as free of vulnerabilities andresistant against attacks as possible
* This can be achieved by continuoustesting and careful design of rigorous authentication solutions and hardware andsoftware components of the system
* In this lesson, we discussed different securityrequirements of cyber-physical systems
* In the next video lecture,we will learn more about the key security concepts incyber-physical systems
* [SOUND]


--- SKIP ---: 02_key-concepts-in-cyber-physical-systems.en.srt


--- SKIP ---: 02_key-concepts-in-cyber-physical-systems.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_key-concepts-in-cyber-physical-systems.en_SENTbySENT.txt
* [MUSIC] Hello, welcome back
* In the previous lesson, we looked at security requirementsof cyber-physical systems
* In this video lecture, we will learnabout fundamental security concepts and methods that provide security forcyber physical systems
* Confidentiality is one of the mostimportant aspect of security
* Confidentiality refers toprotecting personal privacy and proprietary informationfrom unauthorized access
* It is very important to protect suchinformation from being disclosed to people who are not eligible to access it
* In most of the cases, confidentialityis roughly equivalent to privacy
* In cyber-physical systems due tothe heterogeneous nature of the system and physically observable outputs orevents, information flow is complex, resulting in a greater risk ofconfidentiality and privacy violations
* Encryption is one of the mostefficient methods of protecting confidentiality of data in systems
* Cryptographic solutions, however,involves complex computations that require sufficient amount of computingpower to be applicable in the system
* Using encryption in cyber-physicalsystems has some restrictions due to limited computing andstorage capacity of devices
* And in some cases,also limited energy available for devices
* So in order to deal with this problem, lightweight cryptographicmechanisms should be applied
* Data and cyber-physical systems mustbe encrypted when it is stored or transferred
* In addition to encrypting data, it isalso important to limit access to data
* The proper access control system willguarantee that data is accessible only to authorized people or devices
* Besides controlling logical access tocomputings, resources, network and data
* Also physical access to system components,such as computing hardware, sensors, actuators and even monitor environmentif possible needs to be restricted
* Logical access control is accomplishedby an access control policy
* Some well-known access control policiesare Role Based Access Control or RBAC
* Mandatory Access Control or MAC andIdentity based Access Control or IBAC
* Confidentiality could becompromised in different ways
* For example, a physical networkline could be attacked by wire tapping the line to monitor andrecord network communication
* In this case,if the communication is not encrypted, the data will be accessibleto the attacker
* A password attack is anothertype of confidentiality attack, which exploits passwords usingdifferent cracking tools
* Such tools try several differentcombinations of most commonly used words to crack a password
* This is why choosing a strongpassword is very important
* A strong password is moredifficult to crack for the tools
* You can find some good tips on choosinga strong password on the internet
* Phishing or pharming is anotherway of acquiring passwords and other sensitive information
* In a phishing attack,the victim receives an email or another type of message that appearsto be send by unknown contact
* The email might contain malwareinfected attachments or provide a link to a fake looking page Integrity is another aspect of security
* Integrity involves maintainingthe consistency, accuracy and trustworthiness of dataover its entire lifecycle
* Integrity ensures that information isnot modified by unauthorized entities
* In addition to data,integrity is also required for physical components of systems
* Physical integrity ofa system ensures that the physical devices composinga system cannot be modified
* Tamper proof hardware is one wayof ensuring physical integrity in cyber-physical systems
* Such hardware is resistant againsttampering or deliver a changes
* Physical tamper resistant systemsare developed to process or store critical information
* One way of ensuring dataintegrity is hashing
* Hashing is transforming a largeamount of data, for example, text into a short and a fixed lengthpiece of data called a hash value
* The idea is that the initial data cannotbe obtained based on the hash value
* This means that the hash functionwhich does the transformation is a one way algorithm
* If a single bit is changed in data, the hash function will probably usea totally different hash value
* In order to ensure integrity of data,the hash value of data is computed and kept secret
* To check if data has beenmodified at some point, the hash value is computed andcompared to the initial hash value
* If the two hash values are identical,then the data has not been altered
* Another aspect of integrityis configuration integrity
* We assume here that a system hasa set of functional parameters that can take different values indifferent operating scenarios
* For example, a sensor could be setto be read every ten seconds or data could be set to be streamed tothe cloud sever every five minutes
* If such configurationparameters are tampered with, the system may behave unexpectedly oreven crash
* Therefore, configuration integrityis a very important requirement for security of cyber-physical systems
* A reliable way of ensuringconfiguration integrity is to implement a dedicated secure configurationmanagement system
* Code integrity is alsoof utmost importance
* It means ensuring that the embeddedprogram code running on the components of the systemcannot be altered by an attacker
* Software at this station is a challengeresponse technique that enables checking the integrity of the memory contents ofdevices against malicious modifications
* It could be used, for example, to verifycode integrity of sensors and actuators
* Integrity attacks can have a significantimpact on cyber-physical system
* A single integrity attack mightbe a minor attack, as such
* But if it runs over a long period of timeor on multiple devices simultaneously, it results in a larger andsevere attack overall
* For example, in a salami attack, only various small changesare made at the time
* But if such small changes are madein a large amount of data or devices, it will have a severe impact
* A man-in-the-middle attack is anothertype of integrity attack in which the attacker tries to interceptthe communication between two devices in order to manipulate data
* The man-in-the-middle attack can alsobe considered a confidentiality attack
* Availability is another importantaspect of information security in cyber-physical systems
* Availability refers to ensuringthat authorized parties are able to access information andresources whenever needed
* This means that all componentsof a cyber-physical system, including the sensors, actuators,computing and storage systems, security solutions and communicationchannels must be functioning correctly, so that the system isavailable when needed
* In critical applications, systems needto be available basically all the time
* In some critical systems, the tolerated system downtimecan be less than a few seconds
* Imagine the impact of an interruptioncaused by availability attacks to a critical infrastructure,such as a nuclear power plant
* Availability attacks can targetdifferent parts of the system
* Regarding cyber-physical systems,availability attacks can be highly critical, because of the unsupervised andautonomous nature of such systems
* The most common availability attack iscalled a Denial of Service attack or DoS attack
* DDoS attack, which stands for Distributed Denial of Service attackis a more advanced form of DoS attack
* It is carried out from multiple sources,simultaneously
* DDoS has a higher impact andis more difficult to track, and tackle
* Another way of attacking availabilityof a system is to interrupt electrical power of the system
* Lastly, since several physical systemsare exposed to physical environments and interact with them,physical protection of these systems is also very important toavoid availability problems
* In this lesson, we discuss the basic securityconcepts in cyber-physical systems
* Namely, confidentiality,integrity and availability
* We also learn about potentialattacks against them
* In the next video lecture, we will learn more about attack modulesin the cyber-physical systems context
* [MUSIC]


--- SKIP ---: 01_attack-models-for-cps.en.srt


--- SKIP ---: 01_attack-models-for-cps.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_attack-models-for-cps.en_SENTbySENT.txt
* [SOUND]>> Hello, welcome back
* In this lesson, we will learnabout the common attack models for cyber physical systems andthe mechanisms to mitigate these attacks
* Attacks on cyber physical systems aredivided into passive and active attacks
* In an active Attack, the attackermanipulates the system resources and affects the operation of the system
* Active attacks are carried outwithin a short period of time
* In a passive Attack, the attackersmakes use of the information in the system withoutinterrupting it's operation
* The passive attacks are doneover a longer period of time and are more difficult to detect
* Let's explore differentattacks models in more detail
* Eavesdropping, orSniffing is a Passive attack in which the attacker capturesinformation transmitted in a system
* The attacker aims to obtainsensitive information, such as, passwords, session tokens, orany kind of confidential information
* Eavesdropping, therefore,violates the privacy of users, but it does not effectthe operation of the system
* Let's have a closer look at potential Eavesdropping attacks againstcyber physical systems
* In a wireless communication, an attacker can capture networkpackets with the receiver
* If the communication is encrypted, the attacker then try to breakthe encryption to gain the information
* In physical or wired links, Eavesdropping could be done by analyzingthe Electromagnetic fields of the wires
* In addition to wires, other devices such as displays alsohave Electromagnetic emissions
* That could be analyzedto get some information
* Power analysis is someother way of Eavesdropping, in which the attacker attemptsto capture some information by analyzing the electricalpower usage of a system Now, that we got familiar withdifferent types of Eavesdropping
* Let's see how we can mitigate this attack
* Eavesdropping can be preventedby using strong encryption
* This is very important,especially in wireless communications
* Using smart antennas to limit the coveragearea of wireless access points and using minimal power forwireless transmissions are other ways of mitigatingthis attack in wireless network
* Physical protection of cyberphysical systems is also very important to mitigateeavesdropping attacks
* For example, using shielded wires forphysical links and using special racks or rooms for critical devices are somemethods of physical protection
* Denial of Service, or (DoS),is another common attack model
* A DoS attack is an Active attack in which the attacker Targets the availabilityof the service or system
* Temporarily or indefinitely
* A DoS attack can havea devastating effect on the system
* DoS attacks are carried outby exhausting the systems resources with a lot of valid processes
* In other words,DoS attacks take advantage of valid actions in a system by repeating thoseactions a huge number of times in a row
* For example, in ICMP or internetcontrol message protocol flood attack
* The attacker floods the serverwith several ICMP echo requests or ping packets
* In this case, the server will bebusy to respond to ping requests and this will result in a significantdecrease in its ability to process and respond to its main services
* The main objectives ofDenial-of Service-attacks are, Congesting network resources,Draining CPU memory, Reducing computing power,Exploiting TCP timers Or Poisoning domain name translations
* To make a DoS attack even more efficient, multiple computers can attack on a singledevice or server simultaneously
* This mechanism is called a DistributedDenial of Service attack or DDoS
* DDoS is a multi person,multi device attack that is launched from multiple sources thatare distributed over the network
* DDoS attacks, the most dangerous attacks,and are difficult to track and prevent
* SYN flood attack isan example of a DDoS attack
* In a SYN flood attack,a device or servers attacked with a flat of TCPC synchronizationpackets from multiple sources
* In most cases, to make it difficultto detect the source of attack, the attackers use full sourceAcronises in the scene pockets
* Low-rate TCP targeted attackis another mechanism for DoS
* It exploits the propertiesof TCP timers and results in degrading the throughputof a system close to zero
* In order to make a Denial-of Serviceattack more difficult to trace, an intermediate host can be used forlaunching the attack
* This approach is calledReflective DoS attack
* A Botnet attack is an exampleof a Reflective Dos attack
* A compromised-key Attack is anotherattack model for cyber physical systems
* A compromised-key refers to a secretcode obtained by an attacker to interpret secure information
* The key could be a password forlogging into a system or a session key forcommunication between two devices
* If a key is obtained by an attacker,it is considered a Compromised-key
* In this attack, the sender and receiverusually are not aware of the attack
* Hence, it is considered a passive attack
* So why are cyber physical systemsvulnerable to Compromised-key Attacks
* The vulnerability of cyber physicalsystems to Compromise-key Attacks is based on the specialcharacteristics of these systems
* Cyber physical systemsare Physically accessible, and therefore easier to compromise
* For example, an attacker couldPhysically access a device and obtain a password or a secret key
* Another reason is that due to the Resourceconstrained devices used in a cyber physical system,weaker security measures are implemented
* For devices and communication
* Weak measures are easier to Compromise
* A Compromised-key Attack canbe mitigated in several ways
* First, the system should beprotected from Physical attacks, unauthorized access to the devices,and Physical links should be limited
* Tamper proof hardware can be usein critical devices to prevent an attacker from compromising them incase he gains Physical access to them
* Also, Encryption of the keys and Key life cycle managementare necessary to protect the keys
* Man-in-the-Middle is another commonAttack model cyber physical systems
* In this type of Attack, an adversary interceptscommunication between two parties, captures original messages, and passesaltered messages between the parties
* The attacker impersonates both parties andcontrols communication
* He can, for example, get an originalmessage, change some parameters, and then send the manipulatedmessage to the receiver
* This is an active attack type becauseit affects the behavior of the system
* To mitigate the Man-in-the-Middle Attacks,secure communication protocols should be used to prevent the attackerfrom tampering the messages
* We will look into subscript of graphicsolutions in later video lectures
* In this lesson, we learned aboutdifferent attack models for cyber physical systems and alsodiscussed how to mitigate these attacks
* In the next video lecture,we will look into security issues for real world cyber physical system
* [MUSIC]


--- SKIP ---: 02_security-issues-real-world-cps.en.srt


--- SKIP ---: 02_security-issues-real-world-cps.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_security-issues-real-world-cps.en_SENTbySENT.txt
* [MUSIC] Hello, welcome back to the courseon web connectivity and security in cyber physical systems
* This is the last lesson in the module, introduction to cyber physicalsystems security and privacy
* In the previous lessons of thismodule we have learned about security challenges,countermeasures, and attack models
* In this video excerpt,we will explore security and privacy issues of important real worldcyber physical systems called smart grids
* The next generation of power systemsinvolves a variety of smart devices and technologies, such as smart meters,smart appliances, renewable energy resources, andenergy efficiency resources
* Such devices and technologies are keycomponents of a smart electrical grid
* Security is a critical issue in smartgrids, because they involve critical power facilities through millions ofinterconnected electronic devices
* As you can see on the screen,a grid of renewable energy resources, transmission lines, distribution centers, service providers, and smart electricityconsumers forms a smart grid
* In order to provide a service,information is collected and communicated between the components througha distributed and hierarchical network
* Reliability, safety, andusability of these services are highly dependent on securityof smart grid networks
* Based on its features, the smart grid isvulnerable to different kinds of attacks
* Next, some of the most commonattack types are introduced
* Like many other networksalso the smart grid suffers from denial of service attacks
* These attacks can target differentlayers of the smart grid network in different ways
* In the physical layer, channel jammingis the most common attack type, especially in wireless communication
* Since it's easier for an attacker tointercept wireless communication channels than authenticated networks
* In the media access control ora MAC layer, by spoofing MAC parameters, an attacker has a better chanceto access the network in order to reduce the performance ofshared communication channels, and compromise availability andintegrity of the system
* In the network andthe transport layers, denial-of-service attacks can reduce the end-to-endcommunication performance
* Especially worm propagation andtraffic flooding in these layers can considerably reduce the communicationspeed, and thereby the overall performance of the smart grid
* In the application layer, an attackertargets machine's resources, such as CPU or I/O bandwidth by exhausting resourcesof smart devices and computer systems
* In a smart grid, majority of computing and communication devices are resourceconstrained, and therefore, this kind of attack is very serious andthreatening for a smart grid
* In addition to denial of service attacks,which may target the availability, smart grids are also vulnerableto some other attack types which target integrity and confidentialityof the customer's information
* For example, usage and pricinginformation and also power system values, such as device readings
* Such attacks are more complicated and less brute force thandenial of service attacks
* The risks of integrity attacksare very high and real
* False data injection is an exampleof an integrity attack, which influences both users and suppliers
* In this type of attack the attackercompromises a number of measuring devices toinject false information
* This attack can have a long-term andheavy impact on smart grid systems, resulting in a significantfinancial loss for the suppliers
* On the other hand, attacks which targetthe confidentiality of information are not meant to modify the information,but to gain knowledge aboutsensitive information
* Eavesdropping is one of the mainattack types in this category
* Targeted information is typicallya customer's account number or electricity usage
* Data security andprivacy are a top concern in smart grids
* Utilization of cloud computing fordata storage and processing has caused evenmore problems for smart grids
* Indeed, the wide range and large amountof data originating from multiple sources makes it challenging to guaranteedata security and privacy in the grid
* Especially if data, either public orprivate, has multiple owners
* It is more probable that personallyidentifiable information will be eventually passed andrevealed if not handled carefully
* This naturally compromisesthe privacy of smart grid users
* Similar privacy issues are also present when transforming data byaggregating it from multiple owners
* From the system performance point of view,enforcing security and privacy measures leads tofiner granularity of data
* That is more control informationis embedded in data, and this might cause unacceptablelatencies in some cases
* User-centric access control approaches provide flexibility forthe users to control access to their own data,which is stored in a shared environment
* In these approaches,the access control policies could be set to change dynamicallybased on some external information, such as the social mediaactivities of the users
* Dynamically changingaccess control policies impose a high cost in termsof system complexity
* Due to its nature, the data inthe smart grid needs to be archived for a long period of time
* Storing the data for a long time requiresmore powerful cryptographic solutions, because a computationalability to break cryptographic algorithms increase with time
* In addition, the user's perception andrequirements for privacy can change over time
* With this in mind, the systemshould be designed in such a way that there is a built in tolerance forchanges in security and privacy measures forlong-term archive data
* In this lesson,which concludes the module, Introduction to Cyber-Physical Systems, Security, and Privacy,we looked into some security issues of smart grid networks as an exampleof real world cyber-physical systems
* In the next module, we are going tolearn about cryptographic solutions for securing cyber physical systems
* [SOUND]


--- SKIP ---: 01_introduction-to-cryptography.en.srt


--- SKIP ---: 01_introduction-to-cryptography.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_introduction-to-cryptography.en_SENTbySENT.txt
* [SOUND] Hello, welcome back to the onlinecourse on web connectivity and security in cyber physical systems
* This lesson starts a module ona cryptographic solutions for cyber physical systems
* It is the last module of the course
* In this video lecture,we will look into basic concepts and techniques of cryptography
* Cryptography is a scientific andengineering field which develops and analyzes mathematical techniques for somany different information, security, and privacy issues such as confidentiality,data integrity, entity authentication anddata origin authentication
* Cryptography has a long andfascinating history
* Egyptians used some kind of encryptionin their messages about 4,000 years ago
* In the 20th century,during the World War I and II, cryptography was used to protectsensitive war related information
* Even though the usageof modern cryptography originally focus on military applications,today it's widely use for protecting our digital informationin general, everywhere
* This development began in 1960's andhas been boosted by the proliferation of computers and communicationsystems during the last decades
* The main goal of cryptographyis to hide and protect sensitive information which is called a plaintext,from the adversaries or attackers
* You can imagine that you protect yourbelongings inside a suitcase with a padlock
* The idea is that one needsthe key of the padlock to get the stuff out of the suitcase
* The cyber system essentiallyworks in the same way
* The plain text, is encrypted, using a cryptographic algorithm,which corresponds to the padlock
* The algorithm takes the plain text andencryption key as input, and as a result, a cipher text is generated
* The cipher text is a new form orcombination of the plain text
* It is not readable by a human ora computer without decrypting it
* And therefore, the cipher text canbe safely sent to another party
* On the receiver side, if the receiverhas the right decryption key, he or she will be able to decrypt the ciphertext to discover the original message
* The secrecy of a cipher system is highlydependent on the secrecy of the key
* So, the exchange of the decryption keyshould be done in a very secured way
* From the attackers perspective, the mainchallenge is to determine the plain text from a cypher textwithout knowing the key
* The decryption key does not have toalways be the same as the encryption key
* There are two types of cipher systems,a symmetric key cipher system and an asymmetric key orpublic key cipher system
* In a symmetric key cipher system, the decryption key is identicalto the encryption key
* Or can be easily obtainedfrom the encryption key
* In this case, there is a need fora secure channel for key exchange
* In an asymmetric key orpublic key cypher system, the encryption key is notthe same as the decryption key
* It is computation or in principle and practical to obtain the decryptionkey from the encryption key
* In this case theirs a pairof different keys, one for encryption and the other for decryption
* The encryption key is publicly available,so everyone who has the publickey can encrypt the message
* The decryption key is secret andis referred to as the private key
* So only the one who has the privatekey can decrypt the message
* Establishing a public key cipher systemis computationally more complex and requires more resourcesthan symmetric encryption
* Therefore, it is usually used forshorter messages
* In practice, a public key systemis used for encrypting and transferring the encryptionkey of a symmetric key system
* Symmetric ciphers are far further dividedinto stream ciphers and block ciphers
* In a stream cipher, the plaintext isencrypted bit by bit or byte by byte
* For simplicity,we call this unit of encryption a digit
* So instead of one single key, the stream cipher requires a streamof keys to encrypt every digit
* In this model, the cipher text stream is calculated as an exclusive ora modular to addition of every digit in the plaintext stream withthe corresponding digit in the key stream
* The same key stream is then used for decryption on the receiverside in the similar manner
* The key streams are generated as random orpseudo-random digits
* So, the security of a streamcipher is highly dependent on the key stream generation process
* Stream ciphers are small and fast, and that's why they are suitable forembedded resource constrain devices
* In contrast to a stream cipher,a block cipher uses a single key to encrypt fixedsize block of plain text at a time
* Blocks of cipher textare produced as the result
* Block ciphers are mostly used forencrypting large data
* The most of the well-known and widelyused symmetric ciphers are block ciphers
* These include, for example,the Data Encryption Standard, or DES, triple tests and the more recentAdvanced Encryption Standard or AES
* Block ciphers are first as components indesigning many cryptographic protocols
* The block ciphers can be implementedin different modes of operation, offering different levels ofprotection and performance
* Common examples are The cipherfeedback mode or CFB, the cipher block chaining mode or CBC,and the electronic code block mode, ECB
* We are not going to coverthis mode in this course
* However, you can read more about themon the internet if you are interested
* Breaking a cryptographic systeminvolves finding the plain text without the decryption key
* The attack models of a cyber systemdepend on the amount of information that is available for the attacker
* Based on this the main attack modelsare classified four categories
* It is always assumed that the encryptionalgorithm is known by the attacker
* In a ciphertext-only attack, the attacker has access onlyto the encrypted content
* In a known-plaintext attack,the attacker has access to some plain text ciphertext pairswhich correspond to each other
* In a chosen plaintext attack, the attackerhas access to the encryption process and is able to generate the correspondingcipher text for a chosen plaintext
* In a chosen ciphertext attack, the attacker has access tothe decryption process and is able to generate the correspondingplaintext for a chosen cipher text
* In all of these attack models, the ultimate goal is tofind out the secret key
* In addition to the mentionedattack models, if there is no such information available,the attacker has to try all possible combinations of keysuntil the correct one is found
* This kind of attack is known asan Exhaustive Key Search attack or a Brute force attack
* The Cipher System can not be consideredperfect if the exhaustive search is the only way to find the key
* When designing cryptographic algorithms,the time that a message needs to be in the encryptedform should be taken into account
* This period is called a Cover Period
* For example, in a banks transactiona message needs to be in the encrypted form for a few secondsuntil it reaches the receiver side
* While in a database, a file needsto be kept in a encrypted form for a longer period of time
* The design of a cyber system shouldalways ensure that any type of attack to successfully find the key, would takelonger time Than the given cover period
* In this lesson we learned aboutbasic concepts of cryptography
* We also got familiar with differenttypes of encryption algorithms, and more specifically, we learned aboutsymmetric key cipher systems
* In other video lectures, we will learnmore about public key cryptography
* And its usage forsecuring digital communication
* [MUSIC]


--- SKIP ---: 01_symmetric-key-ciphers-and-wireless-lan-security.en.srt


--- SKIP ---: 01_symmetric-key-ciphers-and-wireless-lan-security.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_symmetric-key-ciphers-and-wireless-lan-security.en_SENTbySENT.txt
* [MUSIC] Hello, welcome back
* In this lesson, we will learn aboutcommon security approaches and protocols forwireless local area networks
* These approaches are based onsymmetric key cryptography
* Wireless local area network,Wireless LAN, or Wi-Fi provides more flexibilityin setting up a network system
* In a cyber physical system, which mayinclude a very large number of sensors and actuators Wi-Fi or some other wireless technology is the mostpractical means of communication, because of its cost efficiency and easierintegration with other network components
* However, it can be the mostvulnerable component of a system, if it's not securely implemented
* As information is transmitted throughthe air, an attacker has potentially better chances to intercept thetransmission and capture sensitive data
* Wired Equivalence Privacy orWEP is a cryptographic security protocol, which was included in the I tripleE 802.11 wireless standard in 1999
* WEP provides wireless security bysimulating physical access controls
* However, WEP is a weak method,and its password can be broken in a few minutesusing available hacking tools
* WEP uses Rivest Cipher 4 or RC4 stream cipher for encryption
* WEP was implemented in threeversion with different key sizes
* In each version, a 24 bit random orpseudorandom initialization vector IV is contaminated with the keyto generate the RC4 keystream
* RC4 is a simple andfast bit-oriented stream cipher, which has demonstrated manysignificant vulnerabilities
* For this reason, WEP standard is not usedanymore for secure wireless communication
* In order to address the problemscaused by the weaknesses of WEP, that is to improve the security of Wi-Fi, an I triple E draft standard wasdeveloped and named 802.11i
* In it's 2003 version,the Wi-Fi Protected Access protocol or WPA was introduced as a moresecure replacement for web
* Like WEP, also WPA uses the RC4stream cipher for encryption
* However in WPAa Temporal Key Integrity Protocol or TKIP uses the hash function tomix the initialization vector, IV with a preshared key rather thansimply concatenating them like WEP
* This reduces the effectivenessof the related key attacks
* For further assurance, the size ofan initialization vector is doubled from 24 bits to 48 bits
* Meaning, in practice, that the reuse timeof an initialization vector increased from a few hours of WEPto a few hundred years
* Moreover, by implementinga packet sequence number, WPA provides protectionagainst reply attacks
* It also provides a stronger messageintegrity check called Michael compared to WEP, which uses basic CRC orcyclic redundancy check
* WPA uses the same hardware as WEP forencryption in the access points
* Despite its features also WPA suffersfrom many security vulnerabilities and is currently consideredan unsecure protocol for Wi-Fi
* This the block diagramof the WPA protocol
* As we discussed earlier, WPA offersbetter security compared to WEP, by using a hash function formixing pre-shared keys and initialization vectors, devisinga sequence counter to avoid reply attacks, and using a better dataintegrity check algorithm
* Because of the vulnerabilitiesof the WPA protocol, a new security protocol calledWPA2 was introduced in the 2004 version of the I triple Edraft standard 802.11i
* It provides strong security for Wi-Fi
* WPA2 is based is based ona new encryption method called Counter Mode Cipher Block Chaining MessageAuthentication Code Protocol or CCMP, which usesthe Advanced Encryption Standard, AES
* AES is a proven strong block cipher, which was published in 2001 by NationalInstitute of Standards and Technology
* It is still widely used
* Hardware implementation of WPA2 requires additional components in wireless devices, because unlike WPA,it cannot utilize WEP hardware
* Both WPA and WPA2 offer two authenticationmodes, personal and enterprise
* In the personal authentication mode,a pre-shared key is used as a password
* Hence, they are vulnerableto weak passwords
* In the enterprise mode,a more advanced authentication called extensible authentication protocol orEAP is used
* You can easily find furtherinformation on WPA2, its related protocols andauthentication modes in the Internet
* In this lesson, we learned about differentwireless LAN security mechanisms, and more specifically we learned about WEP,WPA and WPA2 protocols
* In the next video lecture, we will havea closer look at public key cryptography
* [SOUND]


--- SKIP ---: 02_public-key-cryptography.en.srt


--- SKIP ---: 02_public-key-cryptography.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_public-key-cryptography.en_SENTbySENT.txt
* [MUSIC] Hi, welcome back
* Previously, we introducedcryptography as a tool for security solutions incyber physical systems
* We also presented how symmetry key ciphersare used for securing wireless networks
* In this video lecture, we will learnhow public key cryptography works, we will have a close look atthe well-known RSA algorithm
* Public key cryptographycomprises a set of algorithms that are designed based onsome mathematical problems
* As we discussed earlier,unlike in symmetric cryptography, in public key cryptography the decryptionkey is not the same as the encryption key
* And for this reason it is alsoknown as asymmetric cryptography
* A pair of key is called a public key anda private key are used in such a system
* The public key,as it is clear from its name, is publicly known by everybody andis used for encryption, while the private key iskept secret and used for decryption
* So anybody can encrypt the messagewith the recipient's public key, but only the recipient can decryptit using his or her own private key
* This eliminates the need for a secure channel to exchangethe key between two parties
* In a public key cryptography, the keypairs are mathematically related, but it is computationally infeasible to get thedecryption key from the encryption key
* Let's have a brief lookat some important and popular public key encryption algorithms
* The Rivest-Shamir-Adlerman orRSA algorithm is one of the most practical andsecure public key algorithms, which is widely used forsecure communication
* RSA, which is named after its threeinventors was published in 1977
* It provides three main functionalities, key generation, encryption,and decryption
* Diffie-Hellman, or DH protocol, provides an efficient and secure wayof exchanging an encryption key often symmetric cipher through a public channelwithout any need for a secure channel
* Diffie-Hellman is one ofthe earliest applications of public key encryption,published in 1976
* This protocol is stillused in many applications
* Elliptic Curve Cryptography or ECC provides an alternative mechanism forpublic key encryption
* It was introduced in 1985
* ECC is based on algebraic ellipticcurves over finite fields
* And offer smaller keys witha reasonable level of security compared to other publickey encryption algorithms
* It is therefore known asa lightweight encryption method
* ECC is widely use in embeddedresource constraint devices and provides many applications ofpublic encryption such as, encryption and decryption, digitalsignatures, and digital certificates
* To demonstrate how a public keysystem mathematically works, we will first have a bit closer lookinto the popular RSA algorithm
* In another lecture, we will also havea look at the Diffie-Hellman algorithm
* We use these classic algorithms asexamples, because they are well known and relatively easy to presentin a short lecture
* If you are interested in details of ECC,I encourage you to search for related online documentation
* There is a lot of information onECC in a reader friendly forum
* The complex mathematics behind ECCis out of the scope of this course
* So, let's look at RSA
* We start with generation of the public andprivate keys
* The first step is to choose tworelatively large prime numbers p and q
* Typically, 1,024 bits or more in length
* The next step is to calculateproduct of n of p and q, and product phi(n) of (p-1) and (q-1)
* N later becomes the modulusof the public and private keys, which we will see shortly
* Now, the encryption key e is chosen insuch a way that it needs two properties
* First, e has to berelatively prime to phi(n)
* Second, e has to be greater than 1 andless than phi(n)
* Two integers are relatively prime ifthey share no common positive factors or divisors except 1
* In other words, the greatest commondivisor of e and phi(n) must be 1
* We use a tuple notation for the greatestcommon divisor as shown on the screen
* Now our public key is the pair of e and n
* Let's see how the privatekey is calculated
* If e and phi n are prime,then there is some integer d for decryption, such that e timesd equals one modular phi(n)
* Our private key is then definedas the pair of d and n
* Notice that without knowing p and q it ispractically impossible to determine d
* Security of RSA relieson this observation
* Now that we have generated the keys,we can encrypt and decrypt a message
* In RSA, a full message ispresented as a sequence of positive integers between 0 and n-1
* Each taking a fix number of bitsdepending on the value of the modulus n
* The same applies tothe produced cipher text
* For simplicity,let's consider a message m, which is composed of a singleinteger between 0 and n- 1
* For encryption, we take the message m and compute the ciphertext c as mto the power of e modular n
* For decryption we takethe cypher text c and compute the message m as cto the power of d modulo n
* Now let's try an example
* Suppose our two primes, p andq, are 5 and 11 respectively
* Then n is equal to 55,and phi(n) is equal to 40
* Now we should selectthe encryption exponent, e
* Divisors of phi(n) are 1,2, 4, 5, 8, 10, 20, and 40
* So, it could be any number less than 40, which has no common divisor with 40
* Of the candidates, well, let's pick seven
* We should now selectthe decryption exponent d, such that d times e equals 1 mod 40
* Let's pick 23,which satisfies the given condition, because 23 times 7 equals 161, which equals 4 times 40 plus 1
* Determining d is computationallya non-trivial task
* The best way is to usethe extended Euclidean algorithm
* We don't study this algorithm here though
* So, here it is,our public key is the pair 7, 55, andour private key is the pair 23, 55
* Now, let's check how encryption anddecryption work
* First, our message m could beany integer between 0 and 54
* Let's randomly pick the number 8
* For encryption to get the ciphertext c,we calculate 8 to the power of 7 modulo 55,which equals 2
* So our ciphertext c is 2
* Let's then decrypt the cypher text and see if we get our original message orplain text in or not
* We calculate 2 to the power of 23,modulo 55, which, amazingly, equals 8
* So it worked, we managed toretrieve the original message m
* In this lesson, we learned aboutbasics of public key cryptography
* Moreover, we saw how we canprotect confidentiality of data by RSA public key encryption
* In the next video lecture, we will learn how public keyencryption is used for establishing a shared secret between two partiesthat don't know each other previously
* [SOUND]


--- SKIP ---: 03_diffie-hellman-key-exchange-protocol.en.srt


--- SKIP ---: 03_diffie-hellman-key-exchange-protocol.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_diffie-hellman-key-exchange-protocol.en_SENTbySENT.txt
* [SOUND] Hello, welcome back to the videolectures on web connectivity and security in cyber physical systems
* In this video lecture, we are going tolearn how two parties that don't know each other previously can share a secretthrough a public medium like the Internet
* The shared secret could be and often is the encryption key ofa symmetric key cipher system
* The Diffie-Hellman key exchange algorithm was published in 1976 as one ofthe first public key protocols for securely exchanging cryptographickeys over public networks
* The algorithm is based onthe concept of discrete logarithms
* Diffie-Hellman is not an actualencryption algorithm, meaning that it's not used to protectdata transfer between two parties
* Let's explore howthe Diffie-Hellman protocol works
* Suppose that Alice and Bob don't knoweach other and they would like to share an encryption key of a symmetric cipher inorder to initiate secure communication
* To do this, first, Alice andBob have to agree on two numbers, a sufficiently large prime number p and a base generator g,which is a primitive root modulo P
* Alice chooses a secret number or key a and computes her public result, capital A, as g to the power of a mod p andsends it to Bob
* Bob also chooses a secret number orkey b and computes his public results,capital B, as g to the power of b mod P andsends it to Alice
* At this point,a potential attacker may intercept their communication andget the public results A and B
* He might also capture p and g when Aliceand Bob are agreeing on these numbers
* Now, Alice computes a shared secret S1 with her secret key a as Bto the power of a mod p
* And, likewise,Bob computes a shared secret S2 with his secret key b as A tothe power of b mod p
* It can be mathematically proven thatS1 and S2 actually have the same value
* This shared number is Alice's andBob's shared secret and can be used as an encryptionkey of a symmetric cipher
* Because the attacker doesn'tknow the secret keys a and b, he will not be able tocompute the shared secret
* We just learned how Diffie-Hellmanis implemented mathematically
* Let's have a simpler example in orderto demonstrate how the protocol works
* Suppose Alice andBob know a common color yellow
* Alice chooses pink color and Bob choosesgreen color as their secret colors
* Alice mixes her secret color withthe common color and produces a new color
* Bob also does the same
* They exchange the new colors
* Now they mix the new colors withtheir secret colors and produce yet another color
* Since the final color on each side is madeof the same combination of three colors, yellow, pink and green,it is identical on both sides
* So, Alice and Bob ended up with the samefinal color without revealing their own secret colors to each other
* As you can see on the screen,the same thing happens mathematically
* The final values computed on eachside are actually identical
* Diffie-Hellman is one of the mostpowerful security protocols and is therefore still widelyused in many applications
* For resource constraint devices,the Diffie-Hellman protocol can be implemented using ellipticcurve cryptography
* If you are interested to learn more aboutlightweight Diffie-Hellman protocols, you can search on the web forelliptic curve Diffie-Hellman
* You will find many usefultutorials on this topic
* In this video lecture, we saw how the Diffie-Hellman protocolis used to share secret information
* In the next lesson, we will learnhow to establish a public key crypto system to securedigital communication
* [SOUND]


--- SKIP ---: 04_digital-signatures-digital-certificates.en.srt


--- SKIP ---: 04_digital-signatures-digital-certificates.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_digital-signatures-digital-certificates.en_SENTbySENT.txt
* [MUSIC] Hello, welcome back
* In this lesson, we will look intothe concept of public infrastructure, and learn about its twoimportant applications, namely digital signatures anddigital certificates
* A public key infrastructure, or PKI, is a fundamental component of manysecurity protocols of the web
* A PKI is a collection of all software,hardware, people, policies, andprocesses that aim to manage, generate, distribute, and revoke cryptographickeys and digital certificates
* Digital certificatesare documents that are used to prove the ownership of public keys
* Public key cryptographyis a powerful tool, which is widely used inmany security solutions
* One of the most important uses ofpublic key cryptography is to provide confidentiality for the informationin electronics communications
* This is made possibleby encryption of data
* Public key cryptography can also beused for the following purposes
* First, ensuring the integrity ofdata in digital communication
* Second, identification and authentication
* Third, ensuring non-repudiationin digital communications
* Non-repudiation associatesthe actions to individuals, so that they cannot denythe actions they have performed
* Fourth, facilitatingthe establishment of trust between two parties thatdon't know each other
* Fifth, sharing a session keyin encrypted communication
* As symmetric encryption is faster andcomputationally simpler, the actual data is typicallyencrypted using symmetric ciphers
* While asymmetric orpublic key ciphers are used for exchanging encryption keys of symmetricciphers in a communication session
* Next, we are going to learn howpublic key encryption is capable of providing these solutions
* Along with encryption of data or sessionkeys, which provides confidentiality, public keys systems can also be used formaking digital signatures
* Similar to normal signature on a paper,a digital signature is a technique for providing authentication andnon-repudiation for the sender and ensuring integrity of data inelectronic communications
* Let's see how a digital signature works
* Suppose Alice andBob want to communicate with each other
* Both of them have a pair of keys,including one public key and one private key
* Alice has Bob's public key
* So, as she can encrypt hermessage using his public key and send the encrypted message to him
* As we have mentioned in another lecture,no one, including Alice herself, can decrypt the message, except the onewho has the corresponding private key
* So, Bob receives the message, anddecrypts it with his private key
* In fact, anyone who has Bob's public keywill be able to communicate with him, so Bob needs to make sure thatthe message was really sent by Alice
* In a paper based communication,Alice could sign the paper so that Bob could authenticateher with her signature
* Likewise in digital communication, Alice needs to associate herdigital signature with her message
* To do that she computes the hashvalue of the whole message, which is called message digest
* Then she needs to encrypt the messagedigest using her private key
* The result is Alice's digital signature
* The message itself is encryptedwith Bob's public key
* Now she can append the digitalsignature to the encrypted message and send it to Bob
* Bob receives both message andAlice's digital signature
* First, he decrypts the messageusing his own private key
* Then he computes the messagedigest of the received data, using the same hash function as Alice
* Then he decrypts the digitalsignature with Alice's public key and gets the message digest
* He then compares the two versions ofthe message digest with each other
* And if they are identical, Bob can conclude that the messagehas been sent by Alice
* Moreover, he can also ensurethat the message has not been altered before he received it
* Since Alice has signedthe message with her private key, anyone who has her public key canverify if she has sent the message
* Therefore, she will not beable to deny her signature
* This guarantees non-repudiationof Alice's message
* So, we learned how a digital signature,which employs public key encryption, can ensure authenticity,integrity and non-repudiation
* Now, consider the same Alice andBob scenario
* Before communication starts,Alice needs to get Bob's public key
* Imagine that before Alice hasreceived Bob's public key, an adversary breaks into the system andsends Alice another public key, which he has created pretending to be Bob
* So the question is, how can Alice authenticatethe public key she has received
* How can she be sure thatit really belongs to Bob
* Well, the solution is rather obvious
* Alice can rely on a trusted thirdparty to certify Bob's public key
* This third party is calleda certificate authority, or CA
* And the document that containsthe verified public key is called a digital certificate
* CAs are usually companies that issuecertificates and charge their customers
* Let's see how a digital certificate works
* Suppose that Bob wants tosend his public key to Alice
* Both Alice and Bob know a CA and trust it
* So Bob sends his public key and his identification information to the CA
* The CA verifies BobР Р†Р вЂљРІвЂћСћs identity,and then generates a certificate, which contains Bob's public key andsome additional information
* The CA signs the certificate withits private key and sends it to Bob
* Now instead of sendingthe public key as such, Bob sends his public keycertificate to Alice
* Alice can then check the certificate and get Bob's authenticpublic key by decrypting the CA's signature in the digitalcertificate with the CA's public key
* The CA manages public keysit has certified by, for example, revoking compromised keys and setting validation andsuspension periods for keys
* This kind of status informationis part of a certificate
* In this lesson,we learned how public key encryption and mechanisms that use public key encryptioncan ensure authenticity, integrity, non-repudiation, and establishmentof trust between two parties
* In the next video lecture, we willlearn how the public key infrastructure can be used in communication securityprotocols such as DLS, SSL, and DTLS
* [MUSIC]


--- SKIP ---: 05_transport-layer-security.en.srt


--- SKIP ---: 05_transport-layer-security.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_transport-layer-security.en_SENTbySENT.txt
* [MUSIC] Hello, welcome back,this is the last lesson in the module Cryptographic Solutions forCyber Physical Systems
* It also concludes the course,Web Connectivity and Security in Cyber Physical Systems
* In this final video lecture, we willlook into the transport layer security protocol, what it is, and how it works
* Transport Layer Security orTLS is a cryptographic protocol, which facilitates secure communication ornetworks
* The predecessor of TLS is calledSecure Socket Layer or SSL
* In fact,also TLS is often referred to as SSL, because both of these protocolsoffer the same basic functionality, and the first version of TLS is heavilybased on the last version of SSL
* TLS provides a securedtunnel between two hosts
* The primary goal of TLS is to provideprivacy and data integrity between communicating applications, for example,between web browsers and web servers
* The TLS protocol is implemented ontop of a reliable transport protocol, such as the transmission control protocol,or TCP
* Or a datagram-oriented transport protocol,such as the User Datagram Protocol, UDP, and the Datagram CongestionControl Protocol, DCCP
* The TLS protocol is composedof two base protocols, called the Handshake Protocol andthe Record Protocol
* Information transferred through TLS isprotected using symmetric cryptography
* Unique keys for symmetric encryptionare generated for each session and exchanged using the handshakeprotocol at the start of the session
* The handshake protocol enables the clientand server to authenticate each other and select an encryption algorithmprior to sending the data
* The handshake protocol uses the public keycryptography to establish a shared secret key for symmetric encryption between aclient, which is usually a web browser and a server,which provides a service to the client
* In addition to the shared secret key,the handshake protocol also exchanges some other information,such as message formatting instructions
* Suppose you are trying to buysomething from the Amazon website, to start a secure transaction, a TLS or SSL connection is established betweenyour browser and the Amazon server
* First, your browser sends a hellomessage to Amazon server to request for a TLS or SSL connection
* This message also includessome essential information, such as session id anda list of cipher suits
* That is combinations of cryptographicmethods supported by your system
* Then the server chooses one of the offeredcipher suits, and sends a server hello message, which includes acertificate and the selected cipher suite
* The certificate containsthe servers public key, which is verified andsigned by a certificate authority
* In some cases, the server might wantto also authenticate the client
* In this case, it sends also an authentication requestas part of the server hello message
* Once your browser has received the serverscertificate, it will verify and validate the certificate
* Then if everything is all right, thebrowser will generate a session key and encrypt it with the server's publickey and send it to the server
* Handshaking has now been completed
* And your browser and the Amazon serverare ready to start a secure communication
* The second part of the TLSprotocol is the record protocol
* After establishing a shared secretkey using the handshake protocol, the record protocol provides a securecommunication session between the client and the server usingthe shared secret key
* The record protocol hasmultiple responsibilities
* First, it splits the message, which itreceived from the application layer into fixed size blocks of data
* Compresses them if required, and then addsa Message Authentication Code or MAC
* This is not to be confused with the MediaAccess Control Concept at the link layer
* A MAC has the same functionas a digital signature
* It is used for message authentication andintegrity checking
* A digital signature is generatedby using public key cryptography to encrypt a hash value of a messagewith a sender's private key
* A MAC is also obtained by encryptingthe hash value of a message, but now a shared symmetric key is used
* Since symmetric cryptography is use fora MAC, it is faster to generate and verify it in a normal digital signature
* After generating andappending the MAC, the record protocol encrypts the message blockwith the shared symmetric key
* As the last step, it adds a TLS header and sends the message blockto the other party
* On the receiver side, the message blockis first decrypted using the shared key
* Then its authenticity and integrityare verified by comparing the MAC computer from the received message blockwith the one appended to the block
* TLS or SSL secure connections are widelyused in contemporary websites
* If a website uses such a connection,HTTPS appears in the beginning of the web address, which indicates thata secure connection has been established
* HTTPS stands forHypertext Transfer Protocol Secure
* Typically, there's also a smallpadlock icon beside the address line
* If you click on the padlock, you will seeinformation about the secure connection in question as well as the certificate whichthe website has sent to your browser
* If the certificate becomes invalid forsome reason, you will notice a red line acrossthe HTTPS acronym indicating that the connection is still secure,but the server cannot be verified
* A normal HTTP connection is establish when the web address in your browserbegin with the HTTP acronym
* And there is no padlock icon present, indicating a connection whichis not secured by TLS or SSL
* Digital certificates and information on their issuingauthorities are stored in your browser
* You can simply check them inthe settings of your browser
* For example,in this imageyou see Firefox settings
* If you click on View Certificates,in the advanced menu and certificate tabs, you will see the list of certificateauthorities and their issued certificates
* Protocol such as sessioninitiation protocol, or SIP, and electronic gaming protocolsare getting more and more popular
* Such protocols are based onthe user datagram protocol or UDP and require secure communication
* Datagram-based protocolscannot directly use TLS, because of their delay-sensitive nature
* The Datagram TransportLayer Security Protocol, or DTLS,is a natural extension of TLS over UDP
* With maximized reuse of code and infrastructure to minimize the need fornew security invention
* Like TLS, also DTLS is designedto provide communication privacy with equivalent securityguarantees for datagrams
* TLS is inefficient fordatagram-oriented transport protocols, because due to the inherentfeatures of DTLS, possible lost or out of order packets can causeunpredictable communication delays
* This is not acceptable or tolerable fordelay senstive UDP based applications
* A TLS handshake breaks if the handshakemessages are not delivered reliably or in order, or are lost
* To solve this, DTLS assignsa specific sequence number for each handshake message withinthe handshaking process
* It also uses a simple retransmissiontimer for each message
* Once a receiver receivesa handshake message, it determines, by checking the sequence number,if the message is in order or not
* If the right sequence number is detected,the message is processed
* Otherwise, it is queued forfuture delivery
* A queued message is processed only whenall previous messages have been received
* On the sender side, if the sender doesn'tget any reply for its handshake message before the retransmission time runs out,it will resend that specific message
* The record protocols of DTLS andTLS are very similar
* The difference is that DTLS uses sequencenumbers to re-order out of order packets
* This concludes our courseon web connectivity and security in cyber physical systems
* We started with the basics of theinternet, and learned about its layered structure and involved communication andconnectivity protocols
* Then we learned how to design webconnected cyber physical systems
* We also learned that cyber physicalsystems have a close relationship with Internet of Things andcloud computing
* In the security segment of the course, we learned about the basic concepts andcomponents of security and privacy, and so how cryptographic solutions canbe used to secure your system
* That's it,I hope you have enjoyed the course
* Thanks for attending, bye, bye
* >> [SOUND]


--- SKIP ---: 01_the-big-game.en.srt


--- SKIP ---: 01_the-big-game.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_the-big-game.en_SENTbySENT.txt
* Finally as an exercise in using some ofthe concepts introduced in this section, let's consider the following problem
* Stanford people always tell the truth and Berkeley people always lie
* Unfortunately, by looking at a person you cannot tell whether he is from Stanford or Berkeley
* You come to a fork in the road and want to get to the football stadium down one fork, or you did not know which road to take
* There is a person standing there
* Whatsingle question can you ask him to help you decide which fork to take
* There are anumber of ways to approach this problem most interesting involves a question inwhich a person is asked
* How we would answer if you were from Stanford or if youwere from Berkley
* However, we can also approach this problem without entertainingsuch meta-level questions
* Let's draw out a table with the set of all possiblestates of affairs, and leave columns for the question we want to ask and theresponse we want to receive
* We want to ask a question that will list of one response.Let's say true or one, if the stadium is to the left, and a different response, Forexample, false or zero, if the stadium is to the right
* Note that the responsein each case may differ from the actual truth of the question depending on whetherthe informant is from Stanford or from Berkley
* Now, let's see what the actualtruth value or question must be to have elicited this response
* If the stadium isactually to the left, and the informant is actually from Stanford, then we want aquestion that has value true
* If the stadium is not to the left, and the informant is from Stanford, then we want a question with truth value false
* So itstands that if a person's going to tell the truth the value should be the same asthe values in our response
* The opposite is true for the Berkley case, cases, ifthe stadium is to the left and the informant is from Berkley, we want aquestion the has truth value of false since the informant were lying
* If thestadium is not to the left and the informant is from Berkeley then we want aquestion that has truth value true
* Now looking at our operator semantics tables, we seethat this is exactly the set of true values assigned to the sentence left, ifand only if SU, Stanford
* So we can phrase this as a question as follows
* Is it thecase that the left road is the way to the stadium if and only if you are fromStanford
* Okay, that's not a particularly clever or simple question, but it willellicit the right response
* Importantly the example illustrates that it's possibleto solve problems of this sort using just the concepts we have seen so far.


--- SKIP ---: 01_box-logic-out-of-focus.en.srt


--- SKIP ---: 01_box-logic-out-of-focus.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_box-logic-out-of-focus.en_SENTbySENT.txt
* In this segment we're gonna take a look atbox logic
* Unfortunately, we cannot do that here on the studio so we're gonnahave to take a road trip
* Today we're headed for Stanford University's renownedlogic laboratory
* Follow me
* And here we are
* This is the logic laboratory
* It maynot look like much at least not superficially but this is where weinvestigate some of the latest innovations in logic technology
* Today our goal was tolook at box logic
* Now the language of box logic is pretty simple
* There are reallyjust three constants
* There is large box, there is medium box, and there is smallbox and they are all oriented one way or the other
* Forming compound sentences fromour consonants is easy
* If we want to negate a sentence, we just invert
* Notmedium box, medium box
* If you want this form of this junction from our constants,we stack them up
* So here we have small box or medium box
* And a conjunction isformed simply by placing multiple boxes or stacks of boxes on our table
* So it'seffectively colossal for
* Okay
* Now, let's try to use our logic to solve someproblems
* How about the problem case of Mary Patton Quincy
* We call that
* If it'sMonday, Mary loves Pat or Quincy and Quincy, if Mary loves Pat, Mary lovesQuincy
* Let's see how we can represent that information using our new language.So first of all, if Mary loves Pat, Mary loves Quincy let's, let this medium sizedbox represent the fact that Mary loves Pat
* This one represents Mary loves Quincyand the large one is going to be Monday
* So we wanna say, if Mary loves Pat, Maryloves Quincy
* How do we do that
* Recalling the rules for converting to colossal form,we know that p implies q as equivalent to not p or q
* So if you wanted to writethat, we would write not Mary loves Pat or Mary loves Quincy
* So, not Mary loves Pator Mary loves Quincy
* If Mary loves Pat, Mary loves Quincy
* How about our othersentence
* If it's Monday, then Mary loves Pat or Quincy
* It's Monday, let's see
* Weneed to say not Monday or Pat or Quincy
* So it's not Monday mo re quick copies
* OrPat or Quincy
* So there we have it
* If it's Monday, Mary loves Pat or Quincy
* IfMary loves Pat, Mary loves Quincy, represented, representing the premises ofthe problem
* Now you may recall that the object of the problem was to show that ifit's Monday then Mary loves Quincy
* So how could we do that
* What we have done isrepresenting but we can also do computation, deduction with box logic
* Anyrules are pretty simple
* If we ever have one stack which has a constant
* Literalwhich is the complement of literal on another stack, we can do resolution onthem
* So here we have one stack with medium box down, here one stack withmedium box up
* We can combine the two stacks and eliminate the complementaryliterals and form these answers and since it's a duplicate, we can throw that oneaway and we're left with our conclusion
* If it's Monday, Mary loves Quincy, nifty.Okay, what's the point
* The point is that the language of logic is not aboutparticular sets of symbols
* And the active deduction doesn't mean necessarily thatwe're operating upon those particular symbols
* Logic is an abstraction
* Anyinstantiation of the symbols is equally good and any operations on them is equallygood provided that it respects that basic abstraction
* Okay
* That's it for our visitto the logic laboratory today
* We'll be back again later in the course with someadditional demonstrations and we'll see you then.


--- SKIP ---: 02_control-of-mobile-robots.en.srt


--- SKIP ---: 02_control-of-mobile-robots.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_control-of-mobile-robots.en_SENTbySENT.txt
* Welcome to the course Control of MobileRobots
* My name is Magnus Egerstedt, and I'm aprofessor at Georgia Tech in the school of Electricaland Computer Engineering
* And I am delighted to be able to todeliver this, this course to you
* The focus of the course is, how do youmake mobile robots move in effective and safeand predictable ways
* Meaning that they don't slam intoobstacles, they move smoothly and nicely without having weird oscillationsin their motions
* And the trick to achieving this issomething called control theory
* An this first module of the course is going to focus on controls and controltheory, and what it is, and what the pieces are that you need to be able to actually controlrobots
* Before I dive in, though, I wanted to saya few words about myself
* My research hammer is control theory, so that, as I'vealready said, deals with how do you make things move or behavewell
* This could be stock markets
* This could be cruise controllers
* This could be limiting the spread of epidemics, for instance, usingvaccination strategies
* So control theory doesn't really have atight, necessary coupling to robotics
* It's a general language for describing howthings behave
* Now, if that's my hammer, my nail isrobotics
* And I'm very, very interested in how do you make robots do elegant and usefulthings
* And, in my lab, we do really threedifferent types of robotics
* One is swarm robotics
* So how do you get lots and lots of robotsto do exciting things together
* The other is something called behaviorbased control, or behavior based robotics
* And we will see quite a bit of this inthis course
* Behavior is basically a controller that's in charge of something, like, goingtowards a landmark, or not slamming intoobsticles, or following cooridors, or things likethat
* And the question is: how do you design these behaviors and how do you patch themtogether
* The third thing that I'm interested in isfield robotics
* Meaning how do you take robots and putthem out in the unstructured, strange world outside ofthe lab, meaning, if you have a robot driving through the forest,all of a sudden there are no corridors or hallways or doors andlife becomes much more complicated
* So, before we start, I wanted to show alittle video that came out of my lab a few yearsago
* So, here, this is is an example of swarmrobotics
* We have 15 robots that have been asked tospell grits
* And grits stands for Georgia Robotics andIntelligence Systems
* That's the robotics lab that I'mdirecting
* And, these robots have to figure out wherethey should go in the letter
* They need to figure out how they should gothere and they need to figure out how to go there withoutslamming into each other
* So, what's going on there is controldesign at multiple levels of abstraction
* One each, one is the high level, whereshould you go
* Then you have the lower level which dealswith, okay, I know where I want to be
* How do I actually get there withoutdriving into other robots, for instance
* And as you can see, these robots, with very limited information, meaningthey don't really know where every other robot is, theyfigure out where they should go in thisformation
* And this video I like for multiplereasons
* One is, because there's a lot of controltheory going on underneath the hood
* And the second is, you will be able to dothis at the end of this course
* So, let's talk a little about the course
* Control theory will play a key role, meaning, how do you actually controlsystems
* And this will be done decoupled fromrobotics
* But then, we're going to couple in therobotic applications by looking at robot models, because not allrobots are the same
* Some are hopping
* Some are slithering.Some are rolling
* Some are flying
* And different type of robots requiredifferent type of controllers
* We're going to look in general atmobility, meaning, how do you make the robots move
* That's the main question we're interestedin, in this course
* And then we'll end with applications
* So, what can you actually use these robotfor, robots for and where do we need the kinds of solutions that wewill be going through in the course
* I do want to say though, that the courseis not about artificial intelligence, whichis the high level planning, meaning what should the robots actually bedoing
* We're going to be dealing with thequestion of, when they've already figured out what they should be doing, how shouldthey be doing it
* We're not going to deal much withperception, meaning how do we take computer motion, data and actuallyturn it into something actable
* Or how do we actually design perceptionalgorithms
* We're going to assume that someone elsehas done this
* And we're going to act on the perceptualdata that we already have
* And it's not a mechanical engineeringcourse
* Meaning, we're not going to be buildingrobots or dealing with different kinds of roboticdesigns
* However, there is a slight little caveatto that
* Because we will indeed be looking at somehardware aspects of robotics
* Here is a video from a course I taught oncampus at Georgia Tech
* And, this is a robot that's running a lot of the things that we're learning in this course, meaningit's figuring out how to get to a landmark, in this case, apurple little tape mark on the floor
* But it has to do it while avoidingobstacles
* So, it has to design different controllersfor different situations
* For instance, the left robot is not doingso well
* The right robot here is doing even worse
* It's slamming into things
* But the point is that, at the end of thiscourse you will be able to do this
* Hopefully better than what we are seeingright now, because the robots are all over theplace
* Here we're seeing some otherinstantiations of this
* See how the robot is oscillating a little bittoo much, but it is able to navigate the, the cardboard box and, well, the right robot is driving intochairs
* The other robot seems to be a littleconfused
* So, these are examples of roboticcontrollers that aren't perfectly tuned and perfectlydesigned
* Let's look at a final race
* We're going to see what the outcome would be if you'd done the control designproperly
* See, they're going straight.There's very little oscilation
* Well, one robot is oscilating but thepurple robot there seems to be doing really well, goingquite straight
* And this, in my mind, is a successfulrobotic control design
* So, what is actually in the course, or howis this structured
* Well, we're going to have lectures
* There're going to be eight mini lectureseach week
* And, there are going to be seven weeks intotal
* Each week will be capped by a quiz
* And, there will also be glue lectures
* So, lectures that are designed to gluewhat I do, my slides, to the actual quizzes
* And then, as a bonus, there will beadditional material
* This is not mandatory
* But if you do it, your experience will nodoubt be more enjoyable
* First of all, we have a robotic simulator that we use in the lab called Sim.I.am
* It runs on MATLAB and this will be part of the course, meaning you can do it if youwant to
* Few words, MATLAB, is the programenvironment we are using because this is one of the standards inthe engineering world
* Now, you will be able to get MATLAB for free as a student license through thiscourse
* So this will come at no extra cost to you
* But then, we'll also map this onto a realhardware platform, where, if you're interested youbuild your own robot
* Because, I truly believe that there' snothing more exciting than doing the theory right, and then seeing thingsmove in the real world
* So, if you follow along the course, do thesimulatin and also build the robot
* At the end, you will have an awesome platform that can actually run around inthe world without slamming into things
* Before we do this though, I want to makeone minor or maybe even major disclaimer
* To do robotics right and to do controltheory right there is no way around the fact that youneed math
* So mathematics will play a key role
* And this may be a little uncomfortable tosome of you at first but we're doing it for areason
* And I will try my best to make sure that Iexplain why we're actually going through all the stuffthat we're going through
* But things like linear algebra, matrices,and eigen values will show up
* Differential equations will play a keyrole
* Calculus, derivatives and integrals willbe everywhere
* And this is just something you have to doin able, in a, in order to be able to do roboticsright
* And I hope you will be following me along this ride forthis seven week adventure
* As a final note, before the actual coursebegins, let me that this opportunity to introduce the teambehind the course, they are all graduate students in robotics and control theory,here at Georgia Tech, and here is Smriti Chopra, Smriti is going to berunning the, the glue lectures
* So these are lectures that are going tomap the general stuff that I do in class onto the particulars ofthe weekly quizzes
* And, Smriti is also going to be highly involvedon the discussion forums
* And here we have J.P
* de LaQua
* J.P
* is going to be the, the master ofceremony when it comes to running the, the robotic experiments that we'resprinkling in throughout the course to highlight and stressparticular key points
* And JP is also the key force behind theoptional simulation part of the course, and he willbe running the weekly programming assignments.And here lastly is Roland O'Flaherty and Roland is the hardware guy.He's going to show us how to build robots
* And this will also be an optional weekly feature where we will be buildingplatforms that, at the end of the day, we can implementand run our controllers and code on
* And Roland tells me that he's actuallygoing to produce a cooking show, but instead ofbaking bread, we will be baking robots.


--- SKIP ---: 04_whats-control-theory-anyway.en.srt


--- SKIP ---: 04_whats-control-theory-anyway.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_whats-control-theory-anyway.en_SENTbySENT.txt
* In this lecture we're going to be a littlebit more precise about what we mean when we say control theory, and I've beenthrowing around this term controls quite a bit so far, even though we've only seenone lecture
* and what I want to do now is make this a little bit more precise sothat we get a slightly better understanding ofwhat it is that we'regoing to be doing in the class
* And, ultimately controls, it deal withdynamical systems
* These are abstractions that describe something that changes overtime
* This could be a car that's moving
* This could be the price of a particularstock
* But ultimately, controls is dealing with how can we best or how can weinfluence this change of the system
* And some examples, and we're going to see allof these examples in the class of systems that one can control, would be robots,epidemics, you could come up with vaccination strategies, stock markets,thermostat's for keeping the temperature pleasant indoors, electrical circuits, dcengines, power grids, or autopilots on a aircraft and all of these will show up andsee which of these are easy to control and which of these are actually very hard tocontrol
* And we're also going to understand what makes certain systemsharder to control than others
* I put robots in red though because this at theend of the day is the main focus of the course from the point of view.So let's start with trying to build up a control system in terms of the basicneeded building blocks
* And the first thing you need is some way of describingwhat the system is doing or, more importantly, where it is
* If I want tocontrol a car, let's say I want to build a self-driving car that drives from my hometo my office, well I need to know where the car is, and central to this is thenotion of a state
* The state represents what the system is currently doing, whatstate that it's in, and we're going to use x to describe what the state of the systemis
* This could be the position or the velocity of a, of a, robot, this could bethe p ercentage of people that are infected by a certain, epidemic, thiscould be a number of different things, but ultimately the state is the key thing thatdescribes what the system is up to
* And what it is actually doing is the dynamics.And the dynamics is the description of the change of the state as a function of time.Now, this is all good
* But, we want some way of influencing this
* So, we're goingto have a reference signal that is going to
* We're going to use it as a way oftelling the system what it is that we want it to do
* So the reference could be setthe cruise controller to 60 miles per hour, or make me a certain amount of moneyon the stock market, or make the temperature in the room 70 degrees
* Whatdo I know
* now we can do that all we want, but let's say that we want a cruisecontroller to go at 60 miles per hour, that's not going to work until we canactually measure how fast the system is going
* So we also need an output
* So we'regoing to use r for the reference, y for the output
* And out-, the outputs are thethings that we're able to get out of the system
* This is telling us what the systemis doing
* So we can't always measure the state y is the output
* Now this picture isactually a blatant lie, because if I tell the stock market to go make me a certainamount of money there's no way it's going to do that
* If I just you know yell 65 atmy car, it's not going to go 65 miles per hour so we need some way of mappingreference signals into actual control signals, the inputs
* So u is going to bethe thing that takes the reference and produces a control signal that then hitsthe state of the system
* Now this is all fine and good but this control design isnot particularly good because the control signal has nothing to do with themeasurements
* So we need the final building block which is the feedback
* Thisis a mapping from outputs to inputs in the sense that what we're doing is we'retaking Y here
* Oh, sorry
* We're taking y here, let's say y, and thenwe're taking the refer ence and out here comes the reference minus y, which isgoing to be the error in terms of how the system is performance
* And this error istranslating into some control signal that's then hitting the system
* So thisfeedback mapping is really the key to doing any kind of controls in an effectiveway
* Good
* So, now that we know a little bit aboutwhat are the basic building blocks
* I want to talk about examples just so we can tryto understand what these building blocks actually represent
* So, the state of arobot is typically, if it's a mobile robot on the ground, it's the position, maybethe orientation of the robot, maybe the velocity of the robot
* The state isultimately what we need to describe what it's doing
* If it's a manipulator robot,it would be the angles, the joint angles of the various, segments of the, of therobot
* so that would be the state
* The dynamic simply says how the robot ismoving
* The control signal, or the control input, would be things like velocities ortorques or accelerations
* Some ways of moving the robots around, and themeasurements would be things like, where is the robot
* What is it seeing in theenvironment
* The epidemics, like I said a state would be maybe what percentage ofthe population is infected
* The thing we can control, so the input would bevaccination strategies
* In this case, the output is tricky
* It;s very hard to knowwhat percentage of a population is infected for instance with, with aninfection
* So, there, the output would be some kind of measurements at hospitals ofhow many people show up with this particular disease
* stockmarket statecould be, in fact no one really knows what the state is of this stock market which iswhy impart so hard to make money
* the output would be, well, the prices of thestock and the input is simply buy or sell
* Thermostats, temperature, outputstemperature, the thing we control is turning things on and off
* Circuitstypically the state would be currents voltages and, and currents, and the inputsare typically voltages that you're applying and the outputs are measuredcurrents of voltages in the circuits
* Engines you can apply, typically voltagesand out comes a torque
* the power grid, well the state there somehow is powerconsumption across the different modules
* The things you can control are puttingloads and generators onto the grid, maybe same thing with autopilots on aircraft,the states would be positions and velocities, the things you can control areaccelerations or change the, the control surfaces of the aircraft, and themeasurements are a whole bunch of things, how fast is it going, where is it going,what's the altitude
* What's the wind resistance and things like that
* So, whatwe need to do is come up with a rather general way of describing all of thesesystems, in a way that makes sense, that we can use
* And, that more importantly,can use to control mobile robots.


--- SKIP ---: 05_on-the-need-for-models.en.srt


--- SKIP ---: 05_on-the-need-for-models.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_on-the-need-for-models.en_SENTbySENT.txt
* So now we have seen that controls dealswith dynamical systems in generality
* And robotics is one facet of this
* Now what wehaven't done is actually try to make any sense of what this means in any precise ormathematical was
* And one thing that we're going to need in order to do this is
* Comeup with, with models
* And models are gong to be an approximation, and an abstractionof what the actual system is doing
* And the control design is going to be made,rather done, relative to that model and then deployed on the real system
* But,without models we can't really do much in terms of control design
* We would just bestabbing in the dark without knowing really what, what's going on
* So, modelsare actually Key when it comes to designing controllers, because if youremember that the question is really how in control theory, is how do we pick theinput signal u
* So u again, takes the reference, compares it to the output, themeasurement and comes up with a corresponding Course correction to whatthe system is doing
* And the objectives when you pick this kind of control input,well, there are a number of different kinds of, of objectives
* The first one isalways stability
* Stability, loosely speaking, means that the system doesn'tblow up
* So, if you decide a controller that makes the system go unstable, then noother objectives matter cause you have failed
* If your robots drive into walls oryour aerial robots fall to the ground, basically control stability is alwayscontrol objective number one
* Now, once you have that, the system doesn't blow up.You may want it to do something more than not blow up, and something that we'regoing to deal with is tracking a lot
* Which means, here is a reference either ofvalue
* 14, how do we make our system do 14 or here is a path how do I make my robotfollow this path or how do I make my autonomous self driving car follow a road.So tracking reference signals is another kind of objective
* assert important typeof objective is robustness in the sense that
* ,, 
* Since we are dealing withmodels when we're doing our design
* And models are never going to be perfect
* Wecan't overcommit to a particular model
* And we can't have our controller be toohighly dependent on what the particular parameters in the model
* R, model r
* So,what we need to do is to design controllers that are somewhat immune tovariations across parameters in the model, for instance
* So this is very important.I'm calling it robustness
* a companion to robustness, in fact one can ague that it'san aspect of robustness
* It's disturbance rejection, because, at the end of the day.We are going to be acting on measurements
* And sensors have measurement noise
* thingsalways happen if you're flying a in the air, all of a sudden you get a wind gust.Now that's a disturbance
* if you're driving a robot, all of a sudden you'regoing from Linoleum floored carpet, now the friction changed
* So all of a suddenyou have these disturbances that enter into the system and your controllers haveto be able to overcome them
* at least, reasonable disturbances for the, thecontrollers to be To be effective
* Now once you have that we can wrap otherquestions around it like optimality, which is not only how do we do something but howdo we do it in the best possible way
* And best can mean many different things, itcould mean how do I drive from point A to point B as quickly as possible, Possibleor as using as little fuel as possible or while staying as centered into the middleof the road as possible
* So optimality can mean different things and this istypically something we can do on top of all these other things and in other to doany of this we really need a model to, to be a
* Effective.So effective controlled strategies rely on predictive models
* Because without them,we have no way of knowing what our control actions are, are actually going to do
* So,what do these models look like
* Let's start in discrete time
* this means that,what's happening is that, that Distinct time instances, thi ngs happen.In discrete time, what we have typically, is that the state of the system, rememberthat x is the state
* So this is at time instance, k plus 1
* Well, it's somefunction of what the state was like, yesterday, the time, k, and, what they didyesterday
* So, the position of the robot, position of the robot tomorrow, is afunction of where the robot is today, and what I did today
* And then, f, somehowtells me how to go from today's state and controlling to tomorrow's state
* This isknown as a difference equation because it tells you the difference between differentvalues across, different time instances
* So, that's in, in discrete time
* andhere's an example of this
* This is the world's simplest discrete time system.It's a clock, or a calendar
* This is the time today
* Now I'm adding one second
* Andthis is the time one second later
* So the time right now plus 1 second is the time 1second later
* This is clearly a completely trivial discreet time system, but it is adifference equation
* It's a clock, so if you plot this we see that here is, this isthe 8, which is what time it is As a function of time
* So it's silly
* But at 1o' clock, the state is one
* At 2 o' clock, the state is two, and so forth
* And youget this thing with slope one
* So, this would be the world's simplest model
* Thereare no control signals or anything in there
* But it least it is a dynamicdiscrete time model that describes
* How a clock would work
* Now the problem we havewith this though is that the Laws of Physics are all in continuous time
* Andwhen we're controlling robots we are going to have to deal with the Laws of Physics.Newton is going to tell us that the force is equal to the mass times acceleration.Or, if we're doing circuits, Kirchoff's Laws is going to relate various propertiesto capacitances and resistances in the, in the, in the circuit
* So, we're going tohave to deal with things in continuous time, and in continuous time, there is nonotion of next
* But we have something almost be tter, and that's the notion of aderivative, which is, it's not next, but it tells us How is the time change
* Thechange with respect to time
* So in continuous time, we don't have differenceequations
* What we have are these things called differential equations
* And righthere you see that the derivative of the state with respect to time
* Is somefunction of x and u
* So this not telling me what the next value it is
* It's tellingme, what's the change
* Instantaneous change
* And here, it's the same thing
* Butnow I'm written, I've written x
* instead of dx, dt
* and time derivatives, a lot oftimes, is written with a dot
* And I'm going to use that in this
* Class and thisactually traces back to the, the slight controversy between Newton and Leibniz.Leibniz, so in 1684, Newton said, oh I have this idea that I call itdifferential, and Leibniz at the same time had the same idea
* Well, this is Leibniz'snotation and this is Newton's notation, and we're going to use the dot for timederivatives here
* The point is that these are both the same equations and they aredifferential equations, because They are relating changes to the values of thestates
* so if you go back to our clock, what would the differential equation of aclock look like
* Well, it would be very, very simple it would say that the, thechange, the rate of change of the time is one
* Which basically means The clockchanges a second every second
* That's what it means
* So when I drew this picture ofthe discrete time clock
* Or, I drew this line diagonally across it
* What I wasreally doing was describing this
* So this is the continuous time clock
* x dot isequal to 1 And
* We are going to need, almost always,continuous time
* Models for, for our systems
* And next couple of lectures,we're going to start developing models of particular systems
* But, before we dothis, I want to say a few words about how to go from continuous time to discretetime
* Because our models are going to be continuous time differential equations.But th en, when we're putting this on a robot, we're going to put it on acomputer
* The computer runs in discrete time, so somehow we need to map continuoustime models onto discrete time models
* So now if I say that x at time k, well it's xat time k times delta t, where delta t is some sample time
* So we've sampled kmeasurements
* Well if I, use this
* What is x at time K plus 1 which is at the x.kplus first sample time
* Well, I need to relate this thing somehow to thedifferential equation
* So how do I do this
* Well, this is not always easy to doexactly but what you can note is that
* This is known as a tailor approximation.So x at time k times delta t plus a little delta t which is exactly the next state.Well it's roughly what it was last time times the length of the time interval,delta t times the derivative
* So this is a an approximation but the cool thing hereis that this x at time k plus delta t, well that's, xk
* So these things are thesame
* x dot at time k equals delta t, well that's f
* So this are the same things, andthen I just have to multiply my delta t there
* So this is a way of getting adiscrete time model from the continuous time model
* And, this is how we're goingto have to take the things we do in continuous time, and map it onto theactual Implementations of computers that ultimately run in discrete time.


--- SKIP ---: 06_cruise-controllers.en.srt


--- SKIP ---: 06_cruise-controllers.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_cruise-controllers.en_SENTbySENT.txt
* So now that we have a way of describingdynamical systems with differential equations in continuous time
* Ordifference equations in, discrete time
* Let's, see if we can actually use this, todo something interesting with, with robots
* And, let's start with
* Building acruise controller for a, for a car
* And the, the cruise controller
* I mean it'sjob is to make the car drive at the desired reference speed
* And if yourecall, we're going to use r to describe the reference
* So someone You, in the car,have set the reference speed to, to 65 miles per hour, or whatever you desire.Now, we want to somehow understand how we should model the car so that we can makeit go the reference speed
* Well, like I said last time, the laws of physicsultimately will dictate how Objects in the world, like robots or cars, behave
* AndNewton's second law says that the force is = to the mass * the acceleration
* Now,this is what we're going to have to start with
* There's nothing we can do aboutthis
* It is what it is
* Now, what is the state of the system
* because we need tosomehow relate Newton's Second Law to the state
* Well, in this case, since whatwe're going to do is try to make the velocity do the right thing, we can saythat, let's say that the velocity of this, the car is the state
* So x is going to beThe speed at which the carrist is driving
* Now acceleration a appear, this, a issimply dv dt and its the time derivative of the velocity or the change in velocityas a function of time
* So what we get from that of course is that we can relate thevelocity to the acceleration
* Now we're also going to have to have an input, andwhen you're driving a car, the input, if you're dealing with, with speeds ratherthan which direction the car is going is, you press the gas pedal or the brake
* Andwe are going to be rather cruder and say, you know what
* Somehow we're mappingstepping on the gas or the brake onto a force that's applied To the car
* And thisis done through some linear relationship, where we h as some coefficient c, which isan electric mechanical transmission coefficient, and I'm going to go out on alimb and say, we don't know what this is
* And, I control this sign cannot rely on usknowing c, because we're not going to know exactly what it is
* But, let's at leastfor now, go with this, and hope That that's good enough to give us the designwe want
* So now we know that the force is c times u, but it's the mass time theacceleration
* Right
* So x dot, which is the same as dv, dt,which we had up there
* Well, that's A which means that mass times theacceleration which is mx dot is equal to the force, but the force is c times u
* So,that tells me directly that x dot is c over m times u
* So, this, this sweet heartequation here is an equation that describes how my input maps on to
* Thestate of the system
* It's a differential equation
* But it's an equation that tellsus something about how my choice of input affects the system
* Okay.This is, in fact, a rather good model
* And I want to show a little video
* I wasinvolved in one of the, the DARPA
* grand challenges.This was an urban challenge
* Where we were supposed to build self-driving cars and weuse almost exactly this model for, for our car
* So I want to talk a little bit abouthow one would do this
* So here is the front, a spinning thing, that's a laserscanner
* On the side here, is another laser scanner sitting on top of a radar.These were what we used to get measurements
* Now what we see on theinside is our instrumented car, which translated ultimately input voltages ontomechanically things that push down the gas pedal
* So this is how we actually affectedit with the same coefficient
* And now, look at this video
* The car gets aroundobstacles, and then it gets out of bounds, and it starts oscillating
* So, I'm showingthis
* A, because I think the car is awesome
* But, B, because there are, eventhough we didn't crash into things, we were oscillating a little bit
* so there issomething not perfect about this control design
* See how we get out of the lane,we're oscillating too much
* If you look at the steering wheel, see that this is alittle skittish
* and that's another indication that maybe the control designhere wasn't perfect, but the velocity controller was based on a model that'svery similar to, to what we just wrote down
* here's another example of obstacleavoidance where
* We're actually trying to avoid another car, but the point being isthat, this very, very, very simple model that we wrote down is actually applicableto real systems
* And this is part of the miracle of abstractions, that you're thatyou're able to get simple things that you then can apply for real
* Now, I want topoint out that we did real well In this competition up to a point, these wereactually the semifinals before the finals
* So let me show you what happened at theend
* This breaks my heart to show you but I'm going to show it to you anyway
* Herecomes our car
* Sting racing
* It's slowing down, it's slowing down andthen ow
* It drives straight into a k rail, which is this concrete railing
* Whathappened was that we got some measurement errors, a lot of measurement errorsactually from the GPS
* But I wanted to show you this because it was the outcomeof it
* regardless of which, this was still
* A very complicated system
* A verycomplicated robot, a car, and the model we came up with was very simple, and thepoint is that simple models a lot of times get you very far
* So, let's see how weshould actually do, do the control design here
* let's assume that we can measuredirectly the velocity, and record, recall that the state
* X is the velocity themeasurement or the output is what we called y, so y is actually directly equalto x in this case, so we have a some way of measuring velocities which you knowtypically have a, you have a speedometer in your car so we know roughly what thevelocity is and now their control signals should be a function of R-y, where r isthe desired velocity and y is the actual velocity
* And, I'm going to call this e,which stands for error
* And our job, as control designers, is to make the errordisappear, drive the error down to zero
* So let's, before we do the actual designdiscuss a little bit about what are The properties that a useful controller couldhave
* Well 1 property is that the controller should not overreact
* If theerror is tiny, we're almost perfect in terms of the velocity of the car, weshould not have a large control signal
* The control signal should not beaggressive when we're close to being done, it's like
* Lets say that you're trying tothread a, a thread through a needle
* Well, when you're really, really close youshouldn't just jam the thread in there
* You should take it nice and slow whenyou're close
* So, no overreactions
* That's important, because when you startoverreacting, you start responding very Quickly and aggressively to measurement ofnoise, for instance
* So, a small error should give a small control input
* Ushould not be jerky
* And jerky, here
* All I mean with that is that, it shouldn'tvary too rapidly all the time
* Because if it does, then we're going to be sitting inthis car
* With our cruise controller, we're going be having a cup of coffee withus
* And, now the cruise controller is smacking us around all over, because it'sjerking, we're going to spill our coffee
* And, in fact for auto pilot's onairplanes, there are limits on their accep, acceptable accelerations That aredirectly related to cups of coffees standing on the, the tray tables in theaircraft
* so you should be, not overreacting
* It should not be jerky
* Andthe, it should not depend on us knowing c and m
* So, m is the mass of the car
* C isthis semi-magical transmission coefficient
* The mass of the car ischanging depending on what luggage we have
* It's changing depending on how manypassengers we have
* We should not have to Redesign our controller just because a newperson entered the car
* We shouldn't have to weigh everyone and enter how much weweigh to, for it to work
* And in fact elevators have bounds on how many peoplecan be in the elevators
* This is import, related to the fact that they designcontrollers that are robust to Variations in mass across a certain spectrum
* Samething for cars
* The cruise controller should work no matter how many people arein the car and we don't want to know c
* What this means is that controller can notbe allowed to depend exactly on the values of c and m
* So these are the 3 properties,high level properties that we have to insist on our control signal to have
* Sohaving said that, in the next lecture we're going to see how we can actuallytake these high level objectives and turn em into actual controllers and see whatconstitutes a good control design and
* Conversely, it would constitute a badcontrol design.


--- SKIP ---: 07_control-design-basics.en.srt


--- SKIP ---: 07_control-design-basics.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_control-design-basics.en_SENTbySENT.txt
* Okay.So, so far in the course, we have mainly chit-chatted about things
* We've seen somemodels and we have now a model of a, a cruise controller or at least how thecontroller input affects the velocity of a car
* We see it here, x dot was c over mtimes u
* Where x was the velocity, u was the applied input, and c was some unknownparameter, and m was the mass of the vehicle
* We also talked a little bit aboutwhat we wanted the controller to do
* So now, let's start designing controllers.Let's actually do it
* No more excuses
* What we want, of course, is that x shouldapproach r
* And recall, again, that r was the reference velocity that we wanted thecar to get to
* And x is the actual velocity
* And typically, in controldesign, you talk about asymptotic properties, which is fancy speak for whent goes to infinity
* So, what we want, is, after a while x should approach r
* Thevelocity should approach the reference velocity
* Or another way of saying that isthat the error, so the mismatch or imbalance between the 2 two velocitiesshould approach 0
* That's what we want
* So, I am going to give you a controllerhere
* This is attempt 1
* I have picked some values for, you know, how hard I wantto hit the gas pedal
* And I'm going to say that, if the error is positive, sopositive error means that the reference is bigger than the state, which means thatwe're driving slower than we should
* Then, let's hit the gas
* And if the error isnegative, meaning that the velocity, the actual velocity of the car is greater thanthe reference velocity, which means we're going too fast, let's brake
* And if we'reperfect, let's do nothing
* Fine
* So, take a second to stare at this and seewhat you think
* Is this going to work or not
* Okay, a second is up let's take alook
* Yeah, it works beautifully
* I put the reference velocity to 70 so it's uphere, here is 70
* This is the actual velocity of the car and look at what thecar is doing
* It's basically starting down somewhere and then increasing up to 70 andthen it's remaining flat around 70
* So, that's, that's awesome
* It's doing what itshould be doing
* Now, I'm calling this bang-bang control and that's actually atechnical term from doing things like u max and negative u max
* You're switchingbetween two extremes
* so this seems to be easy peasy and there's no need to take acourse on controls and mobile robots
* Now, let's see what the control signals isactually doing
* Let's see what the control values were that generated this nice andpretty plot
* Well, they look like this
* This ladies and gentlemen is miserable.Even though the car was doing the right thing in terms of the velocity, I had umax be a 100, so negative max is minus a 100 and first of all, we are acceleratingup for a while, until we hit the right velocity
* And then, we start switchingwildly between plus and minus a 100
* Well, when the error was 0, the u was supposedto be 0, but the error is never going to be exactly 0
* Just ain't going to happen,and this is bad, because what's going on
* Well, first of all, we get a really bumpyride
* We're going to be tossed around in the car, backwards, forwards, backwards,forwards, because of all these accelerations that are being induced bythese, these extreme control signals
* We're also burning out the actuators.We're asking the car to respond extremely aggressive and for no good reason
* I mean,we're basically doing a lot of work when we're very close to perfect
* So, this isactually not a particularly good control design
* And the problem is exactly this ofoverreaction to small errors
* Even though the error is tiny, as long as it'spositive, we're slamming gas as hard as we can
* so we somehow need to change thisdesign
* So, how shall we do that
* Well, the easiest thing to do is to say, youknow what, when error is small, let's have the control signal be small
* In fact,here's my second attempt
* u is k times e, for some positive k, e is the error.Positive error means we're going too slow, u should be positive
* Negati ve errormeans we're going to fast, u should be negative
* So this is a much cleanerdesign
* It's what's called it's, it's a smooth feedback law
* It's actually linearfeedback in the error, and this seems to be much more reasonable because smallerror yields small control signals, which is what we wanted
* Nice and smooth
* We'renot going to wildly fluctuate in our controller
* And, in fact, this is called aP regulator, where P stands for proportional because the control signal,the input, u, is directly proportional to the error through this k controlled gain.So, here is a completely different and possibly better way of doing it
* This iswhat the P-regulator in action looks like
* So, it's nice and smooth, right
* It seemseven stable
* Stable, again, we haven't really defined it, but it's clearly we'renot blowing up the course
* So, nice and smooth and stable
* Now, here is a littleproblem
* You see what it says up here
* It says 60 and I had my reference be 70
* So,even though we're nice and smooth, we actually did not hit the target value
* Thereference signal was supposed to be 70, and we got to 58 or so
* so even thoughwe're stable and smooth, we're not achieving tracking
* And here is theproblem
* I actually added a term to the model and this is a term that reallyreflects wind resistance because here is the acceleration of the car, this is ourterm
* Well, if we're going really, really fast, we're going to encounter windresistance
* So, add it a little bit of wind resistance
* This says that if we'regoing positive and fast, then we're getting a negative force, we, meaning,we're being slow down a little bit and gamma is some term or some coefficientthat again we don't know
* And this was the model I used when I simulated thecontroller
* and somehow, the P-regulator wasn't strong enough to, to deal withthis, and in fact, let's see what happens
* At steady state, so steady state meanswhen nothing changes anymore, and if for your call from the plot, after awhile, xstopped varying
* At steady state, x is not varying
* Well, another way of saying that,is that the time derivative of x is 0
* So, at steady state, x is not varying, whichmeans that this term here has to be equal to 0
* And this is the model right
* Well, Iknow what u is
* u is equal to k times error, which is r minus x
* So, I'mplugging in u there
* And I'm saying that this thing has to be equal to 0
* Well, ifI write down the corresponding equation now that says that, this term here has tobe equal to 0, then I get this
* Well, I can do even better than that
* What I getis that x, let me get rid of the red stuff there, x is now going to be, ck divided byck plus m gamma times r, and this, for all these coefficients being positive, isalways strictly less than r
* Which means, that at steady state, the velocity is notgoing to be, it's not going to make it up to the reference velocity
* And we can seethat if we make k really, really, really big, then these two terms are going todominate and we're going to get closer and closer to having this complicated thing,go to r
* So, as k becomes bigger, we're getting closer to r, which means we'rehaving a stronger gain
* But we're never, for any finite value of the gain, going toactually make it up to the reference
* So, something is lacking and next time, we'regoing to see what it is that is lacking to actually achieve tracking and stability.


--- SKIP ---: 08_performance-objectives.en.srt


--- SKIP ---: 08_performance-objectives.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_performance-objectives.en_SENTbySENT.txt
* So recall, last time, we saw that
* Wedesigned a controller that was nice and smooth
* It didn't overreact to smallerrors
* made a system stable
* Yet didn't achieve tracking
* And this was theproportional regulator, or the p regulator
* and let's return to ourperformance objectives a little bit
* We've talked about them briefly
* But acontroller at the minimum should
* Stabilize the system
* If it doesn't dothat, we know nothing and I've written this rather awkward looking acronym here,BIBO, which is something out of the Lord of the Rings almost
* What it stands foris, bounded in, bounded out which means that if the control signal is bounded, thestate of the system should also be bounded
* What this means is that, bydoing
* Reasonable things the system doesn't blow up
* And our system doesn't dothat
* Tracking means we should get to the reference value we want
* And robustnessmeans we shouldn't have to know too much about parameters that we really have noway of knowing
* And preferably we should be able to fight noise as
* Well, so recallat this was the model and when I introduced this wind resistant term here,we had a little bit of a problem.The proportional regulator couldn't overcomeit and lets have another controller done one that explicitly cancels out the effectof the wind resistance
* So here is my
* Attempt 3, I'm going to use this part,which is the proportional part that we already talked about, and then I'm goingto add this thing which is plus gamma m/c*x.Well why did I do this
* Well, I did this for the following reason that if you reachsteady state x is not equal to 0, then now What you get is well this was the p part.This is the controller, the p controller
* And then the effect of this thing wellyou're going to multiply this by c/m
* What you're going get then is plus gamma x
* Andthen you have wind resistance which is negative gamma x
* So the gamma x, the badparts cancel out
* And in fact all we're left with then is that x
* Has to be equalto r
* So, voila, we've sol ved the problem.We have perfect tracking
* Or, have we
* dom, dom, dom
* No, we have not
* And, whyis this
* Well, we have stability and we have tracking, but we don't haverobustness
* Here are three things that we don't know
* Gamma, m, and c
* And ourcontroller depends explicitly on, On these coefficients
* So all of a sudden we haveto know all these physical parameters that we don't know, so this is not a robustcontrol design
* So Attempt 3 is a failure
* Okay, let's go back to the P-Regulator andsee what's going on there
* What, what's actually happening is that theproportional error is doing a fine job pushing the system up to close to where itshould be, but, then it kind of runs out of steam, and it can't push hard enough toovercome The effect of the wind resistance
* So the proportional thingisn't hard enough, but take a look here
* This is the error, then the error startsaccumulating over time, so if we somehow, if we're able to collect All of theseerrors over time, even though they are very small
* Over time, that should beenough, so that we can use this now accumulated error to push all the way up.So I wish there was some way of collecting things over time in a plot like this
* And,of course, there
* There is, this is something called an integral
* So, if wetake the integral over the error we're collecting the error over time and overtime as this errors going to accumulate it's going to give us enough pushing powerto actually overcome the wind resistance
* So attempt 4 is a pi
* Regulator.So what I have here is the error at time t
* This is my kp, which is my proportionalgain
* So this is the p part that we already saw
* And now, I'm adding anintegral that is integrating up the error from
* The beginning to the current time.And it's collecting this
* And then we have another term here, or another coefficient.The ki, where I stands for the integral part
* So this a pi regulator
* And it is2/3 of
* The most common regulator found anywhere in the world, and in fact it'salmos t 2/3 of commercial grade cruise controllers
* So if I have a p and an i,what could possibly be missing to get to all of them
* 3/3 instead of just 2/3.Well, we take a derivative
* Right, we have proportion, we have integral, and we havea derivative
* So, why not produce what's called a PID-Regulator
* So now we have aproportional term with a proportional gain
* We have an integral part with anintegral gain
* And then we have a derivative part with a derivative gain, sothis is
* It's an extremely useful controller that shows up a lot
* And, infact, I'm going to hand, have to hand out a big sweetheart to the PID regulator.Because it's such an important type of control structure that shows up all thetime
* And in fact we're going to get quite good at designing the PID regulators
* Nowhaving said that, I can draw hearts all I want, let's see it in action and see whatit actually does
* And if I use just the PI regulator, not even a D component to thecruise controller, then all of a sudden I get something that's getting up quickly,nice and slowly, I mean smoothly, to 70
* Miles per hour, which is my reference
* Sothis solves the problem
* I don't know parameters, so it's robust
* I'm achievingtracking, because I'm getting to 30 miles per hour
* And, I'm stable in the sensethat I didn't crash
* So, this seems like a very useful design.


--- SKIP ---: 09_pid-control.en.srt


--- SKIP ---: 09_pid-control.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_pid-control.en_SENTbySENT.txt
* So, last time we saw that the PIregulator, or its slightly more elaborate brother, the PID regulator, was enough tomake the cruise controller do what it should do
* Which is, achieve stability,tracking and parameter robustness
* Today I want to talk a little bit more about PIDcontrol
* And, the reason for that is, thisregulator is such an important regulator or controller that's out there invirtually every industry you can think of, there is a PID regulator going onunderneath the hood in almost all controllers
* And, there are really threeknobs you can tweak here
* One is KP, which is the proportional gain
* The other's kIwhich is the integral gain and then kD which is the derivative gain
* And I wantto talk a little bit about what are the effects of these gains
* Well first of allP As we saw
* It's a contributor to stability
* In the sense that, it makes thesystem, not guaranteed
* But it's helping out to make the system stable
* And it's,it's making it responsive in the sense that
* You respond if someone, if youclick, or press 70 miles per hour on your cruise controller
* It drives the systemtowards that value
* I'm calling it medium rate responsiveness
* Because it's notsuper fast
* And the speed
* In fact, the rate of responsiveness is a function ofhow big kp is
* But as you saw, it wasn't typically enough to achieve tracking
* Butthe I component is really
* Good for tracking and in fact if your system isstable than having an eye component is enough to assure tracking in almost allcases
* It's also extremely effective at rejecting disturbances so that integralpart is a very effective Part to have in your controller
* Now it's much slower inthe sense that you have to accumulate over time errors to respond to them becauseit's an integral
* So it, it re, responds slower and there is a very there is alittle bit of a warning I need to make there, by making k i large
* You may verywell induce oscillation so this is not, oh I'm going to pick all of the Them.A million and go home
* Yo u have to be a little careful in how you actually select,select these gates
* Now the d part, well, since it's not responding to actualvalues, their values but the change is in their values, it's typically fasterresponsiveness, so something is about to happen
* Well, the rate is changing so the,the derivative part kicks in typically faster
* now there is a little caveat tothis
* And that's the derivative is sensitive to noise
* Because if you have asignal that's noisy then if you compute the derivative of that signal you're goingto get rather aggressive derivatives that don't necessarily correspond to what thenon noisy signal would be
* So you have to be a little careful with the d part
* Somaking KD too large is typically an invitation to disaster because you're,you're over reacting to, to noise
* So, the last thing I want to point out though iswhen you put this together you get PID which is already by far the most used lowlevel controller
* Low level means whenever you have a DC motor somewhere and you wantto make it do something Somewhere there is a PID leak
* Whenever you have a chemicalprocessing plant for getting the right concentrations in your chemicals,somewhere there is a PID regulator
* It's almost everywhere there, or in almost allcontrol applications, PID shows up under the hood in some form or another
* But, Ido want to point out, that this is not a one-size-fits all
* We can't guaranteestability with a PID regulator
* Sometimes it's not enough
* In fact, when we go tocomplicated Robotic systems, the PID regulator will typically not be enough byitself
* So we need to do a lot of more thinking and modeling to, to use it and atthis point we actually don't really know how to pick these gains
* However, I wantto point out that this is a very, very useful type of controller
* And since it isa feedback lob because it depends upon the error it actually fights uncertainty modelparameters in a remarkable way and the feedback has this remarkable ability toovercome the fact that we don't know gamma, we don't know c, we don't know m.But still, we seem to do well when we design controllers for a wide range of, ofthese parameters
* So having said that, let's hook it up to our car and in fact wehad a PID regulator for velocity control on the urban challenge vehicle, Sting 1 asit's called
* We had this model that we've already seen, and I pick It's completelyrandom and arbitrary numbers here for the parameters
* I even put r equals to 1, sowe're going to go 1 mile per hour
* let's say 1 meter per second
* it really doesn'tmatter These are arbitrary values
* Just so you'll see what's going on
* So, if westart with our friend The p regulator so we have kp = 1 here and all the othergains are 0 then well, we don't actually make it up to 1 we only make it 2 - 0.1.This we had already seen
* So the p part by itself was not enough to, to both bestable and achieve tracking
* Well, that's Ok in the i part
* It's cruise-controlleragain kp is 1, kI is 1 and now we are having a very nice so called step responsewhich means we are responding, we are waking up and then we are hitting it witha step, in this case the step of height 1 or 70 if its 70 miles per hour
* so thenthis thing makes it's way up and it stays up there perfect
* So this is actually agood and successful design right here
* Now ,if this is so good why don't we make kihigher to make it even better
* Well if I To crank up KI to 10
* Then, all of asudden, my system starts oscillating
* So this is an example of where the integralpart may actually cause oscillations
* Which is, we should at least be aware ofthis fact
* And be a little careful when we tweak our parameters
* And if we seeoscillations That is a
* Clear indication that the integral part is typically alittle bit too large
* What about the d part
* Well, let's add the d part
* In thiscase, it actually doesn't matter too much
* What you see here is that I had a small dpart
* I'm a little bit paranoid when it comes to large kd terms because they are alittle bit Noise sensitive
* But what you're seeing here is that you'regetting a faster initial response because of the introduction of a D part, but then,we actually get almost a slower response towards the end so the D part is there todrive it well up in the beginning, but then So were stand in this particularapplication, having a d gain that's not ser, it's not even clear if that was, wasuseful
* But this is some of the thinking that goes into tweeking PID regulators.So what we are going to do next time, is we're going to go now, from this ratherabstract, integrals and derivatives, to something that we can actually implement.And we're going to see how these PID gains show up when we control a the altitude ofa hovering quad regulator..


--- SKIP ---: 10_implementation.en.srt


--- SKIP ---: 10_implementation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_implementation.en_SENTbySENT.txt
* Now we have a rather useful seeminglygeneral purpose controller, that we call the PID regulator
* And, we saw that wecould use it to design a cruise controller for a car to make the car reach the, thedesired velocity
* what I haven't said though is how do we actually takesomething that looks, Looks, to be completely honest, rather awkward
* Youknow
* Integrals and derivatives and stuff
* And actually turn it into executable code.Meaning, how do we go from this mathematical expression to somethingthat's running on a platform
* Well, the first thing to note is that, we alwayshave a sample time
* We're sampling at a certain rate
* There's a certain clockfrequency on the, on the computer
* Well, what we need to do is we need to takethese continuous time objects that we have here in the, in the PAD regulator and havethem be defined in this discreet time
* First of all here is an arrow, it doesn'tmatter if this is running in continuous time and discrete time, the proportionalpart we just read in the current's velocity
* And compare it to the referencevelocity, and then we get the error at time, k times delta t
* So that's trivial.Now, but what do we do with derivatives and integrals
* Well, let's start with thederivatives, because they are not so hard
* we know that, roughly, a derivative is thenew value
* Minus the old value divided delta t
* In fact, as delta t goes to 0,this becomes the definition of a derivative limit
* So, we actually knowthat if I can store my old error, compute a new error, take the difference anddivide it by delta t, I have a pretty good approximation of edot, which is this thingde(t)/dt, so I actually can approximate the, the derivative part in a ratherdirect way
* Compared the latest value to the previous value divided by delta two,and we're good
* Now the integral
* That's where we're going to have to do a littlebit of work
* So, what is the integral
* Well the integral is The sum under thecurve right
* That's the integral
* Well is there some way of approximating this?Well, clearly it is
* We can sum up all these little blocks
* This is a rimapproximation of the integral
* So what this means is well we're not going to getthe integral exactly, but if you can sum up these blocks somehow and the width hereis going to be
* what did we call it
* Delta t
* So the width of each base of therectangle is delta t
* So if you can do that
* Then we're getting a, a reasonablygood approximation
* And, in fact, then the integral is simply a sum of the values atthe sample time
* So the value up there
* The value at that time
* And then wemultiply it by delta T to get the rectangle, and then we sum up all therectangles
* That's a reasonable approximation and in fact what I'm goingto do is I'm going to take this sum and call the sum E
* So this is the same thing.So then the integral is roughly equal to delta T times E
* Well, that turns out tobe useful because, let's get rid of that stuff again
* my next value, delta, or Edelta t times e new
* Well, it's delta t times the sum, but now I'm summing to nplus 1, well, let's pull out the last term
* So, the error At time, n plus 1times delta t
* That's the last value that we called little e new up here
* Let's pullthat out, multiply it by delta t, and what's left is the sum from 1 or 0 to n,which is E old, times delta t
* So, delta t
* E new is equal to delta t, E old + thisguy here
* Or if I want to put it in a slightly more compact way, E new where Eis the sum of the errors is E old + the latest error
* Which is a little bit dah.The new sum is the old sum plus the latest entry
* So, that gives me Enew and now,since I kne know that the integral is delta t x E, I know that, well, theintegral term that I get here is simply delta t times Enew which gives me anapproximation of
* The interval
* So, now, having said it, let's put thisinto, into pseudo-code here
* So, every time the controller is called, well, I'mgoing to read in the latest error, which is the reference minus the measurement.And then, I'm going to say e _dot
* E_dot is really.E minus, now we call it, let's call it e old, here
* It's really divided by delta t,right
* But the D part of the controller is Kd times this thing
* Well, what if I justcalled this thing my new, let's call it kD prime
* I just divided by delta t because Idon't actually need to typically know delta t
* Let's call this kD prime
* Well,then I just got rid of delta t, and I don't have to worry about
* Delta t
* I dothe same thing for the integral
* So e new is e old plus the latest error
* Again, Ireally have that this thing, this integral, is roughly equal to delta t.Times E
* So if I have kI times that, I have this times kI, well let's take theseguys and call this, this is my new kI
* Then again I get rid of the T, so then ifI do that, my actual controller is KP times E times KP times E dot
* Which I justcomputed and KI times E
* This is my control structure, this is how we actuallyimplement it
* And then I just need to at the end, remember to store the light, thelatest E as the old E so the next time I call the controller, I have the previousvalue
* This is the implementation of a
* PID regulator.So let's do it
* OK
* I'm going to point out again
* Thecoefficients include the sample times
* I pointed that out already
* But let's do it.Before we do it though I actually want to say that that's the end
* Almost of Module1
* And in Module 2, we're going to go robotics
* In the sense that we're going tosee, now, how to relate some of these initial concepts to robotics
* But, in theinterest of full disclosure, we actually don't know why anything we did in Module.1 actually worked
* So Module 3 is we're going to revisit whatwe did here
* But, revisit it in a much more systematic way
* Okay, that's enoughchitchat
* Now, let's do it
* We're going to do altitude control
* Which means we'regoing to control the height, how high up in the air a Quadrotor is
* And the modelwe're going to use is, well, x is going to be, so here's the height, here's theground, so x is going to be how high up this thing is
* And x.., which is theacceleration of the quadrotor, well g, the gravity, is pulling it down, so there hasto be a -g somewhere
* gravity is pulling it down, and then what we're doing iswe're really controlling the velocity of the rotor collectives
* So these are allthe rotors of the quadrotor, all the four rotors, the angular velocity of this thingwe're controlling
* And that's translating into thrust and upthrust through Thiscoefficient, c, that we don't know
* And we actually really don't know what thegravitational constant is either, but this is the model we're going to use
* And thisis the controller we're going to use
* And instead of me showing plots andsimulations, why don't we get away from the Power Point presentation right here,and move over to an actual quadrotor running a PID
* Regulator.So, now that we have a way of designing reasonably good controllers
* In this case,PID regulators
* we have some understanding of the basic performance objectives we'retrying to hit
* In this case, stability, tracking, and robustness
* We even have amodel, or at least a rudimentary model of a
* Quadrotor aerial vehicle
* What we didin the model is we tried to somehow connect the rotor collective speed to anup-thrust and the model included some parameters that we don't know
* It evenincluded the gravitational constant
* The idea, of course, with robustness now is,we should not have to know these parameters
* Exactly.Because that would actually be a rather poor and fragile control assign
* So I haveJP Delacroix with me here who is a graduate student at Georgia Tech
* Andwithout any further ado, JP, let's see what thee PID regulator actually lookslike in action
* , So what we're doing now is altitude control only
* So we're tryingto make this thing stay at the fixed altitude
* It's going to drift a little bitsideways because we're not controlling sideways drift at all
* one thing we cansee right off the bat is that the system is indeed stabilized
* Because if itwasn't, the quadrotor would actually fall down to the ground
* The other thing we seeis, when I'm pushing it a little bit like this, it's able to overcome it
* I can evenpush it down a little bit
* And the controller fights these disturbance, sorobustness is, certainly achieved
* In terms of tracking, it's not so clearwhat's actually going on because we don't exactly see what the reference height is,however we are measuring altitude with a downward facing ultrasonic sensor and,let's get this thing out of the way of JP
* And the integral part or the integral termin the PID regulator is ensuring that modulatiries these extra errors in theheight measurements, we are actually achieving the
* The altitude we were,looking for
* So with this rather simple initial experiment, we're going to declaresuccess when it comes to PID regulation
* And we now are going to move on to biggerand better problems
* Thank you
* ,, .


--- SKIP ---: 11_glue-lecture-1.en.srt


--- SKIP ---: 11_glue-lecture-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 11_glue-lecture-1.en_SENTbySENT.txt
* Hi, I'm Smriti Chopra
* I am a graduate student at Dr
* Egerstedt'slab, and I will be your instructor for the Glue Lectures, for the duration of thiscourse, which is Control of Mobile Robots
* And just a quick idea: what are these GlueLectures
* Basically, they're going to kind ofconnect, you know what you learn with Dr
* Egerstedt to the quizzes we aregoing to give you
* And give you helpful hints about thequizzes
* Clarify, repeat certain concepts
* By that I really mean we, you know, workout a few examples, understand the math that goesbehind some of the lectures, etc
* Just to help you guys move along thecourse
* And the format is going to be one GlueLecture every week
* And the course is seven weeks, so sevenGlue Lectures
* And on a side note Amy LaViers is a former grad student in our lab, and she was lastyear's instructor for the Glue Lectures
* So we will be reusing some of herlectures
* And so in the coming weeks, you know sheand I are going to share
* Between the two of us, we're going toteach you guys, out of the seven lectures
* But whatever questions, etc, you have, youdirect them to me, because well she's not here, and I'll be answering thosequestions for you on the forums, etc
* And with that, let's get into thelectures
* The first one is Dynamical Models
* This week with Dr
* Egerstedt, you guyskind of, you know, went through this introductorynotion of what a model is
* And he tells you that really, a model isbasically, you know, something that describes how yoursystem changes or evolves with time
* And your system could be a robot, for example, and a model is just going todescribe, let's say, how the positions change withtime, or how the angle, angles change with time,etc
* And the whole idea behind controls is that we're going to kind of try andinfluence this change to make our system do something wewant to do
* And we're going to do this by injectingcontrols
* But let's go really down to the basics.What really is a model
* And before we do that, let's do a littleexercise in derivatives
* So here we have, let's say, position x,with the respect to time, is given by thisexponential function
* Now this is in its general form
* I'm saying that let's say me, for example,my position is x of t, and I wake up at time t equal to 0
* I'm at position 10
* So and I'm saying that my position evolveswith time with respect to this function here, and it'sgiven by this graph here
* That's okay
* That's simple
* And now I can take the derivative of thisposition with respect to time, right
* And I get what, what is the velocity
* And you'll see this is actually 2x of t,really
* And then you can do this further on, andyou can take more derivatives, and now we have theacceleration, which is 4x of t
* One thing I want to point, point outreally quick here is that x dot of t equal to 2x of t, forexample
* Now what is this
* This is really nothing but a differentialequation
* Basically something that relates avariable x to its derivatives, second, third whatever
* So in this case, x dot equal to 2x of t isa differential equation
* Something he mentioned in class, right
* Okay
* So this was just an exercise inderivatives
* You guys should be able to takeexponentials and their derivatives, etc
* No problem
* We saw the graphs related to these, aswell
* But in action, what does it really mean
* So I'm telling you that my position withrespect to chi, time changes like this: 10e to the power2t
* What it really means is, let's say that'sme, or that's a pink ball, whatever
* And now I draw this line, which is the xaxis
* And I start at 10, which is where I wakeup, because you guys see, if we're here in this equation, if you put x at time 0,you'll get 10, e to the power 0, which is 10
* So at time 0, when I wake up, I'm at 10.Right
* And now, the whole point is that let's sayat time t equal to 0, like I said, we wakeup
* Now I say start, right
* And then I start moving
* And as my time increases, my position isgoing to keep changing with respect to thisfunction here
* And because it's exponential, let's say attime point 1, I'm here
* And then I jump really high at point 2, and then evenfurther
* because exponentially my position ischanging
* So, so from graphs, all of a sudden we see how it maps onto, these equations map ontoactual motion
* That's all I wanted to really show inthis
* But now, instead, I tell you that, youknow what, I'm not going to tell you how x changes withrespect to time
* I'm instead going to give you this set of equations, which is adifferential equation, and then an initial condition where I wakeup
* And now I want to find what my x of t isgoing to be, given this, which is x dot of t andx of 0
* So in this case what do you do
* Well, what you do is, and this is what youdid in your lectures as well, just to see howyou evolve with res, with time, you discretize theworld
* And real quick, let's say this is yourtime axis
* And I'm going to divide up this time axisinto, you know, delta t chunks, where each chunk is0.5 seconds, or whatever
* So it's very simple
* I just divide up the axis
* And now, I'm going to say that my t isactually given by this k delta t
* This is how you discretize, right
* And k becomes a counter.Why
* Because when k is equal to 0, my time is0
* And when k is 1, it's 0.5.When k is 2, I'm at one, etc
* So k becomes kind of like a counter,right
* All right.Now let's see how the ball is moving
* So we know that we discretized time
* What we want to see is now, as I move kfrom 0, 1, 2, 3, how does my ball move
* And sort of extract x of t from it.Right
* Okay
* So again, this is our equation incontinuous time
* So remember I told you I have given youonly two things
* These are the two things that I've givenyou
* Okay, so I know this guy here, that attime 0, I'm here
* And now I have the equation, thedifferential equation
* Well, you can discretize this differential equation through something calledTaylor's, Taylor extension, which you guys did with Dr
* Egerstedt, which basically isgiven by this equation here
* And a quick note
* What it really is doing is, it's kind ofsaying, x k plus 1 is nothing but x times k plus 1 times deltat
* Right?And xk is nothing but x at time k delta t
* So it's, by incrementing k, what we aredoing is we are finding out at the next time instant, discrete dimensionwhere should I be, depending on my previous timeinstant
* That's all this equation is really doing
* A good thing to note here, though, is thatwe will be using just the first two terms of the Taylor expansion, whichis what you guys did in the lectures as well
* This expansion is really an approximation, because yousee these dot dot dot here it just goes on and on
* You keep taking derivatives, and you keepgoing on, so obviously the more terms you use, the better yourapproximation of x of t will be
* But as of now, we're just going to use thefirst two terms of the expansion
* So let's see
* Here we have x of t is 2x, delta t is 0.5,we know this, t is k delta t, and now let's put this entirething into this equation of ours, the discretetime equation
* And we get this guy here, x k plus 1 isequal to 2xk
* You guys should do this yourselves.It's really simple
* But just, you know, plug in values.You get this one equation
* And this is now our discrete time updateequation
* And how do we use this
* Well, we are simply going to say okay, soat k is equal to 0, x of 0 is 0, and now xk plus 1, which is x1, will be 2 times xof 0, which is actually 20, right
* So we saw that at k is equal to 1, which is actually time point 0.5, I jumped fromhere to here
* Okay?And now I keep incrementing k
* So now I take k is equal to 1, and Icalculate my x2, which is now 40
* And then I take k is equal to 2, and Iincrement, and I get x3, which is 80
* For all you guys, you guys can kind of see that this is really a linearapproximation
* It's not changing exponentially, and likewe thought it should, because we know that it should changeexponentially, but it's not
* And this is because, like I said, the moreterms you take in the Taylor series for your approximation, the better theapproximation
* So here, since we took just two terms,it's a kind of linear approximation
* If I take more terms and added, you know, acceleration, etc, then your approximationwould have been better
* And so, what we actually just found out,was nothing more than a dynamical model, and how you kind ofsolve it to see how your system is evolving
* So your differential equation and aninitial condition, or just a condition, basically telling you this is where I amat a certain time
* These two things are more than enough tofind out how your system is evolving with respect to time, and whatis your x of t
* And in general, general form, this is, howyou say, is your dynamical model
* Basically, it's an equation x star of t
* That is a function of its, you know, stateor time
* And later on, this is where you put inyour control input, you as well, when you guys go laterinto the course
* So you kind of, like I said, influencingthe change x dot of t, to make x of t do whatever youwant
* Right now we're not dealing with control,so it's just simply x dot of t is given bysomething
* And you have an equation here x t star isx star, which is basically saying that at sometime, I'm going to tell you where you should be inspace
* And with just this information, you shouldbe able to evolve x of t, and see how your state is changingwith time
* So that was pretty simple
* Punchline
* This is the following dynamical model,which we've been solving all this while
* We know how x evolves
* But we know how x evolves numerically,right
* We discretize the world.And we saw how x should evolve as we move thecounter from 1, 2, 3, 4, etc
* But we didn't really get the equation out
* You know, the mathematical expression forx of t, which we know is the exponential 2t,10
* We know that this was the actual solution,but we really didn't get this equation, prettyequation out
* What we got was a list of basically times, and where xshould land up, numerical solutions
* So if you had to, let's say, get theequation out, what do you do
* Well, you integrate
* And again, like I said, we know alreadythe solutions
* That's our hint.All we are given is this
* For all of those, this is not importantfor the course, but for all those people who want to see howyou integrate and get, you know, x of t, we can go over it reallyquick here
* It's really nothing but, of course, anintegration
* Let's say dx by dt is 2x
* You kind of separate the variables realquick
* So you say over x is equal to 2dt.Integrate both sides
* This is actually your logx is equal to twot plus c, c is your constant
* And now this is an equation you've got in which you're going to plugin your initial condition
* So log10 is equal to c
* And from here you say, okay, so let me putall this back into my main equation
* Logx becomes two t plus log10.And now you kind of, you know, shift terms here and there, and you get x isequal to 10e to the power 2t, x of t
* So now you guys even saw that, you know, if you don't want to do thewhole discretizing the world and kind of simulating where youshould be, instead you can integrate
* And a word of caution here, that you cannot always integrate and find thesolution
* Sometimes you have to rely on numericalmethods, because analytical solutions may not evenexist, you know
* You may not get pretty equations fordynamical models, etc
* But here, just to kind of show you that,you know, you can do it
* Just integrate, and you'll get the answer
* Again, it's not important for the course,but woo, we got it
* But what is important for the course is that eventhough maybe, okay, we won't ask you to integrate, what we'll do instead iswe'll say, okay, here is your model
* And I'm going to give you what I call acandidate solution, x of t should be 10e to thepower 2t
* And now what you need to do is figure out, is this indeed a solution to the model ornot
* And for that, there are just two simplesteps that you do
* First is called the initial conditioncheck
* What does that mean
* It basically means that I'm given this candidate solution, andthen within the solution, I'm going to kind ofput in my initial condition x of 0 and see ifI actually get 10 or not
* And here I do get 10, so it satisfies thisequation, my x of t
* And then the second check is thedifferential equation check
* And what is that
* That is really nothing but okay, again Ihave my candidate solution, but I'm going to now take thederivative of that candidate solution
* And 2e to the power of 2t, which is really my 2 times x, and see if it satisfies thisequation
* And it does
* So this is another technique
* So in case, you know, given a model, youdon't want to find out through integration or numericalmethods what your x of t should be, but instead I'm telling you what itshould be, this is how you check or confirm that it is indeeda solution or not
* Okay
* So the take home message of this entire lecture is really first,dynamical models
* What are dynamical models
* I hope I've kind of given you guys anidea, and made you sort of comfortable with the ideaof, you know, models
* And for example, you have something likethis, right
* Okay, then how do we solve them
* We solve, one we can do by numericalsolving, which is numerically discretize the worldand solve it
* And then, another is analytically, throughintegration, right
* And then the third thing, which is veryimportant, is that I give you the model and then I say okay, this isthe candidate solution
* You check the solution through two checks,the first being initial condition, secondbeing differential equations
* And sort of try and verify that this candidate solution is indeedsatisfying the model
* And this is a homework assignment for you guys
* For this model, see if you cannumerically, analytically, and this whole checkingthing, whether, you know, you can kind of solve it and see ifyou get this equation or not
* And before we wrap up this lecture,there's just one concept more, which is the equilibriumpoint concept, which I want to introduce
* Which is really nothing but basically thisconcept that if my state x wakes up here at this point, or at this position, or at this value, it staysthere
* As simple as that
* So it's really not anything more thansaying that my x dot of t is going to be 0
* So to find an equilibrium point, you dosimply x dot of t equal to 0, and find the value of x
* And like I said, now if, if I was to wakeup here, or if at, let's say, time t is equal to 0 I or 3, or whenever I wakeup, I am at this equilibrium point
* Because my x dot of t is 0 and there's nochange, my change is basically 0
* I will stay there.So it's really simple
* So in our case, in the dynamical model case, x is equal to negative 1 by 3is your equilibrium point
* So if you're asked, you know, find anequilibrium point, simply just put x dot equal to 0, or whateverfunction you have here equal to 0, and find the valuesof your state, x in this case, and that will beyour equilibrium point
* And also, with that check the forums
* Good luck with Quiz One.And bye bye.


--- SKIP ---: 12_programming-simulation-lecture-1.en.srt


--- SKIP ---: 12_programming-simulation-lecture-1.en_SENTbySENT.rtf


--- PROCESSING FILE --- 12_programming-simulation-lecture-1.en_SENTbySENT.txt
* Hello and welcome to the first Programmingand Simulation lecture
* I am JP, I am very excited to introduce the program, programming assignments inthis course to you
* Since this course is about controlling mobile robots, the progra, programmingassignments will focus on applying what you learn on thelectures to simulated mobile robots
* Therefore we will be using math lab basedrobot simulator called [UNKNOWN], and its important for you to know that the weeklyassignments are entirely optional
* Meaning that they do not factor into yourcourse grade however you have the option to submit each one of theassignments for feedback
* Since these programming exercises arecompletely optional, let me take a moment to convince you why they are worthyour time and effort
* First of all, they are a very unique opportunity to apply what you learn inthis course to a interesting problem
* In this case, it's safely navigating amobile robot through a cluttered environment which is a superexciting problem to solve
* Second of all, you will learn MATLAB,which is a very powerful tool for any engineer
* And as a bonus, if you build draw inQuickBot in this, that's built in this course, then everything that you write inthe programming assignments can be directlytested on this robot
* Hopefully, that's enough to convince youto start with the programming assignments, so let'sget started with
* Programming assignment number one and theobjective for this first assignment is to get comfortable with MATLAB and to runthe simulator at least once
* We have included detailed instructions forthis assignment in a section called programming assignments and you can findthis directly on our course page
* If your not already familiar with MATLAB
* It can best be described as numerical computing environment and aprogramming language
* Since we will be using MATLAB extensively in this course, and in the programmingassignments
* You'll have access to a license of MATLABfor the duration of the course
* In fact, this license won't expire until afew week, weeks after the course ends, which will be plenty of timeto complete all of the assignments
* These detailed installation instructionscan be found in the aforementioned programmingassignment section
* As well as links to resources for learningthe key MatLab concepts that you're going to be needing, that you're going toneed to complete all of the assignments
* The reason that we're using MATLAB in theprogramming assignments is that we've developed asimulator for mobile
* Robots in MATLAB
* And the simulator emulates the QuickBotand this robot has a two wheel differential drive, five infrared sensors, and twowheel encoders
* All of the programming assignments arebased on the simulator and they will require you to,for, example, write a go to go controller for theQuickBot that drives it from point a to point b
* And to help you in this endeavor, we'veincluded a very detailed user manual
* That will help you both implement and testyour code
* If you choose to receive feedback on your solutions we've designed a user interfacejust for that
* In fact over here is a screenshot of thisof this application
* What you do is you enter your submissionlog in and password, here
* And then you select which parts of theassignment you would like to have graded
* For example, you might want to grade thispart, but not this part.So you just check the first one
* Once you're ready to submit, you hit thesubmit to Coursera for grading, for gradingbutton right here
* What will happen is that a script willstart the simulator, as well as your code to gather output and compare the output to values stored on the Courseraservers
* If your output matches with, with what ison the Coursera server, you will get a checkmark
* And 100% for this part of the assignment.If it does not, you will get an x
* And that means you've gotten 0% credit forthis part of the assignment
* However, don't worry
* You will get feedback about what you mightwant to change in order to get the correctsolution
* And you may resubmit as many times as youwant until you get a hundred percent on all ofthe parts
* Just remember that the points earned inthis assignment will not count towards your grade, but this isreally a great opportunity to get some feedback on your solutions.So let's see all that in action in MATLAB
* This is MATLAB
* Here you see the command window, and to myleft is the current folder
* What I've done is I've downloaded the zipwith the simulator for this week
* And I've unzipped it and browsed to thislocation
* Here are all the files for the simulator
* If you want to launch the simulator you simply type launch into the command windowand hit enter
* This brings up the simulator, along with this cute swatch screen, swatch screenright here
* Along with a few instructions on how touse the simulator
* When you hit play.The simulation starts
* You can see the quick boat in the center,and I can zoom in and zoom out using thesebuttons
* As you can see the quick boat has twowheels, and five infrared sensors
* These infrared sensors in blue are notdetecting any obstacles, but the ones in red are detecting this redobstacle right here
* We can also pen around and see that thereare several other obstacles
* For example, these walls over here in theenvironment
* Any time you click on the robot the robotwill be centered on the screen for you
* You can also pause and resume thesimulation at any time
* Or restart the entire, entire simulationby clicking on the home button
* Once you're ready to submit, you type insubmit
* This will bring up the submission window
* Again, here are, is the login and passwordfor, for the submission on Coursera
* This week's assignment only has one partto it which is to run the simulator
* But on other weeks you might have up tothree different parts to complete
* Once I hit submit to Coursera for grading,the simulator should pop up
* And then close, close again because the entire assignment was just to run thesimulator once
* And as you can see, I've done that, so I've gotten a check mark and 100% for thisassignment
* If you have any questions, issues, bugs,or concerns, please create a post in the discussion forums under theprogramming assignments section
* And make sure to include enoughinformation for us and fellow students to help you out
* And with that, I wish you good luck.


--- SKIP ---: 01_driving-robots-around.en.srt


--- SKIP ---: 01_driving-robots-around.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_driving-robots-around.en_SENTbySENT.txt
* So, welcome to Module 2 of the course,Control of Mobile Robots
* In Module 1, we introduced control theory as a way ofdealing with the systems in general
* And in this module, we're going to introducemobile robots as the key target application of the course
* And what we'regoing to do is start with a very simple question
* How do I drive a robot frompoint A to point B, or in this case from a blue ball to a yellow sun
* And the firstquestion we need to understand before we can even answer how to drive it is what dowe need
* Well obviously, we need to measure where the sun is or the goal pointis, and somehow turn this into the control actions
* So, we've taken the informationfrom the sun and we're feeding it into the controller
* So, one of the things we needis to design the controller which we kind of know a little bit about already
* Wealso need to understand what information the robot actually has
* So, we're going tohave to discuss a little bit about how do robots actually gain information about theworld
* And, of course, for that, we need sensors
* So, we need to discuss sensormodels at the sufficient level of abstraction so that we can reason aboutthem, but they need to be rich enough so that we can trust that the informationthat our controller is based on, is actually something that the robot has
* Andthen finally, in order for the controllers to be useful, we need to be able tobasically predict how they're going to influence the robot
* So, we're going toneed models
* So, what I'm going to do in this module is to discuss robot modelsand, in particular, we're going to look at differential drive robot mobile robots andwe're going to discuss sensors
* And we're going to look at sensors that allow us togain information about the world around us and sensors that allow us to knowsomething about our internal state
* For instance, where is the robot
* what we willnot do is any advanced perception
* We're just going to look at the abstractedsensor models that give us the type of, of infor mation that we want
* But before weeven do that, whenever you try to design controllers for robots that drive aroundin the world, there are two facts that you really have to embrace
* And the first isthat the world is fundamentally unknown
* You're not going to know where every chairin the building is
* You're not going to know where every tree in the forest iswhen you're out driving in the forest
* So, there's no way you can plan in advanceexactly what the robot should be doing
* The second is, people move chairs
* Peoplemove around
* The wind makes trees blow , or sway.So, the world is actually changing and dynamic
* And for that reason, it's also abad idea to try to produce, in advance, a very complicated monolithic controller fordoing everything
* So instead, what we do in robotics, a lot of times, is we dividethe control task into chunks and then we'll design controllers for thoseindividual chunks
* So, for instance, if I'm a robot trying to get to a goal, I mayhave some kind of controller that's taking me to the goal and then when somethingshows up in the environment, I switch to another controller that allows me to avoidthat thing in the environment
* And, in fact these primitive building blocks thatfrom our point of view are different controllers, in robotics, they're calledbehaviors
* So, behaviors are going to be key concepts in this course and we'regoing to design quite a few of them
* And I just want to mention a handful of verystandard behaviors that we will indeed see
* Go-to-goal is the most basic one,which means drive to a, a waypoint or target location
* Avoid-obstacles isabsolutely crucial meaning, don't slam into things on the way over there
* Then ifyou're in, you know, an office environment, you know that the world istypically straight lines, walls, so follow-wall is not a bad type of behaviorto have
* If the goal is moving, you may want to track it instead of going to juststatic goal, and so forth, and so forth
* We'll see quite a few of these differentbeha viors
* And I would like to start with a videohere of a robot that I was developing or working on, that used camera informationto build up a map of what the world looked like and here is what the robot is doingwhen it's based on a planner
* Here's, it's seeing something and it's kind of puttingit in the map and then it's thinking up a new long plan to, for the robot to take.So basically, you saw the robot spending a, a large amount of time dealing with newinformation because it had to re-plan
* So now, we're running to exact same thingwith behaviors
* So, we're following a plan or just, in fact, follow plan behavior andthen when something pops up, we're switching to an avoid-obstacle behavior.So now, the same things which is up in the, or shows up to the robot
* Instead ofthe robot sitting around thinking for a long time, it just avoids it
* And onceit's clear, it goes back to following the, the, the plan
* So, this would be anexample of why behaviors are really useful
* Here is another example
* This isactually a segway robot, so the dynamics is very complicated
* And never mind the,the moving graphs in the lower, lower part of the picture
* What I want you to see isthat this robot is actually, in this case, switching between different arc behaviors.So, there are different arcs that the robot can take and the behaviors, in thiscase, are follow various arcs
* So now, you can put behaviors that are not as simpleas just go-to-goal and instead, the behaviors would be arcs of various sizesand shapes
* And we will become quite good at understanding how to design theseindividual behaviors, and as well, how to combine them.


--- SKIP ---: 02_differential-drive-robots.en.srt


--- SKIP ---: 02_differential-drive-robots.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_differential-drive-robots.en_SENTbySENT.txt
* In order to design behaviors orcontrollers for, for robots, we inevitably need models of how the robots actuallybehave
* And we're going to start with one of the most common models out there, whichis the model of a differential drive mobile robot
* So, differential drivewheeled mobile robot has two wheels and the wheels can turn at different rates andby turning the, the wheels at different rates, you can make the robot move around.So, this is the robot we are going to start with and the reason for it isbecause it is extremely common
* In fact, the Khepera 3, which is the robot that weare going to be using quiet a lot in this course is a differential drive wheeledmobile robot
* But a lot of them out there are, in fact, differential drive robots.Typically, they have the two wheels and then a caster wheel in the back
* and theway these robots work is you have the right wheel velocity that you can controland the left wheel with velocity that you can't control
* So, for instance, ifthey're turning at the same rate, the robot is moving straight ahead
* If onewheel is turning slower than another, then you're going to be turning towards thedirection in which the slower wheel is
* So, this a way of actually being able to,to make the robot more round
* So, let's start with this kind of robot and see whatdoes a robot model actually look like
* Well, here's my cartoon of the robot
* Thecircle is the robot and the black rectangles are supposed to be the wheels.The first thing we need to know is what are the dimensions of the robot
* And Iknow I've said that a good controller shouldn't have to know exactly whatparticular parameters are because typically dont know what the frictioncoeficcient is
* Well, in this case, you are going to need to know two parameters.And one parameter you need to know is the wheel base, meaning how far away are thewheels from each other
* We're going to call that L
* So, L is the wheel base ofthe robot
* You're also going to need to know the radius of the wheel, m eaning howbig are the wheels
* We call that capital R
* Now, luckily for us, these areparameters that are inherently easy to measure
* You take out the ruler and youmeasure it on your robot
* But these parameters will actually play a little bitof a role when we're trying to, to design controllers for these robots
* Now, that'sthe cartoon of the robot
* What is it about the robot that we want to be able tocontrol
* Well, we want to be able to control how the robot is moving
* But, atthe end of the day, the control signals that we have at our disposal are v sub r,which is the rate at which the right wheel is turning
* And v sub l, which is the rateat which the left wheel is turning
* And these are the two inputs to our system.So, these are the inputs, now, what are the states
* Well, here's the robot
* Now,I've drawn it as a triangle because I want to stress the fact that the things that wecare about, typically, for a robot is, where is it, x and y
* It's the position.And which direction is it heading in
* So, phi is going to be the heading or theorientation of the robot
* So, the things that we care about are where is the robot,and in which direction is it going
* So, the robot model needs to connect theinputs, which is v sub l and v sub r, to the states, somehow
* So, we need some wayof doing this transition
* Well, this is not a course on kinematics
* So, instead ofme spending 20 minutes deriving this, voila, here it is
* This is thedifferential drive robot model
* It tells me how vr and vl translates into x dot,which is, how does the x position of the robot change
* Or to y dot, which is how isthe y position, or phi dot, meaning how is the robot turning
* So, this is a modelthat gives us what we need in terms of mapping control inputs onto states
* Theproblem is, that it's very cumbersome and unnatural to think in terms of rates ofvarious wheels
* If I asked you, how should I drive to get to the door, you probablynot going to tell me how what v sub l and v sub r are, your probably g oing to tellme don't drive too fast and turn in this direction
* Meaning, you're giving meinstructions that are not given in terms of v sub l and v sub r, which is why thismodel is not that commonly used when you're designing controllers
* However,when you implement them, this is the model you're going to have to use
* So, insteadof using the differential drive model directly, we're going to move to somethingcalled the unicycle model
* And the unicycle model overcomes this issue ofdealing with unnatural or unintuitive terms, like wheel velocities
* Instead,what it's doing is it's saying, you know what, I care about position
* I care aboutheading, why don't I just control those directly
* In the sense that, let's talkabout the speed of the robot
* How fast is it moving
* And how quickly is it turning,meaning the angular velocity
* So, translational velocity, speed, and angularvelocity is how quickly is the robot turnings
* If I have that my inputs aregoing to be v, which is speed, and omega, which is angular velocity
* So, these arethe two inputs
* They're very natural in the sense that we can actually feel whatthey're doing which, we typically can't when we have vr and vl
* So, if we havethat, how do we map them on to the actual robot
* Well, the unicycle dynamics looksas follows, x dot is v cosine phi
* The reason this is right is, if you put phiequal to 0, then cosine phi is 1
* In this case, x dot is equal to v, which meansthat your moving in a straight line, in the x-direction, which makes sense.Similarly for y, so y dot is v sine phi and phi dot is omega because I'mcontrolling the heading directly or the, the, the, the rate at which the heading ischanging directly
* So, this model is highly useful, we're going to be using itquite a lot which is why it deserves one of the patented sweethearts
* Okay, thereis a little bit of problem though because this is the model we're going to designour controllers for, the unicycle model
* Now, this model is not the differentialdrive wheele d model, this is
* So, we're going to have to implement it on thismodel and now, here we have v and omega
* These are our, the, the control inputswe're going to design for
* But here, v sub r and v sub l are the actual controlparameters that we have
* So, we somehow need to map them together
* Well, the trickto doing that is to find out that this x dot, that's the same as this x dot, right?They're the same thing
* This y dot is the same as the other y dot
* So, if we justidentify the two x dots together, then divide it by cosine 5, we actually getthat the velocity v is simply r over 2, v sub r plus v sub l or 2v over r is vr plusvl
* So, this is an equation that connects v, which is the translational velocity orthe speed, to these real velocities
* And we do the same thing for omega
* We getthis equation
* So, only l over r is vr minus vl
* Now, these are just two linearequations, we can actually solve these explicitly for v sub r and v sub l and ifwe do that, we get that v sub r is this thing and v sub l is this other thing
* Butthe point now is, this is what I designed for, this is what I designed for
* So, vand omega are design parameters
* l and r are my known measured parameters for therobot, the base of the robot, meaning how far the wheels are apart, and the radiusof the wheel
* And with these parameters, you can map your designed inputs, v andomega, onto the actual inputs that are indeed running on the robot
* So, this isstep 1, meaning we have a model
* Now, step 2 is, okay, how do we know anything aboutthe world around us?


--- SKIP ---: 03_odometry.en.srt


--- SKIP ---: 03_odometry.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_odometry.en_SENTbySENT.txt
* So now that we have a model, we need someway of knowing where the robot is because the state of the robot is xy and fine,meaning the position xy and it's heading, fine
* Odometry is the means by which wecan obtain this pose information and the question is, how do we actually get thestate or the pose of the robot
* Well, there are a number of different ways ofdoing it, but at the end of the day, we absolutely need sensors 
* Well, there aretwo possibilities here
* One is we can use some kind of external sensors
* So, anexternal sensor would be a sensor that's measuring something in the environment.So, for instance, you pretend that you can see a, A landmark.Let's say I can see the Eiffel Tower
* And now I start moving around, if I keep trackof the Eiffel Tower I should be able to at least know where I am relative to theEiffel Tower
* Right
* That seem to make some sense
* So theexternal sensors
* Ultrasound, infrared, cameras, laser scanners, these are sensorsthat tell us something externally about where we are
* There is another type ofexternal sensor that one can use, of course, which would be GPS and it'sexternal because we're not measuring it internally, we're getting information fromOutside, and the GPS immediately would give us things like position and so forth.However, when you're running robots indoors, you certainly don't have GPSsignals, And a lot of times GPS alone is not enough to know x, y, and phi to anyhigh level of, of fidelity
* So what you do is you typically couple the externalsensors with internal
* Sensors
* So the internal sensors are sensors thatare sitting in the robot
* And they are helping you know where you are
* So, forinstance, you could use a compass to, figure out which way the, the robot isheading
* So this would be orientation
* Of course, in every self respecting robot,there are accelerometers, and gyroscopes for finding out
* And how far you'vetraveled and so forth
* So position and orientation can both be derived fromaccelerometers and gyroscopes to certain degree
* another useful way is Wheelencoders
* So typically you have tick counts, you can tick and count how many.Basically, how many revolutions the wheels are doing in a certain amount of time, andfrom that you can actually figure out things about where the robot is
* And, Iwould like to discuss a little bit with you about Wheel Encoders
* And the reasonfor that is, that if we are indeed now working with the referential drive robotsfor awhile, lets see, if we can find out a little bit of how we can get positioninformation
* And more importantly, how much can, Can be trusted
* So, a wheelencoder gives the distance moved by each wheel
* So, we have left and right wheelshere
* And here's the following assumption we're going to make
* We're going to assumethat each wheel is following an arc, which means that it's turning at a constant rateand driving at a constant velocity, basically
* So, v and Ohm r are constant.What this means is, on short time scales that's, That's correct.And if we do that, well, let's say that D is the distance the left wheel has turned,and D[UNKNOWN] is the , distance the right wheel has turned
* So in this case, theright wheel is turning quicker than the left wheel because it's turned, turnedmore
* Well, I'm interested in x, y, and phi
* Which is not where the wheels are,but where the center of the robot is
* This is where I'm interested in
* So DC is thedistance the center has turned and that's the thing that I'm interested in
* Nowluckily, the center is simply DL + DR / 2
* I am not going to be particularly Picky inshowing where the geometry of this comes from
* Instead, these are things that arereadily available if you want to look up things, like how wheel encoders work
* ButI want to connect a little bit with the mobile robot model to the wheel encoders,just to see how we reason about things, and in fact, if we are measuring how far.The road the wheels have moved over a time interval
* So let's say that we start at xand after the time interval , well we know Dc because Dc is this thing then we canactually compute the new x primes, the new x position of the robot
* We can similarlycompute the new y position of the robot
* Which is the same as the x update, but hassine instead of a cosine term
* And, we can even compute, the, the new orientation
* Sothis is a way of knowing how to go from, how far the wheels have turned
* Into whatare the new positions of the robot
* And, in fact, we're going to be running quite afew experiments, where the only information the robot has
* Is where it is,based on the wheel encoders
* So but how do we know Dr and Dl, thought
* This is whatwe need to know in order to find out where the robot is
* Well, assume that each wheelhas N ticks per revolution
* So 2 pi degrees is N ticks
* So most wheel encodersactually give the total tick counts as to
* The beginning, so what you measure is howmany ticks since, since you start the system up
* So, the updates I am writinghere for both wheels
* This is for the left wheel and the right wheel, so you couldwrite the you know
* Delta tick r or r or but for both of thesewheels you take the old total tick count
* And subtract it away from the new totaltrick, tick count
* So this tells me, what's the tick count during the timeinterval you just looked at
* And then based on that, you can very easily computewhat the distance that wheel has, turned
* So this d here, this d could either be d'sof l or d's of r, so it's simply 2 pi r delta tick over n
* So this actually givesas a way of mapping ticks on to distances traveled, and as we saw in the previous,previous slide distance traveled we can then map into new position and orientationof the , Fair enough
* There is one major disclaimer I must make,though
* And that is, ta-daa, drift
* A system like this, drift
* It's veryimprecise
* And, if your using only real encoders as your source of odometry, yourprobably going to run into a little bit of trouble
* So, here, I want to show a video.This was from one of the
* Cou rses I taught recently where you have now tworobots competing against each other
* It looks like they're following lines but allthey're doing is following wave points that laid down, and they're using a PDAregulator to get through wave points
* And what you can see is that they're getting alittle but out of whack, and the interesting thing here is one robot getsup on top of the other robot and as a consequence the wheel is spinning withoutit's actually touching the ground
* and as you can see The robot then has acompletely confused idea of where it is in the world
* So this would be an example ofwere drifts its rather severe the robot is going in way wrong direction because ofthe fact that the real encoders no longer correspond to what's happening on theground
* So we're going to use real encoders a lot
* They're used a lot inrobotics, but we always need to be aware of the fact that themselves, bythemselves, wheel encoders do not tell the full story or a particularly robust


--- SKIP ---: 04_sensors.en.srt


--- SKIP ---: 04_sensors.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_sensors.en_SENTbySENT.txt
* We have a model of a robot, we know howthe robot can get position information, in this case we used the wheel encoders butthere are other ways we talked about compasses and accele accelerometers butthe robot also needs to know what the world around
* It looks like
* And for thatyou need sensors
* And we are not going to be spending too much time modelingdifferent kinds of sensors, and see what is the difference between an infrared andan ultrasonic range sensor
* Instead
* We're going to come up with an abstractionthat captures what a lot of different sensing modalities can do
* And, it's goingto be based on what's called the, the range sensor skirt
* This is the standardsensor suite in a lot, on a lot of robots
* And, it's basically a
* Collection ofsensors that are
* The collection that is, gathered around the robot
* That measuresdistances in different directions
* So, infra red skirts, ultrasound
* LIDAR, whichare laser scanners
* These are all examples of these range sensors
* They're going toshow up a lot
* Now there are other standard external sensors of course,vision, or tactile sensors, we have bumpers or other ways of physicallyinteracting with the world or "GPS" or I'm putting them in quotation because thereare other ways of faking GPS
* For instance, in my lab I'm using a motioning,or motion captioning system to pretend that I have GPS
* But what we're going todo, mainly
* It's assumed that we have this kind of setup
* Where a skirt around therobot that can measure distances to, to other to things in the environment
* And infact, here is the Chipera It's a simulation of the Chipera
* And the Chiperain this case, has a number of infrared sensors
* And Well you see the cones, youhave blue and red cones, and then you have red rectangles
* The red rectangles areobstacles and what we're going to be able to do is measure the direction anddistance to obstacles
* So this is what type of information we're going to get outof these range-sensor skirts
* over here on the right you see two pictures of thesensing modalities that we had on The self-driving car that was developed atGeorgia Tech
* And we have laser scanners and radar and vision
* but the point is theskirt doesn't always have to be uniform or even homogeneous across the sensors
* Herewe have a skirt that is heterogeneous across different sensing modalities
* But,roughly you have the same kind of abstraction for a car like this, as wellas for
* Hey, Chipera, little mobile differential drive, robot
* Okay, so,that's fine, but we don't actually want to worry about particular sensors
* We need tocome up with an abstraction of this, sensor skirt, that, that makes sense, thatwe can reason about when we design our controller
* So, what we're going to do is,we're going to do some, or perform what's called a disk abstract
* Abstraction.So here's the robot, sitting here in the middle
* around it are sensors
* And infact, if you look at this picture here, here are little infrared sensors
* And infact, here are ultrasonic sensors.You see that scattered around this robot are
* It'sa skirt of range censors
* We're, they typically have an effective range, andwe're going to extract that and say there is a disk around the robot, of a certainradius, where the robot can see what's going on, right, so this is this, thispinkish disk around the robot and it can detect obstacles that are
* Around it.So the two red symbols there are the obstacles
* What we can do is we can figureout how far away are the two obstacles
* So, D1 is the distance to obstacle one,which is this guy
* And this is obstacle two, well, okay
* join with ratts of ensureand Pi one is the angle to that obstacle, similarly d2 is the distance to obstacle2
* Phi 2 is the angle to obstacle two
* One thing to keep in mind though is that robothas its own coordinate system in the sense that this, if this is the x axis of therobot right now, then Pi one is measure relative to
* The robot's x axis, so therobot's heading, right
* So we need to take that into account if we want to knowglobally where the obstacles are
* So let's do that
* If you have that, and if you knowour own pose, so we know x, y and Pi
* Then since the measured headings to theobstacles
* So this is Pi one which is measuring and we're measuring thisrelative to our orientation
* Lets say that our orientation is this right
* So here isphi and here is Pi two say, then of course the actual
* direction to obstacle two isgoing to be Pi 2 plus Pi
* So, what we could do, is we could take this intoaccount and compute the global position's of these obstacles if we know where therobot is
* So, for instance, the global position for obstacle one x1 and y1
* Well,it's the position of the robot plus the distance to that obstacle times cosine andsine of this Pi 1 plus Pi term
* So we actually know globally where the obstaclesare if we know where The robot actually is
* So this is an assumption we're goingto make
* We're going to assume that we know x, y and Pi
* And as a corollary tothat, we're going to assume that we know the position of obstacles around this inthe environment
* So that's the abstraction that we're going to be designing ourcontrollers around
* And I just want to show you a
* And I'm using an example ofthis, this is known as the rendezvous problem in multi agent robotics, where youhave lots of robots that are supposed to meet at the common location but they'renot allowed to talk, they're not allowed to agree on where this would be bychatting instead they have to move in such a way that
* They end up meeting in samelocation and one way of doing this is to assume you have a rain sensor disk aroundyou and then when you see other robots in that disk instead of thinking of them asobsticles we think of them as buddies so what we are going to do is each robot isgoing to aim toward the center of gravity of all it's neighboors so everyone that isin that disk, Disk, and because of the disk assumption or disk abstraction wejust talked about, we can actually compute where the center of gravi ty is of ourneighbors
* So here's an example of what this looks like
* Every robot is shrinkingdown
* Two, all the robots shrink down to meet at the same point, without anycommunication, simply by taking the disk around them, looking where are myneighbors in that disk, and now we know how to compute that
* And, then, computingthe center of gravity of my neighbors, and aiming towards said center of gravity.Okay, now we have a robot model
* We have a model for figuring out how to know wherethe robot is, we have a model for how do we know where obstacles and things inenvironment are
* Now we can use these things of course to actually startdesigning controllers, so that's what we're going to have to do next
* I do wantto point out though that the model The real encoder, and the disk abstraction.These are but an example of what you can do, and how you should make these kinds ofabstractions
* But for different kinds of robots, different types of models andabstractions may be appropriate.


--- SKIP ---: 05_behavior-based-robotics.en.srt


--- SKIP ---: 05_behavior-based-robotics.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_behavior-based-robotics.en_SENTbySENT.txt
* As I've already said, the world isfundementally dynamic and changing and unknown to the robot, so it does not makesense to overplan and think very hardly about how do you act optimally given theseassumptions about what the world looks like
* That may make sense if yourdesigning controllers for an industrial robot at a manufacturing plant where therobot is going to repeat the same
* Motion over and over and over again
* You're goingto do spot welding, and you're going to produce the same motion 10,000 times in asingle day
* Then you'll overplan
* Then you'll make sure that you're optimal
* Butif a robot is out exploring an area where it doesn't know exactly what's going on,you don't want to spend all your computational money on Finding the bestpossible way to move
* Because, it's not actually going to be best
* Because theworld is not what you thought it was
* So the key idea to overcome this that's quitestandard in robotics, is to simply develop a library of useful controllers
* So theseare controllers that do different things
* Like going to landmarks, avoidingobstacles
* We saw one that tried to make robots drive through center of gravity oftheir neighbors
* Basically, we can have a library of these useful controllers,behaviors if you will, and then we switch among these behaviors in response to whatthe environment throws at us
* If all of a sudden an obstacle appears, then we avoidit
* Then if we see a power outlet and we're low on battery then we go andrecharge
* So we're switching to different controllers in response to what is goingon
* So what I would like to do is to start designing some Behaviors just to see howwhat we learned in module one, a little bit about control design can be used tobuild some behaviors
* So let's assume we have our differential-drive mobile robot.And to make matters a little easier up front, we're going to assume that thevelocity
* The speed is, is constant
* So v not
* We're not going to change how quicklythe robot is moving
* So what we can change i s how we're steering
* So you'rebasically sitting in a car on cruise control, where the velocities arechanging, and you steer it
* That's your job
* And the question is, how should youactually
* >> Steer the robot around
* So, this is the equation then, that'sgoverning how the input Omega, it's the state that we're interested in, in thiscase pi, which is the heading of the robot
* So, pi dot is equal to Omega
* Okay,so, let's say that we have our
* >> Yellow triangle robot, it's a unicycle ordifferential-drive robot
* It's headed in direction five, so this is the directionit's in
* And, for some reason, we have figured out that we want to go in thisdirection, five desired or 5 sum D
* Maybe there is something interesting over here,that were interested in
* So, we want to drive in this direction
* Well, how shouldwe actually do this
* Well, pi dot is equal to Omega
* So, our job clearly is that offiguring out what Omega is equal to, which is the control input
* Alright, so, how dowe do that
* Well, you know what
* We have a reference, pi desired
* Well, in moduleone
* we called references r
* Right
* We have an error, meaning, that compares thereference pi desired to what the system is doing
* In this case, pi
* So it's comparingthe headings
* So we have an error, we have a reference
* You know what
* We have adynamics
* pi dot is equal to Omega
* So we have everything we had towards the end ofmodule one
* So we even know how to design controllers for that
* How should we dothat
* Well, we saw PID, right
* That's the only controller we've actually seen
* So,why don't we try a PID regulator
* That seems like a perfectly useful way ofbuilding a controller
* So, you know what, Omega is Kp times e, where Kp was theproportional gain
* So this response to what the error is right now
* You make Kplarge it responds quicker but you may induce oscillations, then you have theintegral of the error
* So you take the e of tau, the tau times k sub i, which isthe integral gain
* And this thing, this integral, has the nice property that it'sintegrating up all these tiny little tracking errors that we may have, andafter a while this integral becomes large enough that it pushes the system Up to notracking errors, that's a very good feature of the, the interval
* Even thoughas we saw we need to be aware of the fact that a big KI can actually also induceoscillations and then we could have a d terms
* A KD times e dot and that where KDis the, the gain for derivative part
* This makes the system
* Very responsive but canbecome a little bit oversensitive to noise
* So will this work
* No it won't
* AndI will now tell you why
* In this case we're dealing with angles
* And angles are.Rather peculiar beasts
* Let's say that phi desired a 0 radiance
* And my actualheading now, phi is 100 radiance
* Then the error is minus 100 radiance
* Which meansthat this is a really, really large error
* So Omega is going to be ginormous
* But,that doesn't seem right
* Because 100 pi radius is the same as zero radius, right?So, the error should actually be zero, so we should not be niave when we're dealingwith angles
* And, in fact this is something we should be aware of
* Is anglesare rather peculiar beasts
* And we need to be, be dealing with them
* And there arefamous robotic crashes that have been caused by this
* When the robot startsspinning like crazy
* Even though it shouldn't
* But it's doing it because itthinks it's 200 pi off instead of zero radius off
* So what do we do about it?Well the solution is to ensure that the error is always between minus pi and pi.So minus 100 pi, well that's the same thing as zero
* So we need to ensure thatwhatever we're doing is we're staying within minus pi and pi
* And there is areally easy way of doing that
* We can use a function, arc tangents two
* Any languagethere is a library with and it operates in the same way
* It's a way of producingangles between minus pi and pi
* C plus, plus has it, Java has it, MATLAB has it,whatever you, Python has it
* So you c an always do this and how do you do that?Well you take the angle that's now 1,000,000 pi right and You take sine of itcomma cosine of it
* So this is the same as saying that we're really doing arc tan
* SoI'm going to write this as tan inverse sine e over cosine e
* But arc tan or taninverse
* Doesn't, it's not clear what that always returns but arc tan 2, where youhave a coma in it, you always get something that's within minus Pi and Pi.So here's what you need to do, whenever you're dealing with angles and you'reacting on them, it's not a bad idea to wrap one of these arc tan two lines aroundit to ensure That you are indeed having values that aren't crazy
* So, with alittle caveate that we're going to use e prime instead of e, the PID regulator willwork like a charm
* Okay, so here is an example problem
* We've already seen thispicture
* this is the problem of driving the robot, which is the little blue ball,to
* The goal, which is the sun, apparently, and lets see if we can usethis PID control design on Omega to design controllers that take us to the sun, or tothe goal
* and since we're dealing with obstacles and we're dealing with goallocations, and we're also talking about behaviors
* at the minmum we really needtwo behaviors
* Goal to goal, and avoid obstacles
* So what we're going to do overthe next couple of lectures, is develop these behaviors, and then deploy them on arobot and see if there any good or not.


--- SKIP ---: 07_the-grits-simulator.en.srt


--- SKIP ---: 07_the-grits-simulator.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_the-grits-simulator.en_SENTbySENT.txt
* So, when you do control design you alwayshave a number of parameters that need to be tweaked and tuned
* And there's reallyno way of selecting these parameters without actually testing what's going on.So, we have seen how to design now goal to goal behaviors but we haven't reallypicked parameters in the PID regulator
* So, what we're going to do now is takewhat we have done and actually simulate it
* And for that, we're going to use ourin-house GRITS robot simulator, which is a MATLAB-based simulator
* It's based on aKhepera [inaudible] differential drive mobile robots with infrared range sensorsaround it, so it can detect things in the environment and odometry is obtained usingwheel encoders
* and I should point out that I will be using this simulator quitea lot in this course
* and you can actually download it for free at this address andyou can either download it as a standalone executable, which means you'll be able torun it and interact with the user interface, or you can download the entireMATLAB package
* Now, I will not require that you use if for the course, but if youwant to play around with different control designs on a robot, this is a very goodsimulator to start with
* So, let's actually see what it would do
* So, I'mgoing to move over to MATLAB and start up the simulator
* And what we're going to seehere is, this is the robot, it's pointing in some direction
* I have placed a goal atnegative 1, 1 so it's going to go backwards in this direction to get to thegoal
* So, let's see what it's actually doing
* So, I'm going to start playingthis
* The robot is turning, turning and, as you can see here, the blue line is the,is the actual heading and the dotted line, the red line, is the desired heading
* Andhere, we have quite a bit of overshoot
* So, this is not a particularly goodcontrol the sign actually that's going on because we're overshooting even though wenow seem to be stabilizing towards the direction in which we want to go
* So,instead of going in this direction, let' s, let's see if we can do something betterto the, the control parameters
* So, I'm going to open up the file where we definethe PID controller
* So, I have a p gain, a proportional gain of 10, an integral gainof 10 and no d gain
* Well, the integral gain of 10 seems rather excessive to me.So, I'm rather brutally going to say, why don't we make it 0
* We're not caring aboutgetting exactly there
* So, let's turn it down to zero and actually see whathappens
* So, if we do that and close this window here, and this window, let's seewhat happens, let's start it off again
* Well, now, let's, let's start thesimulator and now, it should go again to negative 1, 1
* And hopefully, we'll wewill have cured the robot of its annoying overshoot
* And look at this step response.See how the desired heading goes up to, or the actual heading goes up to the desiredheading quite nicely and then stabilizes to where we wanted
* So now, in simulation,we have verified that this particular choice of control parameters is, is atleast not entirely useless
* which is a good way to start when you actually go ona real robot
* So now, let's stop this simulation business and move on to theactual robot
* So, now that we've seen how to think about control design for buildinga go to goal behavior, and we even simulated it with varying degrees ofsuccess, let's actually now put it on an actual robot
* So, I'm here with again, JP,who is the master of ceremony and a Khepera 3 differential drive mobile robot.And we're going to be running exactly the same code as we did in the simulator
* Allwe're doing is flipping a switch so we're actually running it on the robot insteadof on the simulator
* And this differential drive robot will know where it is basedsolely on the edometric information it's getting from the wheel encoders, and itstask is, is to make it from here over to this turquoise gold point here
* And asimple PID regulator is enforced and we're going to use the same parameters as in thesimulation With a p of 10, an i gain of 0 and a d gain of 0, so its a pureP-regulator
* And without further ado, JP, let's see how the computer does
* ,, , Andas you can see the turn was nice, there are very few or little oscillation hereand the Khepera is making it very nicely all the way to the turquoise goal point.So, we will call that a success.


--- SKIP ---: 08_obstacle-avoidance.en.srt


--- SKIP ---: 08_obstacle-avoidance.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_obstacle-avoidance.en_SENTbySENT.txt
* So now we feel pretty confident abut ourability to design controllers that take a robot to a goal location
* In fact we'veseen it in design, we've seen it in simulation, and we've even seen it in reallife
* But we have not discussed the issue of
* Well what if the robot needs to dosomething slightly more elaborate than just get to the point for instance youtypically don't want to hit things on the way over there so the one behavior that Iwant to talk a little bit about is obstacle avoidance because goal to goaland obstacle avoidance are really the dynamic duo of mobile robatics
* ,, 
* We'regoing to do more things, of course
* But underneath the hood, there will always bea goal to goal, and an obstacle avoidance behavior
* And let's think a little bitabout how one should avoid driving into obstacles
* Because going to goal locationwas not
* Particularly complicated
* Well, we can clearly use the same idea aswe did in go-to-goal by defining a desired heading, and then simply, you know, steerin that direction
* So, let's say that we have the following
* The robot, well, it'sthe blue ball
* And then we have this little red
* C, which is the obstacle,located at xo yo
* And the reason that we know the location of this is because the,the disc obstraction we talked about, when we talked about the sensors
* Okay, if thisis a goal, we would steer towards it
* That much is clear, now, the question is If itis an obstacle which direction should we steer it, when it's not as clear
* I mean,here is a direction we can go in
* You know, let's run away from the obstacle.But that's a little overly cautious I think
* At least sometimes, if I'm not evenon m way towards the, The red thing
* Why do all of a sudden I have to insist ongoing the opposite direction
* So
* This is one direction which we can go in, but itseems a little, how should I put it
* It seems a little skittish, or paranoid
* Weshould be able to be a little bit more
* Clever, maybe like this
* So if we're goingin this general direction, then we should maybe go perpendicular to the, thedirection to the obstacle
* That's one way in which we could be thinking but thereare other choices we could make
* Let's say that we have a goal
* Again, we're not justavoiding obstacles, we're actually trying to go somewhere
* This obstacle The redobstacle we see here
* Well, it doesn't seem to matter if I'm going towards thegoal, what do I care about that obstacle
* So, hey we could just ignore it
* That'sone direction we could go in
* Or we could somehow combine the direction to the goalwith some way of avoiding an obstacle
* So, we could kind of move away from theobstacle while somewhat getting towards it
* To goal.The point here is that there is no obvious correct answer, going to goal its clearwhich direction we want to go in
* When we're avoiding an obstacle its not asclear, its not obvi, obviously have to go in this direction and we have choices andsome how some choices are better than others
* So lets, lets look at some ofthese choices that we have a little bit
* Okay.So we have the robot in blue, we have the obstacle in red
* And we have the goal inyellow
* This was choice one
* Pi 1 is, I'm going to call it Pi obst plus Pi
* So Piobst is this angle, right
* So, here is phi obst
* And in fact, Pi obst is we can writeit as arc tangent y obst minus y over x obst minus x
* So this is some way in whichwe compute the angle to the obstacle and then we can say well Pi 1 suggestion onewhich is the
* The super paranoid robot who's avoiding obstacles at all cost, it'sadding Pi to the mix
* And by the way why am I adding Pi, and not subtracting Pi?All right, so, here's the, the, the angle I want to go to the, this is phi obst.And, what I'm doing no is adding Pi
* Right, so, this is , well the point isthat it actually doesn't matter if you add Pi, or subtract Pi, because by now we knowthat angles are slightly scary objects
* And, we always take something like rtangents too, to ensure that we stay within minus Pi and Pi
* Adding Pi orsubtrac ting Pi as long as we take
* Some safety measures, it doesn't matter
* So, wecan do the same thing
* It doesn't matter which one we choose
* But, that's one way.Now, this direction is pure in the sense that I don't care where the goal is
* I amjust going to move away from the obstacle as much as I can
* So, I'm going to callthis pure avoidance
* No notion of where I'm supposed to be going
* Well, we hadanother choice, right
* We said, what if we go perpendicularly to this direction?Well, so Pi 2 is Pi obstacle plus minus Pi
* Well, what does that mean
* It meansthat if I do minus Pi over 2, I go in this direction
* If I do plus Pi over 2, I go inthat direction
* And there, here it actually matters if I do plus or minus.And the question is, which one should we choose
* Well, typically that depends onwhere the goal is
* So we should pick in this case minus Pi over 2 because thatmoves us closer to the goal, while plus Pi over 2 moves us further away from thegoal
* And the punchline here is really that this is not a pure strategy, becausewe need to know where the goal is
* Instead, what we're doing is we'reactually, I'm calling it blended in, in, in the sense that we're taking thedirection to the goal into account when we are figuring out in which direction weshould be going
* So it's not a pure obstacle avoidance
* If I just ask you toavoid an obstacle, you say I can't, because it needs to know where the goalis
* In that sense, it's not pure
* So, that's one choice
* Well, remember thisone
* We said, you know what
* This obstacle is no big deal to us, we are just simplygoing to go in the direction of the goal
* Well, this is pure goal to goal
* We'rejust running one behavior
* goal to goal, we don't care about the obstacle
* Andwhat's more interesting is this choice, Fi 4 which is really a combination of thedirection to the goal and the direction to the obstacle
* And the interesting thinghere is that this is clearly a blended mechanism, somehow we combining go togoal, type oyds with obstacl e avoidance of ideas and the punch line here is thatthere are really two fundamentally different ways of combining, avoidingslimming interstuff and getting to goal points and these ways of combining thingsis called an arbitration Mechanism so we saw typically in this case twofundamentally different arbitration mechanisms one is the winner takes allapproach which is a hard switch when we're just going straight away from the obstacleright so here was the obstacle here was the robot with the robot was going therewe're doing just avoid obstacles
* Or, if the goal was here, right
* And we're goingstraight to the goal, we're doing just go to goal
* So, these would be two examplesof hard switches
* Now, the two other examples we saw were blended behaviors.One was, you're combining somehow, the angle to the goal and the angle to theobstacle to produce a new desired angle
* and the first blended behavior we saw wasone where we're kind of moving perpendicularly to the obstacle, but we'redoing it in such a way that we're getting closer to the goal
* And these are twovalid ways of designing arbitration mechanisms
* And in fact, we are going tohave to get systematic and careful about how to do it
* And I should point out thatboth Approaches have merit
* Now the nice thing about the winner takes all is thatif go to goal is only going to goal, then I can analyze that
* If obstacle avoidanceis only avoiding obstacles then I can analyze that, which means that from ananalysis point of view it's easier to deal with hard switches
* However, it's notnecessarily the case that from a performance point of view hard switchesare to be preferred
* Because, it seems like as I'm walking around I'm kind ofkeeping an eye on where I'm going while not slamming into things
* So I'm noteither going towards something or avoiding slamming into things
* So it seems likeperformance wise, blending or smoothing the two behaviors makes a lot of sense.However, from an analysis point of view it's harder
* So, the question is ho w doyou design your system in such a way that you can have your cake and eat it meaningyou can analyze what's going on and you still have good performance
* So, we aregoing to have to bite this bullet head on, and in fact we would be very systematic.And what we have done in this module, module two is simply introduce mobilerobots
* We've looked at some basic models
* We looked at some basic ways in whichwe're getting information about the world
* And we designed some basic behaviors, butto be honest, we haven't been particularly careful about what we did
* Module one, wewere also not particularly careful, but there the focus was on control theory
* Somobile, mo, , module three is enough chit chat
* Let actually start this course in amore systematic and formal matter
* So, we're going to return to module one
* Inmodule three and then we're going to return to module two
* And we're going tosee, can we do what we just did, did in a rather heuristic and ad hoc manner in asystematic and more formal way
* And the way to do it is to go to the wonderfulabstraction that is linear systems theory
* So, that is the focus of the next module.


--- SKIP ---: 09_glue-lecture-2.en.srt


--- SKIP ---: 09_glue-lecture-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_glue-lecture-2.en_SENTbySENT.txt
* Hi, I'm Smirti Chopra again, and I'm yourinstructor for the Glue Lectures for the duration ofthis course
* This is Glue Lecture Two, and let's getinto it
* This lecture is titled Robot Models,because this week you guys focused a lot on different models forthe robots specifically
* And as usual pay attention because thislecture will help you guys with quiz two okay, withthat
* So, we saw at this week in Dr
* [UNKNOWN] lectures that he introduced two models forthe robots
* That's your robot, and then one model waswith respect to, you know, the angular velocities Of the wheels of the robot,which is the differential right model
* And then another model that we saw waswith respect to the sine of v and omega inputs
* So why these two different models are,why, why is it that you know, we have a One model that's actually your angular asand the other model that's your b and they go
* Well, he went over it, and he explained toyou guys that, you know, this differential drive model,which is actually the one that is used with the robot, or actually the modelfor the robot, it's a two-wheel differentialdrive Thing is very important because when yourimplementing your controller onto the robot you have to use the correctmodel
* It has to two wheels, so obviously youneed to give it inputs with, for both thewheels
* But when we are designing our controllerand we are designing our controls, in that time we don't want to, you know,think in terms of wheel velocities etc., we'd rather just Think in terms of, you know, okay, mewalking and I'm walking with a linear velocity andan angular velocity, and it's kind of much easierthan, you know, thinking about each wheel and how itturns, et cetera
* So we have these two models here, thedifferential drive and the simpler model, which is usedfor design
* Okay, so I just want to show you guys thisModel in action, or you know, this whole thing of how youdesign controllers based on the different model and then you use somethingelse for implementation
* And that's
* Watch this video, it's a reallyinteresting video
* It's my work
* And it's robots playing music
* And they're playing Beethoven's Fur Elise,actually
* The point here that I want to make is that [MUSIC] All the control that is designed for thisvisual box is done using the model, the simplified model that we saw,the v omega model, but then when you are implementing it onto these robots andactually converting my v omega into, you know, angular velocities for each robotand that is the input that they are getting
* [SOUND] Here
* So in [INAUDIBLE] it's a differentialdrive robot, and that's what, how we are doing it
* Okay, so, how do you do that
* If you really simplify and see, this wasmy robot, and basically what I'm saying is, you know, you go from point A to pointB in time ten seconds
* This is a simple thing you'll, here, thisAt this point it's playing note A on the piano and hereit's playing some G sharp or something, let's say, onthe floor piano and it needs to go from here to here inten seconds
* That is the basic problem for one robot ifyou really simplify it
* Okay
* This is the model I'm using, like I said,to calculate my V and omega to make themactually do this
* That's how or however whatever trajectorythey take, straight line, move like this,whatever they are doing this input that I am giving themis based of the model shown here
* Choose the high level task and thencontrol design is done here
* But then the Cmd that I am going to besending to the robots Are going to be found using thismodel which is the differential model
* You guys have seen all this before
* Okay, what happens is when you use thisguy and this guy together, you can actually derive these solutions.So all I'm saying is that, I'm going to find V comma Omega based onthis guy
* And then I'm going to convert it and putit into this equation here to get v r and vl
* Which is what then i'm going to send tothe robots
* And that is exactly what you saw in that,Music playing robots thing as well
* So okay that is one more we'll do another
* And an intuitive example, let's go reallyquick over it
* Let's say my velocity input that I'm giving to my robotis zero and my omega or my angular velocity is constant, what are the corresponding angular wheelvelocities
* So again, v and omega is what I have foundout But when I send the commands to the robots, I'm going to find Vr and Vlusing these equations right here
* Right
* So, when you plug this stuff in, you seethat Vr is going to be this value here
* Vl is going to be this value here
* Where C is just some constant which isactually the Omega
* Okay, now intuitively, do you understandwhat's happening here
* Let's see that my robot let's its unitspoint and I'm saying that you know it's not going straight at allit's just going to keep moving you know on its' own like I'm saying myvelocity is zero but my omega is constant so I have a constantangular velocity, okay That means that my robot is not moving forward, it's justspinning in place
* And that makes sense because now whatwe've found out, in terms of, you know, right and leftwheel angular velocities
* One, is simply the negative of the other
* So one wheel is getting, let's say, plus five and the other is getting negativefive
* So they're just going to, going to makethe robot spin in place
* It's not going to make it go forward atall
* So that was the whole intuitive example
* But basically you guys should be prettycomfortable going between this,you know, mapping ortransformation, from v [UNKNOWN] to v r u
* Okay, with that, I'm back to our musicalbot
* So you guys remember this
* Of course you do, it happened two slidesago
* This musical bot example My Rova having togo from A to B in, let's see, ten seconds
* Now I want to go a little deeper into thecontrol
* So earlier we, when we showed the mappingbetween, you know, v and omega and vr vlv, assume that somehow magicallyI really had v and omega, right
* Now I want to go a little deeper and sayokay
* This whole finding the control V andOmega
* Based on the model that I said
* How, what does it actually mean?This is the model I have
* Now I'm asking you guys this.That [SOUND] Let's make it really simple
* My robot is here and it's looking also inthis direction
* Okay
* It needs to go from here to here
* Let's say even my Theta is perfect.It's already looking here
* It wakes up at A.It needs to reach it, at 10 seconds
* So why can't I just say?Guess what
* Omega can be zero
* And V can be, B minus A over 10.Right
* And we know all of us know from Physics,Geometry from the model et cetera, that if I was to givemy robot this velocity, and this omega, and atevery time instant for 10 seconds, I can, I'll in fact reach thispoint, over here
* It's simple maths, right
* So why don't we do that
* Why do we make such a big deal about, oh, we have to design the control V, omega etcetera, like
* Is this what the robot is doing actually in that music video that we just sawetcetera
* Well the answer is no.Why
* Because we don't live in a perfect world
* So in our world of simulation this wouldbe perfect, yeah sure, in my computer and in my, youknow
* Mind, it works perfectly, but actuallywhen I put it onto the robots, what's going to happen isthere will be friction
* There will be other problems
* Maybe my wheels don't move at the samerate that they should or maybe the encoders are slightlyoff, or maybe I come and kick the robot off while it'smoving
* Whatever
* I need - To know that let's say while I'mmoving here I wear off slightly by V and omega at this point needs to knowthat I have gone off the path
* In other words we need to have feedback,if there is no feedback of where I am in the world then, then it's so easyfor me to just veer of because of, you know, problems likefriction, etc
* When I'm actually moving the robot andthen my v and omega has no idea that I want to
* So let's say while walking I come here,I'll just keep going straight instead
* I'm not doing any kind, kind of you know,feedback on, on how I should be moving
* So this, I think this a very key conceptin controls that And kind of motivates why itis that we need state information or we needFeedback or even all the stuff that you studied about you know,PID regulators, PI everything
* When you are minimizing the error you needFeedback, you need output, you need to know whereyou are in order to find even the error, how far you are from, what you need to bedoing
* For all this Feedback is a very importantthing that you need
* So hopefully with all this, I have kind of explained to you guys, the motivationbehind why you need to know where you are in theworld
* And as you saw in the lectures Dr.Edgarson goes over this whole thing of wheelencoders, right
* because if you have wheel encoders youwill be to measure where you are
* Okay, for that again real quick.this is how the wheel encoder works
* Each encoder has N ticks, and a total of Nticks that means if you over haul N ticks you wouldhave moved one revolution on the wheel which is two pi r on, you know, your distance, and then you have Dl,Dr, Dc
* What is Dl, Dr, Dc is basically how muchYour wheel is moving how much distance the distance of this arc,for example, based on the number of ticks
* So that I have got 5 ticks how much Imove
* what is this distance
* that is given by Dl, Dr, Dc.Dc is this
* You see all this before and then okay once we had this of this is what you know,the wheel encoders give us now what, how do we find where weare in space
* Okay, I know where I am in the beginninglet's say I this is where I wake up
* Now I use DL, DR, DC in this form, in thisupdate equation and now I get my new position X prime, Yprime, and V prime
* And remember, X, Y, and V is my state, orwhere I am in place, like X, Y, and looking there.That kind of a thing
* Okay, cool.So this whole thing is the wheel encoders
* This is how they work
* So just for your general you know,knowledge or curiosity if you are wondering where did this modelcome from, well we could go back to our, you knowconcepts in physics really quick and we could belike, all right
* If this is a circle, if this is me walkingon the circle with radius Small r here
* And I have a speed of lets say, you know,some v, linear speed
* Well, I must have some angular velocity,right
* For b to be walking on this circle
* Otherwise, I would just keep walkingstraight
* So how do these 3 variables, kind of youknow, match up
* So, There is this very famous formula weuse, omega R, that kind of relates the fact that if somebody iswalking or if you are tracking this point on a circle of radius R, how does thelinear velocity, which is V, and the angular velocity, which isomega relate to one another
* And now if I wanted to see how muchdistance I moved in let's say time delta t, well,what I'm simply going to do is I'm going to say,multiply this with my speed, and my distance then becomesomega r delta t
* That's the distance.And I want you guys to like, kind of Understandthat the same concept can be thought of in terms of the, eachwheel of the robot
* So if my angular velocity for each wheelis vr and my radius is r, I can actually calculate the distance moved as r times vrtimes dt
* And from here, I'm going to let you guysfigure out How it is that we'll reach this model
* And as hence, I'm going to say, okay, wealready found out how we got this
* We know this as our model for the robot
* And now can we do something to you know,kind of get this equation using The update lawthat we know that if we ever want to find theposition of the next time is when we simply sayposition of previous plus x dot time.So it's a nice exercise find out how we get this model and then, all is good.With that let's go to the next example
* So this is an odometry example.Just to kind of you know make it again really clear the concept of wheel-encodersagain very important for the quiz
* So let's say my robot starts at the origin
* When I say origin, I mean my position andorientation both are zero
* And it is located after the 0.1 secondswhat you have to find
* Now, where is it
* And now it is given that your left wheelor your right wheel of the car, then takes your left wheel ofthe car six ticks, blablabla
* All the stuff is given.How will you do it
* Okay
* These are the set of equations that youare going to use
* First, because you know the numbers ofticks, you're going to find out how much each wheel has moved
* Based on these equations right here,right
* And then you're going to use them in thisupdate law to find out finally where your x, y, andpi land up
* And a real quick note just for mysatisfaction here is that it's nice to wonder If I'm the robot, orif I have the robot, I know the input I'm giving it, I know theangular velocities I'm giving it, right
* So why can't I myself find out through mymodel, which is this, right, this guy here, why don't Ifind out By updating using this where my next positionis going to be based on just my VR and VL
* Why is that that I'm using the encoder in the firstplace like why don't I just simulate based on my inputs whereI'm going to be in the time insteasd
* Well, that's exactly the point that we'retrying to make here that Even though I'm giving it a certain input, I don't knowthat it's actually going to be doing that
* So when I update my equation, I don't wantto do it based solely on the model
* I actually want to get feedback, physicalfeedback from the robot, and that's how I want to update myequation
* That's why we do this whole in quarterthing instead of just simply saying, you know what
* I'm going to find it myself through myupdate equation because I know [INAUDIBLE] And I'm going to find out where my x, y,and z line up
* No, that's why we don't want to do this
* We want feedback
* We want to see if it actually translatedinto that much motion or not
* That's why we use the [INAUDIBLE]
* And with that, we will In this lecture andgood luck with quiz two
* Keep checking the forums.Bye bye.


--- SKIP ---: 10_programming-simulation-lecture-2.en.srt


--- SKIP ---: 10_programming-simulation-lecture-2.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_programming-simulation-lecture-2.en_SENTbySENT.txt
* Welcome back to the second Programming &Simulation lecture
* This week I will talk about DifferentialDrive, Odometry and Infrared Sensors
* In fact, this week's programmingassignment is focused on implementing the robot'ssensors and actuators
* Therefore, you will need to transform fromthe unicycle dynamics in the controllers to the differential drivedynamics and the mobile robot
* You also need to use the wheel encoder to keep track of the robot's position andorientation
* This is called odometry
* And third, you'll need to use the infaredsensors to measure distance to any obstacles thatmight be around teh robot
* The simulator emulates the QuickBot, andthe QuickBot is defined in the quickbot.mfile
* This is a class and it's located in therobot package
* Packages in MatLab are denoted by a plusin front of the folder name
* This robot has a two-wheel differentialdrive, meaning that each wheel is independently, controlled bya single motor
* And, it also has a wheel encoder for eachone of the wheels
* And these wheel encoders are responsiblefor measuring the distance that each wheeltravels
* And they have a resolution of 32 ticks perrevolution
* And the robot also has five infrared sensors and these infrared sensors candetect any obstacles, that are within a range of four to thirty centimeters in their field ofview
* Following is a little diagram to explainto you how the simulation actually works
* First of all, there is the simulator andit has a timer object
* And this timer object calls at every time step the execute function inside thesupervisor
* The supervisor is really the decisionmaker and it's responsible for, first of all, gathering the sensorinformation from the robot
* It then selects a controller
* And passes the censor information alongwith an estimate of the robot's position and orientation to theexecute function in the controller
* This execute function in the controller,then computes the appropriate linear and angular velocity ofthe robot which is then, converted to the left and rightreal speeds of the robot and passed back to therobot
* Supervisors also responsible for updatingthe estimate of the robots position in orientation and this whole process is repeated at everytime step
* The supervisor itself was defined in theQB supervisors.Mfile where as all of the controllers are found in thecontroller package
* The first part of this assignment is, toconvert the linear angle of velocity in the controllers to the left and right angular wheel velocities on themobile robot
* You'll do this in the unit diff function which is defined in thedifferentialdrive.m file
* This function takes in the linear andangular velocity of the robot and returns the left and rightwheel speeds
* The skeleton code show you how to retrieve the radius of the reel r andthe distance between the two reels, l
* What you need to use to calculate the leftand right wheel speeds
* The second part of this assignment isodometry
* What you need to do is to measure thedistance traveled by each wheel and estimate the position andorientation of the robot using those measureddistances
* You will implement this in the update odometry function, which is inside theQBSupervisor.m file
* Let's take a look at the skeleton code forthis function
* Here you have the ske, skeleton code forthis function
* First you will retrieve wheel encodertakes from the robot, then you will recall the previous wheelencoder takes; which is used Which is achieved by retrieving theprevious text stored in the pre, from the, in the previousiteration of the code
* Then, you will use, then you will retrievethe current state estimate, meaning, what is the current estimatedposition and orientation of the robot
* Then, you will retrieve the, the usefulconstants such as the radius of the wheel, the distancebetween the wheel, and
* How many readers are there for each ticof, each tic of the encoder
* Then your part comes, which is toimplement odometry by computing the difference in the Xposition, the difference in the Y position, and the difference inthe orientation between now and the last time the odometrywas updated
* You will then add these deltas to thecurrent estimate of the pos, current estimate of theorientation and position, and save, and save that as the new estimate.You will also need to save the current number of ticks in the right andleft wheels for the next iteration
* [INAUDIBLE] Part of these assignments is to make senseof the IR distance sensors
* In particular, these sensors will returnvotages in the range from 0.4 to 2.75 and those correspond to distances between four and30 centimeters
* The relationship between distance andvoltage, is shown in the graph on the left
* Now what, to make matters a little bitmore complicated, is that the robot actually returns a integer value inthe range of 200 and 1,375
* What these values simply correspond to thevoltage divided by two then multiplied by 1,000
* Since the graph on the, in the previousslide is not linked is not linear
* We need to use the [UNKNOWN] polyfit to find a fifth-order polynomial that willfit the data
* We will then use the coefficients fromthat function and the polyval function to convert from the integers toan actual distance in mirrors
* You will do this in the get IR Distancesfunction
* This function is defined in Quickbot.m
* And you need to implement two specificparts
* First you need to properly convert fromthe integers to the voltage, and then you need to hard code the coefficientsthat were output by the polyfit function
* To help you test the assignment, we'veincluded a go to angle controller
* This is a P regulator, which will simplysteer the robot to a specified angle
* If you wish to change the angle to whichthis robot steers, you need to go into the constructur and QBSupervisor.m and change this variable,right here
* Object.theta_d
* I have it set to pi divided by four, sowe'd expect that the robot would drive off at a 45 degree angle withrespect to the x axis
* So let's see this in action
* I'm going to hit play and what we should seeis the robot
* Drived at a 45 de, de, degree angle
* I'm going to move the graph out of the way andwe're going to follow this robot
* And as you can see it's driving at 45degrees with respect to the x axis
* It's going to just continue driving atthis angle all the way until it's going to crash into thethread wall
* There you go, we found a crash
* You'll see in the, in the command window,that I've actually been spitting out the estimated posts from the odometry at everytime step, and you can see that the values that I'm getting for the angle are closeto pi divided by four
* So this controller successfully steers therobot toward that angle
* My tips for this week are to, first ofall, make sure you read the section on week two in the manual formore details than you find in the slide, inthese slides
* And also, to use the commented out fprintfstatements that I've included in the comments in thecode
* Or into, maybe add some more, more of yourown and this is really useful for debugging because for example,when you're dealing with implement in theodometry, you want to print out what you'recurrently estimating the position of the robot tobe
* You know for example you can easily seethat my robot drove at 45 degrees, but I also needed to print that out to thecommand line to make sure that those values notjump
* And that's it for this week.


--- SKIP ---: 01_a-simple-robot.en.srt


--- SKIP ---: 01_a-simple-robot.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_a-simple-robot.en_SENTbySENT.txt
* Welcome to module three of control ofmobile robots
* what we're going to do in this module is try to be a little moresystematic in how we think of our design choices and how we actually Model thesystems that we're dealing with
* So, so far in module one we did some basiccontrol theory
* We developed PID regulators
* we could do some ratherelegant things, but we really didn't know Why anything worked
* And in module 2 westarted talking about robots and some of the more standard robot models we're goingto use, what abstractions are useful for thinking about sensing modalities, and howdo the robots know where they are
* so what we're going to do in this module isactually take a step back and start to revisit some of the things we did
* Andwhat we need to do first of all is develop a Model class that is rich enough in thesense that it's quiet general and it will catch and capture a lot of differentrobotic systems that we're interested in
* But it has to be simple enough so that wecan actually say things about it because, you know, very complicated models don'treally give us anything because we have no effective ways of interacting with them.the model also needs to be expressive enough and relevant enough, and what Imean about With that is, it has to capture the aspect of the systems that we'reinterested in, in a way that matters and actually translate into the actual systemsdoing what they're supposed to be doing
* Because one thing to remember is thatmodels are always approximations, adn you want to make suere that you, the thingsthat you don't fully model
* Don't matter so much
* And what we're going to do iswe're going to go into the wonderful world of linear systems
* So, linear systems areparticularly effective and compact, and well behaved system representations ofdynamical systems
* So let's start with what I want to call the world's easiestand simplest robot
* This is a point mass
* So what it is, is that it's just a mass.On a line and I can immediately control the acceleratio n
* So if you startcontrolling but p is the position of the robot then acceleration which is thesecond derivative of the position is just p double dot is equal to u
* Now we won'tactually like to write it in this way, we don't want the double dots, we don't wantto have
* P is for positions and then we're controlling something else
* We have newvariables
* So, we want to come up with a compact/general form that captures what wewant but somehow glosses over the, the, the minor details of what separates apoint mass robot from a
* Humanoid robot, say
* So the way to do this is to introducesome new variables
* And I'm going to introduce in this case two variables
* Thefirst one I'm going to call x1 and simply say that that's the position
* So x1 is theposition of the robot
* And then I'm going to say that x2 is the velocity of therobot
* And if I do that, I can actually write down the derivatives
* The dynamic'sof these new variables
* So x1 dot, well, we have x1 dot is equal to p dot but p dotwas equal to x2
* So, x1 dot is simply equal to x2
* X2 dot is P double dot,right
* So X2 dot is P double dot, which we have up here, which equal to U
* So X2 dotis simply equal to U
* So this is a slight reformulation that so far doesn't seem tobuy us anything
* But what we can do is we can actually We put now this system onwhat's call state's based form
* And the state of the system is going to be ourexcess
* So I'm simply going to lump x1 and x2 into a new variable that I'm going tocall x, and now note that this is actually a 2-dimensional object
* And then what I'mgoing to do is I'm going to talk about the dynamics of this 2-dimensional object
* Sox dot is x1 dot, x2 dot and we know that x1 dot was x2 and x2 dot was u
* So I cansimply write x dot is this x2 u vector
* Well it gets even better because if I havea matrix
* If I have x1 x2 there and I multiply this by 2 by 2 matrix, let's saythat I would like to get out x2, well what do I have to multiply x1 and x2 with?Well, this is zero times x1 so I'm going to write 0 here and 1 times x2
* Is goingto give me that, right
* So what I am going to do is simply write this as a matrix, sox dot is zero times x1 and 1 times x2 and x2 dot is simply u, so its zero times x1and zero times x2 but we get one u out of it so I am now rewritten my dynamics usingthese matrices, which may or may not look easier
* But trust me, it actually will bemuch easier
* Moreover, the thing we care about in this case would be x1
* So, I'mgoing to take the output of the system to be x1
* And, I can also write this as amatrix
* In this case it's a it's role vector times x
* This simply means that Iget one of x1, and zero of x2
* So, I have now re-writ them, everything in a muchmore, I'm going to claim compact form, using these matrices
* So, to summarize, onstate space form x dot is this thing, And x and y
* Sorry.The output is this thing
* Now, if I introduce some matrices
* I'm going to callthis thing my a matrix
* I'm going to call this thing my b matrix
* And this thing myc matrix
* Then, all of a sudden, I can write everything like this
* x dot is axplus bu, y is cx
* And now we've hidden all the particulars of the model inside thisa, b, and c matrices
* But this is a very
* General way of writting systems so this infact clearly deserves one of these sweethearts because what we have done isto take a system that was really particular and written it in a verygeneral form involving these system matrisis and to make sure that we believethis is in fact generally usefull let's consider 2-dimensional point mass now.Where, what I can do, is I can move in both the x and y directions say
* So, theposition is going to be the x and y position, the input is my acceleration inthe x and y direction
* And then the dynamics of course is p double dot x isux, which means my acceleration, my accelerating in the x direction with themy ux input, and similarly for my, My y direction
* Well, now we need to do thesame thing
* So I'm going to introduce a bunch of new variabl es.So x1 is px
* x2 is p.x
* As I said before
* But now I'm introducing 2 more
* X3 is py,and x4 is p.y
* I have two inputs and two outputs
* So if I do this
* I can actuallywrite this new system, also using a b and c matrixes
* So if you take a look at thisa matrix, up here in this corner is the old a matrix that we had for a 1Dpoint-mass
* Well this is just the x component of the a matrix
* And this wouldbe the y component
* Similarly b, this is my old b Now I have two copies of it
* Andfor C, this is my old C
* Now I have a copy of it
* So with this choice of A, B and Cmatrices, voila
* I can write the same Or that this system on exactly the same formX dot is Ax + Bu
* Y is Cx
* And one thing that I'm going to encourageyou to do is make sure that you go through the matrix multiplications here andconvince yourself that this choice of a, b, and c matrixes is actually correspondsto the original dynamics that we had up here
* but the point that I really want tomake with all this is You know what, x dot is Ax plus Bu, y is Cx, is a very generalway of writing down, the system dynamics that you have
* And in fact, this is what'scalled an LTI system
* Linear time invariant system on state space form, andwe're going to see this a, b, and c
* triple quite a lot in this course, becausethey will show up over and over again
* And they will allow us to be general about howwe reason about our systems
* And then we're going to hide the particulars of thedynamics inside the a, b, and c matrices
* Before we move on to the next lecturewe're actually going to see a little bit more where these models come from
* Let'ssay a few words though about the dimensions of what we have here
* If x isan n dimensional vector so it's a Rn for the point mass on the line x is2-dimensional or a 2D point where we control exploration x was 4-dimensional.Anyway, x is in Rn, then A is an n by n matrix
* If U is in Rm, meaning we have anm dimensional inputs, then V is going to be an n by m matrix
* And similarly if theoutput is p dimensional, meaning we're sucking out p different things from oursystem, then the C matrix is a
* P by n matrix
* And the reason this is right
* youcan see that if you actually write down the equation
* X dot is Ax plus Bu
* Well, xdot has to have the same dimension as x
* So it has to be n by one
* Now, I know thata is n by n
* And x is n by one
* Whenever you have matrix multiplication like that.The first thing is that these numbers have to be the same otherwise you cannot dothis multiplication
* So you have to make sure these are the same
* And when you endup with n at the end, it's an n by one or n pieces here Which means that ax actuallybecomes and n by one factor
* Which is what we need, right
* Because x dot n by one.Similarly with b, b is n by m And you u is m by one, well these things cancel outthat they should and we end up with something that's n by one
* If you look aty similarly, y is p by one, well is p bt n and x is n by one
* These guys cancel out,and what we end up with is a P by one vector
* And, it's important that thedimensions lineup
* So, as a sanity check, we're always going to be forced to insurethat the things that we build, have the right dimensions
* And, if they don't havethese dimensions, then what we write down is actually nonsense, and we can't performthese multiplications
* Okay, that concludes the first lecture on linearsystems
* And in the next lecture, we're going to see a little bit more where thesesystems actually come from.


--- SKIP ---: 02_state-space-models.en.srt


--- SKIP ---: 02_state-space-models.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_state-space-models.en_SENTbySENT.txt
* Welcome to the second lecture on LTImodels on state space forum, where LTI stood for Linear Time-Invariant Systems.And what we saw last time is that we could model at least two systems like x dot isAx plus Bu and y is Cx
* Well, it turns out that this is a very, very generaldescription of a large class of systems
* And x here is state of the system
* Whatthat means is that x describes what the system is currently doing, u is the inputwhich tells us how we effect the system, and y is the output which measures theaspects of the system that we care about or that we have access to somehow
* and theway we should think about these a, b, and c matrices are really that, here, Ax,well, that's the physics of the system
* So, A is given to us by Newton, by thelaws of physics or electromechanics, or whatever it is that we're using to modelour system
* And there's very little we can do about that
* B, on the other hand, thattells us how the input affects the state
* Meaning, this tells us what actuators wehave
* So, if we buy new actuators, we get a bigger B
* In other words, B is, to acertain degree, up to us, the designers who are actually building the systems.Similarly, C, actually encodes what sensors we have
* Meaning, how, can weactually get information about what's going on inside the system
* So, A isgiven
* Typically, B and C redesigned when we designed the system
* And as we will seelater on sometimes, we may not have enough control authority, for instance, to makethe system do what we want, meaning our B matrix is too measly which means that wehave to buy a better B matrix, maybe buy a new actuator or so
* but at the end of theday, a system like this, it's influenced by our control signal u, that's the input,and out comes y, which is ultimately the thing we can see
* We can typically not seex, but we can see y, because that's what our sensors are measuring
* And thequestion that all of control theory is really about, is how do we pick this inputto make the system do what it should be doing
* And, more importantly, since weonly can measure y
* How do we pick u, given y
* Unfortunately, we cannot answerthat question right away
* What we do need to do first is understand these systems alittle bit and come up with tools for describing their behaviors because untilwe understand their behaviors, we can't pick u's that make the behaviors be whatwe want them to be
* so we're going to do that
* but first, we actually need tounderstand a little bit more about where these systems come from
* So, let's startwith our old friend, the car model
* This was the model we used when we built thecruise controller for a car
* So, what's going on here is that, the acceleration ofthe car, v dot, was c over m times u minus gamma v
* so, let's put this model on statespace form
* Well, let's say, first of all that, we're building a cruise controller.All, all we care about is the velocity
* In this case, let's say, that the state isactually the velocity
* The thing we're measuring is the velocity, which meansthat y is Cx, where C is simply 1, alright?We're simply measuring one
* Well, v dot is giving by this expression which means thatx dot, where which x is the same as v is Ax and A here is simply minus gamma, plusBu, where B then become C over m
* So, in this case, we have a one-dimensionalsystem for describing what's going on
* Now, let's pretend that instead ofbuilding a cruise controller, we'll building a self-driving car
* Well,clearly, we not only care about how fast it's going, we care about where it is
* So,in this case, let's make our state, the position and the velocity, so P, V
* Inthis case, we're measuring the position C, which means we're taking out the firstcomponent of the state
* So, C is 1,0
* Similarly, this equation still holds sowhat we're controlling is the acceleration through the Cm and what remains is my Amatrix where the 1 here simply says, that the time derivative of position isvelocity and then, this gamma is the same gamma as we got before
* So, the impo rtantpoint to note here is that the model we end up with, to a certain degree, dependson what we care about and what are the things that we can, can measure
* Now,let's take another model
* Here is a pendulum
* And the pendulum is attached uphere on the ceiling somewhere
* And it's swinging with an angle theta
* It haslength l
* And the acceleration of this angle, this angular acceleration, turnsout to be minus gravity over the length times sine of this angle plus Cu
* And theway we should interpret this is that what we're doing is we're actually applying atorque up here that allows us to swing the pendulum a certain way
* okay.Let's write this as an LTI system
* Ouch
* Sine theta is not linear
* So, we actuallycannot write this as an LTI system
* But, here is something we can observe
* For avery, for small thetas, then sine theta is actually roughly equal to theta
* so whatwe can do for small angles, is actually replace this thing by theta.So, let's do that
* For small angles then, what we get is, wellm if we measure theangle, then y is simply 1, 0, where we're taking out the angle and not the angle orvelocity
* Because the state, in this case, is theta, theta dot.Well, similarly, we're having a C here, so the C shows up there in the B matrix, andthe A matrix looks like this
* 0,1 here, which means that the time derivative ofthe angle is the angle of velocity, and this g over l term here is the same as theg over l term up there
* So, this would be the a, b, and c matrices for thispendulum
* And again, I want to encourage you to gothrough the math and perform this matrix multiplications so that you indeed trustthat this is correct
* Okay, let's do another example
* Two simple robots
* Let'ssay that we have two robots on a line and what we can do is we can control thevelocities of these robots
* So, x1 is the position of robot 1, x2 is the position ofrobot 2, and we want to somehow control them
* Well, first of all, what we get isthat x dot is 1 0, 0 1 u
* We have no A matri x in this case, A is equal to 0 andthe B matrix is simply the identity matrix
* let's say that we can match wherethe robots are, too, so in that case, y would simply be the identity matrix timesx, or just x itself, right
* So, this would be, our, our model of this
* Now, let'ssolve the problem here
* Let's solve what's called the rendezvous problem
* therendezvous problem is the problem we'll have when the robots meet
* And, you knowwhat, why don't we actually have them drive towards each other
* So, here's anidea one can have
* Where we say that u1 is x2 minus x1, which is simply code forsaying that x1 is going to move towards x2
* And similarly, u2, let's make that x1minus x2
* Then, that means that robot 2 is aiming towards robot 1
* Well, what we'veactually done now, is we've designed a closed loop feedback law, where we havewritten control inputs in terms of the states in this case, but since the outputsare the same as the states, we're actually writing them in terms of the outputs.Well, if I do that, I get a new system
* X dot is negative 1, 1, 1, negative 1, x,and what this corresponds to is instead of writing u here, I'm plugging in thesethings there, and then you end up with a new system dynamics that's what's called aclosed loop system dynamics
* And, in fact, if I run this, and let's run it for not 2robots but a gazillion robots here, then as you will see, running exactly thissimple controller makes the robots actually meet on a same, on the samepoint, so that's kind of cool
* let's do another example now
* This is the unicyclerobot we looked at that when we modeled the differential drive robot
* Again, sinesand cosines are unpleasant
* This is not linear, alright
* , But cosine for smallangles is equal to 1
* So, let's assume we're dealing with small angles
* And sine,for small angles, is equal to the angle itself
* So, using that, we get this
* Butlook at this
* This is still not linear because here, we have a multiplication.So, even when we made a simplification, wh ich by the way is a completely stupidsimplification because the pendulum may swing at small angles, but why does thecar have to drive in only direction where we are having small angles
* That doesn'tmake any sense
* But the point there is that this kind of simplification didn't doanything
* Still not linear
* So, we need to be a little bit more systematic when wegenerate linear time invariant models from, for, from these kinds of non-linearsystems because just saying that let the angle be small and hope for the best,won't actually give us all that much
* And in the next lecture, we will be systematicin our generation of these linear time-invariant models.


--- SKIP ---: 03_linearizations.en.srt


--- SKIP ---: 03_linearizations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_linearizations.en_SENTbySENT.txt
* In this lecture, we're going to, dig alittle bit deeper into the original non linear models
* And see, how do we producelinear models from them
* And in fact, I have a wonderful quote here
* That says,classifying systems as linear and non linear is like classifying objects in theuniverse
* As bananas and non-bananas
* What this means is that if you're walkingaround in the universe, let's say your'e on Jupiter and you pick up something,chances are it ain't going to be a banana
* Similarly, if you walk around and you pickup a system or a robot, chances are it ain't going to be linear
* What that meansis that linear systems are really, really rare
* Yet, here I am, two lectures ago,bragging about how useful they are
* So something's gotta give here
* And what itis, is that the non linear systems that are everywhere
* They act very much linear,at least around operating points
* So the linearization is a way of producing linearmodels from non linear models
* Or producing bananas from non-bananas, if youwant
* So what we're going to do in this lecture is
* Produce Linearizations orlinear models from the non-linear models that we start with
* So, here is a generalnon-linear model 
* So, x dot is now not a x plus bu with some general function f ofx and u, and similarly y is not a simple plus in cx, it's a non-linear function hof x
* Okay
* So now, what we would like to do, is wewould like to find some kind of local description of what this system is doing.And this local description needs to be linear, and what I mean by local, is thatwe have to pick an operating point
* In the pendulum we said, let's assume that thependulum is hanging very close to straight down, so straight down is the operatingpoint and then what we do is we are going to have to define a new variable
* So,let's say that this is my operating point
* This in the pendulum case would be, theangle is zero, and I have no control input
* Well then, my actual state is goingto be the operating point, plus some small deviation in this state
* Similarly mycontrol input is going to be, well the nominal operating Input point plus a smalldeviation
* And, what we would like to do somehow is describe these smallvariations
* And in fact, the new equations of motion that we care about well, we'regoing to care about how Delta x
* This deviation from the operating pointbehaves
* Well, delta x is x minus x operating point
* Right
* So delta x dot isx dot minus xl dot
* Well, this thing is equal to zero, because it's a constant,right
* So this is just zero
* So, here's my zero
* So, delta x dot is the same
* As xdot
* Well, I know what x dot is, it's this
* So, now delta x dot becomes this.Okay, let's see if we somehow can simplify this
* So this is my model, now luckily forme there's is something known as a tail or expansion that's allows me to write thisOn a simpler form
* So this thing can be written as f evaluated at the operatingpoint, times this partial derivative of f with respect to x, also evaluated at theoperating point, this is known as 
* And then, you have the same partialderivative, but now with respect to u, evaluated at the operating points
* And, wemultiply this with Delta u here, and delta x here
* And then I have something that Icall HOT, which stands for higher order terms
* So this is where, we're saying thatthe higher order terms
* Where, when delta x and delta u become large, these matter.But for small delta x and delta u, they really don't matter
* Well why is thisuseful
* Well, first of all lets assume that we have picked operating points, sothat f of x0, u0 is zero which that we're holding the state steady, x dot is zero atthis point which means that this thing goes away
* Now.Let's call these guys A and B
* Why is that
* Well, these are just matricesbecause I'm plugging in some constant value here
* Similarly then I'm plugging ina constant value
* So, these partial derivatives are just matrices
* Well, let'scall them A and B
* And now let's do the same thing with Y
* Y was the output
* Wewant to kn ow what it looks like around this operating point
* Well, we have thesame thing here, plus this term, plus high order terms
* So, let's assume that thingis zero, so let's assume that we pick an operating point that kills the output atthat operating point
* So, the output is zero at that point
* Well, then, let's callthis thing c
* Right
* Now I have a, b, and c
* And in fact, let's summarize what wejust did
* If I have this non-liner model, and I pick an operating point, so thatthese two assumptions are satisfied
* And then I look at small deviations from theoperating point
* Then I can write delta x dot
* That's a delta x plus b delta u.Which is linear
* And y is c delta x, where these a, b, and c matrices are given bythese partial derivatives, also known as Jacobians
* So this, ladies and gentlemen,is how you obtain linear models from non linear systems
* Well, let's actually dosome computations here, just to know what's going on
* So let's assume that x isin Rm
* u is an Rm, y is an Rp and we have f and a being given by these things, butreally what we have is f1 over x or is actually a function of x1 to xn of u1 toup right, no sorry Alright
* So when I just write f1, that's what's areally mean
* Okay
* Then, df, dx
* This Jacobian that we talkedabout
* The first one we need
* Well, it has this form
* First component is thederivative of f1, with respect to x1
* Then it's f1 with respect to x2, and so forth.And the reason why I'm writing this is not because I enjoy producing complicatedPowerPoint slides
* It's just, we need to know what the different entries are
* Andit's important to do this right because otherwise your dimensions don't line upwhen you produce your A, B, and C matrices
* So that's df dx or, as we nowknow it, A
* This is my A matrix
* Well, similarly, B is df du, right
* And again,the first component is df1 du1
* This component is the f1, the Here, we have thef and the u1
* All the way to the f and the So this is a n by m matrix, which is whatwe needed
* And, in fact , this is the b matrix, then
* So it has the rightdimension
* And not surprisingly, we do the same thing for our c matrix
* and thereason again I wanted to show this is, this is where the Jacobians come from
* Soif I write dhdx, this is what I mean
* Good.Let's do some examples
* So let's start with what's known as the invertedpendulum, which is a slightly more complicated pendulum where what I have is,I have a moving base, my elbow in this case
* And then I have a pendulum pointingstraight up
* Or with some angle, and by moving the base, the pendulum is going toswing, and in fact, it's going to fall if I don't do anything very clever
* But thedynamics of this can be written like this, where theta double dot is g over l sintheta plus u cos theta
* Okay
* Let's linearize this thing
* the firstthing we do is we pick our stakes
* In this case it's going to be theta and theta dot.And the reason I know that I have a 2-dimensional system is I have two dot'sup here
* So, I have a 2-dimensional system, x1 is theta and x2 is theta dot.Let's say they're measuring the angles, so y is x1
* Well, then I get my f to be thistwo vector
* And I get my h of x to be x1
* Okay, fine.Let's pick the operating point where the pendulum is pointing straight up, and I'mdoing nothing
* And in that case, well, what is my a matrix
* My a matrix becomesdf1, dx1
* So now I have to take the derivative of this thing here, withrespect to x1
* There is no x1 there, so
* The first component is zero
* Then I haveto take the derivative of this thing with respect to x2, which is 1
* So thiscomponent is 1
* Similarly, I have to take the derivative of f2, with respect to x1.So now, I have to take derivative of this guy here with respect to x1
* Well, thederivative of this with respect to x1 is
* g over l times sine
* The derivative ofthat is going to be g over l times cosine x1
* While the derivative of this, withrespect to x1 is actually going to be negative u, sine x1
* But I didn't actuallywrite this here, even though I should have
* Arguably.Because what I'm going to do is I'm going to evaluate this at the operating point.And you know what
* U is zero
* And in fact, x1 is zero
* So this term actually goesaway
* So all I'm left with is this term, evaluated at zero, zero
* And cosine zerois 1
* So after all these pushups, I end up with g over l here, as the known zeroterm
* Now, that's how you get the A matrix
* Again, I would encourage you to gohome, and thus your already home when you are watching this and actually performthese computations so you know where they come from
* Similarly B, you have to do thesame computation and in this case you have no U up here, so you don't get a U in thefirst component
* Here you have U cosine x1
* Take a derivative of that with respectto U
* We get cosine x1
* We plug in the operating point, zero, zero
* And wind upwith this elegant b vec-, b vector here
* C is particularly simple, right
* Because hof x is x1
* Which means that c is simply 1, 0
* So.That was how we would go about getting these a, b, and c matrices
* Okay, lets goto the unicycle the differental drive robot that we have looked at that we sawin the previous lecture that we had a little bit of an issue with
* first of alllets figure out the state
* Let's say that x1 x now I'm having in the slight abuse ofn notation right because x is also the full statement
* But this is the xcomponent, x2 is y and x3 is theta and then lets say that we're actuallymeasuring everything
* So y is this
* Okay We can control the translational velocity,or the speed and the angular velocity, right
* So my inputs would be u1 is v, andu2 is omega
* Okay
* Let's compute, now, the linearizationaround x, operating point to zero
* U, operating point is zero
* Okay.If you do that, what you actually end up with, and I'm not going to show thedifferent steps, you should do it yourself, is first of all, an A matrixthat's 0, a B matrix that looks like this, and a C matrix that's dead end to thematrix, which is not surprising since we' re measuring both the x y position and theorientation of, of the robot
* Now, this is a little bit weird
* Because if I writedown the, the dynamics for x2
* Well, x2 dot it's going to be given by the secondrow of everything
* Well, first of all, it's zero, right
* Because my a matrix iszero
* Then I get zero, zero times u
* So I get plus zero, zero
* I mean, times u, ifyou want
* But this means that x2
* is actually eqaul to zero
* Well x2 was the ydirection, what this means is if I'm pointing my robot straight in the xdirection, then apparently I cannot actually make the car drive in the ydirection
* That seems a little bit fishy actually
* what is going on here is thatthe linearization That we performed didn't quite capture all the nitty grittyexciting things that were going on with the non linear model
* And this is anexample where the non-linearities are so severe, that the linearization as applieddirectly, doesn't entirely apply
* Because we lost control over the y direction
* Eventhough
* >> If I have a car, I can clearly turn it.I can drive it and turn, and drive in the Y directions
* So, here's an example wherethe linearization actually doesn't give us just what we wanted
* And, the punch linehere is that sometimes linearizations give reasonable models, with inverted pendulum,for instance
* And, sometimes they do not, with the unicycle
* and with a unicycle wehave to be a little bit more care, careful, but the fact that I want to pointout though is that when they work
* When the linear stations work they areremarkably useful
* Even though we're finding them around the operating pointsthey seem to work Better than what we really theoretically have reason tobelieve, which is why we do a lot of analysis of the linearizations rather thanthe non-linear models
* And then take what we learned from the linearizations andapply it to the, the non-linear models
* Thank you.


--- SKIP ---: 04_lti-systems.en.srt


--- SKIP ---: 04_lti-systems.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_lti-systems.en_SENTbySENT.txt
* So now we have seen where LTI systems comefrom
* We've seen non linear models that turn into very well behaved and pretty LTIsystems
* And we've seen non linear models that don't necessarily produce useful LTImodels
* But a lot of systems do produce useful LTI models
* And it's really our.Most systematic way of designing controllers
* And they are extremely useful
* So even though there aren't that many bananas in the universe
* A lot of thingsact like bananas
* so what we're going to do now is, we're going to start byunderstanding how these systems behave
* So what I'm going to do in this lecture is,I'm actually going to find
* The solutions to these systems and once we have thosesolutions we can start talking about how they behave
* And we're going to start bysimply ignoring the input and ignoring the output
* So we're going to start by justsaying that, let's say that I have x dot is Ax and at time t not, this is the timewhen we wake up, we start somewhere
* So this is the, the physical part of thesystem
* Not the thing that we bought actuators for
* Not the thing that webought sensors for
* It's just x dot is ax
* Let's see what happens in that case
* Howdoes the system behave or drift if you will, when you're not messing with it
* Sowe need to solve x dot is ax
* let's start with a scalar version of this, where x isjust a number, right
* So the scalar version I'm going to write this x dot aslittle ax
* So this is a scalar version
* And I start some Somewhere.Well, you may not know this, but if you take in or see differential equations, thesolution to this differential equation is actually given by x of t is e to the a, tminus t not times, times X not
* So here, professor shows up and says, ohhh, this isthe solution to this differential equation
* Now you clearly are criticalthinking people who don't just accept anything the professor says, so what youwant to do now is make sure that this is indeed correct
* So how do you ensure thatwhat someone feeds you, say here's a solution to differential equation, how doyou make sure that this is correct
* How do we know
* Well, the first thing you have todo is make sure that the initial conditions are right
* Meaning that, mysolution here actually respects this initial condition
* So what I'm going todo, is, I'm just simply going to plug in t not here, and see what I get
* Well, if Ido that, I get x of t not is e to the a
* T not minus t not times x not
* Well, thisthing is zero, right
* So I get e to the power zero x not
* And e to the power zerois always equal to one
* So, the exponential evaluated at zero is one
* so xof t not is equal x not
* Which means that the initial condition is correct
* So we'redone with this
* Now, clearly, we need to deal with this, right
* We need to makesure that the dynamics is indeed correct
* So now I'm going to take the timederivative of my proposed solution
* So I'm going to take d, dt of this thing, and seewhat I get
* Well, the time derivative of an exponential
* All we do is we pull outthe coefficient there
* So we're going to pull out a, and write an extra a there,That's all we do
* And this is why exponentials are so wonderful
* So the timederivative of x with respect to t is a times what we have here
* Well that thisthing, this thing here that's x right
* So the prime derivative of x, my proposed xis equal to a times x
* Well that's where we started right
* So what we now know isthat the dynamics is correct as well
* And if the initial conditions are right thenthe dynamics is right
* We know Thanks to the existence and uniqueness of solutionsto differential equations
* That this is, indeed, the right solution
* Now here isthe kicker
* For higher order systems
* So now, x is in rn
* We get the same solution.We have x
* is e to the at minus t not x not here
* Well, now we have this, x dot isthe same thing
* The only thing I did different was I wrote capital A instead oflowercase a
* And the thing to keep in mind here is that this is what's called amatrix exponential, instead of a sc alar exponential, which looks kind of, just alittle scary
* But we're not scared of matrix exponentials
* In fact, what we do,is we look up the definition of an exponential
* And an exponential, e to thea t for scalars, well it's simple, simply this sum
* This is the definition of what,the exponential is
* Well, here is just multiplications, and we can writemultiplications for matrices as well
* So, the definition of a matrix exponential isjust this sum
* Now, it turns out that it's actually not that important to us to beable to compute matrix exponentials very much
* However, we need to know where theycome from
* And they come from this sum
* And the reason why this is useful, itactually allows us to compute the derivative
* Of a matrix exponential
* Solet's take the derivative, the time derivative of this whole sum, right
* Sothis is the sum here
* Well the first term that I'm going to do is I'm giong to,going to pull out the k equal to zero term here
* So then I get A to the power zerotimes t to the power zero divided by zero factorial which is one
* So this wholething is actually equal to one
* And now I'm going to take the time derivative ofone well the time derivative of one is a big fat zero
* So I'm going to pull out thefirst term and then I'm going to take the derivative, of the remaining terms withrespect to t
* So all I get here is I get an extra k
* Well, now I can rewritethings, I can pull out then a and write everything in terms of k minus 1 insteadof k here
* But I'm summing from one to infinity so if I shift my k now to see outat infinity I get back this thing
* So what this means is that the time derivative ofe to the At is simply big A times E to the At
* So the matrix exponential behaves justlike the scalar exponential
* That's all I wanted to show with this slide is that,even though this looks a little awkward, we have these sums of matrix powers, allit means is that we can take derivative of matrix exponentials and trust that theybehave just like in the scalar case
* In fact, e to the a, t minus t not is such afundamental object in linear systems theory
* That it has, it has been given itsown name
* It's known as the state transition matrix
* And sometimes, I'mactually going to write big pi of t and t not
* And what we should then remember, andprobably I will remind you of it, is that this is simply this matrix exponential.That's all it means, but it will show up quite a bit
* Okay.X dot is Ax
* That means, in fact, that x of t is e to the big A, t minus t not
* Xof t naught or in general I can write it on this form
* It's this state transitionmatrix which we now know is just a fancier name for this matrix exponential
* And itturns out that it doesn't matter if it's t naught or not, it's just whatever timetao, well we just multiply what x was at that time tao times the state transitionmatrix
* So this is simply code for x of t is e to the a t minus tau, x at time tau.So the point is that we know what the solution to, to this equation actually is.And the way you would show that this is the solution is you would use thefollowing two properties
* And I encourage you to go home and do this
* the first isthe thing we just established
* Which is that the time derivative of pi is a tinesoi
* The other is that, pi tt is the identity
* Well, pi tt I just plug in a there instead of a t not
* So, then I get e to the power of zero, in the scalier casethat's one, in the matrix case that's the identity matrix
* So, that's the onlydifference when you go matrix
* Fine, so now we actually have a control system
* So,we have x dot is Ax
* Plus Bu, what happens
* Well again, the professor goeswell, here's my claim, this is what I claim that the solution is
* This lookslike a mouthful doesn't it
* It doesn't look pleasant at all
* Some stuff, in factthis is the thing we had when we had no B matrix at all, at all and then we havething, thing here that's If you want to be picky this is what's called a convolution,but, we don't have to be calling it convolution
* All w e need to know is that,you know what this is what we claim the solution is
* But how do we actually verifythat this is correct
* Well, we do exactly what we did before
* We have to check theinitial conditions and the dynamics
* So let's plug in t0 see if we get the rightthing
* Then we get pi
* Instead of t here, I'm going to write t not
* And then,instead of t here and here
* I'm going to write t not and t not
* Okay.Let's see what this is
* Well, pi tt is equal to the identity matrix, no matterwhat t is, right
* So this is the identity
* Now, here's an integral between t not andt not
* So this is clearly zero
* 'because I'm just taking the integral over this.Individual points
* So this interval is zero
* So what I haveis I have that x of t not is equal to what it should be, x of t not
* So we're goingto declare success on the initial condition
* Now, we need to deal withdynamics and that's harder
* First of all, we use the fact that if I take thederivative of this, I get an A out
* So the first component is no big deal
* But thenwe have this awkward object here
* We have to take the derivative of an integral,with respect to t, when t shows up both here and here
* And this, it's not atrivial thing
* In fact, what you need to do, is you need to use something known asrule
* That tells us that if I have a generalfunction here of t and tau and I take the derivative of this thing with respect tot
* Well, first this contribution here translates into plugging in, instead oftau I am plugging in t and then I am just getting rid of the integral
* That's thefirst piece.The other piece is I pooled d dt inside the interval and I have to takethe reverse of this thing
* With respect to t
* So this is technically what we have todo to compute this
* So let's do that
* Well, f t, t
* Well, let's pull it, pullout this thing, and evaluate it at tau is equal to t o' clock
* Then I get phi t, ttimes bu of t
* Which, in fact, is simply u of b, u of t, right
* Because this thing isdensity matrix And then, I get the time derivative of this thing
* Or, in otherwords, the derivative of this with respect to t
* Well, I know that that's an a that Ijust have to pull out in the beginning
* So this is a little bit of a mouthful, Irealize, to that
* So, take a deep breath, and redo this computation, just so thatyou believe it
* But what happens when you've done this, then
* Is, you canactually pull out the a, and find that the time derivative of my
* Proposed x is, bigA, times this whole thing, plus B times u
* And now, this whole thing is equal to thesame thing here
* So instead of writing this rather awkwards big expression, I'mjust going to write, x sub t here
* Or in other words, d, xdt is ax plus bu which,which is where we started
* So we can declare success also on the dynamics
* Soto summarize, after all these pushups, and I realize that today's lecture was alittle bit of a it was a little thorny in terms of all the integrals andderivatives
* In fact, it was much thornier than anything we've ever seen before
* Thereason I needed to do it was not because I think you guys need to be world championsat applying rule
* I just want to be able to say thefollowing
* That if I have x dot is ax plus bu
* Y is cx.Then I can write y of t as C times x of t where we computed the solution
* So weactually know that the output is given by this thing in yellow here and you knowwhat
* Let's add another sweetheart to this
* So all these push ups just ended upwith us being able to write
* Explicitly what the solution is
* Now, we're not goingto be able to or particularly interested in actually computing this at all
* But weneed to know it to move forward
* So at the end of this application of rule, what weended up with was an expression for the output or the state if you want to Get ridof the c matrices of this general LTI system
* And fi here, the thing to rememberis that phi known as the state transition matrix was simply given by this matrixexponential
* What we're going to do now in the next lecture is see h ow does thisactually translate into us
* Being able to say things about how the system behaves.And in particular, we're going to look at stability.


--- SKIP ---: 05_stability.en.srt


--- SKIP ---: 05_stability.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_stability.en_SENTbySENT.txt
* So in the previous lecture, we did a lotof technical push ups to end up with end up with a description of what the solutionto a general LTI system is
* the reason for that is, is that I really, really enjoyrule, even though I do
* but that it will actually help us to characterize whatthese systems are doing
* And today, I want to talk about stability, because as youprobably recall when we did a control design, first order of business is todesign controllers so that systems don't blow up
* If they blow up, there's nothingwe can do about it
* The quad rotors just fall out of the air
* The robots drive offto infinity
* The cars smash into things
* We don't want them to blow up, because thedeciding objectives are almost always layered in this sense
* First order ofbusiness is stability
* Then we want to track whatever reference character orreference point we have
* We also want it to be robust to parameter uncertainties,and possibly noise
* And then we can wrap other objectives around it, like when youwant to move as fast, quickly as you can, or use as little energy when you'removing, or things like this
* But, regardless of which, stability is alwaysthe first order of business
* So let's start with scalar systems, no inputs
* Soonly the A matrix now, in this case x dot is little ax, which means that it'sscalar
* Well then the solution x of t is e to the a, we said t minus t naught x of tnaught
* Here I simply picked t naught to be equal to 0
* So this is the solution.Okay, lets plot what this solution looks like
* If a is positive, then x of t itstarts nicely and then pabaah
* Its, its blowing up as far as I can tell
* So if ais positive this system blows up
* Well, if a is negative, then e to the at, this is adecaying exponential
* So we get x to just go, , nice down to zero
* What happens if ais zero in between these 2
* Well, then you have e to the zero t, which is 1
* So then,x of t is simply equal to x naught
* x never changes.So here, it didn't blow up, but it didn't actually go down to zero
* And in fact,what we have its, its really a sitution where three possible things can happen youblow up, you go down to zero, or you stay put
* So let's talk about these threecases
* The first case is what is called asymptotic, stability
* So the system isasymptotically stable if x goes to zero For all initial conditions, so this fancyupside down a, is known as the universal quantifier
* All we need to know is thatwhen we see and upside down a the way we pronounce it is for all x nought
* Soasymptotic stability means that we go to zero and almost always what we want todesign our system so that x actually goes to 0 no matter where we start, that'sasymptotically stability and as you recall, in the scalar case, a strictlynegative corresponds to asymptotically stability
* And then we have unstability,instability where the system being unstable
* What that means is there existsan initial condition, so the flipped e, and to speak for the existentialquantifier, which we read it as exists
* So it's unstable if there exists so manyextra conditions from which the system actually blows up
* In the scaler case, wehad A positive corresponding to instability
* and then we have something wecall critical stability, which is somehow in between
* The system doesn't blow up.But it doesn't go to zero either, and in fact, for the scalar system, thiscorresponded, corresponded to the, a equal to zero case
* So if you summarize that, ifyou have a scalar system then a positive means the system is unstable
* A negativemeans that the system is asymptotically stable, which is code for saying that thestate goes to zero
* And a zero means critically stable
* Okay.Let use this way of thinking now on the matrix case
* X
* is ax, capital A
* So thisis now, x is a vector, a is a matrix
* What do we do there
* Well, we can't just say.Oh, a is positive, or a is negative
* Because a is a matrix
* It's not positiveor negative
* But what we can do is we can go for the next best thing, which is theeigenva lues
* And, in fact, almost always, the intuitionyou get from a scalar system translates into the behavior of the eigenvalues ofthese matrices
* And for those of you who don't know what eigenvalues are, these arethe special things that are associated with matrices
* So, if I have a matrix A; Nby N, and I multiply it by a vector an N by 1 vector, if I can write it as the samevector times a scalar, then what this means is that the way that A acts on thisvector is basically scaling it
* And the scaling factor is given by lambda
* If Ican, if I can find lambda of v to satisfy this, then what I have is a lambda that iscalled an eigenvalue
* And it's actually not a real number
* It's typically acomplex number
* So it's a, a slightly more general object than just a real number,but that's an eigenvalue
* And v is known as an eigenvector
* And eigenvalues andeigenvectors are really these fundamental objects in, in when you're dealing withmatrices and when you want to understand how they behave
* And, whenever you thinkscalar first, you can almost always translate it into what do the eigenvalues,eigenvalues do for your systems
* And, the eigenvalues actually would tell you howthe matrix a acts in the directions of eh eigenvectors
* So, you can almost think ofthem as scalar systems in the directions of the different eigenvectors
* And, youknow, sometimes you may want to compute eigenvalues
* I don't.So, if you use MATLAB
* You would just write, eig(A), and out pops theeigenvalues
* whatever software you, your comfortable with, you want to use C, orPython, or whatever, there is almost always a library that allows you tocompute eigenvalues
* And, the command is typically something like eig(A).So, this would give you what eigenvalues are, given a particular matrix
* Okay.Let's see what this actually means
* Let's take a simple example here
* Here's my asystem
* 1, 0, o minus 1
* if you take eig a of this
* you get 1 eigenvalue being 1
* Andthe other eigenvalue being negative 1
* And the correspo nding eigenvectors are 1, 0,and 0, 1
* Okay
* What does this mean
* It actually means thefollowing
* So let's say that this is x1, and this is x2
* Okay.V2 was 0, 1
* So this was this direction
* So here is what, v2 is
* This is thedirection in which v2 is pointing
* Well, the eigenvalue there is negative 1, whichmeans that, if you recall the scalar system, when a was negative, we hadstability
* So if I start here, my trajectory is going to pull me down tozero
* Nice and stable, and in fact, if I start here, it's going to pull me up tozero, nice and stable
* Right
* So, if I'm starting
* on the x2 axis, mysystem is well behaved
* If I start on the x1 axis, I have lambda 1 being positive,which corresponds to little a being positive in the scalar case, which meansthat the system actually blows up
* So, here, the system goes off to infinity.And, in fact, if I start here, my x2 component is going to shrink but my x1component is going to go off to infinity
* So what I have is this is what the systemactually looks like
* So the eigen vectors in this case will tell me what happensalong different dimensions of, of the system
* So after all of this, if I have xdot as big AX, and I can find a solution, then the system is asymptotically stable,if and only if, for the scalar case, we had that little a had to be negative
* Whatwe need in the matrix case is that the real part, remember that Lambda arecomplex, the real part of Lambda is strictly negative for all eigenvalues toa
* For all, this is what asymptotic stability means for linear systems.Unstable means that there is one or more, but one single bad eigenvalue spoils thewhole bunch
* So a single eigenvalue that has positive real part
* This is an, asufficient condition for instability
* And we have critical stability only if so thisis a, a necessary condition that says the real part has to be less than or equal to0 for all igon values
* But where we are going to be spending our time is Typicallyup here in the asymptotically stabl e domain, because what we want to do, is wewant to design our system or our controllers in such a way that the closedloop system is asymptotically stable
* So we're going to somehow make the eigenvalues have negative real part That's going to be one of the design objectivesthat we're interested in
* And I want to point out something about criticalstability that if one eigenvalue is 0 and the rest of the eigenvalues have negativereal part, or if you have two purely imaginary eigenvalues So they have no realpart, and the rest have negative real part, then you have critical stability.and we will actually see that a little bit later on, but the thing that I really wantto take, you to take with you based on this slide, is, you look at the a matrix,you compute the eigenvalues
* If the real part of the eigenvalues are all negativeYou're free and clear, the system is asymptotically stable
* If one or moreeigenvalues have positive real part, you toast, your system blows up
* That is bad.So, let's end with a tale of two pendula
* Here is the normal pendula, well if youcompute the of this, you get this matrix
* And the eigenvalues are j and negative j.Well, I don't know if you remember, but on the previous slide, there was a bulletthat said if you have 2 purely imaginary eigenvalues, which we have here
* We have 2purely imaginary eigenvalues and then no more, then we have critical stability.What this actually means is that, this pendulum, clearly, there is no friction orgrav-, or damping here
* It's just going to oscillate forever
* It's not going to blowup
* And it's, , excuse me
* And it's not going to go down to zero
* It's just goingto keep oscillating forever and ever
* It's critically stable system.Now, let's look at the inverted pendulum where I'm moving the base, but in thatcase, a is 0110
* We already know, this things is going to fall over
* Right
* So,if you compute the Eigen values you get one Eigen value to be equal to negative 1and 1 to be positive 1, which means that, we have one Rothton eigenvalue
* Thiseigenvalue that's going to spoil the system
* So this in an unstable system
* Sonow that we understand that eigenvalues really matter, and they really influencethe behavior of the system, let's see, , excuse me, how we can use this to ouradvantage when we do control design.


--- SKIP ---: 06_swarm-robotics.en.srt


--- SKIP ---: 06_swarm-robotics.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_swarm-robotics.en_SENTbySENT.txt
* So, in the previous lecture, we saw thateigenvalues play a fundamentally important role when you want to understand stabilityproperties of linear systems
* We saw that if all eigenvalues have strictly negativereal part, the systems are asymptotically stable
* If one eigenvalue is positive,then we have positive real part
* Then, we're screwed and the system blows up.Now, today, I'm going to use some of these ideas to solve a fundamental problem inswarm robotics
* And this is known as the Rendezvous Problem
* And, in fact, what itis, is you have a collection of mobile robots that can only measure the relativedisplacements of their neighbors
* Meaning, they don't know where they are, but theyknow where they are relative to the neighbors
* So here, here we have agent i,and it can measure xi minus xj, which is actually this vector
* So, it knows whereagent j is relative to it
* And this is typically what you get when you have ancensor skirt, right
* Because, you can see agents that are within a certain distanceod you
* And, as we saw, you know, where they are relative to you
* If you don'thave global positioning information, you don't know where you are so there's no wayyou're going to know, globally, where this thing is, but you know where yourneighbors are locally
* And the Rendezvous Problem is the problem where having allthe agents meet at the same position
* You don't want to specify in advance wherethey going to meet because since they don't know where they are, they don't knowwhere they going to meet
* They can say, oh, we're going to meet in, at the origin.But I don't know where the origin is
* Is it in, in Atlanta, Georgia
* Or is it inBelgium, or is it India
* What do I know, right
* So, the point is, we're going tomeet somewhere, but we don't know where
* Okay.So, we have actually solved this problem before
* We sold it for the 2 robot case,where we had 2 robots
* and we could control the velocities right away
* What wedid is we simply had the agents aim towards each other
* So, u1 was x2 minusx1
* And u2 was x1 minus x2
* This simply means that they're aiming towards eachother
* Well, if we do that, we can actually write down the following thefollowing system
* This is the closed loop system now, where we have picked thatcontroller
* So, x dot is this matrix times x
* Okay, let's see if this works now.Well, how do we do that
* Well, we check the eigenvalues of the A matrix to seewhat's going on
* Alright
* Here is my A matrix, type eig in MATLAB or whateversoftware you're using, and you get that lambda 1 is 0, lambda 2 is negative 2.Okay, this is a little annoying, right
* Because we said asymptotic stability meansthat both eigenvalues need negative real part, this doesn't have that
* Butasymptotically stable, so asymptotic stability also means that the state goesto the origin and, like we said, we don't know where the origin is, so why should weexpect that
* We should not expect it
* We also know that one positive eigenvalue oreigenvalue with positive real part makes a system go unstable
* We don't have thateither
* In fact, what we have is this in-between case that we called criticalstability
* We have one 0 eigenvalue and the remaining eigenvalues have negativereal part
* So, this is critically stable
* And, in fact, here is a fact that I'm notgoing to show but this is a very useful fact
* So, that if you have one eigenvaluebe zero and all the others have negative real part, then in, in a certain sense,you're acting like asymptotic stability
* Meaning, you go, in this case, not to zerobut you go into a special space called the null space of A
* And the null space of Ais given by the set of all x, so such that when you multiply A by x, you get zeroout
* That's where your going to end up
* So, your going to end up inside this thingcalled the null space of A, in this case, because you have one 0 eigenvalue and allothers having strictly negative real part
* And if you type null(A) in MATLAB, youfind that the null space for this particular A is given by x is equal toalpha, alpha where alpha is any real number and why is that
* Well, if I takenegative 1, 1, 1, negative 1, this is my A matrix, and I multiply this by alpha,alpha, what do I get
* Well, ll' get minus alpha plus alpha here, and then I get plusalpha minus alpha there, which is clearly equal to 0
* So, this is the null space.Okay, what does this mean for me
* Well, it means that x is, x1 is going to go toalpha and x2 is going to go to alpha
* x1 goes to alpha, x2 goes to alpha, whichmeans that x1 minus x2 goes to 0 because they go to the same thing
* Which means,that we have, ta-da, achieved rendevous
* They end up on top of each other
* In fact,they end, end up at alpha
* We don't know what alpha is but We know that they end upthere
* Okay
* Now, if you have more than two agents, wesimply do the same thing
* In this case, we aim towards what's called the centroid ofthe neighbors
* And, in fact, if we write this down, we write down the same thingfor more than one agent, we get that x dot i, before it was just xj minus xi, therewere 2 agents
* Now, I'm summing over all of agents i's neighbors
* That is doing thesame thing if you have more than one agent
* And, in fact, if you do that andyou stack all the x's together then you can write this as x
* is negative lx
* Andthis is just some bookkeeping
* And the interesting thing here, here is that l it,it's known as the Laplacian of the underlying graph
* Meaning, who can talk towhom
* that's not so important
* The important thing though is that we know alot about this matrix L and, again, and it's called the graph Laplacian
* And thefact is that if the undergrinding, underlying graph is connected, then L hasone 0 eigenvalue, and the rest of the eigenvalues are positive
* But look here,we have negative L here, which means that negative L is one 0 eigenvalue and therest of the eigenvalues are negative
* That means that this system here, thegeneral multiagent system here is actually critically stable
* And we know that itgoes int o the null space of L
* And it turns out, and this is a fact fromsomething called algebraic graph theory
* We don't need to worry too much about it.We just know that clever graph theoreticians have figured out that thenull space to L, if the graph is connected which means that there is some path with,through this network between any two agents is given by not alpha, alpha butalpha, alpha, alpha, alpha, alpha, a bunch of alphas
* So, just like before, if I havethis thing and, in fact, it doesn't have to be scalar agents, what I do have isthat all the agents go to the same alpha or in other words, the difference betweenthe agents will actually disappear
* And when we did this, we design a controller.We actually designed this thing here
* And this thing is so useful that it actuallyhas its own name
* It's known as the consensus equation because it makes agentsagree
* In this case, they were agreeing on position
* But this equation actually willsolve the rendezvous problem because of the fact that the corresponding systemmatrix you get is negative L at the right eigenvalues which means that the system iscritically stable so we can solve rendezvous in the multirobot case
* Andagain, you've seen this video
* Now, you know what it was I was running to generatethis video
* In fact, you can go beyond rendezvous So, here is actually a coursethat I'm teaching at Georgia Tech, where you want to do a bunch of differentthings
* And again, all I'm doing is really the rendezvous equation with a bunch ofweights on top of it
* And we're going to learn how to do this
* I just want to showyou this video, because I think it's quite spectacular
* You have robots that have tonavigate an environment
* They're running these, basically the conses equation andthey have to avoid slamming into obstacles, so I should point out that thiswas the final project, project in this course, it's called network controlsystems
* And I just wanted to show you that you can take this very simplealgorithm that we just dev eloped, make some minor tweaks to it, which we're goingto learn how to do, to solve rather complicated, multiagent robotics problems.So here, the robots have to split into different subgroups and avoid things, theyhave to get information, they have to discover missing agents and so forth
* Andwe will learn how to do all of that in this course
* Now, having said that, talkis cheap, right
* And simulation is maybe not cheap, but let's do it for real
* Inthis case, we're going to have two Khepera mobile robots, and what we're going to dois we're going to use the same PID go-to-go controllers and we're going tolet the consensus equation flop down intermediary goal points
* And what we'regoing to do is we're going to keep track of our position using odometry, meaningour, our real encoders
* And what the robots are going to do, is they'reactually going to tell each other where they are rather than sense where they arebecause we haven't talked yet about how the design sensing links
* So, what we'redoing is we're faking the sensing and telling, they're telling each other wherethey are
* And they're using a PID regulator to go in the direction that theconsensus equation is telling them to go in
* And now, let's switch to the actualrobots running and solving the rendezvous problem
* So, now that we have designed aclosed looped controller for achieving rendezvous we're going to deploy it on ourold friends, to Khepera mobile robots
* so, what we will see now are these two robotsactually executing this algorithm
* and we will be using the same go to goalcontroller as we designed earlier to achieve this
* And, as always, I have J P..De la Croix here to conduct the affairs and practically, we're going to see tworobots crashing into each other which is exciting in its own right
* Butintellectually, what we're going to see, is the state of the system asymptoticallydriving into the null space of our new A matrix
* And the reason for that is, aswe've seen this matrix has 0, 0 eigenvalue, which means that the system iscritically stable and the states approach the null space
* So, J.P., without furtherado, let's see a robotic crash
* So, we see they're immediately turning towards eachother and 
* Pretty exciting stuff, if I may say so myself.


--- SKIP ---: 07_output-feedback.en.srt


--- SKIP ---: 07_output-feedback.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_output-feedback.en_SENTbySENT.txt
* So now we know not only that the firstorder business is to make the system stable meaning it shouldn't blow up, itshould behave well, but we also know what this means, namely that the Eigen valuesof the system should have negative real part and even though we saw somecritically stable cases last time
* Including a rather awesome, set of robotsslamming into each other
* We typically don't want critical stability
* We wantasymptotic stability
* Which means that we need to have strictly negative real partof all the eigenvalues here
* And today, we're going to actually achieve that, ortry to achieve it, by designing a controller
* Because remember this picture., Speaker:We have our system, x dot is Ax plus Bu where u is the input, and then yis equal to Cx
* So, whatever we do to our control choice has to depend on the thingsthat we have access to, which is why we don't know the state of the system
* But,we certainly know the output
* So, today we're going to try something called'output feedback,' which means we're going to take the output of the system
* And useit to feed directly back in as a way of controlling it
* And we're going to startby returning to our old friend, the world's simplest robot, which is just apoint on a line that we can control the acceleration of and, as you hopefullyrecall, we can write this in state space form as x dot is
* This a matrix, 0100x.plus a b matrix that's 01
* And then, the output is 10x
* This means that the outputis the position of the point mass
* And x1, the first component of x is the position.The second component of x is
* The velocity and then u immediately gives us the, theacceleration
* So now our job is to somehow connect y to u meaning pick our input insuch a way that this system behaviors and in fact here is an idea, we want to drive.The system to zero, which means stabilize it
* So, why don't we move towards theorigin
* meaning, the position of the robot is what it is
* And let's say that, here isthe origin
* And our job is to drive it to the origin
* So if the position isnegative
* Meaning we're on the left on the origin
* We should probably move in thisdirection
* If the
* Robot is over there, we should move it tothe left, which is in a negative direction
* So that's a very, very simpleidea
* And in fact if we turn it into math, we see that if y is negative, so ynegative again, corresponds if the origin is here, us being on this side, then ushould be positive, which means moving this
* Direction, and similarly if Y ispositive than U should be negative
* And here's some suggestion
* Right.Let's pick the world's simplest controller that achieves this
* Simply, the negativeof Y
* So Y positive means negative U, Y negative means positive U
* u
* So let's trythis, and see what it actually does
* And what we need to do first is understand.How does this change the system dynamics
* Because what we really did now, is, we hadu equal to well, we had minus y
* So k, in our example, was just a1
* But in general,k here could be
* It's a more rich structure, and if used in the y's ormultidimensional, then this needs to be a vector
* Now, we know that y is equal to Ctimes x, so we can write this as u being equal to negative KCx
* So, now let's plugthis into our differential equation that we have
* So, x dot is Ax plus Bu, and nowinstead of u
* We're plugging in this term right
* So then we get a minus BKCx or ifyou plug everything together, we get A minus BKCx
* And this, we can write if youwant to as a hat times x
* So this is just a new system matrix and of course our jobis to pick k now so that's the real Part of the eigenvalues of A hat is strictlynegative
* In other words, pick if possible K such that the real part of lambda isstrictly negative for all lambda that is, that is an eigenvalue to this new systemmatrix A minus BKC
* So that's really our, our job here and in a way already pickedK, we said K was equal to one
* Well let's see what's happening if that's the case,then we have x dot is, this is A, this is B, this is K a nd this is C
* So this iswhat we have in terms of the
* The system matrix for our, robot
* And one thing tonote, first of all
* That 1 times 1, 0 is just 1, 0
* And if I multiply this by 0, 1,then I get, what do I get
* I get 0 times 1, then 0 times 0 1 times 1
* And 0 times1
* So this is what this whole expression is equal to
* So now I can just take thismatrix, and subtract away this matrix to get the, the right answer
* And if I dothat, I get x
* is 0, 1, negative 1, 0, x
* And this is for my particular choice of k.And let's check out what, what the eigenvalues are of this thing
* Well, youwrite eig in MATLAB and you get the answer
* Or, as we will see in futurelectures, you can actually compute it and, and say something about the clever choiceof k in that way
* But, for now, we're just going to immediately plug this into ourfavorite software system, and we find out that the eigenvalues are plus and minus j.Where j is square root to negative 1
* So is this system asymptotically stable?Well, the real part of lamda for both lamdas so we have two lamdas
* The realpart is zero, because this is a purely imaginary system
* And, as I said lasttime, if I have two
* Imaginary eigenvalues and all the others are well behaved, inthis case I don't have any others, then I have a critically stable system
* And infact since I have imaginary components, we have already hinted at this that what weactually end up with are oscillations
* So this is a critically stable system and ifI simulate with this role, what it's doing, it's going to look like this.Really what's happening is this thing is just going back and forth, back and forth.So, what's the problem
* We clearly did not stabilize it, we know it's notasymptotically stable in fact it's just going back and forth back and forth wellhere is the problem, When the robot is let's say on it's way
* Away from theorigin, then we're pushing it, correctly so, towards the origin
* But when it's onit's way back, we're still pushing it equally hard, even thou gh it's actuallygoing there almost by itself
* So, we're kind of not taking the direction in whichthe robot is going
* Into account
* What this actually means is that we arenot looking at the velocity because the velocity is going to tell you whichdirection it is going in
* So the problem is that we do not take velocity intoaccount
* Remember what the state is
* The state is position and velocity
* So theproblem is that we need all of it to stabilize and we need the full stateinformation not just the output
* So output feedback like this doesn't quiet Work, butinstead we want to operate on x instead of y
* But here of course is the problem
* Howdo we do that
* And the corollary to that is, we don't even know x
* We only know y.How in the world can we design controllers for things that we don't know
* Well, as wewill see in the next module, it's possible to figure out x from y a lot of times
* Ifyou just think of y in this case as being the position And x being y, as x beingposition in velocity
* Then velocity, right, we can get by measuring twopositions after each other, and dividing it by the time in between themeasurements
* Then we get an estimate of the velocity
* So, it's clearly possible inthis case to at least get an estimate of state from the, the From the output
* Solike I said this is the next module but in the next lecture which is the last lectureof this module will pretend that we actually have x and revisits the world'ssimplest robot and see how can we actually stabilize it if we have all of x and notjust y.


--- SKIP ---: 08_state-feedback.en.srt


--- SKIP ---: 08_state-feedback.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_state-feedback.en_SENTbySENT.txt
* So the outcome of last lecture was on onehand a little bit exciting because what we did is we took the measurements that weget and we try to use them as a, for as a way of designing controllers to stabilizethe system
* We actually know how to stabilize systems
* We need the real partsof the eigen values are all strictly negative.On the other hand, the outcome of the last lecture was wildly disappointing becausewe couldn't actually do it
* And the reason for that was that we only looked at theoutput and not at the full state information
* So today, we're going to lookat How do we design controllers when we take all of x into account, and not justy
* so if you recall this picture
* What we're going to do today is simply say, youknow what
* I don't care about y
* In fact, forget about measurements
* What comes outhere is x itself
* And then, what can we actually do
* Now, obviously
* What we needto which is the topic of the next modal is create a way of actually sucking out xfrom y but for now lets just pretend for a moment that we do have access to the fullstate information
* Well if we have that first off we dont have to worry about ywhat so ever So x dot is Ax plus Bu, forget about y
* Then what we do is insteadof saying u is negative Ky, we're now going to say u is negative Kx, where K isthe matrix of various gains in it
* In the previous example, it was just a scalarwith a 1 in it, but in general it could be a matrix
* Now, just like last time, weplug this choice of u Back into the equation for x., and then we get x., thisax, plus bu, well u is negative kx
* So then we can put everything together inthis matrix, a minus bk
* And if we call this A hat, we all of asudden have a new system matrix and our job is to make A hat as pretty aspossible
* Well in particular A hat is known as the closed loop dynamics becausenow we have closed the loop of the system
* We're feeding back the state information.Into the system and in that way we are getting rid of the Ax's or x dot is Axplus Bu and we are getting x dot is A minus BKx and they control the sign taskfrom a stability point of is simply pick if possible K such that the closed-loopsystem is stabilized and luckily for us we now know
* Exactly what this means
* Itmeans that the real part of the eigenvalues of the closed-loop dynamics, Aminus BK, has to be strictly negative
* So, let's go back again to our simple robot tosee how can we understand this in the context of the simple robot
* And arguably,the entire next module, module 4, is going to be devoted to this question
* How do wepick K such that we can stabilize this system, get the eigen values we want
* Andon top of that, how do we get around this rather peculiar conundrum where we onlyhave y but we would like to have x and we're going to pretend that we have X.Well, that, we will have wait for
* But for now, let's go back to the robot
* Let'snote, though, first of all, that u is in r, and x is in r squared, or r2
* And, infact, if u is negative kx
* It's always useful to write down this kind ofdimensional analysis
* Where x is n by 1
* In this case, u is in general, let's saythat u is m x 1, in this case it's actually 1 x 1, then, from a dimensionalpoint of view, K has to be m x n, because otherwise it doesn't work out, so we haveto be able to cancel these things out, and out comes soemthing that's m x 1
* So ingeneral, K is a m x 1 Matrix where m is the dimension of the output and the n isthe dimension of the state
* Okay, in this case m by 1 means 1 by 2, we pick k1 andk2 here, those are our control gains, we plug it to the A-Bk equation here
* So thisis
* This is a, this is b, and this is k, right
* So if we do that, we get thissystem
* And we perform the matrix multiplication
* I would encourage you tomake sure that I got the matrix multiplication right by doing ityourselves
* But, for now, let's just accept the fact that the close loopdynamics becomes x dot, is 0, 1 minus k1 minus k2x
* Okay, so now we have this 2knobs that we can tweak, k1 and k2, and w hen we tweak them, the eigen values of theclosed loop dynamics are going to move around
* So, in the next module we'll besystematic in terms of how we actually pick this case
* For now.Let's just put some case pull some case out of a hat
* Oh, and I'm a lazy man, soI'm pull once out of the hat
* So let's just try k1 equals k2 equals to 1
* Whynot
* As a first, first attempt, at least
* Well, if I plug this in to my A mius BKequation, I get the following closed-loop system dynamics
* And let's check theeigenvalues of these things
* So list write eig in MATLAB or whatever system you wantto use
* if you do that, you'll find out that the eigenvalues are negative 0.5 -plus minus something, something, something, j
* What are the real parts ofthe eigenvalues
* Well the real parts of the eigenvalues
* ,, 
* There, -0.5, sothere strictly negative, which of course is what we needed for stability
* So wehave asymptotic stability, so we have in fact Achieved asymptotic stability
* Now,the other thing to note is that the fact that we have a J hanging around there,meaning we have an imaginary component to our eigenvalues, that means that we canexpect oscillations in the way the system behaves
* So we have an asymptoticallystable system with some oscillations floating around, and they are in factdamped oscillations because, since the system is stable, the oscillations aregoing to become smaller and smaller in amplitude, and as t goes to infinity, theyare going to in fact go away completely
* So if I do this, then here is what itlooks like
* As you can see very quickly we get close to the origin we overshot alittle bit and this because of these osculations
* So lets see if we can dosomething about these osculations
* Well here is another attempt completelyarbitrary
* I am going to make k1 smaller which means k1 tells me how much I reactto position and k2 tells me how much I react to volicity You can always think of,almost think of this as a p parameter in a PID regulator, and this is the d parameteri n the PID regulator
* Because p is the position in this case, and d is thederivative of position, which is velocity
* And that's what k2 is, is affecting
* Okay.If I do that, then my new system matrix becomes this beast here
* Well, let's checkits eigenvalues
* In this case, the eigenvalues end up being these 2 numbers.And they're real, which means we cannot expect, really, any oscillations
* and evenbetter yet
* The real and strictly negatives
* So this is an asymptoticallystable system with no oscillation
* Oscillations.So, this seems like a pretty decent design to me
* Let's see what it would actually doto the robot
* So the robot, eh, well, it's not oscillating but it's unbearably slow.So, what we saw here is that we actually got rid of the oscillations but we gotassistance that was much more or sluggish in the sense that iti's slow andborderline annoying from a performance point of view
* But for now asymptoticstability is achieved and what we saw we need to do is to be able to achievestability while doing other things at the same time
* But one thing that isabsolutely clear is that some eigenvalues are better than others
* And our design ofcontrol gain, somehow, should be reflected by, what are good eigenvalues
* So, someeigenvalues cause oscillation
* Some eigenvalues cause instability
* Someeigenvalues make the system Respond too slowly and so forth
* So what I want toleave you with now is it seems like state feedback is the way to go
* Even though wedon't really know how to get to state yet
* But we will by the end of the next module.And we have to be careful and creative and clever in terms of how we select oureigenvalues
* And that's another topic for the next module
* which is how do weactually Select the appropriate eigenvalues to get the closed loop systembehavior that we want.


--- SKIP ---: 09_glue-lecture-3.en.srt


--- SKIP ---: 09_glue-lecture-3.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_glue-lecture-3.en_SENTbySENT.txt
* >> Hello and welcome to our third Gluelecture
* To sort of round out the third week of thecourse, today's Glue lecture is titled Systems, and I'm going to talk kind of howwe think about systems in this course
* And this will be helpful for quiz 3, we'lldo 2 examples that are similar to questions on the quiz.So the goal of this lecture is to think about how inputs and outputs can define asystem, and that's really How we are going to think of systems in this course.And then, I hope to kind of get you used to this matrix representsation, thisstates based form of systems by doing an example of putting a second order systeminto states based form
* And to do a linearization of a non-linearsecond order system as well
* So first, let's just think for a fewminutes about what a system is
* So, you know, in general, we might thinkof a satellite being a system, as a fancy technological device that, that doessomething that we design it to do
* We might think of it as something that hasthis kind of confusing block diagram
* Description.We might think of it as something in our car, right or a, or a interface which was,a technological interface that we, we interact with..Of course there's also the solar system, that is somehow a system of planets that'sworking together
* That we think of, or systems of the body,different organs that work together to perform basic functions.So the point of this slide is just the idea that the word system a lot and wemight all have different ideas about what a system is and, you know, this course isreally kind of all about systems
* And so I kind of want to clarify whatwe'll mean, and, when we think about them, and the idea, really is that, in thiscourse, we want to understand how inputs really relates to outputs.And so any of these systems, we can be considering different inputs, differentparts of the system that we can control or actuate on and different outputs of thesystem, different things that we might be measuring for different goals.So you know, on, you know, a satellite, you might be controlling orientation.And so you might think of different inputs and outputs there, or you might becontrolling altitude, and so now you have different actuators, different goals forthe altitude than the orientation
* So we could think of those really in thiscourse, as, as distinct systems that have different control objectives.And so the picture that we're thinking about is really this idea that we havesome input here that we're mapping to an output defined by these A, B and Cmatrices
* And so getting into the first example,we're going to talk about how to move a dynamical equation that describes somesystem into this form that looks like this.And at first that can be a little bit tricky and so I want to go over it and ofcourse remembering that both of these equations, have some initial condition.F of 0 equals f not
* X of 0 equals x not.Keeping that in mind, we're just going to think right now about how to go betweensomething that looks like this to something that looks like this.And, really that's just a matter of picking our state variables, de, decidingwhat our state is, and then to/g choosing these inputs and outputs.So which of these variables is what we're controlling and which of these is whatwe're measuring
* And then we're going to write this secondorder differential equation as a pair of first order ones, so that our second ordersystem is now represented In terms of two first order equations.And then, put these in terms of our x, our u, and our y, right?So first, for this example, we'll select our state to be f and f dot That's apretty common choice for, for a state at not necessarily the only choice, butyou'll see that it's convenient because when we think of x dot, x dot is going tolook like this right
* Oops, f double dot.And now we ha, we, we need to be able to know something about f double dot right tofor this choice of state, and so of course we do, and so that's why you'll see thatOften as the choice of the state
* And now we pick our input to be thisfunction p here, so this is somehow, someway that we're influencing what f,the, the various derivatives of f are doing, and now we'll chose our output tobe f, but again this could be chosen as f dot, this could be chosen as both f and fdot, And that will determine the form of these a, b, and C matrices.So those choices are important and usually they are described in the problem setup.So now that we have chosen our state, our input and our output we need to write thisequation in terms of two first order equations.So we can think of f-dot and f-double-dot
* Well now we're going to write them interms of our state variables x 1 x 2 in our input and our output.So, here we have f dot
* Well that was x2, right?So we can directly relate f dot in terms of x2 and now, x2 of course is related tox1 through this, through this time derivative.And then for F double dot, well F double dot is x two dot, and this equation thatwe were given here
* So where I'm dividing by everything by m,and now I'm writing remember X two is F dot, so I filled that in here, and hereI'm filling in that X one is f
* And here I'm filling in that u is p.So just rewriting this to this
* And so now if we come back, this isexactly what I had on the last slide
* X dot in terms of the other statevariables as we renamed them in the first step.And so now it's just a matter of getting it to look something like a x plus b u,right
* So I need to pull out, we need to, what Iwould like to do is write an empty matrix, and I know that I want that to be times x,right
* So, I write x here, so that's the ax term.And, now it's time some other matrix, this one's going to be tall and skinny, timesu
* Okay, so here, I just need to kind ofrearrange these terms
* And here we'll have, so what, rememberthat this is x 1 dot, and x 2 dot, that we're trying to equal.So what does x 1 dot equal
* Well, it equals x 2, so we just need no x1 contribution, and 1 x 2 contribution, and then no u.>> So, now this first line, because, is correct, right?This x1 gets multiplied by the first entry of the matrix, x2 gets multiplied by thesecond
* They get added together, so this all addsup to x2
* Now, for x2 dot, well that equals thiswhole term
* So now we have a contribution from x1, x2and u
* And that contribution for x one is betaover, and from x two is alpha over m
* And now from u, we need to multiply u byc, to get this o, over m, to get this term tied up.So That ends up looking like this, right
* Where this is our a matrix, and this isour b matrix
* And we can do the same thing for y.Y equals c x, and since y was f, and f is x one, you get just a one in the, in theentry of the matrix that x one will be multiplied by.So this is how you work
* Something that looks like this and to stayspace form, So now we have that our system where we picked our state, our input, ouroutput its represented by these three matrices A, B and C.So to pick up to get into example two
* This is going to be an example oflinearizing a non-linear system
* So this is a system where we have this zsquared term
* Sorry let me fix my marker here.So now we have this z squared term, which means we can't do what I just did where IWrote this empty a matrix and pulled out x and just filled in the indices right.We have this z squared term which means it's not going to fit into that abc form.And so what we do is we linearize it around some operating point, and here thatpoint is going to be 0, 0
* And so first what we need to do, ofcourse, is just write this guy, the second order.Differential equation in terms of these 2 first order equations.So just I'm writing this kind so that you remember that x1 dot because of this twicethat we;re given in the problem that x and z and z dot and our input u is tau.That this is how, that d dot and d double dot relate to x1 dot and x2 dot.And so now we have that x1 dot is x2, x2 dot is this whole thing because that'swhat d double dot is
* Again writing it in terms of our statevariables
* But now, again we have this x1 squared, sowe can't just write this in abc form
* So the way we do it in this case is tojust compute this A matrix, this linearization.So here we have f1, f and f2 which are going to be, here's our f1, here's our f2.And so we just have to compute these derivatives in terms of our stayvariables
* So this first, let's I'll write it out.For A, we have the derivative of this guy with respect to x1.That's 0
* Now the derivative x2 with respect to x2.That's 1
* Now we look at f2 to compute the secondrow
* Derivative of x2 with respect to x1 is2lx1, this term
* Both of these other two terms go to zero,and now f2 in terms of x2 is just gamma, right, because here's the x2 term.And so now this is our a matrix evaluated at our operating point, right?So this term is going to go away, and this whole thing is going to equal zero, zero0,1,0 gamma, for this choice of this operating point.So we're linearizing around that, around that point.In the case of the pendulum, when it's hanging down.Right
* That we're just going to be able tocontrol it around that hanging down position.So, in nicer text, this is what we have
* And we do the same, a very similar processfor the B matrix, where Now the b matrix has a different size, right?But we have the derivative f one in terms of u, and the derivative f two in terms ofu
* So that's these two equations again.And we get this, that this is zero c, and evaluated at any operating point this isactually going to be the same thing because it's not And a function of any ofour state variables anymore
* So now, the linearization of this systemis given by these 2 matrices
* And our output is going to be a similarprocess, that I think Dr
* Iverson went over in lecture, as well.So with that, good luck on quiz 3, and I hope you're enjoying the course.


--- SKIP ---: 10_programming-simulation-lecture-3.en.srt


--- SKIP ---: 10_programming-simulation-lecture-3.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_programming-simulation-lecture-3.en_SENTbySENT.txt
* Hello and welcome back
* This is the third Programming andSimulation lecture
* This week I'll be talking about go-to-goalcontrollers
* These controllers are used to steer mobilerobots to, from point A to point B
* In fact, in this week's programmingassignment you'll be implementing a PID basedgo-to-goal controller
* Therefore, you will need to implement theproportional, integral, and derivative, derivative terms of the controller as wellas adjust the gains for optimal performance
* The notation that I will use in thisweek's assignment is as follows
* First, we have the location of the robotdenoted by x and y
* The robot also has an orientation denotedby theta with respect to the x axis
* The location of the goal is denoted by x_gand y_g, and the vector between the goal, and the, and the position of therobot is denoted by u_gtg
* This vector also has an angle, theta_g,with res, or with the respect to the x-axis
* Now, this particular go-to-goal controllerthat you'll be implementing works in the followingway
* We're going to keep the linear velocityconstant and use PID to compute omega, the angle ofvelocity of the robots, that will steer it towards thegoal, and you will implement this in the go-to-goalclass, defined in GoToGoal.m
* An important part of this controller ismemory
* We need memory to keep track of the previous andaccumulated error for the integral and the derivative terms ofthe PID controller
* The way we keep memory is throughvariables in the class
* We have two variables
* The first is this variable right here, which is the total accumul, accumulatederror
* Whereas this, whereas, whereas thisvariable right here is the previous error
* And both of these will be remembered at each time step so that wecan keep track and use them in the, when you're calculating the derivative and when you're calculating theintegral
* You also should note, take note of these three variables up here, which correspondto the proportional, integral, and derivativegains of the controller, which you can adjust for the PIDcontroller
* You will implement all three parts of thePID controller in the execute function
* This execute function is also in theGoToGoal.m file
* And this execute function takes in thelocation of the goal, as well as a linear velocity and thelocation and orientation of the robot
* And computes the appropriate linear andangular velocity, and outputs this
* So let's take a look at the skeleton codefor this function
* This is the skeleton code for the executefunction
* At the top, we're retrieving the locationof the goal as well as the location of the robot and its orientation, and the design of linearvelocity
* Then you will need to compute the headingto the goal
* And compute the error between the robot'sorientation and the orientation of the goal with respectto the robot
* In the last part, you need to complete thethree terms of PID controller
* First, you calculate the proportionalterm, then the integral term, and then the derivativeterm
* And then you combine all three terms alongwith their gains to compute the appropriate angularvelocity of the robot
* Last, the integral, the accumulated errorand the previous error are saved for the next timestep
* Now, if you run this PID controller,you're going to get something similar to the graph on the left, wherethe red dashed line is the desired angle to the goal, and theblue line, the blue solid line is the actualorientation of the robot
* And what you want to see is that thedifference between those two is minimized by the PIDcontroller
* And the other thing you want to see isthat your gains ensure that there is very low overshoot and almost no osco,oscillations in the, in the output
* You can see there's a little bit, but not too much
* And also the blue line almost perfectlymatches up the red line
* Now, to help you test this, we've includeda stop condition so that the robot stops when it gets nearthe goal
* And you can adjust this goal location inthe constructor of the supervisor
* And what you want to edit is this variableright here, obj.goal
* And, and, by default I have selected -1meter in the x direction and 1 meter up in the ydirection, as indicated right here
* Now, let's see this in action.I'm going to launch the simulator
* And this brings it up, us, to the sparscreen
* I'm going to hit the play button and whatyou should see is the graph of the output come up as well as the robot should start immediately moving towardsthe goal location
* So, let's do this
* There's the graph.I'm going to move it out of the way
* And, here you can see the robot drivingtowards the goal location
* And I can click over here and look at the graph, and I see that the output is verynice
* And, if I close down the simulator, I'll show you that I've used fprintf statementto print out the current position of therobot as well as the estimated position of therobot
* And you should be very, very close tostock condition stops the robot within 5 centimeters of the goal.So you, you should be fairly close here
* My tips for this week are the same as lastweek
* Just make sure to read the Week 3 sectionin the manual for more details
* And, use as many fprintf statements as youcan to help you debug your code just like I did in thedemo
* And, that's it for this week.


--- SKIP ---: 01_stabilizing-the-point-mass.en.srt


--- SKIP ---: 01_stabilizing-the-point-mass.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_stabilizing-the-point-mass.en_SENTbySENT.txt
* Welcome to the module 4 of the course Control of Mobile Robots
* So, in the last module we've learned about linear systems and we saw where they came from and at the end we even managed to control them a little bit and in fact we felt rather good about ourselves
* because we could design a state feed back controller for a point mass that stabilized it, but at the same time we were a little queasy and uneasy about this whole thing because we had to have x meaning the state to do our control design but in reality, we actually don't have x
* We have y, the output
* So what this module is devoted to is trying to first of all, be systematic in how we do the control design and, secondly, how do we actually overcome this seeming paradox of needing x but only having y
* So what we're going to do in the first lecture, is stabilize the point mass
* We're going to return to our old friend, and in general, if I have a linear system, x dot is Ax + Bu, y is Cx
* The dilemma, as I've already stated is that we seem to need x for stability but all we really have is y
* So here is the game play
* We're going to ignore the fact that we don't have y
* Instead we're going to design our controller as if we had the state itself and then somehow we're going to hope that we can figure out the state from the Measurements, meaning from y, and this is the game plan we're going to pursue throughout this entire module
* And, the first step is, of course to design u as if we had x
* So step one is to, do the control design and we're going to use a method called, pole placement
* And, pole placement is a rather powerful idea
* So if I have my point mass system again, x dot is Ax+Bu, where we have our old friends the A and B matrices that we've seen over and over again
* Well, state feedback means that, what we are going to do is we're going to pick u is -Kx
* Where K in this particular situation is a 1 by 2 matrix, so it has 2 components
* k1 and k2
* And those are, are gains
* And we've already seen in the previous module, that k1 is a gain that looks at precision
* And k2 is a gain that looks at velocity
* And by tweaking them, somehow, we can get the system to be, behave well
* 'Cuz we've already seen that
* So, the one question we need to ask first, is, of course, is, how do we actually pick these control gains
* Meaning, what should k be
* Well
* Here is the whole idea behind pole placement
* When we plug in U is minus KX we get a closed loop system
* And what we're going to do, is we're going to pick K such that the closed loop system has the right eigenvalues
* And right meaning, we get to pick them
* And the risk is called pole placement, its that eigen values of the system matrices are sometimes referred to as poles and what we're going to do is we're going to make them be what we want them to be, in particular we want them to have negative real part because that is what we need for asymptotic stability
* So but before we do that we actually need to figure out how do we computer eigenvalues
* So in general, if I have a matrix M, this doesn't have to be a 2 by 2, this is just some general M, then every square matrix M has a so-called characteristic equation associated with it
* And it's given by this chi M of lambda, and it's kind of a mouthful
* It's the determinant of lambda times the identity matrix -M
* And then we set this determinant equal to 0
* And the lambdas that solve this are Eigenvalues, well, let's see what this means
* If I have a 2x2 system and equal to M1, M2, M3 and M4 then lambda I, meaning lambda times the identity minus M
* Well it's lambda times the identity minus M, well, if you plug this in, you get the following matrix
* Okay, now, let's take the determinant of this matrix
* So the determinant, well, is this object you get by taking this element times this element
* And then you subtract away this element times that element
* this is how you do it for 2 by 2 matrices
* in general it can become even more complicated
* But in this case, I get this times that which shows up as lambda - m1 * lambda - m4
* And then I get -m2, or - - m2 * -m3, which shows up like this
* So this is the, the determinant of this 2 by 2 M matrix
* Okay
* We need to set this determinant equal to zero, so aa, carrying out the multiplications we have second order equation that we have to solve for lambda in order to be able to find Eigenvalues, okay
* Lets try to that, we have this equation.The way we solve second order equations, is while there are formulas for this it is possible to do it
* In this case it turns out that lambda is this rather annoying looking expression here, but this is what the Eigenvalue, the 2 Eigenvalue to this 2x2 matrix would be
* But it is annoying
* I really don't want to do this
* So the question is there an easier way of making the Eigenvalues be what we would like them to be
* Turns out that the answer is, yes
* There is something called the fundamental theorem of algebra
* And this fancy looking, or fancy sounding theorem says that, if I have a polynomial, the roots to that polynomial are determined by the coefficients, which means that you know what
* I actually don't have to solve this equation
* Here I have coefficients in front of lambda then here I have the coefficients that aren't in front of any lamda, those coefficients alone are enough to implicitly but completely determined eigen values
* So what we're going to do is we're actually not going to solve this
* We're just going to stop here and say, fine, lets start massaging the coefficients direct
* So if we go back to our point mass again
* I pick u as -kx
* Then I get x dot is (A - BK) x We've seen this before
* this is the closed loop dynamics
* And in particular if I plug in what k is I get A - BK being this two matrices here
* And, if I compute that, I get 0, 1, -k1, -k2
* And I, encourage all of you to perform this multiplication at home, just to make sure that you trust that this is indeed Now let's compute the igon values or at least the co-efficients in this thing called the characteristic equation
* So, chi A minus BK lambda is the determinent of this matrix or the negative of that matrix plus Lambda times the identity
* So, this is what I have here of course is lambda I - (A - BK)
* And, if you compute this determinant, you get, lambda ^ 2 + lambda k2 + k1
* That's not so bad
* And the neat thing here is that again, all we care about These coefficients
* The things that determine what the roots are without us actually having to complete the roots
* Now why does that help us
* Well, what we're going to do now is we're going to pick our favorite eigenvalues in the whole world
* We're going to pick the eigenvalues that we would like the system to have, and if we somehow magically manage to make the closed loop system have these eigenvalues, then the characteristic equation would be lamda minus lamda 1 because the characteristic equation has to be 0 has to be lamda 1 as a root
* And if I plug in lamda 1, I get 0 here
* Similarly if I plug in lamda 2 I get 0 here, and lamda and 0 here
* So what I have is a product of lamda minus these desired favorite eigenvalues in the whole world
* So let's do that
* so for the robot or the point mass, I'm going to pick both eigenvalues at -1
* I need, I know that they need to have negative real part, well, -1 is particularly simple Because then I get this phi of lambda which is this desired characteristic equation, not the actual characteristic equation but the desired one
* It's just lambda + 1 * lambda + 1 or, if I carry out this multiplication, I get lambda ^ 2 + 2 lambda + 1
* Now, what we need to do is simply line up these coefficients with the actual coefficients that we have
* So if I do that, I see, this is the characteristic equation
* This is what I would like it to look like
* Well, here are the coefficients in front of lambda
* And here are these coefficients that are hanging out by themselves
* All we do now is simply line these up
* So k2 has to be = 2, k1 has to be = 1 and wahlah, I've actually designed the k matrix that I need
* So now all I do is I plug this in to my original system which is x dot is Ax + Bu but I've closed the loop right now with u being -Kx and I have successfully stabilized the system, by placing the eigenvalues exactly where I would like them to be.


--- SKIP ---: 02_pole-placement.en.srt


--- SKIP ---: 02_pole-placement.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_pole-placement.en_SENTbySENT.txt
* So, in the last lecture, we saw that it was possible to pick the eigenvalues of the closed loop system in such a way that they became equal to some desired eigenvalues
* For the particular case of the point mass robot
* Now, today, I want to be a little bit more general
* In terms of, how do we go about doing this for, arbitrary and linear systems
* And again, the whole idea here is that we pick our control gains such that the actual eigenvalues Of the closed loop system, becomes equal to the desired eigenvalues
* So, this is the whole the whole idea of philosophy behind this, this approach
* So, lets say that the characteristic equation associated with my closed loop system
* So, this is the, again the determinant
* Of (lambda*I-(A-BK))
* That's what this equation here says
* Well, let's assume that if I compute this I get the following expression
* Well, what I now do is I pick my favorite eigenvalues
* What I would like and in this case the lambda I's are my favorite eigenvalues
* so What I have is an actual characteristic equation, which is this thing
* And one that I would have had, had indeed the eigenvalues been equal to my favorite eigenvalues
* And all I do now is line up the coefficients
* So I take Bn-1 has to be equal to An-1
* Now, I'm writing An-1 as a function of K because it really is
* K is the control knob or the control gain that we have to solve these N equations for
* So this is the general procedure and it seems magic, it seems so we can control anything
* So the first question we should ask is, is this always possible
* The second question is, well
* Where do these the side eigenvalues come from
* And the third is, you know what determinants are not that fun to compute
* 2 by 2, fine
* But when we go to higher order systems, it becomes a pain
* Now, the first answer is, unfortunately
* This isn't magic, we can't always do it
* So, what we need to understand is in fact when we can do it and when we cannot do it
* the answer to the other question is, unfortunately there isn't a recipe book that says here are the eigenvalues you need to use
* In fact, it's a little bit of an art and science, and the design choices that we make ultimately boil down to The choices of eigenvalues
* So we have to discuss a little bit about how we pick our eigenvalues
* Now luckily for us, that's the answer to the third question
* We don't have to actually compute this
* In, in math lab, we can very easily use comething, something called the place command
* So if I have my a and b matrices and I wrote down A vector of my favorite eigenvalues, then I simply run K=place(A,B,P) to compute this K matrix that gives us the desired eigenvalues
* Cool
* OKay, let's do some examples
* Here is X dot is whatever X plus whatever U
* These are 2 arbitrary A and B matrixes
* Well, we're going to have to pick a K and again, K in this case has to be 1x2
* And the reason we see that is A is 2x2
* B is 2x1
* That means that K has to be 1x2
* Because these guys have to be the same
* They cancel out and what I end up with has to be of the right
* Dimension
* So, that's why k, in this situation, has to be a 1 by 2 matrix
* So if I compute this, I get the following matrix
* Well, here is the characteristic equation, or the, this determinant
* this should be = to 0
* But we're actually not going to solve it
* All we're going to do is, we're going to compute this determinant
* And again
* The way compute the determinants is this times this minus this times this
* And if you do that in this particular case, you get the following equation
* Here is one coefficient that we're going to have to mess with, and here is the other coefficient that we're going to have to
* To mess with
* Cool
* So, moving on, this is our characteristic equation
* Let's say again for the sake of argument that we want to place both our eigenvalues in negative 1, then this is what we would have had, had this been indeed true
* So now I'm going to have to solve its
* These two being equal and these being equal
* Those are the equations that we are forced to solve
* So, you do that, first of all for the coefficient in front of lambda then we get that, after a while, K1+K2=5 Well lets look at the coefficients in the form of of lamba^0, which means no lambdas
* If we do that we get k1+k2=1
* Hey, wait a second
* This is trouble isn't it
* k1+k2=5 and k1+k2=1 this doesn't seem all that promising, in fact it's impossible
* It can't be two things at the same time
* So here, all of a sudden, we failed
* We can't actually solve this
* And, what's really at play here is a lack of something called controllability
* And controllability is this key term that describes if we have enough Influence or control is already over our system, and when I said that it is not over responsible to do power placement
* This is exactly what I mean
* If we don't have enough control as provided we can do anything
* Nn fact, you can do nothing in that case, you just have to hope for the best or hold your nose
* But we'll, we'll talk about that in a little bit late a little bit later
* So for now, this is what can go wrong, lack of controllability
* We don't know what controllability is yet but that's something to be aware of
* Now, let's pretend that we could do it though
* how do we pick the eigenvalues
* Well
* It's not clear, like I said
* But some things we should keep in mind is
* Well, if the eigenvalues have a non-zero imaginary part
* Alright, well first of all, let's say that sigma+Jomega is an eigenvalue
* Then there has to be another eigenvalue
* In this case I call it lambda J
* There has to be another one that is the complex conjugate pair of this because eigenvalues have to show up in conjugate complex pairs if indeed they are
* complex
* So that's the first thing that we should keep in mind, that we can't just assign an, one complex eigenvalue
* We have to assign two, if that's the case
* The other thing is, of course, we need the real part of the eigenvalues to be strictly negative, because otherwise, we don't have asymptotic stability
* The other thing to know is that if, indeed, we keep an imaginary part around, we get oscillations
* So, oscillations, if that's something we would like, typically we don't, but, so if you don't like oscillations the eigenvalues we pick are all real
* If for, for some reason wanting oscillations, then we have to introduce
* Imaginary parts
* And the last thing is that the choice of eigenvalues actually affect the rate of convergence, meaning how quickly the system is stabilized
* And in fact the rate of convergence is dominated by the smallest eigenvalue
* So let's say that I've actually picked a bunch of eigenvalues here
* I've done poll placement, so here are my eigenvalues, my lambdas
* And they happen to be here, here, here, here, and here in the complex plane
* Notice here that here I have a complex conjugate pair
* Well, the eigenvalue that's closest to the imaginary axis is the smallest eigenvalue
* And this eigenvalue Actually dominates the performance, in terms of how quickly the thing converges
* So what you could do, is if you make all your argmin values equal to minus a million, then you have a really, really, really, really fast system
* The problem is that if you make them really, really really fast you get really large control signals which means that any physical actuators going to saturate.So, you don't wanted to go super fast because then your saturated actuators so its that what we need to do is some how play around with these things to balance a low bit aa how fast or how slow you want your systems to be versus what size the control signal should be so let's investigate these few concepts a little bit and we're going to do it in Matlab
* So I've picked some matrixes randomly, these are my system matrixes and then I picked some poles or eigenvalues
* In this case, I've picked a complex conjugate pair, -0.5+-j, which you have to write as 1i in MATLAB
* and then, I run Pole placement
* K=place (A,B,P)
* And then, all I do is I compute the solution
* So instead of me chitchatting about this, why don't we switch over to It's a MATLAB here, and I actually see it happen
* So Here is the same piece of code that you just saw
* this is the eigenvalues
* And if you run this, we see that we have a system that slowly, slowly, decays down to 0, possibly
* But, there are oscillations going on there, right
* Clearly, because I have
* imaginary eigenvalues
* Now, the real parts here, -0.1
* They're determining how quickly the system is converging
* So if I, instead, use this p matrix here
* Same imaginary part
* But a larger negative, real part
* Then I should get a
* Oscillatory response but faster and if I do that we see here what's happening
* This is the new system it's still oscillating but it's quicker getting down to 0 which is what we would expect
* Now let's get rid of the oscillations altogether
* So if I now pick 2 purely
* Real eigenvalues
* And, in fact, the smallest one is negative 0.5
* So that's going to determine how quickly we're moving
* We run this, then, bam
* See here
* No oscillations
* We're decaying down to zero, quite nicely
* But, maybe we're thinking that this is a little bit too slow
* So let's pick some other eigenvalues here
* In fact, negative 5 and negative 4
* This should be dramatically quicker
* And if I do that, bam
* I get this
* Bam, very quickly down to 0, tiny bit of overshoot, And then we're stabilizing
* So this is how we're going to have to play around a little bit with the ion values to get the system performance out that we're interested in
* Next time, we're going to investigate a little bit more
* What exactly was it that broke
* When we couldn't place the eigenvalues the way we wanted.


--- SKIP ---: 03_controllability.en.srt


--- SKIP ---: 03_controllability.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_controllability.en_SENTbySENT.txt
* So, in the previous lecture, we saw that there was something fishy at play here, where sometimes we can do pole-placement and sometimes we cannot
* And what we really have here is, it's a question of the b matrix
* Is the b matrix rich enough, so that we can make the system do whatever we want it to do
* And remember, that the b matrix, really describes the actuators we have
* So, if we're cheap and we don't buy any actuators, I mean there's nothing we can do, of course, we cannot affect the system
* So, the choice of b matrix meaning what actuators we buy will matter and whether or not we have enough control authority revolves around the concept of controlability
* And that is the topic of this lecture
* And in order to sneak up on controlability, I'm going to start with a rather modest example
* Let's do a discrete-time system, we have seen mainly continuous times systems but let's start with discrete-time system here starting a time zero at the origin at 0
* So, what I would like to do is take this system and in n steps, where n is the dimension of, of my state, I'm going to drive it to a target state, x*
* So basically, here's what I want to do, I want to start at the origin
* And then in n steps [SOUND] flow around until I get to where I would like to be
* And the question one can ask then is, can I do that
* Is it possible
* Does there exist such a u
* Well, let's figure it out
* the first thing I do is I pick view at time 0 and x1, it's Ax0+Bu0
* Well, x0 was equal to 0, so this whole thing is simply equal to B times u0
* Well x2, that's A times x1 plus B times u1
* Well, x1 is Bu0, right, so the whole thing becomes ABu0+Bu1
* x3, well if I plug things in, I get A^2Bu0+ABu1+Bu2
* In fact, if I keep going to xn, I get A n-1 Bu0, blah, blah, blah, blah, right
* So, we seem to have a formula, really, for for where we end up
* And, in fact, what we want to do, of course, is make xn equal to this desired point
* And what I can do is I can rewrite this thing, this equation, which is really an equation in the u's in the following form
* I have u n-1 times B
* Well, that's this term
* And then, all the way down to u0B an-1, which is this term right here
* So, what I'm doing is I'm just saying, this is what I would like to solve with respect to my u's
* Well, when can I do that
* Well, first of all, this matrix here, the B AB all the way to A n-1 B, it's a fancy-looking matrix and, in fact, it's an important-looking matrix
* I'm going to call this matrix, gamma
* And gamma is an n by m times n matrix, where n is the dimension of the state and m is the dimension of the input
* Well, this solution, or sorry, this equation x* is gamma times this U u vector has a solution in terms of u's, if and only if the rank of gamma is equal to n
* And rank is the number of linearly independent rows or columns in gamma
* Well, so that's what we want to do, right
* We want to somehow have a gamma that's rich enough
* And it turns out that this thing generalizes, this way of thinking about the control problem, generalizes quite nicely to continuous time systems as well
* So, if I have a continuous time system, x dot is Ax+Bu, x in Rn
* Well, first of all, this system is completely controllable, which we're going to call CC
* If it is possible to go from any initial state to any final state, so, meaning, if I start here and I want to end up here, there is a u that takes me between these 2 points, for any such points, that's what it means for the system to be completely controllable
* And now, I'm going to define gamma again, which is this B AB all the way to A n-1 B
* This is known as the controllability matrix
* And here, ladies and gentlemen, is the first theorem of this entire course
* Controllability theorem or complete controllability theorem 1
* The system is completely controllable
* If and only if the rank, which means the number of linearly independent columns of gamma or rows, it's the same
* if and only if the rank of gamma is equal to n, where n is the dimension of the system
* So, this is the rank test as its known and its a way of checking controllability of a linear time-invariance system
* So, let's see what happens
* Here I have two different systems, 2 0 1 1 x plus 1 1 u is the first one and 0 1 0 0 and 0 1 u, fine, there should be an x here, by the way
* so the lower one is the point mass the upper one was one where we actually saw that pole-placement was not possible
* In fact, pole-placement is possible for the lower system and not possible for the upper system
* This is, in fact, the system used when we couldn't do it
* Well, let's look at them
* First of all, this top system is a two-dimensional system, n=2
* And gamma, in this case, is B AB, all the way A n-1 B
* But n-1=1 so gamma is simply B times AB
* Well, the lower system also istwo- dimensional
* Gamma is equal B times AB
* Well, let's compute AB then
* It turns out to be equal to 2 2 for the upper system and if I apply this into gamma, I get B here and AB here
* So, this is 1, 1 the first column and 2, 2 the second column
* And if I multiply the first column by two, I get the second column
* So, this thing does not have two linearly independent columns
* In fact, it has one linearly independent column
* So, the rank of gamma is equal to one, which means, it's not completely controllable
* Well, looking at the lower system
* Well, this is AB, this is my gamma, 0 1 1 0
* There is no way I can multiply this column by anything to get this column
* So, the lower gamma has rank equal to 2 because that's two linearly independant columns
* So, it is completely controlable
* So here, pole-placement not possible, not completely controllable
* Here, pole-placement possible, not completely controllable
* It seems like we're ready for theorem number 2
* So, if I have u as -Kx, x dot then become A-BKx
* This is the close loop dynamics
* Then, controllability theorem number 2 says that pole-placement to arbitrary eigenvalues is possible if and only if the system is completely controllable
* So, what this tells me is that we need to check controllability
* If we don't have complete controllability, chances are we're not going to be able to control them
* So, this is the obstruction to pole-placement
* And, in fact let's let's see how we would actually compute something like this for real
* So, let's say that I have again, my point, my, my system
* Well, in MatLab, luckily for us, we don't have to compute things at all
* We just say, here is the controllability matrix
* So, gamma or g is controllability of AB, we can check the rank
* In this case, we get the answer out, 2
* So, the rank of g is 2
* n is 2, in this case, so we have indeed, a completely controllable system, which means, again I forgot an x there, I apologize, which means that we can place the poles wherever we want and we all, it also means that it's possible to go between any two points
* So, let's say that I start here and I want to go to x*
* Is it possible to go like this
* Well, I know it's possible to go from x0 to x* but it turns out that just because you can go between any two points, doesn't mean you can follow any trajectory because this system, the point mass, well, x1 here is position, right
* And x2 is velocity
* Well, if I'm here, that means I have a positive velocity and a positive possession
* And now, what I'm going to do if I start moving like this, I'm going backwards, meaning, x1 is reduced with a positive velocity and there is no way I can go backwards with a positive velocity, so this is not possible
* So, what do we need to do
* Well, here I have a positive velocity so I'm going to keep growing but I can reduce the velocity
* And here, I have zero velocity, right
* Down here
* And that negative velocity, I start going backwards
* And [SOUND] I'm going backwards
* And then, I can start going forward again to get to x*
* So, this is how you would have to go from x0 to x*
* So, you can't follow arbitrary trajectories just because the system is completely controllable, but you know that you can go between arbitrary points
* So, that gives us the tools that we really need to understand when we can control the system and that tool is controllability.


--- SKIP ---: 04_segway-robots.en.srt


--- SKIP ---: 04_segway-robots.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_segway-robots.en_SENTbySENT.txt
* So, we now have a general procedure for designing controllers which is pole placement
* And the whole idea there is, we pick our k such that the desired eigenvalues line up
* We also, in the last lecture, learned when it works and when it doesn't and the key characteristic there was controlability or complete controlability
* We can do pole placement when we have complete controlability
* If we don't, we can't
* Simple as that
* And in fact, it's not just pole placement
* If we don't have complete controlability, we can't make the system do what we want meaning, we have to buy a new one, bigger b matrix
* There's nothing else we can do
* Today, in this lecture, I would like to unleash these awesome powers that we have on a complicated robotic system, namely a Segway robot
* And in fact, this is a robot that's balancing on these two wheels, and in fact, here at Georgia Tech, we have a Segway robot, known as the golem crane in Professor Mike Stillman's lab
* And basically, the way a Segway robot works is that it's a unicycle, roughly a unicycle, on top of which there is an inverted pendulum
* And luckily for us, we know how to model unicycles and inverted pendulas
* Now, I'm writing +..
* there because there's a little bit more going on, but basically we're going to be moving while balancing this thing
* so, let's start with the base
* The base is a unicycle, x1 and x2, that's the x and y position of the base
* And it's v cosine psi, where psi is the heading
* And psi dot is still omega
* We've seen this repeatedly
* So, this is the dynamics of the base, almost
* And then, on top of that, we have this inverted pendulum
* And as we've seen, we need phi, which is the angle by which the pendulum is deviating from upright position and we also need the angular velocity to describe what is going on here
* Now, the inputs to a Segway robot are torques, wheel torques
* So, the left wheel torque and the right wheel torque
* And torques translates into forces, or torques and forces translate into accelerations, but here in the unicycle, these are, are old control inputs
* The velocities now, since we have inputs that acts as torques, we need to actually add v dot and omega dot into the equation
* So, v and omega are going to be extra states, that's where the +..
* comes from because, what I have done is I have added v and omega as states to my, my model
* So, what I really have in terms of the state of the system, well, it's the position of the unicycle, the translational velocity, its orientation, the angular velocity, and then phi and phi dot associated with the upright face
* And my inputs are these wheel torques, left and right wheel torques
* And in fact, if I write down the dynamics of this thing
* Well here, I just have the unicycle dynamics
* That's all that I'm saying here, this is unicycle dynamics
* And then, I have all these other derivatives that I need to solve and compute
* And if you sit down and do the math very carefully or you look in a book or something, you got this mess here
* Wooh, this looks kind of horrible
* Well, the first thing we do, of course, when we have something like this is we linearize it
* This looks absolutely miserable
* But if we linearize it, what we end up with is a, an LTI system and, in fact, it's x dot is Ax+Bu, and I should point out that what I've done, is I've linearized this around (x,u)=(0,0), which means that I have zero torques and the position of the robot is at zero
* It's looking at the x direction and the pendulum is looking straight up
* So, I'm linearizing it around 0,0
* And if you do that, you get the following A and B matrices
* Obviously, I'm not going to ask anyone to [LAUGH] memorize this
* I'm just showing you
* This is where the A and B matrices came from
* Now, before we even attempt pole placement, let's make sure that we can indeed do it
* So, the first thing we have to check now for this system is controllability
* And this is too big, right
* So, I'm going to go to MatLab right away and write, here's the controllability matrix of my A and B, here's the rank, and out comes 6
* Does anyone remember what n was in this case
* Well, I do
* n was equal to 7, which means that the rank of the controlability matrix was not equal to 7
* So, this is not a completely controllable system
* And the problem here is the unicycle
* We've already seen that when we linearize the unicycle, the dynamics gets messed up, we can't move in the y direction
* I don't know if you remember that but if you say an x and y is the position of the unicycle, then we had y dot equal to 0
* What that means is we have no way of moving sideways basically
* So, the unicycle is what's making life hard for us here, so what I'm going to do is I'm just going to ignore the unicycle
* Say, that the position and orientation of the base, I don't care about that, but what I care about is, the velocities, how quickly it's moving and how quickly it's turning
* So, I'm going to shave off x, y, or x1, y, x1, x2 and psi from the state space and get a smaller system that has s states, the velocity, translational velocity, angular velocity and these phi and phi dot associated with the pendulum
* If I do that, I get a 4 by 4 system with the following A and B matrices, again, the actual numbers aren't that, that important
* Well, I go to MatLab, I write rank controllability matrix, I get the answer being 4
* In this case, n was equal to 4
* So, if I shave off the unicycle base from my system, I get the completely controllable system
* Now, I can start controlling it
* The last twist though before I do that is, I want my system to actually move
* So, I'm not going to stabilize it to v and omega equal to zero, because that's not what I want
* Instead, I'm going to say, I would like it to go to v desired and omega desired
* So, let's just subtract away v desired and omega desired, and then I have a 0 here because you want to stabilize it to phi and phi dot being zero, meaning, the pendulum being upright
* I'm going to find a new state, x tilde, which is my old state minus this delta which is the thing I would like to stabilize it to
* So, this is my delta
* So, I have a new state
* Well, what's the dynamics of the new state
* Well, delta x tilde dot is x minus delta dot, delta is constant so this is 0 so this is just x dot
* So, it's Ax+Bu
* Well, I can write, I can add a minus delta and add in an A delta at the end because then I have x tilde again here
* so, if I do that, I get a new system and here is the lucky part for us
* A times delta turns out to be equal to zero because of the structure of A so I get this thing going away
* I have x tilde here so my new system dynamics is the same as my old system dynamics
* x tilde dot is Ax tilde plus Bu
* And now, I want to stabilize this system down to the origin, which means that the velocities are actually going to end up being equal to the desired velocities
* So, we have completely control of the system
* We wish to stabilize it
* We do pole placement
* And again, like we talked about last time, it isn't entirely clear how to pick the eigenvalues
* So, I played around with the eigenvalues and this seemed to give a good response
* I didn't want oscillations, so there are no imaginary parts, and I picked lambda 1 minus 19, lambda 2 minus 7.5, and so forth
* This is the smallest eigenvalue, it's going to tell me how quickly, in general, the system responds
* So, with this, I'm going to pick u as -K not x but x tilde, which is the, the new system I'm interested in
* I get my close look dynamics like this
* And, in fact, the way I compute K is to use the, the place command in MatLab
* So, I type in my P and K is place A, B, and P
* So, this stabilizes the Segway robot
* So now, the last thing we have to do is to actually do it
* And the reason why I'm okay with neglecting the unicycle base and only controlling v and omega is that the curvature of the path that's being traced by the Segway robot, actually is omega over v
* So, what I'm really controlling now is the curvature of the path rather than where the actual robot is
* And what I can do in the simulation that I'm about to show you is basically, with buttons, make v bigger or v smaller or omega bigger or omega smaller
* And in essence, what I'm doing when I'm changing v and omega is I'm changing v desired and omega desired
* So, that's the way I'm going to be giving reference signals or commands to the, the unicycle robot
* So, with that, let's move to the actual, actually the simulation of an actual Segway robot
* So now, we're ready to see our developed Segway robot controller in action
* And I'm here with Greg Droge who is a graduate student at Georgia Tech who will be showing us a simulation of the, the Segway robot, so, Greg, what do you have to show us
* Okay
* Here, we have a simulation of the Segway robot
* On the left, we have a 3D implementation of the graphics
* So, you can see that now, I'm able to drive it around changing the velocities
* Just as, just as Dr
* Egerstedt mentioned with the keypad
* and you notice a few interesting things
* Right here in the top right corner you see the plot of the translational velocity
* The red line is the desired velocity and the blue line is the, the actual velocity
* And you see that it converts this very quickly to the inputs that I give it
* And on the middle, you see the rotational velocity and you see because of the eigenvalues that we've chosen, that it actually converges really slowly but it still converges
* And on the bottom you see that they're, the tilt angle will always keep the, the robot stable
* So, I have a question
* Are you simulating this on the linearization or on the full nonlinear model
* So, the simulation is on the full nonlinear model
* Aha, so I actually have a question
* So, linearizations are only valid locally
* do you have any sense for when this breaks
* Meaning, can we make the robot fall over, for instance
* Yeah, so if you give it a really big huge step input of the translational velocity you'll see that in the 3D simulation, it goes in a full circle and it actually hit the ground
* Do, do that again
* That was exciting
* Okay
* Aha, so there, we actually get a feeling for how good or reasonable the linearizations are
* And in this case, it's fairly reasonable, you can drive it around, but if you give it really large desired velocities, it actually falls over
* Correct
* Alright
* Thank you very much, Greg
* Yup
* You're welcome.


--- SKIP ---: 05_observers.en.srt


--- SKIP ---: 05_observers.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_observers.en_SENTbySENT.txt
* So with the last lecture, we are actually declaring success in terms of designing controllers
* The useful placement, which add controllability, and off we go
* the big problem, though, is well, we don't have x
* And we have to, when we do
* u=-Kx
* Well, x is there, but we don't have it
* So, what about y
* Ultimately, we don't have x
* We have y coming out of the system
* And somehow, this Y has to translate into a u
* It's not enough to say x translates into u because we actually don't have, y
* Well here is the, cool idea
* I'm going to put a little magic block here
* And the output of that block, somehow should become x meaning I would like to be able to take y push it through a magic block
* And get the state out
* Now I'm not going to get x exactly, in fact I'm going to put a little hat on top of it
* This is my estimate of a state
* Meaning I'm taking my sensor measurments, y and based on those measurements I'm going to estimate what x is
* And I'm going to call that x hat, in fact the magic block
* The thing that allows to get x from y is called an observer
* So in today's lecture I'm going to be talking about these observers and how do we actually be design them
* Well, it turns out the general idea behind the observer design can be summarized in the predictor-corrector
* Under the predictor corrector banner
* So, let's say that we have, a x is ax
* Forget about u for now, that doesn't matter
* And y is cx
* Well, here is the idea
* The first thing we're going to do, is we're going to make a copy of this system
* And our estimator is going to be this copy
* So I'm going to have x
* is =
* Sorry
* xhat
* is = to Ax hat, so my estimate is going to evolve, according to the same dynamics as my actual state
* And this is known as the predictor, which allows me to predict what my estimate should be doing
* But that's not enough, what I'm going to do now is I'm going to add some kind of notion of a wrong, or right the estimate is to the model
* And one, one thing to note is the actually output is Y, the output I would have had if the state was, was exact is c*x hat * exact
* So I'm going to compare y
* To c*x hat
* And, in fact, what I do, is, I add the piece to my predictor
* So, x
* is ax or hat, + this difference
* y-cx hat
* which tells me how wrong I am
* And then I add some game matrix here, l
* And this
* Gives me a predictor and a corrector
* So, this part here is the predictor, and this part here is the corrector
* And this kind of structure is known as a Luenberger observer named after David Luenberger, but the point is that, when you have this predictor correct repair, you have some way of hopefully figuring out the state, or at least a good estimate of the state, from the measurements, y, that show up here
* So the only question now
* Well, one question is, does it work
* The other question is, what is this L
* So the first thing we should ask is, how do I actually pick a reasonable L
* Well the first thing we'll do
* Is, let's define an estimation error, e, as the actual state - my estimated state
* And I should point out that we don't know e
* Beacuse we don't know x .but we can still write down e as x-x hat
* Well, I would like E to go to 0, right
* 'Cuz, if I can make e go to 0, the x hat goes to x
* Which means that x hat is a good estimate of x
* So what I would like to do is actually stabilize e
* Make e asymptotically stable
* So, what we need to do first, is, write down the dynamics for my error equation
* So e dot well that's x dot-x hat dot
* Well x dot is just Ax and x hat dot
* Well, we have this format the Ax hath+ L(y-Cxhath) and then we get the minus signs in front of everything
* so this is my estimation
* Now y Is equal to c*x, right
* So what I actually have here is e dot being A(x-xhat)-LC(x-xhat)
* But x-xhat is e so e dot is (A-LC)e
* This is the dynamics of the estimation error
* We don't know e but we know that this is the dynamics
* So what we need to do now, of course
* Is pick L in such a way that the eigenvalues to this matrix, A-LC, have negative real parts
* Because if we've done that, we've stabilized the estimation error
* And I wonder, I wonder how we should go about doing that
* Actually, I don't wonder, we know how to do it, pole-placement
* We know how to do control design this looks just like control design but it's actually observier design
* well, we wanted to import the values from (A-LC) to be the negative
* So, let's just pole place away
* Okay
* So here's an example
* x dot equal to this, y is equal to that
* Fine
* Now, I want my error dynamics to be asymptotically stable, so if I write down A-LC
* And I should point out that in this case C is a 1x2, that means that L has to be a 2x1 because these things have to cancel out
* And I get a 2x2 left so L is actually a 2x1 matrix in this case
* So, if I write down what A-LC is, it becomes this semi-annoying matrix but at least we know what this matrix is
* What do we do now
* Well, we compute the characteristic equation to A-LC
* And if we do that, we compute the determinant of lambda i
* So this is the determinant of lambda i
* Minus A-LC
* Right, if we compute that, we get the following expression
* Well, now we do what we always do in these situations
* We pick our favorite eigenvalues
* And it seems like I am very, very fond of lambda equal to negative 1
* If I do that, I get this as the desired
* Characteristic equation
* Well, what do we do now
* Well, we line up coefficients, of course
* These coefficients have to be the same, and these coefficients have to be the same
* And if you actually solve this, I'm not going to go through the algebra
* I encourage you to do it on your own
* You get that L 1 = -2/3
* And L2 is a third
* And if fact, the way this would look my observer gain is well, L1 was -2/3, there is L1
* And L2 was the third which is there
* So my observer dynamics is x dot
* Well, x hat dot is Ax hat plus this is L*Y-CL
* So this is my observer dynamics
* What I'm showing here in the plot in blue, this is x1, the actual x1 and how it's evolving and in red you see my xhat1
* and you see that after a while, they end up on top of each other very nicely
* Similarly, in the right figure, in blue, you have x 2, and in red, you have x hat 2
* And as we can see, the state, the estimated state, x hat, thus, indeed converge 2
* The actual set
* So here is what's going on right now
* I have x as Ax, y is Cx out of this thing I can suck y right
* Because that's what I'm seeing, these are the measurements
* What I'm doing now is I'm feeding this y into my server That has a predictor part, which is the dynamics, plus a corrector part, which looks at the difference between the actual output and what the output would have been if x hat was my state
* And then out of this comes x hat
* Which means that we have some way of figuring out what the state of the system is
* Now, obvious questions are
* Well, well
* There's only 1 question, actually
* Does this work
* And the answer is, no
* It doesn't always work
* Just like pole placement doesn't always work when you're doing control design
* For the same reason pole placement doesn't always work when we do observer design
* And, what we need is we need something that's related to controllability
* So, controllability tells us
* Do we have enough control authority, are actuater is good enough
* Well, for observer design, the concept is known as observability, which means do i have a rich enough y, meaning rich enough sensor suite so that I'm able to figure out what the system is doing
* Meaning estimate, estimate x from y
* And the topic of the next lecture is exactly this observability
* When can we indeed figure out x from y.


--- SKIP ---: 06_observability.en.srt


--- SKIP ---: 06_observability.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_observability.en_SENTbySENT.txt
* So, in the last lecture, we saw that it was possible to recover the state from the outputs using this observer structure
* And the key there was to build an estimate, or a copy of the state, x hat
* And to let the dynamics be given by the predictor part, which is x hat dot this ax hat which is a copy of the original dynamics
* Plus the corrector part, that basically compares the outputs to what the outputs would have been if x hat was indeed the state, and that output would have been C times X hat
* Now, what we have here, is this gain L
* And we saw that designing this L, was just like designing A K, when you're doing control design and, what we really need to do then was just pull placement on the aerodymamics, so if the error, we had e dot now being equal to A minus LC times E, and we just needed to stabilize that system
* But just with to control the sign observer the sign doesn't always work and we saw that we needed some kind of notion related to controlability that works for obsever the sign and that notion is observability So observability is really the topic of today's lecture
* And just ask for controllability, it's easiest to approach this with a rather modest and simple example
* So we're going to deal with a discrete time system where xk + 1 is Axk and the output, yk is Cxk
* And we start somewhere, we have some X0, and the question is, by collecting N different outputs, can we recover the initial condition
* Meaning can we figure out where we started from
* Well, at time 0 the output is simply C times X0, right
* At time 1, the output is C times X1
* Well, X1 is A times X0, so the output at time 1 is CAx0
* And so forth
* So at time, n - 1, the output is CA^n - 1 times X0
* So now I've gathered this little n different measurements, or y's
* And the relationship that we have is this
* It looks very similar to what we had in the controllability case
* And in fact, this matrix here is going to be the new main character in the observability drama
* In fact, this is an important matrix that we're going to call omega
* In fact omega will be called the, observability matrix, as opposed to gamma, which was the controllability matrix
* Now, just as we had in the control problem, we have a similar kind of setup, where we want to be able to basically invert omega to recover Xo from this stack of outputs
* And just as in the controlability case, this is possible when this omega, the observability matrix has full rank
* Meaning that the number of linearly independent rows or columns is the same, is equal to little, little m
* And luckily, for us, just as for controllability, this result generalizes to the case that we're actually interested in
* Which is, the continuous time x is ax, y is Cx
* So, observability, in general
* Means that the system is completely observable, which I'm going to call CO, if it is possible to recover the initial state from the output
* That's basically what it means
* I collect enough outputs, and from there I'm able to tell you where the system started
* And just like for controllability, we have a matrix
* This case it's omega which is the observability matrix and theorem number 1 mirrors exactly theorem number 1 in the controllability case its as, so this is controllability complete observability theorem number 1
* It says the system is completely observable if and only if the rank of omega is equal to little n meaning this observability matrix has full rank
* Now as before, the rank is simply the number of linearly independent number of rows or columns of the matrix only in this case
* Now, we have the second theorem, it follows directly in the same way as it did for control ability
* So, if I have this as my observer dynamics, and then I find the error dynamics where e simply is the actual state minus my state estimate
* Well, what I wanted to do of course, is drive e to 0, that's what I would like
* Well, theorem number two tells me that this is possible, if and only if, using pole-placements to arbitrary eigenvalues
* If and only if, the system is completely observable
* So, we have an exact dual to controlability when we're designing observers
* And in fact, designing observers, or estimating the state, is really the same thing as doing control design
* It just happens that we're stabilizing aerodynamics instead of stabilizing the state
* So this is good news, right, because now we can actually figure out what the state is
* So we are very, very close now to being able to design controllers as if we had x, which we don't, we have y, but we use y to figure out an estimate on x
* So what we're going to do in the next lecture is simply put what we've done on the control design side, and on the observant design side together, in order to be able to actually control liner systems where we don't have the state but all we do have is the out


--- SKIP ---: 07_the-separation-principle.en.srt


--- SKIP ---: 07_the-separation-principle.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_the-separation-principle.en_SENTbySENT.txt
* Now we have lots of really good building blocks
* We haven't yet put them together
* Cause we don't fully know how they fit together, but we have lot's of cool things
* We have controllability, that tells us whether or not it's possible to control the system, if we have access to the state
* And the way we do that is using state feedback
* We have this notion of observability, which tells us whether or not it is possible to, to figure out the state from the output, and the way we do that is
* by building observers and we have this tool that seems remarkably strong which is pole-placement which basically allows us to place the closed loop eigen values where ever we want
* So make them equal to the desired eigen values and the big question now is how do we put everything together
* And the answer is known as the separation principle
* And in a nut shell, the separation principle, which by the way, is quite wonderful tells us that we can actually decouple observer design and control design from each other meaning we can actually control the system as if we have X, even though we don't
* And then we can get their estimate from x using an observer structure
* So this is the topic of today's lecture and it really is the reason why we're able to effectively control linear systems
* So, here's the game plan
* Now, I have x dot is Ax + Bu
* Y is Cx
* So this is a standard linear time and variance system
* Now I'm going to assume that this system is both completely controllable and completely observable
* If it's not then, to be completely frank, we're toast
* What that means, we need to go and buy new sensors, which is fancy speak for get a new C matrix
* Or we need to buy more actuators which means get a better B matrix
* So let's assume that we have complete controllability and complete observability
* Well, the 1st step in our game plan is let's ignore the fact that we don't have X
* So I'm going to design the state feedback controller as if I had X, meaning I'm going to pick U=-Kx, which means that I get my closed loop, my closed loop dynamics to be this
* Now, this is what I designed for and I have my favorite pole placement tool to do this
* Now, in reality, I don't have that
* reality is I have u is -Kx hat, where the hat is my estimated state
* So that's what I actually have even though that's not what I designed for
* Now step two, of course, is I'm going to estimate x using, using an In order to get this x hat and to make it be as pleasant as it can
* The big thing that we should note now is that previously we didn't have a U term in the observer dynamics
* Now we do have a U term that we need to take into account but it turns out that it's very simple to do that
* I built my predicter and the predicter part now
* Contains both Ax hat and a BU term, because a predictor is just a copy of the dynamics
* And then I have my corrector part which is this error between the actual output and what the ouput would have been if I had x hat instead of x
* Well, this structure again gives me the same aerodynamics here
* So what we do is I pick L so that my error, my estimation error is stabilized
* And that's before the error is the actual state minus my estimated state
* So this is my game plan
* Now, let's see if this game plan is any good
* A fact
* It should be good right
* because otherwise I'm wasting everyones time with these slides, but let's make sure that it indeed is worth while
* What do we want, this system to do
* We want to drive x to zero, because we're stabilizing it, and we want to drive e to zero, because we want the estimate to be good
* So, what I need to do, is analyze the joint dynamics together
* So x dot, is ax+bu, but u is, if you remember, u = -k, not x, but x-hat, which is why I get my x dynamics to look like this
* While me e dynamics, that's the matrenary dynamics, is what it has always been
* Okay, let's simplify this a little bit
* So, I know that the error is X minus X hat
* So I can replace this X hat with X minus the error
* So then I get my dynamics after some pushups to be A minus BKX
* Plus BK
* E
* So now I have something that involves X and E and here it only invovles E
* So now I can actually write everything in a joint way
* X dot E dot is this large matrix now that's not an NxN but it's a 2Nx2N*X E
* And mow, our strategy, our joint strategy works if and only if this new joint system is an asymptotically stable system
* Which means that we need to check the eigenvalues of this new system matrix
* Now, here is where the separation principle comes into play
* This is my dynamics
* Now, this matrix here is a rather special matrix
* Because it's triangular
* It has a block there, it has a block there and it has a block there
* And triangular matrices, or block triangular matrices
* May they be upper or lower triangular
* They have a particularly nice structure
* So this is an upper triangle block-matrix and the eigenvalues are given by the diagonal blocks
* Which means that the eiganvalues to this whole matrix are the eiganvalues to this matrix and the eiganvalues to this matrix
* Or another way of writing it is that the characteristic equation is the characteristic equation to the first block here
* Times the characteristic equation to the second block here
* All that this means is that the eigenvalues are given by the values of the diagonal blocks
* And here is the wonderful part
* If we haven't been stupid in how we did the design, then this thing has been stabalized, because we did cold placement to make sure that the real part of our diagonals is strictly negative
* This part we have made sure is also well behaved because we have designed our observer in such a way that real part of the eigenvalue is completely negative
* Which means that we haven't messed anything up
* Everything works
* What that means is
* Control design people, we can design our controllers as if we had the state and than we rely on our clever sensing people to estimate the state for us
* And thanks to the separation principal everything works
* Now the ones that we keep in mind is that we still have this term here, and this term that basically tells you something about what happens to transients
* But after awhile
* This term doesn't really matter and everything works, so now we are ready to state the separation principle
* The separation principle tells us that we can in fact design controllers as if we have x
* And then, we can design the observers independent of the control actions, because all we're doing is, we're adding a + Bu in the observer dynamic, so the control actions are actually just canceled out
* In other words, control and observer designs can be completely separated
* So, if you put everything together, in a final Glorious block diagram
* This is what the world looks like
* We have our system
* This is physics
* This is what a system does
* Now, we have modeled it using A B and C matrices, but what comes out of this thing is Y, meaning our measurements and what we push into this system is U, our control action
* Now, we're taking u, sorry, we're taking y and feeding it into the observer
* So the observer now is, ax-hat + bu + l(y-Cx-hat) and, the one thing to note, is that we need both, y and u to Feed into the observer
* Now, out of the observer comes x-hat, meaning, our estimate of what the system is actually doing
* And now, we use x-hat to feed back, to get are, are u
* And the beautiful thing here is that, these two blocks together, they constitute the controller
* So these two blocks are what's being done in software and this, is the physics of the world
* So this the plant, there's nothing we can do about that and the controller consists now of two pieces
* One piece that, estimates the state and another piece that computes the control action/g
* So now we have everything we need to do effective control design and what we'll do in the next lecture, which is the final lecture, lecture of this module is that we'll actually deploy it
* And in fact, we're going to see it in action on a humanoid robot where we're doing simultaneous control and state estimation.


--- SKIP ---: 08_practical-considerations.en.srt


--- SKIP ---: 08_practical-considerations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_practical-considerations.en_SENTbySENT.txt
* So, last lecture was really satisfying because there, we finally understood how we can do control design using the state and then at the same time, figure out what the state is and everything works
* Thanks to this fantastic principle known, known as the separation principle
* So, what it tells us is that we can completely decouple a control and observer design, and here, I have a rather important little parentheses that says, in theory
* Now, there is a great American thinker that has figured out that this in theory is actually kind of important
* This is Yogi Berra, the baseball player who presumably said, in theory, theory and practice are the same
* In practice, they are not
* Now, this is rather profound and it has some implications on the fact that just because the theory tells us something, we need to be aware of certain things at least
* So, the first thing we need to be aware of is, the controller is really only useful once the estimate, that the estimated state is close to the actual state, meaning, that the controller doesn't really do anything useful until the observer has converged
* So, what we want to do is want to make sure that the observer converges quickly
* What that means is that we want the observer to be faster which in turn means that this eigenvalues that we were picking should be larger for the observer than the controller
* Now, one thing we saw with large eigenvalues though, is that we get large gains
* So, in the control side, this is kind of bad, because that means that we have large actuation signals, which means that we can saturate the actuators
* In the controller side, I'm sorry, the observer side, that's no big deal because the observer is entirely done in software
* There is nothing that's going to saturate, so we can actually make our observer eigenvalues large without having to run into issues like saturation
* So practically, what we need to do is pick the eigenvalues typically in such a way that the controller eigenvalues are all, first of all, they all need to have negative real part, of course
* And then, what we want to do is we want to make the observer eigenvalues bigger because that means that the observer is faster than what the controller is
* So, here is a completely made up eigenvalue selection
* But the important thing here is that the slowest observer eigenvalue, which really dictates how quickly the observer converges, is significantly faster than the slowest controller eigenvalue
* So, that's something that we typically want when we're building our joint observer control design structures
* Okay
* Having said that, let's actually use this to control a humanoid robot
* And this is the Aldebaran Nao that we're going to be working on, and in fact, what we can control on this thing are joint angles, meaning how the different angles are, are moving
* And luckily for us, we actually have detailed models of these joint angles
* In fact, for a given joint, the angular acceleration is 1/J times Ki minus B theta dot
* And these things, well, they are physical things
* So, J is the moment of inertia, i is our input, alright, so i is actually equal to u, here in this case
* This is our input to the system
* This is the current replying at the motor
* Well, K is a torque constant that translates roughly currents into accelerations and then there's always a friction coefficient, the viscous friction coefficient in these motors
* Now, luckily for us when you buy a robot like this, someone has already figured out these physical parameters and there are user manuals that describe what these parameters are
* Now, we need to put this on state base form
* And the first thing we're going to do, as always is say, well x1 is theta and x2 is theta dot, alright
* We're also going to say that what we can match around this thing is the angle itself
* So, y is going to be equal to theta
* Well, with this choice, we get a linear time-invariance system that looks like this
* x dot is 0 1 x 0-b/Jx and then we have this b matrix which is 0K/J times u and y is 1, 0 x is since we're pulling out the, the, orientation
* Now, one nice thing about this system is that it is completely controllable and completely observable
* So, what we have indeed learned in this class should be applicable
* Okay
* So, let's do that
* The last thing we want to do though is we actually don't want to hold or stabilize the Nao into all the angles being zero
* We want to be able to move it around
* So, what we want to do is, we actually would like to track a reference angle
* We would like the, the angle of joints to be something
* So, I'm going to define a new variable e, it stands for error
* It's not the estimation error, it's another error, which is the current angle minus the desired angle
* And then as the second variable tossing in the angular velocity
* And I would like to drive e to zero because if I have e=0, then I have theta equal to theta desired, meaning, I'm holding it at the angle I would like
* And I have theta dot equal to zero, which means I'm actually holding it there
* I'm not moving through it only
* Okay, so this is what we would like to do
* okay, then we need to write down the dynamics for our new variable e
* Well, e dot, well, it's simply, Ax+Bu, because e dot is really, [SOUND] well, it's theta dot minus theta desired dot theta double dot, right
* But this thing is 0 because the, the desired heading is constant, so all we're left with is theta dot, theta double dot, which is the same as x dot, right
* This is the same as x dot so what we do is we plug in the equation for x dot and we get this
* Now, we don't want to express this in terms of x
* We want to express it in terms of e
* And what we get if we plug in e is, we get this expression instead
* Now luckily for us, a times this vector is actually equal to zero
* And I encourage you to compute this so that you trust me
* But having done that, what we get is that e dot is equal to Ae+Bu meaning we have same system dynamics as before but now, defined on this error, where the error is the current orientation or angle of the joint minus the desired angle of the joint
* So, this is the dynamics we're caring about
* Well, we have to do the same thing to the output
* The output is Cx, well again, we replace x with e plus this vector
* So, this is Ce+C times this vector, and remember that C was actually 1,0
* So, if I take 1,0 times that, out comes data desired
* So, my output is C times e plus theta desired
* Now, this doesn't scare us one bit
* We just plug it into our standard controller and observer design methodology
* So, u is -K, not e because we don't know e but e hat, which is our estimate of e
* And e hat dot, well, it has the standard predictor part and it has the corrector part
* And the corrector part is the current output minus what the output would have been
* And the only difference is I have to keep track of this little extra theta desired
* But it's no big deal
* It acts exactly the same way
* So, this is now my control structure
* And instead of me talking about it, why don't we move on to see an actual humanoid robot executing this controlled strategy
* So now, that we have designed a, an observer based state feedback controller for controlling the joint angles of this humanoid robot, the Aldebaran Nao, we're ready to do it for real
* And I'm here with Amy LaViers
* She was a graduate student at Georgia Tech
* And what she has done is made the Nao move its arms and its head, and even its upper body, in such a way that it is executing a friendly wave towards, probably you, who are watching this right now
* And, what's happening is we're running the same controller on all the different joints with different desired angles to get the effect out
* So, Amy, why don't we take the Nao for a little spin there and see what it can do
* So, what's going on here is that we're sequentially running multiple desired angles and that's how we're getting this effect
* In fact, why don't we watch this again because I think this is quite, it's quite charming to be honest
* So, here we go
* Observer-based state feedback controlling action
* Oh, thank you very much, Amy
* And thank you.


--- SKIP ---: 09_glue-lecture-4.en.srt


--- SKIP ---: 09_glue-lecture-4.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_glue-lecture-4.en_SENTbySENT.txt
* Hello, and welcome to Glue Lecture Four
* I'm Smriti Chopra, your instructor for theGlue Lectures, and let's get into it
* So this lecture is titled Controllabilityand Observability, because this week, with Dr
* Egerstedt, youguys learned about what is a system and then more importantly, how do you see if it'sstable, unstable
* And if it's unstable, how do you stabilize it through controls
* But before you can do that, you need tosee if the system is controllable
* And let's say you did stabilize it
* Now you want to see if it's observable,because, you know, you don't have state information, so you needto somehow bring in output, etc
* And then we see how you put everythingtogether
* So in this lecture, we're just going to goover this one big example clearing all theseconcepts for you guys
* Okay
* So let's start with system stability
* Let's say this is my robot, and just anarm is all that we're going to consider, which is your theta 1 and theta 2 to jointhe angles of this arm, two angles
* And I'm going to see that my state is this guy here, which are the angles and theirvelocities
* And my A matrix is this
* This is how my state relates to itsderivatives, right
* This is given to us
* So this is what our system looks like,this guy, by this equation here
* There you go.So now what are we going to do
* We're going to check if the system isstable
* Does it blow up, or as time goes to infinity, or is going to be stable on itsown
* And the way to do that is by checking theeigen values of A, right
* So in Matlab you can simply type eig A, oryou can sit and find out the eigen values yourself.Either way
* Here we just put it in Matlab, and we seethat all eigen values of A are 0
* And we know from our lectures that whenthe eigen values are all 0, that means your systemis unstable
* So we found out that for this system, thisparticular x and A, our guy is unstable
* Okay, so that means we need to introducecontrol, right
* But how do you introduce control
* We know this pretty equation here, x dotequal to Ax plus Bu
* But what does it really mean?What is B
* What is u; u of course, is our controlsignal
* Well, we need to first find out what it isthat we can control about the system, let's saythrough putting motors or through puttingactuators, etc
* So we're going to assume that we cancontrol the acceleration of my first joint angle,theta 1
* And if we do that, then we see that our Bmatrix turns out to be this guy here
* Why
* Because now, when you put B here in thisequation of yours, you'll see that the input u shows up next totheta 1 double dot
* That means you can influence theacceleration of my theta 1 double of my theta 1, right
* That's where my input shows up
* So that's how you generate your B matrix.Now that we have this, great
* But can we, with this particular choice ofB, actually control this guy or not
* That is, do we see if it's controllable ofnot
* And for this we have a very simple test,which is you create this matrix
* This is the controllability matrix, right
* And then you simply check the rank of thismatrix
* So here we going to make this matrix first
* And you guys should be comfortable withfinding matrix multiplications, etc
* Not for maybe such big systems, but forlet's say a two by two matrix, you should be able todo it
* If you want we can really fast go over oneexample
* For example, this is your A, right: 0000,1000, 0000, 0010.And then you've got, I'm going to find AB
* So let's put B here, which is 0100.And now, because my A is a 4 cross 4, and my B is a 4 cross 1, my resulting matrixis going to be a 4 cross 1, right
* And let's multiply quick: 0 times 01000
* So this guy, because there's a one thatlines up at the same place
* We're going to get a 1 here, which is heretoo, right
* And then there are no 1s that line up, soyou get a 0, 0, and 0
* So you see how we got this guy here, which correlates to this vector in thecontrollability matrix
* So you should be able to do AB, A square B, etc, quite easily, for at least 2 cross2 matrices
* And now we're going to check the rank ofthis guy, and it turns out that the rank here is 2
* But we have this condition that the rank needs to be full rank, orthe matrix needs to have full rank in order for it tobe controllable
* That means it should have all linearlyindependent vectors, right
* And what do you mean by full rank
* Basically, your rank should be equal to n,Where n is the number of states that you have
* Here n is 4, right
* So clearly, this guy has rank 2, not equalto 4, and that's why this guy is uncontrollable.And in case you don't want to sit and, you know, compute rank, etc, of all thesethings, you can even do this in Matlab
* And this is the code for it
* You create your A matrix.Create your B matrix
* Then the CTRB function will give you thecontrollability matrix gamma
* And then you just do rank of this guy andpops out 2, which is not equal to 4, we know that, andso it's uncontrollable
* Okay
* All right, perfect
* So now what do we do?It's uncontrollable
* Should we just give up
* No
* We need to introduce more controlssomehow, right
* And then we saw earlier, how do you introduce control
* It's by putting actuators, putting motors,seeing what else you can control
* So here in this case, let's say now we cancontrol theta 1 double dot, and theta 2 double dot, theacceleration of theta 2 as well
* And of course, then what will happen toyour B matrix
* This is how the B matrix will look, right?And to double check again, put it here
* See if, in fact, u shows up for both theta1 double dot, and theta 2 double dot, and then we know that u is influencing theseaccelerations, right
* Okay, so now we have this new guy, and we have to check if this is controllableor not
* And we do the same thing again.We create the controllability matrix
* And we're going to do this in Matlab, because we don't feel likecomputing everything
* And this is the code again for it
* Again, very similar to what we didearlier
* This time your controllability matrix isgoing to be much bigger, because you have twovectors here in B
* So your AB is going to have dimension 4plus 4 times 4 cross 2, which gives you 4 cross 2instead of 4 cross 1
* So each guy here is going to be your, youknow, B, AB, A square B, A cube B
* So you see, now your matrix has expanded
* And anyway, now you find the rank of thisguy in terms of this rank is 4, which is equalto the number of states we have, and so weare full rank, which is great, because thatmeans we are controllable
* Okay, so now that we are controllable, forthis particular system, what does it mean
* It means that I can use u to make myoriginal system, which was x dot equal to Ax, unstableoriginal system, stable, right
* And how do we do that
* We use state feedback
* That is, we say, u is equal to negativeKx
* And now we're going to try and design ourK so that we can force the eigen values to make sure that this system isstable, right
* Okay, let's go over this example, becausefinding K for this huge 4 cross 4 matrix, etc, is reallycumbersome
* We'll just use a simpler system
* Let's shave off one angle completely
* So let's just think of our state as theta1
* And theta 1 double dot, theta 1 dot.So we've just gotten rid of theta 2
* No problem
* So we have this new guy here, but again, now we have to do this entire charadeagain
* First we need to find out, is this guystable or not
* And I'm just going to give you the answer
* You should do it yourself, just toconvince yourself
* But yeah, this guy is unstable
* So I'm going to introduce control throughthis plus Bu thing
* And again, I'm going to say I can controlthe acceleration
* I'm going to get this as my B matrix.And now, is this controllable
* Because that's the second question youask, right
* And I'm going to tell you it'scontrollable
* You guys can find out on your own
* Just make the controllability matrix
* Do it.It's good exercise
* And now I'm going to come back to, okay,state feedback
* We're going to design state feedback, butfor the much simpler system, so we can actually work it out ourselvesinstead of putting it in Matlab
* Okay, with that, so how do we do this
* We know that our system is controllable,and we have this guy, u equal to negative Kx
* So let's put u into this equation of our xdot, and we get this new guy here, right, x dot is equalto this big guy here
* Okay
* So we just put the values inside.A, this is A
* B, your K is this.1 cross 2 matrix, k1 and k2, two gains, and whatyou finally get after solving this entire thing is thisnew guy here, or simply A dash, right
* So you have this new A dash, where you'veput in your control and everything, which isthis matrix here
* And we all know that if you are given asystem x dot equal to Ax, or A dash x, orwhatever, to see if it's stable or not, you checkthe eigen values of A or A dash
* In this case, we have control over k1 andk2, so we're actually going to force the eigen values through our k1 and k2 to B tomake sure that the system is stable
* And if you remember, the eigen value's onecondition is that the, the real part of the eigen value should be inthe left half plane, right
* So we're going to force, through our k1and k2, the eigen values to be in the left half plane of the world
* Okay, with that so how do you find theeigen values
* So in the first slide we pretty much justput it in Matlab and said eig A
* But really, how you do it is, you findthis guy here, the determinant of A dash minus lambda I, which is really, if youfollow it, turns out to be this
* So basically what you're doing is, you're saying A, and then you have, so when you actually solvethe system, you're just going to get minus lambda 1, 1 minus k1, minus k2, minuslambda 2 as your final matrix
* And then you find the determinant of thisguy and solve it, and you'll get this equationright here
* Okay
* Another exercise that you guys should bedoing on your own
* And it's good stuff
* Okay
* So now that we have this characteristicpolynomial, what we're going to do is we're going to pick our two favorite eigenvalues on the left half plane
* And let's say we pick negative 1 andnegative 2
* So now what we're going to do is, this iswhat we got
* And this is what we want, right, which isjust this guy here
* So we are just going to simply comparethese two guys, and get our values for k2 and k1, just bysimple comparison of two polynomials
* Because what happens now is that, withthis particular choice of k2 and k1, my system, with this particularchoice is going to actually be stable
* Just one quick thing
* So yeah, when you put this k2 and k1 here,in this guy, right, in this matrix, now your A dash isdefinitely going to have this eigen value
* This is what it really means
* And because we chose these eigen values tobe in the left half plane, we know that this new systemis going to be stable
* Okay
* So yeah.There you go
* We have state feedback on a simplersystem
* We chose our key, and now we know thatthis guy is stable
* So, woo-hoo
* But now, we come to another annoyingthing, which is that we don't know our state
* We are very happy saying that, oh, youshould be negative Kx, but we don't have this x
* What we instead have is x hat, an estimateof our state
* We don't even have that, but this is whatwe are using really
* And now we need to find this estimate ofour state
* And for that, again, now we have tointroduce this concept of output
* What can we see
* What are our senses
* What can we measure
* That's why the whole y matrix and thewhole thing comes in
* Why
* Because now we say, assume we can see thisguy here
* Theta 1
* So, accordingly, my C matrix is going tobe this, and my y is equal to Cx
* Again, why?Because when you put the C guy inside here, you'll seethat your y becomes simply theta 1, and that's whatwe can see, right
* So we choose what we can see, we choosethe senses we have, and then we create C, and accordingly, getthis y equal to Cx thing
* But now we come to this other whole thingof, is, is this observable
* Is this new system now observable
* The new system being these guys.Is it observable
* Which means, that can I, in fact, estimatemy state, x hat, based on this particular Cmatrix
* And for that, you have a very simple test, very similar to thecontrollability matrix
* This guy is called the observabilitymatrix
* And because we have just two states here,this is going to be a short little matrix
* And you find out what it is which, youguys can
* And then you check the rank of this guy
* This rank is actually equal to 2.Is it full rank or not
* Well it is, because our states, our numberof states are, sorry, 2, right
* Here.So yes
* It is in fact full rank, which means thatthis guy is observable
* Perfect.That is great
* So yay
* But what does it really mean?Again, just to reiterate, what it means is that from lectures, you guys rememberthat you can write the dynamics of your estimate of yourstate in this form
* Where L is just some gain matrix, very similar to your K matrix forcontrollability, right
* And by saying this, what it really meansis that if you were to write down the error dynamics giventhis guy for your state dynamics, you get this matrix here, which looks verysimilar to A minus KB right?For, if you guys remember from your earlier controllability analysis.So very nice
* Why
* Because now we can choose L the same waythat we chose K, to make sure that the eigen values ofthis guy here force the error to become stable, or infact, what that means is basically force that the errordoes not blow up
* It, as time goes to infinity, the erroractually diminishes to 0, and that's what reallyobservability means
* Can you in fact find an L that will makesure that the error goes to 0, which means that my estimatewill become equal to my state
* Okay, perfect
* So for the quiz, it's important you guysshould be familiar at least with what is really going on, what is thedynamics of my estimate, error, etc
* Just be comfortable with understandingwhat it is that's happening
* And now all together, execution, becausethis is the most important part, right
* We have got these little blocks everywhere, controllable, observable,blah, blah, blah
* But we really don't know how to put it all together.And that's what we're going to do now
* So this is our system
* X dot equal to Ax plus Bu, y is equal toCx
* With this particular choice of x, A, B, and C, which we've been solving all thiswhile
* Okay, and then we have found out that xdot equal to Ax on its own is unstable, and then byintroducing B and C, the system is controllable and observable.Great
* Controllable means I can find a K to makesure that my system becomes stable
* Observable means I can find L to make sure that I can in fact estimate my state,right
* So let's put it all together
* So I wake up at this time t equal to tnought where I'm at some x equal to x nought that I don'tknow, because I don't know my state
* But I'm going to estimate my x had to be some xhat nought
* Right
* Just something
* And I'm going to start my loop with DDincrements
* So I started d not, and I'm going to startincrementing time with dd increments
* Okay, and I'm going to read the output
* Because I don't have my state information,all I have is the output, so I'm going to read what myoutput is giving me
* Okay, then using that, I'm going to compute mycontrol, u equal to negative Kx hat, not using the output, using the estimate,the initial estimate that we had
* Simply
* Okay and, remember that you've alreadydesigned K and L
* Okay, so you compute your output, sorry,compute your control, and then you send this control signal toyour system, right
* And then you update x hat using yourdynamics, where x hat was this guy here
* And this is where you use your output,what output you read
* Right
* Because for control you need x hat, so nowobviously you need to see where is your new x hat, and that you'regoing to update through this guy here
* And just remember, when you're updatingyour dynamics, all I have here is x hat dot
* How do I find out what my x hat should bethe next time instant, you know what, you're going to use this Oiler'sapproximation, which we all studied together in the Glue LectureOne, I think
* And of course you've been going over it with Dr
* Egerstedt
* Basically, your next step is your previousstep, plus dt times your dynamics
* Right?So that's what we're going to do
* We're going to find out x hat dot, andthen we're going to just say our next guy is our previous guy, which was thisestimate here, plus dt times x hat dot
* And that'll give us our new guy
* And now we're going to repeat
* So now when we come back, we can read the output again, compute the new controls andthe control update x hat, etc
* This is how we put all of this stuff together, for execution, in yourcode, etc, whatever
* Okay, and with that, check the forums,good luck with Quiz Four
* All the best.


--- SKIP ---: 10_programming-simulation-lecture-4.en.srt


--- SKIP ---: 10_programming-simulation-lecture-4.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_programming-simulation-lecture-4.en_SENTbySENT.txt
* Welcome back.This is week four
* So we're halfway through the programmingand simulation lectures as well as theassignments
* So congratulations on making it this far
* Last week I talked about goal to goalcontrollers which allowed our robots to drive from their current location to some location in theenvironment
* And this week I'm going to talk about
* How to create an obstacle avoidancecontroller
* And this obstacle avoidance controller,the point of it is that we want to be able to drive around the environment without colliding with any of theobstacles
* So if you're driving a robot in yourliving room you don't want it to drive into your sofa andget destroyed
* So this week we're going to take care ofthat
* And there are actually many ways of doingobstacle avoidance
* And I've picked out one particular way ofdoing obstacle avoidance
* And this is how we do it
* First, we're going to interpret the IR distance as a point in the coordinateframe of the sensor and transform this point into thecoordinate frame of the robot
* Then we're going to take this point that's in the robots coordinate frame, andtransform it once again into the world coordinate frame, sothat we know where each obstacle is in theworld
* What we will do then is compute a vectorfrom these points to the robot, and we will use that as an, andsum them together as an obstacle avoidance vector
* And then what we will do is the same thingas last week is we're going to use this vector And use a PID controllerto steer the robot towards the orientation ofthe vector
* And effectively what will happen is thatthe robot will drive in the direction that points away from anyobstacles that are nearby
* And thus will avoid collisions.So I've mentioned coordinate frame at least four or five times on this slide.What do I mean by that
* We use coordinate frames to give meaningto points in some sort of space
* So when I tell you that the robot islocated at xy theta, you need to know whichcoordinate frame I'm talking about
* So, in most cases I'm talking about theworld frame
* And this world frame is centered at theorigin, which I'm going to denote as just zero,zero
* So I pick this, where this is in thesimulator
* And with respect to this world frame, thelocation of the robot is given by X and Y
* And of course, also with respect to thisworld frame, we have an orientation of theta, ofit
* So, the, the robot, right here has anorientation given by theta, and it's important that this theta is defined with,with respect to the X axis of this world frame
* Now, the next coordinate frame that wehave is the robot's coordinate frame, and this coordinateframe is located right at the robot
* So wherever the robot is, at the center ofthis robot, there's a cornered frame and it's, this, this wecall the robot frame
* So, with respect to the robot, thisdirection right here going out in front of the robot, which aligns with therobot's orientation is, would be theta, what it's maybe called theta prime isequal to zero, in that robot's frame
* But, theta prime in the world frame, somaybe I'll call this theta prime w f, would be equal to the actualtheta of the robot
* Now, the reason that we care about the robot'sframe of reference, is because we only know the location of the sensors andthe orientation of the sensors; with respect to the robot, robot frame.So the robot knows for example, that it has one particular sensor, mounted righthere which is, sensor number one
* And this sensor, it knows is, is locatedat, at this point with respect to its own robot's coordinateframe, and its orientation along in this direction.And this orientation, with respect to the robot, is 90 degrees.But in the world frame, this orientation would be also a functionof the actual orientation of the robot
* So, let's call this maybe theta S prime
* So we said that was 90 degrees, which isthe same thing as pi over 2.And what we want to do is, to figure out where the sensoris, so theta prime S, in the world frame this would be not,nothing more than, pi divided by 2 plus the orientation of therobot
* So this would give you the angle of thissensor in the world frame
* Now, the way that I've denoted this in, inthe manual is, using
* Sorry, I'm going to color this out.Is using, X sub S four
* So this is the x position of sensor fourin the robot's frame
* The y position of sensor four in the, inthe robot's frame and the orientation of sensor four in the, in the robot's frame,so in this case, theta s four is actually, so this is equivalent to minus 45 degrees
* because that's the orientation of thesensor with respect to the robot
* Now, we can go even one step further thanthis
* What we can define is, a coordinate frame,with respect to the sensor itself
* So each sensor has its own coordinateframe
* So we're getting fairly deep in here, but, the point of that isthat when we defy it for example here this sensor i's frame and in this case it's sensor you know, it's actuallysensor four
* And again the origin of this coordinate frame is located where the sensor islocated
* And the x axis of that coordinate frame aligns with the orientation of thatsensor
* And this is important because what we're going to do, is we're going tofigure out that the distance that we're measuring is actually nothingmore than a point in this coordinate system
* So, here, what I've done is, the robot measures a distance of, so this distanceright here is D 4 and all I've done is I said well inthis, particular coordinate frame, this pointright here is equal to this vector right here
* So D 4 0 so because we're going a distanceof D 4, the X direction the distance is 0 and the Y direction in that particularcoordinate frame
* Now, what we really care about in this,in, in, in the controller is, well if I have thispoint in this sensor's coordinate frame, what doesthis point correspond to in the world frame
* Because, as you can imagine, if I forexample have a, a point up here that is on an obstacle, I can saythat the obstacle is at this location in the world, and I knowwhere the robot is and from that we can make an informed decisionabout how to move the robot
* And that's exactly what we'll do
* So, in order for you to be able tocalculate the transformation between the different coordinate frames, you'regoing to need to know how to rotate and translate in 2D
* And what I mean by that is that if we havea coordinate frame, so say, this is my coordinate frame righthere, and I have this point
* Right here, so I have a point right here,lets call that 1,0
* Now this I can also, I can pretend thatthis point is a vector going from the origin to this pointand suppose what I wanted to do, is rotate this vectorand then translate it
* And let's say that I want to rotate it andI'm going to use this notation: r, and I'm going tosay, translated by one unit in the x direction, two units in the y direction and pi over four is thetranslation
* So what does this R actually mean
* Well, the R is given by thistransformation matrix
* And what this transformation matrix is,does, is exactly what I just described
* It's going to take a vector and, when youpre-multiply this vector by R you're going to get the,the, the vector transformed in space by x and y, translated by x and y and thenrotated by this theta prime right here
* So we're actually translating by x prime yprime according to my notation here
* So going back to my example
* What, what really, what's really going onis that first, we're going to rotate thevector by, Pi over 4, which means that it's now located at, squared of 2over 2, squared 2 over 2
* And then we're going add a translation in the x direction and then a translation inthe y direction of one unit and two units
* Which means that, the vector that I get, corresponds to 1 plus squared of 2 over 2and 2 plus squared of 2 over 2
* So what I've effectively done here is I'vetaken this point, 1,0 and I have translate, rotated and translatedit to this point up here, which is 1, 1 plus square root of 2 over 2.2 plus square root of 2 over 2
* And that's how the rotation andtranslation works, and so, so whether it's a point or vector doesn'treally matter
* The point really is that I've gone throughthis, this transformation, I've gotten a, atranslation and a rotation
* And to be a little bit more specific, whatI've really done is so, on this side I would have so,so here this, this should have been R,1 comma 2comma pi over 4
* And, what I'm multiplying, the vector thatI'm multiplying with, what you'll notice is that this is first of all a 3 by3 matrix, so we want to make sure that thisis going to be a 3 by 1 matrix for this to be a validmultiplication
* And what we're going to do is we're going to put the point that we'retranslating, so let's call this xy, so this is x, which would've been, which was equalto 1, y equal to 0
* And then we're always going to place tomake, going to place a 1 right here
* So, this stays a 1 independent of what xand y are
* So, why am I telling you about this
* Well, you need this tool, you need thistransformation matrix in order to do our transformationfrom the point in the centers, reference framed allthe way back to the world, uh,to the worldcoordinate frame
* And this is the entire calculation thatyou're going to be doing
* As you can see here what I've done is Ihave, the point d sub i 0
* So this is the distance that was measuredby sensor i
* Then, I'm doing the transformation fromthe sensor frame to the robot frame and my input into therotation and translation matrix is the position of the,and position and orientation of the sensor on the robot, inthe robot's frame
* So now this entire thing gives us this point in the robot's reference frame, instead of the sensor's referenceframe
* So, we have to do another rotationrotation and translation
* And we do that by using the robot'slocation location and orientation in the in the, inthe world frame
* When we do that, this entire thing, righthere will, point, give us the point, this originalpoint right here, in the world frame
* And this is exactly what this is
* So these are the world frame coordinatesof this, of this point detected by this particularinfrared sensor i, now, let's get to the code.Now that we're armed with this tool
* First of all, we're going to create, or we've already created a new file for thiscontroller
* It's going to be it's own file, so it's it's own controller, it's going to becalled AvoidObstacles.m
* And like this comment says, AvoidObstaclesis really for steering the robot away from anynearby obstacles
* And really, the way to think about it, is we're going to steer it towardsfree space
* And, first of all, all thesetransformations are going to happen inside of this functioncalled apply_sensor_geometry
* We're going to do all three parts in therebefore we even get to the PID part of the, of thecontroller
* And the first part is to apply thetransformation, from the sensor, sensor's, coordinateframe to the robot frame
* And really, what I'm doing here is I'm em, already giving you the location of thesensor, of each sensor eye in the robot'scoordinate frame
* And that what I, what I what i want you to do is first properly implement the gettransformation matrix
* According to the equation that I gave on,on previous slide, previous slides
* And once you've done that properly, ofcourse, you're going to have to input these here
* And then you have to figure out the propermultiplication and again, you should look back at whatI've done before
* But remember, we're only doing one step,so really what you should be doing is, R, xs, ys, theta S multiplied by di, 0, and 1.So this is what I expect you to implement, righthere
* Then, we're going to do the next part,which is transforming from the, the point from the robot's coordinateframe over to the world coordinate frame
* So, this follows a si, the, a similar pattern as what we did in the previousslide
* Again, what you want to make sure is thatthis becomes the input for this
* You've already implemented gettransformation matrix so it's spits out the appropriate R, and then you're going toagain have to do the calculation
* So you pick the previous vector, so I'mjust going to represent that by scribbles and multiply that by r,x, y, theta
* And that should give me all of the IRdistances, all, all the points that correspond to the IRsensors in the world frame
* And now we know where, where obstacles arein the world or free space in the world, depending on whether you'repicking up an obstacle or you're not picking up anobstacle
* Now, so like I said, we've computed the world frame coordinates of all of thesepoints
* So each one of these points right here in green, we know where they're located inthe world, right
* So, what we can do, is we can compute vectors from the robots to each one ofthese points
* And then what we can do, is since they'reall vectors we can just sum them up
* And we can sum them up and we get thislarge vector that's point, that is going to end uppointing away from any obstacles
* And the reason for that is that thesesensors so for example
* This sensor right here, that is detectingno obstacles or the distance is really great, is going to contribute muchmore than this sensor which is picking up an obstacle close by
* So when you sum up all these sensors, themain contribution is going to be along a direction which is,away from the obstacle
* And then once we've done that, we can usethe orientation of this vector and use PID control much like we did in the doog,google controller to steer the robot in to the direction of the free space.So here is the code, in the main execute function of the avoidobstacles controller
* One thing I would like for you to pay attention to is that I have created thissensor gains, and I ask you in the manual to think about how do you want to structure thesesensor gains
* Do you want all of the sensors to countequally, do we contribute with equally, do you maybe care about a particular sensor more
* So for example do you care about the one that's in the front and that's the thirdsensor
* So maybe this should be 3, so that you paymore attention more to the obstacles that arein front of you
* Do you or do you want to pay moreattention to obstacles that are on the side in that case you would maybe increase these two,so sensor one and five, that go to the left and to the, to the right of the robot
* So, play around with that and you shouldget some interesting results
* And again, here I'm going to, here I'masking you to properly calculate each of the UIs, so each one ofthe vectors
* And then, we're just going to sum themtogether and then you're going to have to figure out the angle of thisvector, so you get theta ao
* And then, just like last weekend, the goalto goal controllers, so you're alreadyfamiliar with that, you need to compute the error between, this anglethat you want to steer to, and the actual angle of therobot
* Now, to test this we're just going toimplement this controller and run it on the robot so let's see whathappens
* I mean, obviously we're, we hope that therobot's not going to collide with any of the walls or any of the obstaclesthat I've added to the environment
* But let's make sure this actually happens
* I've already implemented the controller,so I'm going to head eh, go ahead and launch thesimulator
* I'm going to hit Play, and we're going tofollow this robot and see
* So I clicked on it to follow it, and we'regoing to see what, what it does
* It's already turned away from the, fromthe obstacle
* Now there is a wall and phew, we made it and here's another wall and yetagain, the robot turns away
* And since I've implemented this controllercorrectly, the robot should just drive around aimlesslyaround this environment
* We haven't told him where he needs to go,we just have told him that he needs to avoidany obstacles
* And, in fact, next week, we'll talk abouthow to combine goal to goal controllers andavoid obstacle controllers
* My tips for this week are again to referto the section for Week 4 in the manual formore details
* And I have always provided very detailedinstructions that should help you get through theseassignments
* And also keep in mind that, even though this seems like a really difficultapproach and really tedious, and you could probably think of,of a way easier ways of doing obstacleavoidance with robots
* The reason that I've done it in a waywhere we end up with a vector is that it'll makeit a lot easier next week, when we combine the goal to goal controllers and the obstacle onecontrollers
* Because then it's a matter of justblending two vectors together, we know definitely know how tosum vectors together so
* Stick with it and I'll see you next week.


--- SKIP ---: 01_switches-everywhere.en.srt


--- SKIP ---: 01_switches-everywhere.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_switches-everywhere.en_SENTbySENT.txt
* So welcome to Module 5 of the course, Control of Mobile Robots
* So far the first 2 modules were kind of introductions to the topic and the previous 2 modules they went rather deeply into the issue of, control the sign for linear time in variant systems
* And we ended the last module on a high note
* Which showed that we could do rather remarkable things, like make a humanoid robot wave in, exciting ways
* Using, control of linear time in variant systems
* Now, unfortunately, the world isn't that easy
* And especially, the robotic world is not that easy
* So this entire module is devoted to how do we take Module 4
* And make it cope with the realities of the world in which robots are embedded
* Then in Module 6, we're actually going to go full force robotics, 100%
* And this module can be thought of as the glue module between linear systems and actual robotics
* And in fact, the title of this lecture is, Switches Everywhere, because so far the modules, or models have been the same all the time, and in fact, because the models are the same, we design a size fits all type of controller
* the way we've kind of messed with the controllers, is by changing the, the, reference values to some desired angles for the...
* this humanoid robot, or desired velocities and angular velocities for the segue robot
* But, it's certainly not always true that the models never change in the real world
* And, this is never true in robotics, unfortunately
* In fact, if you recall, what we talked about in module 2
* We talked about something called behavior based control
* Where the robot switches between different modes of operation, or behaviors, in response to what the world throws at you
* You see an obstacle, you switch to avoid that obstacle
* If you, need to go recharge you switch to a, let's look for outlets behavior
* So what we need to do is somehow come to grips, or terms with this reality
* And that is how we're going to start this module
* The first thing to note is that in the world there are switches everywhere
* So here, over on our left, is a bipedal walking robot
* Well, bipedal walking robots have a leg that's swinging, has one dynamics, and then bam, the ro, the leg is on the ground, now the dynamics changed
* So because of the fact that the dynamics changes
* Depending on whether or not you're in the swing face, or the stance face
* The dynamics is different
* Here, I drew a cartoon of a bouncing ball
* Well, it has 2 modes
* It's in the air, [SOUND]
* And then it bounces
* Something new happens
* The b-, the ball gets squished, and then it releases again
* So, there
* We have switches
* I actually included this wonderful picture of locusts because I have actually worked on locusts
* These locusts don't bother anyone during what's called a solitary mode
* And then something happens and they switch to a gregarious mode where they lump together and devastate harvests everywhere
* and this is a transition that occurs because of a lack of food, for instance
* But in the, all of these cases, these are naturally occurring switches that our models have to take into account
* Now, from a robotics point of view, it may be slightly more relevant to look at switches by design instead of doing it by necessity
* So here is a gear box to a car
* We're switching between different gears because we want the car to run more smoothly at different RPM's
* so we're switching the dynamics not because we have to but because it's better
* Here, this is a, a cockpit
* It's supposed to be representing an autopilot on an aircraft where you're switching between cruise climb turn land takeoff modes
* So, instead of designing 1 controller that takes me from Atlanta, Georgia to Stockholm, Sweden
* You have a bunch of different controllers that you're switching through in order to do this
* And at the bottom here, we have a sensor network
* Where, in order to preserve power, you're turning sensors on and off on purpose
* So, you're switching by design, rather by necessity
* And, in robotics
* Everywhere it switches by design
* This is our south driving Georgia Tech car that switches between different behaviors depending on what's happening in the world
* Here's a mobile robot that switches between behaviors depending or not, whether or not there are obstacles, I wish we worked on snake robotics
* We're switching between different modes, depending on what is going on in the environment
* This is a friend in now, this is the sensor network, and this is the aerial robot that we've seen, and we're going to see more of
* In all of these cases, we're going to have to switch in order to respond to what the world throw's our way
* Now, there are some issues that we need to deal with
* Issue number one is really how do we model these switches
* How do we model systems that aren't staying the same all the time
* Well, the other question then, of course, is if these models change, what about stability
* What about the performance
* Can we go with our old methods to try to understand this
* Well, this all boils down to the fact, that T does not go to infinity, within a single mode
* Meaning you are not staying in 1 mode forever, and stability is defined what happens when T goes to infinity, but T does not go to infinity in the in, individual mode
* So, we somewhat need to understand that
* We also have issues of compositionality
* This is fancy speak for saying, if I have multiple modes and multiple controllers, how do I put them together
* What is the way in which they fit together like Lego pieces in a big Lego drawing
* And, most importantly, are there traps
* Are there issues that arise because of these switches that we don't fully know how to deal with
* Now, this module will deal with all of this, and more
* And in the next lecture, we're going to start with the first question which is, how do we really model hybrid or switched systems in a systematic and coherent way?


--- SKIP ---: 02_hybrid-automata.en.srt


--- SKIP ---: 02_hybrid-automata.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_hybrid-automata.en_SENTbySENT.txt
* So in the previous lecture, we saw that switches show up very naturally, especially in robotics where we're going to switch between different modes of operation
* And what I want to do today is talk a little bit about the models that we're going to use to describe these phenomena
* And the models that we're going to use are called Hybrid Automata
* And these are models that contain both the continuous dynamics
* Meaning to x dot part and the discrete switching logic that says oh, if you see an obstacle you should switch to an obstacle avoidance behavior, or something like that
* Now, what this means is that the discrete logic will be modeled as a finite state machine that moves between different discrete states, so that's the discrete logic
* But just a finite state machine on static steroids in the sense that inside each state we have a continuous dynamics loraking so
* Having said that, what we need first of all is the notion of a state
* So x, as before, is the continuous state of the system
* This is the physical state typically of what a robot is doing
* But then what we're going to do is we're going to add a discrete state that I'm going to call q
* And q is going to tell me which different continuous mode I am in
* So my dynamics now can be encoded not As xdot=f(x,u) but xdot=fsubq(x,u)
* Where this q now tells me which mode am I actually in
* And what we're going to do is transition between different discrete modes in a state machine where here I'm having mode q
* So really, xdot inside that mode
* Is going to, be fsubq and xdot inside this mode is going to be xdot is, fsubq prime
* Now, these are called transitions right, so when you jump in between different discrete modes you're making transitions between different states in the finite state machine
* Now what we need to understand is, when do we actually make these Jumps, well for that we need something called a guard and the guard is something that checks whether or not you should jump
* And then we're also, [COUGH], excuse me, also going to add something else which is called a reset which is going to tell you not when you jump but where you end up after you made the transition
* So the guard condition is a condition that tells you when it is time to jump
* So let's say that I am in mode q and I want to jump to mode q prime
* Well, what I have, is I have a guard that says, if
* x belongs to this guard, let's say that this is, I'm going to switch from one gear to another gear if my rpm is above 3,000 then I'm going to switch
* This is a guard condition that encodes when it is time to jump
* Now, when I'm jumping I may actually reset the value of my state
* For instance, if I'm dropping a ball, whoop, onto this desk, and it bounces up, it loses energy in, in the bounce so what we're doing is we're subtracting a piece away from the state
* At each bounce
* This way of messing with the state at the moment the transitions occur is called a reset
* So, if I am going, I'm here in mode q
* [SOUND]
* And then my guard is true, so I am moving to q prime
* Well, what's happening here is that x changes for instance, x is now lets say, the old x/5
* That would be a guard that says, oh I'm getting only a fifth of the energy somehow after this jump
* So, what we need are dynamics, individual dynamics which are called modes
* We need transitions which tell us, tells us which discrete states are we moving in between
* We need guards which tell us When we're going to make these jumps and we're, need resets to tell us how these jumps end up effecting the state
* So if we put all of this together, we get a rather arguably messy looking thing
* But it's very rich
* This is the hybrid automaton
* Singular, or hybrid automata, plural model
* And the way this works is, let's see here, we start with x equal to x not, we end up in this mode, which is q=1, where we are evolving according to this differential equation
* Right
* Okay, if in this case, x belongs to G12, then x, we're going to move, over into this mode
* And on our way
* We're going to reset the state
* Now the state is here
* This is my dynamics
* I'm in q2 mode
* Well if, G21 becomes true, I jump this way
* But if G23 becomes true, I jump that way
* So let's say G23 became true, I jump this way
* I change my state, possibly according to this reset map
* I have a third dynamics, q=3
* And then when x enters G31 guard, it jumps back into q=1, with a new possible reset
* So this is the general model that we're going to work with
* Now, it looks a little bit messy, but it's actually really not
* In most cases, these models are going to look rather, innocent
* So, here's for example, a very very simple Hybrid system
* it's a thermostat, or it's my idea of a thermostat
* Typically, the way a thermostat works, at least cheap ones, is you set some temperature you would like
* The thermostat is on the heater is on until you reach that temperature, or typically, go a little bit above it
* And then, it turns off, and then you cool down, and then, when you're too low, you turn it on again
* And you've heard this all
* In buildings with, with heaters, or that turn on and off
* So, what we're doing is, we're heating it up until we're comfortable and warm
* And in fact, this is my desired temperature and you typically want to add a little slack that says that I'm going to, shut this thing off when I'm at, whatever I want to be 70 degrees
* Plus a little slack, let's say
* By the way, this is 70 degrees Fahrenheit
* For you Celsius people out there, let's say it's 20
* so now, we're above 20 Celsius, and now we're going to cool it down
* And then we're cooling it down until we're,in this case, below, well, 20 degrees Celsius, or whatever it is in Fahrenheit, - epsilon
* And the reason why we need this epsilon is
* If we didn't have it, then this guard is true
* And this is guard is immediately true
* 'Cuz if t is = to t desired, we're just going to start spinning around indefinitely here
* So, the little epsilons are important
* So, this would be 1 way
* In which we will model a thermostat
* There are no resets here just current conditions because we're not magically making the temperature jump just because we're changing the heaters from, from on to off
* Well, here's a gear shifter, right Well, we have some dynamics
* v is the velocity of the car
* We're now in first gear
* This is our dynamics
* u is our smashing the break of the gas pedal down
* So this is how we are driving
* When we have the RPM above some threshold then we change gears
* We switch up to second gear which is here, right
* So now we are having the second gear
* If we keep pressing the gas
* So that the RPM goes up beyond, beyond some c2, then we switch to third gear
* Apparently this car only has three gears
* but, we go to the third gear, and the same thing here with a downshift
* And note this here that I have c2 prime and c1 prime
* And c1 and c2 here
* This is again, because you want to build in a little bit of slack
* This is my way of hiding an epsilon inside there so we don't immediately transition between, between gears
* So this would be a hybrid atomaton gear shifter
* And I'm not writing out these dynamics
* Because the particulars aren't that important right now
* The important thing is, the switching logic and the way the guards operate
* Well finally, let's look at the behavior-based robotics system
* What I'm doing is I'm running the robot
* So let's say at x is the position of the robot
* According to a go to goal behavior
* So f go to goal of x
* This is me having to assign that
* When the distance between where I am and where the closest obstacle is when that's less than some sum d, meaning I'm too close to an obstacle, then I'm going to switch to another mode or another behavior which is Avoid obstacles
* So now I have decide my avoid obstacle behavior and it's safely taking me away from the obstacle and then when the position of the robot is greater than some other distance, the prime away from the obstacle then I switched to goal to goal again
* And the way this would look is, let's say here's the obstacle
* Here's the goal
* Here's my robot
* [SOUND]
* My robot is doing fine
* Here's the ball of radius d
* Once I get in here, I'm going to switch to a goal to goal behavior
* That's going to take me away from the robot
* Let's say here is a larger circle of radius d prime and when I'm here, I'm going to be safe and I'm going to switch to goal to goal behavior
* So this is what would happen in practice if you ran this hybrid atomaton as a behavior based robotic system
* Now, unfortunately, things aren't all rosy in the hybrid world
* And what we'll see in the next lecture is that things may actually go wrong even the we are meaning very well when we start building our systems
* So the next lecture is a Danger:Beware sign that we need to put up whenever we are designing hybrid systems, as opposed to standard standalone linear time and variant systems.


--- SKIP ---: 03_a-counter-example.en.srt


--- SKIP ---: 03_a-counter-example.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_a-counter-example.en_SENTbySENT.txt
* What we saw in the previous lecture was how to model switch systems in a rather general way using these things called hybrid automaton
* today, I want to show that just because we know how to design good linear time invariant controllers and we know how to draw a hybrid automaton, doesn't mean that we can just say, [SOUND] we're done, we can do everything we want to be able to do
* In fact, what I want to do today is talk to you about a rather famous counter example that makes thinngs hard when you're in the hybrid world
* So, I'm going to answer the following question, what can possibly go wrong when you start switching between different controllers
* And this tangle of yarn here is supposed to illustrate what can happen when you start switching and messing things up together in, in rather surprising manners
* Well, lets let's start rather modestly
* Let's say that I have two modes
* I have x dot is equal to A1x and x dot is equal to A2x and this A1 and A2 matrices they look rather innocent, if you ask me
* Some small negative value on the diagonals, same small diagonal negative values, their epsilons is positive
* And then, on the off-diagonals, you have one and negative two here, and two and negative one there
* Well, well let's check the eigen values, that's the first thing we should always do
* Well, it turns out that no matter which system you have, both A1 and A2, the eigenvalues are both -epsilon plus -1.41j
* Well, what does this mean
* Well, the real part is equal to -epsilon, which is strictly negative, so both systems are asymptotically stable, meaning that x will die down to the origin
* And both of them have a nonzero imaginary component, which means that you're going to have oscillations, alright
* So, we have asymptotically stable systems with oscillations
* And, in fact, let's see what happens when we start combining these different modes
* Before we do that though, let's actually look at the modes a little bit more carefully by themselves
* So, here is mode 1, x dot is A1x and what I've plot that here on this axis is x1 and what I've plot that here is x2
* What this would look like if I have time here and let's say, x1, is I would gets decaying oscillations
* Well, we don't have that now because I plotted x1 and x2
* And this is where I start, in this case, I guess, I started at 1,1 and the system starts flowing
* And because epsilon is small, you're going to get closer and closer to zero but slowly
* And you're going to spiral in like this
* And, you know, t goes to infinity
* You're going to end up at the origin because you have indeed an asymptotically stable system
* So, A1 is well-behaved
* It spirals a little bit but what do we care
* We're not afraid of spirals
* Here's A2
* It also looks like a spiral but instead of a tall and skinny spiral, it's a short and chunky spiral
* Again, we start at 1,1
* And this system starts spiraling and it goes inwards and then, [SOUND] it goes like this so it's also asymptotically stable as it should but because of the particular eigenvectors of these two systems, we end up spiraling in slightly different ways
* But the point is we have two stable systems
* Now, let's put them together in a hybrid automaton
* So, this is hybrid automaton number 1
* I'm going to spiral, tall, and skinny, until [0 1]x=0
* this means that the second component, so x2=0 is what this guard means, right
* And when x2=0, I switch to my short and chunky ellipsoid or inward spiraling system
* And then, when x1=0, I switch back
* So, this is my first hybrid automaton
* Well, let's see what that actually looks like if you do it
* So, as always
* we start at 1,1
* I start in mode 1 [SOUND] until this point, right, where x2=0, then I switch to mode 2 which as the short and chunky ellipsoid
* Here, x1 becomes 0 and now I switch to mode 1 again so we have 1,2,1
* Now, we switch to mode 2, to mode, mode 1, and so forth
* And as we keep doing that, we spiral in, and one thing that you're going to notice then is that we're actually ending up at the origin at a much faster rate
* So, this system is not just asymptotically stable, it's asymptotically stabler, which is not a word, by the way than the original systems, because it actually converges at a faster rate
* So, by switching, we were able to get to the origin faster, which makes you wonder, why am I calling this a counter example
* Well, this is not a counter example
* But aha, hybrid automaton number 2, maybe that is the counter example
* It's the same as hybrid automoton number 1, but I switched the guard conditions
* So I'm switching from mode 1 to mode 2, when x1=0 and I'm switching from mode 2 to mode 1, when x2=0
* This seems like a modest enough modification if you ask me, but modesty in all modesty, it turns out that that is a huge deal
* Now, 1,1 is hiding somewhere here and what's happening is that we're now starting to spiral out
* So now, here we have, for instance, that x1 became zero
* Now, we're switching to the, the fat spiral
* Here, x1 becomes 0 and we're switching to the skinny spiral
* And in this way, we're going to end up getting further and further out
* And this is indeed an unstable system and this is a little bothering to us because I took two stable systems and I put them together in a hybrid system, and I got instabilities
* So the punchlines here is, first of all, stable modes by themselves, that's not enough to guarantee that the resulting switch to hybrid systems is stable
* In fact, you may induce instabilities through switches
* And that's a little bit of a downer, to be completely honest
* The other thing is that you can actually reverse this and say, you could even design unstable modes, which we're never going to do
* But you could and actually get a switch system that is stable
* So basically, you could reverse time when we, what just looked at
* And we get to unstable modes that renders the switches But here is how we actually will approach this
* We will design stable modes because it would be suicidal to design unstable modes and then hopefully, miraculously hope that the switches will, will take care of it
* So, we're going to design, design stable modes but we need to be aware of the fact that the new system is not stable
* And, in fact, it would be nice if we could check that either analytically or at least in simulation because the hybrid world is a little bit scarier than the nonhybrid world.


--- SKIP ---: 04_danger-beware.en.srt


--- SKIP ---: 04_danger-beware.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_danger-beware.en_SENTbySENT.txt
* So, last time, we saw that it was possible to destabilize a hybrid system by switching between different modes even if the different subsystems or modes were stable or asymptotically stable themselves
* in this lecture I want to harp on this theme a little more and, in fact, I've called it Danger, Beware
* because this is actually something that we need to be aware of and it is not always so easy to ensure that the overall hybrid system is stable even if the subsystems are unstable
* In fact, like I saw, we looked at a counter example that allowed us to actually destabilize, which means drive the state off to infinity, by being unlucky or unclever in how we transitioned in and out of the different modes
* So, if we ignore the resets, meaning there are no reset maps, the state doesn't jump when you're making transitions, we get something called a switch system where you have x dot if is f(x,u) but now I have this a little sigma index here and sigma is what's known as the switch signal
* So, sigma is going to tell me which mode the system is in
* So, if sigma is 1 I am in mode 1
* If sigma is 10, it's in mode 10 or if it's p it's in mode p
* So, all I'm doing is I'm switching between different modes and this switch signal can be, be rather different
* It can be just random
* It can be driven by time
* It can be driven by things happening in the state
* But it's a very general way of describing a switch system
* Now, if you have that, we can actually talk about different kinds of stability
* And I just wanted to point out that these things actually exist and we should be aware of them
* The first is what's known as universal asymptotic stability
* And universal means that there is nothing I can do to destabilize the system
* No matter what, this upside-down A means for all sigma, so x will go to 0 no matter how I switch
* That's called universal stability
* The other notion is existential stability, which means there exists the flipped E it's called an existential quantifier
* It means, there exists a switch signal that makes the system stable
* So, not all of them, but at least there is one that makes it go down to zero
* And these are the two main ways in which people want to deal with switch systems
* In our case, we don't have, there exists a switch signal typically, or for all, we have what's called hybrid stability and that we actually have a hybrid system that is itself generating the, the switch signal and this is known as hybrid stability
* So, x goes to zero, not for any all sigma or for all sigma, but for the one that happens to be the one that we have in our hybrid system
* So, here are some results
* Let's say that I have a hybrid system where all the individual modes are asymptotically stable
* Well, then, can we guarantee that it is at least existentially stable
* Well, clearly, we can, right
* Because what we do is we don't switch
* If I design a switch signal that just picks one mode and then stays with that forever and ever and ever, well, we're never switching but all the individual modes are asymptotically stable so if all the modes are asymptotically stable, we never switch and voila, we do have an existentially stable system
* But, as we will have, as we have seen, they're not always universally asymptotically stable
* And the reason for this is well, this counter example
* The reason is that we can actually destabilize the system by an unfortunate switching between the modes
* So, what do we do about this
* Well, there is something in nonlinear control known as a common Lyapunov function
* I'm not going to talk about this in this course, mainly because the common Lyapunov function is an elusive beast that you can almost never find
* But theoretically, that's what you're going to have to hunt for
* Practically speaking though, what you need to do is the following
* First, never design unstable controllers because then you're going to be in trouble probably, right
* So, design stabilizing controllers for the subsystems
* And then, we design the switching logic, meaning how are we going to switch between the different modes and if we're lucky or we have a lot amount of free time on our hands, we can go find, or try to find these common Lyapunov functions
* Now, like I said, finding that is really more art than science in the sense that it's very hard in general to find it
* So, the most important thing here is really, we need to be aware of the fact that stable subsystems do not ensure asymptotic stability of the hybrid systems
* So, we need to be aware of it and test, test, test, test, test
* In the sense that, run it, see what happens, do we get instabilities induced
* And if we do, we need to start messing with our switching logic
* But this is really key and I cannot underemphasize the testing aspect of the hybrid system
* In fact, when people design avionics software, for instance, the majority of the time is spent not on test, on, on the development of the controllers, but on testing that the switching logic in combination with the controllers does not induce instability
* So, that's what we need to keep an eye out for.


--- SKIP ---: 05_the-bouncing-ball.en.srt


--- SKIP ---: 05_the-bouncing-ball.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_the-bouncing-ball.en_SENTbySENT.txt
* So welcome back
* today, I would like to investigate a particular hybrid system that has to do with a bouncing ball
* So, that is, I take a ball and I drop it on a surface and I would first of all, like to model it
* And secondly, like to figure out how the ball behaves
* And the reason why I want to do this is not necessarily because I really like balls but because this bouncing ball example holds the key to another little peculiarity of hybrid systems that we should be aware of
* So, here is the set up
* I have a ball
* It's h above the ground
* Now, what happens in between the bounces
* Well, Newton tells me that force is mass times acceleration and, and the acceleration is, in fact, -g, where g is the gravitational constant
* So, if I let x1=h and x2 be equal to h dot, which is what we always do, then what I get is that x dot is this thing, 0100 x, which is just the point mass, plus this gravitational force that's pulling it down
* Now, let's say that the thing that I'm interested in also is, where the ball actually is, how high, how high up it is, so y is going to be 01 x
* So, that is my model of the ball
* What happens at the bounces
* Well, you could try to model ball deformations and whatnot, but that seems rather complicated so what we're simply going to say is that these are what's called inelastic bouncers which mean, which means that a little bit of energies sucked out of the ball every time it bounces
* And in fact, what we're going to say is that velocity, this is the velocity, so if the ball is coming down here [SOUND] hits the ground then the velocity instantaneously flips, it means, that's why we have a minus sign there because the ball instantaneously flips but we're also scaling it with this gamma constant, so we're making the velocity change direction from downwards to upwards, but a little bit less, which means we lost some energy in the bounce
* Well, the position doesn't change in the bounce, so this means that my reset condition is going to be this
* This is just encoding this fact that I'm flipping a little bit, I'm flipping my velocity, and I'm loosing a little bit of energy at the time of the bounce
* Alright, so lets see what this bouncing ball hybrid automaton might look like
* Well, x dot is Ax+b, in this case, not Bu and b is 0-g so this is this forcing term that is gravity, no big deal
* Now, what's going to happen is I'm going to switch from that mode to itself when I'm bouncing
* And we already saw that the reset condition is this inelastic bounce condition that says that we're losing a little bit of the velocity at the time of the bounce
* So, that's the reset condition
* Now, the guard condition is what
* Well, clearly, we're bouncing when we're hitting the ground
* So, we would like the height to be less than or equal to 0, right
* Well, let's see what happens
* Here comes the ball [SOUND] hits the ground, now the height is 0, we're switching and now the first thing we do is we reverse the velocity but, meaning, we're switching
* But hey, wait a second, the height is still less than or equal to 0
* The height is still 0
* So, what we're going to do is we're just going to end up spinning like crazy if we have this guard
* So, this is not a good guard
* Let's get rid of it
* Instead, what we need to do is we're, we're going to switch when we come down to the ground and the velocity is pointing downwards
* Meaning that h needs to be negative or less than or equal 0
* And h dot has to be less than or equal 0, meaning, we're facing downwards
* Or since h and h dot constitute our state, then the guard should really simply be that x is less than or equal to 0
* That's the guard condition
* Well, it could be it's just a, the height is just 0, but this is really the condition that tells us that it's time to, to switch
* Okay, good
* So now, we have that
* Is this any good
* Well, I mean clearly, it's good
* It's pretty and we have guards and resets
* But does it model, first of all, faithfully what balls do when they bounce
* And secondly, are there reasons why a model like this would cause us to be a little bit nervous
* To answer that, we need to figure out what the ball is actually doing if we have this model
* So, first of all, we have this system again now
* What I would like to know is what is the output of this system
* Well, fast forward, sorry, not forward, reverse two weeks and we go back to linear time-invariant systems
* We know what the solution to this system is
* We know that the output is C times this bad boy here, that we call the state transition matrix, which was fancy speak for this matrix exponential times the initial condition plus C times this rather awkward-looking integral there
* Now, all of these is, is, is not particularly pleasant
* And I remember vividly how we struggled to get through this because there were so many integrals to keep track of here
* Now, in this particular case, we're a little bit lucky because this A matrix is what's called nilpotent because if I take A to the power two, or three, or any high there, higher exponential here, then I get 0 out
* And that turns out to be quite wonderful for us
* Why is that
* Well, remember, that e^At is really this infinite sum
* A, there should be a parentheses here, I apologize
* 0 At to the power of k divided by k!
* Well, in our case, all the higher order A's are equal to 0, so I get first k=0, which gives me the identity matrix
* Then I get k=1, which simply gives me A times t
* And then, I have all the others which are equal to 0
* So, e^At, in this case, is simply this matrix
* Here is the part that comes from the adjacent matrix and since A is simply that times t, I get the t up here
* So, this is my e^At or my state transition matrix
* So now, I should be able to plug this back into the equation for y and get a rather nice looking expression
* So, let's do that
* Well, here is C
* Here is the state transition matrix
* Here's my initial condition
* Here's this rather awkward-looking differential equation sorry, integral
* now, we can try to solve that
* and if we do that, instead of actually doing the math, I did the math, I encourage you to go home and do that
* I'm just going to write down what the solution is
* It's going to be h0 times the initial velocity, h dot 0 of t-t0 and that's then minus g/2 t-t0 squared
* So, this is what the output looks like in between bounces
* Good
* Now, that we have that, let's figure out how long it takes in between bounces
* So, let's say that we start at zero o clock, at height zero
* This is when the bounce is about to start and then, [SOUND] we want to know how long this, this took
* We want to know how long it took us to get back the ground
* Well, that's simple
* Let's pick a big time, big T and say, well, y at that time t has to be equal to 0
* Well, then we plug that in
* h0=0 not so we don't any turn there we just get h dot 0 times T minus this thing
* or another way of writing it is like this
* And you know what, this needs to be equal to 0 because h is 0 there and h is 0 there, which is why we have two solutions
* So, one solution corresponds to T=0, which is at the beginning of the bounce
* And the other solution is when we return down
* So, this is how long it took me to go from the ground, up into the air, and then back down to the ground
* This is the time in between bounces
* Let's compute the accumulated bounce times, just because we find it amusing
* Well, the velocity at the beginning, so at the first time, let's just say that the velocity is v, right
* So then, the time of the first bounce, instead of h dot 0, I just plug in v there
* I get 2v/g, that's the time of the first bounce
* Well, the velocity after the first bounce, well, the reset condition says that I have gamma times v, so okay, I have a new v here
* That's what I'm going to plug into my h dot 0 here that immediately tells me that the time of the second bounce is, well, it's the time of the first bounce plus the time it took for the second bounce and instead of v, I have v divided by gamma there
* So, that's how long it took me to perform two bounces, and so forth
* This tells me that the time of the nth bounce is given by this 2v/g which is this term that shows up over and over again
* And then, every bounce gets this gamma to the power of k accumulated
* Now, this is what's called a geometric series
* And if you look that up or you happen to know it, if gamma is less than one, which means that you're not adding energy at the bounce times, this thing will actually, okay, and we have gamma less than one, this will actually converge in the sense that when n goes to infinity, this thing becomes equal to this expression
* Well now, maybe some of you are asking, so what
* [LAUGH] Well, you shouldn't be asking so what
* Well, what's going on there
* This is the time it takes to perform infinitely many bounces, infinitely many bounces, and this is less than infinity
* What that means is this bouncing ball is going to go [SOUND] infinitely many
* And there is some time t infinity here where this system is just going to grind to a halt and our model is just going to keep computing bounce after bounce after bounce after bounce faster and faster and faster
* And this is actually a serious problem that causes our system to actually crash
* So, the ball bounces in infinite numbers of times in finite time
* And like I said, this is not just a mathematical curiosity that shows that we can compute geometric series
* It means that if I'm simulating it, then my simulation would crash
* In fact, I encourage you to write this exact model into your favorite simulator and watch it crash
* This also means that if I write down my hybrid system like this, then it's undefined beyond T infinity because it's not clear what's happening beyond there
* Time is not allowed to go to infinity
* So, stability, which says what happens when T goes to infinity [SOUND] you can't even ask that question because t doesn't go to infinity
* what's worse obviously is that real balls don't do this, real balls bounce and after awhile they lay still, right
* So, this is also an indication that our model is not particularly good
* And, in fact, this type of phenomenon where you have infinitely many switches in finite time is known as the Zeno Phenomenon, after the philosopher Zeno, that had the a tortoise race, a hare
* And the paradox that Zeno came up with was the fact that the hare never managed to overtake the tortoise
* And in the next lecture, we will see, first of all, why the tortoise is able to beat the hare and what to do about it, meaning how do you make the rabbit overtake the turtle
* Well, that, my friends, is the topic of the next lecture.


--- SKIP ---: 06_the-zeno-phenomenon.en.srt


--- SKIP ---: 06_the-zeno-phenomenon.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_the-zeno-phenomenon.en_SENTbySENT.txt
* So, in the last lecture, we investigated this innocent-looking model or system, which was a ball bouncing on a surface
* And we saw something rather strange there, which was that, that the, the ball ended up bouncing an infinite number of times in finite time
* And this is part of another potential complication that comes from hyberdizing your model, namely, that you have these kinds of infinitely many swicthes
* And this is known as the Zeno Phenomenon
* And in today's lecture, we're going to dig a little deeper into the, the Zeno Phenomenon and see what we can do about it and if you can understand it
* But fundamentally, what I would like to point out is that Zeno is bad, because if you're actually running something that's asked to do an infinite amount of things in finite time, it crashes
* If you're running this on the computer, the simulations crash
* another thing is that we know that there is something inaccurate or wrong with our model because the ball, if I drop a ball, it doesn't bounce an infinite number of times, it bounces 17 times and then it stops bouncing
* So, there's something wrong with our model
* That's another warning flag
* And the third warning flag is that we don't actually know what the system does beyond the, the Zeno point, meaning the time up to which we have an infinite number of switches
* So, since we can't really define what the system is doing beyond that point, things like asymptotic stability is meaningless because time is not allowed to really progress off to infinity
* So, first of all, why is it called the Zeno phenomenon
* Well, there was a Greek philosopher, Zeno, Zeno of Elea who spent a lot of time thinking about movement and the dynamic world and basically his point was that our perception of the world is wrong because clearly there are all these problems out there
* For instance, here's one of his famous paradoxes
* We have a hare racing a tortoise
* And the tortoise is a little slower so the tortoise gets a head start
* In fact, the tortoise starts there and then, the race is on
* And at some point, the hare reaches the point were the tortoise started from but at that point, right, the tortoise has moved, not much but it has moved a little bit
* This is how far the tortoise has moved
* Okay
* The race goes on
* And at some point, the hare catches up to where the tortoise was last time but now, the tortoise has moved a little bit more, not much, and then this repeats
* In fact, here is the, the paradox
* The paradox is that the hare never catches up with the tortoise because every time it reaches the step that the tortoise was last time, the tortoise would have moved a tiny bit
* Now mathematically, this is nothing
* We know now about convergent series
* We know that even though there are infinitely many of these small intervals the sum of them will converge and there is indeed a point where the hare will catch the tortoise
* but the problem for us is that if I model this as a hybrid system, I have, again, infinitely many switches in finite time
* So, this is why this kind of infinite amount of switches is called the Zeno Phenomenon because it can be traced back to Zeno's many paradoxes about motion
* Now, let's look at another example, one that's not a hare and a tortoise but one that's rather innocent-looking
* Let's say that x-dot is negative, for +x - 1 and it's positive for -x
* Okay, so we have this
* If I write this as a this is a hybrid automoton, so let's see what's going there
* An if I draw this little plot here, right, here is here is time and here's x
* Let's say that x starts there
* Well, it starts positive so x-dot is going to be -1, so it's going to decay down with a slope of -1 and then it becomes tiny bit negative, and then oh, it's going to switch back up to plus, and then it goes up and in a second, it becomes just a tiny bit positive again, it switches down and, in fact, really what's happening is that once it hits 0, it starts switching like crazy here
* In practice, it would chatter but in theory, it starts switching like crazy here and this is actually not good at all
* So, this is really a Super-Zeno Phenomenon because not only do we have infinitely many switches in finite time, we have it at the single time instance, which is when the system actually hits x=0
* So, for that reason, we typically talk about two different kinds of Zeno types to, so type 1 Zeno, which is what I now call the Super-Zeno
* It says that you get infinitely many switches in a single time instant
* In this case, again, I want to reiterate this, the ball came down here and then, not the ball, this system came down here and then it started switching infinitely many times right there
* Now, type 2 is Zeno by not type 1, meaning, you have infinitely many switches but you have that over a time interval and the bouncing ball is really an example of that
* So
* there are some good news and bad news in all these rather messy switching situation
* The bad news is that Zeno is a problem as we've seen
* However, type 1 which is arguably the more common type is not only detectable, meaning, it is easy to see if you're going to end up in a situation where you are going to switch infinitely many times at a single time instant
* But the other good news about type 1 is that we can actually deal with it because you know what, what should this system do
* It should go down to zero and then it should stay at 0
* It's clear that that's what we want the system to do and, in fact, you can do that as you will see in the next lecture
* Now, the last piece of bad news though is that type 2, the bouncing ball type, that is hard, it's hard to deal with a bouncing ball
* It's hard to detect it, it hard, it's hard to remedy it
* and this is again, a situation where you really need to test your system and see do I get something like this where you start seeing an accumulation of switch times
* And if you do, you need to go back and revisit your model
* But in the next lecture, we will see how to indeed overcome the, the problems that a type 1 Zeno system will will cause us.


--- SKIP ---: 07_sliding-mode-control.en.srt


--- SKIP ---: 07_sliding-mode-control.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_sliding-mode-control.en_SENTbySENT.txt
* Last time we saw that not only we have to worry about Zeno
* This zeno problem or the zeno phenomenon comes in two different flavors
* And one thing that I stated was that type 1 zeno which is infinitely many switches in zero time or in one timing sense here represented by this system where
* Again, if I have x here, and time here, and I start positive, then x is going to be -1 until x becomes, just, just negative
* And then, we're going to get this infinitely many switches going on right there
* that's type 1
* Well, it turns out, that we can actually remedy this
* And the reason for it is, you know what is very, very clear what should happen
* The system shouldn't grind to a halt
* It should just nicely keep continuing on like this Like x is equal to 0
* So how do I take this intuitive notion of that x should just keep saying and be equal to 0 and make that mathematically sound
* What, what's the topic of today's lecture, and this construction by which we can continue beyond the zeno point in the type 1 zeno system, using something that's known as
* Sliding mode control
* So, let's be a little bit general here
* Let's say that I have one system, x dot is f1(x) and then I have a switching surface, g(x)
* And when g is negative, I switch to f two, and when it becomes positive I switch back to f1
* So here it is, here's my switching surface, g(x) = 0, that's where the action is
* Now on this side I'm going to be using f1, and da, da, da, da, da, da, da, when I hit this point, well let's say that f1 is pointing inwards
* Well on this part of the world I am going to be using f2
* Well, let's say that f2 here points outwards
* This means that when I hit this point again, I grind to a halt
* so this is really what's going on is that both of the vector fields both f1 and f2 point in the wrong direction
* So f1 points over in to the f2 territory
* f2 points over in the f1 territory, but again it's clear what should really happen
* We should somehow slide along the switching surface here
* That's clear because f1 and f2 are pulling in different directions and this is why it's known as sliding mode control because what we do is we slide along the switching surface
* So let's see how to actually make this sliding happen
* Again, I have g positive on this side, g negative on this side, and the switching surface is g = 0
* f2 wants to drive me in this direction, and f1 wants to drive me in this direction
* I want to slide along the surface
* That should be the right solution
* Well first of all what are the conditions under which I'm going to slide
* Well f2 needs to point in the positive direction of g because on this side g is positive
* So what I'm going to do is I'm going to find this thing, the vector that's normal to the switching surface and it turns out that luckily for us this is the gradient
* The partial derivative of g with respect to x, transpose
* And now I take what's called the inner product, so, with this thing and this thing
* So the inner product is just a multiplication
* and if this inner product is positive, it means that this one and this one are pointing
* in the same direction
* I also take the inter-product with this and that, and if the inter-product is negative, it means that they're pointing in, in different directions
* So what this means is I actually have a condition for sliding
* I need dg the x, where this is actually dg, dx1, blah, blah, blah, blah, blah, dg, the xn a roll vector like this times f1, well f11 to f1n, 'cause these are all vectors
* If this is negative, that is code for having this arrow and this arrow pointing in different directions
* So, f1 points into negative g territory
* f2 points into positive g territory
* if this happens at the switching surface, then we have sliding
* And, one way we can think about this object here, it's the derivative of g, in the direction f1
* And this is the derivative of g in the direction f2, and there's actually a fancy term for this
* it's called the Lie derivative
* So the derivative of G in the direction f, we're going to write this Lfg which is simply code for dg/dx * f
* So when I write Lfg, this is what I mean
* It's the lead derivative of g in the direction of f
* So, using our slightly fancier notation we know that sliding occurs
* Meaning we should slide if the derivative, g, in the f1 direction is negative, which, again, means this and this have different directions, and the derivative of g in the f2 direction is positive, which means this and this have the same signs meaning they point in the same, in the same directions
* So this actually tells us whether or not we have sliding and wallah, we actually have a test for type 1 zeno that says that sliding occurs
* If Lf1g is negative and Lf2g is positive, and this is at g(x) = 0 so this is along the switching surface when we're inside the different mode regime
* We don't have to worry about this
* But on the switching surface, this our zeno type 1 probe that we have to use to see whether or not we slide
* And this nice because this is something that's easily implemented
* We still don't know what actually happens beyond the zeno point, meaning, how do we slide
* And that is going to be the topic of next lecture.


--- SKIP ---: 08_regularizations.en.srt


--- SKIP ---: 08_regularizations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_regularizations.en_SENTbySENT.txt
* So last time we saw that we could actually test for type1 zeno and the way we could test this was to see whether or not the gradient dg, dx transpose points in the same direction as f2, in the opposite direction of f1
* So if I have that, then I do have type 1 zeno
* And we came up with a little probe here to check whether or not, this is indeed happening
* So, the first thing we do is we check LF1G negative, and LF
* 2 G positive
* Where LFG was this thing we called the lead derivative
* Which was simply just fancy speak for DG, DX times, in this case, F1 of X
* That's all it means
* So this is the probe that checks whether or not sliding occurs
* Today, I want to talk about what's called regularizations, which is
* Code for okay, let's say we have that, we have sliding, how do we compute how we slide
* And it turns out that this is going to be very important when we move on to robotics because this occurs quite a bit when you actually start running robotic navigation systems
* So today's lecture is all about How to be actually slide along this surface.Well, lets actually try to be a little careful in [UNKNOWN]
* So if I'm sliding here, what is characterizing that motion well, i know that g(x)=0 which means that if i take the time, the relative of g, we respect to t Then it should be 0 because g is not going to change when I'm sliding because I'm staying at g=0
* So one thing we need to do is say that dg/dt=0
* Well, let's see where that takes us, dg/dt It is equal to dgdx*xdot
* So now what is x dot along here
* Well, what I am going to postulate is that it's a combination of f2 and f1
* In fact let's say that is equal to sigma1*f1+sigma2+f2
* So it's a convex combination of, of these two Vector fields
* So if I do that, I get instead of x dots, I get this thing here sigma 1 f1 plus sigma 2 f2
* Well, since these are scalars, I can actually pull them out here, which means that I can write this expression that's is a little bit messy looking like sigma 1 times the lead derivative of g along f1 plus sigma 2 times the lead derivative of g along f2
* So that's what the time derivative of g actually is
* But I want that to be equal to 0
* This needs to be equal to 0 because that was our condition
* So if I put this thing equal 0 then I can solve for instance for sigma 2 and I get
* This expression right here
* So I know how Р СџРЎвЂњ2 is going to depend on Р СџРЎвЂњ1
* Well that's a good start
* We also know that both Р СџРЎвЂњ need to be positive because I'm not allowed to always start flowing backwards and they also should sum up to 1 because otherwise they can go super fast along this direction which I typically don't want
* I want it to respect the dynamics
* So
* I have additional constraint too
* So the sigma needs to be positive and they need to sum up to 1
* Well
* let's see how we can actually solve it
* So, let's go back to our old friend, the example
* And again this example
* Looks like this, where, you know what
* I'm sliding down with slope -1
* Here's x and here's time
* And when I hit the switching surface, I stay with x=0 for the duration
* Okay, what is the switching surface, first of all
* Well, it's x=0, so g(x) is simply x=0
* Okay, let's compute some of these Lee derivatives
* So, lf1g
* It's, it's the derivative of g, with respect to x
* So, the derivative of that with respect to x, is simply 1
* F1 is simply negative 1
* So, the Lee derivative is negative 1
* Which is 1 of the things we needed for zeno
* We needed, or for sliding
* We needed this to be negative for, type 1 zeno to occur
* That's the first
* Well let's do the same for f 2
* Sorry this is an f 2 right here, apologize about that
* l f 2 g well it's a dgdx which equals the derivative of that with respect to x which is 1, and f 2 which is plus 1
* Right, so I get 1*1, which is equal to 1, which is positive, which was the other condition for having Type 1 Zeno
* So we know that we actually have Type 1 Zeno, or sliding, here
* okay
* So now, let's try figuring out what what the The sigmas should actually be
* Well, we had a formula for sigma 2.
* It is equal to -sigma1 and these two Lee derivatives divided by eachother
* Well, this was -1 and this was +1 so sigma 2 is simple equal to sigma 1
* Rather simple
* [INAUDIBLE]
* But what, what are they
* Well, recall that the need to sum up to 1
* Which means that they both have to be a half
* What this actually means, then, is that we can compute what the induced mode, sliding mode, actually is
* Well, I take sigma 1 * f1, which is half of f1
* And then i take sigma2 times F2 which is half of F2, well F1 is negative one and F2 is plus one so i get -0.5 + 0.5 and that's equal to 0
* So I know that my induced mode, in this case, is x dot = 0, which is exactly what we wanted
* because remember this picture that we've drawn over and over again
* We want to start here, get down there, and then keep staying at 0
* And the math turns out to work out, in this case
* Now, let's find the induced mode in general
* I know that the general formula for sigma2 and I, I want to point out that this is not a formula any one in their right mind should memorize, but we should know where it comes from and be able to use it when we need to
* But, here is the general formula for the, for the induced mode
* Well, we also have that sigma 1 plus sigma 2, is equals to 1, which means that I can take sigma 2 here, and plug it in, because this is what sigma 2 is
* So now I have an expression on sigma 1 so if I solve that, I acutally know what sigma 1 is
* I encourage you to go through the math yourself, it's a little bit of a mouth full, but what its, what it tells me is that I compute sigma 1, and I can compute sigma 2, just as well
* And, if I now sum all of this up together, I get this expression inside the pink box there
* And I recognize again, this is a little bit of a mouthful, but what this tells me is Exactly what the induced mode is
* So I am going to put a sweet heart around this thing, not because it's particularly pretty but because it's systematic and it tell us how to actually find the sliding mode controller or the induced mode which means that we know Exactly, not only when type 1 zeno occurs
* But how to progress beyond it
* So, let's figure it out
* If I have, this is my hybrid system
* And, if this is a type 1 zeno hybrid automaton
* How do I regularize it
* What do I do to add this extra sliding mode
* Well, this is what I do
* Now, let's parse this, even though it looks a little bit like a mouthful, let's figure out what it means
* So let's say I'm here, g is positive
* G is positive and all is, all is well
* Then, if g becomes 0 and the sliding condition is satisfied
* Then I move in to what we just computed here which is the induce mode
* And again it's a little bit of a mouth full but we will see later on that in robotics we have no choice but to actually use this
* So then I'm going to use this mode until if g becomes positive I jump back to f1
* If g becomes negative I jump to f2
* And of course we don't always have Type 1 Zeno some switches are nice if I simply end up g negative, I jump directly from mode 1 to mode 2 and vice versa
* So, this is how you take a hybrid system and make it immune to the Nauseous and bad effects of Type 1 Zeno
* And the nice thing is that this is completely general, and we don't ever again have to worry about Zeno
* Type 1 Zeno, Type 2 Zeno we already said them about
* Having said that this actually brings me to the summary of this entire model and hybrid systems
* So, what do we have, we have models, we have very rich models which are the hybrid [UNKNOWN] models
* We have something what we call Stability Awareness or just We're aware of the fact that, just because the submodules, or the submodes are stable themselves doesn't mean that the hybrid system is stable
* And we need to be aware of it, test for it
* We also have seen zeno as another awkward hybridization that occurs
* Or an awkward phenomenon that can occur when you go hybrid
* we have 2 classes of zeno
* 1, which is type 2, which is the bouncing ball
* Infinitely many switch, many switches in finite, but not, not zero time
* That's bad and scary, and we can't do anything about it except, look out for it
* But then, we have type 1
* And we now know, not only how to check for it
* But how to get around it using these things that I call regularizations or the induced sliding mode and with that if I had, you know a confetti, I would toss it up into the air because this ends the massive part and the pre-robotics part really of this course
* So what we're going to do in the next module is go back to robotics
* Apply, all of our new and awesome tools, and see, how we can unleash them to actually make mobile ro, robots do cool things in the real world
* Well done.


--- SKIP ---: 09_glue-lecture-5.en.srt


--- SKIP ---: 09_glue-lecture-5.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_glue-lecture-5.en_SENTbySENT.txt
* Hi, and welcome to Glue Lecture 5, Controlof Mobile Robots
* I'm Smriti Chopra, your instructor for theGlue Lectures
* And this lecture is titled, HybridAutomata
* So this week, Dr
* Egerstedt uh,introducedto you guys this concept of hybrid control,right
* Where a system, or in our case, a robot,has to go through these different behaviors inorder to complete a task
* For example go to goal, avoid obstacle,hop skip jump, whatever
* Different behaviors in order to complete atask
* And the problem with that is, or not theproblem, but what you need to keep in mind, is that now suddenly we need a bigger model thattakes into account all these little models or littlebehaviors of the robots
* And how do we do that
* We do that through something called ahybrid automata, which takes into account all thesecontinuous dynamics, and yet, switching logic, to switch betweendifferent dynamics or different behaviors
* So basically, an example of a hybridautomata is this
* Guy here, and it's really nothing but afinite state machine
* And a state machine is something that justskips between different states, etc
* So we have a q, for example, is your counter fordifferent states
* So when q is 1, you're in this state
* When q is 2, you're here
* When q is 3, you're here
* And each mode, or each state, in itselfhas different dynamics, x dots
* Right?Or different behaviors or modes
* And then you have these guard conditionsthat tell when you want to switch from one mode toanother
* Pretty simple.And then we have what we call resets
* Which is basically once you do switch to adifferent mode, do you change your state in any wayor not
* It's just something you can add into theautomata
* So this is a simple example of what ahybrid automata looks like
* And then we while studying this hybridautomata, came across this phenomenon called Zenoeffect, right
* And what is that, really
* It's this annoying thing that makes yourstate or your system just kind of go really fast betweenyour guard conditions
* So here your guard, when it's less than 0,you go from x dot f1 to f2
* When it's greater than equal to 0, youswitch back
* But the problem is when it's equal to 0,you switch, and then you just keep switching betweenthese two modes infinitely fast
* And that's something we don't want in oursystem
* And this is called Zeno Phenomenon
* And there's this whole thing called Type 1Zeno and Type 2 Zeno, which is studied in thelectures
* We're going to deal with Type 1 Zenoes,because we know how to deal with them
* Type 2 Zenoes are tough, and we're notgoing to deal with them here, in this class atleast
* And an example is that, okay, you're givena system, right
* This is a simple system here of twostates, and you want to see if this guy here is Type 1 Zeno ornot
* And once again, just remember that thiseffect happens when you have, lets say, the same guardcondition, but just flipped, right
* So this was g1 and g2, it's possible thatyou did not keep going between the states really fast
* But because it's the same condition here,g of x, which is less than 0, and then greater or equal to 0, that's the only wayyou get this surface g of x equal to 0, along which you're going tokeep moving like this, right
* Okay
* So when is it going to be Type 1 Zeno
* This is the first question you ask whenyou're designing a system here
* And you have certain conditions for it
* These are the conditions
* Basically, what you want to see is thatthis is my surface g of x equal to 0
* And when I'm hitting the surface fromwhichever direction I'm coming, either I'm coming from greater than equal to 0 orless than 0, right
* Whichever condition I'm coming from, whenI hit the surface does this particular equation holdtrue or not
* Or does this particular condition hold true or not
* Which is simply just saying that wheneverI hit a surface, is it true that one mode, or f1 for example, is pulling me in onedirection, and f2 is pulling me in the otherdirection
* And that's encoded in this condition here
* So it's not always true
* So that's why you want to check when is itgoing to be true that I'm being pulled into differentdirections when I hit the surface, which is g of x equal to 0.Okay, so this is pretty simple
* You guys saw the derivation in class, etc
* And once this is true, or once you dodetermine that yes, it is a Type 1 Zeno, then what do youdo
* Okay, then you don't want to keep movinginfinitely fast along the surface, right
* What instead you want to do is you want toslide along the surface
* So once we have found out that it is Type 1 Zeno, we're going to try and induce thesliding mode instead of going back and forth really fast sothat, you know, we kind of remove this whole annoyingthing with Zeno effect
* So we have this example that we just saw
* And now we want to find out, the firstthing, is this in fact Type 1 Zeno or not, right
* And we saw that we need to do this checkto ensure if it's Type 1 Zeno or not
* And this check is pretty simple, again geffect equal to 0, and then see if this condition holds or not,and we're going to do that
* So we know g of x equal to 0 gives us xequal to 10, right
* And then your lead derivative, Lf1g, isreally nothing but the partial derivative of g with respectto x times f1
* And because your g of x is x minus 10,your partial derivative of g with respect to x is going to be just 1times f1, which is just f1
* Which is 6 minus x, right
* Okay
* And now we want to make sure that our new derivative is negative, in the f1direction, right
* So in order to have this expressionnegative, we find now that our x must be greater than6
* In the same way, with the same math, youcheck out this condition, and it gives you xgreater than 0
* So you have these three things here: x isequal to 10, x greater than 6, x greater than 0
* And you want to see if this makes sense ornot
* Will this situation ever occur, right?And it turns out, of course it will occur, because x equal to 10 automatically meansx is greater than 6, and x is greater than 0
* So that means when I hit the surface, I am in fact going to experience Zer, Zenoeffect
* So we have established that.Okay
* So yeah, x is equal to 10.Kind of make sure of that
* And that means that we must in fact dosliding control
* Because once we hit the surface, we don'twant to keep moving infinitely fast along that surface, wewant to slide smoothly along the surface
* So we have to do sliding control.Okay
* So in general form, this is what it lookslike
* The thing is, once you find out that it isType 1 Zeno, or that there will be Zeno effect,now what, right
* You've hit the surface
* You know that this is Zeno effect
* Now what are you going to do?Now you need to move along that surface
* But to move along that surface, you needto know the dynamics, right
* You need to know x dot.How am I moving along the surface
* So that's what this log diagram hereshows
* This guy in particular is the dynamics orthe x dot that you employ in order to move alongthe surface
* And the way you get this is by taking the time derivative of your guard condition,and setting it to 0
* And the logic behind that is because youwant to move on this line, gx equal to 0, obviously because you want to stayhere where g is 0, you, you going to say that the timederivative of g is also 0
* There's no change: g is going to stayconstant at 0
* And that's the whole intuition behind howyou get x dot
* The actual derivation is there in thelectures, so you guys can, you know, go refer to it andstuff
* But I'm just giving you the formula here,and I'm telling you how you actually get it bysetting dg by dt equal to zero
* And okay, let's go back to the slidingmode dynamics and [COUGH] find them now
* So we know that for this system, wealready found out our guy is going to have Zenoeffects, right
* So now I'm going to find sliding modedynamics by this equation right here
* And there are two ways of doing it
* One is pretty much what I told you, that Iknow it's going to be Type 1 Zeno, so I'm justgoing to set dg by dt equal to 0
* And again, g of x is x minus 10
* So dg by dt is going to really be just xdot, right
* And then when I set x dot equal to 0, wellguess what, I got my dynamics
* So I means when I hit the sliding surface,I just stop; x dot is 0
* I have no velocity
* I have nothing.I pretty much just stop
* Okay
* But then, there's another way of doing it,if you don't want to go through this
* And that's by pretty much solving itthrough this expression here
* So you actually compute these little guys,the derivatives, which we have done, by the way, and plug them intothis equation
* And then you get x dot.So remember Lf1g was our f1
* Lf2g was f2, so when you put this stuff into this guy, this becomes f2f1minus f1f2, which is 0.And so you get x dot equal to 0
* So both ways we saw that we can get ourdynamics, x dot equal to 0
* And that was really the whole point ofthis slide, to show you how, given a system, first you find out if it'sZeno Type 1 Zeno or not
* Or let's say I tell you it's Type 1 Zeno,and then how do you find the sliding modedynamics for it
* So all together what happens is, okay, nowI've got this new mode here, but I need to somehow connect it,right, to my initial system
* So this is pretty simple
* I know that when I hit the surface, I'm going to go into the sliding mode,whichever mode I'm in
* When I'm transitioning, I hit x equal to10
* I come into the sliding mode, and then, ofcourse, when I get out of it, the sliding mode, then Icome back into my states
* And if you're wondering, you know, how howdo you come out of it well in this case x dot is 0, so maybe you'rejust going to grind to a halt
* But there are times where, you know, yourx dot is not 0
* And you are continuously moving, but yourcondition, do you remember that Lf1g condition should be 0, less than 0,something else should be greater than 0
* Basically vectors pointing opposite
* So while moving, if at some point your vectors stop pointing opposite directions,or they start pointing in the same direction, etc,suddenly now you don't experience Zeno effect at thatpoint, right
* And that's how your dynamics are thengoing to just push you out off the sliding mode, and you're going to get out of it and thencome back to these guys here
* So this is just a general form of it
* Okay
* With that, keep checking the forums, goodluck with Quiz 5, and bye-bye.


--- SKIP ---: 10_programming-simulation-lecture-5.en.srt


--- SKIP ---: 10_programming-simulation-lecture-5.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_programming-simulation-lecture-5.en_SENTbySENT.txt
* Welcome back.This is week five
* In week three we wrote a controller totake our robot from point A to point B
* This was called the go-to-goal controller
* And in week four we designed a controllerthat avoids obstacles
* So, what we want to do this week iscombine those two
* So that our robot can drive from somepoint in the world to some other point in the world withoutcolliding with any of the obstacles
* And the way that we're going to do that isto arbitrate between the go-to-goal and avoid-obstaclecontroller
* And that really means, think about howshould we combine these two so that we make theright decision
* Should we be, should we be avoidingobstacles
* Or should we be going to goal
* So the two techniques that we're going tobe using is blending and hard switching
* And in blending what we're going to do iswe're going to create a new controller which combinesboth the go-to-goal controller and the avoid-obstacle controller
* Then what we're also going to test is switching between the go-to-goal and theavoid-obstacle controller
* So we'll either run the go-to-goalcontroller or we'll run the avoid-obstaclecontroller, and we'll switch back and forth depending on whetherthe robot is close to an obstacle or not
* And then we're going to do a thirdexperiment, which is to use the blended controller as anintermediary between the two
* So we're going to go to goal when we'reaway from any obstacles, if we're getting close to obstacles, we'll switch to the blendedcontroller
* And if we're within a dangerous distanceof the obstacle, we'll switch over to the intermed, intothe avoid-obstacles controller
* So, what do we do when we, when we, whenwe blend
* What we're going to do is create onesingle controller that does both
* And what we'll do is first compute ourgo-to-goal vector which is U gtg, and then we're going to compute theobstacle avoidance vector, U ao
* And we will know how to compute both ofthose from the previous weeks
* And what we want to do is we want tocombine these two in some way
* And, one way to combine these two is to dothis in a linear fashion
* So, what I'm going to do is take a fraction of the obstacle-avoidance vectorand take another fraction of the go-to-goal vector and just add themtogether
* And then what I should get is this vectorU ao go-to-goal
* So so this is a combination of these twovectors
* And this vector will point us in somedirection that is both somewhat in the direction of the goal, and somewhat inthe direction away from the obstacle
* And what I really want to point out heretoo, is that I'm using u ao,n, and that just denotes that fact that I'm using the normalized versionof the vector, and that's nothing but, taking thevector itself and dividing it by the magnitude of thevector
* And that way you get, a vector that's a, a unit length rather than somearbitrary length
* And that just allows us to if we take thenormalized version of the obstacle avoidance vectorand add it to the normalized versions of the go-to-goal vector
* Then we get an equal balancing of the twovectors rather than having to worry about whattheir respective magnitude is
* Hard-switching is going to work in alittle bit different way
* What we're going to do is, we're going tojust use one controller at a time
* So, for example, is like I said, if we'reclose to the obstacle, we're going to want to doobstacle avoidance
* But, if we're clear of the obstacle, we'regoing to want to just do go-to-goal
* So, if we're away from the obstacle, usethe go-to-goal vector
* If we're close to an obstacle, use theobstacle avoidance vector
* And the way we're going to do this iswe're just going to make a decision about how close the robot is tothe, to, to an obstacle
* So for example, if one of your infraredsensors on the robot senses a distance less than say, 15centimeters, we might want to switch over to avoidobstacles
* But whereas if we're greater, at adistance greater than 15 away from, 15 centimeters awayfrom the obstacle we can go, we are safe and we cango ahead and do, just go to goal
* And then the last one is to, is to use thego-to-goal if we're some distance away from the obstacle, if we'regetting closer we're going to switch over to the combined blended version ofthe vector or of the controller
* And, then, if we're too close to theobstacle, if it's unsafe for the robot to do, be worrying about where to go to,worrying about going to the goal
* We're going to switch over to avoidobstacles
* And that way we're going to ensure thatwe're definitely not going to slam into anyobstacles
* Now, the logic for deciding whichcontroller to use is going to end up in the supervisor
* And the supervisor really considers eachcontroller to be its own state
* And the supervisor can switch betweenthese states
* Which means we're switching between thedifferent controllers
* So, we're going to have three differentcontrollers
* And, kind of going back to week three, anexample of this is if you look at, at the ex, execute function of thesupervisor and QB supervisor dot m, you may, might have seen that I had astatement that says switch to state stop
* And this means that I'm switching from thego, go-to-goal controller that we were using at that time and switchingto the stop controller
* And the stop controller is nothing but acontroller that sets the linear angular velocity of therobot to 0
* Now, we, we also had a condition when we wanted toswitch over to the start, to the stop controller fromthe go-to-goal controller
* And that condition was that the robot wasat its goal
* So, and the, and the check_event function,what it did, is it looked at, well, is this condition,at_goal, true, and it was true whenever the goal orwhenever the robot was within a distance of d_goal ofthe goal location
* So that, that statement then becomes true,which means that we have switched over into the stop controllerfrom the from the go-to-goal controller
* And that was a very, very simple statemachine
* because all it said was, that we start off in the go-to-goal state, or we're usingthat controller
* And then when we're close enough to the,to the goal location, we switch to the otherstate
* Which is the stop state which correspondsto the stop controller
* It's very, very simple
* What we're going to have to do this weekis going to be a little bit more complicated
* And here's one example of a state machine that you could implement using all threecontrollers
* Or actually, four controllers
* We're going to start off on thego-to-goal
* Because we're going to assume that therobot starts somewhere
* It's not going to be near an obstacle.It wants to go to the goal
* Then, if, we are at the obstacle, someaning that we're at some distance close to the obstacle, we're going toswitch into the blended controller with is the ao and go-to-goal controller
* And if we leave the obstacle, meaningwe're some distance farther away from theobstacle, we're going to, the condition obstacle_clearedwill become true, and we're going to go back to goal
* And so, we could, you know
* You can imagine that we can switch between these, whenever either one of theseconditions is true
* And, but this gets a little bit morecomplicated than that
* If we are in the state ao_and_gtg, so ifwe are in this state right here, and the robot issome distance less than, dsafe
* So what I want, we want, we're going to beless than dsafe away from the obstacle, then this will becometrue
* And in that case, what happens is that weswitch from this state into this state righthere, which is avoid_obstacles
* Because this is kind of like a last resort of, avoiding any collision with anyobstacles in the world
* Now again, if, if we, if we're, end up in a, if we avoid the obstacle and we end upin a, at a distance that is safely away fromthe obstacle, we can switch back to the blendedcontroller in the middle
* So you can kind of think about your, you,the robot is always in some state so, in some state, and it takes atransition if one of these is true
* And then it switches to this othercontroller
* So then it ends up here
* So if, if this one becomes true, itswitches back to this one
* So you can just follow the, theseconditions from state to state to state to figure out where the robot, whatthe robot is going to do
* And I said that we're going to have fourstates and four controllers
* It's because I also have one for stopping.So, if we are, if we are in this case in the go_to_goal state, in the, in the, in, in this controller,end state
* Then, [COUGH] if at_goal becomes true,then we go ahead and stop
* And, what you will probably notice here,is that I don't have a connection from any of the other statesto the stop state
* So, in this state machine, the only waythat the robot will stop at the goal location is if it's inthe go_to_goal state
* If it's executing the go-to-goalcontroller
* So maybe a better design would be to alsohave some paths down here, that's at, at_goal.And the same thing for here
* So maybe this was a better one
* But you're free to design the statemachine whichever way you want, so long as youmake sure your robot doesn't collide with theobstacle and ends up at the goal and stops there
* Now, as far as implementation is concerned, the files that you'll beinterested in are first of all, the execute functionand the supervisor, so QBSupervisor.m
* That's where we're going to implement thelogic for the state machine, where we're actual, well, I should say we'reimplementing the state machine in the execute function
* And the other file of interest is going to be this new controller which isAOandGTG.m
* So that's where you implement the blendedcontroller
* And, of course, we'll also take advantageof GoToGoal.m and AvoidObstacles.m
* Not only in the design of the blendedcontroller, but also, we're going to switch it back and forth betweenthese controllers that we've already written in the previous weeks
* So, let's see the blended controller inaction in MatLab
* See here, I'm going to go ahead and launchit, and of course I've already implemented it, andwe're going to run this
* So, this is the blended controller
* I'm going to click on the robot and followit
* And, as you can see, the robot is avoidingthe obstacles
* But it's also going to go to the skulllocation, which is -1, 1 up here
* And also has a condition for stopping
* So what I've done here is I'm running the,the, the blended controller
* And if I am at the goal, then I stop.And so, this is a success
* Now, my tips for this week are, as usual,make sure you read the section corresponding to this week's orweek five in the manual for more details
* I also encourage you to really experimentwith different ways of blending the go-to-goaland avoid-obstacles
* So I showed you in an earlier slide oneway of combining the two vectors together
* But I'm sure you can think of, of evenbetter ways of combining those
* And also experiment with different state machines
* So there's different, definitely differentways of combining the different controllers or the differentstates and conditions
* To construct a state machine
* And just explore and see what works thebest for you and good luck
* [BLANK_AUDIO]


--- SKIP ---: 01_behaviors-revisited.en.srt


--- SKIP ---: 01_behaviors-revisited.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_behaviors-revisited.en_SENTbySENT.txt
* So, congratulations, all that hard work paid off
* Or at least, congratulations if you managed to hang in there this far
* and claiming all that hard work paid off
* My job now in this module is to show that it indeed did pay, Because we're going to unleash our Newfound powers on mobile robots
* And this entire module is, dedicated to, what's known as the Navigation Problem, which means how do you make a robot drive around in a world populated by obstacles without slamming into things, and getting safely to landmarks or goal positions
* So, in the first lecture, we're going to return to this idea of behaviors
* And we're going to use control theory, now, to describe what's actually going on
* And I don't know if you remember
* But, we actually talked about behaviors before
* These were these atomic primitive things that the robots should be doing
* And then, by connecting them all together we get the overall navigation system
* Now we probably know that behavior is just code for a sub-system or a controller, and connecting them up together is code for a hybrid system
* So this is really what we need to do, we need to revisit behaviors in the context of control failure
* So first we need a model and in fact almost always it pays off to start simple so we're going to start with old friend this point
* So the position of the robot is X, so X is in R2, and I mean its a plain [INAUDIBLE]
* And I'm saying that I can control that velocity, of this robots direction
* Now to compare us, as we've seen are differential drive robots
* You can't really do this
* Instead, you have to control translational velocities and rotational velocities
* So, we can think of this really as for the purpose of planning how we want the robot to go
* And then we have to couple this to the actual dynamics
* But, to start with, let's just say that x
* is equal to U, well first of all what does that look like in the ax plus bu paradigm
* Well A is equal to zero so this is my A matrix simply go to zero and my B matrix is simply the identity matrix
* Well before we do anything else we need to see whether or not we can actually control this system and we formed a controllability matrix B AB
* Well, A is zero, so this term is zero
* B is the identity matrix, so this is the identity matrix
* The identity matrix is as full rank as any matrix anywhere come
* So, clearly the rank of gamma is equal to 2, which by the way is the dimension of the system
* So, we have a completely controllable system
* We should be able to make the system do What we would like it to do
* So we're going to start with what I call the dynamic duo
* These are the key behaviors that you always need
* No matter what your robot is going to do, you always need to be able to go to a goal location
* Or a landmark, or a waypoint
* You always need to be able to go to somewhere, and you need to be able to do it without slamming into things
* Without either one of those two, your robot just ain't going to be able to do what you want it to do
* So our job now is to design these two behaviors using What we've already learned
* So, we're going to do it rather simply
* We're going to actually simply say, you know what, if my robot is here, and I want to go in this direction, well, why don't I simply say that this is equal to my u, because that's equal to x dot
* So that's going to tell me, this is the direction in which The robot is actually going to do
* It's going to be moving or using my handwriting but some pretty graphics
* This is what we are going to do
* We're going to figure out the direction in which we want to move and then set u equal to that desired direction
* Okay, let's start with Go-To-Goal
* This is where the robot is
* Let's say their goal is located at x of g
* Well, I want to go to the goal, so it's really clear where I would like to go
* I would like to go in this direction, xg-x is this vector, and I'm going to call it e
* So, why don't I just put u=e, or u equal to some constant k
* Times Z, well let's see what E dot in this case, actually becomes
* Well, E dots is X gold dot, which is 0, minus X dot
* And X dot, well, that's equal to U which is equal to KE so E-dot becomes -ke
* Well, that's kind of good so if I have E dot is -ke, does this work, does it drive error down to zero
* Well, we know we have to check the eigenvalues
* So, if k is just a scalar, as long as this scalar is positive, we're fine
* If we want, for some reason, the matrix k
* We just have to pick a matrix k that has positive eigenvalues
* So, if k is a scaler and positive, we know that the system is asymptotically [INAUDIBLE] stable
* If we pick k as a matrix
* For instance, it could be a diagonal matrix, you know
* 10, and A 1000, say seems silly, but why not
* This is a positive, definite matrix means that the eigen values are all positive
* I have a minus sign here so I need to worry about the negative of K in this case the eigen values would be all negative
* So, if you have that I would go with K constant but if you have this you will indeed drive the error to 0 which means that we have solved the go to go problem
* There are some concerns, though in fact there's just one
* A linear controller means that you have a bigger vector the further away you are, which means that you're going to go faster towards the goal
* The further away you are
* Which doesn't, to be honest, make complete sense
* So what we should do, is we should, in practice, moderate this
* To make, maybe the game smaller, when we're far away
* Or make the game constant somehow
* Because we don't want to go faster when we're far away
* That doesn't quite make sense
* And you can play around with this
* As long as K is positive we're actually fine
* And what we're going to implement on the robot is this choice of K
* It's a K that makes the norm of U reach some Vnot, so here is Vnot when you're kind of far away, and then it's going to not go faster when you further way, and then when you get closer to the goal, meaning when the arrow goes down You start slowing down, and in fact, if you try to be a little creative in how you pick your K, this K here is the K that corresponds to this plot then
* That's the K that we're going to be looking at, but you don't have to do that
* in fact, a lot of robotics involves clever parameter tuning and Tuning of these weights
* But the whole thing, point here, I want to make is that you want to make sure that you don't go faster when you're further away because that actually doesn't make entirely sense
* Okay, we know how to go, you to go to goal
* Let's avoid obstacles
* Well, if I wanted to go towards the obstacle, I would simply pick xo-x=u, or some scaled version of that
* Well, now I want to avoid the obstacle
* Why don't I just flip it
* And that's now x-xo, instead, so flipping it means, I'm just going to avoid the obstacle
* And in fact, that's what we're going to do
* Let's just pick u=K*e, where K is a positive constant, and e, now, is x obstacle minus x
* Well, if I do that, I get E dot is ke, which is actually an unstable system
* And it's unstable in the sense that the error is not stabilized
* 'Cuz the error is the distance to the obstacle instead
* We're avoiding the obstacle
* Obstacle
* Now it's a little scary to have on purpose an unstable system in there but as you will see we don't worry too much about it because we need to make sure that the robot actually does not drive off to infinity which it would if we were was unstable
* the other thing that a little weird, so this is if I use u=k(x-x0)
* The other is, that it's, it's a rather cautious system in that we seem to be avoiding obstacles that are also behind us even that doesn't entirely make sense and we also cared less about the obstacle the closer we get which
* Absolutely makes no sense, because we should care more the closer we get
* Well, the solution is again, make k dependent on e, or actually the distances, so the normal e
* And to aviod this being overly cautious, we are actually going to switch between behaviors, and in fact, what we're going to do is using something like a induced mode, the sliding mode to very gracefully Combine goal to goal and avoid obstacles but for now let me just point out that one clever thing for instances is say that you want to care more about to obstacle u closer you get, so you want u to be bigger the closer to the, the obstacle you get
* So in this case this was the K that we used, then in fact this is that K that I'm going to use to implement things but, again I want to point out that you want something that you don't care so much when you far away
* And you care a lot when you close
* The reason I have an Epsilon here which is a small number is just to make sure that this thing doesn't go up to infinity when they normally is 0
* Things going off to infinity is typically not that good of an idea
* Okay so we know how to build the individual control modes
* Now we also saw that choice of weights matter
* you should be aware, again, that there isn't a right answer in how to pick these weights, and depending on the application, you may have to tweak the weights to make your robot more or less skittish or cautious
* But the structure still is there
* What's missing, though first of all, is to couple this X dot is equal to U model to the actual robot dynamics
* And we're going to ignore that question all through this module
* And devote the last module of the course to that question
* But what we do need to do is make transitions between goal to goal and avoid obstacles
* And that's the topic of the next lecture
* Before we conclude, though, let's actually deploy
* This dynamic duo on our old friend, tho compare robots, to see what would happen in real life
* So, now we've seen, in theory, how to design this dynamic duo of, robot controllers
* In par-, in particular, we've seen these 2 key behaviors, goal to goal and avoid obstacles
* And, now, let's actually deploy them
* For real on our old friend, the [UNKNOWN] mobile robot
* As always, I'm joined by with Sean Pierre Delacroix here, who will conduct the affairs
* And, first we're going to see the go to gold behavior in action
* And
* What we now know is that what this behavior really is doing is looking at the error between where the robot is, right there, and where the robot wants to be, in this case this turquoise piece of tape
* And then globally asymptotically stabilizing this error in the sense that it's driving the error down to zeros
* So, JP why don't we see the [INAUDIBLE] make the error go away
* So, as you can see, the robot is going straight for the goal, and the error is indeed, decaying down to zero
* And this is how you encode things like getting to a point
* You make the error vanish
* Very nice
* Thank you
* So now, we're going to run act two of this drama
* now the robot's sole ambition in life is not driving into things, and things, in this case, is going to be me
* one thing that's going to be slightly different from what I did in the lecture, is that I am not a point, meaning it's not just a point but in fact an obstacle with some spread that the robot is going to avoid
* In fact, what we're going to do is we're going to first of all ignore everything that's behind the robot because it doesn't care about avoiding things that are behind it
* And the things in front of it, it's going to sum up the contributions from all the sensors and it's going to care a little bit more about things ahead of it than on
* Its sight, so J.P., let's take it away
* Let's see what can happen here
* So, here I am
* Oh, no
* All right
* Very nice
* Don't hit me
* Thank you
* [SOUND] Perfect
* We have a perfectly safe robot that is not driving into professors at all
* and with that I think we compute
* Thank you.


--- SKIP ---: 02_hard-switches-vs-blending.en.srt


--- SKIP ---: 02_hard-switches-vs-blending.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_hard-switches-vs-blending.en_SENTbySENT.txt
* At the last, lecture we designed the dynamic duo of robotic behaviors, mainly goal to goal and avoid obstacle
* And the question I want to talk about in today's lecture is really how do we combine these two
* So Let's say that I actually have, as always, a go to here, a goal here, and an obstacle here with go to goal telling me to go in this direction, and avoid obstacle telling me
* To go in this direction which is straight away from, from the obstacle
* How do I actually combine these two
* And the question is really this, right
* It, is there some blended version of the two directions we should go in or should we actually switch between the different behaviors in a hard way, so that the winner takes all
* And, these are really the main two options at our disposal
* And what I want to do today is just discuss almost philosophically
* What are the pros and cons associated with these two options
* And then in subsequent lectures, we will be a little more technical in terms of how to actually build these so-called arbitration mechanisms
* Some mechanisms for transitioning in and out of different behaviors
* So the philosophical question is really this right
* Can robots can chew gum and walk at the same time meaning can they do two things or should they do two things or should they really only be doing, doing one thing
* So the same cartoon here over on the left where the black arrows again are the directions in which we think that the robot should go
* So if we're going with the hard switches paradox time
* What's going on is when we're let's say far away from the obstacle then the robots should be doing nothing but going towards the goal which I've illustrated here with the, a red arrow saying that right now that's all the robot is trying to do
* And then when it gets lets say closer to the obstacle it switches completely
* To the other direction which is, in this case, straight away from the obstacle
* And the reason one might want to do something like this is that, we're actually designing the behaviors, to do something really well
* The obstacle avoidance behavior is designed to, not drive into things
* And hopefully we design it right, so that we can actually trust that, if we're only avoiding driving into things, indeed We do not drive into things, or if we are only trying to a goal, than we have designed our controller to be as methodically stable, so that we can actually trust, trust that we end up at the goal
* So, the pro the benefit we're doing hard switches is then that we can actually trust these systems, that they are doing what they were designed to do from a performance guarantee point of view
* Now there is a drawback with this
* So, if you are a robot and you're just switching ma, ma, ma, ma, ma, back and forth between going to the goal and avoiding an obstacle
* Let's say you're riding this robot
* It's a really bumpy ride
* Or in general it, it's a, you're going to get, rather, jerky motions out
* And as we've already seen, if we're using odometry, for instance, to knowing where we are, then, the odometric readings can get really, a little bit messed off, up if you start switching quickly
* So, there is, the, the, the potential for having a really bumpy ride and theoretically this bumpy ride can translate into Zeno behaviors where we're forced to switch very, very, very quickly, In fact infinitely quickly in the worst possible scenario between the two behaviors
* So on the one hand we can trust that the system is doing what it supposed to be doing, but it's doing it in a rather Bumpy and unpleasant way
* So that's the, the, the deal with, with the hard switches
* The other alternative, of course, is to blend the two behaviors
* So the answer to the philosophical question here would be, yes
* Robots can, indeed, chew gum and walk at the same time
* They can avoid slamming into things and going towards goals
* And, I'm going to argue that all of us, when we're walking around were trying both, not to walk into other people and go to the particular place we're interested in going to
* So we do it all the time
* Why shouldn't we let the robots do it
* So the pro or the, the benefit we're doing this would be to get a smoother ride when we're not switching between behaviors rapidly
* we avoid typically that the Zeno issue
* So this would be an argument for blending
* An argument against it is that we no longer can completely trust that we have guarantees that our system does what it's supposed to be doing
* In the sense that now we're not only avoiding obstacles, we're kind of avoiding obstacles but we're kind of doing something else and it's not clear that we can actually guarantee anymore that we're staying clear of obstacles or if we are going to the goal while not only doing that but something then are going to indeed hit the landmark
* So there are potential drawbacks with with blending the behaviors and that one of them that is that it's hard to guarantee what's actually going to, to happen
* So, lets first of all build some both of these solutions and then we're going to to take some kind of stand here where we're going to prefer, prefer one over the other
* So lets actually start with with the switched hybred atomatom
* So, again we have the robot, the goal, and the obstacle, and what were going to do is we're going to used the behavior that we assigned last time
* So we're saying that we're controlling the volocity of the robot directly
* So lets say X dot is equal to U
* This is in R2, because this is a planar robot, so it's a two-dimensional control signal
* And let's say for the sake of simplicity that the go to goal behavior is simply a proportional regulator driving X to the goal
* And as long as KGTG is positive, we've seen that this is an asymptotically stable controller
* And we're also using the avoid obstacle controller that's just simply pushing us away from, from the goal
* So this is actually an unstable controller that's driving us away, straight away from the, from the obstacle point
* So let's say that we have these two these two behaviors
* Then, here would be a hybrid automaton that switches between these two behaviors
* So the robot is going towards the goal, until the distance to the obstacle, so this distance here, d do is less than or equal to some critical safety distance
* So when we're too close to the obstacle, we switch and then after we've switched we're now avoiding the obstacle and we're going to do that until we're no longer unsafe and what I've written here is that d obstacle should be
* Strictly greater than d safe plus some epsilon
* And the reason we want this epsilon here is that we don't want to end up switching too quickly so if we get rid of the epsilon, we're immediately in this situation where we might have ZnO or very very rapid switches so this would be a switched hybrid automaton that switches between behaviors and its kind of clear how we would design that
* Blending on the other hand is not as straight forward, so lets say that we have the same setup as before and lets define a blending function as a function of the distance to the obstacle
* So this blending function is going to be For a given distance do its just going to take on a value between 0 and 1 and the idea is that if this is 1 say we're only going to the goal and if its 0 we're only avoiding obstacles
* Here's an example, where sigma is 0.75 which means that I take you know 75 percent of this
* Vector and I take 25% of this vector
* That's what the blending is doing and what I'm doing now is I'm taking this little snippet, adding it on here and getting this as my new direction of travel
* So if I do that I get the green arrow here and the green arrow would now be the blended direction
* So x dot is going to be 0.75 in this case of going towards to goal and 1 minus 0.75 which is 0.25 of avoiding obstacles
* So this is a very natural way in which you can actually blend blend these two types of behaviors now you have to design the, the blending function and the very standard way to do it is something like An exponential like this
* So, what's going on is sigma is basically one for large do values and when sigma is 1 that means they were only going towards goal
* Then as we get closer to the goal d not becomes or do becomes small, then all were doing is avoiding obstacle
* And, basically, the parameter here, you get the tweak, is beta
* Which tells you, how quickly is this thing going to decay off
* Is it going to go like this, or is it going to be slower
* That's, that's really the, the design choice we would have to, to make
* If we're using this kind of exponential blending function, which for the record is quite standard
* so the punch lines behind this lecture is really that we,we have two choices when it comes to, switching, or mixing behaviors
* One is to switch hard between avoiding obstacles and going to goal
* And the other is to kind of blend them
* And as we've seen, there are drawbacks and benefits with both of them
* So, if you're switching hard, you can guarantee that your system doesn't do anything stupid but you get a bumpy ride potentially out of it
* If you're blending, you get something much nicer and smoother out but, the guarantees are kind of gone
* So of course, what we want to do is have our cake and eat it
* Meaning we want to take what's best with both of them
* So, we want to get the performance guarantees that the hard switches give us but the smooth ride that the blending gives us
* And the answer to that is surprisingly enough going to be this induced Sliding mode that we've already talked about
* That is going to give us the means by which we can do
* We can walk and chew gum at the same time
* Yet, somehow guaranteeing that we don't trip over just because we started to chew gum
* So in the next lecture, we're going to start approaching this issue.


--- SKIP ---: 03_convex-and-non-convex-worlds.en.srt


--- SKIP ---: 03_convex-and-non-convex-worlds.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_convex-and-non-convex-worlds.en_SENTbySENT.txt
* In the last lecture, we saw that we have really two choices when it comes to combining behaviors
* We can either switch between them or we can blend them
* And what I want to do in this lecture is really discuss a little bit further this issue of, of maybe not how we should combine them but if we need to introduce something more than just our dynamic duel of behaviors in order to deal with the navigation problem
* And as a hinted act at the end of last lecture, was the induced mode, the sliding mode is somehow going to be important
* But what I want to do today is start by discussing different kinds of worlds or environments
* And I'm going to start simple with worlds where everything is a point, the obstacles are all points
* And then, I'm going to start building up more and more complex scenarios to see when do we actually need to introduce another mode or another behavior in order to be able to act well in the world
* So, I'm going to start with points then I'm going to add a little bit of spatial dimension to these points so they're going to be circular obstacles
* Then, we're going to generalize that to something called convex obstacles
* we're going to make it harder than by making them nonconvex
* And finally, we're going to look at labyrinths
* So, basically the maze problem
* If you're a, if you're a rat, a lab rat trying to get to the cheese, what kind of behaviors do you need to actually find, find the cheese
* So, let's start like this and what I'm going to do now is basically discuss the different worlds at the rather high level by drawing cartoons of what's going on
* And then, in the next lectures, we're going to be a little bit more precise about what's going on
* But let's start with point worlds
* As always, blue means the robot, here's the robot
* Green means go and red means obstacle
* And this little disk around the obstacle is simply me saying, this is the distance when it's unsafe to, to travel towards the obstacle and just switch, somehow, to avoiding obstacle
* Either with a hard switch or a bland and in this case, it really doesn't matter too much which one we do
* So, the robot, well, it's simply going to start [SOUND] so here is go to goal
* Start moving towards the goal and then here, right
* We're now hitting the, the bad region
* Well, we know that the obstacle avoidance is going to push us away like this somehow so, you know, we do, we're going to do something like this and we got away
* Let's say, there's a little epsilon disk around it
* So, here's avoid obstacle and then, now, we're going to switch back and start [SOUND] going towards the goal
* So, this seemed like a slam dunk, we did well somewhat at least
* so, maybe we can declare successful point worlds
* in fact, I want to show you another situation where I move the point a little bit
* Now, [SOUND] I'm going towards the goal and here, go to goal, we want to move in this direction and avoid obstacle, you want to move in exactly the same direction
* So, what could potentially happen in this set up is when you answer here, the robot just keeps oscillating back and forth and it's never really finding a way around itself
* There is a really, really, really unlikely scenario that could happen if you have this bilinear line up where everything is on the same line, where you just end up switching back and forth without really making, making any progress
* Now, that is extremely unlikely when an actual robot is out in the world
* That ain't going to happen because the world is always a little bit noisy, the sensors are always a little bit noisy and even the slightest amount of noise is going to push you out, away from this situation
* So, the punch line, when we look at point worlds, is these two behaviors seem to be enough unless we're super unlucky
* And I call this some kind of mild Zeno
* basically you may end up trasitioning back and forth with no progress but like I said
* in the real world, we're going to have noise, so points we don't really worry too much about
* Well, let's go up in complexity
* Let's look at circles
* Well again, let me draw a cartoon on what's going on
* Now, the red dot is big but I'm going towards the goal
* [SOUND] Here, I'm going to start avoiding the goal and then let's say here, I'm going to start maybe, maybe I end up switching back and forth a couple times and then save
* So, circular obstacles here seem pretty reasonable
* it seems like our two behaviors are, are basically doing the same thing
* Now, if the circular obstacle was moved down, again, so the center of mass of the obstacle was bilinear, on the same line as the goal and the robot, the again, we would get stuck in this highly unlikely, never-gonna-happen-in-real-life scenario
* But basically, circular obstacles are point obstacles, just larger
* But philosophically, and complexity-wise, we can deal with them
* Now, the next level up in complexity is convexity versus non-convexity
* So, on the left here, you see what's called a convex obstacle
* It's basically a, it looks like a circle or a disk that's being squished a little bit
* what makes it convex is that if I take any two points inside this obstacle and I draw a line in between them, that line lays entirely inside the obstacles, right
* If I take the right obstacle, which is in fact, not convex then, you know what, if I take two points, we'll find this line lies entirely with in the obstacle
* But if I take a point here and a point there, then this line actually falls outside of the obstacle
* So, an obstacle or a set is convex if every line in between two points in the set lies entirely inside that set itself
* So, we're going to start with convex obstacles as the first step up from circles or disks and then we're going to look at non obstacles
* So, I have a nonconvex obstacle, right
* It's not a circle anymore and what I have here is, well, now my red marker doesn't show up, but any line I can draw here, of course, is entirely within this this disk
* So, let's see what's happening here
* the robot starts moving
* [SOUND] A straight line
* And then here gets, let's say that they, they now want to starts avoiding the obstacles so maybe avoid obstacle is going to push it there, it may be pushed back
* What's going to happen is there is a point when avoid obstacle is going to point straight away from go to goal and now and we've ended up in this situation that was super unlucky and unlikely when we had a point
* But in the convex with noncircular obstacle situation, that situation is no longer super unlucky because we ended up in it
* Let me again point out what's happening is that we're getting here, let's say, here is actually the point where avoid obstacle wants to go in this direction, go to goal wants to go in this direction and by switching, we're ending up there, which is the unlucky point, but in this case, it's actually not unlucky
* So, these two behaviors themselves, no matter, no matter if we blend them or switch between them, we actually get stuck
* So, we need someway of you know what, getting around the obstacle and somehow we need to follow the boundary of this obstacle and not just switch back absent-mindedly between going into goal and avoiding obstacles
* So, here is a situation where we clearly need to introduce another behavior in order to be able to navigate this obstacle
* Well, if you have a nonconvex obstacle, this is known as a robotic flytrap
* what it is, it's, it's a nonconvex obstacle
* It's a cul-de-sac
* And you know what, this robot is going to get down here
* First of all, it's going to get stuck here right, right, because here, we have this go to goal and avoid obstacle pointing in different directions but even if we were able to continue here, well, now all of a sudden, we're going away from the obstacle and, no, sorry, from the goal
* Clearly, we need something more than just go to goal and avoid obstacles to do this
* we need some clever way not only of following the boundary of this obstacle but following it in such a way that we actually progress towards the goal globally even though we're locally in the short run and getting further away
* So, nonconvex obstacles, it's even worse than convex obstacles
* Two, two behaviors certainly aren't going to work
* Well, what if you have a labyrinth
* So this is, you know, you have a bunch of different things
* You may have something extra here
* You may have something here
* You have a bunch of things
* And the robot needs to figure out that it's supposed to do this, right
* Which., I mean, [SOUND] now I'm going to sound, try to sound like I'm from New Jersey, forget about it
* That was probably not so close with my Swedish accent
* But anyway, it ain't going to happen with just two behaviors
* Clearly, no way of dealing with that with only avoid obstacle and go to goal so what we need is really at least one more behavior that allows us to deal with worlds that aren't just circular obstacles or point obstacles
* That are, in fact, convex or nonconvex or even, you know, labyrinths
* We want to be able to solve this problem, we want our robotic rat to get the, the cheese
* And that is going to be the topic of the next lecture.


--- SKIP ---: 04_boundary-following.en.srt


--- SKIP ---: 04_boundary-following.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_boundary-following.en_SENTbySENT.txt
* So, in the last lecture, we saw that, even for rather un-, scary looking environments
* Let's say that we had, slight non convexities, or even extended convex obstacles
* the dynamic duo of behaviors, go to goal and avoid obstacle, no longer was enough to negotioate these environments
* And we saw that we really needed some way of flowing a long the boundary of an obstacle in order to be able to get around in the world
* And today, I want to talk about this missing piece
* The missinig behavior which is a wall following behavior
* And what I want to do now is really just introduce it and then in the next lecture introduce it in a more systematic way as to induce mode when you're trying to avoid sliding or avoid type 1 Zeno
* So, here is the question
* How do you actually follow walls
* Or when I say walls what I really mean are boundaries of
* boundaries around obstacles
* So let's, let's start simple
* Here is, as always, an obstacle and I have a disk around it where, this is my safety disk
* Well, avoid obstacle is going to tell me, you know what, I want to move straight away from this From this obstacle
* Well, how do I , which direction do i go in, in order to maintain a constant distance from this obstacle
* Well what I need to do is, I need to flow, right, along the boundary of this, this region
* Well, what this means is that here, I need to go in this direction
* And what I really need to do then is take The direction, given to me by my avoid obstacle behavior, and flip it down, like this
* And this is a negative pi over 2, or a negative 90 degree flip
* So, that's what I need to do
* I need to flip it down by 90 degrees, like this
* And now, I'm going to call this FW, for Follow-wall, and follow-wall is now, simply, like I said, a flip down of 90 degrees, which this curious looking matrix here is actually achieving
* And I may want to scale it, so I may have some scaling that's making this Longer or shorter, depending on, I don't know
* Whatever concerns you may have
* Now, I should point out that, this matrix here, I can write as a rotation matrix, that corresponds to a pi over 2
* Sorry, negative pi over 2 flip
* so I can actually write this as alpha, which is the scale, times the rotation matrix, that is, the flip, times u, avoid obstacle, because that is ultimately the behavior that I'm, that I'm flipping
* So, this tells me that the way to move around this obstacle, is to simply take my avoid obstacle behavior, and flip it
* That's as simple as that
* So, there is a problem though
* I can actually flip in 2 different directions
* Not only can I go like this, I can also go like that
* So 1 question 1 should ask of course is which direction should I go in, but the other question is how do I even mathematically describe these 2 options
* Well, what I have, what we saw before was, we called it U clockwise follow wall, and the clockwise follow wall corresponds to a negative pi over 2 flip to avoid the obstacle
* A counter clockwise follow wall, which means follow it in the other direction, well that is simply a pi over 2 flip of the void obstacle behavior
* So if I introduce this thing that I've already called the rotation matrix, this is simply an operation that does this flip over vector
* If I have a vector here
* V, and I want to flip it by phi
* This new thing here, is simply r of, it's not phi, it's theta
* R of theta times v
* This is how I get this new, this new rotated vector
* So the rotation matrix is cosine theta negative sine cosine
* That's the form of this linear operator that's flipping vectors at certain angle
* Well what we've already seen is that the clockwise follow-wall it's a negative pi over 2 flip so this behavior is simply equal to alpha times, this matrix times, uAO
* Now the counterclockwise, while I can write that in the same way, it's just a pi over 2 flip instead of a negative pi over 2 flip, which gives me the following expression
* So, I actually have very, very clean expressions for how I should make my flip, meaning how I should proceed along the boundary of the obstacle
* And this works even if their obstacle is not just a point, because all I really did was I took a void obstacle, a void obstacle behavior and, and flipped it
* Now we don't know which direction to go with them
* So lets say that we have this situation, right
* [SOUND] I'm going towards the goal, and then let's say when I'm here, I now want to switch to a follow-wall behavior
* Which direction to choose
* it's not entirely clear
* Right
* I, if the robot only sees what's going on around here, for instance, how does the robot know what the world looks like
* We haven't built a map of anything
* So, you could either go clockwise, which in this case turned out to be the long way around, or you can go counter-clockwise, but it's really not clear how we should make this choice
* But here's one thing one can observe, is that go to goal here is wants to move you kind of upwards a little bit
* So maybe we can let go to goal make the choice for us
* Go to goal once the drive was a little bit in this direction, not at all in that direction
* So that's the idea we have here at, that there is no obvious answer, there is not then obvious right choice given what local information the robot has
* The robot doesn't know globally what the world looks like
* So given that we only know locally what's going on may be we can lack this goal to goal behavior
* Decide which direction we should go in
* So let's, let's try to make this a little bit more mathematically precise, what it means to let the goal to goal behavior decide
* Here, goal to goal, the angle was wrong here
* Goal to goal wants to go in this direction
* Right
* So here, goal to goal wants to drive us up
* Limit up, so may be we should take follow-wall up
* So this would be u clockwise
* Well, u counter clockwise or u follow-wall counter clockwise wants to go down
* And note, that this angle is less than pi over 2, but this angle, the absolute value of it, is greater than pi over 2
* So we should be able to look at this angle to determine
* Where we should go, but lucky for us there's a very simple way of checking these angles
* If I have two rectors v and w I can take what is called the inner product of those t which is simple v transposed to w
* Well that's equal to the absolute values of, or the, the length of vectors times cosine of this angle in between them
* And if this angle is less than pi over 2, then cosine is going to be positive
* If it's greater than pi over 2, then cosine is going to be negative
* So all we need to do
* It's to look at the sine of this thing, to figure out whether or not we're kind of pointing in the right direction
* So, here is a test
* Check go to goal inner product with follow wall clockwise
* If that's positive, we should go clockwise
* So, in this scenario, again
* Again, we're pointing in this direction, here is the follow wall, so this, go to go
* Here is u clockwise
* This angle, is less than pi over 2, which means that, this situation is satisfied
* Here is u counter-clockwise, so this angle is greater than pi over 2
* So, that means that the other condition is not satisfied
* So what we actually have is a local check
* We compute the direction that two different follow-wall behaviors would take us in
* Then we just take this inner product with go-to-goal behavior, and we check the sign
* And whoever comes up with a positive sign is the winner
* and that's the direction we choose to go in
* Now, there is a problem with this of course
* And that's that if you remember our labyrinth, or our little maze here, right
* If I'm following wall, you know what, I'm going to follow it all the way around
* And I don't want to keep going indefinitely around and around, right
* So then I'm just spiraling
* At some point, if here's the goal
* I want to release and go towards the goal
* So one thing that we don't know yet is
* When do we actually release the follow-wall behavior
* When do we stop following walls and start approaching goals again
* The other question is, you know what, we had avoid obstacle we had the rotation matrix, that flips either up or down, depending when we're going clockwise or counterclockwise
* And then I have this little alpha there Is there some natural or systematic way on which we can think about the alpha
* And that is going to one One of the things we will discuss in the next, the next lecture.


--- SKIP ---: 05_the-induced-mode.en.srt


--- SKIP ---: 05_the-induced-mode.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_the-induced-mode.en_SENTbySENT.txt
* So the outcome of the last handful of lectures, was that we needed something more rich to solve complex navigation problems, and that something was wall following
* In fact was saw that we really had 2 barriers, wall following clockwise and wall following counter clockwise
* And, the way we could encode that was to take our avoid obstacle behavior and simply flip, Either flip it -pi/2 for a clockwise negotiation of the obstacle or +pi/2 for a counterclockwise negotiation of the obstacle
* What I want to do today is relate this wall-following behavior to the induced mode when we looked at type 1 zeno in hybrid systems
* And the point with this is really for us to first of all, trust that this is the right thing to do
* Trust that we understand alpha
* And trust that we understand plus or minus there
* We use some kind of inner product rule to determine whether or not we should go plus and minus
* Now we're going to see that that's, indeed
* the correct rule from a sliding mode vantage point
* However we're going to do little bit of maths today and at the end of it we're just going to return back to this and say, this is how, still how we going to implement it because it is much simpler but we need in the math to get there and trust a that's correct
* So here's the general set, set up
* As before we have an obstacle x sub o
* We have a goal, X of G, and we have X, which is the position of the robot
* We also have a distance from the obstacle, when we're going to switch to avoid obstacle as opposed to go to goal, and even though I'm doing everything with points now This works for non-convex obstacles, for pretty much anything
* We can write that down at least in this way
* And the distance then being constant, let's say it's delta from the obstacle, when I can simply say that that means that the distance between the X and XO is equal to Now, what do I have
* I have 2 different behaviors
* I have one behavior that wants to take me towards the goal and I have another behavior that wants to push me away from the obstacle
* And now I also have a switching surface and I'm going to write this as the distance between X and the obstacle minus delta, should be equal to 0
* But, I'm going to put squares in there because I'm going to start taking derivative and taking the derivative of the square of a norm is easy taking the derivative of a norm is not so easy, and then I'm going to put the half here just for the reason of getting rid of some Coefficient but this half doesn't change anything
* So now what do I have
* I have g
* On one side I have g positive, which means that you're further away from the obstacle than delta, which means you're out here where you're going to use this behavior
* So we have f1 coming in here, so this is going to be my f1
* And then I have g negative on this other side, which is inside here, where I'm going to use this behavior
* So that's going to be equal to f2
* So I have everything I need to be able to unleash our induced mode piece of mathematics
* So, f1 is goal to goal
* f2 is avoid obstacle
* Now, we need to connect these somehow with the induced mode
* Well, here is the connection
* We actually computed the induced mode
* It was this convex combination of the two modes, or the two behaviors
* And this convex combination was given by this, mouthful of Of an expression
* But let's actually try to compute this, in this case, to see what, what the induced mode should be
* Well, first of all, we need the Lee derivatives
* So, lf2g, if you remember
* That was dg, dx*f2
* We need the same thing for f1 and then this lead derivative show, show up repeatedly
* Well, first of all the derivative of g with respect to x is simply x-x obstacle transpose and this is the reason why I put squares here because that made everything easy and I put the half there because that hills an extra 2 that would show up
* This really doesn't but it just makes the math a little bit easier
* This is again one of these things that I encourage you to try to compute yourselves, just to make sure that you actually trust that this is indeed the correct answer
* Well, now I can compute the [UNKNOWN] derivatives, right
* I have LF2G, well it's DG/DX times F2 Well the GDX which is computed it was that
* F2 is C avoid obstacle, X-Xo
* In previous lecture, I used K, with the prime index [INAUDIBLE] was C here
* Well, this is X-Xo transposed times X-X0
* But that's just X-X0 squared, the norm squared
* So this lead derivative has a rather simple expression
* Similarly, I can compute the other lead derivative
* And its' c, goal to goal times this thing, that we now know is an inner product of x-x obstacle, transposed times x goal minus x
* So I have the 2 lead derivatives that I actually need
* So, with that, I could go ahead and compute the induced mode
* For instance
* You know, this little thing here
* What is that
* It is let's see, it's (x-xo) transpose times (CAO*(x-xo)), that's the first term, minus C goal to goal times (xg-x)
* So, that's that term
* We have an explicit expression for it
* We can also go ahead, and compute this, right, for instance
* It's CAO, x-x0 transposed times f1
* Which is, what was f1 again
* It was goal to goal times xg - x.
* So I can compute this
* Similarly, I can compute that
* The point is first of all that everything is entirely computable here
* The other point is, you know what, this is a little bit of a mess
* It's a mess to write it down, but what we've actually done is [SOUND] We have recovered the same controller because what we're doing is again we're sliding
* The only difference is if you write it in this form, you automatically get alpha to pop out because you get the certain scaling, and you get plus or
* Minus flip
* So you actually get the flip for free, your told which direction to go and which alpha to go in and the nice thing is that the flip direction you get from computing the induced mode is actually the same as taking the inner products with U follow ball counter-clockwise with U avoid obstacle, if this inner
* U avoid obstacle
* If this inner product is positive, we go, counter clockwise, and otherwise we go clockwise
* So, the nice thing is, we have actually ,in a mathematically rather involved way arrive at same expression
* And with the difference being that we can have the plus or the minus automatically determined for us, and these scaling factors automatically determined for us
* In practice though, we're not going to do this, because this is too messy
* Instead, we're just going to pick some alpha that we feel good about
* I always pick alpha=1 because I'm lazy and then use the inner product tasks to figure out whether we should go clockwise or counter-clockwise
* So, that's practically what we're going to do
* Now, that's not enough, so let's say that I"m going towards the goal here
* Here I want to go in this direction, and avoid obstacle once to take me there, so sliding is immediately going to tell me that I'm going to start moving up like this
* Well you know what
* This was all good and Dandy, but if I'm simply looking at the sliding rule
* Then here, all of a sudden I'm pointing in both direction, and sliding is going to tell me to stop, So what I need to do is to just keep following the ball, verify then I'm going to follow the ball for a long time way and way and way, around and around and around and may be here the right time to stop following the ball
* The question that really need to answer now
* When we know that follow wall is the right thing to do, we know which direction to go in, and we know, really how to scale it even though we're just going to scale it by one because it really doesn't matter is when do we actually stop this sliding or follow wall
* Well, that turns out not to be so easy and in fact there are multiple ways of Answering that and this is precisely the topic of the next lecture.


--- SKIP ---: 06_a-complete-navigation-system.en.srt


--- SKIP ---: 06_a-complete-navigation-system.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_a-complete-navigation-system.en_SENTbySENT.txt
* The missing piece of the navigation puzzle was follow walls
* And now we have it, in the sense that we know how to move along boundaries of obstacles
* We also know which direction to go in and that was given by this sliding condition
* the one thing we don't know though is when to stop, because take a look here
* First of all, this is how follow wall, or go to goal is taking me
* Sliding tells me that, you know what, I should move up in this direction
* Let's look at this point
* Go to goal wants me to go there
* Avoid obstacle wants me to go there
* And if I draw this again a little better, they are pointing in completely opposite directions
* And if I'm just sliding, I no longer have anywhere to go
* If I'm, instead using, in this case, r negative pi over 2 times u avoid obstacle, then that's just going to keep me going in a counterclockwise, sorry, in a clockwise manner
* so that's why this is the better behavior to use, even though sliding is useful to go, to know which direction to start in
* Now, if I do that, then I'm happily going like this, but check out at this point
* Go to goal wants to go there
* Avoid obstacle wants to go there
* We are no longer in conflict when it comes to the switching conditions so any kind of sliding condition is going to fail because here
* I'm simply going to return to go to goal and then I'm going to just keep doing this over and over again and I'm going to get stuck in this corner
* So, sliding is not answering when to stop sliding or when to stop following walls
* Instead, we need some other condition for this
* And here is what needs to happen
* First of all, we need to [COUGH] excuse me, have made enough progress
* What does that means
* It means that if I'm switching here I'm kind of, I don't want to stop here, here, here because in fact, I should stop when I'm closer to the goal than where I was when I started sliding
* Because otherwise, you can indeed end up in a situation where you're moving successively further and further way from the goal and basically you're switching your way away from where you want to be
* So, you want to insure that you're closer to the goal at the end of the maneuver than you were when you began it
* The other is that you have a clear shot to the goal in some sense
* Meaning that you can actually move towards it
* [COUGH] Excuse me
* Clear shot doesn't necessarily mean that there are no obstacles
* Becuase, let's say that the goal is there and here's a giant obstacle that I haven't seen yet
* I don't know about that, but from any practical purpose, I somehow have a clear shot to, to the goal
* So, what we need to do is understand what these conditions mean
* Okay, let's say, that I started following walls at time tau
* So, let's say that I'm here, x at time tau, that's where I am
* Well, then progress, sufficient progress can simply say that the current position, this is the current position x current, it needs to be closer to the goal than where I was when I started my follow wall
* So, if I draw a circle here, at this distance around the, the goal, let's pretend that this was a perfect circle, then, any point here is going to be closer to the goal than where I started
* So, here are positions where I'm allowed to stop following walls
* But that's not enough
* We needed this notion of clear shot also
* And the clear shot simply is this condition here, where if I'm sitting here, then follow wall, sorry, go to goal wants to take me in that direction
* Avoid obstacle wants to take me in this direction
* And we already know how to check whether or not they are somehow in agreement
* What that means simply is that this angle, the absolute value of this angle should be less than pi/2, which we can simply encode by this inner product condition, which simply take and compute u avoid obstacle transpose u go to goal and check if that's positive, then we have a clear shot
* We don't really know about other obstacles but at least we have some notion of a, a clear shot
* So, these are the two pieces we need to determine when its time to no longer move along the boundary
* Okay
* Now, we have everything
* Here's my robot
* It's very happily going towards a goal, right, that's, that's all it's doing
* And then, you know what, it encounters an obstacle
* So now, xo Sorry, x-xo is equal to delta
* So, I'm delta apart from it
* And I have this directionality condition, right
* So, I'm going to check if this inner product is positive
* If it is, I should go clockwise
* Similarly I have a counterclockwise check
* So, if this condition is satisfied, I should go counterclockwise
* So now, I know when it's time for me to move either in a clockwise or counterclockwise direction
* Well, it's conceivable because the real world isn't the same as the theoretical world that, as I'm sliding, I end up closer to the obstacle that I wanted to be
* Let's say that the distance of the obstacle is now strictly less than delta, then I shouldn't slide anymore
* I should let my dedicated, custom-built avoid obstacle behavior just make sure we don't slam, we don't slam into things
* So, you always wrap a pure avoid obstacle behavouir in there for safety reasons, in order to guarantee that you don't hit things
* Remember that we're actually looking for both guarantees and a smooth ride
* And this is our way of having the cake and eating it, which very rarely works, but in this case, you actually can do it
* Okay, the one thing we need to remember though is, we needed to know how close we were to the wall, or the obstacle at the time we started following it
* So, we had this thing that we said, let tau be the time of the next switch
* Well, I'm going to have something that I call d sub tau, which is just the distance when I switch
* And I'm going to reset, remember we talked about resets, I'm going to reset d sub tau to be the distance to the goal at the time I started to follow walls
* So, here are resets, right
* Now, I'm going to stop sliding or stop following walls, well I wrote it as one guard, because it's the same condition no matter where we're coming from
* And this condition says, we should have had or made enough progress
* So, this needs to happen and we need to have a clear shot, which is this condition, okay
* Is it beginning to look a little a little messy to be honest, but regardless of which, we are able to write it down and we know what all of these things are
* Now, this isn't quite work yet because right now, it's possible to avoid obstacles forever so we need some way of stopping this thing and the way to stop is, you know what, now this looks like a huge mess, right
* But this simply is the sliding condition for following walls in a clockwise direction so it's the same condition as up here
* But now, since I'm running out of space, I have to write it right on top of the arrow
* I also need the same resets that I had here so it's the same condition
* And similarly, if, well, first of all, this condition is satisfied, I do counterclockwise and I need to reset this distance again
* So, it's the same condition and the same reset as before
* so now, I basically have everything
* I just want to add one more thing and that's this
* If the distance to the actual goal is less than or equal to some epsilon, then I'm done and then I'm going to stop
* So, here is a rather messy looking hybrid automaton, but it is quite glorious in its mess because it allows us to get smooth performance, or guarantee the performance out while running in the smooth way
* And even though it looks hard, all of the things are inherently computable and it's actually not that complicated
* So, what I'm going to do is I'm going to take this thing that looks messy, shrink it down, and make it look even more messy, and say, this is our complete navigation system
* I think it is quite elegant, to be completely honest
* and now, its time to ask you know what, its elegant, we've done some math, we know that it works, so this we think so, does it really
* And here is the unfortunate answer to the question, does this work
* Nope, it doesn't, which is why you're now getting a little annoyed with me because I've spent all this time developing this framework and now I'm claiming it doesn't work
* the reason it doesn't work as is is there are all these practical considerations to take into account
* And what I'm going to do in the next lecture is actually, make it work so that it was worthwhile and we can take this little messy-looking hybrid automaton and print it out and turn it into a badge that we can put it on our clothes or wherever so we can be really proud of the fact that it does work
* but that is the topic of next lecture.


--- SKIP ---: 07_practical-considerations.en.srt


--- SKIP ---: 07_practical-considerations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_practical-considerations.en_SENTbySENT.txt
* The outcome of the last lecture was, in some sense, quite glorious
* We ended up with this beautiful hybrid atomaton that solves the general navigation problem
* And it had all these cool things in it
* Now, the problem is that, after we have solved the general navigation problem i said, but it doesn't work
* It was a kind of annoying to be completely honest and today I want to make it work by dealing with some of the practical considerations that we really have to, to think about
* the first is that we have this notion of XO everywhere
* Now, its hard to see, but this is the distance
* Or the point where the obstacle is
* Well, obstacles aren't points
* And it's not entirely, clear how we should translate these, real world obstacles that aren't points, into something that we can deal with here
* The other is what I call fat guards
* Here for instance, we're saying that the distance to the obstacle should be exactly equal to delta
* Well We're never going to be exactly = to delta, because sensors are noisy
* So what we need to do is, we need to say, you know what
* The distance is delta + -epsilon
* So we basically just need to just fact ta fi the guards, make them larger
* So that instead of switching exactly when we're at the distance delta, we're building some slack into the system
* [INAUDIBLE]
* And then, I have a third bullet here, that I'm calling tweak, tweak, tweak
* And the point with that one, is that, even if you have dealt with non point obstacles
* And we have fat a fi our goal, guards
* There are parameters
* There are things like, CGTG
* Which is the coefficient in front of the goal to goal behavior
* We have things like, delta and epsilons
* And there are all these Parameters that we have chosen
* That, mathematically, they're all fine
* But, in practice, there is no way out of the fact that you need to test, test, test, and tweak your parameters
* And this is, in some sense, why robotics is so hard
* And that's, how do you actually transition from your beautiful theoretical design, into something that works on the actual robots
* Well, lets start with obstacles that aren't points
* Green ball is the robot, red thingy is the obstacle, it's not a point
* Now the first thing to note is that almost all actual sensors they're really the return points
* Point [UNKNOWN], laser scaners, Infrared, ultrasonic sensors, all of them measure distances to things in certain directions
* So, here are the points that I'm actually detecting on this obstacle
* So now the question is, how do I actually deal with this situation
* Where I have not one obstacle, where I have one obstacle but for the purpose of robot these are let's see, 1, 2, 3, 4, 5, 6 obstacle points
* So, I have 6 points all of a sudden
* Then I somehow need to deal with
* So how do I do that
* Well, We have some options
* One options is, you know what
* I'm really not interested in driving into this obstacle, so, the point in my algorithm that I'm going to care about, is simply the closest obstacle
* In this case, it's this point, right
* So, I'm simply going to say that xo is there, that's actually not bad, it's not a bad idea at all and then this is supposed to be straight line
* you avoid obstacle would simply take me in this direction, just straight away from the closest point
* That's not bad at all
* But you know what, we have all this other information
* Why don't we take that information into account a little bit more
* So, another option would be to, weigh and add obstacle vectors together, depending on the distances
* Right so, here it's closer, so I'm going to get more in this direction
* And I'm kind fo far away so I'm going to get little in that direction
* And then I'm going to weigh these together and maybe, get something out like this
* That's better
* So, there are different ways of weighing them
* Let's say that I get these weighed or scaled obstacle vectors
* And then my obstacle avoidance is simply going to be some scaled version, or weighted and scaled version of that
* So this would be, U avoid obstacle now
* And what you now need to do, to find x obstacle which we need, is to backtrack this thing, and say that this point here, would be x o
* Now x o is not necessarily a point that we're measuring now
* It's the scaled and weighted version of the other points but, this is a much better way of Of doing.Now the last thing I should point out this you know what , you should weigh these things depending on the distance.But then you should also weigh depending on the direction of travel, [COUGH] excuse me and what do I mean by that.Well you know what, if I'm really on my way In this direction [NOISE]
* What do I care about obstacles behind me
* Why should I care about that
* I really shouldn't right
* So, what I really want to do is weigh it also based on the direction of travel and in that case I would get a weighted obstacle avoidance vector out like this
* So this is almost a I would say the best way of doing it
* And that's in fact how we're going to do it
* Now, the last thing I want to point out, though, you know, there's another option
* I should be able to collect all the points I'm getting, building a map of it, so here is the obstacle service
* And then, you know what
* Instead of just dealing with the questions, like you know, sliding, or snow sliding
* Maybe I can, plan my way around this obstacle
* Now, what I want to point out , this, in this class, we don't say things like most bestest, because it's grammatical nonsense
* we stay with grammatically correct things, which means that Ultra4 is out
* what I really want to say is that building maps is an entirely different type of topic, and all that we are learning in this class is still very much applicable
* So, I just want to point out that there are ways of building maps and then planning in those maps and then you're goal to goal behavior, for instance, wouldn't aim at the goal point but aim at following planned path based on these obstacle maps
* So want to point out option 4 but its really not part of what we're going to pursue in, in the class
* Now the last thing or did the second thing I said is we need to allow for fat guards and this is because no sensor is perfect, no actuator is perfect
* Robots aren't prefect, right
* So if I have this as my navigation hybrid automaton, when I'm doing f1 for some reason until g is negative, then I'm doing f2
* And then when g becomes positive I'm doing f1 again
* This is not sufficiently fat
* Because I may end up actually switching a lot, I may do C note for instance or I may not but, the point is that what I really should do is replace these guys with this, right
* Instead of saying G less than 0, I should say G less than negative epsilon
* And instead of saying g positive, I should say g greater than epsilon
* so Instead of having this as my switching surface, I'm actually building this little corridor here where I'm saying, I'm going to use f1 until I've gone through the entire corridor and so here's f1
* And then I'm going to use f2 until I've gone through that corridor
* And this factification not only reduces chattering but it also allows us to switch not when we're exactly delta away from an ob, obstacle but in somewhere delta plus minus epsilon
* So always build fat guards as a practical precaution against the fact that de, deployed real world is not as clean as the theoretical world on my powerpoint slides
* And then, like I said, the final advice, when it comes to practical considerations, is even though you have built a beautiful hybrid automotan, you've thought about everything, you have dealt with practical considerations and that you deal with point obstacles or non point obstacles as susceptible points since [UNKNOWN]
* you are using sufficiently [UNKNOWN] guards, you still have to tweak, tweak, tweak
* You have to test these parameters
* You have to do it over and over again and Like I said, this is what makes robotics hard and why it's a little frustrating at times, but at the end of it, it's also what makes it satisfying when you get it right
* So what I'm going to do in the next lecture is not talk at you or to you at all
* Instead, what we are going to do is to actually going to build this system that we now have and tweak parameters until we are satisfied with our glorious, great, unifying navigation system.


--- SKIP ---: 08_lets-do-it.en.srt


--- SKIP ---: 08_lets-do-it.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_lets-do-it.en_SENTbySENT.txt
* So after all this work that we've gone through, we've seen how to design control systems, we've seen how to take different controllers and put them together in a hybrid navigation architecture
* We've seen how to deal with practical issues, like the fact that obstacles are indeed, not points, and that we're never going to be able to measure exactly where we are, so we need to factify the guards
* we have tweaked our parameters
* We're actually ready to do it for real
* So the presentation, or slide part of this lecture is very short
* It's this
* Enough talk
* Let's do it
* So now, we are indeed ready to, see all our hard work pay off by deploying these, rather elegant algorithms that we've developed on the actual robots
* And as always, I'm here with, J
* P
* DeLacroix/g, and we are going to, take our old friend, the computer, differential drive mobile robot, through a series of
* Obstacle courses where the obstacles become become more and more complicated and as you can see, the first set up is a convex/g obstacle
* We saw in the lecture that in theory, the robot can actually get stuck in one of these local minimum where the goal to goal and obstacle avoidance behaviors will cancel each other out
* In practice, for an obstacle of this size, that ain't going to happen
* Because the world is indeed a noisy place and
* The noise will always kick the robot out of these particular local minima
* So, what we're going to see first is goal-to-goal and avoid obstacles and together that should be enough to have the robot navigate this single convex obstacle
* So as we can see the robot starts in a go-to-goal behavior
* It approaches the obstacle, and there, the infrared sensors picks up the obstacle, and the robot successfully navigates around it
* Now
* It's safe to go back to go-to-goal, and as we can see, the robot successfully managed to navigate this particularly simple environment with only two behaviors
* So now, let's take our two favorite behaviors, go-to-goal and avoid obstacle, and set them up to fail
* As we saw in the lectures, there's really no way for these two behaviors to successfully negotiate a
* Non-convex, obstacle
* In this case we have a cul-de-sac that we will try to get around using onlt these two behaviors, but we are not, to be completely honet, honest, expecting this to go all that well
* So, the robot starts out in a go to-go mode and it is entering the cul-de-sac, and it's going to start avoiding the obstacles here, but it doesn't quite know where to go, because
* It's pulled away, but the goal to goal is pulling it forward and the poor robot is completely confused and really has no of punching its way out of this cul da sac with only two behaviors
* And as we can see the end result is somewhat disastrous
* So that was rather depressing
* The poor robot was stuck in the cul de sac without really anywhere to go and obstacle avoidance and going to go and kept pulling it in different directions and it ended with a mild disaster
* We have now seen in the lectures that the way around this problem is really to introduce a third behavior, induced mode Follow-wall, which will allow the robot to purposefully make its way out of the culdesac and once it has a clear shot to the goal, and sufficient for forward progress has been made follow-wall will be released and go-to-goal will again take over
* So JP, let's see the grand finale here, with the full blown hybrid navigation architecture in
* Action
* The robot starts out, again, in a go-to-goal mode, and enters the culdesac, and what's going to be different now, is the obstacle avoidance is going to be replaced by a follow-wall, and the robot purposefully makes its way out of the culdesac along one of the obstacle arms
* And, as you can see
* The problems we had before with the confusion
* And being pulled back and forth between the 2 different behaviors, is no longer there
* now the robot has successfully navigated around the obstruction
* And is back into the goal to goal behavior.


--- SKIP ---: 09_glue-lecture-6.en.srt


--- SKIP ---: 09_glue-lecture-6.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_glue-lecture-6.en_SENTbySENT.txt
* Hello and welcome to Glue Lecture 6.Today's lecture should kind of walk you through a little bit of this idea of howrobots are going to behave using the framework introduced in Module 6 this weekin Dr Edgersett's lecture
* So hopefully it'll help you with Quiz 6.So this week in lecture, Dr Edgersett introduced this kind of scary lookinghybrid automaton that has lots of complicated guard conditions.And today we're just kind of going to break through those and sort of show youhow we might move through this automaton as we try to navigate towards a goal.So we have these behaviors
* Go to goal, this is actually a controller,you go to goal, follow wall, navigating around the obstacle counterclockwise.Avoid obstacle and follow the wall of the obstacle navigating in the clockwisedirection
* So, we're going to answer this question,what does this look like on a robot
* So in our little set up we have some robothere
* He has a heading, given by this blackarrow
* We have our obstacle in red.Around this obstacle I've drawn a, a line in grey that represents this deltadistance away from the obstacle at which we need to switch to avoid obstacles whenwe get inside
* And then here, the little orange star isour goal
* So now, where does the robot wake up interms of this high level description of the control?So this, this first arrow points right here into u, u go to goal, which means thego to goal controller will be running right when the robot wakes up.So this is the behavior we start with
* So what does this look like in ourscenario
* We have this vector here drawn in red.It points to our goal
* And this is the direction along which u goto goal will drive us
* And remember that on the robot, kind of atthat lower level, we're thinking of these controllers with these equations.Right
* So our go to goal controller is going tocause us to drive our current state x to this goal using some gain given in k.Likewise with the, with the avoid obstacle controller.And then with follow wall, we're just rotating the direction that you AO, avoidobstacle controller takes us and we're rotating that by 90 degrees depending onwhether we're going clockwise or counterclockwise which way the 90 degreesgoes
* And remember that's given by this rotationmatrix here
* So, if you see something like, you knowwhere you have, say 0,1,1,0, notice that this could be a rotation matrix.You know, there might be some theta that satisfies what this matrix looks like thatmeans that this matrix is causing a rotation of a vector.Anytime you see kind of, of a symmetrical structure like this in a, in a matrix, sayon Quiz 6, keep that in mind
* And remember that our robot isimplementing this, this, controller up here U in terms of VNW and our actuatorwheel commands
* And we know how to go with, between VNWand the wheel commands back in Module 2, that's where we learned that.So, while we have this high level kind of controlling automaton, there are theseother things going on kind of at the lower level on the robot.But for now we'll just think okay we know that the u go to goal is running, ourrobot is going to drive towards that star, directly towards it.So let's watch that as it happens, they're driving towards it and now .All of a sudden, we're at this point where, where within delta away from ourobstacle
* So let's go back to our automaton, and seeif that changes anything
* And indeed, two of the guard conditionsare that, when we're inside of this radius delta, we might have the condition wherewe need to change
* So let's look at the other half of both ofthose conditions, where
* We're looking at this inner productbetween these vectors defined by this, these control laws, the, the go to goalcontroller and the follow wall controller, both clockwise and counterclockwise.And this is really going to determine, once we're inside this delta range, do wefollow the obstacle clockwise or counterclockwise.And we were talking about vec-, vectors here in the Euclidean space.This, so we have our follow wall vector and our UA, avoid obstacle director this-- vector, this is the direction we would drive in if we were operating under thiscontroller or this controller or this controller.So now, how do we kind of decode this condition of this inner product?So with these, with these vectors in Euclidean space our dot, our inner productis just a dot product
* And so we can write it as the magnitudesof both of these vectors here, for example, with the clockwise follow wallcontroller
* And then the angle between those two guys.So, this is really the important term, right?Because this is going to vary between 1 and negative 1, in the following way.So if the two vectors are, are collinear, then the angle between them is 0.The cosine of that is 1
* So that would satisfy this condition,right
* When they're perpendirect, you know, exactperpendicular to each other, the cosine of that is 0.So we did not satisfy this condition
* And then of course, when they'recompletely open and the angle between them is pi, we get this negative 1 value.So we know that our vector is this cosine term is going to vary between these valuesand if it's 0 or negative 1, no matter what these magnitudes are, it's kind ofirrelevant
* So really, what we're worried about iswhen we're in between these two cases between 0 and 1 where this is going to begreater than 0
* So you can kind of see now directly fromthe picture in this case, my angle between the clockwise and the avoid obstacle is alittle bit smaller than between these two
* Right?Because these are going to add up to 180
* This one looks like a little bit less than90
* So that means we're going to follow thatclockwise rotation that way
* So we can see that these two conditionsare satisfied now
* And so we move from operating under the goto goal controller to now the clockwise follow wall.And at this point when this is true, we note the time detail because that's theimportant condition for whether we switch later given by this guy down here.So we note the, the detail what time it is or not, not what time it is but, how faraway we are at the goal
* Here at d tal, so we, we mark the distancefrom our goal at d tal
* And now we follow wall.So we're going to follow this new kind of pink vector.The robot's going to keep moving forward
* And now, we've actually gotten a littlebit closer to the goal, right
* So let's go back to that automaton.Let's look at the condition that might cause us here, we're in this state now.What might cause us to leave is if we get, within the distance delta.Well that's not going to happen, right
* Because we're following the wall.Or if we get closer to the goal than we were at time detail or at time tell so thedistance at time tell
* And then again this other inner productthat we need to consider
* So lets look at those two vectors now sohere we have follow wall, avoid obstacle, and go to goal.Now, we're interested in whether the cosine of the angle between these twovectors avoid obstacle and go to goal is between 90 and 0.And of course in this case we can see that that's more than ninety so we're going tostay with following wall because we don't satisfy both of the conditions to go backto go to goal
* So we continue to follow wall Continue tofollow wall and now, we're getting closer to that point where, now this angle hereis less than 90
* Our inner product between these twovectors is now greater than 0, and so we switch.These are our two conditions we needed to satisfy right, we switch back from followwall to go to goal
* We've made it all the way, and this iskind of where we're home free
* Because we're not going to encounter anymore obstacles
* But, if we did, we'd kind of go throughthat whole process again
* So you can see how this overall hybridautomaton switching our controllers
* We get to these, to this what we did,right
* This path around the obstacle.And it would make the goal
* So I hope that this helps you with some ofthe kind of high-level behavior questions you are going to have on quiz six thisweek and check the forums for more help
* And good luck.


--- SKIP ---: 10_programming-simulation-lecture-6.en.srt


--- SKIP ---: 10_programming-simulation-lecture-6.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_programming-simulation-lecture-6.en_SENTbySENT.txt
* Welcome to week six
* This week I'm going to be talking aboutfollowing walls
* Why do we need to follow walls
* Well, last week we solved the navi, we somehow seemed to solve the navigationproblem
* We had our robot drive from point A to point B without colliding with any of theobstacles
* But, the obstacles were fairly easy, and
* The reason for this is that they'reconvex
* But we can have these obstacles that areconcave in shape
* So, for example, take this U-shaped obstacle, and if arobot starts here and it's goal location is on the otherside of the obstacle, what will happen with thecontrollers that we designed last week is that the robot willdrive from here
* Into the obstacle, and then start avoidingthe obstacle, and then drive back into theobstacle
* Because it's always trying to get to thisside, but also avoiding this obstacle
* But it's trapped in here
* because the shape of the obstacle isconcave
* So what we need is an additionalcontroller, the follow-all controller, that will, so that when wemake a decision that we're inside of our concave obstacle,then we're going to follow the contour of the, the boundary ofthis object, and
* We're going to follow it all the wayaround until we've cleared it and then we can proceed ontothe goal location
* And that's, that's the objective for thisweek
* And the way that we'll do this is we're going to use the infrared sensors toapproximate a section of the wall, alright
* It's really an obstacle but we're going tocall it a wall
* And
* And once we've, once we've estimated asection, we're basically going to figure out a vector that'stangential to the wall
* And also one that's perpendicular to thewall
* And the point is to combine these twovectors into a single vector that will not only steer the robotinto,into one direction along
* The the, the, the contour of the, theboundary of the wall
* But also a vector that will make sure thatthe robot neither steers into, into the wall or awayfrom the wall
* So we're going to maintain some distancefrom the wall as we follow it
* Now
* How is the robot going to estimate thewall
* Well, first of all, one of the two inputsinto the controller is going, is going to be eitherleft or right
* So we are either going to follow a wallthats to our left or to our right
* So we have to make that decision before wedo anything else
* If we decide that we are going to use
* The left the left direction.What we're going to do, is we're going to use sensors one,two, and three on the robot
* So we're going to use these three sensors
* to, to estimate a wall that's the left, or an obstacle that's to the left of of therobot
* And
* What we'll do is we'll pick of these threewe're going to pick the two, that have theshortest infrared sensor readings
* And, we already know how to get a point,on these in the world frame
* So, what we end up is we end up with apoint so
* We have, this point right here which I'mgoing to denote as, point 1
* And, this is going to be point 2
* So, we've picked these two, and sincewe've picked two points in the world, we can come up with a vectorright
* So, we're going to come up with this greenvector right here
* And, this green vector is going to be ourvector that's tangential to the wall
* So I'm going to call this u, the vector u fw denotes that, this is for the followwall, and
* Comma T denotes that this is tangential tothe wall
* And really, the way that you define it is,it's p2 minus p1
* That's the definition of this, of thisvector
* Now, I also said that we want to maintainsome spacing from the wall
* So we're going to have to calculate a vector that's perpendicular
* And the way that we're going to calculateit is, again, we have the vector from theprevious slide
* We have u_fw_tp, and this time it has aprime mark, and that's because I'm going tonormali, normalize it, and
* Thus, and again, I think last week Italked about this is, what we're going to do is we're going to just take the vector, and divide it by itsmagnitude
* So that's the, that's the normalized version of the ofthat vector
* And what we'll do is we'll first take a point on this vector, which is going to beua, and
* This point, I'm just going to pick for, tomake it easy, I'm going to pick the first I'm going to pick the point detected bythis first infrared infrared sensor
* So, this one right here
* because I know this one I could alsopicked
* This one right here but I picked the firstone
* Now I'm also going to pick another pointwhich is going to be the location of the robot inthe world
* So that's going to be my point or vectorup, u sub p
* And since I again have but I have so, Ihave this point so I have
* Let me indicate that on the slide.I have this point right here, this point righthere, and this vector, and what I can do is I can compute the, a vector that pointsfrom the robot, so from the robot
* To this closest point on the wall
* And the, and the equation that describesthis vector is as follows
* It's this, so this vector, thisperpendicular vector I'm denoting by u sub fw, p
* And it's this subtraction of these pointsdotted
* With a dot product of, of the tangentialvector and then multiply it again by thetangential vector
* So this is just some linear algebra thatgives me a vector from the robot to the closest point on the wall, that's, that lies on the tangentialvector
* And, this is not sufficient for us tomaintain spacing yet
* What we really want to do, is we want tofind another vector that's goes in the opposite direction, and, and againfrom the previous slide I have thisperpendicular vector, so all I'm going to do is I'm going to normalize it and multiply it by somedistance fw
* So d sub fw
* And
* This distance right here is the distancethat we want to maintain between the robot andthe walls
* So we want the robot to end up in such away that this is equal to dfw
* So the reason that I define this vectorlike, like so is that when we can combine
* The two together
* If we combine these two vectors together,we're going to get a vector that either pointsus toward the wall if the robot is fartherthan d fw from the obstacle, or from the wall
* And we're going to get a vector thatpoints us
* Away from the, from the wall if we're closer than dsub fw
* So, that's the, that's the purpose ofgoing through, through these equations
* And really, what ends up happening is ifwe div if we
* Somehow linearly combine the, tangentialvector to the, to the wall
* And the perpendicular vector the, to the wall, that you know either points us towards or away depending on thedistance
* If we combine those in some way, we'regoing to get a, vector, u sub fw, which will both
* Point us in the direction in which thewall is going to, that allows us to follow the wall, and it also has thecomponent that either pushes us towards or away from the wall depending on how closeor far we are away from the obstacle, and this isexactly what we wanted
* And then the last thing that we have to dois we just have to use our good old PID controller to steer the robot inthe direction of this vector, and we're goodto go
* So how all does this work
* Well, you saw in the previous slides thatI got a really good estimate of, of, of the, of the, of asection of the wall
* But that's not always the case
* So, for example here on the inside corner,what I have here is this is the robot's estimate of, of the,of the wall
* And you can see that this is anoverestimate
* So, we're actually okay with that, becauseif we're overestimating the wall, that's, youknow, that's not really problematic because we're notgoing to
* We're going to avoid this, this virtualpiece of the wall and we're not going to slam intoit
* There's no danger of, real danger of that.But that is on, these inside corners
* On the outside corners we areunderestimating the wall
* So you can see here that the robot thinksthat this represents
* Is it a good representation of the wall
* And if we cut this corner too closely therobot collide with this part of the obstacle that it doesn'treally sense because there's a little bit of spread between the sensors becausewe don't have, you know, 20, 20 sensors on the robot that cover everysingle inch outside the robot
* We only have five sensors, so we got tomake, deal with what we have, so here we have to be a little careful, and that's where thedesign of this distance, d sub fw comes into play.So, you want to make sure that this, this, value is large enough to allow us to notcut corners and collide with the wall
* But also not too large so, so that wedon't lose track of the wall, because we don't want to endup too far away from the wall and then the robot doesn'tsense the wall anymore and we can no longerfollow it
* So, we want to kind of stick to the wallas close as possible, but not too close tocollide
* Now the implementation is going to happenin a new controller, FollowWall.m
* And you're going to have to implement somemissing logic and, and, and math that was covered in theprevious slides
* And ag, also again covered in the, in the manual in much greater detail.And
* As I said before the, what's, what'sreally unique about this controller its going to accept eitherleft or right denoting which side of, which side of therobot the wall is going to be in which its going tofollow
* So we're going to tell it you're going tohave to follow a wall that's going be on your left or we're going to tell you you're going tohave to follow an op a wall that's on your right
* And that those are going to be inputs andthose [INAUDIBLE], really come into play
* And next week when we have our fullnavigation algorithm and state machine going on
* So, let's see what this looks like in, inMATLAB and in the simulator
* I'll launch the simulator and hit Play
* And here, we have the robot, following thewall on it's left
* And as you can see here I got really,really close, to this corner
* So that was a little dangerous
* Maybe I should have picked a better, better distance to maintain from, from thewall
* And here we are overestimating so we'reokay
* And here we're going to cut it fairlyclose again
* So this is pretty, pretty much a littletoo close for comfort
* But, you know, we're not crashing intothe, into the obstacles
* So we're, we're, we're gon, we're okaywith that
* Alright.Great
* So, the robot's going to follow this wallon and on and on until I close this
* Now, again, make sure re-read the manual for weeks, that's been updated for weeksix
* It has a lot more details especially, youknow, for the math and, and has diagrams that willhelp you
* Implement the logic in all the math in inthe, in the controller
* And I encourage you to experiment withdifferent values of the distance to maintain from the wall
* So you'll see different results fordifferent distances that you pick
* And also you can decide how to combine thetwo vectors that are tangential and, and perpendicular, tothe, to the wall, and, and, and
* In different ways, so
* And it depends on where you want to putthe emphasis
* You might want to put the emphasisstrictly on following the law, on following the law, and not worry about maintaining adistance too much, or you could do the converse ofthat, it's really up to you
* And with that I wish you good luck.


--- SKIP ---: 01_approximations-and-abstractions.en.srt


--- SKIP ---: 01_approximations-and-abstractions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_approximations-and-abstractions.en_SENTbySENT.txt
* >> Welcome to the last module of thisentire course
* In this module, Module 7, I will beputting all of the pieces that we have developed together into one neat unifiedpackage
* And what we're going to have to do in thismodule is, connect the robotics piece that we discussed early on differential drive,mobile robots, odometry sensors to the control theoretic developments that we'vegone through
* And in particular, we need to see how wecan take the navigation algorithms we have developed, and actually make them fit ontothe actual robotic platforms that we're interested in.And the first lecture is really going to be a little bit of a high leveldiscussions of what are the things that we need to be aware of when we start puttingthings together
* I've call it approximations andabstractions and the reason for that is whenever we try to design control systemsor navigation algorithms, we're using models.And we need to understand when these models are indeed relevant or useful, orapplicable
* So, recall our rather messy, yet excitinghybrid automoton
* When we developed this, we assumed that wehad perfect sensing
* We even assumed that x dot was equal to u,meaning that we directly could control the velocities of, of the robot.But then, as we saw at the end of the last module, we ran it on a differential drivemobile robot
* And these two robot, or systems, theactual differential drive mobile robot and x dot equal to u, it's very unclear whatthey even have in common
* How do we make our models fit the reality,or more importantly, when are the models relevant to the real world?Well, I like to think of models as fables
* Let's return to our old friend, the hareand the tortoise
* So, when we discuss the Zeno phenomenon,we had the hare race the tortoise
* Well, I don't exactly know where all ofyou live but chances are that where you live, very rarely do you see hares andtortoises actually racing
* So, here's a story or a fable that neverapplies, but somehow, we still gain some kind of insight into the real world fromthis story
* Like, slow and steady wins the race if thetortoise wins
* Or, in the Zeno case, the hare is going towin
* Well, what we should take away from thatis, well, don't rush it when you're doing the quizzes for this course.So now, the hare and the tortoise actually had something to say about how we shouldapproach the course
* And similarly, the models are fables.They have some relevance, but they're not exactly telling the full story.So, let's take a step back and see what assumptions did we actually make and whatkind of models did we actually use when we were talking about the robots.Well, we really had two main classes of assumptions.One was the dynamics
* And when we developed our controlalgorithms, we made the assumption that we had this particle located at x, where weimmediately controlled the velocity, x dot is equal to u.Well, that may or may not be reasonable
* We also made this assumption that therobot has a sensor suite
* It's actually one of these sensor skirtsthat allows the robot to see roughly, a disk around it that's not exactly true,because as we saw in the last module, we only see certain parts of this disk.But from, in assumption point of view, we still kind of made the assumption that, wecannot, we can see everything around us up to a point and we can measure whereobstacles are and the angle to that obstacle.When it turns out that the sensing assumption is more or less okay.As the robot moves around, you can actually build up rather accurate modelsor, or maps of what's going on in the world.The problem is with the dynamics
* This is not even close to beingreasonable
* The Khepera [inaudible] that we've used alot, it's not, at all, looking like x dot is equal to u.So, in order for our fable, or our model, or our navigation algorithm to be relevantto the actual robot, we somehow need to remedy this lack of reasonability.So, the problem, of course, is that we have the point mass.And then we're using the unicycle model for actually describing the robot, where xdot is v cosine phi, where v is the speed and phi is the heading, y dot was v sinephi, and phi dot was equal to omega, where omega was the angular velocity.Well, this robot, this model, doesn't act like x dot is equal to u and somehow forwhat we've done during the last couple of modules to be relevant, we need to makethese two models actually co-exist peacefully.So, what we're going to spend the next two lectures on is a very, very simple problemwhich is, how do we make a unicycle robot or a differential drive model robot actlike x dot is equal to u?


--- SKIP ---: 02_a-layered-architecture.en.srt


--- SKIP ---: 02_a-layered-architecture.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_a-layered-architecture.en_SENTbySENT.txt
* We saw that the one remaining challenge is, how do we actually make our real robot or a model of the real robot, which was the unicyle model, behave or act like the simpler model x dot is equal to u, that we used when we designed our navigation architecture
* And we really have a problem because we used the simplest possible model, x dot equal to u, as the basis for our control design
* And then, we started switching between go to goal, follow wall, follow wall counterclockwise avoid obstacles and so forth
* And the navigation architecture we ended up with is this, as we've seen a couple of times now, rather messy-looking hybrid system
* Now, what we need to do is somehow come up with a way of making the real robot relevant or this model relevant to the real robot
* And we would like also to do this in such a way that we don't have to worry too much about what kind of robot is it that we're using
* We want this navigation architecture to be relevant for differential drive robots or 4-wheel robots or snake robots or flying quadrotors
* So, the question is, how do we do this
* And the standard way of approaching this problem is to produce a layered architecture, where you have different levels of abstraction
* So, in today's lecture, I'm going to talk about the standard layers that people think of when they build architectures high-level architectures for robotic systems
* Well, the standard and most canonical way in which people approach this is to have three levels and borrowing terms from the military tactical literature people typically talk about a strategic level and operational level and a tactical level
* So, the strategic level is high level
* Where do we go
* Recall, for instance, that we have go to golal behaviors, we have a goal point, well, where did that goal point come from
* Who decided that that's reasonable
* Well, that happens at the strategic level, where the high level decisions are being made
* And then at the operational level, you're trying to figure out, okay, I know that there is a goal point somewhere out there, where do I go now
* Meaning, this is a short term, low-level planning problem
* And in many ways, we can think of our x dot equal to u model to live at the operational level
* But then, we have the lowest level, the tactical level, which asks, well, okay, I know that I want to go this way but how do I actually do that
* I am snake robot, how does a snake go in this direction or I am a differential drive mobile robot, a unicycle, how do I actually go in this direction
* So, the question of mapping x dot equal to u onto the real robot is a question of moving in between these two levels or layers in the architecture
* While, if you want to be slightly less militaristic, which, maybe we do we can call the highest level a high-level planning level
* We want to plan where the intermediary goal points should really be
* And then, the low-level planning that's the question of which direction to move in-between these goal points
* And then at the execution level that we previously called the tactical level, it's just a matter of how do we actually execute this
* How do we make the robot do what it is that we want it to do
* And I should point out that the highest level, we haven't touched at all in this course
* In fact, we have assumed that someone very clever has designed a, an AI, artificial intelligence algorithm for somehow producing the correct goal points
* And then, at the low-level, well, that's where our navigation architecture sits
* That's where we're assuming that x dot is equal to u, which really tells the robot, if I'm here, this is x, then u is really going to be, this is the direction in which I would like to move
* So, the navigation architecture we've seen really sits squarely at the low-level planning layer
* And then, of course the execution level
* Well, one thing we can do is simply say, here is our actual system
* Let's say x dot is, oh, let's, let's say, it's a complicated nonlinear system
* This is a slithering robot, that every now and then, can fly
* I don't know how to build that, but if I did, that's what this system would be
* And now, I would like it to follow, let's say, this reference
* And this reference is generated as if x dot is equal to u
* Well, this is simply r, right, a reference signal
* And we have seen repeatedly how to design controllers for making systems, general systems, track reference signals
* So, the execution problem be, really becomes a question of how do you track reference signals
* Well, we kind of know how to do this, at least for linear systems, so that seems rather promising, as far as I can, I can tell
* Okay, let's discuss these levels a little bit more
* at the high-level, like I said, it's really not part of the, the course, there are many, many different ways in which people think about how to produce these high-level plans
* Typically, you somehow discretize the world into a graph structure or somehow, a kind of grid structure and then you can use Dijkstra's algorithm for searching through graphs, something called Dynamic Programming
* There are more specialized robotic planning algorithms, something called A*, a version of A* called D*, which is a dynamic version of A*, or something called RRTs, Rapidly Exploring Randomized Trees
* These are all methods for generating these intermediary waypoints
* And this big picture here, you're seeing underneath it is, this is the kind of maps that we produce at the high-level kind of plans and maps we produce at the high-level at, when we're building this autonomous self-driving car
* So, this map clearly doesn't tell us how the car should drive but it tells us where do we want to go and how are the things that we want to go to connect it
* So, all I want to say about this is if your'e interested in probing further when it comes to high-level methods this six different methods are good places to start if you want to to learn more about these high-level methods
* Okay, low-level, well, ta-da, we already know how to do this
* The simplest thing is to assume a very simple model, in our case, we've said x dot is equal to u, and then we simply go to work
* Again, if I do that, my model, x dot is equal u model, is going to produce a trajectory that we would like the actual robot to follow
* So, this trajectory becomes the plan, the low-level plan that will take us, let's say, that here is a, a goal point and here was an obstacle
* Well, this low-level plan will tell us how we should go about avoiding the obstacle and going to goal, but it doesn't at all tell us how to achieve it, which leaves us with the execution level
* as you can see, this is the video that I've shown before of our self-driving car that is trying to to drive around in the world
* Well, the car, it's not a unicycle, but it's almost a unicycle
* but, if we're trying to build a navigation system explicitly for a unicycle, it's not going to work, it's going to be too complex
* So, what we had to do in order to make this car actually drive, was well, plan at a high-level, then a low-level, and then make the car execute the trajectory
* So, for instance here, you're seeing the car overtaking an obstacle and what's going on here is that we have a low-level planner that's telling it roughly how to do it
* And as you can see, the car overshoots a little bit and this is due to the fact that the execution level reference trajectory isn't perfect
* Okay, so, what we've now arrived at is a layered architecture where at the highest level, we're generating sequences of intermediary waypoints
* Well, those waypoints are fed into the plan level or the low-level plan level where our navigation architecture generates reference trajectories
* Well, these reference trajectories are then fed into our actual nonlinear systems
* The actual dynamics were u now, well, it's going to be function of this state, and r, where r is the reference and then out of the trajectory comes the actual trajectory, the actual control signals that will be running on the robot
* So, what I want to do in the next lecture is take this high-level view of a layered architecture for robots and apply it to the [UNKNOWN] or 2-differential drive mobile robots, in general
* So that's it.


--- SKIP ---: 03_differential-drive-trackers.en.srt


--- SKIP ---: 03_differential-drive-trackers.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_differential-drive-trackers.en_SENTbySENT.txt
* In the last lecture, we saw that one way of overcoming this inherent or seeming tension between x.+u was a way of generating, references, and the actual robot dynamics was to introduce a layered architecture, where you had a planner that planned reference directories, and a tracker that tracked these reference directories
* What I want to do today, in today's lecture is, see how do we make, this, architecture concrete for the particular example of a differential drive wheeled mobile robot
* And if you recall, going back in time to module 2, a differential drive mobile robot has 2 wheels, and the wheel velocities can be independently controlled
* So we have v sub l for the left wheel, and v sub r for the right wheel
* And if, this robot is located at x,y and in this case it's heading straight up
* So this is the angel Phi then we saw that the dynamic for the differential drive mobile robot was given by this expression
* We also quickly realize that there was something
* Rather unintuitive about this
* It's hard to feel real velocities
* It's much easier to feel what' happening if you're, assuming that you can control the speed of the robot directly and the angler velocity meaning how quickly you're turning
* If you're doing that you instead get a unicycle model
* The differencial drive mobile robot, dynamics is not the unicycle dynamics but it's close, and infact module 2 part of the the things we did in that module was connection these 2 and we actually derived, derived this expression where the right and the left wheel volocities could be related to VE anomia directly meaning, the control signals we produce under the unicycle assumption can be directly mapped onto v sub r and v sub l
* And that's nice
* Because v and [INAUDIBLE] are intuitively clear about v sub r and v sub l are not
* So, the way we think about differential drive mobile robots is really in terms of unicycles
* And then, we make this final transformation onto the actual real velocities before resending the, the com the actuation commands
* So that's the model we have to deal with
* Well, if we now buy that we can use unicycles then, we really have already seen how to make the unicycle go in a desired direction
* So here is the unicycle model again
* Well I would like it to go in the direction phi sub d or phi desired
* Well, we actually saw early on that, why not use a PID regulator
* Well, if I let the error Between the desired angle and the actual angle, be given by E, and in particular, if you don't do E but you use arc tan 2 of sine phi [UNKNOWN] minus phi comma Cosine, the same thing
* Then you get something that's between -pi and pi, then you don't have to worry about the angles being, poorly behaved
* Well, if you use a PID regulator
* Then we've seen that this actually allows us to track this, reference direction, theta or phi sub d, rather elegantly
* And, as a recap, this is what the PID regulator looks like
* It looks rather hairy, but, we also saw how to implement it in a rather direct way
* So we know, already, how to track angles
* Well, all we need to do then is add in the speed component
* So, let's assume that the low level planner has given us a desired velocity, u, where we have assumed then, that x does equal to u
* Well, we have, actually, the unicycle, right
* And now, this vector, is actually the desired direction and magnitude, we want to move in, and, why not simply set that equal to u
* U is the desired velocity
* Well, if we do that, then we can start seeing, okay, how do we get, desired headings out, and what should our velocity be
* Well, it's very simple
* If we simply take arc tangents of u2 over u1, where u2 is the y component of u, and u1 is the x component, then that is the angle
* So phi desired, we get for free
* All that remains to be designed, then, is the velocity component, but hey check this out
* If I take the unicycle model and I take X dot squared plus Y dot squared and then I take the square root of this, I get This square root here
* Well, that is the square root of v^2 cosine squared phi plus sin^2 phi
* Well, this is one of the well-known trigonometric identities
* This is exactly equal to 1, so all I get is square root of v ^ 2
* Which is v itself
* So what I noticed is that, if I'm moving the unicycle around
* The magnitude of this vector in the direction I'm going with
* Well, that's v
* Well, but I know what the magnitude is of the u vector
* It's just the absolute value, or the, the norm of u
* So what this simply means, is
* You know what
* V should be equal to the norm of u
* Well, the norm of u is the square root of v1^2+u2^2
* So, I immediately know, not only which direction I would like to go in but how quickly I should go in that direction
* So, the way to build a tracker for the unicycle robot is simply to take arc tangents of u2 over u1 as the desired heading, and then let omega be equal to PID of e, where e is phi desired minus phi, and v be the magnitude of the u vector itself
* That's good news, because this gives us all we need
* Before, as before, we plan using our navigation algorithm
* Out of the navigation algorithm comes u1 and u2, the direction in which we would like to move
* Well, at the end of the day, the tracker needs to spit out V sub R and V sub L, which is derived from the left wheel velocities for the differential drive mobile robot, and now we know what to put inside a tracker block
* If I desire, the desired heading is the arc tangents of U2 over U1 Then we use a PID regulator, for instance, or some other regulator, for regulating the angle
* So omega = PID of phi desired - phi
* The velocity is simply the magnitude of the u vector, which we know how to compute now
* So, this gives us omega and v for the unicycle
* And then we take this and map it onto the left and right wheel velocities of the actual robot
* So this means that we can actually successfully use this layered arcitecture for our differential drive mobile robots, and this is the way we did it in the experiments that we saw In the previous module
* Now, for the unicycle
* There is an even more clever trick that is not involving layered architecture, but it's letting the unicycle really Act like x dot = u
* And in the next lecture, we will not use this PID based tracker, but this clever trick as a way of being eeven more elegant when handling differential drive mobile robots.


--- SKIP ---: 04_a-clever-trick.en.srt


--- SKIP ---: 04_a-clever-trick.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_a-clever-trick.en_SENTbySENT.txt
* The outcome of the last handful of lectures was that we can really use a layered architecture to make our robots act like a simpler system
* Like x dot = u, in our case
* And they key idea was to plan using the simple dynamics
* And then track using some clever controller
* And what we saw last time was we could use a PID regulator, for instance for, controlling the heading of the robot, and then simply set the velocity of the robot equal to the magnitude of the planned velocity, u
* Well, today, I want to discuss another twist to this theme
* In fact, I want to be even more clever
* And there is a particularly eloquent and cute way you can think about unicycles
* And in general I'm not a big fan of clever tricks for the sake of clever tricks, but because differential drive mobile robots are so common
* And we know that unicycles model them well, then this trick becomes more than just a piece of mathematical curiosity, becomes an effective way of thinking about a large, a large and rich class of mobile robots
* So, instead of doing tracking, we're going to transform the unicycle dynamics
* So recall that we have the position xy, we have the heading phi, and we have the dynamics as seen here
* Well, typically, what we've seen so far is, we want the robot not to slam into things, we want the robot to end up on top of goal points we want the robot to folow walls
* We don't particularly care which way it's pointing, so the first thing we're going to do is say, you know what let's just pretend that we don't worry about orientation whatsoever
* Well, we still have a rather awkward looking nonlinear differential equation but let, now, pick another point
* Let's not pick x, y, which as you remember, was really the point right in between the wheels of the differential-drive mobile robot
* What if we picked another point, instead
* Let's pick this point
* The red point here
* And let's say, that the distance between, the red point and the black point
* That's, that's some distance l, where l is some small number
* What would happen if we looked at this new point, instead
* Well, let's place the new point at x tilde y tilde The next tilde is simply x + l cosine phi
* Simple geometry
* And y tilde is y + l sine phi
* Where, again, l is the distance removing our point along the heading of, of the robot
* Well, let's see what the dynamics of this new point
* The tilde point actually looks like
* Well, this is our old dynamics this how X and Y and phata actually behaves
* This is our new point and now, what we need to do is put dots over the tildes to see
* What do the time derivatives actually look like
* Well, it's not so complicated
* X till the dot, well, it's x dot + the time derivative of this thing, and, the time derivative of cosine phi, and remember phi is a function of t, if I take ddt of this thing, then
* What I get, is, I get - phi dot * sin phi
* Well, that's what we have here, x tilde dot, is x dot - l phi dot sin phi, and similarly for y, tilde dot
* Alright, this still doesn't seem all that helpful, to be completely honest, so lets simplify this a little bit
* Well, first of all, I know what x dot is
* It's this thing here, so instead of that, I'm just plugging in v cosine phi
* I also know what phi dot is
* It's, it's omega
* So, now I end up with a slightly, less scary-looking expression
* And, then we do the same thing for y tilde dot
* Well okay, where does this lead us
* Well, let's assume for a second that we can control this new point directly
* That this new point is indeed, the point that we before have called x dot = to u, as a way of generating reference velocities
* Let's assume that we can actually immediately control this new point
* What would that tell us
* Well, x tilde dot as you recall, was given by this mouthful of an expression
* Well, let's set this equal to u1 which is our desired velocity in the x direction
* And similarly, we set y tilde dot = u2
* Now, all we need to do at least, well I can say all we need to do, I don't know if we can do it
* But, all we would like to do is actually solve this equation with respect to V and omega
* Because, if we did that, we would relate the actual velocities of the unicycle to these u1 and u2 velocities, which are The planned velocities
* So let's see if we can do that
* Well the first thing we do is we pull out the cosine and the sine terms
* So we get that cosine * v - sine * l omega well that's that thing, that's equal to u1
* And similarly for the y tilde dot, or the u2 dot, sorry, the u2 equation
* I don't know, this equation still looks a little hairy but, as you hopefully recall, this matrix right here is a rather nice matrix
* It is, in fact, a rotation matrix
* All it's doing is it's taking a vector and rotating it theta degrees
* Actually, it's rotating it phi degrees, but it is a very well behaved and well understood matrix, okay
* I don't particularly like l there, because l is not part of what I would like
* I would like v and omega and, no l
* So, what I can do, is I can rewrite this thing as, a matrix, a diagonal matrix, with one on the first diagonal, and l on the second diagonal, simply times v, and omega
* And if I do that, I get the following expression
* Rotation matrix phi, sorry, yeah, phi, * this matrix, v omega
* Well, these are all invertable
* What is the inverse of the rotation matrix
* Well, the rotation matrix rotates something phi degrees
* Well, the inverse would be to rotate it back, right
* Then you're back where you started
* That's -5
* So, R inverse phi always exists and it corresponds to rotating it back five degrees
* So, we can invert this matrix easily
* Well, this is a diagonal matrix, and the inverse of this thing is simply the inverse of the diagonal, 1 / 1 00 1 / l
* So the inverse of this thing is also trivial
* That means that I can actually solve directly for V and omega, no problem
* No questions asked, no tracking, no approximation, just bam, I get the right velocities out
* So if I have my low level plan producing U1 and U2, then I can transform that into V and omega directly
* And this seems almost too good to be true, and it is too good to be true, because remember We're actually not making x y behave perfectly, we're making this new point that we call x tilde y tilde, we're making that point behave perfectly
* And then we have l, that tells us how far away we are, and by making l small, we're getting closer to x and y, so you practice
* You pick l tiny and then you go to work
* So what does this mean, it means that before we had a planner we used our complicated navigation algorithm to spid out u1 and u2 all right and then we had a tracker and in our case we use the PID tracker for the heading and simply set the velocity equal to the magnitude of u and from that we got v and omega out
* Well now, we don't have to deal with trackers
* We've actually replaced second part with a transformation of the unicycle where we're simply saying that V and omega, or these 2 matrices * u1, u2
* And again, these matrices are, not particularly complicated to compute
* This, is simply the rotation matrix and phi of course we have
* This is one, easy to compute, it's just one
* And ;; is something that we decide, so what we put here, this is 1 / l, l should be small so 1 / l should be some large number, right
* And the larger this number becomes the closer the tilde the point and the actual point approach each other
* I should put out a little warning though that if you make this number too large, then you get a behavior where the robot starts turning quite a bit, because this going to hit omega directly
* Okay but, this gives us a direct transformation, instead of a tracker, to produce the desired velocities
* And the reason why I like this trick, and why this trick shouldn't be thought of as simply, an interesting little curiosity because it is kind of interesting is that so many robots are differential drive robots, and this transformation applies to all of them, because all of them can be mapped onto the unicycle dynamics
* So, that takes care of, how do we actually go from low-level plans
* To executable, desired velocities for differential drive mobile robots.


--- SKIP ---: 05_other-robot-classes.en.srt


--- SKIP ---: 05_other-robot-classes.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_other-robot-classes.en_SENTbySENT.txt
* The punch line with last lecture was that we can, in fact, make the unicycle model or a differential drive mobile robot, act like a simple x dot equal to u
* What this means is that if we have some desired direction we want to go in, direction and magnitude, we can come up with v's and omega's, speeds and angular velocities that make the differential drive robot execute this controller
* And we did it in two ways
* First, we saw that we can actually use some kind of tracking controller to follow this
* But then, in last lecture, we came up with a rather clever transformation that allowed us to, to actually track this u vector more or less perfectly
* And when I say more or less, what I mean is that we really ignored orientation
* So, we only cared about where the robot actually was, not particularly which direction it was pointing
* And we couldn't track or used the original point, we had to accept this small offset error
* But it was rather elegant, because no longer did we have to design trackers
* the question one should ask then, of course, is does this apply to other types of robots
* Meaning, this idea of starting with a unicycle and then somehow making it behave well, how, how relevant is that to other kinds of robots
* So, we have dealt with the differential drive robots
* We know that it's super important in relevance to that but you know what, what if you have flying things
* What if you have snake bots
* What if you have, this is called a snake board, what if you have fixed-wing aircrafts or blimps or underwater robots
* Does this even apply
* Well, what I want to do today is basically see that it does supply but, it does supply if you squint your eyes a little bit and focus on what these types of robots have in common as opposed to what they don't have in common
* So, what I want to do today is simply go through a smorgasbord of different robot classes and see how they actually are like unicycles or maybe not
* We'll see
* Okay
* Here's the unicycle, right
* We have, as always, position, x y, and it's pointing in some direction, phi, this is the standard robot model
* So, the states are position and orientation
* The inputs to this model, this abstraction, are angular and transalational velocitiies
* Meaning, how quickly do you turn and how fast do you go
* Well, let's start expanding this model to encompass slightly more elaborate systems
* So, let's start with what's called a car-like robot
* A car-like robot is not a unicycle because all of a sudden, we have more states
* We have our old friends which is x and y, which is the position
* We have phi which is the orientation, but then we also have a new angle known as the steering angle
* So, here is the picture we should have in mind
* Here's a car, here are the rear wheels
* Well, the front wheels are going to be turned because we're turning the steering wheel
* So, if I call this point here, x and y, as always, then this, of course, is, as before, the heading
* And now, we also have this angle here, which is psi, known as the steering angle, how much are we actually steering it
* And all I wanted to show here is that we have almost the same equation for x and y, the only difference is that we are now going in this direction, which is phi plus psi
* and then, the orientation has its own dynamics that's a function of the velocity and the steering angle
* And then, what we can do is we can control how quickly we're steering
* So, psi dot is equal to u
* So, this is the next level up in complexity where we no longer have a unicycle but a car-like robot, four wheels we can turn the front wheels
* Well we've already seen the Segway robot
* So, the Segway robot is really a unicycle or a differential drive robot at the base
* And then, you know, this, this mess here
* I drew it like this because it actually didn't fit in the box if I didn't make it small and sideways
* The point is that, we had a rather complicated equation describing the pendulum part or the part that's sitting on top of the unicycle
* So, we had a bunch of states, position, orientation, tilt, angle, and here, we actually had to deal with the tilt velocities and other kinds of velocities because we actually need to get into dynamics
* Many accelerations of what's happening for this thing not to fall over and the inputs were the wheel torques to this model
* The point now is that this still has a unicycle underneath and then this mass sitting on top of it
* So, that would, would be the Segway robot that we actually already seen
* Well, what about flying things
* Well, a standard model for a fixed-wing aircraft is ta-da, a unicycle, right
* Which means, it's moving
* And then, it can change altitude
* So now, no one in their right mind would actually say that this is what a, an aircraft is actually doing but from a high level obstruction point of view, it's not a bad idea
* An aircraft can't go sideways but it can kind of move like a unicyle in, in the plane
* And then, you can change altitude
* now, you would actually have to couple this to the real dynamics of the aircraft if you wanted to do it for real
* the one thing to note though is that there is something slightly fishy about this and that's the fact that the fixed wing aircraft cannot hover
* When you can't have v=0, but there's really no constraint or no way of capturing this in, this model, we see later how to do it, but the point here is that there are ways of thinking about flying things as unicycles plus an altitude component
* Now, let's look at another model
* This is the standard model of an underwater glider, and, well, let's go back a slide
* Aircraft, underwater glider, nothing changed, right
* So, an underwater glider, people typically model as a unicycle
* And then, you can go up and down
* So, you can go down to a lower depth or you could climb up towards the surface
* So, again, unicycle plus an altitude or a vertical component that describes how high up or high down the, the robot actually is
* Well, all of these robots have some notion of where it is at least in the plane and where it's pointing
* And if I call position plus heading for POSE, the punchline, at least based on the models I showed you, cars, segways, flying things, things on the water, and as we know, differential drive robots, they have this key thing to it known as POSE
* And POSE is x, y, and phi
* You know, that's just, that's just what's going on, where is it and which way is it pointing
* It's pointing in the phi direction instead of the x and y
* Well, you know what, if you ignore the dynamics, the actual dynamics and say at the certain high level abstraction, we already know how we should think about this, the unicycle
* So, almost everything involves a POSE
* And almost everything with POSE is almost a unicycle and I will make this more precise
* But the point here is that whenever you start dealing with postion and heading, the unicycle model is applicable, maybe not perfectly, but fairly well
* So, this model is still very, very rich
* So, the punchline then becomes that we can almost use everything that we've already done and then possibly add another layer to to what's going on
* So, what you have, is you have, let's say, your, your u plan, right, that comes into your unit cycle, and out of that comes our old friends, v and omega, and then, whatever actual robot you have is going to move like this
* [SOUND] And the point is that, in here, we may be forced to somehow make the actual robot look like a unicycle a little bit
* But it's just another layer to our already elegant and well-layered architecture that we've discussed
* And, in fact, next time, what I want to do is exactly this for the car robot, to see how do you make a car act like a unicycle and this is something I had to do when I was dealing with the autonomous self-driving cars
* We were reasoning about them at the level of position and orientation and speeds and angular velocities but then we have to map it back onto the, onto the, the car robot
* Before we do that though, I need to talk a little bit about constraints
* What I mean, mean by that is if you're flying, for instance, you can't hover
* You're going to have a certain minimum velocity or a lot of times, it's convenient to assume a fixed velocity and then you can turn
* But here's an aircraft
* It can't immediately or very quickly just spin either
* So, there are caps on how quickly you can actually turn
* Well, the most famous of all constrained unicycle type models is known as Dubins vehicle
* And all it is is a unicycle with the added caveat that we can only fly with v=1 or drive with v=1, meaning we're going to go with a constant velocity and we have a max and a minimum angular velocity
* If you want, you can say, you know, v0 there and omega v max or omega max plus omega max instead of -1 and 1, but the point is that we're constraining the velocities
* This means, that Dubins vehicle can basically execute straight lines, it can go along paths like this so, so it can go along angles, I mean, along circular arcs
* Or it can go anything in between, right
* But basically, you have, you cannot go arbitrarily tight with a Dubins vehicle
* So, this is one way in which people incorporate constraints
* And this makes the planning part significantly harder
* We're not going to cover it, but I encourage you to look up Dubins vehicles, for instance, to see how people think about curvature constrained versions of unicycles, for instance
* Well, another version or another standard constraint that people deal with is what's known as the Reeds-Shepp model, where omega again, is between -1 and 1, or negative omega max and omega max, and v can now be, well, the absolute value of v is 1, which means that v is either +1 or -1, meaning it's a Dubins vehicle that can also go backwards
* That's all that this means
* You can go forward along these arcs or you can actually pull back in in reverse
* And Reeds-Shepp is also a standard type of model that people like to deal with when they're dealing with mobile robots
* Now, aircrafts typically can't back so it's not a par, all that relevant of a model for fixed wind aircraft, for instance
* But there are, for instance, robots, at the end of the day, we have a top speed, for instance, so we can't go faster than v=vmax, so, but we can indeed go backwards
* So, the Reeds-Shepp model would not be a bad model if you actually want to take max velocities into account
* So, remember that this may or may not come into play
* The last thing I want to say though is that there are, of course, robots where POSE is not a reasonable way of describing them
* You know, you have a humanoid, well, people will have maybe a position and orientation but there is so much more going on in a humanoid
* A snake, you know, which way is the snake pointing, well, you know, if the snake looks like this, what's, what's the orientation of the snake
* It's very unclear
* What's the position of the snake
* Who knows
* It's not clear what we mean by that
* same thing, we would like mobile manipulators like this robots that we have here at Georgia Tech, where, well, the base is a unicycle
* So, if you only care about the base, fine
* But if you want to do more things like carry things around or opening doors and so forth, we have to care about more than the just the POSE, more than just position and orientation
* So, there are situations where we have to worry about more things, but in a surprising amount of situations, POSE is indeed the way to go
* And like I said, the next lecture will be about cars and how to actually make a car behave like a unicycle.


--- SKIP ---: 06_car-like-robots.en.srt


--- SKIP ---: 06_car-like-robots.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_car-like-robots.en_SENTbySENT.txt
* The punchline with the previous lecture was the POS, meaning position and heading, is central in a lot of different situations
* and we made the claim that, other POS-based models, like cars or underwater gliders, or other kinds of autonomous vehicles, can be made to look like a unicycle
* Today, I want to make this observation precise and concrete by looking at the car-like robots
* So, for instance, there's a picture of our autonomous car out of Georgia Tech
* And the question is, how do we make this thing look like a unicycle
* Well, the first thing we need is a model
* And the standard car kinematics is to add another state to the system, which is the steering handle
* So here is the picture that we have in mind
* The, the rear wheel wheels are just pointing in whatever direction the car is going which it or the car is facing, which is the orientation phi
* The position of the car, well, we're going to take this point which is in the middle in between the front wheels
* And this distance here is going to be l
* So, the rear wheels are l away from the front wheels
* And then, we have this angle which we're going to call psi
* So, what we're actually going to end up doing is moving the car in this direction
* And the direction then is psi+phi
* So, if we make this observation into a model, we first see that the states are x, y, phi, and psi steering angle
* The inputs now that we're going to have are, as before, the speed
* How quickly is the car going
* And, how fast are we turning the steering wheel
* I'm going to call this sigma
* Angular steering velocity, or steering angle velocity
* The model then becomes, well, x-dot and v-dot is as before v cosin and then the direction we're going in
* But the direction we're going in is now psi+phi
* Then, we have an equation that relates the steering angle and the velocity to the heading of the car
* And then, the last component is that we can immediately influence the velocity of the steering angle, so how quickly are we turning the, the wheel
* Okay, good
* Now, what we're going to do is pick sigma and v in a clever enough way to make this thing become a unicycle
* Well, let's start then with the unicycle itself
* So, this is our car model
* Well, let's start with our unicycle model and do something called curvature control
* So, what this means is that if I want to drive along a particular circular arc, let's say that the radius of the arc is raw
* And here's the car, it's going, sorry, the unicycle it's going, do, do, do, do, do, right
* This is the direction in which it's going so the orientation in the unicycle, this angle is just phi
* Well, here's alpha and simple geometry tells me that alpha is just phi minus pi over 2
* Okay
* If I'm describing how this thing is evolving along a circular arc, then I get, for instance, that the x position is simply, let's say that the center of the circle is x0, y0
* Then, x is simply x0 + rho cosine alpha
* But because alpha is phi minus pi over 2, I can write this is x dot plus rho sine alpha, thanls to one of my favorite trigonometric identities
* Well, if I take the derivative of this with respect to time, I get that, well, this thing the derivative of that is zero
* The time derivative of this, phi dot is equal to omega
* So, my x dot becomes omega rho cosine phi
* But, wait a second
* I know what x dot is, it's v cosine phi because it's a unicycle
* So now, these two expressions have to be the same
* Which means that the radius of the circle is v over omega
* Now, a lot of times, we care about what's called curvature
* And curvature is 1 over the radius
* So, the curvature is simply 1 over rho
* Which means that the curvature I would get if I have omega and v, well, it's omega over v
* So, the bigger the omega is, the tighter the circle, meaning the higher the curvature
* If omega is zero, I'm going at a, in a straight line and the curvature is zero
* So, this is the curvature of a unicycle
* Okay
* Let's figure what the curvature is when we have a car
* The only difference now is that the you, the car is actually pointing in this direction but it's going in this direction because of the fact we have a steering angle
* So, as before, alpha, this angle where we wanted to say where the car is, is, well, it's phi plus psi minus pi over 2
* So, we're doing exactly what we did before
* x is x0 plus rho where rho is the radius of the circle, sine phi plus psi
* Taking the derivative, we get x dot is rho phi plus psi cosine phi plus psi
* Now, let's assume that we're driving on a circle
* This means that we're going to hold the steering wheel fixed
* Which means that this term is going to be equal to zero because we're not changing the steering angel, right
* So, we know that psi dot is zero
* Well, we also have the equation for phi dot, it looks like v/l sine phi, sorry, psi, v/l sine psi
* And, we also know that x dot should be equal to this expression
* So, what do we do
* Well, we simply now line up v here and rho phi dot there to get the curvature
* Sorry, to get the radius of the circle
* So, this becomes l divided by sine psi
* And now, we invert this to get the curvature
* So, the curvature becomes sine psi over l where psi is this fixed steering angle we're driving
* Okay
* Then, we have curvature for the unicycle, this thing
* Curvature for the car, that thing
* Well, we just put them equal, right
* Why not
* If we put them equal, then we immediately get that sine psi should be equal to omega l/v
* So this is the steering angle we, if I have a unicycle that's driving at omega and v, then this is what the steering angle should be to get the same behavior out
* Which also means that my psi then should be arcsin of, well, omega l/v
* Well, I can't set psi directly
* So, what I need to do is say that this is my desired steering angle
* And then, I somehow need to make my actual steering angle become close to my desired steering angle
* That's the name of the game here, right
* So when we get these arcsin, or arcsine sorry
* psi d is arc sinus of omega l/v
* Okay
* Now, arcsin is a little bit of an annoying thing to have to do
* So instead, we're not going to do that
* So, let's say that I have this thing and I would like d to be close to it
* Well, one thing I can do is a simple P-Regulator, which is something you've seen
* But this thing involves this arcsin and one thing to note is what happen if actually keep sinus in there while we would get something kind of cleaner, right
* So, let's get rid of it and simply say that instead of psi here, I'm going to do sine of psi
* And instead of omega d then, I'm going to do sine omega d
* So, I keep saying omega, I mean psi, sin psi d, which we know is omega l over v, which goes in there, right
* So, we keep the sinuses in there instead of taking arcsin
* And the reason for that is that for small enough angles this is, this is roughly equal to the angle itself
* So, sinus is, is not a bad thing to do
* well, let's see if this works
* So over on the left there, you see the unicycle, and over on the right you see the car
* And the unicycle has some omega and v, and the car is running the sinus version of P-Regulator
* And, as you can see, they're pretty close, which means that we can basically do the same kind of curvature control on the car as we can do on the unicycle
* So, the moral of the story with this is, you know what
* We're planning
* We're getting some direction we want to move in
* Here is my direction I want to move in
* Well, we know the clever trick
* The trick, right
* The trick gives us v and omega, which is what are the speeds and angular velocities we would like
* We now also know that the curvature is omega over v
* So, if you give me v and omega, I can tell you what the curvature is going to look like
* Well, let's use this curvature idea to make the car track the unicycle which gives us v and sigma
* And, of course, this v is the same as that v
* So, we don't have to do anything about it
* The only thing we have to do, is to add what sigma should actually be
* And this, ladies and gentlemen, allows us to make the car act like a unicycle simply by using this curvature idea
* And this generalizes to other types of unicycle like systems where POS, again, is really important.


--- SKIP ---: 07_to-probe-further.en.srt


--- SKIP ---: 07_to-probe-further.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_to-probe-further.en_SENTbySENT.txt
* We are now extremely close to the end of this entire course and I'm actually done, believe it or not, with the technical part
* The grand finale was really this idea that we could even make complicated systems like cars act like unicycles that we now know how to control and navigate around in complex environments as we've seen both in theory In simulation, and actually in real experiments
* What I want to do in this sub-lecture is basically probe further
* There are lot's of things, believe it or not, that are actually not in this course, pretaining to other control robots
* Here I have a picture of a praying mantis and the reason for that is that, we have not covered praying mantises
* So I'm going to let this be a proxy for all the things we haven't talked about
* Well one thing that we haven't talked about is, what happens when your system is generally non-linear instead of linear
* So we are now really, really good at dealing with linear control system
* Well, what if it is linear, non-linear
* Well we have dealt with some, we've dealt with the unicycle quite a bit, but there we were kind of lucky that we had a lot of intuition
* What if this is not the unicycle
* What if this is massively non-linear, and strange, and complicated
* What do we actually do
* Well, that's called nominal control and it's not in this course but I encourage you to keep educating yourself and probing further along these lines
* another thing that we didn't deal with is what is called optimal control
* So for us, the name of the game was stability
* Stability, it was performance in the sense of tracking, right, so we want it to track reference signals, and then we had robustness, but what we didn't have, explicitly, were things like this
* So this is a general, type of cost, where we're saying, well we want to minimize some cost involving x and u
* This could be, you know, the fuel consumed, or the time it takes to get there, plus possibly some cost on the final point as well
* This is known as optimal control, and this was also not, in the course
* So this was one grasshopper that we didn't see
* There is another branch of decision theory known as Machine Learning that we didn't touch upon
* The reason why I am putting this as a another thing that you might want to probe further along is it's useful in robotics and it's highly related to control in general and optimal control in particular
* So the idea is that
* I'm going to have some costs V and I'm going to have some policy pie which says what are you going to do when you're at the certain state
* And the cost is just going to be a cost of the different, where I am at time k and what I'm doing at time k
* So this is really U sub k, right
* And now I'm going to sum up this entire cost and if you do that you can write down
* Something known as Bellman's Optimality Equation or Bellman's equation, that basically characterizes what is the smallest you can make this cost while it satisfies this kind of weird looking expression
* And the point here is not the math, the point is that we have this equation, and machine learning is all about finding this V* by exploring
* If I'm at this position, let's try doing u4
* if I'm in another position, let's try doing u9
* And while doing this, you're building up this a, this V* cost function
* And when you're done building it up, you all of the sudden have a complete map or guide to what should you do
* If you encounter a certain state, and that's in a nutshell what machine learning is about
* Another thing that we didn't do much with is perception and mapping
* We had infrared or ultrasonic range sensors, but a lot of times
* We have those
* We have laser scanners
* We have cameras
* We did not deal with complicated sensing modalities and we did also not deal with, okay what do we do with all these sensor data
* How do we actually produce maps of the world
* Our world was, here is the, the robot
* Here is an obstacle
* It's a point
* Let's just avoid it
* But you know what
* This obstacle may not be a point it may be part of, I don't know, a corridor, and we would like to go in the corridor
* Well then it's good to actually describe what the world looks like
* This is known as mapping
* And again, this is a perfect opportunity for you to probe further, trying to build maps of the world
* There are lots of different methods for doing it
* And finally, the thing that we didn't do at all either is really talk about the high level artificial intelligence
* So, how do you actually decide in the first place where you should be going
* We said, given a goal point, how do we go there
* But where did the goal coin, point come from
* Somehow, somewhere, someone is going to have to make decisions about what at the very high-level the robot should be doing
* And this falls Squarely under the domain of artificial intelligence
* Not covered in this course, I encourage you to probe further
* So, to conclude, there are things that we haven't done in this class
* There are lots of praying mantises that we didn't cover
* And those are good things for you to probe further
* And learn more about
* If you know all of it, you can build an awesome robotic system
* But, beyond that, there are also lots of things we don't know
* So here, Not only praying mantises, but other green creatures
* We have no idea what they look like
* We don't know if they exist, we don't know what they are
* It's the same with robotics
* There's a lot of stuff going on that we as a community don't know how to do yet
* So the last thing I want to do is give you the impression that this is a closed and complete case
* We know everything about robotics
* We don't
* So, not only in this course are there praying mantises, but outside of the course there are potential aliens that we still have not discovered.


--- SKIP ---: 08_in-conclusion.en.srt


--- SKIP ---: 08_in-conclusion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_in-conclusion.en_SENTbySENT.txt
* So, welcome to the last of the lectures
* I've had a great time, I hope you'velearned quite a bit
* What I want to do with this last lecture,is just wrap things up
* And the first thing I want to point outis, what really are the key things that I was hoping to get out of this course, or was hoping that you would get out of thecourse
* The first is, just learn in general how touse control theory to make robots move around
* And not just move but move elegantly, orsafely or effectively
* And in order to do this I want you to gohome, if you're already home, stay home
* And appreciate the value of systematicthinking and design
* Sure, you could have hacked together 60%of what we did in this course
* But once you push beyond simple things, you really have to do the theoryright in order for it to work
* And then, I'm hoping that some of youmanaged to bridge the theory-practice gap byactually not only doing the lectures and the quizzes, butalso, going through the simulation and experiments andbuilding your own robots
* And if I could wish for one thing, it isthat at the end of this course, you don't juststop being robot-Isis
* You use this as a stepping stone to go outand think abouut new and exciting ways in which you can userobots or program robots
* So have fun, and I want it to sparkfurther investigations
* So, let's talk a little bit about thepunchlines
* Punchline #1 is the model
* I've been using models all through thiscourse
* And the point is not that I love models
* It's you need a model in order to be able to designcontrol systems effectively
* Because, if I'm going to be able to saywhat this robot is going to do over time, I needsome way of predicting what it's going to do, andthe only way I can do a prediction is if I have amodel
* The other reason why we really need modelsis, well let's say you build a controller
* Well the only way of ensuring that thecontroller is actually sound and doing what it's supposed to be doing is to go back and analyze how the controllerinteracts with the system
* But the system is modeled using the model
* So that's where we really, really, reallyneed the model
* Now, we need the model to be rich enoughto be relevant
* Meaning it should describe somethingthat's going on in the real world, but, it has to be simple enough tobe useful
* You don't have to model everything
* You don't have to worry about frictionunless you're trying to go really, really high speedsfor instance
* It needs to be simple enough, enough to beuseful, and that's really key, and I talked aboutbananas versus non-bananas
* In the sense that, there are no linear models out there, or linear systems outthere
* Non bananas
* But, the world is filled with non-bananas, meaning non-linear systems, yet at thesame time, the linear model is rich enough to do alot of things
* So keep the bananas in mind, meaning makeit as simple as possible
* The other punchline is feedback
* We don't just say, okay robot, drive fortwo meters, make a left turn, and drive forfour meters
* No, instead we measure what the robot isdoing and adjust the control signal based on what the robotis actually doing
* And this is feedback
* And feedback is so important to controltheory
* In fact, it's important to life
* Our cells regulate what enzymes to expressbased on feedback
* Without it none of us would be here
* So, I want you always to think feedbackand there are somethings that we talked about whenwe're designing feedback controllers
* Stability is the most important thing
* If the system ain't stable it won't work.Then we talked about things like tracking, how do you make it follow areference path
* And robustness, how do we suppress noise,for instance
* And then, how do we actually designcontrollers
* Well, the key idea in control theory isstate feedback
* We design our controllers as if we had thefull state of the system
* Which we don't
* And then, we use observers to actuallyestimate the state
* And, thanks to this wonderful thing called the separation principle, wecan design the controllers as if we had the states, and then design our observers as away of getting an estimate of the state
* So that's punchline number 2
* Punchline number 3 is architectures, youreally have to do the design at different levels ofabstraction
* And we talked about three abstractionlayers, that's quite standard where you plan high level where you want to go, then yougenerates reference paths, and in this case we did that using linear models, and then you track those using non-linearmodels
* And in particular, we looked atdifferential-drive robots
* Now, this is not because, we just happenedto like differential-drive robots
* It's because the most robots out there areeither differential-drive robots, or they can be approximated withdifferential drive robots
* So this is a very, very good way of modeling the actualnon-linear dynamics in a way that's simple enough to actually, be ableto say something about it
* The fourth punchline, and this is the lastpunchline - is whatever, don't listen to me, thisfield is not done
* There is so much left to explore in thewonderful world of robotics
* So, just because I didn't cover it here it doesn't mean, it's not important, or italso doesn't mean that we know already how to do it
* So, I would like you to leave the course thinking that, you know what,there's a whole world of robotics out there, that not onlyis for me to discover, but for me to invent
* So the field is certainly not done yet
* And with that, I would like to say thankyou
* I've really enjoyed myself and I do need to point out the five people that havehelped make this possible.Which are all graduate students in my lab
* Greg Droge showed up, he was the Segwayman
* JP de la Croix has been the master ofceremonies throughout the course doing all therobotic experiments in the studio
* He's also been supporting the simulatorand without him, this course would have looked verydifferently
* Amy LaViers and Smriti Chopra have been providing the glue lectures,combining or connecting the lectures to the quizzes and Smriti has also tirelessly answeredall the questions on, on the forums
* And last, Rowland O'flaherty has beenworking on the hardware aspect
* Meaning, building the robots
* Showing you how you can actually buildyour own robot at a relatively low cost
* And then the last person, or persons, that I need to thank is really all of you
* I don't know exactly what you look like orwhere you are, but sometimes I like to imagine what you look like and when I feel that a lecture has goneparticularly well
* This is what I hope, it is
* People that are happy
* People that are learning robotics andpeople that are going out in the world, exploring anddiscovering new things
* Thank you.


--- SKIP ---: 09_glue-lecture-7.en.srt


--- SKIP ---: 09_glue-lecture-7.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_glue-lecture-7.en_SENTbySENT.txt
* Hi, and welcome to the Glue Lectures forcontrol of mobile robots
* This is the last Glue Lecture, GlueLecture 7
* And I really hope that you guys haveenjoyed the course and learned a lot of awesome things, aresuper excited about robotics
* I hope you are.So, this Glue Lecture is just going to be
* Basically the course in a nutshell in avery big nutshell, in the sense of a very broadoverview
* Basically what we think from a layman'sperspective is like the best thing you got out of the course, you know,really simple stuff
* Because your quiz is also going to kind ofgo over what you've done
* All this while etcetera
* So this is what the glue lecture is about.The first thing that I think was amazing about thisentire course is the fact that, you know, we saw how math can be related to motion.How we can actually visually see
* Equations turn into motion
* So if you guys remember here we have this pink ball that's moving happily in thiscorner, you know
* And from the new lectures and the coursewe saw that the motion of this ball can actually be described through equations or throughmath
* Not only can the motion be described, butwe can actually derive the motion
* Through something called a dynamicalmodel, or dynamical models in this case, we have this here,right
* Which is also math, and then from this wecan actually get how this ball is moving withtime, right
* So, this was an example we saw in the gluelectures
* Basically, you have a dynamical model that describes the velocity and where the ballwakes up at a particular time, and then kind offind out how the ball is going to change withrespect to time
* Really simple
* The whole point is that, you know, we all saw how math basically translates tomotion, which is great
* Then we also saw that okay, since thiscourse is about robots, right
* So we read a few dynamical models of the robots
* So this is the most common robot that isthere, basically, or that we deal with, atwo-wheel differential drive robot
* And we saw that, you know what, we canwrite the model of this guy through this equation here, orthrough the set of equations here
* Where you control the angular velocitiesof the right and left wheel of the robot, right
* And then we also saw that you can simplify the model even farther, and make it aunicycle robot, with just like one wheel, andbasically
* This figure here
* And you can control the velocity and theangular velocity of this simplified model
* The good thing about this was the factthat, you know what, this simplified model can beused for design
* And then we have a beautifultransformation on or relation basically between these two models that once wedesign our v and omega for the simplified model, we can just, youknow, put it on to the differential
* Rate model and and find out vr and vi togive to the robots, right
* And actually this week with Dr
* Edgarstedyou learned another even simpler model
* Not even a model but a simpler thingcalled x dot equal to u
* Basically where, you know, you don't even want to controllet's say the vel, linear velocity and theangular velocity
* Instead you just directly going tocontrol, you know, x dot
* Equal to u
* And, and then you learn this very nicetransformation that allows you to transform this x star equal to udirectly to your reason omegas
* Right
* So, now all of the sudden you don't even have to design your controller based onthis model
* You just design it based off this guyhere
* You know, map it back to v and omegamodel, map that back to your vr vm model, and you're reallygood to go, just excellent
* Another thing that you learned in this week's lecture was the car-like modelwhere you have a current, all you do is there is youinclude this steering angle psi
* Into your correlate model, and then you can even map that model onto the simplified model, and the simplified modelonto whatever
* So on and so forth
* You're good to go
* So this was how math translates to motion and basically what is a dynamical model,or
* How do we start with any robotics problemwe start with the model so this is what thatis
* okay
* This is one excellent thing
* The second thing that we learned in thecourse was systems, so now that we know how a model of a, you know robot oranything we want to control is
* Described through math.Now we want to influence it, right
* We want to control it.We want it to do certain things
* So that's when this whole idea of systemscomes in that okay, we're going to have an input, we'regoing to have an output
* And we're going to actually describe our system through these three matrices.A, B and C
* Again, something that we went overextensively in class
* And your system can now again, of course,be a robot, here it's a Capera robot, herethere's a humanoid
* Now robot
* Anything for which you can find your A, Band C matrices
* Now A matrix, just remember
* Is your model, which we just discussedright now, right?It's something that's given
* Something that's from the physics or frombasically the device
* B matrix is actually something that weconstruct, that describes the actuators
* Basically, what are the actuators on thismodel or on this robot, in particular, that we cancontrol
* And that information is encoded in the Bmatrix and then the C matrix of course is, what canwe measure
* Or what's the output
* Wha, what are the sensors on this robotfrom which we can get our output
* And together, A, B and C will make youmake the system
* Yeah.So that's awesome
* Right
* And this is extremely important becauseonce you have the model and now you have the system and now you have everything youneed to do cool things with the robot
* Which is precisely what the slide says
* We can make robots do basically anything.Well, not anything but
* You know, close enough
* And, in this lecture, or sorry, in thiscourse, basically what we saw was that, you knowwhat, once we have our model and then we createour system for the model A, B and C matrices,etcetera, then, we can in fact make sure that oursystem
* Robot, with, you know, sensors, actuators,and the, everything, does not blow up, does not end up doinganything random
* It stays stable
* And we also do this whole controllability,observability analysis, which is very important in order to makethe robot actually do anything
* Before you can even start talking aboutcontrolling the robot
* Etcetera
* You need to know that, you know, is itcontrollable, is it observable, do I in fact have the abilityto do all these things
* We did all this extensively in class
* Another very cool thing that we learnedwas this whole automata, our hybrid controls notion, youknow, that you can
* For a robot to do some task you can actually divide up this task into makesmall, small behaviors that the robot does and thenkind of mash all these behaviors together and intothis automata thing
* And then also we learned that once you dothis you know there are undesirable things like the zeno effect for instanceand how do you get rid of it
* And a lot of other things that we saw inthis course, right
* What is great though, was that we did allthis with math
* So, by the end of this course, you guyshave actually learned about differential equations, linear algebra, geometry, a lotof these awesome tools that
* Can you make you, you know, actually dosuch nice stuff with the robots visually
* Not only just in software simulation but you actually see it happening.You know, in front of you
* Which is great
* And on the same track if you can makerobots do anything
* These are two robots, the humanoid robotsin our lab
* The now and one guy is doing a cheerleading the team and the other one is doing a discodancing routine
* This is Emy Lavier's work when she was a grad student at George Dake, in our laband basically she has a command of this entire thing based of this course of, of hybridautomators etcetera
* Right in front of you guys we are actually making robots dance, which isgreat, right
* And, you can see more amazing videos andstuff about, you know, what a lab does or what the robots do on theGRITSLab YouTube Channel
* For more stuff, and anyway this is us signing off
* Me, Swati Chopra and the robots on behalfof Amy Leviers
* And good luck with quiz seven and the restof your lives
* And bye, bye
* [BLANK_AUDIO]


--- SKIP ---: 10_programming-simulation-lecture-7.en.srt


--- SKIP ---: 10_programming-simulation-lecture-7.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_programming-simulation-lecture-7.en_SENTbySENT.txt
* Hello and welcome to the seventh and finalprogramming and simulation lecture
* This week, the programming assignmentcomes to its grand finale, and we will have an ro, quickbot navigate to themost complicated environment yet
* And what makes this different From ournavigation, from from week five, is that we need toanswer three new questions this week
* And the first one is, we need to keep track of the progress that the robot ismaking
* Last in week five, I talked about thisproblem that the robot can get trapped inside ofan obstacle
* And if it does, it doesn't, it doesn'tknow that it's not making progress
* It's just going to try to keep going tothe, to the goal, and then it'll avoid the obstacle, try to get back to thegoal, and it'll go on and on
* It'll never make any progress to the, towards the goal
* So this week, we'll actually think about,is the robot making any progress
* And If robot is not making any progress,maybe we should, you know, use the controllerfrom week six
* And follow the wall either to the right orto the left
* So we're all have to make a decision notonly, do we now start following the wall but in whichdirection, right or, or to the left
* And finally
* We also need to again revisit our final[INAUDIBLE] finite state machine from week five because that one will no longer cutit for, for this week's obstacle course
* We're going to have to, to really thinkabout if we're in a certain state and certain eventbecomes true
* To which other states should we switch inorder to have the rogo, robot progress towards its ultimate goal,which is to reach the goal location
* And of course, don't collide with anyobstacles, because that would be bad for ourquickbot
* So, all of the implementation this weekwill happen in the supervisor, so we're only going to beworrying about one file this week
* And that's mainly because for the pastseven weeks or six weeks we've written all of the necessary controllers that,that we need to, to solve this problem
* And unlike the previous weeks I'm actually going to start off with the demo thisweek
* To show you what it looks like when itworks
* So Let's see it in action
* I'm going to go ahead and launch thesimulator and hit Play.And we're going to click on the robot and try to get it, oop, there we go.And what you see here is first of all the robot has Isnavigating out of this obstacle that it's trapped inside of and it's following thewall nicely, or the boundary of the obstaclenicely, and it's going to stick to the wall untilit decides, hey, I'm going to peel off and go towards the goal location, becausethe goal location is somewhere up around thisarea
* And you'll see the robot has made it
* And eh, in the next couple slides, I'll goover exactly what decisions have made to get to this point and what all of thesebeautiful colored lines actually mean
* And one more thing, here in the map landcommand window, you can see that I have a few f, f statementsand these are
* The robot switching between a state, so Ican actually see that I was in ao and go to goal, and then I switched to avoidobstacles, and then back ao to ao and go to goal, and then to avoid obstacles, and eventually, there's also a follow wallin here
* And so on and so forth
* But let's get back to the slides
* So.I talked about progression
* And we need progression because if we werejust to use the controller from week five I saidwe were going to get stuck and that's for the, the, thereason for that is that the robot is first of all trying togo to the goal
* So
* Right here I have the goal to goal vector
* And that was ugtg and that's pointing metowards this goal
* So you can just imagine this extends tohere
* So is our goal to goal vector we'realready familiar with that one
* And I also have the obstacle avoidance vector
* And perhaps I'm either going truly, go to goal, or perhaps I'm doing something inbetween
* So, but the point is that I'm trying, thatthe robot is really trying to drive itself in thisdirection, or in this general direction
* So it's wants to go to this, to this goalbut it's a blocked off by, by, by this obstacle and it has tosomehow navigate around it
* Now, [BLANK_AUDIO] With respect to progression, what Iwant to do is I want to keep track of how close the robot getsto the goal
* So, first, in the previous slide the robotwas at this location, and now in this slide hasprogressed to this location
* And it's actually gotten closer to thegoal
* And
* Because the reason it's gotten closer togoes goal, because this distance to the goal is larger than this distance to the goal.And the way that we update our progress is by calling the function,set_progress_point right here
* So this function we'll call and we'llmake, we'll say, well, you know, the robot has madesome progress, and we're going to save its progress butwe're always going to store the closest it's ever gotten to thegoal location
* And the reason that we do this is becausewe want to check a certain event, and this event iscalled progress made
* And progress made to checks whether thecurrent location the current distance of the robot to the goal location is shorterthan the last set_progress point
* And if so, it returns true otherwise itreturns false and we're going to use this to checkwhether you know our robot has made progress towardsthe goal or not
* So, what we saw in the what we saw in the simulation, was that the robots startedsomewhere over here, and then it drove in this direction and it started avoiding goals and now it's gottento this point
* So it's kind of follow this generaltrajectory, because it's gone here, it's probablygoing
* Go to goal, and then here, it's doingavoid obstacle, and then here, it gets to the point where itsays well, no progress made
* So, the robot's not made any, not made anymore progress
* So, time to make a decision
* And, the decision that the robot makes isthat when it's no longer progressing, it's going to try toswitch into the Follow Wall behavior
* But an important question is, what shouldthe direction should be
* Should we follow the obstacle at our leftor the obstacle on our right side
* And we're going to make this decisionbased on three vectors
* And we're going to make this decisionbased on the goal to goal vector which pointstowards the goal
* So this is pointing me towards the goallocation
* The obstacle avoidance vector, which is pointing the robot away from theobstacles
* And we're going to inspect both the followwall vector
* That we computed last week
* In the, on the right side and on the leftside of the robots
* So we're going to look at these fourvectors and make our decision whether we need, we should follow anobstacle to the left or to the right
* And that's, and that's how we determinethe follow wall direction of the robot
* And the way we're going to do this iswe're going to ask the questions, is this vector, righthere, follow wall, and this is L again denotes that it's, it'swith respect to the left, is this between the vector'sobstacle of ordnance and [INAUDIBLE]
* We're going to ask that question
* And we're also, at the same time we'regoing to ask
* Is this vector.U Follow Wall comma R
* Between U _ao and ugtg.And of course you can argue in this picture, well they're both, right?Because this is one, this is between [BLANK_AUDIO] This one right here is, this vector isbetween the two vectors on this side of things, whereas thisvector right here is between these two.On these thought-side of things
* And really, the requirement is going to befor, is it between these two vectors
* If the A is, we're going to look at the side where the angle between U goto goal and U A O, so this angle between them isless than Pi
* So less than 180 degrees, so when we sayis a vector between these two vectors
* It has to be between them on the sidewhere it's less than, probably where these two areless than pi apart
* [BLANK_AUDIO] And the reason I'm setting it up in thisway is because that allows us to just do a little bit oflinear algebra
* And the little bit of linear algebra that we're going to do is, is this followingequation
* So what I have here is I have the go togoal vector
* I have the obstacle avoidance vector.I have some scalar parameters
* Sigma one and sigma two
* And on this side I have the follow wallvector that I care about
* In this case, I pick the left side, butthis might as well be the right side
* And the condition is that we're going to solve this linear equation for these twoparameters
* So
* [BLANK_AUDIO] What is this vector equal to and oh, I'mso sorry
* What is this scalar equal to
* And what does this second scaler do
* And we can compute this we're you know, you just have to rearrange this a littlebit
* And What we're going to do is, say, the,the condition that we're going to come up withis, as follows
* If sigma1 is greater than 0, and
* Sigma 2 is greater than 0.So if they're both positive, that implies that if we have the two vectors, ugtg and uao, then.This vector ufw,of L is between those two.So it's not on the other side
* It's, it's on this side between the two,because this, because this angle right here is less than Pi, that's going to beour condition
* And I have posted 2 PDF's online, and in and announcement that go over why this exactlyworks
* Why this linear algebra works, and why itmakes sense
* And I'll have and, and then, those notes,I have some more diagrams and a lot moredetailed math, and you'll be able to follow alongexactly what this little piece of linear algebradoes for you
* Now, at some point the robot is, the robot youknow follows the, follows the, the wall, the obstacle, soOriginally it was over here
* Over here and then it drove around anddrove around
* And this was the, this was the bestprogress we had made at any point, so right here
* And it follows it around, follows itaround all the way until it gets to this point right here
* And at this point, it says look Thisdistance here, from here to the goal, is less than thedistance from here to here to the goal
* And if that's the case, and I no longerneed to slide, and sliding refers to that condition that I just talked about in the previous slide and we have one for eithersliding left or one for sliding right, but in thiscase, it's sliding left
* And so if this condition is no longertrue, which it isn't because the, because as you cansee right here these vectors are no longer betweenthe [INAUDIBLE] goal and the obstacle points vector, andprogress has been made
* If those two conditions hold.Then we can go switch back to go to goal and our robot can goahead and make its way to the goal location and it doesn't, itno, no longer has to follow this obstacle right here.Now, like I said, the
* State machine, the finite state machinefrom week five is no longer sufficient for this particular problem so you'regoing to have to design a new one
* And the design is up to you, but here area few pointers of what you should probably think about in your finite state machine.The first is, as usual
* If the robot is at the goal, then youstop
* And it's useful for that as the firstthing that you check in the finite state machine, because you don't want to execute anything else once you're at thegoal
* Once you're at the goal the robot is donewith its task and it's just going to stay inthe stopped state
* Also, if the robot get into an unsafedistance to the obstacle, we immediately want toswitch to avoid obstacles, because avoid obstacles really is our lastditch effort to make sure that a robot doesn't crash with,with obstacle
* So it's usually a good idea to have that in there, to make sure that there are nocollisions
* Then Also, you want to have the condition thatif are you going to goal or maybe you're doing obstacle [INAUDIBLE] and[INAUDIBLE] goal together, but both of these goal seekingbehaviors
* And you're no longer making progress thenyou want to switch to either to follow walland you want to do that based on the conditionwhether you're sliding, you're suppose to slide left orslide right
* And I talked about it in the previous slides but make sure you have that inthere
* And the fourth one is if you do get around the obstacle there will be a point whereyou're going to start making progress again toward thegoal location and you Will probably no lee, no longer needto slide along the wall in order to make progress,so if those both tho, both of those conditionsare, end up being true, then you can go ahead andswitch back to your goal-seeking behavior, so which iseither go to goal, or what I usually like do to is if, if I'm close to an obstacle, which I typically ambecause of the follow all behavior I first switch intoavoid obstacles and go to goal before I switch into pure go togoal behavior
* Now, my tips for week seven are.Again, read the manual
* It has more details
* And also read the handouts, the, theadditional handouts that I'm going to be posting that explains theLinear Algebra
* And do that
* And then really the more, even moreimportant one is when you design this finite state machine,it's fairly complicated
* And what I like to do is I like to get out a piece of paper and a pen and I like to draw the finite statemachine
* Really think about..
* What are all the states that the robot canbe in, and what are the events that can take it from state to state, and thenconstruct it on paper before you even start codingit
* Because then you, what you can do is youcan take your piece of paper, and you can pretend you're the robot and you can gostep through and, and see if you can make it
* All the way around the obstacle to thegoal location
* And then after that, you can implement it and youcan test it
* And then you'll always, always have thispiece of paper to go back and forth and make sure, hey is the robot actually doing what I designedthe funded state machine What I'd de, how I'd design thefinite state machine
* Is it doing that, is it not, and that really makes debugging this week'sprogramming assignment much easier
* And usually I would end the video lecturehere, but I have one extra special slide for youthis week
* And that's the What's Next
* Well, it is the last one, but thesimulator and it's documentation will be available outside ofthis course at the following URL
* So the project continues to lives on afterthis course, and at any time if you want to get new updatesto the simulator
* If you want to check in
* Have their new robots been added to thesimulator has there, have there, are there new sensors, if there'snow maybe a camera sensors, or, whatever it may be, you go to this URL,and you'll be sent to a webpage where there'llbe updates
* And there also will be links to a GitHubrepository
* And the point of this GitHub repository is for everybody to have access to shareimprovement
* And using improvements can be either, hey,this is a way better way of for example, limiting the error betweenminus pi and pi
* I want to add that to the simulator
* You can go ahead and do that there
* You can also add new robots, so if you wanted to have, for example, a robotthat's more like a car you can add that to the simulator and then have that become part of theofficial project
* And the same thing with sensors andanything else that you think of, so I would really like to encourageyou to consider if you're making any improvements or addinganything to the simulator, contribute back to the project becauseit'll just make everything better
* And future students and future users ofthe simulator will really, really benefit fromyour improvements
* And the last thing is just, thank you verymuch for your hard work and your participationin programming assignments
* I've seen some really exciting discussionson the forums, it makes me really, really happy And privileged towitness everybody grow into seasoned robotics experts during thecourse of this of these seven weeks
* And with that, thank you very much andgoodbye
* [BLANK_AUDIO]


--- SKIP ---: 01_general-presentation-of-the-course.en.srt


--- SKIP ---: 01_general-presentation-of-the-course.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_general-presentation-of-the-course.en_SENTbySENT.txt
* [MUSIC] This course is going to give you a globaloverview of modern subatomic physics
* In order to follow it easily, it wouldbe good if you had basic notion of classical mechanics andclassical electrodynamics
* You must also be able to understand andappreciate a simple mathematical formula, including simple differential andintegral equations
* >> If you have the educationallevel of a third-year student of any scientific discipline, then you havethe right level to follow this course
* >> It would also be good if you had basicnotion on the restricted relativity and quantum mechanics
* But in any case, it will give youa quick reminder of this notion and the specific vocabulary
* >> We will cover the atomic nucleus,its structure and its properties, and how they are put to practical use
* >> We will guide you throughtechniques to create, accelerate, and detect particles andmeasure their properties
* >> The fundamental particles,namely the quarks and leptons, will be discussed in a lot of detail
* With the same amount of detail, the fundamental forces will also bediscussed, as well as their properties
* >> We will complete our tour of what iscalled the Standard Model of particle physics by discussing the Higgs boson
* Which prevents the particles frommoving at the speed of light
* >> We will go beyond anddiscuss how we search for new physics beyond what isalready well understood
* That way you will understandthe use of the formidable machine, such as the LHC of CERN,and it's experiments
* >> But those experiments are usingthe particles like cosmic rays, which are not manmade
* >> Andyou will understand how dark matter and dark energy contribute toforming the universe we live in
* At the end of this course, you will be able to answer questions fromyour friends about the subatomic world
* And you will be well preparedto continue your studies
* So once again, welcome to the course,Particle Physics, An Introduction
* [MUSIC]


--- SKIP ---: 01_1-1-matter.en.srt


--- SKIP ---: 01_1-1-matter.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-1-matter.en_SENTbySENT.txt
* [MUSIC] Hello, and welcome to our introductorycourse on subatomic physics brought to you by University of Geneva
* During this first module, we will give anoverview of the objects that are treated by particle physics, namely matter,forces and space-time
* We will also discuss how one goesabout to characterize the strength of a reaction between particles withthe concept of the cross section
* Which is a central issue of our subject
* At the end of the module, we will visit the laboratory of thenuclear physics course at University of Geneva to see a small example ofhow all of this works in practice
* In this first video, we will take a quick tour of the elementsof matter at the subatomic level
* After having watched this video, youshould know quarks and leptons by name and a few of their fundamental properties
* You should be able to assign theseconstituents to families and generations
* And you should know the quantum numberswhich are conserved in interactions among these particles
* We are interested in this course inthe subatomic structure of matter
* Here is a schematic pictureof the components of an atom
* Of course it is not to scale otherwise,the nucleus would be completely invisible
* The atom consists of a positively chargednucleus of small size of the order of ten to the minus fourteen meters in thesurrounding electron cloud which is about ten thousand times larger that is to say,ten to the minus ten meters in radius and negatively charged
* For all we know, the electron isan elementary particle, without internal structure and probably without size.It belongs to the family of leptons
* Electrons and the nucleus are boundtogether by the electromagnetic force
* The nucleus on the other hand,is not elementary
* It contains protons and neutronsbound together by the nuclear force
* We will talk about the physics ofthe atomic nucleus in the next module
* Protons andneutrons are not elementary either
* They contain quarks boundtogether by the strong force
* As far as we can tell today, quarks are equally elementary inthe same sense as electrons are
* But be careful, all of thisdescribes just 5% of the universe, the rest is dark matter and dark energy,and we will introduce you to these two forms of matter andenergy in module number eight
* One can assign quarks and leptons tofamilies according to their properties, and to generations according totheir mass as shown in this table
* The lepton families are shown on the left
* All charged leptons have similarproperties as the electron, which is the most well-knownmember of this family
* The electric charge is minus oneelementary charge
* The neutral leptons, the neutrinos,are produced in radioactive decays
* They have zero electric charge andthey're very small mass
* The quarks families are shownon the right of this table
* These are the constituents of proton andneutron and of all particles which we call hadrons
* There are also two types
* The up-type quarks have an electriccharge of 2/3 of the elementary charge, the down-type quarkshave a charge of -1/3e
* Every family has three generations, almostidentical copies of the first one, but a lot heavier than the first one
* In the first generation,we find the familiar electron, the light neutrino nu_L,the quarks up and down u and d, these are the constituents ofthe ordinary matter around us today
* The second generation, has the muon Р вЂ™Р’Вµ,the medium mass neutrino nu_M, the charm quark andthe strange quark, c and s
* And finally, in the thirdgeneration we find the tau lepton, the heavy neutrino nu_H,the top and bottom quarks, t and b
* There is a quantum numberwhich is called flavor which distinguishes betweenthe generations inside each family
* It is conserved by all interactionsexcept the weak interactions
* The range of masses in this table is very,very large
* Neutrinos are the lightest matter particles
* Their masses are foundexperimentally to be below two electron volts but they are probably rather inthe range of milli electron volts meV
* We will talk about them in Module 6,which covers weak interactions
* The top quark has a massas large as a Hafnium nucleus
* The Hafnium nucleus hasan atomic number 178 and 72 positive electric charges
* But as far as we know the top quarkis a point-like particle like all the others in this table
* With these constituents we canimplement an order scheme, a descriptive nomenclature,Р вЂњР’В  la LinР вЂњР’В©
* We call hadronsall particles which contain quarks
* They are sensitive to strong andnuclear reactions, leptons are not
* Baryons are bound statesformed by three quarks
* Mesons contain a quark and an anti-quark
* And the two together formwhat we call hadrons
* The nucleons p and n are the lightest baryons
* They form the atomicnuclei we find around us
* And particles like the pion are thelightest mesons formed by quarks and anti-quarks
* There are no hadrons including a topquark because of it's short lifetime
* This quark decays before it can everform a bound state with any others
* Leptons on the right of thistable are elementary in the sense that they are not composed ofother particles for all we know
* Observations are compatible with themhaving no size, they are thus point-like and so are the quarks
* But not the hadrons
* We will often see the neutrinos, nu_e,nu_mu and nu_tau in tables of this sort
* I don't adhere to this
* These particles, nu_e, nu_mu and nu_tauare mixtures of the true particles with a specific mass which we denote by nu_L,nu_M and nu_H in this course
* Ww thus respect their mass hierarchy andassign them to their respective generations according to that propertylike we do for all other particles
* The enormous strength ofthe strong force binds together, quarks to form very stable bound states
* To be sensitive to the strong force, particles need to have the necessarycharge, which is called color charge
* Quarks do have color charge,leptons do not
* This leads to a whole zoology ofhadrons as shown in this summary table
* The Particle Data Group is responsibleto collect all the data concerning their properties, an exhaustive list of states as well as a summary of the knownproperties is available on the site of the Particle Data Group quoted inred on the bottom of the slide
* On the left you see a list ofbaryons containing three quarks
* Like the proton whichis a uud bound state
* And the neutron whichis a dud bound state
* On the right is a list of meson formedby quarks, quark anti-quark pairs, like the positive pionwhich is a u-dbar bound state
* Leptons are not sensitive to the strongforce because they do not carry the necessary color charge
* They intreact only, via the electromagnetic and weak forces and do not form long lastingbound states among themselves
* Here's a table summarizing some importantproperties of elementary particles
* In the upper half of the table youfind the constituents of matter
* Leptons and quarks are ofspin one half as you can see
* In the lower half you findparticles that transmit forces
* These are bosons of integer spin
* The charges are indicated in units ofan elementary charge for each one of them, like the one of the electron inthe case of the electric charge
* Here we say that its chargeis -1 which means that it is -1 times the elementary charge, e
* The weak charge is called weak isospin andit has two components in contrast to the electromagneticcharge which has only one component
* We denote them by T and T3, the total length of the weak isospin andits third component
* This charge depends on the orientation ofthe spin of the particle with respect to its direction of motion, which meansit depends on the helicity of the particle
* The strong charge has three components
* It's called color, and we use theabbreviation r for red, g for green, and b for blue to denote them
* Color is a property of quarks and of gluons where the latter even carrya color and an anti-color simultaneously
* For every particle, there's ananti-particle which has the same mass but all charges opposite,as indicated in this red table
* Charges are additive quantum numbers
* For a system of particlesthe total charge is the sum of the charges of its constituents
* But there are other quantumnumbers that are conserved
* The first one quoted here isthe total number of baryons, i.e
* the number of baryons minusthe number of anti baryons in a system
* This number is conserved, this applies in particular to quarkswhich have a baryon number of 1/3, and anti-quarks which havea baryon number of minus 1/3
* The total lepton number, the numberof leptons minus the number of antileptons is also constantin a closed system
* To a certain extent this is eventrue generation by generation but the neutrinos which show up here,nu_e, nu_mu and nu_tau are mixtures of the true particles,nu_L, nu_M and nu_H
* So, there's some mixture betweengenerations in weak interactions
* But more important than that, the charges of all types are rigorouslyconserved as far we know
* This evidently concerns the electriccharge Q that you are familiar with but also the weak isospin T and T3, and the color charges R, G, and B
* The flavor which distinguishesbetween generations is a special case
* It is conserved by the strong andelectromagnetic interactions but can be altered by the weak one
* We will define what it exactlymeans to conserve a quantum number when we discuss Feynman diagrams,in Part 1.5, first of this module, andthen later in Video 4.1a
* In the next video Mercedeswill introduce in more detail the forces which interactbetween matter particles
* [MUSIC]


--- SKIP ---: 01_1-2-forces.en.srt


--- SKIP ---: 01_1-2-forces.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-2-forces.en_SENTbySENT.txt
* [MUSIC] In this first module, we are introducingthe objects studied in particle physics, namely matter, forces and space-time
* In this video, we will takea quick tour of elementary forces, and their action at the subatomic level
* After watching this video, you shouldbe able to name these forces and their associated charges, to knowthe particles which transmit these forces, and know the difference between real andvirtual particles
* Here is a table comparingelementary interactions
* Note the vast differences betweentheir respective strengths and ranges
* The strong force acts between quarks andparticles containing quarks
* It has a large strength buta very short range
* It is transmitted by gluons
* The electromagnetic force concerns allparticles carrying an electric charge, and it has a modest strength but an infiniterange, and it is transmitted by photons
* The weak force concernsall matter particles
* It has a low strengthat long distances but becomes comparable to the electromagneticforce at short distances
* It is transmitted by the W and Z bosons
* The gravitational force is weaker thanthese three but acts on all particles
* Because of the large massof astronomic objects, the gravitational force dominatesthe evolution of the Universe at cosmological scales, but is however,negligible at the subatomic scales
* We don't know how this forceacts at these scales and we don't know if it is quantizedas the other three forces
* Note also that the strength ofthe forces depends on distance or equivalently on momentum transfer
* We will discuss this fact for eachforces separately because the distance laws forthese forces are quite different
* So forces are transmitted byexchange of bosons of spin 1
* The photon for electromagnetic interactions, the WР вЂ™Р’В± and the Z bosons for the weak forces andgluons for the strong force
* These bosons are collectivelycalled gauge bosons
* Particles can emit or absorb such a bosonif they carry the required charge
* To emit a photon,an electric charge is required
* But the concept of charge is notlimited to electric charge
* A particle must have a non-zero weakisospin to emit a W or a Z boson
* And a color chargeto emit a gluon
* The Higgs boson is the only entryin this table, which has a spin 0
* Its role is to keep particles frommoving at the speed of light, and this applies to all particles,even to the Higgs boson itself
* The only exceptions are the photons,which always move at the speed of light, and which are howeverconfined to bound states between quarks as we willdiscuss in module 5
* So, how does the transmission of forcesvia the exchange of particles work
* To understand this, we need to recall how forces act inclassical and quantum physics
* How does classical physics dealwith the action of forces
* Particles are described as mass points
* Their position x andmomentum p can be known with certainty
* Their motion is a smooth curve,in space a function of time, which we call a trajectory
* It is determined by Newton's law,once we know the vector sum of all forces acting, and the initialconditions on the position and velocity
* The action of forces is continuous,thus the trajectory is a smooth curve
* The number of particles is conserved, mass points cannot disappear or appear
* Field and potential are notions which are subordinate tothe central ones of force and energy
* We give here the example forthe electric force and energy which are related to the potentialas shown in the last equation
* This description is not wrong
* After all,it allows you to drive your car
* It's just that its validity is limitedto non-relativistic velocities and distances, much largerthan the size of an atom
* To talk about subatomicsystems at high energies, we need to go beyond classical physics
* Quantum mechanics radicallychanges the approach
* Particles are fields described bya probability amplitude psi, which is a function of the position x and the timet, which is also called a wave function
* The square of this amplitude rho,which must be always positive definite gives the probability density to find theparticle at the time t in the position x
* This density is a probabilityper unit volume
* The trajectory does notexist at small scales
* Multiple measurements of the position ofa particle do not form a smooth curve
* Probability amplitude andprobability itself evolve starting from initial state,described it by the SchrР вЂњР’В¶dinger equation
* Particles interact with the potential,the action the potential is continuous
* However, the origin ofthe potential remains unexplained
* Even though the action the potentialis continuous it can be implemented as a sequence of point-likeinteractions in a pertubative approach
* The number of particles is conserved,since probability amplitudes follow a continuity equation as shown at the bottom of the page
* This law relates the local probabilitydensity rho to the flux density j
* If the probability densitydiminishes at a certain place, there must be a divergentflux at the same place
* So the flux j is thus a flux of probability density
* The validity of Quantum Mechanics islimited to non relatively velocity, since the SchrР вЂњР’В¶dinger equationis not covariant, its forms depends on the reference frame
* To overcome this limitation,we have to use relativistic field theory
* Here, we are going just to introduceits language, its concepts and its results, butwe will not use it in a formal way
* The evolution of particles is describedby a relativistic equation of motion, the Klein-Gordon equation, which is covariant because it containsonly scalars under Lorentz transformations
* The number of particles isno longer conserved about the electromagnetic current density is
* This current is analogous tothe probability current, but is proportional to the chargee of the particle
* This conservation means that itis the electrical charge, which is locally conserved,and not the number of particles
* This allows to describe the creationof charged particles in pairs of particle-antiparticle
* The potential no longer comes out of nowhere, but is generatedby a second current density j_2 according to Maxwell's laws
* The four-potential A^Р вЂ™Р’Вµ is generatedby the current density j^Р вЂ™Р’Вµ by means of the propagator1/q^2
* This quantity describesthe probability amplitude for the exchange of a photon of invariantmass q between the two currents
* Those who follow carefully may havenoticed that there are at least three unfamiliar notions, in the formulae that come with relativistic field theory
* The dimensions of the quantitiesdo not seem to fit
* In the first equation, there is a relation between a quantitywhich is an energy, a momentum and another quantity which is a mass,which have all different units in the international systemwhich we are familiar with
* Even worse in the second equation,since psi has no dimension, the first time has dimension1/s^2, the second 1/m^2,and the third kg^2
* The solution to this apparentinconsistency is the use of natural units
* Secondly, what does the notation j^Р вЂ™Р’Вµ andp^Р вЂ™Р’Вµ mean
* This is the notation used for four-vectors, with implicit summation over Greekindices in scalar products
* Finally, the last equationrequires the the photon has non-zero mass
* The real photon of course has zero mass
* After all, it moves at the speed of light
* The solution is the notionof your virtual particles, which is central to the actionof forces in field theory
* Virtual particles have all the sameproperties as the real ones, except that they canhave a different mass, which can even be negative orimaginary
* We will introduce these three notions inthe videos 1.2a, b, and c, one by one
* In the next video,we will explain how the probability for a reaction between particles to happenis expressed by the cross section
* [MUSIC]


--- SKIP ---: 02_1-2a-natural-units-optional.en.srt


--- SKIP ---: 02_1-2a-natural-units-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_1-2a-natural-units-optional.en_SENTbySENT.txt
* [MUSIC] For those unfamiliar withthe notion of natural units, we will briefly introduceit in this short video
* High energy physicsdeals with relativistic quantum processes
* The scale of the action isthe Planck constant hbar and the scale of velocity is givenby the speed of light, c
* In the system of naturalunits we set hbar = c = 1
* This means that we define hbar as the unit of action and c as the unit of velocity
* In such a system 1 second is equal toapproximately 3 x 10^8 meters
* As an added value the electriccharge is now dimensionless
* It often shows up as the finestructure constant alpha, which is the electrostatic potentialenergy of two electrons at unit distance, divided by the mass of the electron
* This constant is equal to 1/137 to a good approximation
* The system of natural units is ofgreat practical value since it eliminates a lot ofconstants from equations
* It does make them less heavy andmore easy to understand
* The basic unit, the electronvolt,is defined as the gain in energy of an electron when it traversesthe potential difference of 1V
* In the system on natural units, the electronvolt is the commonunit of energy, momentum and mass
* A billion of these units correspondroughly to the mass of the proton, and thus sets the naturalscale of energy physics
* Whenever you want to convert a resultto units of the international systems, you need to multiply by a combinationof hbar and c as shown in this table
* [MUSIC]


--- SKIP ---: 03_1-2b-special-relativity-and-four-vectors-optional.en.srt


--- SKIP ---: 03_1-2b-special-relativity-and-four-vectors-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_1-2b-special-relativity-and-four-vectors-optional.en_SENTbySENT.txt
* [MUSIC] In this short video,we will remind you of special relativity and the notation of four-vectors which are essential toolsto work with in high energy physics
* This course will treat phenomena at high energy, so at a velocity which requiresa relativistic treatment
* The fundamental principles ofspecial relativity which have been based on experimental findings arethat the speed of light c is constant at the same value in every inertial frame
* It means that the Galilean way of addingvelocity is not valid at high speeds
* This way, the speed of light isa maximum velocity which cannot be exceeded in any frame
* Motion is described in a four-dimensional space, called space-time
* An event in space-time is localizedby the Carthesian coordinates ct, where t is the time, andx, where x is the position
* And this is described by a four-vector x_Р вЂ™Р’Вµ
* The metric of space time isdefined by the speed of light c, invariant constant inevery inertial frame
* So suppose that a lightray connects two events
* (ct_1,x_1) and (ct_2,x2)
* The distance between these two pointsin space is always proportional to the propagation time of the light
* Since the proportionality constant,the speed of light, is the same in every inertial frame, it follows that the norms of a four-vector is also constant
* Lorentz transformationsdescribe the rotations and translations in space-time whichare compatible with these principles
* Let us specify Lorentztransformation by a simple example
* Let S and SР Р†Р вЂљРІвЂћСћ be two reference frames
* The first one is at restin the laboratory
* The second one moves relative tothe first one at a constant velocity v in the direction of the x axis,which are parallel for the two frames
* Which are the coordinates ofone point in the moving system, so tР Р†Р вЂљРІвЂћСћ and xР Р†Р вЂљРІвЂћСћ, expressed in the coordinates ofthe laboratory frame, t and x
* The answer is given by the Lorentztransformation which relates tР Р†Р вЂљРІвЂћСћ and xР Р†Р вЂљРІвЂћСћ to t and x, by the relative velocity, beta, whichis the ratio between the velocity v and the speed of light c, andthe relativistic factor gamma
* The transformation corresponds to a rotationin space-time which leaves the norm of four-vectors like x_Р вЂ™Р’Вµ invariant
* The transformation involves onlythe time coordinate t and the spatial coordinate x along the direction of motion
* The coordinates orthogonal tothe motion, y and z, are left untouched
* In the non-relativisticlimit that is beta << 1 and gamma, which approaches 1, the Lorentz transformationreproduces the Galilean transformation where tР Р†Р вЂљРІвЂћСћis equal simply to t, and xР Р†Р вЂљРІвЂћСћ is simply equalto x - vt
* Four-vector notation unitestime and space coordinates in a single vector
* Four-vectors transforming like thefour-vector x^Р вЂ™Р’Вµ of space-time under Lorentz transformationsare called the contravariant
* An important example is the contravariantenergy-momentum vector p^Р вЂ™Р’Вµ
* The norm of a four-vector isdefined via the scalar product between the contravariant four-vector andits covariant form
* The two are related by the metrictensor g_Р вЂ™Р’Вµnu, as shown here
* All scalar products between four-vectors areinvariant under Lorentz transformations
* More generally, the scalar product isthus defined as the product between a covariant anda contravariant four-vector
* When the same Greek index shows upin the two, implicit summation over this index, which runs from zero to three, is assumed
* The first example here repeats the normsquared of the space-time four-vector
* The second example shows the norm of theenergy-momentum four-vector, which is the square of the invariant mass
* The third example Is a scalar product between the space-time and the energy-momentum four-vectors, which shows up inthe wave function of particles
* The scalar products betweenfour-vectors are all indeed scalars under Lorentz transformation soare invariant, when one changes from oneinertial frame to another
* The notation simplifies if weadopt the system of natural units, since the ubiquitousspeed of light c disappears
* Two other important examples offour-vectors are the four-vector of electromagnetic current density, j^Р вЂ™Р’Вµ, which has the charge density rho as the time-like component, and the vector current densityj as the space-like component
* The four-vector ofthe electromagnetic potential A^Р вЂ™Р’Вµ, which has the electric potential Vas a time-like component and the magnetic vector-potentialA as the space-like component
* As an example, we calculate here the totalavailable energy in the collision of a 200 GeV electron with a protonat rest in the laboratory frame
* And we confront the results witha collision in the center of mass frame, where a 200 GeV electron collideswith a 200 GeV proton
* >> As an example we calculatethe kinematics of a two body process in the laboratory andthe center of mass frame
* In the laboratory frame a particle of massm impacts on a particle of mass M at rest
* We calculate the total energy-momentum vector in this frame as well as the square of its length, s
* When one neglects all masses in the systemone obtains that the maximum invariant mass which can be produced isequal to square root of 2EM
* In our numerical examplethis corresponds to 14GeV
* In the center of mass frame on thecontrary the two particles impact on each other with equal and opposite momenta
* The same calculation leads us toan invariant mass which can be produced, which is two times the energy of eitherparticle or 200 GeV in our example
* [MUSIC]


--- SKIP ---: 04_1-2c-virtual-particles-optional.en.srt


--- SKIP ---: 04_1-2c-virtual-particles-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_1-2c-virtual-particles-optional.en_SENTbySENT.txt
* [MUSIC] For those who do not feel sufficientlyfamiliar with the concept of virtual particles, we propose a small reviewof the phenomenon
* In a field theory, the field, or rather the potentialis created by emitting a vector boson, which has a certain probabilityof traveling to its destination
* We will compute a small example comingfrom electromagnetic interactions
* Consider an electron which enters withan energy E and a momentum vector p
* It emits a photon with an energy k_0 anda momentum vector k, and thus, changes its energy to EР Р†Р вЂљРІвЂћСћand its momentum to pР Р†Р вЂљРІвЂћСћ
* The energy-momentum four-vector must be the same before and after the emission of the photon, and in particular the square of its lengthmust be the same before and after
* On the left, we get the massof the electron squared, and on the right,the expression I'm writing down here
* On the right, we obtain, thus,the mass of the electron squared, plus the mass of the photon squared,plus a mixed term
* The mass of the electron cancels on the twosides, and the mass of the photon is 0
* One obtains, thus, a relationshipbetween outgoing energy and outgoing momentum,which is in conflict with reality, because the energy becomes smaller orequal to the momentum
* But the outgoing photon didnot necessarily have a 0 mass
* It can be a virtual photon, which is themass squared that I'm now writing down
* It is not equal to 0,indeed it can even be negative
* It is clear that such a virtual particlecannot propagate in space and time
* I just remind you that the Feynmandiagrams are defined in energy-momentum space
* Everything you see in the Feynmandiagram happens at the same time and in the same place
* So we must, of course,immediately reabsorb the virtual particle by another pair of realparticles, as shown in this diagram
* There's a second current consistingof an electron, which by entering and exiting a second vertex,will absorb the photon
* [MUSIC]


--- SKIP ---: 01_1-3-probability-and-cross-section.en.srt


--- SKIP ---: 01_1-3-probability-and-cross-section.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-3-probability-and-cross-section.en_SENTbySENT.txt
* [MUSIC] During this first module, we are introducing the objects studied byparticle physics namely matter, forces and space-time but also, of course,reactions between particles
* In this third video,we present the concept of probability, to characterize the strengthof fundamental forces
* We'll also define one ofthe most important quantities in particle physics, which iscalled the cross section
* This quantity allows to calculate and to measure the strengthof subatomic reactions
* After watching this video, you will beable to define the cross section in terms of incident flux andnumber of target particles
* You will also be able to relate the crosssection to the probability, and the rate of a particle reaction
* In quantum physics the motion offields and their way of interacting is described by probabilityamplitudes and probabilities themselves
* They are defined in a frequentistway by multiple measurements
* For the movement of a particular the wavefunction psi, describes the probability amplitude as a function of space-time,and the four-momentum of the particle, namely as a function of t and x andof energy E and momentum p
* The probability density to findthe particle at time t and at location x, is given by the squareof the wave function psi* psi
* Integrating this densityover a finite volume gives us the probability thatthe particle is in this volume
* The probability amplitude M fora reaction is the joint probability amplitude that twocurrent densities j_1 and j_2 meet and exchange a virtual photon offour-momentum q
* The probability for the reaction isthen given by the cross section sigma, which is proportional to the squareof the amplitude |M|^2
* The physics of particle motion and particle reactions is thus expressedvia statistical probabilities
* Mathematically speaking, a probabilityis a real number between 0 and 1
* In a frequentist approach, the probabilityis defined as the ratio between the number of desired outcomes of an experiment,we might call successes, and the number of trials ittook to obtain them
* In terms of physics, this isthe ratio between the number of times an event happens, and the numberof times it could have happened
* An event can for example be the localization ofa particle inside a given volume
* The ratio can also be the numberof times a reaction takes place, divided by the number of timesit could have taken place
* This means in particular thatreactions do not always happen
* In fact, we will find thatthey happen rather rarely
* Probabilities follow their ownrelatively simple algebra
* For our purposes it suffices toknow our two simple rules
* The joint probability oftwo independent events to happen is the product oftheir individual probabilities
* The probability that at least oneof two incompatible events happen, is the sum of the two properties
* The two probabilities, sorry
* Incompatible means that the two eventscannot be realized at the same time
* And all of these rules applied tothe probability amplitudes that we have introduces earlier
* The two limiting cases fora probability are p=0 for impossible events andp=1 for certain events
* In general,we will find that probabilities for particle reactionsare rather small numbers
* Processes which follow probabilisticlaws are not certain individually, but can still be predicted collectively
* This little simulation shows what iscalled a Galton board as an example
* The small balls are introduced inthe middle at the top of the board
* The obstacles scatter them either left orright with 50% probability
* The multiple scattersare independent of each other, the result does notdepend on a previous one
* At the bottom of the board,the balls show, as you can see, a Gaussian distributionaround the middle position
* For those of you who know a littlestatistics, this is an example of how chains of multiple events withan arbitrary individual distribution Р Р†Р вЂљРІР‚Сљ Boolean in this case butnot necessarily Boolean Р Р†Р вЂљРІР‚Сљ asymptotically producea Gaussian distribution, the famous bell-shaped distribution,which is perfectly calculable and characterized by just two parameters, themean and the width of the distribution
* But let us come back to particle reaction
* Particle physics explores matter bymeans of scattering experiments
* For this purpose a beam of particlesis directed towards a target
* One counts the number ofscatters which take place, and measures the scatteredparticle direction and energy
* This sketch showsa fictitious situation where each target particle is representedby a small gray surface
* Let us consider a simple modelwhere a reaction takes place if and only if, a particle hits a gray surface
* Let us make the assumption thatthe distance between target particles is large compared to their size suchthat the gray surfaces do not overlap
* The interaction thus stays rare
* In real life this corresponds toa target which is made by a thin foil or a rarified gas
* The number of possiblescatters is evidently proportional to the flux of incomingparticles, of incoming projectiles
* That is to say, their number per unit time which passthrough a perpendicular surface
* The number of actual scatters isproportional to the number of target particles per square meter
* That is to say,the surface density n and the individual surface sigma
* If fact, the probability tointeract is simply the product of the surface density andthe surface size sigma
* A small part dI of the initialflux I will thus be scattered
* The rest of the flux is just transmitted
* The small fraction of the scatteredflux -dI/I is thus equal to the interactionprobably n times sigma
* The density of targets can also beexpressed as the volume density rho, if one multiplies by the infinitesimaltarget thickness, dx
* Integrating over the thickness up toР Р†РІвЂљВ¬РІР‚В x, one obtains an exponential law for the attenuation of the incident flux
* We call sigma the cross section for the reaction because it hasthe dimension of a surface
* It has nothing to with the geometricalsize of the target particle, it rather represents the probability of interactionbetween an individual projectile and an individual target particle
* The cross-section is often measuredin enormous units which are one Р вЂ™Р’В«Р вЂ™Р’В barnР вЂ™Р’В Р вЂ™Р’В» ten to the minus 28 square meters,which is a very large one
* The cross-section is, thus, a sort of probability expressedby strange units, one must admit
* But the rules forprobability calculation apply
* If two processesare independent of each other, the probabilities just simply add up
* One distinguishes, for example,processes of elastic scattering, where the kinetic energy ofthe projectile does not change, just its direction changes, inelastic scattering,where the projector looses energy and the target particle recoils and/orchanges mass, and absorption where the projectilesimply disappears inside the target
* For these mutually exclusive processes, the cross-sections can just be added toform what is called a total cross section, like in the bottom equation on this slide
* The cross-section must obviouslybe a positive real number
* It has a maximum, which corresponds to a reactionwhich always takes place
* That is called the unitarity limit
* An application example iscalculated in video 1.3a, it deals with the attenuationof photons by a sheet of lead
* The result will probably surprise you,and encourage you hopefully, to be very careful the next time you exposeyourself to a beam of energetic photons
* It is clear that the properties of theoutgoing particles are also important to understand the reaction
* For example, the angle by whichthe projectile is scattered gives useful information about the structure ofthe target, and the properties of the interaction as we'll see with manyexamples in the course of these lectures
* Keeping in mind that the cross-section hasnothing to do with the physical size of the target, let us continue to imaginethe cross-section as an effective area for the interaction
* If the projectile hits ita reaction takes place, otherwise the projectilepasses without perturbation
* The scattering into an infinitesimalelement dOmega of solid angle, centered on the polar angle theta andthe azimuth angle phi, then comes from an element dsigma ofthat surface in our geometrical model
* The fraction of the incoming beamsscattered into the solid element is proportional to the differentialcross section, dsigma dOmega
* The probability that a projectileis scattered into a solid angle element is not normally uniform
* It depends on the angles theta and phi,the scattering and the azimuth angle, and allows one to look intothe target in a literal sense
* The total cross section is obtainedintegrating the differential cross section dsigma dOmegaover the solid angle dOmega
* Let us consider a systemwith cylindrical symmetry
* The scattering probability is then independentof the azimuthal angle phi and only depends onthe scattering angle theta
* An example from classical physics isthe scattering by a central force
* It shows a fixed relation betweenthe impact parameter b and the polar scattering angle theta
* All projectiles with an impactparameter between b and b plus db and an initial azimuthalangle between phi and phi plus dphi, are scattered into an element dOmegaaround the direction (theta,phi)
* The fraction of the incoming beam whichfalls into such a region is dI/I equal rho times Р Р†РІвЂљВ¬РІР‚В x times b db dphi
* Integrating over the azimuthalangle on which the force does not depend we will just obtain a factor of 2Р СџР вЂљ,and the results defines the cross-section in terms of impact parameter,and the scheduling angle
* Taking the absolute valueguarantees that the cross section, is always a positive definite real number
* The scattering angle theta depends on theimpact parameter b, in a specific manner, which is determined, in fact, by the distance law of the centralforce or its equivalent potential
* Let us take a really trivial example: the classical shockbetween two rigid bodies
* The geometry and the laws of elasticreflection relate b to thetha, in the simple geometrical waysketched in this little drawing
* The differential cross-sectionis just constant, it does not depend onthe scattering angle
* The angular distribution ofthe scattered particles is isotropic
* The total cross section is foundto be sigma times Р СџР вЂљR^2, equal to the geometricalsurface of the target and we're not surprised to find this resultwhich we expected in the first place
* In the next video, Mercedes will giveyou a much more interesting example of a realisticelectromagnetic interaction
* In this case,the interaction of a He-4 nucleus also known as an alpha particlewith a heavy nucleus like gold
* This process is called Rutherford scattering,its experimental observation has revealed the existenceof the atomic nucleus
* [MUSIC]


--- SKIP ---: 02_1-3a-attenuation-of-a-photon-beam-optional.en.srt


--- SKIP ---: 02_1-3a-attenuation-of-a-photon-beam-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_1-3a-attenuation-of-a-photon-beam-optional.en_SENTbySENT.txt
* [MUSIC] We calculate the attenuationof a photon beam of energy 1 MeV by a onecentimeter thick lead plate
* The attenuation of the beam intensity I is exponential with threefactors in the exponent: the cross section sigmabetween photons and lead nuclei, the density rho of target nuclei andthe thickness Р Р†РІвЂљВ¬РІР‚В x of the target
* Let us first consider lead properties
* It's mass density is about 10,000kilograms per cubic meter
* The molecular weight is0.20 kilogram per mole and the number of nuclei per moleis given by Avogadro's number
* The second major ingredient is the cross sectionbetween 1 MeV photons and lead nuclei
* We get it from the data collectedby the Particle Data Group
* And 1 MeV we find a huge crosssection of about 10 barns
* With this we can calculatethe attenuation of the beam
* First, the number density of lead nucleiis approximately 3 times 10^28 per cubic meter
* The exponent of the attenuationlaw is thus of the order of 0.33
* That is to say that the beam isattenuated by only about 28%
* There is no less than 72% of the beam which passes this onecentimeter thick lead plate, despite the enormous cross section
* [MUSIC].


--- SKIP ---: 01_1-4-rutherford-experiment.en.srt


--- SKIP ---: 01_1-4-rutherford-experiment.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-4-rutherford-experiment.en_SENTbySENT.txt
* [MUSIC] During this first model we are introducingthe objects studies in particle physics, so matter, forces and space-time
* In this forth video we give an example
* for calculating and measuring a cross-section forthe Rutherford experiment
* This is the scattering processwhich demonstrated the existence of the atomic nucleus as we know it today
* The goals are to applythe concept of cross-section, in a process that can be treatedin a semi-classical manner
* And to compute an interaction rate fromthe characteristics of an experiment
* We will use a seminalexperiment to demonstrate, how the cross-sectionserves to understand The unknow subatomicstructure of a target
* Geiger and Marsden measured in1909 the angular distribution of alpha particles Р Р†Р вЂљРІР‚Сљ fully ionized He-4 Р Р†Р вЂљРІР‚Сљ scattering off thin foils ofheavy metal like gold
* The preferred model of the time forthe nucleus and for the atoms was due to Thomson who had discovered the electron in 1897
* This model describedthe atom as a homogeneous positive substance in which electrons are embedded
* It thus has a very modest charge density
* In this case, the alpha particles,being much smaller than atoms, should be able to penetrate the foilwith only minor perturbation
* If on the other hand, the atom consistsof a tiny, dense, and positively charged nucleus surrounded by electrons tofill the atomic volume, as proposed by Rutherford, larger scatteringangles would be possible
* As we have seen in the previous video,the classical calculation of a cross section requires to find the relationbetween the impact parameter b and the scattering angle theta
* We will calculate the relation for non relativistic velocities ofthe incident alpha particle
* We base this calculation on three laws
* The first one is Newton's law whichrelates the rate at which the momentum changes to the Coulomb force betweenprojectile and target nucleus
* It is quoted here using the variablesindicated in the sketch on the right
* The second law is the conservationof kinetic energy, characteristic for elastic scatteringon a heavy target, which does not recoil when hit by the projectile
* The third one is the conservationof angular momentum which introduces the angular velocity dgamma/dt
* Combining these three equations weobtain the relation between the impact parameter b and the scattering angle theta,which we are looking for
* If you are interested inthe details of the calculation, we refer you to the video 1.4a
* Inserting our result into the general relation for the classical cross-section,we obtained the differential cross-section for the Coulomb interaction witha point like heavy target
* The cross section is proportional tothe square products of the two charges (z Z)^2
* This factor determines the orderof magnitude of the cross section
* The cross section is strongly peaked inthe forward direction according to 1/sin(theta/2) to the fourth power, and inversely proportional to the squareof the kinetic energy of the projectile
* These factors are due to the propagatorof the photon exchanged between the two reaction partners
* These basic properties have indeed beenexperimentally established by Geiger and Marsden counting the impact ofthe scattered alpha particles on a screen coveredby zink sulfate
* This molecule emits a small flash oflight when hit by a charged particle
* The experimenters counted these flashes bywatching the screen through a microscope
* Is it realistic to countscatters by eye in such a setup
* The small video 1.4b will convinceyou by actually calculating the rate
* So the procedure to measure a cross section is thus clear
* One must count the rate ofinteractions per second
* For that we need a detectorat a distance r covering a surfacer^2 dOmega
* One must then normalize the countingrate by the maximum possible interaction rate to obtain a probability
* The maximum rate is obtained when everyprojectile interacts with the target
* It is thus the product ofthe incident rate and the surface density ofthe target particles
* It can also be expressedby the flux of projectiles multiplied by the number of targetparticles covered by the incident beam
* The proportionality factorbetween the counted rated and the maximum counted rateis the cross section
* The proportionality factorbetween counting rate and cross section is called luminosity
* In the laboratory frame wherethe target is at rest it is given by the rate of the incoming beam timesthe surface density of target particles
* If you want to use the volume density ofthe target you multiply by the target thickness
* In the center of mass frame, where twobeams collide head-on like in a collider, the luminosity is proportional tothe population of the two beams, n_a and n_b, and tothe frequency f at which they cross
* And it is inversely proportionalto the common surface S of the two beams
* Counting rate and luminosity thus depend on the details ofthe experiment that we are conducting
* Their ratio, the cross section,characterizes the physical process independent of these details
* Until now we have only considered processes using the toolkit of classical physics
* But we already know thatthis is not sufficient
* In the next video we will show how quantumphysics approaches scattering processes
* Further on we will introducean indispensable tool kit of particle physics, Feynman diagrams
* [MUSIC]


--- SKIP ---: 02_1-4a-rutherford-cross-section-optional.en.srt


--- SKIP ---: 02_1-4a-rutherford-cross-section-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_1-4a-rutherford-cross-section-optional.en_SENTbySENT.txt
* [MUSIC] We will calculate with classical arguments Р вЂњР’В  la Rutherford the cross section of a small nucleus of charge z scatteringof a heavy nucleus of charge Z
* The basis of this calculation, isthe relationship between the differential cross-section and the dependence of theimpact parameter b on the scattering angle theta
* First we use the fact thatthe kinetic energy is conserved, and that, as there is no recoil of the target,the initial and the final projectilevelocities are the same
* In the same way,the angular momentum will be conserved, which tells us that mvb is a constant
* This means that dgamma/dt can beexpressed in terms of the initial velocity of the projecile,the impact parameter and the distance squared betweenprojectile and target
* This serves to express the Coulomb force, which is just the product of the twocharges divided by 4 pi r^2, times the unit vector which connectsthe projectile and the target, in terms of what we know that is to say,the projectile velocity and the impact parameter
* When we integrate this relationshipbetween gamma = 0 and gamma = pi-theta, one side is the vector difference betweenthe final and initial velocities
* The other side is the integral overthe relationship we just obtained
* With a little trigonometry, we get Р Р†Р вЂљРІР‚Сљ ratherpainfully Р Р†Р вЂљРІР‚Сљ the value of this integral
* In particular, we obtain that the integralof the unit vector between the initial and final states, is = 2 cos(theta/2)
* On the other hand,simple trigonometry gives us a relationship between the lengthof the vector difference between final and initial velocity and the scattering angle,which turns out to be 2 v sin/theta/2)
* The two relationships togetherfinally give us the relationship between impact parameter andthe scattering angle we have been looking for
* We then insert this resultinto our formula for the differential cross section
* After some simplification,we finally obtain the Rutherford formula for the differential crosssection of the process
* It tells us that there isa very steep angular dependent, inversely proportional tosin^4(theta/2)
* [SOUND]


--- SKIP ---: 03_1-4b-counting-rate-rutherford-optional.en.srt


--- SKIP ---: 03_1-4b-counting-rate-rutherford-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_1-4b-counting-rate-rutherford-optional.en_SENTbySENT.txt
* [MUSIC] In the beginning of last century,Geiger and Marsden have measuredthe Rutherford reaction
* They have counted scatters by eye
* In this little video we will convinceourselves that this is indeed possible
* Geiger and Marsden took a sourceof polonium 210, an alpha emitter collimated to an intensity ofabout 1,000 particles per second, which scattered off a gold foilof 100 nanometers thickness
* And they counted the number of scattersper second by eye at angle of ten degrees at a distance of ten centimeters and overan area of about one square centimeter
* Let us first computethe properties of gold
* It has a density of about 2 times 10^4kilogram per cubic meter
* Its charge is 79 andits mass is 197 atomic units which gives us a number density of about 0.6 times 10^29 nuclei per cubic meter
* Alpha particles are He-4 nucleiwith charge 2 to 4 mass units and an initial intensity of 10^3 persecond comes out of the collimator
* The cross section for Rutherfordscattering is proportional to the product of the two charges squared inversely proportionalto the incident energy squared and the sin^4 of halfthe scattering angle
* Using the correct conversion factors, we thus obtain a differential crosssection at an angle of 10 degrees of 2 times 10^-24 square meters steradian
* This corresponds to a fraction of theinitial intensity of about 1.3 per mil, which is scattered intothe observed solid angle
* That is to say the count rate is about 1.3 Hz,easily observable by the naked eye
* [MUSIC]


--- SKIP ---: 01_1-5-quantum-scattering.en.srt


--- SKIP ---: 01_1-5-quantum-scattering.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-5-quantum-scattering.en_SENTbySENT.txt
* [MUSIC] In this first module, we're in the processof introducing objects studied by particle physics, namely matter,forces and space-time
* And in this context we must obviouslydiscuss scattering processes
* In this fifth video, we will show how toapproach the scattering processes between particles in a quantum way
* The goals for you are to identifythe conceptual differences between the classical approachthat we've used up to now, and the quantum evolution of a system
* And to know how to drawa Feynman diagram for simple scattering processes andexplain its ingredients
* In video 1.4 Mercedes has calculatedthe differential cross section for Coulomb scattering off a static target,which is reproduced here
* By lucky coincidence, the classical result is still validin a relativistic quantum context
* The reasons are the following
* The result of quantum theorycontains no factor of hbar
* This means that the artificial limit hbargoing to zero which normally takes us back to the classical result will notchange the answer that we obtained
* The classical result is also validin the relativistic regime already
* This fact is not surprising, Maxwell's equations are valid forrelativistic velocities
* After all,they also include the motion of photons
* We also do not need to take into accountnuclear interactions between projectile and target, since the alpha particle willnever penetrate into the target nucleus, even for a head-on collision
* Only the electromagnetic forceacts outside the nuclear volume
* But until now, we have discussedthe scattering process in a language adapted to classical physics
* Now, we will change toolkit todiscuss the quantum approach
* So while the classical resultsstays valid in the quantum regime, the interpretation is totally different
* Particles may well be point-like butthey move like a probability wave
* Also, because of Heisenberg's principle,the impact perimeter b has no more role in our consideration
* We must use a scenario Р вЂњР’В  la Huygen tounderstand how scattering works
* This means that the target particle willbe the origin of a new scattered wave, which will add to the incomingwave of the projectile
* The classical trajectory is replacedby the wave function psi(x), as we've mentioned earlier
* It contains the particle aspect, energy andmomentum, and the wave expect, frequency and wave number,of the kinematics at the same time
* Before the scattering, the projectileis described by a plane wave in the x direction in our little example
* Here we have also normalizedthe amplitude to one for simplicity
* Huygens' principle saysthat a small fraction f of the incident amplitude will bespherically re-emitted by the target
* The factor 1/r inthe scattered amplitude is necessary
* It ensures that the number of scatteredparticles, psi* psi, remains independent of distance
* The remaining amplitude (1-f)continues as an unperturbed plane wave
* As a consequence of the wave approach wemust also reinterpret the cross section in terms of intensities of incoming andscattered wave
* This means that we now look fora relation between the cross section and the scattered amplitude f(theta,phi)
* The square of the second term isproportional to the number of particles scattered into a volumesubtended by a solid angle dOmega, and the radial thickness dr
* It represents the scattered flux
* For a normalized incident wavethe particle density is rho=1
* Thus the incident flux is simply rho timesthe velocity, or the velocity itself
* The ratio between the scattered and the incoming flux is preciselythe cross section
* We find a simple result,f is the probability amplitude for our scattering process
* And sigma = f^2is the scattering probability itself
* The amplitude f is calculable if we knowthe potential generated by the target, just like in the classical sense
* To visualize reactions between particlesand calculate their probability, we use a very, very useful toolwhich is called Feynman diagrams
* They represent lines of propagationof particles in coordinates E and p
* Not in space-time but in momentum space
* They also represent the vertices ofan interaction, that is the points where a force particle is emitted orabsorbed to transmit energy and momentum
* Finally they represent the virtualparticles living between two vertices
* Those have the properties oftheir real counter part, but not the mass of a free particle
* Feynman diagrams are a usefulvisualization of a reaction but also a prescription forcalculating their probability amplitude
* One does that by applyingwhat is called Feynman rules
* At each vertex energy, momentum, andquantum numbers are rigorously conserved
* The virtual particle transfersenergy momentum from one of these particles to the other one, thus a forceact between the projectile and the target
* Details on how to construct a Feynmandiagram will be discussed in module 4 when we talk about electromagneticinteractions in a quantum way
* For each type of elementaryinteraction there is a spin one boson transmitting the force aswe have explained before
* They are collectively called gauge bosons
* The photon transmits electromagneticinteractions, the W and Z bosons transmit the twoforms of weak interactions
* And the eight differentgluons are responsible for transmitting strong interactions
* To absorb or emit one of these bosons a particlemust carry the required type of charge
* In our jargon we say the bosoncouples to a given charge
* The charge is thus a coupling constant
* It needs electrical chargeQ to couple to the photon
* Q has one component
* It needs weak isospin T andT_3 to couple to W and Z
* This charge has two components
* It needs color charge R,G or B to couple to gluons
* This charge has three components
* The probability amplitude to emit or absorb a gauge boson is proportionalto the charge of the particle
* The probability is thus proportional tothe square of the charge as we found for Rutherford scattering already
* In the Feynman diagram at each vertexenergy and momentum are conserved
* But do not forget that virtualparticles which relate two vertices do not necessarily have the massof their real counterpart nor even a real number as their mass
* At each vertex charges aswell as baryon and lepton number are conserved
* Flavor is conserved by electromagnetic and strong interactions as we statedbefore but not by the weak one
* Charge weak interactions transmitted by aW boson in fact change a particle flavor
* Here are a few examples of allowed andforbidden vertices
* Let's start in the top row on the left
* In this top left diagram, neitherthe photon nor the Z bosoncan change the flavor of the lepton
* The electron must thus stay an electron
* In the second top diagram from the left, conservation of charge requires thatthe emitted W boson has a negative charge
* We can only emit a negative boson
* On the right-hand diagram, we showa diagram that does simply not exist
* Since the electron does not carry colorcharge, it cannot emit or absorb a gluon so this diagram is simply non-existant
* Now let's go through the bottomrow of these diagrams
* On the left you find a u quarkthat emits a photon or a Z
* Neither of these two particlescan change the flavor of the quark such that it must stay a uquark and cannot become any other quark
* In the middle diagram, the flavor changes
* The u quark becomes a dquark by emitting a W
* And if you make the balance ofthe charges you start out with a plus two-third charge and you come outwith a minus one-third charge quark
* So you must emit a W^+to conserve charge
* The right-most diagram isa diagram of strong interactions
* The incoming red d quark emits a gluon andbecomes a green d quark
* And in order to conserve color the quantumnumbers carried by the gluon must be red, anti-green
* On the other hand, the gluon isnot able to change the flavor of the particles such that the dquark must indeed stay at d quark
* In the next video we will visitthe laboratory of the nuclear physics course at University of Geneva tosee how our students go about to measure the Rutherford cross-section
* [MUSIC]


--- SKIP ---: 01_1-6-rutherford-experiment-in-practice-optional.en.srt


--- SKIP ---: 01_1-6-rutherford-experiment-in-practice-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-6-rutherford-experiment-in-practice-optional.en_SENTbySENT.txt
* [MUSIC] >> To conclude the first module of this course, we visit the lab course on nuclear physics at University of Geneva, to see how one does an experiment Р вЂњР’В  la Rutherford
* I present Dr
* Alessandro Bravar, a senior lecturer in our department, who is responsible for this lab course
* He is also an active researcher, like all our collaborators, who is part of our neutrino physics group and also has his own experiment, which he prepares to measure the detailed properties of muons
* It will take place in a few years at the Paul Scherrer Institute in Villigen, near Zurich
* So in front of us we have a typical set-up for a Rutherford experiment
* Alessandro, can you please explain the ingredients of this set-up and the way it works
* >> Okay
* Here, we try to repeat the Rutherford measurements, but with modern equipment and a technique that looks a bit like the experiments that we make today to study, for example, the electron structure
* So we have, in our case, an alpha emitter, which emits alpha particles sent to a target, and we are detecting alpha particles scattered by the target
* >> Indeed, it was not Rutherford, who did it first, it was Geiger and Marsden who have implemented his idea
* >> But it was Rutherford who interpreted the observations of Geiger and Marsden
* So to make this experiment, we have to work in a vacuum
* This will require to open this box in a moment, to show all the ingredients
* The reason that one works in vacuum, is that we use alpha particles and alpha particles are already stopped by an air layer of about ten centimeters
* So that the alpha particles can propagate from the source to the target and our detector, we need to remove all the air that otherwise would stop the particles
* We have therefore put in in this box with a pump that pumps the air; it makes the noise you hear now
* What we will do now is to stop the pump and open the cover to see all the ingredients of the experiment
* >> Let's go
* You open the valve
* >> Yes, first thing, open the valve and let the air in, otherwise we cannot lift the cover
* >> We hear the faint sound of air entering the vacuum chamber
* I think this is it
* >> Not yet
* We have to wait a while
* Here we go
* So we open the vacuum chamber and the three main components of the experiment can be seen
* Here we have a source of americium that emits alpha particles
* Alpha particles travel to a target, here we use a gold foil with a thickness of 1 micron
* Alpha particles interact with the gold nuclei and are scattered by the gold nuclei in different directions
* To detect these alpha particles, we use a silicon detector, a diode placed in the tube here
* We will see the silicon detector in a little more detail
* Thank you Martin
* That's our silicon detector
* The central part we see here is the active part of the detector, while the rest serves to define the acceptance of the detector
* Behind it there is a small connector to measure the electrical signal generated by alpha particles, which are completely absorbed in this detector
* >> The signal is then propagated
* >> Yes, it goes through this cable and an amplifier we have here, because the charge left by an alpha particle in the silicon detector is only about a few femtocoulombs and we need to amplify this signal for detection
* >> Then the experiment is to measure the count rate, the rate of alpha particles, which have been deflected, depending on the angle that the detector made with incident alpha beam
* The target may be varied, it may be gold of different thicknesses, and can also be made of other metals, such as iron here, 3 microns of iron, nickel, a thin foil 3 microns thick, or different thicknesses of gold, as here, a gold foil of half a micron
* One varies two things: the target, that is to say the Z and the thickness Р С›РІР‚Сњx of the target in the direction of the beam, and one varies the angle
* How many different angles does one typically measure in an experiment
* >> About a dozen different angles One puts the detector on both sides of the alpha beam to ensure, that we make a symmetric measurement relative to the dir


--- SKIP ---: 01_2-1-nuclear-mass-and-binding-energy.en.srt


--- SKIP ---: 01_2-1-nuclear-mass-and-binding-energy.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-1-nuclear-mass-and-binding-energy.en_SENTbySENT.txt
* [MUSIC] Hello, welcome to the second module of ourintroductory course on Subatomic Physics
* During this module, we'll deal withnuclear physics and its applications
* At the end of the module, we will visit the Tokamak of the SwissInstitute of Technology in Lausanne
* And the Beznau Nuclear Power Plant whichis the oldest one still in operation
* This is pretty mucha self-contained module, if your main interest is nuclear physics,you will be well-served
* You will also notice that it issomewhat longer than other modules, so just take your time to digestthe contents without pressure
* In this first video, we will reviewwhat is known about the mass of nuclei
* The goals for you are the following
* To know the nomenclature of atomicnuclei and their periodic system
* And to be able to qualitatively describethe mass and binding energy of nuclei
* Experiments of the Rutherford typedemonstrate the existence of a positively charged nucleus, which is four orders of magnitudesmaller than the size of the atom
* These experiments only requireto understand electromagnetic interactions between the project andthe target
* Scattering experiments can also yieldinformation about nuclear properties
* And thus establish a catalog ofthe properties of the nuclear interaction that holds together protons andneutrons inside the nucleus
* One must not confuse this nuclear forcewith the strong force introduced in the first module and more extensivelydiscussed in module number five
* The strong force binds together quarksinside hadrons by gluon exchange
* It does not permit quarksto leave the hadrons
* So hadrons in general and nucleons in particular,do not carry a net color charge
* Thus gluons cannot bind protons andneutrons to form a nucleus
* The nuclear force is more like a longdistance residue of the strong force in that it resembles the well-knownVan der Waals force, which is a residue of the electromagneticinteraction which acts between electrically neutral molecules
* Let us compare some basic properties ofatoms, and the electromagnetic force on one side, to nuclei, andthe nuclear force on the other side
* The electromagnetic force isresponsible for holding atoms together
* Its properties are well known,classically, and rather easy to extrapolateto quantum distances
* The study of atomic spectra indeedgave rise to quantum mechanics, which qualitatively and quantitatively explains many phenomenaof condensed matter physics
* The fine structure constant, the electromagnetic couplingconstant, is a small number
* Alpha is about 1/137, which makesperturbative calculations feasible
* The nuclear force, on the other hand,must be much stronger, since it wins over the Coulomb repulsionbetween tightly-packed protons
* It must be of short range, since it doesn't make itselffelt outside the nuclear volume
* It has no classical analog
* Only experimental results can helpto understand its properties
* One thus uses experiments asa guide towards empirical models of the nucleus and of the nuclear force
* We will come back to the relation betweenexperiments and models as we go along
* Let us first summarize how we identify anddenote nuclei
* We denote by Z, the nuclear charge, which is equal to the atomicnumber in the periodic table
* Itis given by the numberof protons in the nucleus
* A is the number of nucleons,the sum of protons and neutrons, it is also called the mass number
* Nuclei are thus completely identifiedby their electric charge and the number of nucleons
* The name we give them identifies Z andusually is supplemented by A
* When we say carbon 14, that means a nucleus with Z=6 and A=14
* Evidently, the number of neutrons is thenthe difference between the mass number and the atomic number, and is denoted by N
* The chemical properties of the elementsare determined by the electron cloud surrounding the nucleus
* The periodic table is thusorganized according to Z
* Nuclei with the same number of protons,but with a different number of neutrons,are called isotopes
* They have very similarchemical properties but not necessarily similarnuclear properties
* Examples are uranium 235 anduranium 238, which have both 92 protons, but a different number of neutrons andthus different stability properties
* Another example is hydrogen,deuterium, and tritium which all have one proton andzero, one, or two neutrons
* Nuclei can also beexcited to higher states, keeping the number of protons andneutrons constant
* These are called resonances or isomers
* Nuclei with the samenumber of nucleons but the different number ofprotons are called isobars
* They have roughly the same nuclear mass
* Examples are carbon 12 and boron 12,with both have 12 nucleons
* Naively one might assume that the massof nuclei is simply given by the sum of the masses of protons andneutrons they contain
* But in reality, this mass is, of course, diminished by the bindingenergy between the nucleons
* The mass deficit Р Р†РІвЂљВ¬РІР‚В Mmust always be negative so that the nucleus is in a bound state
* We call it the binding energy
* It has been measured forpractically all nuclei
* The absolute value of the binding energyis the energy required to decompose the nucleus into separate nucleons
* The binding energy per nucleon,Р Р†РІвЂљВ¬РІР‚В M/A, is the energy required to separatethe average nucleon from its nucleus
* It is much smaller thanthe mass of a nucleon p and n
* The mass of the nucleus is thus indeeddominated by the mass of its constituents
* For the nucleons themselvesthe situation is very different
* The total mass of the quarks insidethe nucleon is only around 1% of the nucleon mass
* It is their binding energy whichdominates the nucleon mass
* When one analyzes the dependance ofthe binding energy, Р Р†РІвЂљВ¬РІР‚В M per nucleon A, on the mass number A onenotices the following
* For A less than 20 onthe left side of this graph, Р Р†РІвЂљВ¬РІР‚В M/A oscillates butrises rapidly with increasing A
* For A between 20 and 60, Р Р†РІвЂљВ¬РІР‚В M/A saturates
* For A about 60, it has a broad maximum
* That is, the iron group formed by nickel,iron, and cobalt with about 9 MeVper nucleon of binding energy
* And then for A larger than 60, the bindingenergy per nucleon decreases slowly
* The general mean is about 8 MeV per nucleon
* The kinetic energy of nucleons insidethe nucleus must thus be relatively small
* Otherwise, they would not stay bound
* The velocities of bound nucleonsare thus non-relativistic
* The binding energy corresponds indeed to awavelength of nucleons inside the nucleus
* This wavelength is less than two Fermi ofthe order of the nucleus' size itself
* It is thus plausible that the nucleus cancontain nucleons with the maximum kinetic energy of about 8 MeV
* Or a maximum momentum of about 120 Me
* If, on the other hand,the nucleus would contain electrons, they would be relativistic andtheir wavelength would be 2.5 x 10^-12 centimeters,much bigger than the nucleus size
* The nucleus can thus notcontain bound electrons
* They need a much largervolume to be contained
* This is obviously in agreement withthe findings of Geiger and Marsden, that we have discussedin the previous module
* In the next video, we will talk aboutthe size and the spin of nuclei
* [MUSIC]


--- SKIP ---: 01_2-2-nuclear-size-and-spin.en.srt


--- SKIP ---: 01_2-2-nuclear-size-and-spin.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-2-nuclear-size-and-spin.en_SENTbySENT.txt
* [MUSIC] During this second module, we deal withnuclear physics and its applications
* In this second video, we will summarize what is known aboutthe size and the spin of nuclei
* The goals for you are to know how nuclearsize is measured and what the results are
* To know general factsabout the spin of nuclei
* And to be able to describe the valleyof stability of nuclei as a function of the number of protons andneutrons
* The size of a subatomic objectmust be carefully defined
* In a quantum system, it is given bythe root mean square of the eigenvalue of the coordinate operatorin its ground state
* For an atom, this is the root mean squareof the radial position of the electron, which is farthest away from the nucleus
* This distance can be calculatedbecause we know perfectly the binding electromagnetic force and because it is defined withrespect to a static reference point, the position of the nucleus
* For the nucleus, we do not havea simple description of these actions
* So we must interpretthe results of experiments, which probe the distribution ofnucleons inside the nucleus
* It will be unwise to usehadronic probes to do so because they are sensitiveto the nuclear force
* High energy electrons, on the contrary,can penetrate inside the nucleus and their scattering maps out the chargedistribution of the target
* The cross section for a point-like target without spin is givenby the Mott formula displayed here
* If the charge instead isdistributed according to a volume density rho(x),leaving the total charge intact, the cross section will bereduced by form factor F(q), which is a function ofthe momentum transfer q
* For a static target, F(q) is the Fourier transform ofthe spatial charge distribution
* For small momentum transfers, we can develop the formfactor in a Taylor series
* If the distribution isspherically symmetric, the terms with an odd power drop out
* And the dominant second term isproportional to the mean square radius, <r^2> of the charge distribution
* And this can serve as a size estimator forthe nucleus
* For an exponential charge distribution, the form factor takes whatis called a dipolar form
* The dependence of the electron nucleuscross section on the momentum transfer for small angle scatteringat high electron energies is thus used to measurethe size of the nucleus
* Scattering experiments establisha simple relation between the radius of a nucleus R andthe number of nucleons A
* The radius is proportional to the cuberoot of the number of nucleons, with a universal proportionalityconstant of 1.2 femtometers
* Nuclei are thus indeed smallcompared to the atomic size
* The nuclear volume is proportional to A
* This corresponds to densely packed andincompressible nucleons, which do not fuse
* The mass density of nuclear matter isof the order of 10^14 grams per cm^3
* Nuclear spin is the sum of the spinS of all individual nucleons and the relative angular momentum, L
* Protons andneutrons are fermions with spin one-half
* Like in atoms, the nuclear angular momentum Lfollows an integer quantum number
* The total should therefore be ahalf integer number if A is odd, an integer if A is even
* Indeed, all nuclei with both N andZ even have nuclear spin 0
* Heavy nuclei have rather smallnuclear spin in their ground state
* We conclude that neutrons and protons tend to arrange in pairsof opposite spin direction
* Every charged particle has a magneticdipole moment associated with its spin, including the nuclei
* The order of magnitude for an electronis given by the Bohr magneton, Р вЂ™Р’Вµ_B
* The nuclear magneton is three ordersof magnitude smaller due to the larger proton mass
* The gyromagnetic factor g measuresthe ratio between the angular momentum and the magnetic moment
* For a point charge,g is about 2 with small deviation of order 10^-3 for electrons andmuons as we will see in module 4
* The magnetic moments of proton andneutron are considerably different, +2.79 and -1.91 nuclear magnetons, respectively
* This is the first indication ofa charged substructure of the nucleons
* In fact, since the neutron has zero netcharge, it must contain charged particles
* All nuclei have measured magneticmoments between minus three and ten nuclear magnetons, thus,relatively small ones
* This is a consequence ofthe spin pairings of nucleons, leading to a limited totalnuclear angular momentum
* Most nuclei andtheir isotopes are unstable
* Stable nuclei are found in a narrow band, in the N-Z diagram which iscalled the valley of stability
* The valley has the following shape
* For lighter nuclei withatomic mass less than 40, the number of neutrons equalsthe number of protons
* For heavy nuclei withatomic mass bigger than 40, the number of neutrons is about1.7 times the number of protons
* This indicates that forheavy nuclei, the charge density, and thus the Coulomb repulsion mustbe diluted by additional neutrons
* The decay of unstable nuclei isthe source of nuclear radioactivity
* Alpha radioactivity isthe emission of He-4 nuclei or so-called alpha particles
* Beta radioactivity isthe emission of electrons or positrons together with neutrinos
* And gamma radioactivity isthe emission of photons
* Nuclei with a surplus ofneutrons can be stabilized by converting a neutron into a proton
* And those with the surplus of protonscan convert a proton into a neutron
* These are isobar decays oftype beta plus or minus
* Heavy nuclei often decay intoa pair of lighter nuclei
* This corresponds to spontaneous fission,often by emitting a He-4 nucleus
* This is the alpha decay
* This decay is normally related toan excited state of the daughter nucleus
* And they're often followed by a gammadecay towards the ground states
* We will enter into more detail onthese processes in the fourth and fifth video of this module
* So let us summarize what we havelearned about the nuclear force
* It has a very short rangelimited to the nuclear size
* The binding energy per nucleon it leads tois independent of the size of the nucleus
* The nucleon thus interacts onlywith its nearest neighbors
* The nuclear force is attractive and much stronger than the Coulombrepulsion between protons
* But it must also have a repulsivecomponent at distances compatible to the size of the nucleon,which is about 1 femtometer
* This is due to the existence ofquarks inside the nucleon
* The repulsive component is necessaryto prevent the fusion among nucleons
* QCD is a quantum fieldtheory which describes the interaction among colored particles, so quarks inside hadrons, via the exchange ofequally colored gluons
* But the strong force acts only insidehadrons, which thus have a zero net color
* Nucleons cannot exchange gluons
* It is by the exchange of colorless objectslike mesons that they bind together
* This makes the nucleus a complex multibodyobject, which is difficult to understand
* The appropriate theoretical methodsare effective field theories like Chiral Perturbation Theory ora numerical calculation like Lattice QCD
* All of this goes beyondthe scope of this course
* In the next video, we will ratherconcentrate on much simpler models, which describe the grossfeatures of nuclei
* [MUSIC]


--- SKIP ---: 01_2-3-models-of-nuclear-structure.en.srt


--- SKIP ---: 01_2-3-models-of-nuclear-structure.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-3-models-of-nuclear-structure.en_SENTbySENT.txt
* [MUSIC] During the second module,we are discussing nuclear physics and its application
* And in this third video we will introducesimple models which allow to better understand the structure of nuclei andtheir properties
* After watching this video youshould be able to describe these models of nuclear structure
* Distinguish which features each modeldescribes and where it's limits are and in particular know the so-called magicnuclei and their special properties
* For reasons discussed in the previousvideos we know quite well the strong force acting between quarksinside the protons and neutrons, thanks to quantum chromodynamics
* A complete theory of the nuclearforce between these based on first principles of QCD however does not exist
* Since we do not know how to calculatethe properties of the nuclear force ab initio it is difficult to apprehendnuclear structure theoretically
* Consequently the models of nuclearstructure are rather qualitative
* Most precede QCD itself, the models of nuclear structureare rather qualitative
* However, one can of course base modelbuilding on experimental facts and on physical intuition
* Each of these models presented in thefollowing will concentrate on a particular aspect of nuclear structure andnuclear properties
* So let us start with the most simple onewhich is called the liquid drop model
* In this model, which has been the first phenomenologicalmodel to describe the binding energy and size of nuclei, the quantum propertiesof nucleons are largely ignored or taken into account in an ad hoc way
* The model describes the nucleusas a compact packing of incompressible nucleons
* This gives a total nuclear volumeproportional to the number of nuclei, as we have observed
* The mass density of nuclei isapproximately independent of A
* This considerations lead toimagine the nucleus like an incompressible drop of liquid
* The molecules ofthe liquid are the nuclei
* The Van der Waals force is replaced by nuclear force
* The binding energy Р Р†РІвЂљВ¬РІР‚В M orBE on this slide is equal to the mass difference between the nucleusand the sum of it's nucleons
* It is the energy won by the boundsystem and thus negative for stable nuclear states
* It is principally proportional to A,i.e
* to the number of nuclei or the nuclear volume
* This is due to the fact that each nucleon mostly interacts withit's nearest neighbors
* But the nucleons on the outer boundary haveless neighbors and are less tightly bound
* This is taken into account by a term proportional to the nuclearsurface A to power two-thirds
* It's always analogous to the surfacetension of a liquid drop
* It reduce the binding energy, per nucleon, and it makes the bindingenergy somewhat less negative
* Hence it has a positive sign
* This surface term is more important forheavy than for light nuclei,which explains their less tight binding
* The third term takes into accountthe energy of Coulomb repulsion between protons
* This term also decreases the absolutevalue of the binding energy and thus has are positive side
* Up to now the considerationsare purely classical but corrections inspired byquantum effects are important
* Like nuclei with a equalnumber of protons and neutrons, that is to say Z=N,are particularly stable
* They have a more negative binding energy
* Also there are more stable even-evennuclei and few stable odd-odd nuclei
* Odd and even refers to the numberof protons and neutrons
* One thus adds twoempirical terms to obtain what is calledthe Bethe-Weizsacker formula
* The asymmetry terms reduces the bindingenergy for N not equal to Z and the pairing term has a positive sign forodd-odd nuclei which are less stable
* For even-even nuclei the sign is negative andthe nuclei more stable
* For all other combinations, i.e
* forodd A, the last term is zero
* Once the coefficients ofthe terms a_1 through a_4 are adjusted to match nuclear masses, the formula describes rather accurately the bindingof sufficiently heavy nuclei
* It is less accurate for light nuclei, and it fails especially to matchthe exceptionally large binding energy of the very stable He-4 nucleus
* However, we will use it extensivelyto qualitatively understand the phenomena of fusion and fission
* An approach more compatible withthe quantum nature of subatomic particles is the Fermi gas model
* In this model, the nucleus isdescribed as a gas of free protons and neutrons, confined to the nuclear volumeby a potential of unspecified origin
* The nuclei then occupyquantized energy levels, the potential is modelledas a spherical well
* It's size representsthe size of the nucleus
* It's depth is adjusted to obtainthe right binding energy
* The difference betweenthe ground states of protons and neutrons is due to the Coulomb potentialwhich is only present for protons and decreases the depth of a potential well
* Since n and p are fermions there can be only two perenergy level with opposite spin
* The last filled energylevel defines the energy which refers to the leasttightly bound nucleons
* So how many nucleons canwe store in a given volume
* It's the SchrР вЂњР’В¶dinger equationthat gives us the answer
* We consider the nucleons to beconfined to a square box with side a
* The solution can then be factorized with n_x, n_y, and n_z positive integer numbers anda normalization factor a
* The phase space is thus quantified
* Setting E equal to p^2/2m one sees that k_i are the wavenumbers equal to the momentum along each axis in natural units
* So now we can count states,let us consider momentum space
* Due to the boundary conditions, foreach elementary cube of side pi/a there is a single point which is compatiblewith the SchrР вЂњР’В¶dinger equation
* The number of viable solutionswith the wave number between k and k + dk is thus the ratio ofthe corresponding spherical shell and the volume element, (pi/a)^3rd
* The volume of the box is a cube but we only consider 1/8,since all k_i must be positive
* In the grand state all levels up tothe maximum momentum are filled
* Integrating up to the Fermi mo,entum one does obtains thenumber of states which can fill the volume
* One must of course take intoaccount the factor of two for the two spin orientations,as well as the nuclear volume, which is 4 (pi/3) r_0^3 A
* The energy correspondingto the maximum momentum is, what is called a Fermi energy, E_F
* It is approximately 33 MeV independent of A
* The result is in fact also independent ofthe shape of the confinement volume
* The value of the Fermi energymeans that the nucleons are non relativisticinside the nucleus but still move at a considerablevelocity, Р вЂњРЎСџ equal to roughly 0.4
* The nucleus is thus a verydynamic environment indeed
* The model also explainsin a rather natural way the asymmetry term of the Bethe-WeizsР вЂњР’В¤cker equation
* Given E_F the Fermi energy andthe binding energy of the last nucleon of roughly 8 MeV we obtain a potentialdepth V_0 of about 40 MeV
* In analogy with the atomic shell model,a shell model for the nucleus can be constructed
* The orbital quantum number n describesthe energy level of the nuclei
* For each n, there are n levels oforbital angular momentum l and 2l+1 subshells of the projectionof l on an arbitrary axis
* These subshells are degenerate in energy because of the rotational symmetryof the Coulomb potential
* There are two spin states per subshellwith m_s equal to Р вЂ™Р’В±1/2
* A state can thus be described by fourquantum numbers, n, l, m_l, and m_s
* The nuclei with completely filledshells are particularly stable, which explains the notion ofmagic numbers, which are Z or N equal to 2, 8, 20, 28,50, 82, 126, and so forth
* Isotopes with shells of both protons andneutrons completely filled, i.e
* with Z and N equal to a magicnumber are even more stable
* Example of these doublymagic nuclei are He-4, O-16, Ca-40, Ca-48, Ni-48, Ni-56 and PB-208
* One of the strong points of the shellmodel is its prediction of nuclear spins
* According to the model p and n fill up the levels independently, two ineach subshell due to the Pauli principle
* In this way, the last or valence nucleon, which does not have a pair, willdetermine the nuclei spin
* The immediate consequence is thateven-even nuclei should have spin 0 in agreement with observation
* However the share model fails topredict the spin of odd-odd nuclei since it does not include interactionsbetween protons and neutrons
* When the correct spin is predicted, the model also gets the nuclearmagnetic moments right, which is important for nuclear magneticresonance phenomena for example
* We will talk about that when we treatapplications of nuclear physics
* It is obvious that more sophisticatednuclear models than those we have treated here can be constructed
* But that goes beyond the scopeof this introductory course
* In the next video, we will rather go overthe properties of unstable nuclei and their radioactive decays
* [MUSIC]


--- SKIP ---: 02_2-3a-qcd-and-nuclear-force-optional.en.srt


--- SKIP ---: 02_2-3a-qcd-and-nuclear-force-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_2-3a-qcd-and-nuclear-force-optional.en_SENTbySENT.txt
* [MUSIC] Here in the second module, we're in the process of dealing withnuclear physics and it's applications
* We have underlined several times thatthe basics of the nuclear force in terms of quantum chronodynamics,are anything but clear
* The purpose of this optional interludeis to trigger a discussion on this particular subject
* The relation between the nuclear forcewhich binds together nucleons inside the nucleus and the strong forcewhich binds quarks to form hadrons is not clear at all althoughthe two must be obviously related
* In fact the nuclear force oughtto be a long range effect of QCD, binding nucleons viacolor neutral objects
* An interesting discussion is found in thisarticle by one of the fathers of QCD, Fred Wilczek, in the journal nature, thesource is quoted on the top of the slide
* An accessible summary can be found on theweb at the address quoted on the bottom
* And here is a short excerptthat I will read to you
* Ironically, from the perspective ofQCD the foundations of nuclear physics appear distinctively unsound
* He continues by explainingwhat the contradiction is
* Yet QCD tells us that protons and neutronsare themselves built from quarks and gluons that move at verynearly the speed of light
* These more basic particlescarry color charge, leading to the additional requirementthat they be confined within bags whose contents are overall color-neutral
* And he further asks, butwhy don't a separate proton and neutron bags in a complexnucleus merge into a common bag
* On the face of it, the one bagarrangement has a lot going for it
* It would allow quarks and gluons freeaccess to a larger volume of space and so save on the energy cost of localizingtheir quantum mechanical wave function
* But in such a merger, protons and neutronswould lose their individual identities, and our traditional quite successfulmodel of atomic nuclei would crumble
* What prevents that calamity
* I invite you to think aboutthis question yourself, and discuss it in the forum of this course
* We will come back to it in module fivewhere which will deal with hadrons and their strong interaction
* [MUSIC]


--- SKIP ---: 01_2-4-radioactivity-alpha-decay.en.srt


--- SKIP ---: 01_2-4-radioactivity-alpha-decay.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-4-radioactivity-alpha-decay.en_SENTbySENT.txt
* [MUSIC] During this second module, we dealwith nuclear physics and its application
* We'll now discuss radioactivity
* In this fourth video, we'll talkabout nuclear decay in general, and the alpha decay in particular
* After watching this video, you will be able to describe the valleyof stability and its surroundings
* To know how to locate and characterizethe nuclei with respect to this valley, and characterize alpha decays andtheir properties
* An unstable nucleus can transformitself in a more stable one through radioactive decay
* We distinguish three types, historicallylabelled as alpha, beta, and gamma decays
* Alpha decay is the spontaneous fission ofa heavy nucleus into a less heavy one and the nucleus of He-4,also called alpha particle
* The beta decays are transformationbetween a nuclear neutron into a proton, or vice versa,by respectively emitting an electron and its antineutrino ora positron and its neutrino
* This way, both baryon number andlepton number are conserved
* This decay is often leave the daughterthe nucleus in an excited state, and a gamma decays allows it to returnit to its ground state by emitting one or more photons
* Decays are a spontaneous processes
* The happen if they tightenthe binding of a nucleus
* Thus very heavy nucleican reduce their mass and increase their binding energy by emittinga tightly-bound He-4 nucleus
* Nuclei which are rich in neutrons can gaina more symmetric state by transforming one of them into a protonvia a Р вЂњРЎСџ- decay
* Nuclei, which are rich in protons, cancorrect this asymmetry by a Р вЂњРЎСџ+ decay
* And excited daughter nuclei can reachtheir ground state by meeting one or more photons
* All these reactions take the nucleuscloser to the valley of stability
* This table showsthe distribution of nuclei with the stable isotopesover the periodic system
* About 60 radioactive nucleiare naturally present on Earth, compared to about 1,000radioactive isotopes so far produced in the laboratory
* When our planet was formed, we can assume that all these nucleiwere roughly equally abundant
* The absences of certainradioactive nuclei today can give us an idea ofthe age of the solar system
* This estimate give us an age ofroughly 10 billion years for the Sun
* All nuclei with a shorter lifetimehave completely disappeared
* The naturally present radioactivenuclei have a nuclear charge, Z, between 81 and 92
* They are characterized byan excess of neutrons
* Since they are heavy,they first undergo an alpha decay, leading to an even largerrelative excess of neutrons
* This then can be fixed bysubsequent beta decay
* The grand daughters are oftenthemselves unstable and undergo alpha decay and so on
* This results in a chain of alpha andbeta decays which will continue until the valley of stability in the N-Zplane is reached
* All of this results in fourseries of alpha emitters where the daughters progressively differby a multiple of four nucleons
* We have the Thorium series witha mass number which is 4N, the Neptunian series with massnumber A equal to 4N + 1, the Uranium-Radium series with A equal to 4N + 2,and the Uranium-Actinium serieswith A equal to 4N + 3
* One of the important applicationsof radioactivity is the dating of organic materials, which canwork up to several thousand years
* We will see this in moredetail when we speak about radioisotope dating in video 2.7
* Let us now discuss the physicsof alpha decay in more detail
* A parent nucleus, P, decays into a daughternucleus D via emission of a He-4 nucleus
* This corresponds to a spontaneous fissioninto daughter nuclei of vary asymmetric mass, since the nucleus D is muchheavier than the He-4
* For more details on other fission processes,we refer you to the video 2.8
* If we consider the parentnucleus to be at rest, energy conservation gives us a relationbetween the masses and energies
* Since the number of electronsis unchanged in the reaction, you can directly use atomic mass forthis calculation
* T_alpha and T_D are the kineticenergies of the alpha particle and the daughter nucleus
* The gain in binding energy that drivesthe decay is called the Q value
* And it is converted into the kineticenergy of the decay products
* An example of the calculation ofT_alpha and T_D is given in video 2.4a
* Because of the asymmetry inthe masses the alpha particle takes most of the kinetic energy
* The spectra of alpha particlescoming from the decay of the same isotope can revealintermediate metastable states
* One the observes alpha particleswith slightly different but, of course, quantized energies.One also observes gamma ray emission which comes from the decaycascade towards the ground state
* The parent nucleus can of course alsodirectly decay to the ground state without passing by intermediate states
* This direct decay results inthe most energetic alpha particle
* An example is shown here forthe decay chain of Am-241, which is a radioactive sourceoften used in the laboratory
* The kinetic energy of an alphaparticle from nuclear decay is typically of the order of 5 MeV
* When such a low energy particleapproaches a heavy nucleus from outside, it cannot penetrate the Coulomb barrier
* For a nucleus of mass number about 200,it has a typical height of 20 to 25 MeV
* So why does the process workin the opposite direction
* How can an alpha particle traversethe Coulomb barrier from the inside
* The answer is given bythe quantum process of tunneling
* The probability thatan alpha particle traverses the Coulomb barrier is ofthe order of 10^-40
* But this is the probability oftraversing on a single trial
* This is why a low energy alpha particle from the outside cannotpenetrate the barrier
* The velocity of an alpha particle,bound to a nucleus with kinetic energy of about 44 MeV, is notrelativistic but still impressive
* It has a velocity of about0.15 speed of light
* Confined to a region with a radius ofabout 10^-12 centimeters, the particle bounces off the barrierwith a frequency of about 4.5 10^21 times per second
* The probability of penetration per second is thus0.5 10^-18 per second
* This quantity is calledthe decay constant lambda, which is the inverse of the lifetime tau
* For a typical nucleus we find a lifetime of 10^10 years, which is representative fornuclei with alpha decay
* The number of nuclei N(t)remaining after elapsed time t from an initial sample of N_0 nuclei diminishesexponentially according to the decay law
* We will give more detail on thislaw in the optional video 2.5a
* In the next video, we will talk aboutthe other two types of radioactivity, namely beta and gamma decays
* [MUSIC]


--- SKIP ---: 02_2-4a-energy-of-alpha-particles-optional.en.srt


--- SKIP ---: 02_2-4a-energy-of-alpha-particles-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_2-4a-energy-of-alpha-particles-optional.en_SENTbySENT.txt
* [MUSIC]
* We will quickly calculate the kinematicsfor the decay of a heavy parent nucleus P, to an alpha particle, anda daughter nucleus D
* The conservation of energy requires thatenergy gained in the form of missing mass will be transformed into the kineticenergy of the daughter nucleus and the alpha particle
* The masses of the two nuclei are bothlarge, compared to the binding energy
* We can thus do a non-relativisticcalculation with T = 1/2 Mv^2
* For heavy nuclei, which have a much largermass than the alpha particle, the velocity of the daughter nucleus will be negligiblecompared to that of the alpha particle
* It is in fact reduced by the ratio of M_alpha and M_D
* Therefore, most of the Q value isconverted into kinetic energy for the alpha particle, andthe reaction of course, only takes place when the Qvalue is greater than zero
* The kinetic energy of the daughternucleus will be much smaller than that of the alpha particle
* When neglecting the differencesin binding energy between nuclei, we have an M_alpha/M_D roughly equalto 4/(A-4)
* This allows us to approximately calculatethe kinetic energy of the alpha particle and the daughter nucleus
* [MUSIC]


--- SKIP ---: 01_2-5-beta-and-gamma-decay.en.srt


--- SKIP ---: 01_2-5-beta-and-gamma-decay.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-5-beta-and-gamma-decay.en_SENTbySENT.txt
* [MUSIC] During the second module, we deal withnuclear physics and its applications
* And in this fifth video,we go into more details on the two other types of radioactivity,that is to say beta and gamma decays
* The goals for you are to be able tocharacterize beta decays of nuclei and their properties
* To relate these properties to thoseof the underlying weak interactions, and to be able to characterizegamma decays of excited nuclei
* A neutron-rich nucleus, i.e
* one that hasN/Z larger than what stability requires can transform into a morestable nucleus by emitting an electron and transforming one ofits neutrons into a proton in what is called a Р вЂњРЎСџ- decay
* To conserve lepton number, this emission must be accompanied bythe emission of an anti-neutrino
* In the contrary case, proton-rich nuclei,which have too many protons to be stable, can reach stability by Р вЂњРЎСџ+ decay,accompanied by neutrino emission
* Since the proton islighter than the neutron, this latter process can only happen for a bound proton where the Q value is turnedpositive by a gain in binding energy
* A nucleus with a surplusof protons can also capture an electron from the internalK-shell of the atomic cloud
* The other electrons of the atom willthen cascade down to fill the gap
* Since a lepton disappears in the capture a neutrino must be emittedto conserve lepton number
* All these decays are isobar,they have Р Р†РІвЂљВ¬РІР‚В A = 0 and Р Р†РІвЂљВ¬РІР‚В Z = Р вЂ™Р’В±1
* Since beta decays arethree body processes, the spectrum of the emitted electronor positron is a continuous one
* It has the shape which issketched in this graph
* The neutrino interacts onlyvery weakly with matter
* It will normally escape undetected
* This is also the reason why the neutrinohas taken so long to be discovered
* Neutrinos and anti-neutrinos are fermionswith zero electric charge and a very small mass
* The maximum electron energy is obtainedwhen the neutrino is produced almost at rest
* Its maximum value then approaches the Qvalue, like it would in a two body decay
* When one measures this energy, one can establish an upper limit onthe neutrino mass by energy conservation
* The video 2.5a introducesthe exponential decay law, which describes the time evolutionof this and other decay processes
* At the quark level, beta decay proceedsvia the exchange of a W boson, which is the gauge boson mediating the weakforce like it is shown in this Feynman graph
* The large mass of thisboson is responsible for the short range of the weak force andits weakness at low energies
* Neutrinos are very peculiar particles.Their generations can mix with each other
* Their mass is the lightestamong all particles and probably in the order ofmilli electron volt
* It is not even clear if neutrinos and anti-neutrinos are reallydifferent particles
* Their charge is the same, andthey have no magnetic dipole moment, contrary to other neutral particles,like the neutron for example
* The definitive answer will comefrom experiments searching for what is called double beta decay
* They deal with nucleiwhere two beta decays happen simultaneously toreach the value of stability
* If neutrino andantineutrino are really the same particle, one of them can then arrangethe lepton number of the other one, such that there are no neutrinosemitted in the process at all
* If they are not identical, two neutrinos must always be emittedin the process of double beta decay
* For recent review ofthe experimental situation, please see the article by Rodejohanncited on the bottom of this slide
* Weak interactions havetwo more peculiarities
* The first one is that only the left-handed part of the quark and lepton fields participatein the interaction
* What we mean by that is that only matterparticles will spin anti-parallel to the direction of motion,interact via the weak force
* The opposite is true formatter anti-particles
* Only right-handed anti-particles whichhave the spin parallel to the direction of motion can interact
* Neutrinos and down type quarks, andthat is the second peculiarity, which participate in weakened directions,are mixtures of the corresponding real particles
* One denotes the neutrinomixtures of nu_e, nu_Р вЂ™Р’Вµ, and nu_tau according to their generation
* They are mixtures of the real particles nu_L, nu_M and nu_H which we haveintroduced in the first module
* The quark mixtures are denoted by dР Р†Р вЂљРІвЂћСћ,sР Р†Р вЂљРІвЂћСћ and bР Р†Р вЂљРІвЂћСћ for the three generations, mixtures ofthe real particles d, s, and b
* We will come back to these astonishingproperties in module 6 when we discuss weak interactionsin more detail
* What I mean by participating in weakinteractions is that only the left handed mixtures are able to emit orabsorb weak bosons
* What I mean by real particles are quantumeigenstates of the mass operator
* These states propagatewith a specific velocity when their energy-momentum is known
* This is not the case for nu_e orfor the dР Р†Р вЂљРІвЂћСћ for example
* It is the nu_L and the d quark which havea mass which is a constant of motion
* Let us now come to the last type ofradioactivity, the gamma decays
* They often follow another previousdecay which leaves the daughter nucleus in an excited state
* It can then fall back into its groundstate by emitting a photon of a quantized energy
* The energy of the photon willcorrespond to the energy difference between the excited and the ground state
* The study of emission andabsorption of nuclear gamma rays thus constitutes nuclear spectroscopy inan analogy to atomic spectroscopy
* With one remarkable difference, one cannot neglect the recoil ofthe daughter nucleus in gamma decays
* The more massive the system, the lessimportant will be the recoil energy
* One can just freeze the nucleus into acrystal structure which has a much larger mass and allows the recoil tobe reduce to almost nothing
* This is called the MР вЂњР’В¶ssbauer effect,it allows to reduce the line width of a gamma decays to of the order of 10^-7 eV, which in turn allows to measurethe relative line separation to an accuracy to the orderof 10^-12
* One can thus study nuclear energylevels with great precision
* This can also be used to measurethe composition of materials
* We show here an example of the gammaspectrum of natural uranium mineral
* It allows to identify andquantify the presence of radionuclides like Ra-226, Pb-214
* and Bi-214 coming fromthe decay change of U-238, which itself is not a gamma emitter
* In the next video, we are invited tovisit the laboratory of the nuclear physics course at University ofGeneva to see experiments on radioactivity
* [MUSIC]


--- SKIP ---: 02_2-5a-exponential-decay-law-optional.en.srt


--- SKIP ---: 02_2-5a-exponential-decay-law-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_2-5a-exponential-decay-law-optional.en_SENTbySENT.txt
* [MUSIC] In this second module, we deal withnuclear physics and its applications and we're discussing radioactivity
* In this video, we calculate how manydecays per second can be observed from an initial sample of nuclei,that is to say, we discuss the decay law
* Radioactive decay isa statistical process
* Every nucleus has the sameprobability lambda to decay in a given interval of time
* This means that a constant percentageof the nuclear existing at the time t, N(t), will decay inan infinitesimal elapsed time, dt
* The number of remaining nuclei thendiminishes in an exponential manner
* The inverse of the decayprobability lambda is what is called the lifetime tau = 1/lambdaof the nucleus
* When one lifetime has passed, a fractione of the initial sample will remain
* One also defines the half life,T_1/2, which is the time interval leavinghalf of the initial sample
* And the activity of a sample,which is a number of decays per second
* It obviously depends onthe decay constant, and the sample size whichdiminishes exponentially
* The natural activity of Ra-226 is used as the unit of radioactivity andit's called the Curie
* A more practical unit is the Becquerelwhich corresponds to one decay per second
* [MUSIC]


--- SKIP ---: 01_2-6-radioactivity-in-practice-optional.en.srt


--- SKIP ---: 01_2-6-radioactivity-in-practice-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-6-radioactivity-in-practice-optional.en_SENTbySENT.txt
* [MUSIQUE] >> In this video, we'll introduce you to the handling of radioactive sources of type Р С›Р’В±, Р С›Р вЂ  and Р С›РЎвЂ“, and radiation protection measures to protect both the people who handle sources and the environment
* Let me present Dr
* Alessandro Bravar, who is senior lecturer in our particle physics department, and who directs the nuclear physics lab course for our students
* Dr
* Bravar is an active member of the neutrinos research group in our department, and he prepares an experiment on muon physics at the Paul Scherrer Institute in Villigen, near Zurich
* Alessandro, can you explain to us what the rules of the game are, when handling radioactive sources
* >> First, in this laboratory, we are using several radioactive sources
* In general, they are stored in a safe, to block all the radiation, and also to restrict access to the sources because we cannot allow anyone to use radioactive sources, unless they have had adequate preparation
* So, I will take out some radioactive sources, a Р С›Р вЂ  source, and a Р С›РЎвЂ“ source, and we will see how they are protected, how they are stored, and also how we measure the radiation coming out, with shielding and without shielding
* >> Very good
* So let's go
* [BIP] [BIP] So, first thing, I open the safe
* This is a first source, a Р С›Р вЂ  source, here we have a Р С›РЎвЂ“ source, and as I'll show you an old watch, where one used radium to make the needles visible
* [NO AUDIO] >> So, that's three sources, you see there Р С›Р вЂ - source, 90Sr, you see a Р С›РЎвЂ“ source, 137Cs, and an old alarm clock that incorporates a very, very weak source of radium
* >> So, Alessandro, can you explain why the sources are packaged like this and how students are protected from excessive radiation
* >> Okay
* So I begin with the first source, it's a Р С›Р вЂ - source, which emits electrons
* So all the sources we use here are sealed sources
* That is to say that there is a small layer of protection around the source to avoid physical contact and thus contamination
* But the protective layer is not sufficient to block all radiations
* Depending on the type of radiation, different materials and also materials of different thickness are used to block the radiation
* In this case, there is a Р С›Р вЂ - source so it emits electrons
* To stop the electrons, one needs about 2cm of plastic, and therefore, the source is contained in this plastic object
* Here, if you look, you can see the silvery part, it is the radioactive part that emits electrons
* To show that the source is well shielded, you can use a Geiger counter to measure the radiation level
* So I turn on the counter, and as we see, there are not many counts coming from the source
* On the contrary, if I remove the protection (as I said, 2cm of plastic), and placing the counter on the source, we seecompteur sur la source et on voit que on that the count rate goes up a lot, say several thousand hits per second
* So I put the cap back on and we see that there is no more radiation from the source
* The second source I will show you is a Р С›РЎвЂ“ source, gammas are photons of a certain energy, rather high energy compared to visible light photons
* To protect photon sources, one needs a lead shielding
* To stop the photons, it takes a rather heavy material with a rather high Z, such as lead
* Here is the lead container, inside we have a second lead container, the source is hidden inside
* To remove the source, I use a pair of tweezers, I do not touch the source with my fingers.Inside there is this little piece of lead, which contains the source in its tip
* So if I place a Geiger counter just in front of the source, we see that the count rate is quite high
* On the contrary, if I put the source in its containers almost no radiation comes out
* So to protect from a source of Р С›РЎвЂ“-type, one does not just choose the good material, but also a thickness of the shielding according to the intensity of the source
* The more the source intense, the more lead I need to stop all photons emerging from the source
* >> In fact, we did a little calculation of the absorption of photons in the minimum of their cross section, in a previous video
* In the old times, in the 1950s, everyone was much more relaxed with respect to radioactive sources, right
* One even put them into objects of every day use
* Can you explain what was the purpose of the radioactive source in this clock
* >> This is an old alarm clock, and to make the hands visible during the night, they used radium to make them phosphorescent
* Today, we use different materials, such as phosphorus, but in the past, people used radium, and this is a very, very dangerous substance
* The reason why the radium is so dangerous is that it decyas into radon
* Radon is a radioactive element, it is a gas, which is everywhere in nature, and we can breathe radon
* Breathing air one also takes in a portion of radon in our lungs, where radon decays by emitting alpha particles, which come in direct contact with the tissues of our body and can do much damage
* In fact, radon is one of the concerns we have around the world, in homes, also in Switzerland.There are regions in Switzerland, especially the Alps and the Jura, where there are rocks outgassing a lot of radon, while in big cities, like in Geneva or Zurich etc., there is not much radon
* >> That is to say that one should not spend the night in a basement in the Alps
* in a basement in the Alps
* >> Exactly
* Houses must be properly ventilated
* >> And, that's why we have banned the use of radium since a long time
* To show the effect, although there is a minimum amount of radium, which has been deposited on the clock, with the same Geiger counter, which I used before, one can reach a certain number of counts, which tells us that there is a lot of radium decays from this clock And so it's not a good idea to sleep with such a clock by the bedside
* >> And that's why, we have long since banned using radium in clocks
* Thank you very much
* [MUSIQUE]


--- SKIP ---: 01_2-7-radiocarbon-dating-and-nmr-imaging.en.srt


--- SKIP ---: 01_2-7-radiocarbon-dating-and-nmr-imaging.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-7-radiocarbon-dating-and-nmr-imaging.en_SENTbySENT.txt
* [MUSIC] In this second module, we are in theprocess of discussing nuclear physics, and we now turn to a few examplesof its applications
* In this seventh video,We will briefly discuss two applications, which are radiocarbon dating andimaging by nuclear magnetic resonance
* After watching this video you will be ableto describe how one determines the age of organic substances based ontheir contents of C-14
* And to describe the principles of imagingusing nuclear magnetic resonance
* One of the important applications ofnatural radioactivity is the dating of organic materials by what iscalled radiocarbon method
* This works up to several thousand yearsand with relatively good accuracy
* An example is the very controversialdating of the Turin linen, which some believe to show an imprintof the body of Jesus after his death and it is shown in this image behind me
* Now, let us examine how thismethod dates organic materials
* Our atmosphere contains a lotstable N-14 and C-12, which play an important roleplay in organic processes
* The atmosphere is constantly hit by cosmicrays and very high energy, they consist mainly of protons and helium nuclei, butalso electrons, photons and neutrons
* Cosmic rays interactwith atmospheric nuclei
* The slow neutrons they produce,among many other particles, can interact with N-14 toproduce the radioactive carbon isotope C-14 ina charge exchange reaction
* Carbon-14 is a beta emitter with alifetime of a bit more than 8,000 years, so well suited to date materialsthat are several thousand years old
* At any moment, our atmosphere thuscontains a majority of C-12 and a small quantity of C-14 nuclei
* Both of them can form CO2 molecules, sincetheir chemical properties are the same
* Living organisms, like plants,consume carbon dioxide for their photosynthesis, andwill integrate both carbon isotopes alike
* When the organism dies,the CO2 ingestion stops
* From then on,the C-14 component slowly decays, but the level of C-12 will stay constant
* One thus uses the relative concentrationof the two isotopes to estimate the age of fossils
* But of course, the concentration of C-14 in theatmosphere is not necessarily constant
* It depends on the flux ofcosmic rays at a given time and this dating method thusneeds a calibration
* This curve shown here gives an exampleof the deviation from linearity of the method
* Let us now turn to a noninvasive medicalimaging technique that uses nuclear spin
* Imaging by nuclear magnetic resonance,NMR, is based on the absorption and re-emission of electromagnetic radiationvia the nuclear magnetic moment
* The sample is immersed inmagnetic field B_0 to establish an external quantization axis
* The component of the nuclearmagnetic moment along this axis will be proportional to the quantumnumber m_s, which is equal to plus or minus one-half,depending on the spin orientation
* The associated energy isproportional to both m_s and B_0
* The transition energy between the twoorientations of the spin, parallel and anti-parallel to the magnetic axis,is Р Р†РІвЂљВ¬РІР‚В E = hbar gamma B_0, where the proportionalityfactor gamma is equal to the gyromagnetic constanttimes e divided by 2M
* The spin vector rotates aroundthe magnetic axis with a Larmor frequency nu_0, which is equalto gamma B_0/(2 pi)
* A photon can thus be absorbed bythe nucleus if its frequency corresponds to this resonance in the range of radiofrequencies if B_0 is a few tesla
* This resonance can then be use to dowhat is called nuclear spectroscopy
* And you see a nuclear spectroscopyapparatus in the image on the right
* But let us now discuss how oneuses this to locate molecules and nuclei inside your body
* By varying the magnetic fieldaround B_0 with gradients in all three spatial directions,one can correlate the resonance frequency with the position ofa certain type of nucleus
* The intensity of the signalis then proportional to the local density of the element
* This is the principle of nuclearmagnetic resonance imaging, NMR
* One uses the resonance frequencies of,for example, hydrogen, Na-23, or P-31 to obtain an image ofthe internal structure of the body
* Most often, hydrogen is indeed used to obtain accessto the density distribution of liquids and soft tissues, which are difficultto render by classical tomography
* The patient is introducedinto a solenoid or between two Helmholtz coils,as in these two examples
* They provide the field B_0of typically a few tesla
* Additional coils adapted tothe body region under examination provide the magnetic field gradient
* A pulsed radio frequencysignal is then applied, and its absorption by the tissue isanalyzed by Fourier analysis
* The height of the Fourier peakat the resonance frequency measures the local densityof the chosen nucleus
* After a characteristic relaxationtime between milliseconds and seconds, the RF signal is restored
* The time delay can revealadditional tissue properties
* One then obtains an image with a typicalresolution of order millimeters, and a very good contrast, as you can seein this NMR picture of the knee
* In addition,the image shows also the soft tissue, difficult to visualize byclassical x-ray tomography
* The mechanism of nuclear magneticresonance even allows for a functional imaging of organs
* This is due to the magneticproperties of hemoglobin, which transport the oxygen in our blood
* Hemoglobin is found intwo different forms
* The red blood cells,which are oxygenized by the lungs, contain oxyhemoglobin,a molecule which is inactive in NMR
* The red blood cells, which havedelivered the oxygen to the tissue, contain deoxyhemoglobin,which is a paramagnetic molecule
* This means that under the influenceof the external magnetic field, it will acquire a magnetization,which is detectable by NMR
* Brain activity, for example, causes characteristic dynamicsof blood flow and composition
* In active brain regions, wherethe neurons are stimulated, one observes simultaneously a higher oxygen consumptionand a higher local blood flow
* In healthy tissue,the increase in blood flow is more important than the localconsumption of oxygen
* This corresponds to a relativedecrease in deoxyhemoglobin, which can be used tolocalize brain activity
* In the next video, we'll representanother important application, the physical principle of energyrelease in nuclear fission, which is currently furnishing about10% of the global energy consumption
* [MUSIC]


--- SKIP ---: 01_2-8-nuclear-fission.en.srt


--- SKIP ---: 01_2-8-nuclear-fission.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-8-nuclear-fission.en_SENTbySENT.txt
* [MUSIC] During the second module,we are dealing with nuclear physics
* And in this eighth video, we will explainhow to transform a part of the nuclear binding energy into heatby nuclear fission
* After viewing this video, you willknow how the nuclear fission mechanism works and its necessary conditions
* A very important application of nuclearphysics is the transformation of nuclear binding energy into thermal and electricalenergy by the fission mechanism
* Low energy neutrons can penetrate inside the nucleussince they're not subject to Coulomb repulsion
* This way they increasethe nuclear mass and the excited nucleus may break up intotwo daughter nuclei of smaller mass
* This fragmentation of a heavynucleus into two medium mass fragments plus accessory productsis called nuclear fission
* The alpha decay which we havediscussed in video 2.4 is an extreme example of a veryasymmetric spontaneous fission
* But more important is the fissioninduced by the absorption of a neutron
* Nuclear fission stay in the domainof a heavy matter nuclei and this is due to the shape ofthe binding energy per nucleon as a function of the mass number A which we have shown in video 2.1
* Beyond the iron group, it decreasessteadily such that binding energy can be gained by splitting a heavy nucleus into twonuclei in a more or less symmetric way
* Thus, a less tightly bound nucleuscan gain binding energy by splitting it into two lighter,more tightly bound ones
* As an example,the binding energy per nucleon is -7.5 MeV for U-235 and -8.4 MeV on average forthe two daughter nuclei
* The energy released by fission istypically 0.9 MeV per nucleon
* One gram of U-235 contains about3 10^21 nuclei
* The complete fission of all of thesenuclei would release the impressive energy of 10^11 joules, about one megawatt a day if weignore all efficiencies involved
* To give you an idea forcomparison, burning one ton of coal yields about 0.36 Megawatt-day,if again you ignore efficiencies
* Thus one gram of U-235 contains as much nuclear energy as three tons of coalcontain in chemical energy
* We can understand the nuclear fissionqualitatively and quantitatively using the liquid drop model of the nucleuswhich we have introduced in video 2.3
* Let's first look at the process qualitatively
* The liquid drop model presumesa spherical shape of the nucleus
* But for a heavy nucleus a small external perturbationlike for instance an incident neutron can produce surface wavesleading to a change in shape
* The drop may thus extend into spheroР вЂњР вЂЎdal shape and if this perturbation is small enough,the nucleus will be left excited and just return to its groundstate by emitting a photon
* This process is calledradiative neutron capture
* If on the contrary the perturbation is large, Coulomb repulsion along the axis of this spheroР вЂњР вЂЎd can split the drop into two droplets bywhat is called induced fission
* Now, let us calculate underwhich condition this may happen
* A sphere of radius R will turn intoa spheroР вЂњР вЂЎd of a constant volume because of the incompressibility of nuclear matter
* We denote its half-axes by a andb, which is equal to c
* In terms of a small deformation epsilon, they transform into(b - epsilon) and (a + epsilon)
* For the binding energy, the volume term stays constant, but the surface and Coulomb energy are different
* The deformation increasesthis surface energy but decreases the Coulomb term
* So the gain or loss in binding energy will depend on therelative importance of these two terms
* If the difference is greater than 0, thespherical nucleus is more tightly bound and thus stable againstthis small perturbation
* If on the contrary,Р Р†РІвЂљВ¬РІР‚В  is less than zero, the spherical nucleus is less tightlybound and can undergo fission
* Putting in the typical values forthe coefficients a_2 and a_3, one obtains stability if the ratioZ^2/A is less than 47
* There are small quantum correctionsto this classical approach which, however, do not change the conclusion
* We expect on the contrary, that nucleiwhich set Z^2 > 47A, are highly unstable against a small perturbationand thus can be easily induced to fission
* Heavy nuclei have Z < A/2so  the conditions that Z^2 < 47 A is satisfied
* The spherical shape correspondsto the maximum binding energy but even in that case,a fission can be energetically favorable, if the sum of binding energies of thedaughter nuclei is favorable with respect to the mother nucleus
* Let us calculate this case for a symmetric fission assuming sphericaldaughter nuclei for simplicity
* A and Z of the parent nucleus must thus be even
* We again ignore quantumterms of the Bethe-WeizsР вЂњР’В¤cker formula
* The energy difference is denoted by Р Р†РІвЂљВ¬РІР‚В 
* With typical coefficients,we obtain delta equal to 0.27 A^2/3 (-16.5 + Z^2/A)
* Thus for Z^2 < 16.5A the two daughter nuclei are more tightlybounded than the mother nucleus
* We thus see that forthe region Z^2 between 16.5A and 47A, the spherical shape maybe stable against fission but it remains energetically favorable forthe parent nucleus to split into two smaller ones,when it is sufficiently perturbed
* Beyond that zone, even a minorperturbation by a thermal neutron, for instance, will suffice to cause fission
* Let us consider Uraniumisotopes as an example
* U-238 is an even even nucleus and thus more tightly bound than U-235,which is odd even
* We thus need a smaller perturbationto induce fission in U-235
* The activation energyis about 5 MeV for U-235 and 6 MeV for U-238
* When capturing a neutron,U-235 becomes an even-even nucleus
* This transformation releases about 6.5 MeV of binding energy, which issufficient to activate its fission
* For U-238, a neutron capture changes the nucleusto a less tightly bound odd-even one
* This will be a less exothermal process
* It releases only 4.8 MeVout of the necessary 6 MeV
* So additional 1.2 MeV per neutronmust be provided to induce fission
* The fragments are often rather asymmetric
* One observes a grouping of the daughternuclei around mass number 95 and 140 as shown in this picture, fora reason which we have not yet understood
* The picture here in fact shows the massspectrum of daughter nuclei from the fission of U-233, U-235,Pu-239, as well as a mixture
* The mass spectra are similar
* After the fission process the daughternuclei are often in a excited states
* And they turn into stable isotopesby neutron emission
* Neutrons are thus abundantamong the fission products
* They can cause a chain reactionof nuclear fission processes
* U-235 produces on average2.5 neutrons per fission
* These neutrons can in turn inducenew fission reactions and so forth
* To see if a chain reaction can bemaintained, we consider the ratio k of the number of neutronsproduced in step n+1 to the one producedin step n of the chain
* If k is less than one,there are not enough neutrons to sustain a chain reaction, andthe process will stop by itself
* If k is equal to one or around one,there are just enough neutrons to maintain a chain reaction with aconstant number of fissions at each step
* This is the ideal situation fornuclear fission reactor
* If k is bigger than one, more and moreneutrons will be produced at each stage, thus leading to an exponential growthof the number of fission reaction
* And this is the situation which is searchedfor the production of nuclear weapons
* In the next video,we will talk about how to use the fission process innuclear power plants
* [MUSIC]


--- SKIP ---: 01_2-9-nuclear-power.en.srt


--- SKIP ---: 01_2-9-nuclear-power.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-9-nuclear-power.en_SENTbySENT.txt
* [MUSIC] In this second module, we are discussingnuclear physics and its applications
* In this ninth video we will continuediscussing the transformation of a portion of nuclear binding energy intoheat through the fission process
* After following this video,you will know how fission is used and controlled inside nuclear power plants
* Natural uranium is a mixture ofonly 0.7% U-235 and 99.3% U-238
* U-235 has a five time shorterlifetime than the other isotope and the natural mixture therefore onlycontains a small fraction of U-235
* Enriched uranium isa material in which the U-235 component has been increasedby isotope separation
* This separation uses the small differencein mass between the two isotopes to separate them, for example, in a gascentrifuge filled with uranium fluoride
* In these devices rotation generatesan enrichment of the light element towards the axis, and the heavier elementtowards the periphery
* The devices are used in parallel andin series to obtain the required quantities andthe desired level of enrichment
* Enriched uranium is a critical componentof both civil and military applications
* A nuclear bomb usually containsat least 85% of U-235
* But a simple and ineffective weapon canalready be obtained with a minimum of 20%
* The International Atomic Energy Agency,IAEA, attempts to monitor and control the production and storage offissile materials around the world
* In the controlled environment ofa nuclear reactor, the chain reaction with k roughly equal to 1 can beused as a sustained energy source
* The reactor core contains fuelrods with a fissile material, control rods with a neutron absorber and a moderator to reduce the neutronkinetic energy and thermalize them
* Thermal neutrons incident onnatural uranium are radiatively captured by U-238 andwill thus not cause fission
* That's why one uses uraniumenriched to 3% to 5% of U-235 as fuel in nuclear reactors
* The control rods in a reactorregulate the neutron rate
* They are often made of cadmium which has ahigh cross section for neutron absorption
* By inserting or removing the rods onemanages the flow of neutrons and therefore the reaction rate to keep k close to oneand therefore a constant power source
* The role of the moderator,on the other hand, is to slow down neutrons by scattering toincrease thir probability of capture and therefore increase the fission rate
* A material with small absorptioncross section is chosen
* Water, H_2O, is used in light waterreactors often found in western countries
* In research reactors designed toproduce a large flux of neutrons, one also uses heavy water, D_2O, because the cross-section for neutron capture is smaller indeuterium than it is in hydrogen
* In reactors of the RBMK type likethe Chernobyl nuclear power plant, graphite moderation rodsare used in addition to water
* In a nuclear power plant the reactorcore is immersed in a cooling liquid, actually water
* It's goal is to collectthe heat generated by the core
* Through a heat exchanger the coolingwater is used to produce steam which will in turn driveturbines to generate electricity
* At the exit of the turbinesthe steam is condensed and recycled
* The residual heat is often removed throughcooling towers or dumped into rivers
* The second goal of the coolant is to keepthe core temperature under control and prevent a meltdown of the core
* The whole is surrounded bya containment building, the small roundish buildingon the left of this picture, in order to avoid contaminationof the environment by radiation
* At the beginning of an exploitation cycle,the value of k is set to slightly above one, until the desiredpower level is reached
* And at this point, k will be reducedto one to have a stable power source
* We already calculated the impressivemaximum energy yield related to nuclear fission
* Ignoring the efficiency ofpower plants and other losses, one gram of uranium is equivalent tothree tons of coal in heat output
* This explains the important usage of thisenergy source in developed countries
* On March 31, 2014,435 reactors shown in this map, were operating in 31 countries, with a total installedcapacity of 372 gigawatt net
* 72 reactors were under construction
* In 2012, about 10% of the global electrical energy wasproduced by nuclear power
* However, most nuclear reactorstoday are over 20 years old
* The economic crisis in 2008 and the Fukushima nuclear accidentcaused a decrease in production of nuclear electricity by about4% in 2011 compared to 2010
* Countries such as Germany, Belgium, Switzerland and Taiwan have announcedthe end of their usage of nuclear power
* Other countries no longer engagein new nuclear power plants
* According to Wikipedia, the construction of 18 reactors appearsseveral years late at this time
* Nine are under constructionsince more than 20 years
* However, the fight againstglobal warming and the necessary reduction of fossilfuels may change the impression that nuclear fission is a powersource in decline
* In the next video, we will present theprinciples of nuclear fusion as a source of heat and see how it works in stars andin future power plants
* [MUSIC]


--- SKIP ---: 01_2-10-nuclear-fusion-the-sun-and-iter.en.srt


--- SKIP ---: 01_2-10-nuclear-fusion-the-sun-and-iter.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-10-nuclear-fusion-the-sun-and-iter.en_SENTbySENT.txt
* [MUSIC] During the second module, we are dealingwith nuclear physics and its applications
* In this tenth video,we show how a portion of the nuclear binding energy can betransformed into heat by fusion
* After having watched this video, you will know the principle ofenergy release by nuclear fusion
* You will know how the starsuse fusion to produce their energy and also heavy elements
* And you will know the application ofthis principle to future power plants
* Let us return to the spectrum ofthe binding energy per nucleon as a function on the mass number A
* We see that there is a maximum forA = 60 around iron
* For lighter nuclei, the dependence of the binding energy onA is much stronger than for heavier nuclei
* Light nuclei are generallyless strongly bound except for the double magic nuclei,like for instance He-4, and their binding energyincreases faster with A
* One can therefore use this strongvariation of binding energy with respect to the mass number of light nucleias a source of energy by fusion
* The yield of energy per nucleon isgreater than what is obtained by fission
* But the yield per nucleus is smallerbecause of the lower mass number A
* In any case, the natural abundance of light nucleimake this process interesting
* In particular, the fusion of lightelements is the source of energy in stars
* In principle, fusion can occurwhen two light nuclei come close together enough sothat they can merge
* But for these to occur,they have to overcome the Coulomb barrier
* The maximum potential is reachedwhen the two nuclei just touch
* For a mass number of about eight, thismaximum potential is of the order of 4 MeV, so a kinetic energy of a fewMeV can overcome the barrier
* One must thus heat nucleiat very high temperature, so that they can overcomethe Coulomb barrier
* To estimate this temperature, let's say that each nucleus musthave a kinetic energy of 2 MeV, which corresponds to a temperatureof 10 billion Kelvin
* Typical temperatures inside the sun and other stars are of the orderof 15 million Kelvin
* But the tail of the Maxwell distributionof the Sun spectrum reaches far enough for fusion to take place
* Currently in the heart of the sun, every second about 627 milliontons of hydrogen fuse and produce about 622 million tons of helium
* The difference in mass of 4.3million tons of hydrogen which is of the order of the mass of the GizaPyramid is equivalent to the luminous energy produced, which is about4 10^26 Joules
* The Sun will still burn for 1 million years beforerunning out of fuel
* Ideal conditions fornuclear fusion prevail within stars
* An example is the Sun,which weighs about 10^30 kg, mainly in the formof ionized hydrogen
* The main source of the sun'senergy is the hydrogen combustion, the proton-proton cycleshown in this schematic
* The large energy release in the thirdstage is due to the fact that the helium nucleus is doubly magic andextremely tightly bound
* In total, a cycle fuses four hydrogennuclei to produce two positrons, two neutrinos, two photons and24.68 MeV of kinetic energy
* Positrons annihilate withambient electrons and so contribute to the total energy release
* Photons can also interact with stellarmatter and deposit their energy
* Neutrinos escape
* Helium produced in the proton-proton cycle can then produce carbonthrough a double fusion
* For the synthesis of the elementsin stars, the CNO cycle, or so called carbon cycle, is fundamental
* For stars heavier than the Sun thisis even the dominant energy source
* Nitrogen and oxygen are produced inthis cyclic exothermal reaction
* In addition positrons andphotons are emitted in the process
* Neutrinos escape from the Sunoften without interacting
* Elements up to iron are abundantly cooked insidestars following similar cycles
* Even beyond, the chain does not stop
* All stable and unstable elements can beproduced under favorable conditions
* One finds elements up iron and beyondin cosmic rays from exploding stars in supernovae
* Their chemical composition is howevermodified by interaction with the interstellar medium
* For example, the lithium-beryllium-boron group is enriched by spallation of heavier nuclei
* In general, the abundance of odd nuclei is moreimportant in cosmic ray than inside stars
* Our experiment, the AlphaMagnetic Spectrometer AMS on the International Space Stationis taking data since several years and is measuring thechemical composition of cosmic rays as function of theirenergy with high precision
* This will enrich our knowledge onthe origin and propagation of cosmic rays
* There is a substantial effortto achieve a man made nuclear fusion undercontrolled conditions
* Various fusion processesbetween deuterium and tritium have been observedin laboratory conditions
* The most important one is deuteriumplus tritium which produces He-4 plus a neutron plus a 17.6 MeV of energy
* The main difficulty fora fusion reactor is to maintain the fuel long enough at a sufficientlyhigh temperature, so that it can penetrate the Coulomb barrieroften enough to have a sustained process
* Once can contain a plasma in two ways,by magnetic confinement, where the plasma flows in a helical orbit,or by inertial confinement, where electromagnetic energy via lasers orheavy ions is injected into a smallarea that contains the fuel
* ITER, which is the InternationalThermonuclear Experiment Reactor, is the largest current project with the aimof demonstrating fusion energy production
* The reactor is being builtin the south of France
* In the next two videos,we will take you to visit the experimental Tokamakreactor at EPFL in Lausanne and the world's oldest workingnuclear power plants in Beznau
* [MUSIC]


--- SKIP ---: 01_2-11-the-tokamak-of-epfl-optional.en.srt


--- SKIP ---: 01_2-11-the-tokamak-of-epfl-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-11-the-tokamak-of-epfl-optional.en_SENTbySENT.txt
* [MUSIC] In this second module of our introductory course in particle physics, we are discussing the physics of the atomic nucleus
* And in this eleventh video, we are fortunate to be invited to visit the experimental Tokamak of the Federal Institute of Technology in Lausanne, or more precisely of their Swiss Plasma Center
* This is a research tool for nuclear fusion, which is the source, I remind you, of energy produced in the sun, and other stars
* If we ever manage to use fusion energy in commercial power plants, mankind will have a virtually inexhaustible source of energy, safe and environmentally friendly
* Fusion power plants impact the environment in fact very little and produce no greenhouse gases
* One can also exclude any serious accident with large release of radioactivity because the fusion process does not by itself produce any radioactive waste from its fuel; only the structural components inside the reactor become somewhat radioactive
* Nuclear fusion has also the major advantage of using fuels that are available on Earth, in virtually inexhaustible quantities
* It could thus become one pillar of our energy supply that will provide the necessary conditions for sustainable development
* I remind you that the fusion reaction between deuterium and tritium has already been introduced in video 2.10
* It produces a strongly bound helium nucleus and a neutron, releasing a large amount of energy, approximately 17.5 MeV per reaction So today we will visit a medium sized reactor, which is behind me, called the TCV, Tokamak with Variable Configuration, of the Swiss Plasma Center
* In such an instrument the issues of containment and stability of the plasma are studied, which are necessary for the realisation of a fusion reactor
* To realise an efficient fusion reaction, and to study burning plasma which produces energy, will require larger machines like ITER, which we will discuss at the end of this video
* [NOISE] So we are now in the lobby of the Swiss Plasma Center, and I present to you my two colleagues from EPFL, who will be our guides during the visit
* Here on my left is Dr
* Yves Martin, who is the Administrative Director, and also the person responsible for communication of the Swiss Plasma Center; and on my right is Dr
* Antoine Pochelon, who is senior lecturer, admittedly in retirement, but who has lost none of his enthusiasm for plasma physics and nuclear fusion
* Our subject today is nuclear fusion, and how to put it to use in the transformation of nuclear energy into usable energy
* So what does this have to do with plasmas, Yves
* >> In fact, the fusion reaction we seek to produce in a Tokamak can be obtained only at very high temperatures, because one must overcome the Coulomb repulsion
* And to overcome this Coulomb repulsion, it is necessary to heat to temperatures at which matter takes the form of a plasma
* A plasma is a gas in which the atoms are ionised, in which the electrons are dissociated from the nucleus of their atom And from that point onwards, we have a mixture of charged particles, but globally neutral
* >> Okay.>> And the benefit of this state of matter is that we can guide the particles using a magnetic field
* >> Ok
* So therefore there are several steps
* First one must create a plasma, confine it, magnetically I imagine, and heat it to relatively high temperatures, indeed, incredible temperatures
* So can you describe a bit these steps
* >> The beginning of plasma formation
* >> Yes.>> Well, it actually begins with a gas in which an electric field is applied
* And this electrical field short-circuits the plasma it causes in fact a discharge in a rarefied gas
* And then, the electric field draws a current, this current heats the plasma, heats the gas which is becoming a plasma when it reaches a temperature, typically of 10Р Р†Р вЂљРІвЂћСћ000 degrees Kelvin, corresponding to a kinetic energy of typically one eV
* >> That is to say, to the binding energy between a typical electron and a typical nucleus
* >> It's the order of magnitude, effectively to separate the electron from its nucleus
* We are producing this discharge in a magnetic field, which guides the particles, and forms a magnetic bottle
* And we have behind us an example of such a bottle, called a Tokamak
* >> Yes, is it a model of one-to-one scale
* >> It's a 1:1 model of the machine that you'll see in a moment, and different colours allow us to see the many different elements
* First one starts, on the inside, by the vacuum chamber, wherein the plasma will be installed
* The main magnetic field of the magnetic bottle is generated by the blue coils, toroidal coils, which create a field around the center in a toroidal sense
* >> A field that revolves around the machine's center
* >> That's right, here we have a transverse section of the machine
* And then, to generate the electric field, which we spoke about, we have these coils, which form the primary circuit of a power transformer, which induces an electric field, and thus the plasma current
* In addition, it is a special feature of this machine, that we have as many as 16 additional coils, in yellow hereР Р†Р вЂљР’В¦ >> The yellow ones, yes
* >> Р Р†Р вЂљР’В¦powered by independent generators
* Р Р†Р вЂљР’В¦powered by independent generators
* This allows controlling the plasma shape and position
* It also helps to extend the plasma, since ultimately currents of the same sign repel each other, opposite currents attract each other
* >> To simplify somewhat, the blue coils create a field that is confining, and then the yellow coils are used to manipulate the shape of the containment
* So, Yves, can explain how, then, the plasma is heated beyond the initial temperature
* So first of all, as in any Tokamak, ohmic heating is used; simply, as Antoine has said, there is current flowing in the plasma
* >> Okay
* So it is the plasma resistance that will heat the plasma
* >> Absolutely
* But the temperature, which can be achieved with this heating, is not sufficient yet
* So we must add other heating systems, and what we normally use, notably here in our Tokamak, is heating by microwaves or radiofrequency heating
* It will act on resonances to be found in the plasma
* >> But, this will heat the electrons, right
* And not nuclei, primarilyР Р†Р вЂљР’В¦ >> Indeed, the heating system we have here primarily heats the electrons; but afterwards, by collision with the ions, the electron energy is also transferred to the ions, and therefore, the temperature of the ions also increases
* >> So, to learn how one generates the radiofrequencies, which heat the plasma, we will go up, to see gyrotrons producing this radiofrequency
* [NOISE]>> I'll go through what a gyrotron is: you have one installed down there, we'll get back to that in a moment
* The gyrotron is essentially a vacuum tube that generates 0.5 to 1 mega-watt of power
* At the bottom of the image, you find the electron gun producing an electron beam, which passes through the tube
* The electrons arrive in the collector, here, at the bottom right
* Then, the electron beam passes through a cavity within the magnetic field generated by a superconductor
* Then using a wave converter, the microwave power is directed onto a mirror and laterally removed from the tube
* Here we see such a gyrotron: Invisible below, the electron gun, in the middle the cylinder housing the superconducting magnet with the cavity
* On top, under its yellow lead cover, you have the electron collector
* In front, the microwave enters the optical adapter box with various mirrors that elliptically polarise the wave, in the right way to heat the plasma locally in the Tokamak
* We use, as you see here, a whole battery of gyrotrons
* We have six at a frequency of 80 GHz,  with a total power of  3 MW
* And back here we have gyrotrons of 120 GHz, which are very long pulse gyrotrons we manufactured in collaboration with French colleagues
* [MUSIC]>> So here is the TCV Tokamak with first the magnetic coils that will create the main field, the toroidal field, and a little bit on the back coils that will help shape the plasma, the eight coils
* So we see only the outer coils, all the others are hidden inside the machine
* And right there behind, one sees the vacuum chamber into which we will inject our plasma
* To heat the plasma, we use microwaves to take the plasma to very, very high temperatures
* The temperatures required for fusion are of the order of 100 to 150 million degrees, and in this Tokamak, we obtained such temperatures
* Note that in the sun, temperatures are much lower, around 1.5 keV, and at this temperature, in fact, only the particles found in the tail of the Maxwell distribution will merge
* >> The inside of the TCV vacuum chamber is covered with carbon tiles, in fact, like a space shuttle
* And the tile surface is covered with boron carbide by plasma deposition, almost as hard as a diamond layer, which reduces on one hand, the plasma abrasion of the carbon tiles
* Moreover, as B4C is formed by elements with low charge Z, it makes that the plasma sees only low Z
* This is very important because a source of plasma energy loss is radiation
* And this radiation increases sharply with the electric charge, typically as Z to the 4th power
* [MUSIC] The role of the TCV we have behind us is to study the properties of the plasma
* That is to say for example the density, temperature, or even the rotation of the plasma, because the plasma rotates in the vacuum chamber
* With that, we will be able to study the confinement, the transport of heat and the stability
* And this, we will study as a function of different characteristics, such as density, temperature and rotation
* One thing we will particularly examine with the TCV, this machine where you can vary the shape of the plasma, is the dependence on the form
* One can also create a divertor
* A divertor is basically a magnetic structure outside the plasma that removes impurities, which are, in the case of fusion, helium, which is the product of the reaction
* So we will eliminate it, and also remove impurities at high Z, which as we have seen, make the plasma radiate
* Therefore, around the machine, we have an amount of diagnostics, measurements such as this neutral injector measuring the ion temperature and plasma rotation
* But we also have tools, i.e
* actuators to vary the plasma parameters
* We have already spoken about the microwave heating which primarily heats the electrons
* We are also installing now 1 megawatt heating by neutral injection to heat directly the ions
* So this makes a total of 4.5 megawatts for gyrotrons at frequencies between 80 and 120 GHz, and then to begin with 1 megawatt of neutral injection
* [MUSIC]>> So all this means that the TCV is a research tool rather than a prototype reactor, right
* But I guess it is part of a more comprehensive program that should lead to a fusion reactor, a true one, right
* >> Absolutely, the Tokamak here is an experimental Tokamak, which is used in a vast fusion research program
* It is clear that to meet the many challenges of fusion, i.e
* to arrive at a commercial fusion reactor, it is necessary to coordinate our efforts at the European level, at the international level, and Switzerland is part since 1978, through a bilateral agreement between Switzerland and Euratom, in all European programs
* >> What is the role of the TCV in such a program
* Antoine, what are the specifics of the TCV that can contribute to this program
* >> The most important specificity of TCV is that it allows varying the shape of the plasma
* And this is a program that we are heavily exploiting
* For example, most large Tokamaks today have a D-shaped plasma, that is to say the plasma belly looks towards the outside
* But in TCV, one can also make plasmas in the shape of an inverted D, that is to say the belly looks inward
* And it is, in fact, the only machine in the world to make this type of plasmas
* >> And what is the point of having this form of plasma
* >> We were lucky to have as a bonus a rather surprising result, it was not expected of all at first, which is to have the energy confinement increased by a factor of two with the inverted D
* This is first interesting in itself
* Then, when you have a doubled confinement, you can put half the heat into the plasma, so you pay less to heat the plasma to the same temperature
* So that's a first advantage.The second advantage is that it allows having plasmas of equivalent temperature, but with completely different shapes.And who says different confinement, also says different turbulence
* So we can compare now with complex codes, which simulate the plasma turbulence and its confinement, and we can compare in this way the experiment with numerical models and this is really what the experiment is good for
* >> So it is the turbulent plasma instabilities that limit confinement, confinement time in a Tokamak
* >> Actually, at the plasma edge we observe instabilities that strangely resemble the solar prominences, solar flares
* We see in this video, which comes from Tokamak MAST in England, these flashes of light, which resemble solar flares
* And we develop operational modes precisely to reduce the impact that these solar flares would have on the Tokamak material
* [MUSIC] This Tokamak with its shape control system, the electron heating system, and soon its ion heating system, as well as with its set of diagnostic tools, measuring devices, it is an exceedingly productive machine
* We obtain large quantities of absolutely fantastic results, which can be created with this machine that is absolutely unique worldwide
* Moreover, the fact that we are part of an academic environment in the context of EPFL, gives the possibility to educate a lot of doctoral students in plasmas physics tasks
* [MUSIC]>> So the next step towards commercial use of fusion is called ITER
* A true reactor this time
* >> Yes, absolutely, it is the first reactor, it is likely the first time that we will produce much more energy than what the machine requires to function
* They talk about a factor of ten of energy amplification
* Here is a model, of a much smaller scale than the model we saw before
* So the scale here is 1:50, you see a little man here behind
* Otherwise it has exactly the same components that we have in our Tokamak
* >> So it is an international program, I imagine, it is not only Switzerland who builds it
* >> Absolutely
* It is a global collaboration with Japan, South Korea, China, India, Russia, the United States and Europe, including Switzerland
* >> So what is the role of Switzerland in promoting this project
* >> We contribute first of all scientific aspects: the operation is prepared for this machine, the scientific program, to know which experiments wewill perform with it
* But we are also preparing physical elements, notably the microwave mirror systems, which allow injecting the microwave, for which we are experts here at the Swiss Plasma Center, with all the knowledge we have accumulated over the years
* We also participate in magnetic measurements, and also in the superconductor tests; all superconductors to be used for all the coils of the machine will pass through Switzerland, through our laboratory to be tested
* >> So, in contrast to the TCV, it will not be normal magnets, but superconducting magnets that will serve here
* >> Absolutely.>> So, up to a large size increase, all this follows somewhat the same principles, that of the Tokamak, right
* But are that there are no other means to store a plasma that can undergo fusion
* >> In magnetic confinement, there are essentially two major strategies
* We talked about the Tokamak, and I will quickly repeat what a Tokamak is
* In a Tokamak, the confining field is made at same time outside the plasma by the toroidal coils, and within the plasma, by the field created by the current circulating in the plasma
* There is another way of making magnetic bottles, the Stellarator
* In that concept, the field, which confines the plasma, is generated completely on the outside, by coils with rather complex shapes
* That is why there are not so many Stellarators worldwide right now, they are difficult to build
* The stellarator is promising also because there is no disruption like in a Tokamak, that is to say brutal interruptions of the plasma current, and you can get to very high densities
* It is therefore extremely promising from the plasma point of view, but it is difficult to build
* >> But there is a Stellarator, which was built in Germany
* >> Yes, in Greifswald on the shores of the Baltic sea, the Stellarator Wendelstein 7-X was built in recent years and, right now, they are currently testing the shape of the magnetic field produced by the very complex coils outside the machine
* There you have a very elegant picture, which shows that the magnetic field, which they had wanted to achieve, is indeed realised
* >> And according to you, these two strategic directions will they result in a reactor that works and produces energy soon
* >> We explore the Tokamak, which is relatively simple to build, and the Stellarator, which is an alternative
* In fact, fusion is a program that spans many generations
* It's long, it's a program that includes both fundamental research and also an extremely applied research: we must develop the materials necessary for fusion, we need very large superconductors at high fields, then we must, to name just one example, regenerate tritium from lithium irradiation
* Thus, a vast program
* >> Thank you very much, Yves and Antoine, for this visit and for this fascinating journey through the world of fusion and plasma physics
* I draw your attention to a MOOC offered by EPFL in parallel to this course, entitled "Plasma Physics and Applications", you will find information on the web site shown here
* [MUSIC]


--- SKIP ---: 01_2-12-the-beznau-nuclear-power-plant-optional.en.srt


--- SKIP ---: 01_2-12-the-beznau-nuclear-power-plant-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_2-12-the-beznau-nuclear-power-plant-optional.en_SENTbySENT.txt
* [MUSIC] >> During this second module, we are discussing the physics of the atomic nucleus
* In video 2.8, the physical principles of nuclear fission were discussed and in video 2.9, it was explained how these principles are implemented to build a nuclear reactor
* Today, we visit the Beznau nuclear power plant, which has been in production since 1969, making it the oldest nuclear power plant that is still being commercially exploited
* The power plant welcomes us in its showroom called the Axporama, which you see around me
* After watching this video, you will know how to do three things
* The first is to describe the operation of a pressurized water nuclear power plant such as Beznau
* The second is to describe the regulation mechanisms of the chain reaction and the security mechanisms that monitor the safety of this process
* And the third, appreciate the role of nuclear energy in the mix of energy production in Switzerland, in Europe and in the world
* Today we are invited to the Beznau nuclear power station, whic


--- SKIP ---: 01_3-1-principles-of-particle-acceleration.en.srt


--- SKIP ---: 01_3-1-principles-of-particle-acceleration.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-1-principles-of-particle-acceleration.en_SENTbySENT.txt
* [MUSIC] Hello, and welcome to this third module ofour introductory course, where we'll touch upon the basics of particleacceleration and detection methods
* In this video, we will explain the physical principlesof linear and circular accelerators
* Afterwards, you will be able toanswer the following questions
* What are the principles of particleacceleration by electromagnetic fields
* How does an electrostaticaccelerator work
* And how do cyclotrons andsynchrotrons work
* The force acting on a particle ofcharge e, in an electric field E, and a magnetic field B, is given bythe Lorentz force that is quoted in blue
* Electric fields are used to accelerateparticles by increasing their momentum
* Magnetic fields serve to deflectthem from their original direction, to store them in a ring, orto focus a beam of particles
* The simplest accelerator forelectrons is the cathode ray tube, that you may remember fromyour grandfather's TV set
* An electron emerging from a heatedfilament is accelerated by a potential V
* The energy of the outgoing electronis then obviously V electron volts
* Electrostatic accelerators chaintogether stages of this type as shown in this photograph
* Their energy is limited by the stabilityof the high voltage insulation
* Thus, it does not exceeda few million electron volts
* To reach a higher energy requires thatthe projectile passes several times by an accelerating potential
* The simplest circularaccelerator is the cyclotron
* In a uniform and constant magnetic field B,a particle of charge e moves on a circle of radius rho equal to pdivided by eB where p is its moment
* The angular frequency of this movementis called cyclotron frequency omega_c
* It is proportion to the ratio e overm of the particle charge and mass and proportional to the magneticfield intensity B
* The particle is acceleratedby the electric field present between the two D shaped cavities
* This field is provided bya radio frequency generator such that its frequency is equalto the cyclotron frequency
* In the non relativistic domain, this frequency is constant becausethe circumference of the orbit increases proportional to the velocityof the particle
* Thus, we can inject particlesin a quasi continuous manner, if the accelerating RFfrequency's high and an even multiple ofthe cyclotron frequency
* You can find a calculation ofthe cyclotron frequency in video 3.1a
* The cyclotron has its limits in that the velocity of the particle does notremain proportional to the momentum, but approaches the speed of lightin an asymptotic process
* In the relativistic limit, the velocity barely increasesdespite a steady increase in energy
* Acceleration radio frequency andparticle revolution frequency dephase thus quickly at an energy of some tensof MeV for protons
* One must thus adjust the radiofrequency to the relativistic velocity
* For example, the proton cyclotron atthe Paul Scherrer Institute in Villigen, Switzerland accelerates protons tonearly 80% of the speed of light
* And you can see a picture of thisaccelerator in this photograph
* The asymptotic saturation of the speed ofthe particle to the speed of light is, on the contrary, very useful, provided thatthe radius of curvature is held constant
* In this case, the rotational frequency,again, is independent of energy
* This is the principle of the synchrotron
* By increasing the magnetic fieldproportional to the momentum of the particle,the radius of curvature remains constant
* One does not have to fill a largevolume with a magnetic field, but can concentrate it inside a vacuumchamber, whose shape approximates a ring
* The synchrotron frequency becomesconstant at high energies if the field B is kept proportional to the momentum
* We can then work with a constantaccelerating radio frequency
* The RF field is transmitted tothe beam by resonant cavities
* The synchrotron principle requiresa certain initial velocity sufficiently close to the speed of light
* The beam is thus usually pre-acceleratedbefore injection by say, a linear accelerator
* The acceleration process must stopwhen one reaches the maximum field of the dipole magnets
* One then either extracts the beam or converts the acceleratorinto a storage ring
* In this latter operational mode, it provides at each turn just the energylost by the beam via bremsstrahlung
* This loss of energy will be introduced inthe next section of the module, video 3.2
* The separation of functions andthe concentration of the components around the ring, allows to combine two ringsto construct what is called a collider
* A historical example is the Princeton-Stanford storage ring, an early example of a particle collider
* It worked with electrons in the tworings which interact in the middle, where the two storage rings touch
* The detector was ratherprimitive, a spark chamber, but it did allow to determinethe scattering angle
* Obviously, one can also fold the twoaccelerators on top of each other, or even combine them if you want tocollide particles and antiparticles
* Examples of the latter type ofcolliders are the Tevatron at the Fermi National Laboratoryclose to Chicago in the US, which collided protons andantiprotons until 2011
* And also the Large ElectronPositron collider, LEP at CERN, which collided electrons and positrons
* It was in operation between 1989 and 2000 in the tunnel which now housesthe Large Hadron Collider, LHC at CERN
* We will return to the LHC inthe next video of this module
* [MUSIC]


--- SKIP ---: 02_3-1a-cyclotron-frequency-optional.en.srt


--- SKIP ---: 02_3-1a-cyclotron-frequency-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_3-1a-cyclotron-frequency-optional.en_SENTbySENT.txt
* [MUSIC] I will first show you the effect of the Lorentz force with a cathode ray tube filled with a rarified gas
* This gas is fluorescent, and thus makes the particle passage visible
* A heated filament emits electrons, which are then accelerated by an electric field
* They leave the cathode pointing upwards
* The Helmholtz coils, in front of and behind the tube, generate a magnetic field which points towards you
* The electrons are thus deviated towards the center of the tube
* With ambient light, one cannot see the faint fluorescence of the gas
* When we dim the light, it becomes visible
* Now I increase the magnetic field strength
* At constant electron momentum, the radius of curvature becomes smaller
* The electrons circulate around the magnetic field direction, with the cyclotron frequency
* If I now reduce the magnetic field strength, The radius of curvature increases, and the electrons hit the glass of the tube
* Let us quickly calculate the cyclotron frequency with which The electrons circulate in the tube
* The Lorentz force q(v x B) gives us the centripetal force, which makes them follow a circle, if v is orthogonal to B
* The absolute value of the force is simply(evB) and must be equal to mv^2/rho, where rho is the radius of the circle
* This gives us v = e B rho/m, the velocity is thus constant
* The frequency with which they circulate is v/(2 pi rho), which equals (eB)/(2 pi m)
* This is thus also a constant in the non-relativistic case
* This gives us an angular frequency of (2 pi f)= eB/m, the cyclotron frequency
* [MUSIC]


--- SKIP ---: 01_3-2-acceleration-and-focalisation.en.srt


--- SKIP ---: 01_3-2-acceleration-and-focalisation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-2-acceleration-and-focalisation.en_SENTbySENT.txt
* [MUSIC] In this module we are treatingthe basics of particle acceleration and detection methods
* In this second video,we treat the acceleration and focusing mechanisms inside accelerators
* After watching this video, you will beable to answer the following questions
* What are the main components ofan accelerator and how do they work
* And how does a complex of acceleratorslike that at CERN work together to achieve the highest energies andhighest intensities
* Inside an accelerator,particles move in an evacuated tube
* And this is to prevent them frominteracting with air molecules and lose energy, or be transformed
* Even if they don't, we still have to  supply radio frequency acceleration, even in the storage ring if we wantto keep the beam energy constant
* This is because an acceleratedcharged particle loses some fraction of its energy inthe form of radiation by emitting photons
* This process is called bremsstrahlung, the same process that producesphotons in an X-ray tube
* In such a tube, the electron cathode ray beam is stoppedby an inclined water-cooled target
* The energy of the electron istypically ten kiloelectron volts
* They thus yield X-ray photons ofa comparable energy
* But also lateral acceleration creates bremsstrahlung, namely synchrotron radiation
* For relativistic particles, the lost power per turn P isproportional to the fourth power of the relativistic factor gamma, and the inversely proportionalto the radius of curvature rho
* It is large for light particlescirculating in small orbits
* This loss must be replacedconstantly to get a stable beam in an orbit of constant radius
* But synchrotron radiation is more than a nuisance
* One uses it to producemonochromatic photons
* The Swiss Light Source at the Paul-Scherrer-Institutein Villigen is a source of high brightness brightness light based on an electron synchrotron of 2.4 giga electron volts
* Is beam lines are used researchingmaterial science, biology, and chemistry
* The accelerating electric field is generatedby a vacuum tube amplifier, the klystron
* An intense electron beam is accelerated,then bunched in a resonant cavity
* In a second resonant cavitythe electron kinetic energy is extracted in the form ofa radio frequency wave
* Modern klystrons have normally severalsuch amplification stages
* The beam is held on a circularpath by dipole magnets
* The transverse focusing of the beam isdone by quadruple magnetic fields
* A low quadruple component is normallypresent even in a dipole magnet
* The focalizing forces come from a slighthorizontal component of the magnetic field, which changes sign as one passe frombelow to above the orbital plane
* By alternating this quadruple configuration withone which is rotated 90 degrees, the focalization is obtainedin both horizontal and vertical directions transverse to the beam
* Magnets with dipolar and quadruple fieldsthus the complany in the accelerator ring
* Two coils have create a dipole field,four create a quadruple field as shown
* Today these coils are normallysuperconducting to minimize resistive loss
* But focalization is alsoneeded in the longitudinal direction
* The reason is that the particlesmust arrive synchronously to acceleration points
* Thus, they are injected in short packets.If they arrive at radio frequency resonators on the increasing slope of theelectric field, their phase remains stable
* A particle arriving with a slightdelay compared to the ideal phase will see a field that isstronger than the average field
* A particle with a slight advance will onthe contrary see less accelerating field
* In this way, the particles will automaticallyoscillate around the ideal phase
* We can lower energy losses from synchrotronradiation by increasing the radius or curvature rho, weakening at the same time the dipole field
* Asymptotically, we canlet rho tend to infinity, resulting in a linear accelerator
* Almost every accelerator complexbegins with such a device
* Much of the vacuum tube which containsthe beam itself is a resonant structure of radio frequency witha traveling electromagnetic wave
* Between the resonant cavities,there are spacers made of conductive tubes
* Their length must follow the velocityof the accelerated particles, i.e
* they should be equal to the velocity timeshalf the period of the radio frequency
* It is also necessary that whenpassing in a unshielded portion of the cavity, the electric field hasthe desired sign and value
* Once the velocity of the particle issufficiently close to the speed of light, the spacing becomes constant
* Today's powerful acceleratorsare mainly working in synchrotron mode
* The most powerful, the Large Hadron Collider,has been in operation since 2008
* It is part of a complex of acceleratorsto obtain maximum energy and luminosity
* In 2011 and 12, the energy of theproton beam was 3.5 TeV
* In 2012, it was raised to 4 TeV
* And after a technical interruption,that started in February 2013, the operation resumed in 2015 with7 TeV per beam
* This corresponds to the impressiveenergy of 1.12 Р вЂ™Р’ВµJ
* The path of particles throughthe complex is shown in the short CERN video 3.2a
* In the next video wewill visit CERN to discuss the key components of the LHC with Prof
* Tobias Golling of University of Geneva
* [MUSIC]


--- SKIP ---: 02_3-2a-the-cern-accelerator-complex-optional.en.srt


--- SKIP ---: 02_3-2a-the-cern-accelerator-complex-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_3-2a-the-cern-accelerator-complex-optional.en_SENTbySENT.txt
* [MUSIC] The CERN accelerator complexis a chain of machines, which accelerate particlesto increasing energy
* Each machine increases the energy ofa particle beam before injecting it into the next machine
* Most of the chain's accelerators areequipped with their own experimental hall in which the beams are used forfixed target experiments at lower energy
* The source of protons is a simplebottle of gaseous hydrogen
* An electric field ionizesthe hydrogen atoms to obtain protons
* The Linac 2, the first link in the chain, acceleratesthe protons up to an energy of 50 MeV
* The beam is then injected intothe PS injector synchrotron, which is called the PS Booster
* It accelerates protons up to 1.4 GeV and accumulates them
* They're then injected into the Proton Synchrotron, the PS, which carries the beam up to 25 GeV
* The protons are then sent tothe Super Proton Synchrotron, the SPS where they are inturn accelerated to 450 GeV energy
* And finally, the protonsare sent to the two beam tubes of the Large Hadron Collider, the LHC
* The beam travels clockwisein the first tube and counter clockwise in the second tube
* It takes about 4 minutes 20 seconds tofill each of the two rings of the LHC and 20 minutes for the protons to reachtheir maximum energy of today 6.5 TeV
* Under normal operating conditions, the beams circulate forseveral hours in the tubes of the LHC
* They are focused by pairs of quadropoles towards the interaction point
* The two beams collideinside four detectors
* ALICE, ATLAS, CMS and LHCb
* At the collision point, the total energy in the center ofmass is 13 TeV today
* But the LHC does not only accelerateprotons, but also heavy ions
* The lead ions of the LHC are extractedfrom a vaporized lead source and passed through a Linac 3before being collected and accelerated into the ringof low energy ions
* Then their path is the same as that forprotons
* At the end of this path, the ions reach their maximum energy
* [MUSIC]


--- SKIP ---: 01_3-3-components-of-the-lhc-optional.en.srt


--- SKIP ---: 01_3-3-components-of-the-lhc-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-3-components-of-the-lhc-optional.en_SENTbySENT.txt
* [MUSIC] >> During this third module, we are discussing techniques for the acceleration and detection of elementary particles
* For this video, we are invited to hall SM18 of CERN, a hall where the magnets of the Large Hadron Collider have been tested in the past and spare magnets are still being checked out
* A part of this hall has been transformed into an exhibition
* At the end of this module, you will know how to describe the elements of an accelerator and know how they look like in real life
* So, let us meet todayР Р†Р вЂљРІвЂћСћs host
* For this video, we are accompanied by Tobias Golling, who is one of my colleagues, professor at University of Geneva, who dedicates 100% of his research to the analysis of data from the ATLAS experiment at the LHC
* So, Tobis, can you let us know what exactly you are doing in this domain
* >> Yes, with pleasure
* In short, I try to find new phenomena in the data, with my group
* Let me put this in context
* The Standard Model is a great success, it describes all visible matter, all forces, well almost all forces
* >> Except one
* >> Yes, except one
* The Higgs mechanism describes how all particules acquire a mass, and the Higgs boson has been discovered at CERN in 2012, so all of this is very, very well set
* But, there are weaknesses of the model
* For example, it cannot explain dark matter and it cannot explain gravity, that his the missing force, and there are other phenomena, like, for example, the famous hierarchy problem, i.e
* >> the difference in scaleР Р†Р вЂљР’В¦ >> exactly, between the Higgs mass and the scale of gravity
* So, there are open questions
* What are we to do
* We can ask our theorist colleagues, and they formulate hypotheses, that there are particles, that one must introduce particles beyond the Standard Model, and the hypothesis is that one can create these new particle in our collisions
* So I dedicate my research to finding new particles, like particles predicted by supersymmetry, or theories with extra dimensions
* >> So, for this, the predicted cross sections are very, very small, are they not
* >> They are of the order of, or smaller than the cross sections characterising the Standard Model, and thus we evidently need an high performance accelerator, a collider
* >> So, what are the properties of the LHC, which are crucial for your research
* >> We expect that these particles have a very large mass, and that their production rate is very low
* So, the two most important parameters of the LHC for this are the energy and the luminosity
* Higher energy allows us to produce more massive particles
* >> And a higher luminosityР Р†Р вЂљР’В¦ >> It means more data, a higher production rate, more events, which can be observed
* >> The LHC is a sort of double accelerator and storage ring, where the protons circulate in two directions
* So, in principle, it is two accelerators in one, isnР Р†Р вЂљРІвЂћСћt it
* >> Exactly
* We have the principle of two-in-one, for all the magnets of the LHC there are two coils
* >> Why does one need two accelerators
* >> Because there are two proton beams in opposite directions
* So, one needs two magnetic fields
* >> One beam circulates in one direction.>> Yes
* >> And the other in the opposite direction
* And they meet at the interaction points
* >> Yes
* We need the same Lorenz force towards the center of the orbit, so we need one magnetic field pointing upwards, the other one downwards
* And for this one uses these dipole magnets
* >> So here, we are almost sitting on one of these dipole magnets, Can you explain the elements of these magnets a little
* >> Exactly
* So here, one sees the two rings, the two vacuum tubes, and one sees two coils, one and the other, which are exactly the same, the only difference is that the current is reversed
* And here is the common yoke for the magnetic fields and the cryostat is also in common
* >> Ok
* So, in one of these coils, there is an upward pointing magnetic field, and in the other, the same dipole field, but pointing downward
* With means that we are deviating the two beam in the same direction, even though they have opposite directions, simply applying LorentzР Р†Р вЂљРІвЂћСћ law, which gives the centripetal force, which we need, q(v x B) in this case
* >> Exactly, with the right hand rule
* >> Mh mh
* The two coils are in the same cryostat
* Why
* Why does one not simply build two separate magnets
* >> One can reduce the cost this way, having a common cryostat for the two coils
* >> So, for the enormous energies of the LHC, one needs superconducting coils
* >> Exactly
* >> Ok
* And because of that, all are in one cryostat
* So, the coils themselves are made of copper, arenР Р†Р вЂљРІвЂћСћt they
* >> Maybe a few numbers about the magnetic system, which show that it is really very important, even essential for the LHC
* Of the 27 km of circumference, 85% are occupied by magnets, the magnet systemР Р†Р вЂљР’В¦ >> Ok
* >> Р Р†Р вЂљР’В¦and 75% by dipoles, like this one
* >> So this is really the heart of the matter
* Magnets are practically everywhere
* >> There are magnets everywhere, right
* There are more than 1000, more than 1200 elements like this
* Each one weighs 30 tons, has 15m length and a maximum magnetic field of 8.3 Tesla
* >> So what we see here is just a small segment of a dipole, which in reality is much longer
* >> Ok
* So this makes a gigantic cryogenic system, so, practically all the ring is at cryogenic temperature, all around its length of 27km
* >> Yes
* So, later we will see the superconducting cables, there are 1200 tons of superconducting cables and it needs 130 tons of superfluid helium to cool down all this mass to 1.9 Kelvin
* >> Wow
* >> So I propose to move on to see how these coils look and also the focalising elements of the LHC
* Here we are in front of one of the quadruples of the LHC, which serves to focalise the two beams
* So, the principle of this focalisation has been explained in video 3.2, but why is it important to focalise the beams of the accelerator, Tobias
* >> So, here we come back to the luminosity, which we have already mentioned
* The luminosity is inversely proportional to the common surface of the two proton beams, and that is why one must focalise them, to reduce this surface
* And here we see very well a section of a quadrupole magnet, which is responsible for the focalisation
* One sees very well the four poles, here two north poles and two south poles, and then here are two version of this magnet, one is responsible for horizontal focalisation, the other one for the vertical one
* One alternates the twoР Р†Р вЂљР’В¦ >> Puts them in chains
* >> Р Р†Р вЂљР’В¦to have an optimum focalisation
* >> So if we look at the coils, the wires go effectively in this direction, donР Р†Р вЂљРІвЂћСћt they
* >> Exactly.>> So here we have in fact a section of such a coil
* Can you explain the ingredients of such a coil
* >> Yes
* All coils are composed of superconducting cables, they are very important, as we said, there are 1200 tons of these cables
* They are in fact composed of these strands, with a diameter of roughly 1mm
* And these strands are themselves composed of filaments, which are ten times finer than a human hair
* >> That means about 10 micrometers in diameter
* >> Something like that
* >> What is the material
* >> It is niobium-titanium
* And there is copper layer around
* >> And all of this is normally imbedded in a sort of aluminum stabiliser, that is why there is this gray material
* >> Yes, yes
* >> OK.So this serves to wind the coils of the active part of the magnets
* But also to transport current around the accelerator, doesnР Р†Р вЂљРІвЂћСћt it
* >> Exactly
* We have these cables all around the accelerator
* If one takes the total length of the filaments, one arrives at an astronomical scale
* One can go five times to the sun an back with this
* >> It is really incredible, all this effort which is made to produce the particles you are searching for, isnР Р†Р вЂљРІвЂћСћt it
* >> In fact it serves this purpose
* >> So, we still need to discuss an element of the accelerator which we have not covered yet
* These are the accelerating elements themselves
* So I propose that we move on to see what they look like in reality
* In this small video animation we see a cryostat which contains four superconducting elements, i.e
* radio frequency resonators
* The radio frequency wave enters through these wave guides and establishes an electric field with the right polarity, such that the beam is accelerated in its direction of motion
* So here is one of these elements
* Tobias, can you please explain these ingredients of this radio frequency cavity
* >> Of course
* Such a cavity has as you said, the principle purpose to accelerate protons from an energy of 450 GeV, the energy with which they enter the LHC, up to 7 TeV, which is their maximum energy
* Here we see the wave guides, the radio frequency generated by the Klystron enter here and leaves there
* For the LHC, they have a frequency of 400 MHz
* >> OK
* So inside, a stationary wave is formed
* And when the polarity is right at the right time of arrival of the protons, we will have a net acceleration in the direction of the electric field
* So, how does one synchronise this wave with the beam passage
* >> It is very important to have mono-energetic beams So we must equalise the proton energy
* So when the proton with the right energy enters at the right moment, there will be no acceleration if we are already at the maximum energy level
* However, if the protons arrive too early or too late, i.e
* when their energy is a little too large or too small, an acceleration is felt the protons are decelerated or accelerated to approach the ideal energy
* This happens automatically, when the protons enter in the increasing phase of the electric field, as we have seen in video 3.2
* So, this accelerating cavity, the resonator and all what is around, is made of copper and is emerged in a cryostat, which holds it at liquid helium temperature, such that the copper is superconducting
* >> So why is it important that this structure also is superconducting
* >> Yes, it is very important that there is a minimum ohmic resistance, such that the power of the wave is not attenuated
* >> Ok, this means that the radio frequency wave arrives without loss from the klystron to the beam
* >> Exactly
* >> Ok
* So, thank you very much, Tobias, for this visit, and for this demonstration of the LHC elements
* This concludes this video
* In the next video, we will start to discuss particle detection
* [MUSIC]


--- SKIP ---: 01_3-4-heavy-particles-in-matter.en.srt


--- SKIP ---: 01_3-4-heavy-particles-in-matter.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-4-heavy-particles-in-matter.en_SENTbySENT.txt
* [MUSIC] In this module, we touch the basicsof particle exhilaration and detection matters
* And in this fourth video, we will show how heavy chargedparticles interact with matter
* These interaction mechanismsare used to detect them
* At the end of the video, you will knowthe energy loss by ionization and excitation of heavy charged particles
* And the distribution of the energyloss for these particles and their angular deviation whentraversing a slice of material
* To detect particles, one must makethem obviously interact with matter
* With the exception of neutrinos,all particles interact in one way or another via the electromagnetic force
* Hadrons, obviously, also interactvia the strong or the nuclear force
* Electromagnetic interactions thus playa predominant role among the mechanisms of interaction and particle detection
* Its different reactions are listed here
* We will discuss them in this video andthe one that follows
* When a charged particle passes througha slice of material of thickness dx, it ionizes or excites the atoms it meets
* By this, the particle losesthe part dE of its energy
* The energy lost per unit length, dE/dx, plays a central role inthe detection of stable charged particles
* It depends on both the properties ofthe particle such as its charge z and its velocity beta, as well asthe properties of the material crossed, like the volume density n_eof its electrons, which is proportional to the atomiccharge and its ionization constant I, which describes how easyit is to ionize its atoms
* The dependence of dE/dx onthese factors is described by the Bethe-Bloch formula reproducedon the top of this slide
* One can combine many of the constantsinto a single one which is called K in this slide
* Thus, it can be seen that at low velocitydE/dx is proportional to the charge of the particle squared and inversely proportional tothe square of its velocity
* The energy loss goesthrough a shallow minimum, located approximately at the samevelocity for all particles
* In this minimum,particles are called minimum ionizing
* Because of the strong dependenceon the square of the charge, we can even identify the charge of theincident particle by measuring dE/dx
* Beyond the minimum, the energyloss dE/dx increases slightly with the logarithm of beta gamma equalto p/m, as shown in this graph
* Here's a summary of dE/dxin typical gases, liquids, and metals as presented bythe particle data group
* The minimum of the curves isapproximately at the same velocity for all the materials
* It is surprising that the curves forsolids are below that for gas
* Do not forget that the energy lossis given here with respect to the surface density
* To find dE/dx in units of penetrateddepth, one must multiply by the volume density of the material which is a 150times greater full lead than for hydrogen
* The beta gamma scale, the x-axis ofthis graph, is converted to momentum from neurons, charged pions andprotons to simplify the use of this graph
* Obviously, the energyloss by ionization and excitation is a random process, whichwill not always yield the same result
* Therefore, dE in a givenmaterial thickness dx follows a Landau distribution
* This is an asymmetric distributionaround the most probable value E_W with a width characterized by xi
* The most probable energy loss isderived from the Bethe-Bloch formula
* Since dE/dx increases with decreasingvelocity, the particle loses more and more energy per unit depthwhile penetrating the material
* The greatest loss happens immediatelybefore the particle is stopped
* This is called the Bragg Peak
* The effect may be beneficialin medical applications
* When irradiating tissue by chargedparticles, one can adjust the initial momentum and thus, the penetration suchthat most of the energy is deposited where a cancerous tumor is located,preserving healthy tissue around
* Multiple scattering offatomic electrons also deflect the incident particle from its initialdirection and displaces its path
* The distribution of angular deflectionfollows a Gaussian around zero
* The width depends on particle andmaterial properties as shown
* The latter can be combinedinto the radiation length, X_0, which we will introducelater in this module
* Hadrons, of course, also belongto the class of heavy particles
* In addition toelectromagnetic interactions, they can interact with matter nucleithrough strong or nuclear interactions
* Elastic scattering makes themlose energy to a lesser extent because nuclei are typically heavy andrecoil little
* Inelastic interactions occur at highenergies and create additional particles
* These deposit energy by dE/dx, butcan also, in turn, produce more particles
* At sufficient energy, typically,a few GeV, this will generate a cascade processwhich is called a hadron shower
* You see in this image a simulationof such a process with an incoming high-energy proton
* Each block dot represents a unit ofenergy loss by a charged particle
* The characteristiclengths of this processes are the nuclear collision lengthsapplying to elastic interactions and the nuclear interaction lengthapplying to inelastic interactions
* Both can be found in the tablesof the Particle Data Group
* They are typically much larger thanthe radiation length of the material
* In the next video, we talk aboutthe interactions of light particles in general, and bremsstrahlung in particular
* [MUSIC]


--- SKIP ---: 01_3-5-light-particles-in-matter.en.srt


--- SKIP ---: 01_3-6-photons-in-matter.en.srt


--- SKIP ---: 01_3-6-photons-in-matter.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-6-photons-in-matter.en_SENTbySENT.txt
* [MUSIC] In this module we are in the process of discussingthe basics of particle acceleration and particle detection
* In this video, we will demonstratehow photons interact with matter
* At the end of this video, you will knowthe mechanisms by which they are detected, namely, the photoelectric effect,Compton scattering and pair production
* In these processes, the photon is eitherabsorbed or scattered by a wide angle
* Most of the photons in a beamkeep their original energy, but their flux is diminished
* A photon beam will thus beattenuated rather than lose energy
* The probability of an interaction ina given target thickness is a constant, proportional to the crosssection of the process
* This leads to an exponential decreaseof the intensity of a photon beam as a function of absorber thickness
* We've already calculated an exampleof this in the optional video 1.3a
* Photons are detected by interactionswhich produce charged particles
* The photoelectric effect is the absorptionof a photon by an atomic electron, dominant between the ionization energy of an atomand about 100kV of photon energy
* Compton scattering is the elasticscattering of a photon off a quasi-free atomic electron, dominant around photonenergies roughly 1 MeV
* Pair production is the conversion ofa photon into an electron-positron pair in the electromagnetic field oftypically of a nucleus, dominant for photon energies much largerthan 1 MeV
* We will discuss these processesone by one in what follows
* In the photoelectric process, the atomic electron is releasedwhen the atom absorbs the photon
* Its kinetic energy is then the differencebetween the photon energy and the ionization energy
* This latter one depends on the shellwhere the electron was and is typically between and1 and 25 electron volts
* The photoelectric process isnot feasible for a free electron
* It would violate conservation of momentum
* If the photon energyis larger than the K shell energy, the cross section is dominatedat the level of roughly 80% by the absorption of K shell electrons, since the proximity of the nucleuseases absorption of the recoil energy
* Sigma_Th, in this formula, is the standardcross-section of Thompson scattering, it sets the scale of this cross section
* The dependence on the atomiccharge to the fifth power and the photon energy tothe power -7/2 favors the photoelectric process forlow energy photons in heavy materials
* At high energies inthe relativistic limit, the energy dependencebecomes simply 1/E_gamma
* The vacancy opened bythe photoelectric effect can be filled by another electron of an upper shell,say the L shell for example
* This will result in either the emissionof an X-ray with energy E_l- E_k or the emission of an Auger electron, if the available energy is greater thanthe ionization energy for higher shells
* In Compton scattering, dominant atintermediate energies around 1 MeV, a photon is scattered off a quasi-free electron
* The cross section is given by theKlein-Nishima formula which is obtained by quantum electrodynamics thatwe'll discuss in module 4
* The energy of the scattered electron ismaximum when the scattering angle is 90 degrees with a maximum electronenergy that is given by the formula on the bottom of this page
* The Compton scattering cross section is typically about 0.1 barnin the forward direction
* For backward scattering,it varies between 0.1 barn at low energies and 0.04 barn at 100 keV
* At high energy, the process is thus dominatedby scattering in the forward direction
* In the electromagnetic field of a nucleus, the photon can convert intoan electron-positron pair
* The energy threshold is essentiallytwice the mass of the electron with a small correction for therecoil fo the nucleus
* This process cannot take place in vacuumbecause of energy-momentum conservation, but little energy is transmitted to thenucleus, about 1 MeV for heavy nuclei
* At low andmodest energies the cross-section per atom is given in terms of the radiation length
* This is the same length as the onewe defined in video 3.5, i.e, the length after which an electron losesall but 1/e its energy by bremsstrahlung
* In this image, taken with a historicalbubble chamber, we see the tracks left by charged particles as smallbubbles formed in an overheated liquid
* The chamber is immersed in a magneticfield octagonal to the projection plane, which deflects the trajectories
* This is an atypical process in thata photon enters from the left and converts into an electron positron pairin the field of an atomic electron and not in the field of a nucleus
* This produces what is called a trident
* These are the three charged particle tracks you seeattached to the left vertex
* The pair particles losetheir energy in the liquid, their trajectories are the spiralsthat you see on the left
* The atomic electron takes an appreciablerecoil energy because of it's small mass
* Its stiff track goes to the rightwith very little curvature
* About halfway,the electron emits a bremsstrahlung photon, which in turn converts intoan electron-positron pair
* You see this pair by the V-shapedtracks on the right
* The cross-section for pair productionbecomes almost independent of the photo energy abovean energy of about 1 GeV and then depends only on the material,that is to say on X_0
* The conversion probability per unitdistance is inversely proportional to the radiation length
* The mean free path fora photon before it converts is the inverse of this probability andthus 9/7 of a radiation length
* The busy plot on the right showsthe summary of the contributions of all processes to the photontotal cross section in metal
* Among this the most important ones are thephotoelectric effect at low energies and pair production at high energies In between around 1 MeV, atthe minimum of the cross section, Compton scattering dominatesover other processes
* At high energy, as we have seen atenergies above 1 GeV, electrons and positrons lose their energy almostexclusively by bremsstrahlung
* Photons convert to electrons andpositrons by pair production
* The two phenomena have the samecharacteristic length, the radiation length
* The successive combinationof these two effects results in the formation of what iscalled an electromagnetic shower
* Whenever an electron, positron or photon of highenergy enters into a medium, it will cause such a shower
* A simulation is shown on the right
* Again, each black dot correspondsto a unit of energy loss
* In the next video, we will see how ionization detectorsmeasure the passage of charged particles
* [MUSIC]


--- SKIP ---: 01_3-7-ionisation-detectors.en.srt


--- SKIP ---: 01_3-7-ionisation-detectors.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-7-ionisation-detectors.en_SENTbySENT.txt
* [MUSIC] In this module we touch upon the basicproperties of particle acceleration and detection methods
* In this video and in the next, we will discuss chargedparticle detection techniques
* First we talk about ionizationdetectors in general, and gaseous ones, in particular
* After watching this video, you willknow how gaseous ionization detectors count charge particles andmeasure their trajectories, and which operational modessuch a detector can have
* Ionization detectors detect the passage ofa charged particle by measuring the total charge of electrons and/or ions produced by the ionization of the medium
* This medium can be a gas,a liquid, or a solid
* To collect the electrons and the ions before they recombine into atoms,an electric field must be present, which separates the charges andmakes them drift towards electrodes
* The charges induce a smallcurrent on the electrodes, a signal which can be detectedthrough an amplifier
* The average number ofelectron-ion pairs produced during the passageof a charged particle is given by the Bethe-Bloch formulathat we have presented earlier
* With d being the thicknessof the detector, and W, the average energy requiredto ionize one of its atoms
* In a gas, W is typically ofthe order of 30 eV
* The size of the detected electrical signaldepends on several technical factors, but mostly on the applied high voltage
* So this graph shows the mostimportant operational regions
* On the y-axis you see the detectedcharge in a logarithmic scale, and on the x-axis you seethe applied high voltage
* The first useful region for particledetection is the ionization region, where the voltage is large enough toprevent ion-electron recombination and the ionization chargesdrift towards the electrodes
* The resulting signal reflects thenthe total ionization charge
* The advantage of this operational region is that you obtain an excellent energyresolution at a very good linearity
* The obvious disadvantage is thatthe detected signal is very small, since there's no internalamplification in the detector itself
* So special low-noiseamplifiers have to be used in order to render this signal detectable
* This operational mode is used inionization chambers filled with gases or noble liquids
* Also, solid state detectorsmade of silicone or germanium, which will be discussed inthe next video, work in this region
* The next useful region for particledetection is the proportional region
* If the field is high enough, ofthe order of 10^4 V/cm, electrons are accelerated by the electric field and gain enough energy toproduce secondary ionization
* The total number of atoms ionized growsexponentially with the applied voltage, as shown in this graph
* The amplification factor is between10^4 and 10^8
* And the large amplification factorcan especially be obtained in gases, which is why detectors operating inthis region are mostly gas-filled
* The advantage of using this region is thatthere's no need to have a very low-noise electronics, since there's internalamplification in the detector itself
* The disadvantage is thatthe energy resolution is worse, because of fluctuations inthe amplification process
* These fluctuations are mainly due toinstabilities in external parameters, like the high-voltage,the temperature, the pressure, etc
* Detectors operating inthe proportional region are mainly used to measure the position of particles
* Drift chambers, proportional wire chambersand so on, use this operational region
* In these chambers, the electric fieldis implemented using thin wires, to put as little material aspossible in the path of the particle As an example, we show here, the centraldrift chamber of the L3 detector at the Large Electron-Positron Colliderat CERN
* As the particles lose very littleenergy in the gas by dE/dx, the measurement is not destructive
* Wire chambers are ideal to measure chargedparticle tracks in front of a colorimeter, which will then measurethe particle energy by absorption
* We'll talk about spectrometers andcolorimeters in video 3.10
* The last useful region of gazeous ionization detectorsis the Geiger region
* If the field is increased even more, the energies of secondaryelectrons increase rapidly
* And they excite or ionize other atoms
* Thus, an avalanche of freeelectrons is produced
* Furthermore, a large number of photonsis produced when the atoms fall back into their ground state
* These photons add to the ionizationby photoelectric effect along the wire where the electricfield is strongest
* The avalanche develops quickly andan audible discharge is produced
* This is the principleof the Geiger counter
* Due to the discharge,the current on the anode is saturated
* The signal amplitude is thusindependent of the primary charge
* The advantage of using this regionis that low radiation levels can be measured by counting particle rate,even if the particles have low energy
* The disadvantage is that the energy ofthe particles cannot be measured
* The discharge stops when the spacecharge formed by the positive ions around the anode decreases sufficientlythe electric field so that the avalanche process stops
* The detector will beinsensitive to new ionization until the positive ions havemigrated far enough from the anode
* This is the origin of deadtime in a Geiger counter
* A further increase in the electricfield produces a permanent discharge
* A short circuit between cathode and anode,which will eventually destroy the device
* Here's a picture of a Geiger counter, which makes an audible soundevery time a particle is counted
* And in fact,I've brought a Geiger counter here
* It has the Geiger tube fixedto the electronics and the counting device in this base
* So if I switch it on
* [SOUND] You can hear the audiblesound created by the device
* The counting rate is mostly due to the Potassium radioactiveisotopes inside my own body
* In the next video, Mercedes will discusssemiconductor-based ionization detectors
* [SOUND]


--- SKIP ---: 01_3-8-semiconductor-detectors.en.srt


--- SKIP ---: 01_3-8-semiconductor-detectors.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-8-semiconductor-detectors.en_SENTbySENT.txt
* [MUSIC] In this module, we touch the basicsof particle acceleration and detection methods
* In this video, we will continue ourdiscussion on particle detection techniques with semiconductor devices
* After having watched this video, you willknow how semiconductor detectors detect the ionization caused bytraversing charged particles
* And how this is used toidentify charged particles and to measure their trajectories
* This particular type of ionizationdetectors uses the properties of semiconductors to detect and measuredE/dx of charged particles
* When a charged particletraverses a semiconductor, it will create an electron-hole pair
* Since the conduction band isclose to the valence band, it takes only 3 eV of dE/dx to create a pair compared to the 30 eV to ionize a gas atom
* The charges can be detected byapplying an electric field
* Semiconductor detectors havevery good energy resolution
* They are compact sincethey are made of a solid
* They are thin with a required thicknessmuch smaller than their additional length
* The special resolution is inthe order of micrometers, ideal for a tracking detectors
* And also they produce fast signals,however they are expensive
* They are fragile to make mechanical,chemical and electrical impacts, and their performance isdegraded by irradiation
* The basis of a semi-conductor detectoris a p-n junction with reverse bias
* When two different semi conductor types,n and p, are in contact, diffusion creates a zone free of chargecarriers around the contact surface
* A depletion zone forms at the junction,creating a potential barrier, which prevents conductionbetween the two semiconductors
* The application of a reverse biasvoltage widens the depletion zone, and this is how semiconductor diodes work
* The passage of ionizing particlesliberates electron-hole pairs in the depletion zone
* Charge are collected to both ends, and the diode conducts a small current fora short time
* Semiconductor detectors have a goodefficiency since only 3 eV are necessary to createa single electron-hole pair
* So, these detectors are tentimes more sensitive than a gas, and a hundred times moresensitive than a scintillator
* It, therefore, has a lower detectionthreshold and a better energy resolution since more primary ionizationmeans less signal fluctuations
* The threshold for dE/dx isvery low, so that is a good linearity
* However, to measurehighly ionizing particles requires a large dynamic range ofreadout electronics since dE/dx is proportional to the squareof the charge of the particle
* Even if the junction is in reverse bias, there is still a small current of theorder of nA through the junction
* This is called leakage current andit is due to the motion of minority careers, effectsof impurities and surface effects
* The time of the electrical signalis of the order of nano seconds
* So semi conductor detectors are as fast as scintillators which we willdiscuss in the next video
* The energy deposition bythe dE/dx is very local
* Therefore, the electrodescan be structured in one or both sides to locatethe passage of particles
* The distance of metalized structures, called strips, is typically ofthe order of 50 Р вЂ™Р’Вµm
* And in this picture, you see an exampleof silicone microstrip sensor of the AMS detector which is operatingon the International Space Station and of the ALICE detector operatingat the Large Hadron Collider
* Each channel of the metallic structuremust be connected to the readout electronics through micro bonding
* Applications of a semiconductor detectorin particle physics include the following
* They are used arranged in layers to measurethe trajectory of charged particles
* And this profits from the development inmicro electronic technology to fabricate precise structures on silicon andother semiconductor materials
* Example are microstrip detectorsused in the ATLAS at the Large Hadron Collider and in AMS
* Pixel detectors which are being used forthe first time at LHC
* Charged coupled devices, CCD, used indigital cameras, and many others
* Semi conductor detectors alsomeasure the deposited element
* Their excellent resolution allowsthe identification of the charge of the penetrating particlein a tracking device
* They can also be sensitiveelements in a calorimeter
* This application is only limitedby the thickness of the depletion zone which goes from 50 micrometersup to order of millimeters and the maximum chip size that can be producedwhich is about 50 centimeters squared
* Here is an example of a silicon wafer, so the big rectangle at the center.And the sides, they are testing circuits whichallow to test the quality of the sensor before usingit to assemble a detecting unit
* Before using it,one must cut the sensor
* And this is an example of a cut sensor
* And usually, one connects severalsensors together to build the detection unit like thisone where there are two silicon sensors connected atthe middle by micro bonding and at the one end micro bonding connectsthem to the readout electronics
* More example of applicationsusing semi-conductor sensors will be shown in video 3.10
* In the next video, we'll first talk aboutthe scintillators and Cherenkov detectors
* [MUSIC]


--- SKIP ---: 01_3-9-scintillation-and-cherenkov-detectors.en.srt


--- SKIP ---: 01_3-9-scintillation-and-cherenkov-detectors.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-9-scintillation-and-cherenkov-detectors.en_SENTbySENT.txt
* [MUSIC] In this module, we are touchingthe basics of particle acceleration and detection metals
* And in this video, we'll continue ourdiscussion of particle detection, the techniques, talking aboutscintillators and Cherenkov detectors
* After watching this video, you will knowthe principle of particle detection by scintillation light, and the measurementsthat can be done via the Cherenkov effect
* In scintillation detectors,also called more simply scintillators, particles are detected by meansof their luminescence mechanism
* Certain materials,when exposed to radiation, absorb energy, which is then emitted as light
* If the light emission occurs soon afterradiation, we call it fluorescence
* If it takes more than 100 milliseconds toemit light, we call it phosphorescence
* Scintillation corresponds to fluorescence, after radiation by charged particles,high energy photons or neutrons
* There are two types of scintillatingmaterials, inorganic materials, for which fluorescence is associated tointermediate states due to impurities
* They have a high atomic number, sothey are well-suited for photon detection
* And they can be ceramics,glasses, liquids, noble gases and crystals, such asthallium-doped sodium iodide, lead tungstate or bismuth germanate,also called the BGO
* And this is an exampleof a bismuth germanate, a BGO crystal, which is quite heavy
* Organic materials are the secondtype of scintillating materials
* And in these, the source of fluorescenceare excited molecular states
* They have high hydrogen content, so theyare well suited for neutron detection
* They can be crystals, liquids anddoped plastics like this example here
* Both have a very short response times,ranging from nanoseconds for organic scintillators towards 0500nanoseconds for inorganic ones
* A particle traversing a scintillatorexcites the atoms of the molecules of the material, which will then returnto their ground state emitting photons
* If the material is transparent throughat least a portion of the scintillation wavelength spectrum, the photonsemitted can be collected at the end of the scintillator by a photosensitivedetector, for example, in photomultiplier tube, PMT,and often to a light guide
* The collected light is thentransformed into an electrical signal
* The shape of the signal,which is shown in the plot on the bottom, is characterized by the very short risetime, typically less than one nanosecond, and then much larger decay timeof the order of 100 nanoseconds
* This short rise time makes scintillatorresponse faster than ionization detectors
* That's why they are usedin triggering systems
* They have a good efficiency, the energyneeded to create a scintillation photon ranges from 20 electronvolt forthallium-doped sodium iodide, to a few hundred electron volts fordoped plastic and BGO
* Except for low energies,they are linear, that is, the number of photons is proportionalto the energy deposition
* Thus, counting photons allows tomeasure the deposited energy d by dx
* Often, light guides are used to transportscintillation light to the photodetector, minimizing losses both by absorption andleakage
* They are used to adapt the shapeof the scintillator cross section to that of the photodetector
* And here is an example of a light guide,so typically the scintillatorswill be connected here and the light will be routedto the photodetector, which will be connectedhere at the bottom
* In some cases, light guides alsoserve to shift the emission spectrum of scintillation lightto better match the spectral sensitivity of the photodetector withwhat is called a wavelength shifter
* These are materials whichabsorb scintillation light and remit it in a different wavelength
* In order to minimize lightlosses by reflection, light guides as well as scintillatorsthemselves use total internal reflection
* If the incident angle theta of the photonis larger than a critical angle, theta c, which sine of theta c is equalto the ratio between the reflecting index in air andin the scintillator over the light guides, the photon will not escape by reflectionand will reach the photodetector
* For plastic,the critical angle is about 39 degrees
* At smaller angles, mirror reflection on aexternal reflector like reflective paint, paper orspecial foils like liquidity are used
* Reflection can be furtherreduced using luo gel, with the same reflectiveindex to join the elements
* And here is an exampleof scintillator bars, which have painted with whitepaint to minimize reflection
* And then also connected towavelength shifter fibers, which guide the lightto the photodetector, which will be connected here at the top
* The wavelength spectrum of photonsemitted by scintillation has an error of distribution around a maximum
* For plastic,the maximum is at 423 nanometers
* For thallium-doped sodiumiodide at 430 nanometers
* At 480 nanometers for BGO,and 475 nanometers for cadmium tungstate, as shown in this graph
* Also shown is the detection efficiency for a specific photodetector,a photomultiplier
* This quantity is often calledthe quantum efficiency
* It is optimum in a certain spectral range,so the photomultiplier must beadapted to the material used
* Sometimes a dopant is added tothe detection material to shift the wavelength and better fitthe photomultiplier sensitivity
* The dopant absorbs the scintillationof photons and quickly, that is in less than one nanosecond,emits photons with another wavelength
* Photon must pass through the scintillatorto reach the photosensitive elements
* Some photons will be absorbed on the way
* The number of non-absorbed photonsdecreases with distance following an exponential distribution, which dependson the attenuation length of the material, which is generally ofthe order of one meter
* And this allows to build largescintillation detectors
* The purpose of the photodetector isto convert scintillation photons to an electrical signal, which can be then processedelectronically after amplification
* Here we show a photomultiplier,where the conversion of photons into an electrical signal is achievedvia the photoelectric effect in a thin layer of alkali metalalloy called photocathode
* The quantum efficiency measures the number of photoelectrons createdper incident photon
* For modern photocathodes,this is typically 30, 40%, depending on the wavelength, as shown inthis plot for two different photocathodes
* Behind the photocathode isa series of electrodes, typically 10 to 14, called dynodes
* They contain a particular alloywith low ionization energy
* An increasing electricalpotential is applied
* The photoelectrons emitted bythe photocathode are accelerated and focalized on the first dynode
* They release, typically between two and five electrons per photoelectron,depending on the applied voltage
* The signal amplification progressesfrom line to dynode, and the total gain can reach 10million after 14 dynodes
* And here is an example of a photo tube with metal dynodes
* Another type of photodetectorimplements dynodes as grades like in this exampleof a metal mesh photo tube, which you see is much more compact thenthe photo tube with metal dynodes
* So let's now see how the Cherenkoveffect an be used to detect particles
* A charged particles of velocityv going through a medium of refractive index n willpolarize the atom along its path
* These atoms become electric dipoles and emit electromagnetic radiation uponreturning to the ground state
* If the velocity of the particle doesnot exceed that of light in the medium, radiation of the dipoles of the upstreamand downstream sides are about to cancel
* If on the contrary, the velocity ofthe particle v is larger than c over n, where c is the velocity of the lightin a vacuum and n is the reflective index of the medium, the downstreammaterial cannot be polarized
* The electromagnetic field createdby the particle propagates less quickly than the particle itself andthe net radiation results its waveform to form the cone of light,around the part or the particle
* This is the Cherenkov effect
* This kind of radiation is producedin all transparent media
* The energy loss by Cherenkovradiation is negligible
* There are mechanical analogiesto this mechanism, which is like a boat in the water or a plane whichexceeds the velocity of mach one
* The additional thresholdis then a bit larger than the inverse of the refractiveindex of the medium
* A threshold of radiation is emittedin the direction of the particle that is at theta equal to 0
* The different threshold for chargedparticles with different masses can be spread to differences between them forreason to identify different isotopes
* Particles heavier than m maxwill not emit radiation
* Ring imaging Cherenkov,go the reach, go a step further
* Here the Cherenkov light isintercepted by a detection surface
* Photons form a ring, which allows tomeasure Cherenkov light angle, and thus determine the velocityof the incoming particle
* In addition, the intensity ofthe Cherenkov light, that is the number of photons in the circle, is proportionalto the square of the particle charge
* Cherenkov light is also emitted in water
* This gives the possibility ofbuild a large mass detector like the Super-Kamiokande in Japan
* This gigantic water tank,surrounded by photomultipliers, is used to detect neutrinos
* In the next video, we will see howthe different detectors are combined to form spectrometers and calorimeters
* [MUSIC]


--- SKIP ---: 01_3-10-spectrometers-and-calorimeters.en.srt


--- SKIP ---: 01_3-10-spectrometers-and-calorimeters.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-10-spectrometers-and-calorimeters.en_SENTbySENT.txt
* [MUSIC] In this module, we are discussingthe basics of particle acceleration and detection methods
* In this video, you will see how differenttechnologies are combined to build the two basic types of particle detectors,spectrometers, and calorimeters
* At the end of this video, you will be ableto describe how a spectrometer measures the direction and momentum of a chargedparticle in a nondestructive manner
* And to describe how a calorimeter measuresthe direction and energy of a particle by total absorption
* You will also be able to identifythe strength of these two basic methods and their synergy
* A magnetic spectrometer is usedto measure the direction and momentum of a particlewith minimal interaction
* It is a nondestructive methodto measure these properties
* The particle trajectory is measuredin a known magnetic field
* For a homogeneous field, the trajectory isa spiral, a circle in the plane orthogonal to the field, and a straight linein the direction of the field
* The radius of curvature is proportional towhat is called the magnetic rigidity R, which is the ratio between the momentum p,and the charge Z
* R = p/Z, and can bemeasured by the product of the radius of curvature and the magnetic field
* The magnetic field itself is provided bya permanent magnet or an electromagnet
* Measurements of the path are performedby an ionization detector, a gas filled wire chamber, for example,or layers of semiconductor detectors
* The tangent to the trajectoryat the entry of the magnet gives the direction ofthe incident particle
* As an example, here's, again, a photo ofthe drift chamber from the L3 experiment at the Large Electron-Positron collider at CERN as well as a picture of an e+e- annihilationinto hedrons on the right side
* The reaction takes place inthe middle of the device, the center of the image on the right
* In the central part, you see the tracks ofcharged particles in yellow reconstructed from the measured coordinatesindicated by the small green crosses
* The curvature is barely visible but well-measured by the highresolution drift chamber
* In this photograph on the left, you see a central detectormade out of silicone sensors, the one that is used bythe ATLAS experiment
* The right image is a reconstruction of areaction between protons in the middle of the device
* The charged particles, which are produced, leave tracks forming circlesorthogonal to the magnetic field
* The purpose of a calorimeteris to measure the energy and direction of particles by absorbing them
* The principle of operationis the following
* The incident particle initiatesa shower of particles in the detector, an electromagnetic shower,or a hadronic shower
* The shape, size, and composition of theshower depends on the incident particle
* But also on the detector material,namely, its radiation length,its nuclear interaction length
* The energy is deposited in the form ofheat, which is not very useful, but also produces detectable signals,like ionization and excitation by dE/dx, scintillation light,Cherenkov radiation, etc
* This energy is detected by sensors
* The resulting signal is proportional tothe total energy deposited by the particle of the shower in the activemedium of the detector
* There are two kinds of calorimeters,homogenous ones with only one material to absorb and detect the shower particles andlayered calorimeters, which use different materials forinteraction, absorption and detection
* Here's an example of a layered calorimeter
* In such a calorimeter, layers alternate
* There are absorption layers made of heavymaterials like copper, lead, or uranium with the shortradiation in direction
* Here, particles interact andform a shower
* In the sensitive layers,the energy lost by dE/dx is recorded
* These layers may beequipped with a gaseous or noble liquid, a proportional chamber,a semiconductor sensor, or a scintillator
* You see here, the electromagneticcalorimeter of ATLAS which contains absorption layers of lead and steel alternating withsensitive layers filled with liquid argon
* The whole has a shaperesembling an accordion
* In a homogenous calorimeter on the otherhand, the two functions are combined
* The same material is used as an absorberand as a detector for deposited energy
* Scintillators made of heavymaterials can be used, like bismuth germanate,BGO, or lead tungstate
* Because of the short radiation length andthe transparency of these materials, they are often used to detectelectromagnetic showers
* The scintillation light,emitted by the electrons of the shower, is detected by photomultipliers orby semiconductor photodiodes, as in this example, which shows you the lead tungstatecalorimeter of the CMS experiment at LHC
* Calorimeters are also one of the mainapplications of plastic scintillators
* The large calorimeter for hadron showers ofthe ATLAS experiment is an example
* Here, you see a small animationshowing the structure of one of its wedge-shaped slices
* It uses scintillated tilesinserted between steel absorbers to measure the energy of hadrons
* The shower develops mainlyin the metal layers
* The charged particles it generates producescintillation light in the sensitive layers
* The scintillation light iscollected by optical fibers and guided to photo detectors
* In this way, a three-dimensionalimage of the shower is measured, which allows to reconstruct direction andenergy of hadrons
* But also the Cherenkov effect allowsto build complete detectors
* The Super-Kamiokande Detector in Japanconsists of a huge cylindrical tank, which contains 50,000tons of ultra pure water
* When a charged particle passes throughthe water at the speed beyond that of the speed of light in water, which isabout 75% of the speed of light in vacuum, a cone of light is emitted
* This cone is intercepted by an arrayof photomultipliers distributed on the walls
* They detect an ellipse of photons, whichallows to reconstruct the direction and velocity of the particle
* Lateral and longitudinal segmentationallows to distinguish between hadrons and particles, which interact only via theelectromagnetic force, like electrons and photons, or muons
* As a general rule, one can say that electromagneticshowers are short, slim and regular
* Hadronic showers are penetrating,wide, and irregular
* Because of the different characteristicsof electromagnetic and hadronic showers, they are often two calorimeters,a fine grain electromagnetic one and a coarser hadron calorimeter
* But it is the synergy betweendifferent detector types that allows to both identify particles andmeasure their direction and energy
* This is further explainedin optional video 3.10a, which shows how the ATLASdetector at LHC works
* In the next video, we will show whichtypes of particle detectors are developed and produced in our laboratoriesat the University of Geneva
* [MUSIC]


--- SKIP ---: 02_3-10a-particle-detection-with-atlas-optional.en.srt


--- SKIP ---: 02_3-10a-particle-detection-with-atlas-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_3-10a-particle-detection-with-atlas-optional.en_SENTbySENT.txt
* [MUSIC]
* In a 27 kilometer long tunnel burieddeep underground at the CERN laboratory, the seven story high ATLAS detectoris designed to enable scientists to study the conditionsof the early universe
* In this episode,we will see how ATLAS works
* The detector consists of many components
* These are needed to measure the differenttypes of particles produced in the collision which thenpass through ATLAS
* [MUSIC] The intersections measurethe tracks of charged particles, which are bent by the magnetic field ofa thin superconducting solenoidal magnet
* Outside of all of theseare two calorimeter devices, measuring the energies of particles
* [MUSIC] Finally, the muon spectrometermeasures the tracks of muons, which are bent in the field ofthe superconducting toroidal magnets
* [MUSIC] Here's how ATLAS detectsdifferent types of particles
* An electron will plow through the innerdetector, leaving a track behind before finally stopping inthe electromagnetic calorimeter
* A photon behaves in a similar way,but leaves no track
* A proton leaves a track and interactsprimarily in the hadronic calorimeter
* [MUSIC] A neutron behaves in a similar way,but leaves no track
* [MUSIC] A muon passes all the way through ATLAS,leaving tracks behind
* [MUSIC] Finally, a neutrino passes throughATLAS without being detected at all
* [MUSIC] Billions of subatomic particles calledprotons advance towards each other from opposite directions atalmost the speed of light
* [SOUND] As two protons collide,hundreds of new particles are formed fromthe energy of the collision
* These collisions occura billion times a second
* [MUSIC]


--- SKIP ---: 01_3-11-particle-detectors-at-dpnc-optional.en.srt


--- SKIP ---: 01_3-11-particle-detectors-at-dpnc-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_3-11-particle-detectors-at-dpnc-optional.en_SENTbySENT.txt
* [MUSIC] In this video, I will give you a little insight into how one uses the particle detectors which we have introduced in Module 3 to detect charged particles and light
* At the end of this video you will know how one integrates semiconductor sensors into so-called particle trackers, which reconstruct the trajectory of particles, and how one uses light detection techniques to detect particles using scintillators
* We have already introduced the principles of particle detection by semiconductor detectors in video 3.8, and by scintillators in video 3.9
* So, to my right, you see two applications of semiconductor detectors, on top for the ATLAS experiment of the LHC at CERN, and below by the space experiment AMS installed on the International Space Station
* Let us start by the top set-up
* You see here a part of the ATLAS forward detector and the particles enter this part of the detector in roughly this direction
* They are localised by these silicon microstrip detectors, which you see on my left
* There are in fact two superimposed detectors, glued to each other
* They make a small angle, which permits, even by a detector with single sided read out, to localise the particles in three dimensions
* You see on the bottom of each detector a small electronics card, directly connected to the detector, which shapes the signal and, when a trigger arrives, transmits it, in this case an optical signal, through this slim optical fibre coming out
* You also see this piping behind, which is part of the detector infrastructure, and which transports a cooling liquid, absorbing the heat and stabilising the temperature of detector and electronics
* The second line of particle detectors, which we very actively follow here at the Department of Nuclear and Particle Physics of the University of Geneva,are scintillation detectors, which we have already introduced in video 3.9
* So, here you see the classical way of constructing a scintillation detector
* You take a scintillating material, you connect it via a light guide to a photomultiplier
* In the past, in the 1970-80Р Р†Р вЂљРІвЂћСћs, these were vacuum tubes, very bulky and heavy
* And here you see the direction which is being followed today
* On can produce scintillating fibres, very fine ones, which can be connected to a very small light detector like this one, which allows at the same time to localise particles ant to measure their specific energy loss dE/dx, as we have explained in video 3.9
* Once integrated, the set-up looks roughly like this, you see a fine layer of scintillators directly coupled to a semiconductor light detector, which localises light emission and measures its intensity, produced by the passage of the particle
* With this one can also construct particle tracking detectors, which are light, deformable and can be adjusted to practically any detector shape since the whole stays flexible and can be made to made to follow almost any desired form
* With this, you have seen two of our specialties in the development of novel particle detectors
* But we do not stop here
* The direction we follow for semiconductor sensors goes towards pixel detectors, which allow, in the same sensor, to directly localise particles in two directions
* They also present an improvement in resolution, which is rather impressive
* You see here a sensor, which localises particles to about ten micrometers
* I remind you that the diameter of a human hair is about 100 micrometers, i.e
* the sensor localisation is 10 times more precise
* [MUSIC]


--- SKIP ---: 01_4-1-reminder-describing-particle-interactions.en.srt


--- SKIP ---: 01_4-1-reminder-describing-particle-interactions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_4-1-reminder-describing-particle-interactions.en_SENTbySENT.txt
* [MUSIC] Hello, and welcome to this fourth module of our introductory course on subatomic physics
* This module starts a series of threemodules, where we talk about the three fundamental forces described by the standardmodel of particles physics
* During this first module,we go into more details about the electromagnetic interactions andtheir properties
* You will notice thatthe intellectual challenge, and also the mathematical levels is slightlyhigher than in previews modules
* But in this first video,we will remind you how to describe the intensity of the reaction using thecross section and the decay rate, so that you are up to speedwith the rest of the course
* After following this video, you will knowthe relation between the reaction rate and the cross section
* Also, the relation between the decay rate,and the lifetime of a particle
* And how the probability amplitude fora process enters into all these notions
* So, we now resume our discussionof scattering and decay processes
* To characterize these processes, we needa quantity which measures the intensity of a reaction or, in the context ofquantum mechanics, its probability
* This quantity is the cross section sigmathat we introduced in video 1.3 for scattering processes, and it's analog fordecays, which is called the decay rate
* Both quantities measure the ratioof the number of scatters or decays, that actually take place, tothe number that would have been possible, that could have taken place
* If this were a game, we would speakof this probability as the ratio between the successes andthe trials of the game
* We have already seen that the unit forthe cross section is a bit surprising, it is a surface
* We will see that forthe decay rate, it is an energy
* This is due to using the system of naturalunits that we have introduced in video 1.2a
* If you are still somewhat uneasy withthe construction an interpretation of Feynman diagrams, like the onesthat you see behind me, Р Р†Р вЂљРІР‚Сљ on the left for a scattering process on the right for a decay process Р Р†Р вЂљРІР‚Сљ you should follow the optional video 4.1a
* As quantum physics takesa statistical approach, the basic problem of particlephysics is the measurement and calculation of the probability fora process
* Both calculation andmeasurement use the cross section to express this probabilityindependently of experimental details
* We consider here a four-bodyreaction a + b -> c + d
* If each target particle bhas a cross section sigma, which represents the probability to hitit, the rate of scatters per second will be proportional to the incident flux ofprojectiles and the number of targets
* The cross action is thus defined asthe reaction rate per target particle, normalized to the flux of projectiles
* It represents the intensity of a reactionindependent of exponential parameters
* The proportionality factorbetween the cross section and the rate of interactionis called luminosity
* The laboratory frame,the flux of project ions I_a, that is to say their number per unit surfaceand per unit time is equal to their volume density times their velocity relative to the targets b,which are at rest
* The luminosity L is the product of thisflux, and the number of targets N_b
* In a colliding beam experiment on thecountry, the luminosity is the product of the number of projectiles and targetsper bunch, N_a and N_b, multiplied by the crossing frequency f and divided bythe surface, that is common to the two beams
* The unit of the cross section is the barn
* In high energy reactions, we rather find cross section ofthe order of the nanobarn, or even picobarn
* The smallest known cross sectionsare those of neutrinos, of the order of attobarn
* As far as decays are concerned,the description is quite similar
* There's of course no projectiles, so we only considerthe particles b in the initial state
* We normalize the number of decaysper second to their current number N_b, to find the decay rate Gamma
* It is the inverse of the lifetime tau_b
* The decay rate Gamma hasthe dimension of an energy
* It is also calledthe width of the particle, because it corresponds to the uncertaintyin the mass of b particles
* Therefore, it can be measured eitherby measuring the lifetime of the particle, or by observing the width of the invariantmass distribution of its decay products
* As the decay rate is a constant,we find an exponential law for the number of remainingparticles at time t
* Consequentially, also, the absolute number of decay in timeinterval Р Р†РІвЂљВ¬РІР‚В t decreases exponentially
* If several decay channels exist, the lifetimeobserved in each channel is of course the same, butthe decay rate depends on the channel
* One thus defines a partial decayrate Gamma_i, for each channel i
* By probability conservation the sumis equal to the total width Gamma
* The branching ratio Gamma_i/Gamma expresses the relative probability of observingchannel i, among all decay channels
* Analogous to the differentialcross section, one can also measurethe differential decay rate, dGamma/dOmega,depending on the solid angle
* Let us think for a moment
* If, for a decay with multiple decaychannels, we only observe one channel i
* Is the time evolution determined by Gamma,or is it determined by Gamma_i
* Well, it is, of course,determined by Gamma
* Since the lifetime of the particleis independent of the decay channel, that it will choose
* In the next video,we will apply the concept of cross section to elementaryelectromagnetic interactions
* [MUSIC]


--- SKIP ---: 02_4-1a-how-to-construct-a-feynman-diagram-optional.en.srt


--- SKIP ---: 02_4-1a-how-to-construct-a-feynman-diagram-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_4-1a-how-to-construct-a-feynman-diagram-optional.en_SENTbySENT.txt
* [MUSIC] In this video we will give you a few hintson how to construct a Feynman diagram for the two-body process a+b -> c+d
* We first have to decide wether this can be an annihilation process in which the two initial state particlesannihilate into a gauge boson
* In that case the momentum transfer will be equal to the total energy-momentum
* If they cannot annihilate, they have to exchange a gauge boson in a scattering process
* In this case the q^2 is equal to the difference between the final particle momentum and the initial particle momentum.Now we must decide, which gauge boson can be exchanged
* First of all we have to remember that at each vertexquantum numbers are strictly conserved
* First of all baryon and lepton numbers must be conserved, and, if we are not talking about weak interactions, also the particle flavor
* Then we must consider the charge at each vertex
* If the electric charge is not 0 and it does not change at the vertex,we can exchange a photon
* If the particleР Р†Р вЂљРІвЂћСћs weak isospin is not 0 and the charge does not change, we can exchange a Z
* If the charge does change by Р вЂ™Р’В±1 unit, we can exchange a WР вЂ™Р’В±
* Finally, if the color is not 0 and it changes at the vertex,we can exchange a gluon
* So here is a first example, the process e+e- -> u ubar
* We clearly cannot couple the electron directly to a u quark so this is an annihilation process in which the e+ e- annihilate into a u bar pair
* This can proceed via the exchange of a photon or a Z, since both the electron and the u quark carry both electric and weak isospin charge
* It cannot go via the exchange of a gluon or a W because the e+ e- does not carry color and the charge does not change at the vertex
* A second example is the process e+ e- -> nu unbar
* Unless the neutrinos are electron-type neutrinos, this is again an annihilation process
* It proceeds via the exchange of a Z boson
* It cannot proceed via photon exchange, because the neutrino does not carry electric charge
* Neither the electron nor the neutrino are colored, so gluons cannot be exchanged
* The electric charge is not changing at the vertex, so WР вЂ™Р’В± exchange is also excluded
* The third example is the process e- u -> nu_e d
* In this case it must be a scattering process,since the e- cannot directly couple to the u quark
* They must in fact exchange a W boson since the charge changes by 1 unit at each vertex
* This is possible because both the e- and the u quark carry weak isospin
* They cannot exchange a photon since the charge changes neither can they exchange a Z
* And since the e- and the nu do not carry color, they cannot exchange a gluon either
* The next example is the decay of a d quark into a u e- and an electron-antineutrino
* To conserve baryon and lepton number we must connect the d quark to the u quark and the electron to the antineutrino
* This means that at each vertex, the charge changes by 1 unit and we can exchange a W boson
* We cannot exchange a photon because the charge changes, likewise we cannot exchange a Z
* And since the e- and the nu donР Р†Р вЂљРІвЂћСћt carry color we cannot exchange a gluon
* The last example is a red d quark scattering off a blue d quark, giving a blue u quark and a red d quark
* This is clearly a strong process since it involves color exchange
* Since strong interactions conserve flavor, we must connect the two u quarks and also the two d quarks
* That means that the two vertices are connected by a gluon of red-antiblue color such that the color is conserved at each vertex
* We cannot exchange a photon since the color changes, neither a Z or a W bosons since all of these cannot change the color of a particle
* [MUSIC]


--- SKIP ---: 01_4-2-electromagnetic-scattering.en.srt


--- SKIP ---: 01_4-2-electromagnetic-scattering.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_4-2-electromagnetic-scattering.en_SENTbySENT.txt
* [MUSIC] During this fourth modulewe're going into more details on the properties ofelectromagnetic interactions
* In this second video, electromagneticscattering is analyzed in terms of invariant amplitudes and cross section
* After following this video youwill know Fermi's Golden Rule
* The scattering amplitude of a particlein an electromagnetic potential, how the target particlegenerates this potential and the difference between distinguishable andundistinguishable processes
* In the previous video we have seen how thecross section for a scattering process is measured by normalizing the reactionrate by the luminosity
* For one incoming projectileon a single target particle, the cross-section isalso calculable quantity
* The main ingredient is, again, the probability that both interact byexchanging an intermediate gauge boson
* This probability, or rather its amplitude, is calculable in a quantum fieldtheory based on a gauge principle
* One can thus compare experiment andtheory in good precision for both
* Such comparison can test the theory and determine is parameters like masses andcoupling constants
* The prescription for the calculation of a cross-sectionis called Fermi's Golden Rule
* In scattering theorythe reaction rate, W, is given as the product between|M|^2 times Q, with invariant scattering amplitude M andthe density of final state Q
* The latter is also calledthe phase space factor
* It takes into account the numberof states, in the quantum sense, that the final state can contain
* The more there are, the more probable the reaction becomes
* For a four body reaction a + b -> c + d, the amplitude M can be interpretedas the probability amplitude of the process that converts the initialstates into the final state
* It is therefore a probability amplitudein the same sense as the wave function, and its square is a probability density
* To obtain the cross section we still have to normalize by the fluxof incident projectiles
* This may seem surprising fora single projectile, but the flux is the number of projectilesper second and per unit surface
* Here is then Fermi's Golden Rule forcross sections
* It is obtained by properly normalizingthe probability of the reaction, and contains both this probability|M|^2, the incoming flux F, and the phase space factor Q
* The incident flux for the initial statedepends on the relative velocity, the modulus of (v_a- v_b), and the volume density of projectile andtarget
* This volume density must beproportional to the energy of the two particles to berelatively equally invariant
* In our normalization, it is simplyequal to twice the energy for a single particle per unit volume
* The second equation is valid forthe two velocities, v_a and v_b, parallel
* and clearly shows the invariance of the fluxfactor under Lorentz transformations
* The phase space factor, dQ, takes into account the number of stateswhich can be realized by the final state
* It contains a delta function that ensuresthe conservation of the energy-momentum, as well as the number of quantum statesfor all the particles in the final state
* The factors of twice the energies, again, come from the way we normalizethe wave functions
* How does one proceed to calculatethe invariant amplitude
* We will outline the argument forthis simple case of scalar fields
* We mentioned that to first orderone local action of the potential V(x) will transform the initial statePhi_a into the final state Phi_c
* The probability amplitude of this process,ignoring the normalization factors for the moment, is given by this integral
* The argument of the integral isthe probability of finding the state Phi_c at position x at the time t among all states produced by the potentialV from the initial state of Phi_a
* The integration over space-timereflects the fact that this local interaction can occur whereverthe potential is present
* To help your intuition, imaginethat the two wave functions Phi_a and Phi_c correspond to free particleseverywhere, except at the place and time where the potential intervenes
* The initial state Phi_a willbe a superposition of eigenstates of the free Hamiltonial witha given set of coefficients
* The potential will change these coefficientsto produce another superposition of eigenstates with a differentset of coefficients
* The amplitude M is thenjust the amplitude of the final state Phi_c,which contains the new mixture
* The invariant amplitude M containsall the dynamics of a reaction, Thus the whole physics of the typeof interaction under study
* It therefore follows fromthe potential operator V
* This is the same operator which changesthe homogenous equation of motion into an inhomogenous ones
* For electromagnetic interactions, the inhomogeneous equation is derivedfrom the Klein-Gordon equation by the so-called minimal substitution
* To struct thispotential will neglect terms proportional to e^2 which is verymuch smaller than one
* The invariant amplitude is then given byan integral over the product of the four-potential of the target, and the current density j_Р вЂ™Р’Вµ ofthe projectile
* The invariant amplitude ofelectromagnetic scattering off a fixed target is thus the integral overthe product between the transition current of the projectile and the electromagneticpotential of the target
* Note that this is a local interaction
* Current and potential are definedat the same point in space-time
* But this point may be anywhere
* Thus an integral over space-timegives us the total amplitude
* The electromagnetic current densityat work here looks like that for a free particle, except that the fields in the initial and final states are not the samesince there was an interaction
* So the electromagnetic current densityinteracts locally with the potential A^Р вЂ™Р’Вµ, which we identify with the photon field
* It remains to be understood howthis potential is generated
* That is, how the photon is produced
* For electromagnetic interaction,the Maxwell equations tell us how the electromagnetic fieldsare produced by charges and currents
* Let us start by writing downthe homogeneous Maxwell equations in four-vector form, using the electromagneticfield tensor F^munu
* Translating into equations for the potential this gives four differentialequations for the four-potential A^nu
* Using the invariance of the potential under the gauge transformations withan arbitrary scalar field xi(x), we can always rearrange things sothat a A^Р вЂ™Р’Вµ has no divergence
* We call this arrangement the Lorenz gauge
* In this gauge the homogeneous Maxwellequations are nothing else than four Klein-Gordon equations forthe components of the potential
* But only three componentsare independent of each other because of the gauge condition
* This justifies that we considerthe homogeneous Maxwell equations as the equation of motion forthe photon, which is a vector boson and thus has three independent components
* In the presence of a current,the equations become inhomogeneous
* There is a source j_Р вЂ™Р’Вµ, on the right
* We construct j_Р вЂ™Р’Вµ from the wavefunction of the two other partners in the reaction,the target particle b and its final state d
* Their transition currentis the source of the field
* The potential A_Р вЂ™Р’Вµ that corresponds to thissituation is proportional to this current density and inversely proportion tothe square of the transfered momentum q
* The invariant amplitude thus correspondsto the interaction between two currents
* The intervening factor 1/q^2is called the photon propagator
* It described the probabilityamplitude that a photon with four-momentum q is exchangedbetween the two currents
* Since each current density brings ina factor of e as a calling constant the amplitude is proportionalto e^2/q^2
* This process can be represented bya feynman diagram as shown in this slide
* These diagrams describe elementaryprocesses in a manner that is both elegant and intuitive
* If the construction of the Feynman diagramfor a given process is still a problem for you, please go back tothe optional video 4.1a
* At the same time Feynmandiagrams are a prescription for the corresponding invariant amplitude
* The vertices are characterizedby coupling constant, the electric charge in the caseof electromagnetic interactions, and an operator which describesthe properties of the interactions
* The lines correspond to the propagators of particles, real ones for external lines,virtual ones for internal lines connecting two vertices
* The propagator 1/q^2 wefound for the photon is a special case for the more general one, which is 1/(q^2 minus the square of the mass) for massive intermediate vector bosons
* If more than one elementary processcan cause a reaction we must either add the amplitudes orthe cross-sections
* Because of the quantum nature ofthe processes there exist two cases
* If initial and final states ofthe processes are indistinguishable, one must add the amplitudes
* If there is an observable,which allows in principle to distinguish different contributions, no matter ifit is actually measured or not, these processes are distinguishable andone must then sum the cross sections
* The first case occurs of course forexample if one considers two contribution of different ordersin the coupling constant
* The exchange of one of two photonscan intervene between the same initial final state as shownin the picture in the left
* If the two amplitudes M_1, M_2 describethe two contributions, the square of the total amplitude, which leadsto the cross section, is then |M_1|^2 + |M_2|^2 + 2M_1M_2
* is then |M_1|^2 + |M_2|^2 + 2M_1M_2
* So this last term is aninterference term with appears in the probability
* This is precisely not the case ifthe processes are distinguishable in principle
* Take the example of differentspin directions of the particles that interact
* These are observable in principle
* As in the example shown in the right, an unpolarized initialstate corresponds to a mixture of all possible spin orientationsin equal proportion
* We must therefore averagethe cross-section or the squared amplitude over the spindirection of the initial particles to calculate the cross-section foran unpolarized initial state
* If one does not distinguishthe polarization of particles in the final state either, one mustsum the cross-section corresponding to the spin direction ofthe final state particles
* The square of the amplitude resulting fromboth operations, averaging over initial spin andsumming over final spin, is denoted by |M|^2-bar
* In the next video we'll discuss fermionspin and its consequences in more depth
* [MUSIC]


--- SKIP ---: 01_4-3-spin-and-magnetic-moment.en.srt


--- SKIP ---: 01_4-3-spin-and-magnetic-moment.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_4-3-spin-and-magnetic-moment.en_SENTbySENT.txt
* [MUSIC] During this fourth module, we go into details about the propertiesof electromagnetic interaction
* In this third video,we discussed the phenomenon of spin and its consequences forelectromagnetic interactions
* After following this video, you will knowspin as a typical quantum observable, and its measurable consequences and thefunctional principle of a Penning trap
* We have seen in video 1.1 thatthe matter particles known up to now are all fermions with spin one-half
* And the particles carrying theforces are spin one bosons
* The only elementary scalar bosonobserved to date is the Higgs boson
* It is therefore inevitable that wediscuss date spin in more depths
* We will not do thatwith a formal approach, instead we discuss onlythe consequences of spin
* Spin is a typical quantum observablewhich has no classical equivalent
* It is an intrinsic degree of freedomcorresponding to an angular momentum manifesting itself by a magnetic moment
* There's no movement associated to eitherof these moments, let alone a rotation
* This is evident because spin isa property of pointlike particles
* We will nevertheless use a classicalanalogy laid out on this slide
* For a particle with charge q and mass m,the magnetic moment Р вЂ™Р’Вµ is related to the angular momentum L byР вЂ™Р’Вµ = q/(2m) L
* This is easy to see fora particle traveling on a circle of radius r
* Its magnetic moment is the product ofthe current caused by the motion and the surface included in the path
* The current can be expressed usingcharge and angular velocity, the magnetic moment is thusproportionate to the angular momentum
* The proportionality factor issimply q/(2m)
* It is plausible thatan intrinsic angular momentum would cause an analogous magnetic moment
* A new proportionality constant comes in,it is called the gyromagnetic ratio g
* It's value depends on the internalstructure of the particle
* For a pointlike fermion,such as the electron, muon or tau, the spin is one-half,the charge is -e, so Р вЂ™Р’Вµ is equal to -ge/(4m)
* A QED calculation to first ordergives g simply equal to two
* The classical experiment to measureg uses an electron trapped in an electromagnetic bottlecalled a Penning Trap
* A very good description is availablein the article by Ekstrom and Wineland, in Scientific American,that is quoted on the bottom of this page
* The system resembles a macroscopic atom where the nucleus isreplaced by an external field
* The electron circulatesin a magnetic field which is pretty much homogeneous exceptfor the focusing component generated by a ferromagnetic nickelring in the equatorial plane
* An electric field counteracts excursionsalong the axis of the magnetic field
* It is generated by a ring electrode andtwo cap electrodes
* We calculate the energy levelsof such a system in video 4.3a
* The result which is given here,neglecting the focusing effects of the ring the caps, is relatively simple
* The first term in blue corresponds toa free movement in the z direction
* This movement is constraint bythe focusing components we have neglected
* And they caused the axial oscillation
* The two terms in red correspond toharmonic oscillator in the equatorial plane with energyeigenvalues which are omega times (n+1/2) forn equal to zero, one, two and so on
* Adding the magnetic moment of the spin Р вЂ™Р’Вµ_s,the last term in green is obtained
* The two directions of spin, s_z equal plus one-half and minus one-half, are therefore separatedby the same energy difference omega as the main levels, provided thatg is exactly equal to two
* The energy levels for spin parallel and anti-parallel to z would then bedisplaced by exactly one step omega
* This degeneracy does not exist ifthe value of g differs from two
* The levels are then slightly displacedby a frequency shift delta omega equal to omega times (g-2)/2, which can be measured with impressiveaccuracy using a Penning trap
* The principle of the measurement isshown here by its electrical analogue
* In an empty trap, the threeelectrodes form a capacitance network that transmits the AC signal generatedon top to the detector on the bottom
* The trapped electron introducesan additional capacitance-inductance in the circuit
* The amplitude of the transmitting signalas a function of frequency thus indicates the number of electrons in the device
* And the frequency shift deltaomega which determines the deviation of g from two
* The figure on the left shows the detectedsignal as a function of time at the well adjusted frequency
* Each major step corresponds tothe loss of one electron in the trap
* The right figure shows the frequency shiftdelta omega as a function of time
* It's too minima indicatethe two directions of spin
* Also indicated are the much largershifts due to a change in orbit
* The precidion of the experimentalresult is amazing
* You see the value obtained inblue on the bottom of the page
* The value in bracket indicatesthe measurement error which applies to the 13th and14th decimal places
* Comparison of this value toelectromagnetic theory requires a calculation of the same quantity to10th order in the pertubation expansion
* One finds good agreementbetween measurement and theory even at this unrivalled precision
* The measurement also gives us one of themost precise values of the fine structure constant alpha equals e^2/(4Р СџР вЂљ)
* In the next video, Mercedeswill discuss Compton scattering, the elastic scattering ofa photon off an electron
* [SOUND]


--- SKIP ---: 02_4-3a-motion-in-a-penning-trap.en.srt


--- SKIP ---: 02_4-3a-motion-in-a-penning-trap.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_4-3a-motion-in-a-penning-trap.en_SENTbySENT.txt
* [MUSIC] We will calculate the motion ofelectrons in a Penning trap like the one shown in this small sketch
* For the moment we will neglectthe influence of the slight inhomogeneity of the magnetic fieldcaused by the nickel ring, and the electric field of the cap electodes
* If B points in the z direction itfollows from a vector potential equal to (-By,0,0)
* So the Hamiltonian of such a systemusing minimal substitution is 1/(2m) (p - eA)^2
* So with a bit of trivial mathematics,we find 1/(2m)(p + 2m omega y p_x + m^2 omega^2 y^2)
* If you write this in terms ofCartesian components of the momentum, we find that all the terms proportionalto p_x can be joined together and the remaining term is p_z^2/(2m),which corresponds to a uniform motion in this z direction, which in reality,will be limited by the cap electrodes
* The other two terms correspond to aharmonic oscillation in the x-y plane
* The energy levels forthis oscillation are equal to omega(n+1/2) with n a whole number, 0,1, 2, and so on
* We now take into accounta spin of the electron
* The Hamiltonian acquires a termР вЂ™Р’Вµ_s B where Р вЂ™Р’Вµ_s is the magnetic moment of the electron andB is the magnetic field vector
* So this gives an additional splittingby plus or minus g_e (eB)/(4m)
* This last term is g/4 times the samefrequency which we had found earlier
* The energies correspondingto these two spin directions differ from E_n by plus orminus g_e/4 times omega
* This results in a level spacing due tospin of g_e/2 times omega compared to one level spacing by the cyclotronmotion which is Р Р†РІвЂљВ¬РІР‚В E_n = omega
* The difference betweenthese two level spacings directly measures (g_e - 2)/2
* [MUSIC]


--- SKIP ---: 01_4-4-compton-scattering-and-pair-annihilation.en.srt


--- SKIP ---: 01_4-4-compton-scattering-and-pair-annihilation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_4-4-compton-scattering-and-pair-annihilation.en_SENTbySENT.txt
* [MUSIC] During this fourth module,we are going into more details about the properties ofelectromagnetic interactions
* In this fourth video, we describe Comptonscattering, which we already encountered in module 3 when we discussedthe interaction of photons and matter
* After following this video, you will be able to characterizeCompton scattering, which is the elastic scatteringbetween a photon and an electron
* Describe how the polarization ofthe photon influences the process, and understand why theannihilation of electron- positron pairs into photonshas similar properties
* We have not yet discussed that vectorbosons, which carry forces, can also appear as real particles, andmatter particles as virtual ones
* Compton scattering, elastic scatteringbetween a photon and an electron, involves a virtual intermediate electron,as shown in this Feynman diagram
* The kinematics of the process ischaracterized by the energy omega of the incident photon andthe scattering angle theta, the angle between k and k prime,which are the four-momenta of the incidence photon andthe outgoing photon, respectively
* The conservation of energy-momentumreduces the energy, omega prime, of the outgoing photon comparedto that of the incident one, omega, if the reaction occurson an electron at rest
* The reduction depends on the scatteringangle theta and the photon energy itself
* The figure gives an exampleof this relationship for a source of Am-241,which emits photon with omega = 59.54 keV
* Because of Heisenberg's principle,we can in fact, not know whether the photon inthe final state is emitted after or before the absorptionof the incident photon
* So there are two configurationsof the Feynman diagram which are indistinguishable
* The processes caninterfere with one another
* To calculate the cross section,we must then add the amplitudes and square the result,as we explained in video 4.2
* For the differencial across cross-section, one finds the so-called Klein-Nishina formula
* Two factors are of particular interest
* The first is the factor alpha squared, which determines the order ofmagnitude of the cross section
* It result from the fact thateach vertex introduces a factor of e when constructingthe invariant amplitude M
* Consequently, the cross-section, which isproportional to |M|^2, which is proportionalto the fourth power of e, is proportional to the square ofthe fine structure constant alpha
* The second interesting factor involvesthe product of two four vector of photon polarization, epsilon andepsilon prime
* These appear as the amplitude inthe wave function of the free photon, which is the solution ofthe homogeneous Maxwell equations
* Under the Lorenz gauge,these equations of motion constrain epsilon such that k^2 = 0, which is the condition for a real photon
* The gauge condition, Р Р†РІвЂљВ¬РІР‚С™_Р вЂ™Р’Вµ A^Р вЂ™Р’Вµ = 0, means that epsilon^Р вЂ™Р’Вµ k_Р вЂ™Р’Вµ = 0
* The four-vector of polarizationepsilon, indicating the electric field direction, is thus orthogonal to thefour-momentum of the free photon k
* In addition,this gauge condition shows that the photon will function as only threeindependent components, not four
* It is therefore justified to callthe photon a vector particle
* When the polarization ofthe initial state is 0, and that of the final state is not measured,we must average the cross-section over the direction of the initial spins,and sum over those of the final state
* This must be done at the level ofthe cross-sections, not of the amplitudes, because the spin is an observable, making the contributions distinguishableas we discussed in video 4.2
* For the factor containing the polarizationthis results in a distribution (1 + cos^2 theta) of the scattering angle theta betweenthe incoming and outgoing photons
* At high photon energy omega much largerthan m, the total cross-section is roughly inversely proportional tothe square s of the total initial energy
* This is a property shared by allscattering processes between point-like particles
* Their cross-section decreaseswith the square of the energy scale, which characterizes the process
* Obviously, the square of the finestructure constant alpha, again determines the order ofmagnitude of the cross section
* Compton scattering can be measured at high energies using the Large Electron- Positron collider, LEP, at CERN, which operated during the 80s and 90s
* The incident photon beam is generated by the incomingelectrons via the bremsstrahlung mechanism
* An accelerated charge tends to emit photons
* Here the acceleration is caused bythe electromagnetic force coming from the particles in the other beam
* The electron or positron emits a photonin its original direction of motion
* The photon interacts with a positron orelectron n the other beam,via Compton scattering
* The outgoing electron andphoton are observed in the detector
* As the initial photonconnects two vertices it is a virtual photon with k^2different from 0
* Our treatment of the Comptoneffect applies to real photons with a k^2 = 0
* To apply it to this case,we select events for which the mass of the initialphoton is negligible compared to the characteristic energy, that is tosay k^2 << s
* The cross-section forCompton scattering with this quasi real photons measured by the experiment L3 at LEP is shown on the right
* The dependence on the initialenergy square root of s predicted by the calculation is in factobserved
* It is proportional to 1/s
* Rotating the Compton scatteringFeynman diagram by 90 degrees, one obtains another process
* The annihilation of an electron-positron pair into a pair of photons
* Notice that we also convertthe outgoing electron of the Compton process intoan incoming positron
* This remains without consequencebecause these two states are completely equivalent
* We will come back to that inthe beginning of module 6 when we discuss antiparticlesin more details
* With the appropriate changesin the kinematic variables, we can convert to the Compton scatteringresult directly into the cross-section for pair annihilation in the center ofmass frame and neglecting masses, for s much larger thanthe square of the electron mass
* Note again the characteristic factor,alpha squared, which comes from the coupling constants,and 1/s, which characterizes the square ofthe energy available in the process
* We have chosen the center of massframe where the electron and positron collide with equal andopposite momenta
* The photons are therefore also emittedwith equal and opposite momenta
* The scattering angle theta is the angle between the incomingelectron and the outgoing photons
* It is obvious that the angulardistribution is symmetric under theta going to theta plus Р СџР вЂљ
* The factor (1 - cos^2 theta) inthe denominator can come as a surprise, because it makes the cross section divergewhen the scattering angle approaches 0 or 180 degrees.Such divergence is not admissible
* The cross action that represent theprobability must always respect the upper limit of unitarity correspondingto a probability of 1 for the process
* Already the factor 1/slooks suspicious, but the dangerous limit, s -> 0, cannotbe reached because of the threshold s > 4 m_e^2
* The angular divergence onthe other hand is real
* It is finally not realized, because ofhigher order corrections which cancel it
* In fact, the perturbative expansionby orders of a small coupling constant, always ends up convergingin a quantum field theory based on the principlesof gauge invariance
* The demonstration of this fact hasbeen rewarded by Nobel Prize in 1999 for tР Р†Р вЂљРІвЂћСћHooft and Veltman
* In fact, the cross sectionis always really a finite quantity
* The figure shows the results of themeasurement by the L3 experiment at LEP
* The cross section follows with greatprecision in absolute magnitude and in energy dependence,the prediction of quantum electrodynamics
* In the next video,we give an example of an electromagnetic interactionbetween four fermions, e+ e- annihilation intoa fermion-antifermion pair
* [MUSIC]


--- SKIP ---: 01_4-5-electron-positron-annihilation.en.srt


--- SKIP ---: 01_4-5-electron-positron-annihilation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_4-5-electron-positron-annihilation.en_SENTbySENT.txt
* [MUSIC] In this fourth module, we are in theprocess of discussing the properties of electromagnetic interactions
* And in this fifth video,we discuss the annihilation of electron-positron pairsinto pairs of fermions
* After following this video, you will knowthe main properties of the process of e+ e- annihilation into lepton pairs, and also the peculiarities of theirannihilation into hadrons
* The annihilation of electron-positronpairs into pairs of photons that Mercedes has introduced int the previous videois not the only annihilation reaction
* There's a whole class of reactionsof electron-positron annihilation into fermion-antifermion pairs andthe example is shown here
* We do not include the reactione+ e- -> e+ e-, which is complicated by a secondscattering diagram where the two electrons exchange a photon rather than annihilate
* Let us take the creation ofpairs of muons as a prototype
* In the center-of-mass frame the finalstate is characterized by two muons with equal and opposite momentum
* Having no strong interactions and being too heavy to causeelectromagnetic showers, muons penetrate all the material in thedetector, just losing energy by dE/dx
* The total cross section again exhibitsthe well known factors, alpha squared in the nominator and s, the square of thecharacteristic energy, in the denominator
* These are the characteristic factors for electromagnetic reactionsbetween point-like particles
* The cross section for tau production,e+ e- -> tau+ tau-, is the same, far from threshold, that is to say,at s, much larger than m_tau^2
* The differential cross section issymmetric with respect to the sign of the scattering angle theta,if one neglects the masses, s >> 4 m_Р вЂ™Р’Вµ^2
* The figure shows the angular distributionat high energy, the dashed lines indicate the shape of the symmetric distributionpredicted by quantum electrodynamics
* The solid lines include an asymmetric termthat comes from electro-weak interference
* The angular distribution in factshows a deviation from symmetry that increases with energy
* It is due to the interferencewith weak interactions that we will treat in module 6
* This prototype cross-section applies toall annihilation reactions which produce a fermion pair of negligible mass andcharge Р вЂ™Р’В±e
* The coupling constant is hiddenin the fine structure constant, alpha = e^2/(4Р СџР вЂљ)
* Again, an identical angular distributionis observed for the reaction e+ e -> tau+ tau- at energies much largerthan the threshold for this reaction
* Let us now turn to pair productionof quarks, or rather quark-antiquark pairs by e+ e- annihilation
* Here we must considertwo important changes
* First, quarks carry electric charge,either +2/3 for u, c and t quarks or-1/3 for d, s, and b quarks,relative to the elementary charge e
* As the quark charge comes in atonly one of the two vertices, we must introduce a factor Q_i^2 inthe cross section for each quark type i
* Second, quarks are produced withthree color charges, red, green or blue, charges that are responsible forthe strong interactions but to which electromagneticinteractions are insensitive
* The color of quarks is another example ofthe property of the final state which is observable only in principle
* We have no way to measure it, but it distinguishes nevertheless final statescorresponding to different colors
* We must therefore add the amplitudessquared or the cross-sections
* These are obviously independent of color,and for each flavor we obtain a cross-section which dependsonly on the electric charge, but is three times larger thanif the object had no color
* The mass of quarks is negligible for u,d, and s, but not for the heavy quarks c, b, and especially t
* For them, their production thresholds,as indicated on the bottom of the slide, in the inclusive cross sectione+ e- -> q qbar, there are steps at these thresholds
* Quarks in the final state are notobserved as such, because of their strong interaction which startsacting as soon as they are produced
* The color field that is establishedbetween them is so energetic that additional quark-antiquark pairs spontaneously pop-up and cluster around the primordialquark as hadronic jets
* You see an example in this picturefrom the L3 experiment at LEP
* The jets follow the initialdirection of the quark
* Their total energy is that of the quarks
* The multiplicity of charged andneutral particles inside each jet is high
* Each quark forms at least onejet such that the event contains at least two of them
* We will come back to the jet phenomenonin module 5 when we discuss strong interactions
* Because of the conversionof quarks into hadrons, we cannot necessarilydifferentiate their flavor either
* We consider therefore often the inclusivehadron cross section sigma(e+ e- -> hadrons), which to first order is given bythe sum of the individual cross sections
* This again because in principle,flavor allows to distinguish them
* You may wonder if the conversionof quarks into hadron jets does not change the cross-section
* This is not the casebecause as far as we know, this conversion is always happening,it has probability one
* In other words, the quarks are always, andwithout residues, converted into hadrons
* The cross section thus does not change
* To compensate for the important reduction with the square ofthe energy, proportional to 1/s, of the electron positron cross-section,we often form the ratio R of the hadronic cross-section to that of our referenceprocess, e+ e- -> Р вЂ™Р’Вµ+ Р вЂ™Р’Вµ-
* The sum includes all flavors,as indicated in this equation, that can be produced at the givenenergy in the center of mass frame
* To first order in the differentenergy regions we just obtain simple ratios of whole numbers
* At each threshold there is a step inthe cross section because a new channel opens up
* This figure compares the rough calculationthat we just did to a compilation of experimental results fromthe particle data group
* The data comes from experiments at variouse+ e- colliders, at different energies
* We see the gross features ofthe cross section as predicted, including a small stepat the quark threshold
* But the measured cross sectionare significantly larger than the simple fractions we have just calculated
* This is again due to higherorder contributions
* We will see in the next module thatfinal states with additional gluons add some 10% to the totalinclusive hadron cross-section
* At high energies, above few tens of GeV, we see theinfluence of the weak neutral interaction
* The exchange of its intermediate boson, the Z boson, dominates the totalcross section at these energies, and causes the big peak that yousee on the right of this graph
* We will see much moreof this in module 6
* But before that, in the next modulewe'll discuss strong interactions and hadronic structure
* [MUSIC]


--- SKIP ---: 01_5-1-elastic-electron-nucleon-scattering.en.srt


--- SKIP ---: 01_5-1-elastic-electron-nucleon-scattering.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-1-elastic-electron-nucleon-scattering.en_SENTbySENT.txt
* [MUSIC] Hello, and welcome to this fifth module of ourintroductory course to subatomic physics
* In this module,we'll discuss the structure of hadrons and strong interactions
* In this first video, we discussed the elastic electromagneticscattering between electrons and nucleons, which is one of the ways used tostudy the structure of hadrons
* After following this video, you will know the main properties ofelastic scattering between fermions, and the meaning of the different termsthat enter into the cross section
* The form factor concept you will know, and its interpretation,in terms of the size of the nucleon
* And you will get to know the historic experiments at the StanfordLinear Accelerator Center in this area
* When the structure of an interaction isknown, it can be used as a tool to better understand the particlesthat are involved
* Within this video, how elasticelectron nucleon scattering is used to determine the internalstructure of nucleons
* We take advantage of the fact thatthe electron as far as we know, is a point like particle in that we knowelectromagnetic interactions very well
* We can thus elucidate a single,but important unknown, which is the distribution and the dynamicsof quarks inside the proton and neutron, represented by the big bluedot in the right diagram
* WeР Р†Р вЂљРІвЂћСћll see in video 5.3, also, how meson resonances are formed byan incident photon, for example
* These can be used to better understandthe strong force that binds quarks and anti-quarks together
* The prototype process for the scattering between point likefermions is electron muon scattering
* It is very similar to e+ e- annihilation, with the Feynman diagramrotated by 90 degrees
* We will approach this process in steps
* The first step is already shown here,since we have encountered it in the past
* It is to consider scatteringof a very heavy type target, which is without structure andwithout spin
* Also, ignoring the spin of the incomingelectron, and neglecting its mass, we obtain the formula shown here,the Rutherford cross section, which we already encountered in video 1.4
* As usual, the factor alpha squared comesfrom the two electromagnetic vertices
* The denominator contains the squareof the characteristic energy
* It results from the propagator of thevirtual photon, one over q^2, and you can easily verify this inthe approximation that the mass of the electron is negligible, as I did here
* The angular distributionis extremely steep for the scattering of point like particles,and it peaks at small angles
* This remains valid when includingthe effect of the target recoil, and the spin of the particles
* The additional term in red,shown here with M the mass of the target, takesinto account the recoil
* It is the ratio between the incident and the outgoing electronenergy EР Р†Р вЂљРІвЂћСћ/E
* This ratio is 1 for an infinitelyheavy target, but less than 1 for an important recoil
* This formula still neglects the magneticcomponent of the interaction
* For a point like fermion target with amagnetic moment, Р вЂ™Р’Вµ = e/(2m)
* One finds the complete Mott formulagiven on the bottom of the page, quoted here in the laboratory frame, andfor relativistic electron projectiles
* The last term in red isof a magnetic nature
* It becomes important at highmomentum transfers q^2, much larger than the massof the target squared The angular distribution, still roughlyfollows the form of the Rutherford formula, the third term contains sub-termsproportional to cosine squared theta, and to sine squared theta, which reduce a little the steepnessof the angular distribution
* The historic experiments on elasticscattering between electrons and protons have been conducted at the Stanford LinearAccelerator Center in the 1960s and 1970s
* The experiment consistedof a liquid hydrogen target bombarded by electronsof a few hundred MeV
* In the final state,only the electron is observed, in two spectrometers positionedat variable scattering angles
* The kinematics of the hadronicfinal state is then deduced from energy-momentum conservation,assuming a target at rest
* Here are some results on the cross sectionas a function of the scattering angle on the left, and as a function ofthe incident electron energy on the right
* The measurements confirm the calculationsat these modest energies, already below one GeV
* One observes a steep angulardistribution in the left plot, and a strong reduction of the cross sectionwith energy in the right plot, as we expected from the formulae
* Let us now consider what happens ifthe target is not a point-like particle
* Let us first take the model of a staticcharge distribution rho(x), normalized such that the chargeof the target remains elementary, which means that the integral overrho(x) must be equal to 1
* The cross section then will bereduced with respect to a point-like target by a factor of F^2,a so-called form factor
* We have already used this concept in video2.2, when we discussed the size of nuclei
* In the static case, F is simply the Fourier transformof the spatial charged distribution
* For small momentum transfers, one can develop the form vectorsin powers of q times x
* If the distribution possessspherical symmetry, that is rho(x) is only a function of r,and not of the spatial directions separately,terms with odd exponent will not conribute
* Thus, the form factor measures the meansquare radius of the charge distribution, <r^2>, which representsthe size of the distribution
* Take, for example, an exponentialdistribution as a function of distance
* It leads to the so-called dipolarform factor that is shown in the last formula on the right
* It is clear that in the case ofa non-static charge distribution, things get more complicated
* First, magnetic interactions come in,since the target is moving
* Second, the charge distributionitself changes during the time represented by the time-like componentof the four-momentum transfer q_0
* By the action of the moving chargesinside the distribution, electric and magnetic terms will be modified, andtheir functions will in fact be mixed up
* We then find the cross sectiongiven here with the parameter tau, which is the ratio between the momentumtransfer and the target mass squared, the ratio of the two quantities,which characterize this process
* We call G_E and G_M the electric andmagnetic form factors, although the distinction between the twoobviously depends on the reference frame
* In the same sense, one can attributeG_E and G_M to the Fourier transforms of the charge and magnetic momentdistribution of the target particle, even though this interpretation is,strictly speaking, only valid in a veryspecial reference frame
* The form factors G_E andG_M of the proton are measured by analyzing the differential cross sections forthe reaction e- p -> e- p, and separating the terms proportionalto cosine squared theta and sine squared theta ofthe angular distribution
* We observe that G_E and G_M followthe dipolar shape, predicted for exponential charge distributions
* The parameter Lambda then characterizesthe size of the distribution, and we find Lambda equal to 0.84 GeV,in both cases
* The size of the distribution is thus of order 1 fm and the same for electric andmagnetic form factors
* Finding the same distribution forboth form factors is not a miracle
* The quarks inside the nucleon areat the origin of both charge and magnetic moment distributions,such that we find the same distribution because they'recaused by the same ingredient
* The figure shows representativeresults obtained by Hoffstetter and collaborators at SLAC in the 1960s
* The form factors G_E, shown on the left,and G_M, shown on the right, for the proton are measured as a functionof the momentum transfer squared, and extracted from the cross section forthe elastic electron proton cross section
* One finds the dipolar shape,G equals one over one plus q^2 over Lambda squared, both squared, with the samesize perimeter Lambda equal to 0.84 GeV
* In the next video, we will see whathappens when we increase q^2, such that the exchanged photon can excite,or even break the nucleon
* [MUSIC]


--- SKIP ---: 01_5-2-inelastic-scattering-and-quarks.en.srt


--- SKIP ---: 01_5-2-inelastic-scattering-and-quarks.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-2-inelastic-scattering-and-quarks.en_SENTbySENT.txt
* [MUSIC] In this fifth module we are discussingthe structure of hadrons and strong interactions
* In this second video we discussinelastic scattering between electrons and nucleons and what one can learn from that
* After following this video, you will know about resonancesas excited states of nucleons
* Dee inelastic scattering andnucleon structure functions
* And the so.called scalinghypothesis as evidence for substructures inside the nucleon, as well as the role anddistribution of quarks in the nucleon
* Form factors decrease rapidly withq^2 like we showed in video 5.1
* Consequently, the probability to observe an elastic scatteringbecomes low at high energy-momentum transfer
* This is not surprising
* Large q^2 corresponds toa short photon wavelength, which is then more and more able to resolve the internalstructure of the target particle
* This structure will then not beinsensitive to the energy-momentum transfer
* The target will be excited oreven destroyed
* In other words,inelastic processes take over
* At the moderate q^2, inelasticprocesses produce excited states of the nucleon, also calledresonances, such as Р Р†РІвЂљВ¬РІР‚В +, which have the same quantumnumbers as the proton
* These resonances an extremelyshort lifetime and therefore a broad mass distribution
* The figure show the result of anelectron-proton scattering experiment at an energy of about 3 GeV andat fixed scattering angle
* The elasticity of the reactionis first visible in the energy distribution ofthe outgoing electron on the left, which is no longer fixedas in elastic case
* Broader secondary maxima are formedwhich corresponded to the excited states of the nucleon, also clearly visible in the invariantmass distribution of the outgoing hadronic state on the right
* Is kinematic is completelydetermined by measuring the outgoing electron as in the caseof elastic scattering
* The position and the inverse width ofthe large maximum indicate the mass and the life time of the resonanceР Р†РІвЂљВ¬РІР‚В +(1236)
* At higher q^2, beyond the resonance region weenter into the region of the so-calleddeep elastic scattering
* The final state consists of multiplehadrons with at least one baryon to to conserve quantum numbers
* This is the region wherethe photon interacts individually with the chargedconstituents of the nucleon
* The cross section can be parametrizedwith 2 terms as before, but with 2 unknown structure function W_1 andW_2 replacing the form factors
* They parametrize the distribution and dynamics of the nucleon constituents.They depend on the tranfered energy nu which is the energy of thephoton and its invariant mass squared
* The kinematics now requires a secondadditional kinematic parameter because the mass of the hadronicsystem is no longer fixed, as was the case with a proton orresonance in the final state
* In addition to the scattering we canthus choose a second variable
* Here it is the energy EР Р†Р вЂљРІвЂћСћof the outgoing electron
* The structure functions are measuredexperimentally, analyzing the dependence of the cross section on the scatteringangle, like in the elastic case
* The big discovery at SLAC in the late60s was that the structure functions do not depend on nu andq^2 separately but on their ratio x_Bj, which is equal to q^2 over twicethe mass of the proton times nu
* The variable is named afterits inventor James D
* Bjorken
* The phenomenon was called scaling at thattime because of the very general observation that the dimensionless variable x_Bj doesnot depend on any energy nor mass scale
* Structure functions follow in factscaling if inside the nucleon there exist sub-structures with whichthe photon interacts elastically
* This interpretation of scaling isbest demonstrated in the limit of large equal square, where the interaction between quarksis negligible compared to the force transmitted by the photon
* Quarks then act as quasi free particles with which the photon interactsin an incoherent manner
* To respect the kinematicconstraint in such an elastic electron-quark scattering,the photon can only interact with a quark which carries a fractionx_Bj of the nucleon momentum
* Consequently, the cross section isproportional to the probability to find such a quark in the nucleon
* In the limit of square going to infinity, the structure functions W_itend toward the function F_i(x) which are directlyrelated to the distribution of the fractional momentum x_icarried by quarks of type i
* The experiment at SLAC have in fact shown that the phenomenon already occurs at the moderate squared
* The structure function W_2,as a function of the kinematical variable omega,which is about equal to 1/x_Bj, smoothens with increasing the q^2beyond the resonance region, and then follows a universal functionof x_Bj independent of q^2
* The kinematic constraint imposedby elastic scattering of point-like particles insidethe proton is indeed respected
* However, the scaling ofstructure functions is not exact
* This figure show modern measurementsthat come from experiments at the electron proton collider HERA
* The curves and data for different xare expressed by a constant in order to be all visiblein the same graph
* At small x, so at small quark momenta, the structure function variesstrongly with q^2 because of the contributions from virtual gluonsenriching the quark contents
* The smaller deviation atlarge x are more subtle
* The coupling constantof strong interactions depends on the momentum transfer
* It is not really a constant
* We will come back to thisastonishing fact in video 5.4
* Structure functions can thus be used tomeasure the momentum distribution of quarks inside nucleons
* We qualitatively demonstrate the behavior of the structure function F_2(x) based on successively refinedhypotheses on the dynamics of quarks
* If the nucleon consisted of threequarks without interaction, x will be fixed to 1/3 for each quark, and F_2 will be a delta function at this value
* If it were a state wherequarks are bound together via gluons,the average value of x would still be 1/3, but with a wider distributionaround this value
* If we finally take intoaccount that quarks can emit virtual gluons which can splitinto a quark-antiquark pair at low energy, we expect that the quark distributiontends to fill up at x -> 0
* The experimental data indeed tofollow this qualitative picture
* First of all for the valence quarks,that is the two up quarks and one down quark for the proton, the structure function varies around1/3 with a strong enhancement at small x by additional quark-antiquark pairs produced by gluons
* The integral of the distributionis twice as large for the up quark than forthe down quark, as it should be
* The contribution gluons of is indeedseen in the contribution of s and sbar quarks which would not bepresent in the nucleon otherwise
* When integrating this distribution wesee that only about 1/2 of the proton momentum is carried by quarks
* The rest is carried by gluons
* In the next video, we discuss mesons,bound states between quarks and antiquarks
* [MUSIC]


--- SKIP ---: 01_5-3-quark-antiquark-resonances-and-mesons.en.srt


--- SKIP ---: 01_5-3-quark-antiquark-resonances-and-mesons.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-3-quark-antiquark-resonances-and-mesons.en_SENTbySENT.txt
* [MUSIC] In this module, we are in the processof discussing the internal structure of hadrons and strong interactions
* In this video, we discuss mesons, which are bound states between quarks andantiquarks
* After following this video, you will knowthe basic mechanisms that bind quarks and antiquarks to form mesons, andtheir excited states and their spectra, which provide information about the natureand behavior of the binding force
* In addition to the baryons andtheir resonances, which we have already treatedin the previous video, there are bound states between quarks andantiquarks which we call mesons
* If their quantum numbers are right,they can be produced in vacuo by a virtual photon,as shown in this Feynman diagram
* For light quarks,their mass is dominated by binding energy
* For heavy quarks, their mass is slightlylower than the sum of the masses of the corresponding quark pair
* An example is the productionof rho mesons, a bound state between light quarks,which is shown in this Feynman diagram
* Resonances can also appear as intermediatestates in hadronic reactions
* In this case, there's obviously morefreedom regarding their quantum numbers
* In general,bound states between quarks and antiquarks have a rather short lifetime,especially if heavy quarks are involved
* This is due to the substantial phasespace available for their decay
* The energy dependence ofthe electron-positron cross section around a resonance generally followsa Breit-Wigner function, which is shown in this equation
* M is the mass andGamma is the width of the resonance
* The cross section is reducedto half of its maximum value, sigma_max, for square root of s equalto M Р вЂ™Р’В± Gamma/2
* The lifetime of the resonance isthe inverse value of the width, tau is equal to one over gamma
* The form of the Breit-Wigner functionresembles the squared amplitude of a classical damped oscillator
* Square root of s corresponds to thefrequency of the external periodic force, M to the resonance frequency andGamma to the damping factor
* The cross section in this analogyappears as the squared amplitude of the oscillation,as shown in the graph on the left
* For resonances between light quarks,such as rho and omega, one observes widths from a few MeV to 150MeV, corresponding to lifetimes between 10^-22 and 10^-24 seconds
* They are produced in a resonant mannerby the intermediate photon when the mass of the virtual photon is sufficientlyclose to that of the meson
* When produced this way they mustobviously have spin one and charge zero, just as the photon does
* They decay into pions
* Around a mass of about one GeV,one can produce the Phi resonance, which is an s-sbar bound state,which decays into strange particles
* It's width is narrow,of the order of 4.4 MeV
* Around 3 GeV, we find the J/Psiresonance, the lowest lying c-cbar bound state, as well as itsexcited states, the Psi mesons
* Their width are small,about 90 keV for the J/Psi, itself
* Their lifetime is thus long, and the e+e- -> hadron cross section is significantly enhanced around theresonance energy, as shown in this plot
* Close to 10 GeV, the Upsilon resonancesare produced, made of b-bbar pairs
* We see on the right the e+e- -> hadrons cross section around the Upsilon_1s resonance,and its excited states, Upsilon_2s and Upsilon_3s,all mesons formed by b-bbar states
* The states are distinguished bythe relative angular momentum of the two quarks
* The spins are always parallelto produce a vector meson
* The study of resonance states, especiallythose of heavy quarks, allow us to better understand the potential generatedby the strong force that binds quarks and antiquarks into mesons, as well as alsothe decay mechanisms for heavy quarks
* As an example, the figure shows the massspectrum and decay scheme of c-cbar and b-bbar resonances
* The energy levels indicate thatthe potential between two quarks has two terms
* The parameter alpha_s, of order of 0.2, is the strong interaction analog of theelectromagnetic fine-structure constant
* The first term diminishes with distance
* The second term, on the contrary,grows with distance and keeps the two quarks from being separated
* The constant in this confining termis of the order of 1 GeV/fm
* In video 5.4, we will discuss in moredetail the properties of the strong interactions which providethis binding force
* The peaks of the cross section aroundresonances invites to build storage rings for the mass production ofthe corresponding states
* The collider DAFNE in Frascati,Italy is one such factory dedicated to the productionof Phi resonances
* The Beijing e+e- storage ring, BEPC,produces J/Psi and Psi mesons
* The PEP-II collider inthe United States and KEKB in Japan are factories forthe Upsilon and other b-bbar mesons
* The systematic decrease ofthe width with the mass of the resonance could make you believe thata t-tbar resonance would be very narrow, and thus have a long lifetime anda significant cross section
* This, however, is not at all the case
* The top quark is so heavy, on the orderof 175 GeV, that the phase space for its decay becomes enormous
* The t-quark lifetime isthus extremely short
* It decays before it caneven form a bound state
* Consequently, there will be hardlyan increase in e+e- cross section at the threshold forthe production of pairs of top quarks
* In the next video, Mercedes willdiscuss what all of this means for the properties of strong interaction
* [MUSIC]


--- SKIP ---: 01_5-4-color-and-strong-interactions.en.srt


--- SKIP ---: 01_5-4-color-and-strong-interactions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-4-color-and-strong-interactions.en_SENTbySENT.txt
* [MUSIC] In this fifth module, we're discussingthe structure of hadrons and the strong interaction
* We've seen several times that the stronginteractions have special properties
* Quarks behave as almost as free particlesat short distances inside the hadrons
* Nonetheless, free quarks havenever been observed outside hadrons
* This indicates that the strong forceconfines them within bound states and does not allow to separatethem to large distances
* In this fourth video weР Р†Р вЂљРІвЂћСћllqualitatively discuss these seemingly incompatible properties
* After following this video, you willknow the main properties of strong interactions, including its differentvertices in Feynman diagrams, color charge, gluons andtheir role in binding quarks together, and vacuum polarization for electromagnetic and strong interactions
* We already introducedthe 3 components of color charge in video 1.1 asa quantum number of quarks
* We also saw the immediate consequenceto triple the cross section for e+ e- annihilation into hadrons in video 4.5
* Color is the quark property responsiblefor their strong interaction
* The formal theory of this interaction isquantum chromodynamics, also called QCD
* Color can take three different values,red, blue, and green for quarks
* We indicate it by a lower index when appropriate
* A quark can carry only one non zero color,antiquarks carry one anti-color
* The interaction between quarks proceedsthrough the exchange of color
* The intermediate vector bosons transmittingthe strong force are the eight gluons, g
* They carry a color and an anti-color,and therefore are not color neutral
* This is in contrast to the photon which couplesto the electromagnetic charge but does not carry one itself
* For strong interaction,there are eight gluons in total
* With three colors and three anti-colors one would expecta total of nine combinations
* One of them, the fully symmetric combination,that is red-antired plus green-antigreen plus blue-antiblue, has no net color, it does notparticipate in strong interaction and so cannot be produced
* The remaining eight gluons arevector bosons, they are electromagnetically neutral andhave zero mass
* The basic vertex of the strongquark interactions changes the color of the quark
* The coupling constant gappearing in the vertex enters into the crosssection through its square
* Alpha strong is equal to g^2/(4Р СџР вЂљ), in analogy to the electromagneticfine structure constant alpha
* The interaction has the same strength forthe three colors or any of their superpositions
* So there is invariance underan overall rotation in color space
* According to Noether's theorem, thisrequires a conservation law for colors
* The vertex conserves color
* The corresponding amplitude isalso independent of the flavors of quarks and their electromagneticcharge, which are both ignored and conserved by strong interactions
* If gluons carry themselves color, they should be able tointeract among themselves
* Because they carry even color and anticolor, there are two additional vertices
* The color indices indicated hereare only examples
* The three-gluonvertexis proportional to g and has the same strength as the quark-gluon vertex
* We must, in each calculation, consider thefact that there are many more different colors for gluons than for quarks
* The vertex with four gluons onthe contrary is proportional to g^2 and thus disfavored withrespect to the other two
* Color does not show up as a quantum numberin our characterization of hadrons
* They are white
* So far all established mesons are q-qbar states and all established baryons are threeР Р†Р вЂљРІР‚Сњquark statesof neutral color
* Recently, the LHCb collaboration has discovered pentaquark states consisting of five quarks
* However it's still unclearwhether these are bound baryon-meson states as shown inthe picture on the left or genuine compact multi-quarkstates as sketched on the right
* LHCb has also confirmed the existenceof a tetra-quark state first observed by the BELLEcollaboration in Japan
* Again, the same reservations apply
* It could still bea meson-meson bound state, rather than a compact four-quark state
* Mesons contain a superposition of quark-antiquark pais with all colors in equal proportions
* A snapshot is shown here forthe interior of a positive pion
* Gluons are constantly exchangedbetween quarks to maintain binding, changing the color of quarks,as in this sketch, while keeping the overall hadron white
* The same mechanism worksinside baryons
* Between hadrons, for example in a nucleus,objects of neutral color are exchanged to create binding,except at very short distances
* It follows that an ab initio description ofthe nuclear force stays very difficult, although we dispose ofa well-established quantum theory for interaction between quarks and gluons,namely QCD
* At short distances,comparable to the hadron size, the exchange of gluons producesa potential between quark and antiquark which is similar to the one establishedby photons in a positronium bound state
* This potential varies with distance as1/r like the Coulomb potential
* At large distances,there is a different behavior, the potential becomeslarger with distance
* We already saw a potential that fitsthe description of the spectra of J/Psi and Upsilon states in video 5.3
* The second term determines the behaviorof the long range potential with a constant K equal toabout 1 GeV/fm
* This corresponds to a constantlong distance force equivalent to the one requiredto lift a weight of 16 tons
* The second term is created bythe interaction between gluons
* In terms of a chromostatic language, the additional force between gluonsconcentrates the color field along a corridor that connectsthe two color charges
* Because of the particularshape of the field, one also call this a stringthat connects the colors
* The potential proportional to k times r does not allow color andanti-color to be separated, but confines them to distancesof the order of 1 fm
* The potential inside hadrons oughtto be generated dynamically by the interaction between the quarks andgluons
* Obtaining results is complicated bydifficulties which are both conceptual and technical
* Both the confinement of colorat large distance and the relativistic and quasi-free movementof quarks must be incorporated
* One must treat states withmultiple quarks and gluons
* The evolution of the strong coupling constant alpha_strong with four-momentum transferq^2 must be taken into account
* We will talk about thiseffect in a moment
* Calculation techniques are considerablysimplified if one replaces the space-time continuum by a meshof equidistant discrete points, similar to a crystal lattice with sides a
* One defines the quark fieldson the sites of the lattice, and gluon fields on the links
* The continuum of space-time is recoveredin the limit of an infinitely large lattice with a -> 0
* This discretization introducesa lower limit on momentum-transfer of the order of 1/a, and thus regularizes the divergencesinherent to pertulative QCD
* Numerical calculations of this kindrequire tremendous computing resources
* They are performed on the mostpowerful supercomputers
* With this non-perturbative method,one arrives, fo example, at results forthe spectrum of light hadrons
* The calculated masses are the average forthe different particle types
* For instance, the mass of nucleon isthe average of the mass of the proton and the neutron
* Parameters of the calculation are thestrong coupling constant, alpha_strong, and the masses of light quarks up anddown, and the quark strange
* They are fixed using the measuredmass of pions, kaons and Xi as reference
* This results in a prettyimpressive understanding of the hadron spectrum, suggesting thatQCD is indeed a correct theory for strong interaction alsoat larger distances
* Distance laws forelectromagnetic and strong interaction are fundamentally different
* The electromagnetic potential decreasesas 1/r as a function of distance
* The strong potential increases atlong distances proportional to r
* To understand this difference, we must consider quantum correctionto the photon and to the gluon propagators
* A significant correction to the photon propagator is the one which introducesan electron-positron loop
* This loop creates additional electriccharges between the projectile and target
* We call this phenomenonvacuum polarization
* In electrostatic language wecan say that these additional charges screen the target charge
* Therefore the effective chargedecreases with distance
* That is, it increases withgrowing momentum transfer q^2
* This is, indeed,what we find experimentally
* For electrodynamics,this is a small effect
* To see a change of alpha of a few percent,we have to compare momentum transfer at almost zero thatis at very large distances, where alpha is measuredto be about 1/137 Р Р†Р вЂљРІР‚Сљ see the example of the Penningtrap in video 4.3 Р Р†Р вЂљРІР‚Сљ to the energy of the Large ElectronPositron collider at CERN, where the momentum transfer q^2is around 10^4 GeV^2
* That is at very short distances
* For strong interactions, the effectof vacuum polarisation is much more pronounced
* Because of the sizeof the strong coupling, the vacuum polarization and the change in the net chargewith distance are more important
* In addition,the sign of the effect is reversed
* The strong force becomesstronger with distance
* This is because there are two types ofvacuum polarization graphs for gluons
* The analogue of electromagneticpolarization introduces quark-antiquark loops in the gluon propagatorwhich shield the colors charge
* But in addition,the coupling of gluons between them introduces gluon loops whichhave the opposite sign
* And in the chromostatic language,we can say that the gluon loops introduce additional color-anticolorcharges which are attractive
* This reinforces the color charge ofthe target instead of shielding it
* Because of the large number of gluons, and their zero mass, gluon loops dominatethe strong vacuum polarization
* Consequently, the color chargeof the target increases with distance proportional to the inverseof the momentum transfer
* Indeed one experimentally finds that this effect is more significant than itselectromagnetic counterpart
* In the next video we will seehow these properties of strong interaction keep us fromseeing free quarks
* [MUSIC]


--- SKIP ---: 01_5-5-hadronisation-and-jets.en.srt


--- SKIP ---: 01_5-5-hadronisation-and-jets.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-5-hadronisation-and-jets.en_SENTbySENT.txt
* [MUSIC] In this fifth module we are discussingthe internal structure of hadrons and strong interactions
* This fifth video willexamine the consequences of the fact that strong interactionsbecome stronger with distance
* After having watched this video, you willunderstand why one cannot observe free quarks, and what happens when the quark,antiquark pair is created in vacuo
* Because of the enormous amount ofenergy stored in a color field at large distances, separated color charges willcreate additional particles instead of becoming free quarks or gluons
* A dynamic separation occurs, forexample, in the e+ e- annihilation into quark antiquark pairs athigh energy far above threshold
* The left figure shows the Feynman diagram,the right figure, the kinematics inthe center-of-mass frame
* The central figure is an example ofan event of this kind showing multiple hadrons in the final state
* Again, there are two approachesto qualitatively understand the process of hadronformation in the final state
* a chromostatic one anda more chromodynamic approach
* In a chromostatic approach, the quark-antiquark paircreates further quark antiquark pairs as soon as the original pair isseparated by of the order of 1 fm
* At this distance, the stored fieldenergy is large enough to do this
* This process continues untilthe relative momentum of the quarks is sufficiently moderated to permitthe formation of bound states
* Hadron formation occurs along strings,a kind of elastic band connecting two color charges thuswith limited transverse momentum
* The hadrons thus form jets whichapproximately follow the initial direction of the quark and the antiquark
* In a more chromodynamic approach, the process can be visualizedin terms of a quark-gluon cascade
* It starts with the emissionof a gluon by the quark, or the antiquark as shownin this Feynman diagram
* This gluon can produce eithera quark antiquark pair, or a pair of gluons, according tothe elementary vertices of QCD
* Because there are more gluons than quarks,splitting into gluons is more probable, and is thus shown in this Feynman graph
* The strong couplingwill become the larger, the more the invariant mass q^2 ofthe virtual particles involved diminishes
* At the end of the cascade, the quarkswill form colorless bound states
* It is clear that thisapproach cannot be used up to the end ofthe hadronization process
* At small q squared, the coupling constantbecomes so large that a perturbative expansion in powers of the couplingconstant will no longer converge
* In this domain, collective effects take over which end upby the formation of mesons and baryons
* They must be described bymore phenomenological models
* The hadrons are formed in vacuo atthe end of the quark gluon cascade
* Their transverse momenta with respectto the original quark direction are thus limited by Heisenberg'sprinciple to some 300 MeV
* Hadrons are thus concentrated aroundthe initial quark direction and form jets
* Their transverse momentum is small,and independent of the quark momentum
* Thus, jets become more and morecollimated as the quark energy increases
* If the first gluon emitted inthe cascade has sufficient transverse momentum with respectto the natural width of a jet, a third hadron jet will becomevisible along the gluon direction
* One thus observes an event withthree jets as shown in this example
* These events can be attributed tothe reaction e+ e- -> q qbar gluon
* The cross section for this processe+ e- -> q qbar gluon is calculated using the Feynmandiagrams as shown on the left
* The gluon emission from a quarkhas all the characteristics of a Bremsstrahlung process
* Its amplitude has two divergences,becomes very large for the emission of a low-energy gluon,which is an infrared divergence
* It also blows up for a very forwardemission by a collinear divergence
* In both cases, the quark andgluon jets will merge
* Two as well as three jet events arecounted among the hadronic final states
* In the calculation we must thus add theircross section to obtain the total hadronic cross section introduced in video 4.5
* One thus obtains a better approximationfor the ratio R at high energies in better agreement with the experimental dataas shown on the right of this graph
* Jets appear without exceptionwhenever a high energy quark or gluon converts into hadrons
* This means, first of all,that the probability for the hadronization process is 1
* It is an inevitable process
* Second, the conservationof energy-momentum and the limitation of transverse momentumby Heisenberg's principle means that jets follow the direction and representthe energy of the initial quark or gluon
* And this with the more and more narrowcollimation as the energy increases
* This event shows a finalstate with two energetic jets produced in a proton-protoncollision at the LHC
* On the top you see a zoom of the innerdetector and the calorimeters
* On the left, you see multiple vertices
* The high luminosity of the collidercauses multiple reactions at the same bunch crossing
* The two reactions with most of thedeposited energy, which are colored in red and green, show back to back jetswhich are strongly collimated
* The bottom image on the right showsa histogram of the directional distribution of energy
* The two narrow peaks correspond to thedirection and the energy of the two jets
* This concludes our shortdiscussion of strong interactions
* In the next module, we will deal with weakinteractions and the Higgs mechanism
* [MUSIC]


--- SKIP ---: 01_6-1-particles-and-antiparticles.en.srt


--- SKIP ---: 01_6-1-particles-and-antiparticles.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-1-particles-and-antiparticles.en_SENTbySENT.txt
* [MUSIC] Hello and welcome to the sixth module of ourintroductory course of subatomic physics
* In this sixth module, we discuss weakinteractions and the Higgs mechanism
* You will notice that this module is againlarger than the average module
* This is due to the rich phenomenologyof electro-weak interactions
* We recommend that you taketwo weeks to digest it
* Before diving into our subject, in thisfirst video we will go into more depth on the subject of antiparticles
* After following this video, you will knowthe difference between particles and antiparticles and the connection between antiparticles andenergy-momentum reversal
* How do antiparticles come intoplay in the standard model
* It all starts withthe evolution equation for fields which takes the role ofan equation of motion for particles
* It follows from relativisticenergy-momentum conservation by operator substitution
* The result is the Klein-Gordonequation for free particles
* Its solutions follow a continuityequation as seen here
* It describes the conversation of a four-vector current j^Р вЂ™Р’Вµ of particles
* The time component is the probabilitydensity of finding a particle at location x and t
* Its spatial component is the particleflow density at that same position
* Imagine an infinitely smallvolume that surrounds the point that we are considering
* The density in the volume can onlychange Р Р†Р вЂљРІР‚Сљ drho/dt not equal to zero Р Р†Р вЂљРІР‚Сљ if particles enter or exit through theboundaries of the volume, which means that divergence of j should thensimultaneously be non-equal to zero
* This ensures that the numberof particles in the volume is conserved
* It might surprise you thatthe probability density contains the time derivative of the wave function
* We will understand thisfact in a little while
* The Klein-Gordon equation is manifestlycovariant, it contains only scalars under Lorenz transformation
* Plain waves must be a solution ofthe Klein-Gordon equation, and describe a free particle
* We use a normalization proportional toan arbitrary constant square root of N
* You may take N as the numberdensity of particles if you wish
* The current density isproportional to the four-momentum
* Its temporal component isproportional to the energy
* This is due to the covarianceof the quantity
* It requires that the probabilityrho d^3x is invariant
* The volume element changes like d^3x -> d^3x/gamma, because of the Lorentz contractionin the direction of motion
* For invariance, the probability density must thenchange as rho -> gamma times rho
* With gamma equal E/m,rho must thus be proportional to energy
* It is for this reason thatthe probability density and current density contain respectively atime and a space derivative of the field
* Let us now consider the energy eigenvaluesof relativistic free particles, inserting a plane wave solutioninto the Klein-Gordon equation
* We find solutions with positive andwith negative energy
* And since the density of probabilityis proportional to the energy, it is no more positive definite either
* This contradicts the definition ofprobability as a real number between zero and one
* To solve this problem we must interpretthe continuity equation in an innovative way, introducing the electromagneticcurrent density
* Proportional to the electric charge Q, j^0 now becomes the localcharge density and thus, may be negative as well as positivein agreement with intuition
* It is obvious thatsolutions of positive and negative energy are distinguished bythe charge of the considered particle, if one wants to keep the probabilitydensity always positive
* It is thus not the probability density,2N p^Р вЂ™Р’Вµ, which is invariant, but the electromagnetic current density,2Q N p^Р вЂ™Р’Вµ, which obeys the rules forphysically sensible probabilities
* The current density is conservedby the continuity equation
* With this concept, we can very wellspontaneously create and annihilate particles, provided that the total charge in an infinitesimal volume remains constant
* All of this is a consequence ofrelativistic covariance only
* Which are the implicationsof this reinterpretation for the negative energy solutions
* The answer is given by Feynman'sinterpretation of these states
* The electromagnetic current density ofa free electron with charge Q = -e, ignoring its spin, is givenby the first equation
* This current is that of a particle withpositive energy advancing in the direction of its momentum vector
* Let ussay that it emerges from a vertex
* For a free positron, Q = +e,the current is positive but the current density is the same as for anelectron of negative energy which moves in the opposite direction,say entering into the vertex
* That is to say that the particlewith negative energy which comes out of a vertex is equivalent toan antiparticle with positive energy that enters intervals
* In this way, we can eliminatethe solutions with negative energy, and replace them by antiparticlesevolving in the opposite direction
* This establishes a connection betweenthe transformation between particles and antiparticles, which we callcharge conjugation, and the reversal of the directionof momentum called parity
* These two transformations will be analyzedin more detail in the next video
* But first, we look at the consequencesof Feynman's interpretation of negative energy states
* These consequences are indeed quitedramatic as shown by the example of a simple double scattering process
* Heisenberg's Principle allows usto reverse the order of the two scatters in time
* The intermediate state willthen move backwards in time
* We replace it by its anti-particlemoving forward in time
* The double scatter then becomes a paircreation process as shown on the right followed by a particle/anti-particleannihilation process
* Both contributions begin withthe same initial state and end up with the same final state
* We must thus sum them atthe level of amplitudes when calculating the totalprobability of the process
* When calculating simple scatters, it is sufficient to consider particles,the corresponding anti-particle process can be obtained by reversingthe direction of the particles
* In the next vide, we introduce thediscreet transformations of space time, parity, and time reversal and chargeconjugation, which transforms the wave function of a particle into that ofan anti particle and vise versa.


--- SKIP ---: 01_6-2-the-discrete-transformations-c-p-and-t.en.srt


--- SKIP ---: 01_6-2-the-discrete-transformations-c-p-and-t.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-2-the-discrete-transformations-c-p-and-t.en_SENTbySENT.txt
* [MUSIC] In this sixth module,we are discussing weak interactions
* In this second video, we introducethe operations of charge conjugation, parity, and time reversal
* After following this video, you will knowdiscrete transformations of space time, which are parity and time reversal,the charge conjugation transformation, which reverses all charges, andthe behavior of forces and matter under these transformations.The reversals of space and time directions are discretetransformations of space-time coordinates
* For the space coordinates, the transformation is alsocalled the parity, P
* Both transformations can be appliedas operators to a quantum state such as a particle
* These operators are unitary,because a double application to the initial statereproduce the original state
* Therefore the eigenvalues ofthe two operators are plus or minus 1 if they are applied toeigenstates of parity or time reversal
* However, there are many wave functionswhich are not eigenstates of parity
* For example, a function phiequal to cos x + sin x becomes under the applicationof parity cos x - sin x, which is neither +phi nor -phi
* Eigenstates of P can beclassified like in this table
* Scalar wave functions describe the spinzero particles with positive parity
* Pseudoscalar ones describe spinzero particles with parity minus
* Vector and axial vector wavefunctions describe the spin one particles with parity negative andpositive respectively
* Parity is a multiplicative quantum number,so the total parity of a system in its ground state is the product ofthe individual parities of its components
* If there is an angular momentumbetween the components, characterized by am l-typequantum number, it must be taken into account bya factor (-1)^l
* Parity is conserved in interaction due toelectromagnetic and strong forces, but not in weak interactions
* Conservation means that if a system isin an eigenstate before the reaction, it will be in an eigenstate withthe same eigenvalue after the reaction
* For bound states, the total angularmomentum, J=l + s, comes in, multiplying the intrinsicparity of the components
* Consequently, the notation J^P isused to characterize particles
* You find it in the PDG tables foreach particle
* Electromagnetic transitions in boundstates, as the hydrogen atom for example, require that Р Р†РІвЂљВ¬РІР‚В l Р вЂ™Р’В± 1
* So the parity of the photonmust be -1
* The photon is thus indeed a vectorparticle, as we noted in module 4
* Hadrons are parity eigenstates,thus their parity eigenvalues can be used to characterize a particle, just likespin, electric charge or baryon number
* The parity of fermions isopposite to that of antifermions
* By convention, parities are arbitrarilyfixed to +1 for leptons and quarks, and antiquarks and antileptions,therefore, have parity -1
* For bosons, the parity is the same forparticles and antiparticles
* The photon parity,as we already said, is -1
* Baryons which contain three quarkswithout a relative quantum angular momentum, such as the proton and neutron,have a parity (+1)^3, so, finally, parity +1
* That is to say that J^P is (1/2)^+
* The lightest mesons,such as pions as well as light kaons, contain quark andantiquark with anti parallel spins
* They have parity (+1)(-1), so -1, and they are called pseudoscalar mesons
* The states with the same quarkcontents but parallels spins, like the mesons rho, K^*, omega,and Phi are called vector mesons
* They have J^P equal to 1^-
* But parity is not justa theoretical concept, it has a measurable effect whenever itcorresponds to a conserved observable
* Let us look at the dominant decay ofthe Р СџР вЂљ^0, which goes into photons
* The study of this processhas allowed to conclude that Р СџР вЂљ^0 is a pseudoscalar bosonwith J^P = 0^-
* Its decay products are two photons,vector boson of J^P = 1^-
* We project spins on theonly natural axis of the system, given by the direction of the twophotons in the rest frame of the Р СџР вЂљ^0
* Conservation of angular momentum requires one of the two configurations sketchedhere, or a combination of both
* The first configuration has two photons ina right circular polarization state
* The second has the left polarized photons
* Under parity, the momentum of the twophotons change sign but their spin, being pseudovectors, do not change
* So the parity operation changesthe first configuration into the second one, and vice versa
* The photon wave function is characterizedby its polarization vector epsilon, which points in the directionof the electric field, and for real photons is normal tothe direction of motion
* As parity is conserved in decay process, this requires that the total wave functionpsi be an eigenstate of parity
* Up to a normalization constant,the two possibilities correspond to the wave function psi_1 andpsi_2, given here
* The first is proportional to a scalar,so it has parity +1
* The angle phi between the two polarizationplanes will be preferentially zero, with an intensity distributionproportional to the square of cosine phi
* The second is proportional to the productbetween a pseudovector and a vector
* So it has parity -1
* The angle phi between the polarizationplanes of the two photons will be preferentially 90 degrees
* Experimentally, it is found thatthey are indeed orthogonal
* The party of the Р СџР вЂљ^0is therefore -1
* The charge conjugation operator,indicated by C, is an example of a transformation ofthe field itself and not of coordinates
* It transforms the wavefunction of a particle, phi_P, into the wave functionof its antiparticle, phi_pbar
* The operation therefore changes the signof electric charge, color, baryon, and lepton number, in short, all the quantumnumbers of the charge type
* Thus the operator C applied toa fermion gives an antifermion, with all charges opposite,with the same mass, the same spin, and the same momentum
* Again electromagnetic and stronginteractions conserve charge conjugation
* That is to say that this interactions have the same intensity forparticles and anti-particles
* Weak interactions on the contraryviolate C, so they distinguish between the particles andthe anti-particles
* Particles which do not have anycharge can be eigenstates of C
* They are their own anti-particles
* The photon and the Z boson are examples
* The pseudoscalar meson Р СџР вЂљ^0,which is also its own anti-particle, has C phi_pi = phi_pi,with eigenvalue C = +1
* Since the photon isgenerated by moving charges, which change sign ofthe electric charge under C, C A_Р вЂ™Р’Вµ = -A_Р вЂ™Р’Вµ
* So charge conjugation is anothermultiplicative quantum number
* A system of n photons will havea C equal to (-1)^n
* For example, Р СџР вЂљ^0 decay into twophotons respects the conservation of C, but Р СџР вЂљ^0 decay intothree photons is forbidden
* Indeed, the branchingratio of this decay is measured to be less than3.1 10^-8
* Time reversal operation, indicated by T, transforms the coordinate forfour-vector x, so (t,x,y,z) into xР Р†Р вЂљРІвЂћСћ = (-t,x,y,z)
* When applied to a field, T also turnsthem into their complex conjugate, and this is necessary because of thetransformation of the equation of motion
* Except for real boson fields,there are no eigenstates of T alone
* So no conserved quantum number associated
* The importance of T is rather in combinationwith the other discrete transformations, parity and charge conservation
* One can easily understand that allthe local fields theories must be invariant under the joint action of CPT,transforming a process into itself
* We will see what followsthat weak interaction violated to a maximum extentthe symmetry C and P, and even the combined operation CP,which transforms right handed fermions into a left hand antifermions,is not respected by weak interactions
* This introduces a small differencebetween a reaction and its reverse
* It gives an objective direction to time
* We will introduce weakinteractions in the next video
* [MUSIC]


--- SKIP ---: 01_6-3-weak-charges-and-interactions.en.srt


--- SKIP ---: 01_6-3-weak-charges-and-interactions.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-3-weak-charges-and-interactions.en_SENTbySENT.txt
* [MUSIC] In this 6th module,we are discussing weak interactions
* And in this third video, we will gothrough the general properties of weak interactions, which are notquite like the others
* After following this video, you will knowabout the nonconservation of parity for weak interactions
* And the main vertices andcharges which are relevant
* Weak interactions, in fact,do not deserve their name
* Their apparent weakness at low energy isdue to the fact that they are transmitted by heavy particles, the neutral Z, andthe charged WР вЂ™Р’В± bosons
* Their propagator weakens the amplitudeat low momentum transfer
* Their coupling constant, g andgР Р†Р вЂљРІвЂћСћ, on the other hand, are of comparable magnitudeas the electric charge e
* Indeed, they are connected bythe condition of electro-weak unification, which involves the Weinberg angle theta_W
* Its value is close to 30 degrees
* So instead of three coupling constants,there's only one and an angle
* The tangent of this angle isthe ratio between gР Р†Р вЂљРІвЂћСћ and g
* At the same time, it links the masses of the weak bosons by cos theta_W = M_W/M_Z
* Feynman diagrams for typical charged and neutral weak interactionsare shown in the two left graphs
* Comparison with the corresponding photonexchange diagram shows that the structure of weak interactions is quitesimilar to that of electromagnetism
* The neutral component of weak interactionscan even interfere with electromagnetic interactions when it actsbetween charged particles
* The charged weak interaction is the onlyforce that can change the flavor of matter particles
* It can even mediate between members ofdifferent generations at the same vertex
* There are however other majordifferences between electromagnetic and weak interactions
* The weak charge is a quantitywith two components, in contrast with a single component forthe electromagnetic charge, and three components for the color charge
* The weak charge is called weakisospin by analogy to spin
* One characterizes particles by their totalweak isospin T and its third component T_3
* They determine the couplingconstants g and gР Р†Р вЂљРІвЂћСћ together withthe electromagnetic coupling e
* The weak force is transmitted by vectorbosons, similar to the photon and the gluon, but very heavy
* The WР вЂ™Р’В± mass is of the order of 80 GeV,that of the Z of order 90 GeV
* The two bosons carrythemselves weak isospin, and can thus interact among themselves
* In addition, charged bosons canobviously interact with the photon
* Weak interactions alsodo not conserve parity
* Thus, they produce polarization phenomenaeven from non-polarized initial states
* This explains the first part of the smallprint at the bottom of this table
* This non-conservation of parity isthe most visible example of symmetries, which are respected by other interactions,but not by weak interactions
* Weak interactions do not evenrespect the combined CP symmetry, and are therefore the only knowninteraction which distinguishes between matter and anti-matter
* We will discuss this in video 6.8
* At the same time, and maybe even forthe same reason, they are the only interactions which connect particles fromdifferent generations at a single vertex
* They can thus not conserve flavor
* This fact is well established for quarks
* And also has been observed forleptons as we will see in video 6.7 and 6.10, respectively
* Now let us first discuss the discoveryof parity nonconservation in charged weak interactions
* In 1956, based on the study ofexperimental data obtained by C.S
* Wu, Lee and Yang concluded thatweak interactions are not invariant under the operation of parity
* In order to investigate their behaviorunder this transformation, Wu and colleagues have designed an experimentthat remains a classic of our discipline
* It uses beta decay of neutrons n -> p e- nu_e-bar bound in Co-60 nuclei
* At low temperature ofthe order of 0.01 Kelvin and in the presence of a magnetic field,the spin vectors of these nuclei with J=5 are strongly aligned withthe magnetic field direction
* Their decay,Co-60 with J=5 into Ni-60 with J=4 can lead to two spin configurations
* p and E denote momentum andenergy of the emitted electron, and sigma denotes a unit vector inthe direction of the spin of the nucleus
* In case a shown on top, the electron is emitted in the directionopposite to the Co-60 spin
* In case B, it is emitted inthe direction of the initial spin
* Any combination ofthe two cases is allowed by conservation of angular momentum
* The experiment showed the angulardistribution of case a exclusively
* It does not admit a contribution,however small, of configuration b
* This corresponds to a maximumviolation of parity
* Indeed, conservation of paritywould imply that the probabilities of the two configurations a andb are the same
* This also means thatcharged weak interactions only admit a certain spin directionof participating fermions
* In our example, the two spins ofelectron and neutrino must be aligned with that of the nucleus toconserve total angular momentum
* In case a, the electron spin isantiparallel to its direction of motion
* The antineutrino spin is parallel
* So we find that the electron hasnegative helicity, it is left handed
* The antilepton has positive helicity,it is right handed
* This property of charged weakinteractions can be generalized
* As far as we know, the W onlyinteracts with left-handed fermions, fermions of negative helicity
* And right-handed antifermions,antifermions of positive helicity
* Charged weak interactions thusviolate parity to a maximum extent
* Consequently, we assign left-handedleptons to doublets of weak isospin
* Right-handed leptons to singlets
* In this way, left-handed matterfields carry a weak charge and are coupled to W and Z
* Right-handed matter fields do not
* In the same manner,quarks are assigned to doublets and singlets according to their helicity
* For antimatter fields,the opposite is true
* Right-handed antileptons andantiquark carry weak isospin
* Left-handed ones do not
* The W and Z themselves belong toa triplet of weak isospin with T = 1
* They can thereforeinteract among themselves
* In addition, the WР вЂ™Р’В± obviouslycarries an electromagnetic charge and can interact with a photon
* Weak interactions conserve weakisospin such that the fundamental weak interaction vertices withmatter are shown on this graph
* Here, l denotes a generic charged lepton
* And nu_l a neutrino of the same flavor
* q is an up-type quark
* qР Р†Р вЂљРІвЂћСћ is a down-type quark
* The exact definitions we will reserve forlater
* W interactions change T_3 by one unit
* So a charged lepton istransformed into a neutrino
* An up-type quark is transformed intoa down-type quark or vice versa
* Attention, the emitted quarks and neutrinos do not necessarilybelong to the same generation
* The interaction of the Z boson keepsT_3 the same and conserves flavor
* In the next video, we will presenta prototype of W interactions, namely muon and tau lepton decay
* [MUSIC]


--- SKIP ---: 01_6-4-muon-and-tau-lepton-decay.en.srt


--- SKIP ---: 01_6-4-muon-and-tau-lepton-decay.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-4-muon-and-tau-lepton-decay.en_SENTbySENT.txt
* [MUSIC] In the sixth module,we are discussing weak interaction
* And in this fourth video,we discuss a prototype process of charged weak interactions, the leptonicinteraction of the W boson
* After following this video, you will knowhow to describe the decays of muon and tau leptons,in terms of a Feynman diagram
* And how to discuss the propertiesof this interaction quantitatively
* Here is the Feynman diagram formuon decay
* The emission of the W- convertsthe muon into a muon neutrino
* The virtual W then decays intoan electron - electron-antineutrino pair
* This way the lepton numberweak isospin and other quantum numbers, are conserved
* In the diagram, we already convertedthe outgoing antineutrino into an incoming neutrino, by inverting its charge andfour-momentum, kР Р†Р вЂљРІвЂћСћ into -kР Р†Р вЂљРІвЂћСћ
* In the amplitude, the W propagatorcontributes a factor of one over q^2 minus the mass squared of the W, which weakens the amplitude for q^s much smaller thanthe square of the mass of the W
* At low momentum transfers, like for light particles decays whereq^2 is smaller or equal to the square of the mass ofthe muon, that is, it is negligible, the propagator is constant and equal tothe inverse of the square mass of the W
* We can then treat this process in the so-called Fermi approximation
* By convention, one absorbs thisresidual of the W propagator with the square of the coupling constantg^2, to form the Fermi constant G_F
* It takes the role of the fine structureconstant for weak interactions
* In this approximation, valid at lowmomentum transfers, weak interactions can be described by a direct interactionbetween two current densities
* The transition currents correspondingto charged and weak interactions, are similar to the electromagnetic ones
* One denotes them in an imprecise manner,as charged currents CC
* Analogously, the interactionof the Z boson at low energy, that is q^2 much smaller thanthe square of the mass of the Z, can be approximated by direct interactionof two neutral currents, NC
* The constant rho involves the Weinbergangular theta_W, which measures the ratio between the coupling constantsof the weak charged and neutral interactions
* The constant rho is equalto one with good precision
* This is due to the fact that inthe Standard Theory of electroweak interaction, the masses of the vectorbosons and the coupling constants are connected by the Higgs mechanism,which we will discuss in video 6.11
* High-precision experimentalresults verify this relationship
* The differencial muon decay rate,neglecting the mass of the electron, which is much smaller thatthe mass of the muon, is given here as a function of the energyEР Р†Р вЂљРІвЂћСћ of the outgoing electron
* This energy can vary between zero andhalf the mass of the muon
* As this process is virtuallythe only decay channel, the total rate is obtainedby integrating over EР Р†Р вЂљРІвЂћСћ
* The measure of a lifetime ofthe muon is close to 2.2 10^-6 s
* We thus find a Fermi constant G_F of about 10^-5 inverse GeV squared
* The factor m^5 comes inthrough the phase-space factor, which enters into the calculation of Gamma
* Therefore we find the same formula forother weak decays, especially for the tau decay
* It does on the other hand, not directlycorrespond to the total decay rate, because the tau has other importantdecay channels due its large mass
* So Gamma for the specificdecay is just a partial width, we must take into accountthe branching fraction in the numerator
* One of the most precise experimentsthat measure the muon lifetime, is MuLan at the Paul Scherrerinstitute at Villigen in Switzerland
* A mu+ beam enters from the left,and is stopped in a target
* The scintillator ball surrounding the targetregisters the positrons from the decay, and measures their emission times
* The number of decays per unittime follows an exponential law to a very good approximation, with a low background from accidentalcoincidences between beam arrival and the electron signal
* The slope of curve givesthe muon lifetime
* The MuLan Collaboration finds the value of 2,196,980.3 plus or minus 2.2 picoseconds
* This result dominate the globalaverage of the particle data group
* This gives a value of the Fermi constantaccurate to 0.6 parts per million
* The tau lepton lifetime is too short fora direct of measurement
* We rather measure its path length L,at high energies
* Tau leptons are produced in largenumbers in electron positron annihilation into tau pairs
* At high energies, that is atthe square root of s equal to twice the energy of the tau,their lifetime in the laboratory frame is extended bythe relativistic factor gamma
* Their mean part length L istherefore longer by a factor p over the mass of the tau
* With a lifetime of severalhundred femtoseconds, the path length itself is hardly directlyobservable, even at high energies
* At a tau energy of 50 GeV for example, the average decay distanceis about 2.5 millimeters, and thus completelycontained in the vacuum tube, that contains the beamof collider experiments
* One determines the decay point from thevertex of decays into three charged particles
* As the tau decays in threepions plus a neutrino
* The trajectories of the three pionsare measured with a tracking the detector, which is typically a silicon detector,directly outside the vacuum tube
* They are then extrapolatedback to their common origin, which is the decay vertexof the tau lepton
* The tau origin being knownfrom the beam position, the decay length L is thusthe distance between the two points
* The decay length distributionin logarithmic scale, shows the expected exponential behavior, but modified bythe experimental resolution, which is significantly worse than fordirect time measurement
* The slope of the distributionmeasures the average decay length, which in turn gives the lifetimeas L/(gamma v)
* The global average of tau lifetimedetermined by the Particle Data Group is (290.3 Р вЂ™Р’В± 0.5) 10^-15s
* This figure is in excellent agreementwith the precision prediction, based on the Fermi constant as determined bythe measured lifetime of the muon
* This show that the couplingconstants of the electron, muon and tau to the W bosonare the same to within a few per mil
* In the next video,we'll talk a little more about the properties of the W+ andW- bosons, and in particular, about their masses
* [MUSIC]


--- SKIP ---: 01_6-5-the-w-boson.en.srt


--- SKIP ---: 01_6-5-the-w-boson.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-5-the-w-boson.en_SENTbySENT.txt
* [MUSIC] In this sixth module,we are discussing weak interactions
* In this fifth video, we'll talk aboutthe properties of the W bosons, which transmit the charged weak force andare responsible for weak decays
* After following this video, you will knowthe W couplings to matter and forces
* The mass of the W bosons andthe various ways to measure it
* In video 6.3, we already definedthe couplings of the W to matter
* And in video 6.4, we have reviewedthe method to measure the Fermi constant, which applies to processes withq^2 much smaller than the square of the mass of W, and thus defines the intensity ofweak interactions at low energy
* So now the question is how tomeasure the mass of the W boson
* This is done using two different methods which are of comparable accuracy
* The first method determines the mass by measuring the energy threshold for the production of W pairs in e+e- annihilation
* We already noted thatthe vector bosons W and Z themselves carry electro-weak charges
* WР вЂ™Р’В± have an electric charge
* And both WР вЂ™Р’В± and Z have a nonzero weak isospin
* There is thus an interactionvertex among electroweak bosons withthe couplings indicated here
* These vertices fix the values ofelectroweak couplings in a unique manner, and at the same time for interactionbetween bosons and between fermions and bosons
* Charged bosons can then be producedin pairs by e+ e- annihilation
* The position of the threshold forW pair production and the shape of the cross section at threshold determine the massof the W Boson with good precision as done by the L3 experiment at the LargeElectron Positron collider
* A second method forthe mass determination is to measure the four-momenta of the decay products andform the invariant mass
* Since the mass isa relativistic invariant, we do not need to produce the W at rest
* For two-body decays at high energy,this means measuring energy and direction of the particles
* The example shows here an event ofa W+ decaying into a positron and an electron-neutrino, seen by the ATLASexperiment at the Large Hadron Collider
* The high energy positron isshown by the yellow track in the central detector
* And the corresponding energy, the positionin the calorimeter also shown in yellow
* The neutrino, the second decay product of the W+ leaves no trace in the detector but manifests itself as a missing energy andmomentum
* Momentum balance is indeed only guaranteedin the plane transverse to the beam, because gluons andquarks carry a variable fraction x_Bj of the incident proton momentum,as we discussed in module 5
* However, analyzing the kinematics inthe transverse plane alone allows for a good precisionmeasurement of the W mass
* The results of the two methodsare in good agreement and can be averaged becausethey are independent
* The precision reached with threshold andinvariant mass methods is ten times smaller than what canobtained measuring a mass by a resonance, as it is done for the Z mass measurement,which we will see in the next video
* In fact, in the next video,Martin will talk about the properties of the Z bosons,which transmit the weak neutral interaction
* [MUSIC]


--- SKIP ---: 01_6-6-the-z-boson.en.srt


--- SKIP ---: 01_6-6-the-z-boson.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-6-the-z-boson.en_SENTbySENT.txt
* [MUSIC] In this sixth module,we are discussing weak interactions
* In this sixth video, we'll talkabout the properties of the Z boson, which transmits the neutral weak force and can be considered as the heavybrother of the photon
* After following this video you willknow its properties, its mass, and the way to measure it andits couplings to matter
* In video 4.5, we have already discussedthe prototype process e+e- -> Р вЂ™Р’Вµ+Р вЂ™Р’Вµ- for the production of fermionpairs by electron-positron annihilation
* In addition to electromagneticinteractions, as shown in the left graph, this process can be mediatedby neutral weak interactions, as shown in the right graph
* Since initial and final statesare the same, one must add the amplitudes
* In the cross-section,we thus find three terms to lowest order
* The first term, sigma_gamma, contains thesquare of the photon exchange amplitude
* The second one, sigma_Z,that of the Z exchange
* And the third one, sigma_int,the interference between the two
* For the photon alone, we alreadyquoted the cross-section in video 4.5
* The total differential cross-section, which also takes into account the othertwo contributions, contains a term symmetric in the scattering angle thetalike the one we had found for the photon
* The scattering angle, I remind you, is the angle betweenthe incoming e- and the outgoing mu-
* The coefficient A_0 of thisterm now contains a new contribution due to weak interactions
* There is also an additional asymmetricterm proportional to the coefficient A_1
* The coefficients contain the real part andthe square of a resonance term, r, which comes from the resonantproduction of Z bosons when the total e+e- energy approaches the Z mass
* It contains the Breit-Wignerfunction characteristic for the propagator of massive virtual bosons
* The coupling constants, g_V and g_A,depend on the electric charge and the weak isospin of the matter particlesinvolved in each vertex
* Due to the value of the weak mixing angle,sin^2 theta roughly equal to 1/4, g_V has a small value for chargedleptons, g_A is simply -1/2
* At low energies,square root of s much less than M_Z, where r is roughly equal to 0, the influence of weakinteractions is negligible
* We fall back onto the resultfound by electromagnetism, that is to say, A_0 = 1 and A_1 = 0
* The terms proportional to the real partof r are due to electro-weak interference and are important in the intermediateregion where neither the photon nor the Z exchange are dominant
* And finally, close to the Z mass,where the terms proportional to r^2 dominate, we find that the weakinteraction is two orders of magnitude stronger than the electromagnetic one,due to the amplification by the resonance
* The Z resonance manifests itself by aenormous peak in the total cross-section
* Electro-weak interference causes a large, angular asymmetry onthe flanks of the resonance
* At low energies, the cross-section dependson the electromagnetic coupling alpha and the square of the center of mass energy s, like sigma = 4pi alpha^2/(3s), the characteristic size and shape ofpurely electromagnetic interactions
* As the energy approaches the Z peak,we see an enormous increase and weak interactions dominates the process,thanks to the resonant exchange of Z bosons that we now maycall almost real instead of virtual
* Far above the resonance, the two processesadd up and are of comparable size
* The interference term introducesan asymmetry into the angular distribution, which we hadalready noted in Video 4.5
* To quantify it,one defines a forward-backward asymmetry, A_FB, comparing the rate of forward Р Р†Р вЂљРІР‚Сљ theta less than 90 degrees Р Р†Р вЂљРІР‚Сљ and backward scatteringР Р†Р вЂљРІР‚Сљ theta bigger than 90 degrees
* This asymmetry is large and negativebelow the resonance, goes through zero at s roughly equal to M_Z squared and becomeslarge and positive above the resonance
* In the immediate vicinity ofthe Z resonance, that is to say, a few Z widths away from the Z mass,we can neglect both electromagnetic interactions andelectromagnetic interference
* For all e+e- interactions intoa pair of point-like fermions, we then obtain a cross-sectionwith a peak given by r squared
* In this region, the Z boson is quasi-real
* The maximum of the cross-section can be expressed in terms of the decaywidth gamma_Z of the real Z boson
* The partial widths of the Z decay intoelectrons and other fermions depend on their weak and electromagneticcharges T_3 and Q, as shown on the left
* In addition, the number of colors N_Ccomes in for our quark final states
* The partial and total width canbe derived from the shape and height of the measured cross-section, for antifermion species with a masssmaller than half the Z boson mass
* This even includes neutrinos, whichare not seen in the measured final state, as are any other invisible particles
* In this way, experiments have fixedthe number of neutrino species with mass of the neutrino less than mass ofthe Z divided by two to exactly three with very high position,as you can see in the graph on the right
* There are thus only threegenerations of light matter
* The position of the peak determines thatmass of the Z boson with high precision
* Here we show the resultsof the four experiments at the CERN Large Electron-Positron collider,LEP, the predecessor of the LHC
* The mass determination by the resonancemethod is precise to two parts in 10^5
* This accuracy would correspondto a measurement of my own weight to about two grams
* This may not sound very impressive, butmy lifetime is hopefully of the order of 2 billion seconds, andI weigh about 10^5 grams
* The Z boson lifetime is 3 10^-25 seconds, and it weighs 1.6251 10-22 grams
* At such a level of precision, unexpectedeffects influence the measurement
* As incredible as it may seem, the phaseof the moon influences this measurement
* Just like sea water, the Earth's crustgoes through high and low tides, with a height differenceof about 20 centimeters
* The tidal waves deform the LEP storagering by some millimeters compared to its total length of 27 kilometers
* At constant frequency,this changes the beam momentum, and focalization amplifies this effect
* Consequently, the beam energy dependson the moon phase at the level of 100 ppm, parts per million
* This effect has been measured usingresonant depolarization, a method to determine the energy of the circulatingbeam with an impressive precision
* You see the result in this graph, which shows the beam energy over largeportions of the passage of a tidal wave
* And even the passage of the high speedTGV train in nearby France influences the measurement
* Since the TGV is powered bya single-phase DC current, its passage induces parasiticcurrents into the storage ring
* Because of their hysteresis, the magnetsremember the train schedule, as you can see on the right
* This, again, leads to a slightvariation of the collider energy
* All of these incredibleeffects had to be taken into account to arrive at the final result forthe Z boson mass
* This should allow you to appreciatethe impressive precision with which the mass can be measured byresonant production of a particle
* The method remains a specialtyof electron-positron colliders, since the point-like initial state allowsan excellent definition of the kinematics
* The coupling of the Z boson andtwo leptons, g_V and g_A, are measured using the total anddifferential cross-sections as well as the polarization dependence ofe+e- annihilation into leptons
* One finds confirmation of ourchoice of a weak isospin as up and down members of a doublet
* One also finds that all generationshave the same couplings to an accuracy of a few times 10^-3
* For charged leptons, the measuredvalues of g_V are close to zero, and g_A close to -1/2, as we expect
* For neutrinos, one finds g_V = g_A = 1/2, as one would expect for fermions withweak isospin up and electric charge zero
* In the next video, we will talk aboutpurely weak interactions, that is to say, weak decays of quarks
* [MUSIC]


--- SKIP ---: 01_6-7-weak-decays-of-quarks.en.srt


--- SKIP ---: 01_6-7-weak-decays-of-quarks.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-7-weak-decays-of-quarks.en_SENTbySENT.txt
* [MUSIC] In the 6th module weare discussing weak interaction
* And in this 7th video we'll talk about quark decaysmediated by weak interactions
* After following this video,you will know the quark decay mechanism, which is analogous to the muon decay,we discussed in video 6.4, and you will know the quantum nature ofquark states which interacts with W bosons
* And the Cabibbo-Kobayashi-Maskawa matrix, which describes these mixturesin the Standard Model
* The couplings of quarks to the WР вЂ™Р’В±privilege those between members of the same generation, but they alsoexist across generation boundaries
* Pion decay is an example for the dominant case, where the W connects an upquark to a down quark
* An example of an intergenerationdecay is the kaon decay, where the W boson connectsan up quark to a strange quark
* In the Feynman diagrams shown here, we have again replaced the incomingantiquarks by outgoing quarks
* The ratio of the two partial ratesis measured to be of order 1
* These experimental results show thatkaon decay is very much disfavored
* The kaon phase space is large comparedto the pion due to it's large mass
* Neglecting moun and neutrinomasses, the decay width is proportion to the parent particle mass to the 5th power
* The ratio is thus expected to be 100 times larger
* It must be concludedthat the intergeneration interactions are disfavoredcompared to intrageneration interactions by at leasta factor of 100 in the rate or a factor of 10 in the amplitude
* In 1963, Nicola Cabibbo proposeda way to describe these processes
* States which interact with the WР вЂ™Р’В±are not the quarks which are listed in the periodic table of matter particles,which we presented in module 1
* The particles, which interact withthe W bosons, are the mixtures dР Р†Р вЂљРІвЂћСћ, sР Р†Р вЂљРІвЂћСћ, and bР Р†Р вЂљРІвЂћСћ, quantum superposition of the real quarks d, s and b
* The states, dР Р†Р вЂљРІвЂћСћ, sР Р†Р вЂљРІвЂћСћ, and bР Р†Р вЂљРІвЂћСћare not eigenstates of the mass operator
* So they are not real particleswhich evolve in space time, but they come from a rotationin flavor space
* Since these rotations will not change thenumber of fermions, the operator must be unitary
* For two generationthe description is simplified
* In the formula we see symbolicsubstitute the wave function of the quarks with the name of the quark
* The angle of rotation between the firsttwo generations, theta_C, is called the Cabibbo angle
* The mixing corresponds toa modification of the weak charged quark current.A small strange quark amplitude s is added to the down quark wave function andvice versa
* As a consequence the amplitudes ofthe weak interaction of quarks change
* For dominant interactions ofthe W with the u-d current, for example, the rotation induces a factorcosine theta_C in the amplitude
* For disfavored interactions, such as thosewith a u-s current, the factor sine theta_C appears
* The relative rates of the two typesof interaction are thus redused by a factor tangent squared of theta C
* From the observed rate reductionwith respect to the phase space one finds a  Cabibbo rotationangle of about 13 degrees
* This consideration must be generalizedto 3 generations of quarks
* Matrix notation is introduced betweenstates, which appear in the weak charged quark current, that is dР Р†Р вЂљРІвЂћСћ,sР Р†Р вЂљРІвЂћСћ and bР Р†Р вЂљРІвЂћСћ, and the real quarks d, s and b
* The unity matrix V_ckm is called the Cabibbo-Kobayash-Maskawa matrixafter the names of its inventors
* The Particle Data Group compiles the values ofthese elements from many different measurements
* These matrix elements appearat each vertex of the WР вЂ™Р’В± with a pair of quarks
* Absolute values are measured by comparingdecay rates of each type except for top quark interaction where they arederived from the unitarity of the matrix
* The matrix elements become smalleras one deviates from the diagonal
* This means that intra-generationinteractions dominate the weak charged current
* Inter-generation interactions jumpinga single generation are disfavored
* Those which bridge two generation,even more
* The structure of the matrixthus favors decay cascade, like the one of the top quark shown here
* Note that the unitarity allowsthe matrix elements to be complex, therefore a non-trivial phaseangle may appear in the matrix
* This factor makes amplitudes non-invariantunder the operation CP, the symmetry between matter andanti-matter
* We will talk about violation of matter-antimatter symmetry in the next video
* [MUSIC]


--- SKIP ---: 01_6-8-particle-antiparticle-oscillations-and-cp-violation.en.srt


--- SKIP ---: 01_6-8-particle-antiparticle-oscillations-and-cp-violation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-8-particle-antiparticle-oscillations-and-cp-violation.en_SENTbySENT.txt
* [MUSIC] In the sixth module weare discussing weak interactions
* And in this eighth video, we willtalk about the violation of the CP symmetry between particles andantiparticles by weak interactions
* After following this video you willbe able to describe the condition for oscillation between particles andantiparticles and their mechanism
* And you will be able to explainthe violation of the joint symmetry CP in the quark sector
* The Cabibbo-Kobayashi-Maskawa matrix mustbe unitary but not necessarily real
* This allows a non-trivial complexphase which cannot be removed by a global rotation in flavor space
* The existence of sucha phase has very important consequences that we willdiscuss in the following
* But first a reminder.We already saw in video 6.3, that the weak interactionmaximally violates parity P
* A good example is the Р СџР вЂљ+ decay
* The dominant decay channel is Р СџР вЂљ+ -> Р вЂ™Р’Вµ+ nu_Р вЂ™Р’Вµ
* The neutrino produced in the decaymust be left-handed because of the structure of the interaction
* As the pion is a scalar particle,the Р вЂ™Р’Вµ+ must also be left-handed
* Which is allowed to the extent that is mass is non-negligible andallows it to have the Р вЂ™Р’В«Р вЂ™Р’В wrongР вЂ™Р’В Р вЂ™Р’В» helicity
* The mirror decay, on the contrary, which will produce Р вЂ™Р’Вµ+ of the Р вЂ™Р’В«Р вЂ™Р’В correctР вЂ™Р’В Р вЂ™Р’В» helicity is not observed at all, because the W does not interactwith right-handed neutrinos
* This explains why the decay intoan electron, Р СџР вЂљ+ goes to electron and a left-handed electron neutrino is somuch this disfavored, despite it's much largerphase space factor
* The small mass of the electron requiresit much more to have the Р вЂ™Р’В«Р вЂ™Р’В correctР вЂ™Р’В Р вЂ™Р’В» helicity and thus suppressesthe amplitude of this process
* The decay of the charged pionviolates at the same time the charge conjugation symmetry C
* Under this operation we obtaina reaction that is forbidden by the fact that the the W does not couple atall to left-handed antineutrinos but only to the right-handed antineutrino
* Since the symmetries of C and P are both violated in a maximumfashion by charged weak interactions, one might expect that the combinedsymmetry CP will be respected
* This is indeed the case inthe example shown so far
* For the pion, it is simple toverify that the operation CP converts the Р СџР вЂљ+ decayinto the Р СџР вЂљ- decay, with the good helicity for the neutrinos
* But the bad ones for muons are admittedbecause muons are non-relativistic
* This processes are therefore CPeigenstates with the same amplitude
* But this is not the case for all the inter-generation weakprocesses mediated by the W boson
* Let's look at the neutral mesons,like K0, which contains a d quark and an sbar quark, or B0, whichcontains a d quark and a bbar quark
* These can be converted into their own antiparticle by a second-order process
* This reaction is obviouslyonly possible for particles that do notcarry any kind of charge
* The pseudoscalar meson K0, for example,is an eigenstate of parity but not of charge conjugation becausethis operation changes strangeness
* K0 contains an antiquark sbar,so it has strangeness plus 1
* K0-bar contains a quark s, soit has strangeness -1
* Therefore neither K0 norK0-bar are eigenstates of CP
* But one can constructlinear combinations, K1 and K2, that are eigenstates of CP
* If CP is conserved, it should be these twostates which decay by weak interactions
* If the eigenvalue of CP wereconserved by weak interaction, the eigenstates K1 andK2 will decay by weak forces into final states which contains two pions andthree pions, respectively
* These final states havethe right CP properties
* This is approximately true
* The states K1 and K2 are almostidentical to the particles K0_S and K0_L found in the listof the Particle Data Group
* Because of the two very different phasespace factors, one finds that the lifetime of the K0_S is much shorterthan the one of the K0_L, which explains their name
* But their identification K0_S almost equal to K1 and K0_L equal to K2 is not perfect
* First, the two massesare not quite the same, they differ by some Р вЂ™Р’ВµeV
* The mass difference producesoscillation between particles and antiparticles in time, because both states are not evolvingwith the same velocity when their energy is the same
* Imagine a K1 meson at t = 0 at rest in vacuum
* Its wave function evolves according toits mass am_1 and width Gamma_1
* The probability density to find K1 at timet is given by the evolution equation for free particles
* The same reasoning is valid for K2 butwith mass m_2 and width Gamma_2
* Since the strong interaction conserveflavors, including strangeness, the state produced by stronginteraction will have a definite strangeness, like K0 or K0-bar
* If one produces, for instance,a K0 at t = 0, we'll have a mixture of equalquantities of K1 and K2 at that time
* Now the two componentsare evolving differently because of the smallmass difference Р Р†РІвЂљВ¬РІР‚В m
* At a later time t,we therefore find a different mixture
* If we thus measure the strangenessof the state as a function of time, for example by a stronger interaction,we find that it oscillates between K0 andK0-bar with the frequency Р Р†РІвЂљВ¬РІР‚В m
* So far the combined symmetryCP is still respected
* But one finds thatthe long-lived particle, K0_L, which is almost equal to K2, has a low probability to decay into Р СџР вЂљ+ Р СџР вЂљ-, a state which has the wrong CP eigenvalue
* One must thus admit that K0_L alsocontains a small amplitude of K1
* The coefficient epsilonis 2.3 10^-3, which is certainly small, but not 0
* Consequently, charged weakinteraction violates also the combined symmetry CP,but only a little bit
* This means that the amplitudesof charged weak interaction for matter andantimatter are slightly different
* So nature has therefore foreseenan objective way to distinguish them
* A complex phase inthe Cabibbo-Kobayashi-Maskawa matrix allows to introduce thislittle asymmetry in the mixing of quark states involved in weak interactions, with a phase angle theta,which is about 45 degrees
* This describes the phenomenon usingthe CKM matrix, but does not explain it
* CP violation in weak interactionis a subject of active current research both in the kaon sector andin the B0 sector
* The next video will discussneutrino interactions which are among the most rareprocesses in particle physics
* [MUSIC]


--- SKIP ---: 01_6-9-neutrino-scattering.en.srt


--- SKIP ---: 01_6-9-neutrino-scattering.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-9-neutrino-scattering.en_SENTbySENT.txt
* [MUSIC] In this sixth module,we are discussing weak interactions
* And in this nineth video, we talk aboutneutrinos which are the only particles that interact exclusivelyby weak interactions
* After following this video, you will knowthe basic properties of neutrinos and their fabulously smallcross-section with mater
* The processes involving neutrinos are onlydue to weak interactions because neutrinos carry neither electric norcolor charge
* The process through which weak neutralinteractions have been discovered is the elastic scatteringof neutrinos off electrons, namely nu_Р вЂ™Р’Вµ e- -> nu_Р вЂ™Р’Вµ e-
* This picture taken witha Gargamelle bubble chamber at CERN the 1973 documents the firstobservation of this reaction type
* It is in fact the very first observationof a weak neutrino current event
* The neutrino enters from the left and interacts with an atomicelectron of the liquid
* A single visible track leavesfrom the interaction vertex
* It is due to a minimum ionizing particleas shown by the low bubble density
* The particle also causes bremsstrahlung
* It is therefore clearly an electron
* The bremsstrahlung photon is thenconverted into an e+ e- pair
* Since the observation of this reaction, the neutrino has become a precious toolfor the study of weak interactions, particularly the interactions of the Z andW with matter
* For energies much lowerthan the Z boson mass, the cross-section depends on the couplingconstants g_V and g_A of the electron
* Those of the neutrino wehave fixed to one-half
* These coupling constants have alreadybeen discussed and defined in video 6.6
* The cross-section is valid forneutrinos of the second and of the third generation,that is to say nu_Р вЂ™Р’Вµ and nu_tau
* For the anti-neutrino, the cross-sectionis indicated by the lower equation
* It differs from the neutrino cross-sectionin the sign of the interference term between the vector andaxialvector contributions
* Neutrino electron cross-sectionsare extremely small
* The proportionality toE_nu comes from the total energy available in the initialstate s, which is (p+k)^2, or in the approximationof zero neutrino mass, it is two times energy of the neutrinotimes the mass of the electron
* This proportionality is regularizedat high energy by the Z propagator hidden in the Fermi constant, G_F
* At 1 GeV, the cross-sections are of order attobarn
* The rates are thus desperately low
* Obviously, the neutrino can alsointeract with quarks through the exchange of a Z boson
* This image was taken with the sameGargamelle bubble chamber in the CERN neutrino beam
* Here we show the originalnegative picture
* The neutrino againenters from the left and interacts this time witha proton of the liquid
* There are three hadronscoming out of the vertex, two positively charged and one negative, as shown by the curvatureof the tracks in the magnetic field
* The proton in the middle interactswith a nucleus of the liquid, both pions are slowed downby dE/dx and absorbed
* The neutrino escapeswithout leaving a track
* Neutrinos also interact via W exchangein charged weak interactions, like in this example
* The neutrino once againenters from the left and interacts this time with a neutron
* A Р вЂ™Р’Вµ- leaves the chamberwith minimal ionization
* A highly ionizing protonis visible at the vertex
* A Р СџР вЂљ0 decays into two photonswhich in turn are converted into e+ e- pairs
* The two charged pions interact withthe liquid by the strong force and produce other hadrons
* You see by these examples that bubblechamber images contain a lot of information and are very graphical
* They are easily interpreted toidentify the reaction and the final state
* In fact, photos of this type whichawakened my fascination with particle physics in the 1970s
* But this analog technology isof course no longer used today
* We had seen that forneutrino-electron interactions, the cross-section is proportionalto the neutrino energy
* This is true in general to both for purelyleptonic and for interactions between neutrinos and quarks
* And for charged, aswell as for neutral current interactions
* Here you see the compilation ofthe particle data group of neutrino and antineutrino chargedcurrent cross-sections, divided by the neutrino energy tobetter appreciate the proportionality
* You may wonder if at some point,a cross-section that increases with energy willnot violate the unitarity limit
* Indeed, the neutrino cross-sections areregularized by the propagator of the W and Z boson and very high q^2
* But to see this effect of the propagator,we need fabulously high energies beyond 10^15 eV in the laboratoryframe, that is to say 1,000 TeV
* This graph shows a calculation ofthe cross-section at very high energy
* The Z resonance is clearly visible for reactions which involve ans-channel Z exchange
* Beyond the resonance, the propagatorregularizes the cross sections such that it will eventually tend to 0 as it should
* For reactions involving Wexchange in the t-channel, regularization takes much higher energy, since only a small fractionof the neutrino energy is transmitted to the target
* In the next video, we will discuss oscillationsbetween different neutrino species
* [MUSIC]


--- SKIP ---: 01_6-10-neutrino-oscillations.en.srt


--- SKIP ---: 01_6-10-neutrino-oscillations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-10-neutrino-oscillations.en_SENTbySENT.txt
* [MUSIC] In the sixth module, we are discussingweak interactions, and in this tenth video, we talk about oscillation betweendifferent neutrino flavors
* After following this video, you will knowhow to describe the quantum mechanism of oscillation between neutrinosof different generations and the key methods used todetect such oscillations
* You may have wondered why the particlesnu_L, nu_M, and nu_H, which were introduced in module 1, do not appearin reactions via the weak force
* There reason is just that, as forquarks, the neutrinos which interact with the W are superpositionof these real particles
* Consequently, a phenomenonanalogous to quark oscillations happens in the family of neutrinos
* Vacuum oscillations betweendifferent neutrino flavors can occur if neutrinos haveeven zero mass and if their mass is differentfrom generation to generation
* And these two conditions are indeed met
* Let us first consider twoflavors of neutrinos nu_mu and nu_tau forexample, involved in weak interaction
* And two mass eigenstates, two real particles, nu_M and nu_H with masses m_M and m_H
* The relation between the two classesare unitary rotations in flavor space
* The angle theta_MH is the equivalent ofthe Cabibbo angle in the quark sector which we haveintroduced in video 6.7
* The two particles nu_M andnu_H propagate in the z direction, for example, with different wave functionsbecause of their different masses
* The second equation is valid inthe ultra relativistic approximation, where p is equal to E-m^2/2Eand t is equal to z
* Now take a nu_mu beam att = 0 created for instance by Р СџР вЂљ+ -> Р вЂ™Р’Вµ+ nu_mu
* At a later time t, soat a distance z from its origin, this beam will be composed differently
* The probability to find a nu_tau inthis beam will therefore not be 0
* The factor 1.27 takes intoaccount the constants as well as the conversionof units such that we can put delta m^2 which is equalto (m_H^2 - m_M^2) in eV^2, E^2 in GeV^2and z in km
* The two factors in the equationcorrespond to the amplitude and phase of an oscillation
* By choosing a distance z, which isof the same order of magnitude as delta m^2/4E, one can thus make a part of the nu_mudisappear and convert them into a nu_tau
* This nu_mu disappearancewas first observed for the so-called atmospheric neutrinos
* Cosmic rays incident onthe Earth atmosphere are mostly protons
* The hadron shower they cause in the atmosphereis dominated by pions
* In their decay, pions produce nu_mu andnu_e in a relative proportion of 2:1
* Thus there ought to be twice as many nu_muand anti-nu_mu in the atmospheric showers than nu_e and anti-nu _e
* If on the other handneutrinos undergo oscillation, the ratio of both neutrino flavors will vary with distance
* Fortunately, Earthprovides the means to vary the distance between the source andthe target without moving the experiment
* Neutrinos from the nadirtravel a distance larger by the Earth diametercompared to those from the zenith
* As the primary flux of cosmic protonsis homogeneous and isotropic and since low energy neutrinos hardlyinteract with the terrestrial matter, any change in the ratioof nu_mu to nu_e with the zenith angle isan indication of oscillation
* It is evident from the unitarityof the operation that for the probability of survival, wherethe nu_mu which stays a nu_mu, is equal to one minusthe probability of oscillation
* Experimentally one averagesover the unknown neutrino energy at a known propagation distance
* The oscillation curves for differentenergies, shown here by different colors, are thus averaged overthe spectrum of neutrinos
* This gives the black curve as a functionof distance indicated on the top scale, or as a function of the angle ofincidence indicated on the bottom
* The neutrino flux is measured andtheir flavor identified by measuring the reaction rateof charged current interactions, which produced either a muon oran electron in the final state
* With a known cross sectionthe reaction rate is proportional to the incident neutrino flux
* One finds experimentally that the observedflux ratio is compatible with the calculated oscillation probability
* Please note that the scale of length overenergy in this plot is the opposite of the one we have shown inthe slide just before
* The observed oscillationamplitude is quite large, and therefore corresponds toan angle theta_MH equal to 45 Р вЂ™Р’В± 13 degrees
* The difference of square masses is ofthe order of 3 10^-3 eV and thus extremely small
* Furthermore it is more likely that theoscillation of atmospheric neutrinos happens between the second and third generationthat is between nu_mu and mu_tau
* In general the relationshipbetween the states participating in leptonic weak interactions,nu_e, nu_mu and nu_tau, and eigenstates ofthe mass operator, nu_L, nu_M, and nu_H is described by a unitarymatrix of 3x3 elements, analogous to the Cabibbo-Kobayashi-Maskawamatrix for hadronic currents
* For leptons it is called the Pontecorvo-Maki-Nakagawa-Sakata matrix
* Like the matrix for quarks,the one for leptons may contain a nontrivial phase that would violate CP symmetry if it existed
* Future neutrino experimentswill show its existence or not
* Different types of neutrinooscillations have been observed to date, and an inexhaustive list is the following
* The disappearance of atmospheric nu_mu, disappearance of the nu_muproduced by accelerators, appearance of nu_tau and nu_e in a nu_mu beam produced at accelerators
* Disappearance of anti-nu_e which are abundantly reproduced in nuclear power plants
* For each of these measurements we give youa resource of information that you can use to find more details
* As an example we showhere the interaction of a nu_tau appearing in a nu_mu beamproduced at CERN and observed by the OPERA detector situated in the GranSasso underground laboratory in Italy
* The neutrino interactions are observedusing photographic emulsion, which are then developed
* The dE/dx of chargedparticles thus becomes visible
* This animation shows an enlargement aroundthe vertex of the neutrino interaction
* The reconstruction shows in the finalstate a charged tau lepton in red which decays into Р СџР вЂљ- in cyan anda Р СџР вЂљ0, which is invisible
* The kink between the parent and other tracks is a clearsignal of a tau lepton decay
* The photons from the Р СџР вЂљ0 decayare shown in yellow and they point to the decay vertex
* This topology is a clear signatureof a nu_tau interaction which had appeared in the nu_mubeam by flavor oscillation
* Neutrino oscillation are a very livelyresearch sector in the United States, Europe, and Asia
* And we can expect spectacular resultsby experiments which are in progress and under construction
* In the next video we discuss the factthat mass is not an intrinsic property of particles, but it is dynamically generated by the Higgs mechanism
* [MUSIC]


--- SKIP ---: 01_6-11-the-higgs-mechanism.en.srt


--- SKIP ---: 01_6-11-the-higgs-mechanism.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-11-the-higgs-mechanism.en_SENTbySENT.txt
* [MUSIC] In this sixth module, we've beendiscussing weak interactions and we now turn to the Higg's mechanism
* In this 11th video we will introduce thedynamic generation of particle masses by this mechanism
* After following this video you willknow how to argue that mass cannot be an intrinsic property of particles
* How what is called mass can bedynamically generated and how the Higgs mechanism implements this through the interaction of particleswhere the omnipresent Higgs field
* And finally you will knowqualitatively how particles evolve in a vacuum filled with the Higgs field
* What is the mass of an object
* There are two phenomena connected to mass
* First, mass is the property ofan object which opposes itself to acceleration according to Newton's Law
* This is called the inertial mass
* At the same time, it is the property of an object which allows it toattract other bodies by gravity
* This is called the gravitational mass
* It is the equality of these two propertieswhich led Einstein to formulate general relativity, the only theoryof gravitation known today
* But it is only the inertialmass which is of interest here, the gravitational interaction is tooweak to matter at the subatomic level
* One measures the mass of a particle byobserving the energy that it takes to create it at rest or by observingthe invariant mass of its decay products, or by observing itsvelocity at a given energy
* It is in fact this last propertyof the mass that we must retain
* Mass is the property that keeps particlesfrom moving at the speed of light, no matter how energetic they are
* The particle spectrum that you see in thisgraph is extremely large both as far as matter is concerned, with the neutrinoweighing on the order of a milli-electronvolt, and up to the top mass,which is about 170 GeV
* This is also true for forces, where the mass of the photon andof the gluon is zero
* And the spectrum goes up to the Z andW mass of 90 and 80 GeV, respectively
* We believed, me and probably also you, thatthe mass of elementary particles, quarks and leptons, and gauge bosons,was one of their intrinsic properties, like the electric charge,the color, the flavor, the baryon and the lepton number
* But this is not true
* Mass is the product of a dynamic process without which the mass of all theingredients of the universe would be zero
* Let us trace back the origin ofmass across different scales
* For ordinary matter, solids,liquids, and gasses, the mass is to a good approximation equal tothe sum of the masses of the atoms
* The cohesive energy forexample in a crystal is between one and ten electron volts per atom which issmall compared to the mass of the atoms
* The mass of an atom is also pretty muchequal to the sum of the masses of its electrons and its nucleus
* The atomic binding energy is of the orderof 5 to 25 eV per electron, small compared to the mass of the nucleus
* This reasoning continues tobe true at the nuclear level
* The nuclear mass is not far belowthe sum of the masses of its nucleons, but with a more important binding energyobviously
* As we have seen in module 2, the binding energies of the order ofeight MeV per nucleon, but it is still small compared tothe mass of the nucleon itself, which is of the orderof GeV volts
* In summary, the mass of the matterin the universe is dominated by the mass of the protons, the neutrons,and the electrons which populate it
* But at the scale of the nucleonitself this reasoning does not work
* Proton and neutron contain lowmass quarks and massless gluons
* The nucleon mass is dominatedby their binding energy, it already has a dynamic origin
* But quarks and electrons do not havebinding energy because they are as far as we know point-like particles
* They have no substructure sothere is no binding energy involved
* So at least for them could massnot be an intrinsic property
* The answer is no
* And the reason for this is quite subtleand fundamental at the same time
* Continuous symmetries are closelylinked to the conservation of a physical quantity by Noether's theorem
* You see Amalie EmmyР вЂ™Р’В Noetheron this photograph
* In particular gauge symmetry, the invariance of observables relativeto a local phase change of the field, is the basis of the standard model ofelectro-weak and strong interactions
* Gauge symmetry is in fact necessary toensure the regularization of infinities in the field theory, allowing toabsorb them into measured quantities
* Without this possibility the standardmodel would not make any predictions, yet it agrees with experiment everywhere
* On the other hand, an intrinsicparticle mass Р Р†Р вЂљРІР‚Сљfor matter as well as for forces Р Р†Р вЂљРІР‚Сљ violates gauge symmetry
* For a massive field we do not havethe freedom to change its gauge
* In other words, the fact that allgenerations of matter in all families have a different and non zero mass, and the fact that M_Z andM_W are not equal to the photon mass, namely not equal to zero,violate gauge symmetry
* Consequently mass must comefrom a dynamic process instead of being an intrinsic propertythat particles are born with
* Why can we not simply treat the tquark as a heavy u quark and the Z boson as a heavy photon
* The problem comes fromthe propagation probability of heavy bosons
* The probability amplitude for the exchangeof a zero-mass photon between two vertices is proportional to 1/q^2with q the four-momentum of the photon
* This amplitude is thus inverselyproportional to the invariant mass squared of the virtual photon that hasa pole at q^2 = 0, the mass of the real photon
* The amplitude gently tends to zero forq^2 going to infinity
* For massive bosons, on the contrary, the propagator amplitude is proportionalto 1/(q^2 - M^2)
* It has a pole at q^2 = M^2
* For ordinary reactions, this doesnot cause problems to first order, because they occur at a fixed q^2
* However, this propagator causes seriousproblems for higher order processes, as in the case of two boson exchangeshown in this Feynman graph
* Inside this square loop, conservation of energy momentumdoes not limit the circulating four-momentum
* Any q of one boson iscompensated by -q of the other
* To obtain the full amplitude of thisprocess, one must integrate over this internal momentum to infinity,and this interval diverges
* The same is true for the propagatorof the virtual fermion in the loop
* A finite mass will makethe amplitude diverge
* The intrinsic mass of bosons and fermions, which destroyed the gage symmetryof the theory, thus also makes it unusable
* Both facts are indeed intimately linked,as was shown by 't Hooft and Veltman, which were decorated by theNobel Prize for this discovery in 1999
* This is not the case, however,if mass is a dynamical phenomenon
* The Higgs mechanism invokes a scalarfield to keep particles from moving at the speed of light
* This way they appear massive to us,even though they aren't
* If massive fields are incompatiblewith the gauge symmetry, then the opposite should also be true
* Symmetry breaking should makean originally massless field massive
* To understand this intuitively,we again use a mechanical analogy
* Imagine an infinitely fineneedle as shown in this picture, it has no momentum ofinertia about its axis
* Now we apply a coaxial force beyondthe elastic limit of the needle
* At first, nothing will happen
* The system remains inunstable equilibrium
* Through a small quantum fluctuation inthe crystal lattice of the needle, it weakens in a random place, andthe needle folds in a random direction
* The cylindrical symmetry of the systemhas spontaneously disappeared
* At the same time, a moment of inertiaabout the original axis has appeared
* The system has acquired a kindof mass it did not have before
* In a quantum field theory, a similareffect occurs if the ground state of a system does not possess a symmetrythat is present for the system in general
* Let us consider a system witha single complex field Phi where the minimum of the energy
* The energy's plotted here asa function of the real part of Phi and the imaginary part of Phi, where the minimum of energy doesnot match Phi= 0, but occurs for all states with Phi^2 = v, not equal to 0
* The ground state of sucha system is not the vacuum, with all fields equal to 0, buta space time filled with Phi everywhere
* If we want to do a perturbativecalculation in such a vacuum, we need to choose the minimum of theenergy around which we develop the states
* By choosing a specific valueof Phi as the ground state Р Р†Р вЂљРІР‚Сљ with Phi^2 = v becausethat is the minimum of the energy Р Р†Р вЂљРІР‚Сљ one breaks the symmetry withrespect to the phase of Phi
* This is called spontaneoussymmetry breaking
* At the same time, the field Phi itself and any other field interactingwith it acquires mass
* We call such a field Phi a Higgs field
* How does a particle move in a vacuumfilled with the Higgs field
* All fields which interact with the fieldPhi with a given coupling constant are constantly kept from moving freely
* They propagate like in a viscous liquid
* Their speed is lower than c
* They have a mass they would not have ina real vacuum with the Higgs field absent
* Let me demonstrate this effectby again a mechanical analogy
* I have here two test tubes
* One filled with water,one filled with olive oil
* If we look at balls fallingthrough the liquid Р Р†Р вЂљРІР‚Сљ here there are two balls inthe liquid, one is a clay ball the other one is a steel ball Р Р†Р вЂљРІР‚Сљ we of coursesee that they fall with a different speed, because they have a differentinteraction with the liquid
* The porous surface of the clay ballmakes it fall much slower than the smooth steel ball
* So this would correspond to differentparticles moving in a viscous liquid, so that they do not fallat the speed of free fall
* If we change the liquid, in other words,if we make a stronger Higgs field, both balls will fall more slowly but it is still true that their individualspeed, their individual apparent mass, is given by their coupling to the field,by the coupling to the liquid
* So this is analogous tothe Higgs mechanism
* The strength of interaction, the strengthof presence of the Higgs field is analogous tothe properties of the liquid and the coupling of the different particles tothe Higgs field determine with what speed they move, even though their mass is zero
* So the mass of particles is given by theircoupling constant with the Higgs field
* It is dynamically generated throughinteractions with this ubiquitous field
* In the next video, we will discussthe quanta of the Higgs field, the Higgs bosons
* [MUSIC]


--- SKIP ---: 01_6-12-the-higgs-boson.en.srt


--- SKIP ---: 01_6-12-the-higgs-boson.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-12-the-higgs-boson.en_SENTbySENT.txt
* [MUSIC] In this sixth module, we are discussingelectro-weak interactions and the Higgs mechanism
* In this 12th video, we will encounter the particle associatedwith the Higgs field, the Higgs boson
* After following this video,you should know how the Higgs boson is produced at the LHC,how we identify its production and decay, and how it is verified that it hasthe properties required for a Higgs boson
* The Higgs field is a microscopicfield that must be quantized
* There is a particle which corresponds tothe Phi field, the scalar Higgs boson H0
* All its properties were knownbefore it was discovered, except that we didn't know whether itexisted, and that we didn't know its mass
* In particular, its branching ratiointo different fermion-antifermion or boson-boson pairs are fixedonce the mass is known
* The Higgs boson can be produced asa real particle at a hadron collider, provided its energy is sufficient
* This is forthe first time the case at the LHC
* Here we show some Feynman diagrams for the production of a Higgs boson from two protons, either by quarks orby gluons in the initial state
* The existence of the Higgs boson,H0, has been confirmed in a spectacular way by the experimentsATLAS and CMS at the LHC in 2012
* Higgs boson production is detected,among other methods, in the invariant mass distribution ofphoton pairs, or pairs of Z bosons
* The latter ones decay, in turn,into lepton-antilepton pairs, which are then observed in the detector
* A four-lepton event from the ATLASexperiment, with four muons in the final state, serves as the logo of this course,so you've seen it many times
* The signal at the mass of about 125 GeVsticks out clearly above the background of other production mechanisms whichdo not involve Higgs bosons
* On the left, you see the invariantmass distributions of two photons which has a peak at 125 GeV, andon the right you see the invariant mass of the four-lepton system that comesfrom a Higgs decay into Z-Z pairs
* Indeed, we have here a secondnice example of particle mass measurement throughthe invariant mass of its decay products
* The measurements from the two experimentsat the LHC give compatible results which can be combined
* And this determines today the mass ofthe Higgs boson H0 to be 125 GeV with a precision of about 250 MeV, that isaccurate to about two parts per thousand
* This is a remarkable achievement by theseexperiments and is the fruit of the work of thousands of physicists andengineers during two decades
* The experimental findings todaycan be summarized as follows
* The H0 is clearlya well-established new particle
* The probability that background fluctuatesupwards to simulate the signal is of the order of one toseveral hundred million
* It is indeed a boson becauseit decays into two photons
* It very probably has spin zero
* Its couplings to differentparticles are indeed proportional to their apparent masses, as they should
* Here we show a summary ofresults from the CMS experiment
* The only particle or coupling that is missing hereis the Higgs coupling to itself, since the Higgs boson should also beresponsible for generating its own mass
* So that will come in the future
* So, we are sure already at this pointthat H0 is indeed a Higgs boson
* This, however, does not exclude theexistence of other bosons of this type, which are obviously activelyhunted by experiments at the LHC
* In the next module, and Anna will go intomore details about how to search for new phenomena in the challengingenvironment of a hadron collider
* If you want to know more about the Higgsmechanism and its working principles, I recommend these three episodes ofthe excellent series Minute Physics from the Perimeter Institute in Waterloo,Canada
* You will easily find them on YouTube
* To conclude our discussion of the Higgsboson, the next video contains an interview with one of the key peoplewho contributed to its discovery
* [SOUND]


--- SKIP ---: 01_6-13-the-discovery-of-the-higgs-boson-optional.en.srt


--- SKIP ---: 01_6-13-the-discovery-of-the-higgs-boson-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_6-13-the-discovery-of-the-higgs-boson-optional.en_SENTbySENT.txt
* [MUSIC] [MUSIC] >> In this module, we are discussing the propertiesof electroweak interactions
* And in this video we will visit the ATLAS experiment, whose visitor center is behind me
* ATLAS is an experiment installed at the Large Hadron Collider LHC of CERN
* In video 3.2a we have already introduced the full range of CERNР Р†Р вЂљРІвЂћСћs accelerators
* And in video 3.10a, we have discussed theproperties of the ATLAS detector
* Today we will talk with one of the active participants in the discovery of the Higgs boson, who is Sandrine Laplace
* Follow me please
* >> I will quickly present to you ourinterview partner of today, who is Sandrine Laplace
* Sandrine obtained her PhD in 2003 at the Laboratoire dР Р†Р вЂљРІвЂћСћAccР вЂњР’В©lР вЂњР’В©rateur LinР вЂњР’В©aire LALin Orsay, close to Paris
* on a subject of CP violation
* Then she joined the Laboratoire dР Р†Р вЂљРІвЂћСћAnnecy de laphysique des particules, LAPP, close to here, about 50 km from Geneva, to join the ATLAS experiment, to which LAPP contributes in a major way
* Then in 2011, if I remember correctly, she joined the Laboratoire de physiquenuclР вЂњР’В©aire et des hautes Р вЂњР’В©nergies, LPNHE in Paris, where she still works today, always on the ATLAS experiment, which is our subject today
* So, Sandrine, do you still remember when you first heard about the Higgs mechanism andthe Higgs boson
* >> Yes, I do remember
* It was at the university, during a course
* >> I imagine, and I hope so
* >> Well, a course with was called DEA at the time, in the fifth year in France
* Indeed in a field theory course,that is where I think I first heard about the Higgs mechanismand the Higgs boson
* >> And what did you think at that time about this somewhat complex mechanism
* >> Indeed, at the time, it seemedcomplex to me
* As a student, one has asort of intuition of what for example the massof a particle could be
* And then one day, someone explains thatit is more complicated than that
* >> In fact, that mass does not exist
* >> Yes, so I remember that I foundthis pretty complicated for a property that seemed simple to me
* And in addition, it was very theoretical at the time, since it was in the context of a course
* It became somewhat more concrete,when during my PhD, while I worked on a totally different subject, in the year 2000Р Р†Р вЂљР’В¦>> Indeed
* >> at LAPP there was some excitementabout a possible signal
* >> Yes, a possible indirect signal of the Higgs mechanism
* In fact it was very indirectly, through radiative corrections, that one found that the existenceof this effect was not totally excluded, that it was even relatively probable, but not directly accessible tothat generation of experiments
* >> And that was one reason why we built the LHC
* Did this also count among your motivations to join the ATLAS experiment at LHC, at the time
* >> Yes, absolutely
* I did not, at that time consciously tell myself that I will join ATLAS for thisvery reason
* But, once I arrived in theATLAS collaboration, it appeared perfectly natural towork on this subject, indeed
* >> So what was your role during the construction of ATLAS
* >> So I joined ATLAS in 2003
* In 2003, the detector was almostcompletely constructed
* So, I arrived at LAPP Annecy, which was involved in the construction of a sub-detector, which is called the electromagnetic calorimeter, and which serves to measure the energy of electrons and photons
* So, quite naturally, I joinedthis activity, but at that moment the detector construction was already finished
* We exposed modulesto particle beams at CERN to test the final modules,determine their performance
* So, I participated in that,it was in 2004-2005
* And then the calorimeter was lowered down into the cavern, and the electronics was pugged in,I think this was in 2005-2006
* And from then on,until the start of the LHC, in 2009, we were able to study theelectromagnetic calorimeter, to make sure that it worked well in the cavern, that itwas ready for the first collisions
* So, I have participated a lot in this commissioning of the detector, as we call it
* >> And this detector has evidently played a major role throughout the history ofthis discovery
* So when did you decide to get involvedin the data analysis which led to the discovery of this particle
* >> Well, early on, becauseworking on the electromagnetic calorimeter, it was natural to look at a physics reaction that involved this detector
* So, I got interested quickly in thesearch for the Higgs boson in the channel where it decays into two photons
* And which was actually one of the twochannels where we first saw the Higgs boson
* One of the discovery channels
* >> But evidently, this discoverydid not happen in one day
* It was a long sequence of events
* Can you recall for us how you lived this race for the discovery
* >> Indeed, this happened progressively
* We started to take data in 2010
* But very little
* It became interesting in 2011, when we really arrived at an energyof 7 TeV in the center-of-mass frame
* That is when we started to accumulate data
* The way we worked was that we regularly watched,every few weeks, the distribution of photon pairswe were able to reconstruct
* >> The invariant mass distribution
* >> Yes, the invariant mass distribution, indeed, of photon pairs
* And then, we waited to see if photons could come from the Higgs boson, that their mass starts to peak around the Higgs boson mass
* And that started to bethe case very gently
* That is to say, it really happened gradually
* At the beginning,we did not have much data, we saw fluctuations everywhere
* So, we did not know too much
* And then, at a certain moment, therewas one of these fluctuations, which started to somehow deepen
* >> And which stayed always in the same place
* >> Indeed, week after week, itwas always there, larger and larger, in a regular manner
* And then, at a certain moment, we learnedthat our colleagues from the same experiment, who worked on another Higgs decay channel,the one into leptons, saw a fluctuation, which started to grow at the same place like ours
* So, at this moment, we started toР Р†Р вЂљР’В¦ >> You started to believe it
* >> Р Р†Р вЂљР’В¦yes, to believe it
* Exactly
* And in December 2011, there has been a seminar
* >> Here
* >> Yes, here at CERN, where for the first time we announced that we started to seethe premise of the Higgs boson
* The evidence was too weak at the timeto really announce a discovery
* But there was serious premise, which was confirmed on July 4, 2012 when we really announced the discovery, because then it wasР Р†Р вЂљР’В¦ >> Time to celebrate
* >> Yes, right
* >> Above all here at CERN, where there was a grandiose meetingwith the forthcoming Nobel laureates for this mechanism, with Peter Higgs andFranР вЂњР’В§ois Englert
* >> FranР вЂњР’В§ois
* FranР вЂњР’В§ois who
* >> Englert
* >> Englert
* Yes, Englert, thatР Р†Р вЂљРІвЂћСћs it
* So with the dataaccumulated until today, we are relatively sure that we reallydeal with a Higgs boson, arenР Р†Р вЂљРІвЂћСћt we
* How do we know that it is really a Higgs boson and not something else
* >> Well, we study its properties
* The Higgs boson was predicted by the Standard Model since 1964
* >> Yes, right.>> And we knewР Р†Р вЂљР’В¦ >> So, everything was known except its mass, wasnР Р†Р вЂљРІвЂћСћt it
* >> Exactly, we knew everything about it, except its mass
* And the fact that it existed
* So, once we found that it exists and that its mass was measuredР Р†Р вЂљР’В¦ >> Р Р†Р вЂљР’В¦125 Gigaelectronvolts, just to quote itР Р†Р вЂљР’В¦ >> 125 yes
* So, from the moment whenone knew the mass, everything was predicted, like all its couplingswith other particles
* So, by measuring the number of timeswhen it decays into two photons, into four leptons,or into other final states, one verifies if this corresponds exactlyto the prediction of the Standard Model
* So, today this is the case, but still with a largeexperimental uncertainty
* That is to say that we measure these couplings to roughly 15% accuracy
* >> OK
* >> So, there is still some margin
* >> But at this precision, it iscompatible with this hypothesis that it is a Higgs boson
* >> Yes exactly
* We have also verified the quantum numbersof the Higgs boson, its spin, its charge, its parity, etc
* >> With charge zero and spin zero
* >> Right.>> Very probably spin 0, I believe that spin 1 is practically excluded, isnР Р†Р вЂљРІвЂћСћt it
* >> Spin 1 is already excluded by the simple fact that we observe that the Higgs decays intotwo photons
* >> Yes!In fact, thatР Р†Р вЂљРІвЂћСћs true
* >> And afterwards we have excluded spin 2,which is really exotic
* That way we have excluded that it could bea graviton, instead of a Higgs boson
* Here we are
* Rather easily too
* >> OK.So what does it change
* There has been a lot of noise made around the discovery
* What does it change for aphysicist like you
* Did this, the proof that this effect exists, did this change your paradigms
* >> Well yes
* This means that what has been explained to me at university, that the mass of elementary particles, that it is not an intrinsicproperty, but that particles are massless, but theyacquire a sort of effective mass, because when moving, they aresort of slowed down by the Higgs field,which fills the vacuum, this is something completely counterintuitive,you learn it at university, but the day that you really seethis mechanism at work that is when the revolution, for meat least, really happened in my brain
* It is at the moment when wediscovered the Higgs that I told myself: but, this isthus really the mechanism?
* And it was really then that I thoughta bit more intensively that this was a revolution
* >> We all shared the same thought
* To abandon this well rooted notion, that mass is an intrinsic property,that particles are born with, and replace it by a coupling constantto an ubiquitous field, that is a big step
* >> That is a big step
* Yeah yeah, it really is an interior revolution
* >> So, what does this have to do with the mass of the trolley which one pushes
* >> Well, nothing
* Haha, nothing at all
* >> That is where our world decouples a bit from everydayР Р†Р вЂљРІвЂћСћs world, yeah, yeah
* >> Yes, as I already explained in the previous module the mass of ordinary matter,the gravitational mass and the inertial mass are givenessentially by the mass of the nucleus, which has nothing to do with the massof electrons and quarks
* So, what will follow now
* Why does one continue when one has already completed the Standard Model
* One could stop there, no
* Why does one continue experiments like ATLAS
* >> There are plenty of good reasons to continue
* >> Give us some, please
* >> So
* We have there this Higgs mechanism,which is a complicated mechanism, to answer the question: what is the massof elementary particles
* We have answered this question, but at the same time, we have opened lots of new questions
* So, the existence of this field in thevacuum poses lots of questions
* It poses a lot of problems
* It is in fact funny, because one shifts the problem:one poses a first question, one answers it, but inanswering it, one puts a new question
* >> One has shifted the intrinsic mass to a coupling constant, that one must now predict or explain.>> Exactly
* And then the mere existence of thefield is problematic
* Because this field is fluctuating,it receives all kinds of radiative corrections, and thus,it should not be the way it is
* That is already a first reason for usto think that we have not understood everything, and that we must continue to make collisions to understand this mechanism a little better
* So this, by the way, is really a question linked to particle physics
* But there are plenty of other observations,which are more linked to the Universe, like the existence of dark matter and dark energy which correspond to no less than 95%of the contents of the Universe, and of which we do not know the origin,and which are not at all explained by all the particles we have seen todate at accelerators
* So we know from the start that we must still find thingsthat we do not know yet
* Thus, we continue to search
* >> To stay with the Higgs just a little more, we do not even know, as far as I understand, if it is the onlyparticle with these properties, do we
* There could be several.>> Absolutely
* In particular, to relieve the problems which the Higgs boson brings to the Standard Model, which predicts only one, one has invented, for example,a solution to these problems which is called Supersymmetry
* This is one of the solutions, there are several, but in this framwork >> It is not my favorite one, but be it
* >> It was my favourite one, I think, before the LHC started, but by now it is in bad shape, because we have still not seen it,but OK
* So this is one extension of the Standard Model, where one effectively predicts other Higgs bosons
* Where there are even five, neutral ones and charged ones
* At minimum
* So yes, we continue to search forother Higgs bosons
* >> It is for that reason that one has now increased the energy by practically a factor of 2, where one is now
* During the whole year, you have experimented at a total energy of 13 teraelectronvolts
* Is there still more margin, concerning either the luminosity or the energy of the accelerator
* >> So, with the LHC energy one is practically at the maximum
* The theoretical maximum, the energy for which the LHC has been constructed was 14 TeV, and we are now at 13 TeV, I believe it is quite complicated to arrive at 14.>> And I believe it would not make a big difference, it is just 10% more
* >> Right, it will not make a large difference,we have thus arrived at the maximum of the LHC as far as energy is concerned.In terms of luminosity, clearly, there are improvements and there isalready what we call upgrades, foreseen in the future,to strongly increase the luminosity, so as to accumulate 100 times morestatistics, which is what will happen
* And then afterwards, to go to higher energies, means really to construct a new accelerator and that is for the longer term,we talk about several decades here
* There are projects on the tableto do that
* >> We will  certainly dedicate another MOOC to this great project, which has a nickname, it is called FCC for the moment
* >> Yes
* >> So, thank you, Sandrine, for this interview
* It was very interestingto see how someone who has had a rather important role inthis discovery has lived it
* Thank you very much.


--- SKIP ---: 01_7-1-the-world-beyond-the-standard-model.en.srt


--- SKIP ---: 01_7-1-the-world-beyond-the-standard-model.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_7-1-the-world-beyond-the-standard-model.en_SENTbySENT.txt
* [MUSIC], In this seventh module, we'll discusssearches for new phenomena beyond the known ones described by the StandardModel, and covered in previous modules
* We're going to remind youwhy we need new physics
* We will explain how we render hadroncollider data usable for searches and we will discuss examples, split in two categories,based on the general characteristics of how new phenomena wouldmanifest themselves
* In this video, we will describe thetheoretical limitations of the standard model and talk about new theories thathave been proposed to overcome them
* After watching this video, you will know which are the open questionsthe Standard Model leaves unanswered, how the theories are attempting toanswer them using a particular theory as an example and where we stand in oursearches, using the hadron colliders
* The Standard Model is our starting point
* It describes the world as we know ittoday introducing matter particles and force carrier particles, the gauge bosons
* Matter and forces have beenintroduced in module 1 and detailed in modules 4 to 6
* All these particles have beenobserved experimentally, the last one being the Higgsboson a few years ago
* This was explained in module 6
* The precision with which the StandardModel describes our world is really astonishing
* For example, here you can seea representation of the cross sections with which various processes occur at LHC, measured by the Atlas experiment for various center of mass energiesof the colliding protons
* More importantly, note how this comparesto the Standard Model theoretical prediction represented by the solid lines
* For a huge range of production rates, the theory agrees surprisingly well withthe measurements on our collision data
* Despite it's great success, the StandardModel remains a piece in a bigger puzzle
* It leaves, in fact,many questions unanswered
* The Standard Model does not explainwhy the Higgs boson is measured to be so light
* Quantum corrections to itspropagator like the ones shown here, ought to push its massto much higher values
* The Standard Model does not explainalso the observation that the stars in the outskirts of the galaxies rotatemuch faster compared to theoretical predictions, which indicates the existenceof a new form of matter, the dark matter
* The dark matter will beexplained in video 8.2
* Experiments show that the strong andweak forces become weaker and that the electromagnetic force becomesstronger as the energy increases
* We have introduced thisphenomenon in video 5.4
* This is a good indication thatat incredibly high energies the strength ofthe electromagnetic, weak and the strong forces is probably the same
* The Standard Model, however, does not provide a unification ofthese forces at very high energies
* What is really happening there
* A lot of thought hasbeen given to this and other problems the StandardModel comes with and ways to mitigate them have been attemptedby theorists all over the world
* Theorists have come up with manytheories or models, in many variants, trying to address one or more problemsof the Standard Model at a time
* In some of them, they introduce extraspace-time dimensions as a way to explain why gravity is a much weaker forcethan the other fundamental forces
* In such theories, hypothetical forcecarrier particles called gravitons could be disappearing into extradimensions after having been created for example at the proton-protoncollision of the LHC
* There are many other theories andmodels that introduce new particles or interactions
* Common in many of his theories isthe presence of new heavy bosons, similar to the W and Z bosons,denoted as W' and Z'
* How we search fora Z' boson will be explained in video 7.3
* A large theoretical framework ofbeyond-the-Standard-Model physics that has been developed in the last decades issupersymmetry, also know as SUSY
* Supersymmetry is one ofthe most discussed and studied extensions of the Standard Model
* It imposes a symmetry betweenthe spins of forces and matter, which does not existin the Standard Model
* The Standard Model only hasfermionic matter and bosonic forces
* The symmetry requires that therebe a supersymmetric partner to all particles in our periodic system
* They are so-called superpartners
* However, we already know thatsymmetry is a badly broken symmetry
* The superpartners,if they exist at all, must have very different masses to the knownparticles in our periodic table
* Supersymmetry is supposed to be solving allof the Standard Model problems, at once
* Let's take the first open question wetalked about, the Higgs mass problem
* The calculation of the Higgs masswithin supersymmetry has extra loop terms coming fromthe extra particles it introduces
* These terms could cancel the largeterms in the calculation, leading to a Higgs mass that iscompatible to the experimental result
* The lightest superpartner can be neutral,stable, and weakly interacting with matter, becominga perfect dark matter candidate
* And if supersymmetric particles wereincluded in the Standard Model, the strengths of its three forcescould have the same exact strength at high energies,as in the early Universe
* Supersymmetric particleshave been searched for at lepton and hadron colliders formany decades now, but they remain elusive
* We show here limits for the mass the gluino, the superpartnerof the gluon, obtained in a specific supersymmetric model at the latestthree generations of hadron colliders
* The available parameter space for supersymmetry becomes increasinglyconstrained by the experimental findings
* The case is similar formany new theories and models
* Despite the fact thatthere are no hints for new physics in the colliderexperiments today, the urge to find newphysics is always present
* And it is the reason whyhigh-energy physicists keep on seeking an anomaly in the data
* This concludes the firstvideo of this seventh module
* In the next video, we will describe thetools physicists are using to make sense of the data collected at hadron collidersin order to produce physics results and search for new phenomena
* [MUSIC]


--- SKIP ---: 01_7-2-sifting-chaff-from-the-wheat.en.srt


--- SKIP ---: 01_7-2-sifting-chaff-from-the-wheat.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_7-2-sifting-chaff-from-the-wheat.en_SENTbySENT.txt
* [MUSIC] In this module, we discuss searches for new phenomena beyond the known onesdescribed by the Standard Model
* In this video, we will talk aboutthe life cycle of a collision event
* From the time the event is producedin the heart of a detector, until it gets ready to beprocessed in a physics analysis
* After watching this video, you will know why we trigger on physicsevents in the collider experiments
* How we translate the analog and digital signals of the detectorsto physical objects that we associate withStandard Model particles for the events we have triggered on
* And how we deal with the large amounts ofdata that are produced in the collider experiments
* All that in connection to what weneed to search for new physics
* As you already learned in module 3, proton bunches each containing hundredsof billions of protons collide at the LHC in collision points whereexperiments are installed
* This is one of the general purposedetectors of the LHC, the ATLAS detector
* We have already gone through its elementsand their functions in video 3.10a
* If you take a look at the transverseview of the detector you will see that it has an onion structure
* It is made up of various layersof different detectors
* An inner detector inside a solenoidused for tracking charged particles
* Calorimeters for electromagnetic andhadronic shower measurements
* And a muon spectrometer intoroidal magnetic field, for muon momentum measurements
* Proton-proton collisions resultin many particles which decay to the lightest elementary particlescompatible with their quantum numbers
* These leave their signatures in thedetector as digital and analogue signals, which reconstruct as objects that weassociate with elementary particles
* So the particles we reconstruct in thedetector are electrons, and photons, and muons and quarks, andgluons as particle jets
* Details about the detectorresponse to various particle types are given in video 3.10a
* Events that contain sufficientlyinteresting features to be further analyzed are triggered on andstored for further processing
* These events go throughevent reconstruction
* To ensure an accurate measurement of theproperties of the reconstructed objects, a calibration procedure is applied
* Calibrated objects are now ready foranalysis
* In our analysis, we need to compare ourdata to theoretical calculations
* To achieve this, event simulations calledMonte Carlo simulations are performed, which create artificial events basedon a specific theoretical assumption
* With these components in place,reconstructed and calibrated data on one hand, and data simulated according totheoretical predictions on the other hand, we are ready to search fornew physics in our data
* But let's first understandthese components better
* And let's start from the trigger
* What does this actually do
* The LHC is colliding proton buncheswith a maximum rate of 40 MHz
* Each event recorded by theexperiment, containing all digital and analog information from the detector, has a data size of about one megabyte
* So saving all events would lead toabout 40 terabytes of data per second
* This is a huge amount of data to store,but also to process
* Furthermore, most of these eventsonly contain known physics, so we need to select which of them to keep
* This is where the trigger system comes in
* The trigger system of the largemulti-purpose experiments consists of two main components, a hardware based one anda software based one
* The trigger system is builtto be extremely robust and fast as it needs to take a reliabledecision in a very short time
* The trigger helps the selectionof interesting events, but also applies upper limits inthe number of events we select after each of its steps
* Triggering on events that contain newphenomena is an extremely big challenge
* We don't know a priori howthese events would look like
* We therefore have to build our triggerselections generic enough to ensure we don't lose anything interesting, as events we don't trigger onare are simply lost forever
* For events that were triggeredthe detector tells us about the elementary particles that were createdin the collision process as well as their properties
* Typically most of these particles arerelevant in the searches for new physics
* And we will see why in the followingvideos of this module
* An overview is given in video 3.10a
* Here, we summarize the detector responseto the main types of particles
* Electrons and muons both leavetracks in the inner detector
* The electrons are reconstructedby matching the track with the electromagnetic shower
* For the muon, the inner detector track is matched toa muon track in the muon spectrometer
* Photons, being neutral,leave no track in the inner detector
* And are therefore associated toan electromagnetic shower with no track pointing to it
* Quarks and gluons are much morecomplicated objects to reconstruct
* They can't live by themselves
* They have to exist in bound states,as was already explained in module 5
* They hadronize and are therefore reconstructed inthe calorimeter as a hadronic shower
* Algorithms scan the calorimeterdata in order to identify the most significant energy depositions,corresponding to quarks or gluons
* The resulting objects are the jets
* It's worth pointing out thatthe dominant process resulting from a proton-proton interaction isthe production of quarks and gluons
* Therefore jets dominatethe detected final states
* Neutrinos do not interact with a detectorand therefore escape undetected
* However, we can getinformation about neutrinos using the knowledge thatin the transverse plane, because of conservation of momentum, the vector sum of the momenta ofall the objects has to be zero
* So neutrinos are associated with amissing momentum in the transverse plane Any neutral andweakly interacting particle, such as dark matter candidates,will in fact behave just like neutrinos
* And will be identified as missingtransverse momentum in the detector
* Missing transverse momentum is extremelyimportant in our searches for new physics
* W, Z, Higgs bosons, top quarks, and tau leptons decay immediatelyto elementary matter particles
* And we reconstruct themthrough their decay products
* In a detector, we can thereforeobserve various event topologies
* And based on their characteristicswe can classify the events
* This is in fact what we are doingalready at trigger level
* We are running algorithms thatperform simplified reconstruction
* And based on the characteristics ofthe events, we accept or discard them
* For example, events with high momentumobjects, or large multiplicity of objects
* are accepted by the trigger forfurther processing
* Events with only low energy particlesare not generally accepted, as these are of no general interestsince they correspond to low q^2 processes
* It would also be impossible to store and process those as theyare the most common ones
* Despite the fact that we are finding waysto reduce the amount of data we need to process, we are still generatingincredibly large amounts of data
* Such large amounts are needed to ensurethat the rarest processes will be produced and saved in our data
* Such would be processescoming from new physics
* This data gets reconstructed andcalibrated as we said
* It is the products of thisprocess we are eventually using without ever discarding the original data, since we often need to reprocess them to,for example, improve reconstruction or calibration
* In order to make the best useof the large amount of data, we use sophisticated methodologies, such as machine learning techniques or other statistical methodswhich are often CPU intensive
* This adds to the computingneeds of the LHC experiments
* It is not only data and simulation storagewe need, but also processing power
* This is a combination thatcreates a great challenge
* This challenge is being addressedusing major innovations in computing, such as the computing grid
* Numerous computing centers in universitiesall over the world are interconnected, forming a computing grid
* They receive copies of the data
* And give the capability toscientists to run their analyses processes on this grid in an automatic andtransparent way
* Research and development in the computingdomain is in active progress
* And the task is alwaysextremely challenging and rewarding at the same time
* This concludes this lecture
* In the next video we will talkabout a specific type of searches
* The so called bump searches
* [MUSIC]


--- SKIP ---: 01_7-3-hunting-peaks.en.srt


--- SKIP ---: 01_7-3-hunting-peaks.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_7-3-hunting-peaks.en_SENTbySENT.txt
* [MUSIC] In this module,we will discuss searches for new phenomenon beyond the known onesdescribed by the standard model
* In this video, we will talk about bump hunting
* After watching this video, you willknow how we look for new resonances in hadron collider data
* How such signal choice led inthe past to important discoveries
* And the impact of statistics for searches
* We use the data we collect in hadroncolliders for measurements of processes predicted by the standard model andfor searches for new physics
* We typically measure the cross-sectionof a process, the mass of a particle, or other properties
* The searches are typically splitin bump searches or tail searches
* Measurements always precede searches
* It is the confidence that weknow well the standard model and what it predicts thatenables us to look beyond
* One of the things we measure in our datais the rate of production of a specific process which allows us todetermine its cross section
* It is given by the formula you havealready seen in previous videos
* The cross section of the process, forexample production of a Z boson, times the branching ratio for a specific decay,for example to a di-muon pair, is equal to the number of events correspondingto the exact same process divided by three numbers that remove biases relatedto the way the measurement is performed
* The acceptance, indicating the fractionof signal events passing selection requirements we're applying to the data
* The reconstruction efficiency of therelevant objects, muons in our example, and the integrated luminosity indicating theamount of incoming particles we have used
* In the numerator we have to subtractfrom the total number of events the expected number of background events
* These are the events producing the samesignature, a di-muon pair in our example, but resulting from other processes,different to our process of interest
* The Z boson was discovered inproton-antiproton collisions at CERN in 1994 as a small bump around its massvalue as shown in the left plot
* What constituted a major discovery backat the time, is a well established process now, for which we can make precisemeasurements and measure properties, such as the cross-section
* The plot on the rightshows how a mass peak for Z bosons decaying to two muons lookslike in early ATLAS data back in 2010
* Despite the small amount ofdata available at that time, it is remarkable how this compares to thesame topology when the Z was discovered
* This established the lepton pair signature as one with which many particleshave been discovered over time
* It is one of the key signatures we use inhadron colliders to search for new peaks
* Primarily, in the high mass region now
* This is how the muon pair massspectrum looks like in ATLAS
* starting from just belowthe Z mass peak and extending up to the highestvalues we have data for
* The blue area indicatesthe contribution to this distribution from a Z boson decaying to two muons
* This is the dominant processin the whole spectrum, and especially in the peak at the Z mass
* Other colored areas indicate otherstandard model contributions to the spectrum
* The black points correspond to data
* Expected contributions fromthe standard model have been scaled by the same integrated luminosityas for the data we have used
* One can see from this plot, that the datamatch very well the distribution expected from the standard model alone
* Presence of a heavy ZР Р†Р вЂљРІвЂћСћ boson would manifest itselfas a bump in the tail of the distribution, shown here with simulated rates forthree different possible masses
* In the absence of any bump,limits are set on the masses and production cross sections ofthe heavy Z bosons
* To increase the numberof events in the tails, we try to use as manyfinal states as possible
* A natural one in this case,is the electron final state
* Here is the invariant spectrum ofelectron-positron pairs from ATLAS
* Despite some differences,the picture is very similar
* Everything we measurecarries uncertainties
* These originate from both systematiceffects associated with our methods and the limited available statistics
* Searches are also affectedby uncertainties, though statistical uncertaintiesare more important in this case
* Our searches typicallyimprove when using more data
* This is demonstrated in this slide,where compare the lepton pair spectra with luminosities differing bya factor of roughly 100
* The heavy Z boson search has notgiven any hints for new physics yet at hadron colliders
* Other bump searches have beenmore successful in the past
* A very well known one is the Higgs search, which was effectively a bump search
* ATLAS and CMS scientists looked for a bump in the photon pairinnvariant mass spectrum
* We have already seen thisexample in video 6.12
* It is interesting to see inthis demonstration how more and more statistics make a differencein the picture of the spectrum, and lead to a discovery
* Beyond the Higgs mass, the photon pair massspectrum is continuously scanned for new bumps that could indicatethe presence of new phenomena
* A potential bump was hinted in the 2015data at the mass of about 750 GeV
* The significance of the excess was low, so the search was notconclusive at that point
* The spectrum was scanned again whenmore date became available in 2016
* The excess had not increasedproportionally to the increasing luminosity
* It was thus concluded that the bump hadbeen due to a statistical fluctuation
* You see that a firmdiscovery is difficult to make, and strict requirements onthe significance of a convincing signal must be respected before concluding
* This concludes this video
* In the next video, we will discussanother type of searches, tail searches
* [MUSIC]


--- SKIP ---: 01_7-4-hunting-tails.en.srt


--- SKIP ---: 01_7-4-hunting-tails.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_7-4-hunting-tails.en_SENTbySENT.txt
* [MUSIC] In this module, we discuss searches for new phenomena beyond the known onesdescribed by the standard model
* In this video,we will discuss searches for tails in characteristicevent distributions
* This type of searches are, for example, typically used in searches forsupersymmetry
* After watching this video, you will know, how we typically search forsupersymmetry in hadron colliders
* What is the main challenge of researches in the BCproton-proton collision environment
* And, where we stand in our search forsupersymmetry and new physics in general usingthe ATLAS experiment as an example
* We are typically searching for new physicslooking for bumps on a steeply falling spectrum or looking for enhanced tails inthe distribution of a relevant quantity
* We already talked in the previousvideo about bump searches using the heavy Z boson as an example
* While this type of searchesis very intuitive and convincing in case of a positive result, such bumps are not easy to identify inthe case of supersymmetric particles
* Supersymmetric particles decay incascades, generating long decay chains which make it difficult toidentify a resonant signature
* Given the large multiplicity andvariety of particles in the final state, we are typically looking for anenhancement in the tail of a distribution
* Relevant distributions can be relatedto the multiplicity of a specific type of object, for example jets, orto missing transport momentum which in many variants of supersymmetry isenhanced by the emission of neutralinos
* These are the lightest supersymmetricparticles, neutral and weakly interacting, escapingthe detector just like neutrinos do
* In a SUSY search, we are therefore looking for signals that way where a relevant quantitycan be the missing transverse momentum
* The standard model backgrounds,given the large number and variety of objects involved in thesesearches, are very complicated to estimate
* For background determination, we are using data-driven methods combinedwith simulation-based techniques
* We use standard model processes withsimilar characteristics to verify that the detector response to an assumedsignal properly simulated is, indeed, as expected
* In this type of searches, the user of multivaried discriminanceis not uncommon in attempts to achieve a more powerful discrimination ofthe signal with respect to the background
* To increase sensitivity in models thatinvolve large multiplicity of b quarks in the final state likethe one shown on this page, we reconstruct jetsoriginating from a b quark
* We use the knowledge thathadrons containing b quarks travel a short distance insidethe detector before decaying
* Stable hadrons, on the contrary, comedirectly from the proton-proton vertex
* We also reconstruct top quarks from theirdecays using their kinematic properties
* The top quark decays to a b quark anda W boson before forming a hadron andwith a branching ratio close to 100%
* The W boson decays most often to a quark pair
* When the top quark has a large momentum, its decay products are more collimated,as shown in this picture
* At high top quark momenta, some of the jets cannotbe disentangled from each other
* It is therefore common to definewider jets, called fat jets, which capture the products of the decayof a high momentum top quark
* We can therefore require, for example, the presence of multiple fatjets in collision events, a requirement that can improvethe signal to background discrimination compared to an event selection thatdoes not include such requirements
* You can see in these figures examplesof how final distributions look like
* The filled areas show the standardmodel prediction while the dashed line shows how supersymmetrywould manifest itself
* The black points showthe observed distributions which agree very well withthe standard model prediction
* What is shown here where in fact,two signal regions with the largest excess on the left and largest deficit onthe right of a specific search
* The agreement with the standard modelpredictions is usually even better than what is demonstrated inthese examples
* Getting tails of a distribution right in hadron colliderdata is a very significant challenge
* Many experimental factors canalter the expected distributions, therefore, careful study goes todistributions with similar properties but coming from well-known processes
* This ensures an excellentunderstanding of those factors and the associated systematic uncertainties
* One of the most significant challengescomes from what we call pile-up
* At the LHC,protons don't collide individually but in bunches of hundredsof billions of protons
* This results in multiplecollisions in a bunch crossing leading to several low q^2 reactions
* Distinguishing the hard scattering processfrom the rest and understanding how pile-up affects the distribution ofinterest are both very difficult tasks
* In the hadron colliders, we have achieveda significant level of understanding, having thoroughly studiedthe LHC data collected so far
* Having looked at a very broad spectrumof signatures, we have not yet found any significant excessesthat could hint to new physics
* In lack of excesses,we put limits to the theories and models that have motivated our searches
* That way, we can obtain a global viewof where we stand with our searches and ask theorists about their advice on whichdirection to take in our future searches
* The figures in this slidegive the current picture for all ATLAS searches forsupersymmetry and other new phenomenon
* They are all expressed as lowerlimits on the mass scale that characterizes the process
* You can see we are close toexcluding supersymmetric particles up to 2 TeV in mass
* Despite the fact that supersymmetry andother theories beyond the Standard Model remain elusive so far, the openquestions of the Standard Model are so pressing that it is certainthere is something beyond
* With the increasing amount ofLHC data that is available, we are on the right trackto find what that is
* We are faced with a unique chance tomake a unique discovery at the LHC
* And history has taught us,it may be unexpected
* At the LHC experiments,we are looking forward to that
* [MUSIC]


--- SKIP ---: 01_7-5-hunting-new-physics-with-lhcb-optional.en.srt


--- SKIP ---: 01_7-5-hunting-new-physics-with-lhcb-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_7-5-hunting-new-physics-with-lhcb-optional.en_SENTbySENT.txt
* [MUSIC] So thank you very much, Nico, forbeing here with us for this interview
* Could you tell us a coupleof words about yourself
* >> Okay.Thanks, Anna
* Thanks for inviting me
* So, I'm Nico Serra
* I'm professor at University of Zurich andI work in the LHCb experiment
* >> The LHCb experiment
* Could you tell us how the detectorof the LHCb experiment differs with respect to the bigger,general purpose detectors at the LHC
* >> So, LHCb has been designed andoptimized in order to measure properties of c and c hadrons,Hadrons containing the b and c quarks
* This explains the peculiar geometry, which is similar to the geometryof fixed target experiments rather than onion-like geometry that you cansee at detectors like ATLAS and CMS
* And the reason is that the partonsthat compose the protons, the quarks and gluons, have a muchhigher probability to carry a low momentum fraction of the proton with respect tocarrying a large fraction of its momentum
* Therefore, to producerelatively light objects like for instance b hadrons, the probability is muchhigher to have asymmetric collisions
* This implies that b hadrons are producedpredominantly in the beam direction, forward and backward, andwith a very large Lorentz boost
* So this geometry, therefore, allows to collect a really largestatistics of b hadrons even if covering really small solid angles andoperating at a lower luminosity
* In addition, it has the advantage,since the b hadrons have a large Lorentz boost, decays are really displacedwith respect to the proton-proton interaction
* And these are very bighandles against background
* And in this geometry, we can easilyaccommodate RICH detectors for particle identification
* Particle identificatiob, momentum resolution and vertexresolution are the key feature in order to select the signal over the background
* >> Good, so, you said that the LHCbdetector operates at lower luminosities with respect to otherexperiments like ATLAS, in whose cavern we are right now,by the way
* So that means that thereare smaller event rates
* Does it mean that we do notneed a trigger anymore
* >> No, we do need a trigger
* And starting from the 40 MHzbunch crossing rate, we have a hardware level-0 trigger thatreduces the rate to about 1 MHz
* After that, we run a software high-level trigger that runs a mixture of inclusive andexclusive selections to further reduce the rate
* And recently we had a majorshift in the paradigm of triggering in LHCb
* And this is done in preparation forthe LHCb upgrade, where we will run directly afully software trigger
* So what we do is to buffer eventsin the disk, and to perform online calibration and alignment ofthe detector such that we will run in the upgrade the same event reconstructionas offline with the same quality
* >> That's very interesting, indeed
* Can we can now focus on the searches
* What type of searches do you at the LHCb
* >> So, at LHCb we do searches fornew physics
* But rather than doing direct searchof bumps and tails of new particles, we hunt forthese particles as virtual particles
* So, let me explain this with an example
* For instance, let's considerthe decay of the B_s mesons in a di-muon pair
* This decay is a very rare decay inthe standard model because it is suppressed by the GIM mechanism andalso helicity suppressed
* And its branching ratio is about3 10^-9
* If you have new particles,like, for instance, in supersymmetry,they can enter in mediating this decay
* And they can changethe properties of this decay
* For instance, they can enhance thisbranching ratio by orders of magnitude
* Therefore, you compare what youmeasure with the predictions
* >> If you actually measurethen this type of decay, you can constraintsupersymmetry as well
* >> Exactly
* For instance of all this particulardecays, the fact that we measure a value of the branching ratio that is in agreementwith standard model predictions allows to strongly contains supersymmetry
* Also consider that this is complimentary with respect to directsearches in ATLAS and CMS
* Because since we hunt these particlesas virtual particles, we are not limited by the availableenergy in the center of mass
* So we can in principleconstrain particle that have mass higher thanthe collision energy at the LHC
* >> I see
* Could you explain to ushow such a search is done
* >> So these are rare decays so it's very important the selection
* You have to be efficient in rejectingthe background and selecting the signal
* Then, we attribute the di-muon pair to the B_s, because essentially, we see a massbump in the di-muon invariant mass spectrum
* But the difference is that wedo know what is the mass of the B_s, so we do not have the so called Р вЂ™Р’В«Р вЂ™Р’В look elsewhereР вЂ™Р’В Р вЂ™Р’В» effect
* But you do need to know very well the efficiency of yourdetector and the background
* And you have to know how many B_sare produced originally
* What you do normally is to normalize withrespect to another decay that you know very well with a verywell known branching ratio
* And you choose this decay,such that you can somehow cancel some systematicuncertainties in the ratio
* >> Okay, now you talk about uncertainties
* How do these compromisethis type of measurements
* >> So, first of all we have threetypes of uncertainties in these searches
* The statistical uncertainties likeeverywhere due to the limited statistics
* Then you have the systematicuncertainties
* In this case for instance, a source of systematic would be the limited knowledge of the efficiency or the limitedknowledge of the background
* And in addition, since we compare ourmeasurement with the predictions, we have uncertainties which are due tothe accuracy of the theory predictions
* This is due to the fact that theorieshave to extrapolate from the Feynman diagrams at the quark level, to what happens at the hadron level
* And this involves uncertaintydue to QCD essentially
* >> Okay
* So, do you see any deviations withrespect to the standard model in this channel or elsewhere
* >> So we don't see deviations inB_s -> Р вЂ™Р’Вµ+ Р вЂ™Р’Вµ- but we do see deviations with respectto the standard model elsewhere
* >> Could you tell us more about that,actually
* >> Yes, soone of the things we test at LHCb is the lepton flavor universality in b decays
* So, as the students know, the electron,the muon and the tau, they behave exactlythe same way apart from their mass, which comes from their differentinteractions with the HIggs boson
* But apart of that they behaveexactly in the same way
* So if you have a branching ratio of a B mesondecaying to charged leptons and you factor out the effect ofthe mass in the phase space, their branching ratios should be the same
* If you have a new particles,new virtual particles as I said before, they might couple differentlyto electron, muon and tau and they would spoil the leptonuniversality of the standard model
* So, what we see is exactly a departurefrom this lepton universality, in some B decays and by now, we need more data to becertain of this deviation but it certainly looks like an intriguing pattern we are seeing
* >> Okay, well it is certainly interestingthe breadth of the research program of LHCb
* What else have you discovered
* Could you tell us a bit more about that
* >> Yes, so in addition to search fornew physics, what we do is also to dospectroscopy, to measure properties of particles, of hadrons predicted bythe quark model
* For instance, by doing bump searches,as you do in ATLAS, but at lower masses
* We discover new excited statesof D mesons and B mesons
* And in addition, we also do differentanalysis which are called amplitude analysis that allows us to measurethe quantum numbers of these particles
* For instance, the resonance X(3872) that waslong thought to be a D meson molecule
* We could discard thishyphothesis exactly by measuring the quantum numbers of this resonance
* And also relatively recently,we discovered two particles, which are consistent with being neitherbaryons not mesons but pentaquarks
* So particles composed by four quarks andone anti-quark
* And this was a breaking ground results
* >> That sounds really exciting indeed
* But now how about the prospects of LHCb forthe future
* >> So, most of our measurementsfirst of all are dominated by the statistical errors
* So it means that, in order to exploit fully the LHC potential,we need more statistics
* And therefore we are workingto prepare an upgrade of the LHCb detector to run at higher luminosity
* In addition as I said,in most measurements we do see a striking agreementwith respect to standard model and prediction, butwe also see some deviation
* So our hope is that in the futurewe will reveal a pattern of this deviation that can lead usto the discovery of new physics
* >> The prospects for LHCb to be are reallyexciting from what you are telling us
* So, we really hope that you revealthis interesting patterns indeed
* Thank you very much for this interview, Nico
* >> Thank you Anna, bye.


--- SKIP ---: 01_8-1-the-big-bang-and-its-consequences.en.srt


--- SKIP ---: 01_8-1-the-big-bang-and-its-consequences.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_8-1-the-big-bang-and-its-consequences.en_SENTbySENT.txt
* [MUSIC] Hello, and welcome to this eighth, and last module of our introductorycourse to subatomic physics
* In this eighth module, we will talkabout two mysterious components of the Universe which are dark matter anddark energy
* After following this video you will nowwhat we know about the Big Bang and what were the major steps in the history of theUniverse from its beginning up to today
* Observations indicate that our Universewas created some tens of billions of years ago in what is called a Big Bang and went through an extremelyhot period afterwards
* It then cooled down by expansion, down to its currenttemperature of 2.7 Kelvin
* Here, you see a schematicrepresentation of its evolution
* The features of the cosmological standardmodel as we know it today are primarily based on the following observations
* First of all, the systematic red shiftof spectral lines from distant galaxies which leads to Hubble's law
* Second, the cosmic microwave backgroundwhich corresponds to that of a black body
* The abundance of light elements in cosmicrays and the distribution of large-scale structures, galaxies,clusters of galaxies, etc., and its relation to the anisotropiesof the microwave radiation
* We will walk you through some major stepsof the history of the Universe, and review some of thesephenomena as we go along
* Extrapolation of the currentUniverse backwards in time leads us to an infinite energy-densityconcentrated in a single point
* At the beginning there was thusa singularity, the Big Bang
* You should not be afraid of singularities
* They show up everywhere whenwe talk about volume density when the volume tends to zero
* The total energy of the Universe was,of course, finite at t = 0 and the same as today for all we know
* But the volume was extremely small
* It has been constantlyexpanding ever since
* Be careful not to trust your intuitionwhen you think about expansion of the Universe
* The idea that this is happening relativeto a fixed system of reference, is completely wrong.If you think about it like the explosion of a firecracker in the night sky,you're mistaken
* It is space itself which expands
* There's no way to observe thisprocess from the outside
* And the expansion concerns not onlyany distance between two objects, but any other length, such asthe wavelength of photons, for example
* Through this expansion, the temperatureof the Universe has decreased by the same mechanism that your fridgeis using to cool down your vegetables
* We can only speculate onthe first few 10^-40 s in the life of the Universe
* In this era, the temperature was so high that all forces had the samestrength including gravitation
* In addition, the dimensions were such thatgravity had to work in a quantized way, which we know nothing about
* The homogeneity of the temperaturein the Universe indicates that diametrically opposite regions were incausal contact shortly after this era
* This is not explicable unlessit is assumed that around 10^-37 seconds after the Big Bang, the expansion of theUniverse passed through an exponential and superluminous phase
* It is called a period of inflation
* Its driving mechanismremains to be discovered
* Again, we must not shy away from thisthought, it is permissible by relativity that space itself expands at a velocitylarger than the speed of light
* Indeed, no signal exceeds thisspeed limit including this era
* It is space itself which is blowing up
* After the end of the inflation period,the Universe was filled with a plasma of quarks and gluons andother elementary particles
* The temperature was such thatall particles were relativistic
* Particles andantiparticles were in thermal equilibrium
* At some point during this era, a tiny asymmetry of unknown originbetween matter and anti-matter appeared
* Matter became more abundant thananti-matter by about 1 part in 30 million
* The mechanism actually causing thisunbalance, which is called baryogenesis, remains to be discovered
* [COUGH] This mechanism is responsible forour existence
* Without it,all matter would have annihilated with antimatter
* The necessary conditions forthis operation have been formulated for the first time by Andrei Sakharov
* There are three such conditions
* The first one is that C and CP symmetrymust be violated to objectively distinguish between matter and antimatter
* The second condition is thatbaryon number must be violated so that antibaryons can disappearin favor of baryons
* And third, all of this must happenoutside thermodynamic equilibrium e.g
* in a phase transition, for example, so that anti-matter is not recreatedby the reverse process all the time
* Beyond roughly 10^-11 seconds, we know a little moreprecisely what happened
* In this era, the Universe is sufficientlycooled down by expansion so that the laws of the standard model which we haveencountered in this course are valid
* The energies of the particleswere then comparable to what accelerators can provide
* Around 10^-6 seconds, quarks and gluons combined to form baryons,before this was not possible because the kinetic energy of the ingredientsprevented bound states
* The small excess of quarks caused a smallexcess of baryons over antibaryons
* When the temperature was no longersufficient to maintain the equilibrium between nucleons and anti-nucleons,a massive annihilation took place, leaving only about a single proton orneutron among 100 billion
* A similar process followed at about onesecond, for electrons and positrons, leaving a tiny fraction of electrons
* A few minutes after the Big Bang, the temperature had loweredto some billion Kelvin
* Neutrons andprotons fused to form deuterium and helium, butmost protons stayed on their own
* At some point during this expansioncooling process, energy in the form of gravitational mass began to dominateover the energy of photons
* After some 380,000 years, electrons formedatoms with protons and other nuclei
* Before the ambient photons weresufficiently energetic to ionize atoms when they formed
* At this time, this was no longer the case,photons and matter decoupled
* Radiation released at thatmoment still exists today, it is called the cosmicmicrowave background
* When all dimensions expand,the wavelength of photons also expands
* And the correspondingtemperature decreases
* We call the residual radiationfrom that event the cosmic microwave background because its equivalenttemperature today is 2.7 degrees, the wavelength is thusin the microwave range
* This radiation, therefore, provides uswith an instantaneous photograph of the state the Universe was in380,000 years after its birth
* It is indeed the oldest source oflight because before the Universe was opaque since photons wereobserved when ionizing atoms
* By measuring the wavelength ofthe cosmic microwave photons, one can map the temperatureof the Universe
* This was done first using groundbased microwave antennas
* And then, with specializedsatellites like COBE, WMAP and most recently with the Planck satellite
* The distribution of photonenergy from any given direction exactly follows the one expected foran ideal black body
* The characteristic temperaturesare found to be homogeneous at the level of 100th of a per-mil even fordiametrically opposite directions
* This is the motivation forpostulating the so called inflationary era
* However, there are indeed smallfluctuations around the average temperature, which were caused byregions of slight over- or under-density
* These are probably the seedsaround which the large structures of matter that weobserve today have formed
* Since then, thus, over the longperiod which lasts until today, gravitational attraction has causedmatter to form gas clouds, then stars, galaxies and galaxy clusters and so on
* The details of the structure formationdepend on the type of quantity of matter available- Dark matter may have helpedin this process as we'll see in video 8.2
* Once stars are formed,elements heavy than helium are cooked by nuclear fusionas we learned in module 2
* If one takes stock of the observedcomponents of the Universe, one finds the following
* The total density of matterdeduced from the gravitational potential measuredfrom the movement of stars and galaxies is of the order of10^-27 kilograms per cubic meter
* The total density of baryons, visible orinvisible, both measured and deduced from the well established baryogenesis processis smaller by about a factor of ten
* Visible matter, shining light,concentrated in stars, gas and dust is again less denseby a factor of five
* Most of the matter is thusneither visible nor baryonic
* It is called dark matter
* We will talk about it in the next video
* The rest of the energydensity of the Universe is provided by an even more mysterious form
* It is called dark energy and appears to be currently acceleratingthe expansion of the Universe
* We speak about the little thatis known about it in video 8.3
* But first, we will discussdark matter in the next video
* [MUSIC]


--- SKIP ---: 01_8-2-dark-matter.en.srt


--- SKIP ---: 01_8-2-dark-matter.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_8-2-dark-matter.en_SENTbySENT.txt
* [MUSIC] In this eighth module, we discussthe mysterious components of the universe, which are dark matter and dark energy
* In this second video wereview the dark matter
* After following this video you willknow how dark matter is detected by its gravitational effects
* And how we try to identify its quanta,the particles that make up dark matter
* Among the most compelling evidence forthe existence of dark matter is the observation of the rotationalvelocity v of stars around their galaxy as a function of their distanceR from the center of the galaxy
* Accordingly to Kepler's third law, this velocity is determined by the totalM(R), included within the orbit
* If M(R) became nearly constant outside R_vis,the visible boundary of the galaxy, there will be a decreasein the rotational velocity with the square root ofdistance from then on
* Observation indicates onthe contrary that v(R) remains more or less constant at large R
* This means that there isan invisible mass halo that extends far beyond the optical limit
* Its density decreases withthe square of the distance
* Gravitational lensing is a formidable tool to measure the total mass oflarge astronomical structures, even when this mass does not emit light
* The principle is based onthe fact that light rays follow straight lines in space-timedistorted by the gravity of objects
* In this manner the gravity ofthe object in the foreground causes multiple deformed imagesof the object in the background
* Measuring the deformation of the image ofa galaxy behind the cluster for example, we can calculate the mass ofthe cluster in the foreground
* In this way a kind of tomography of thestructure in the foreground is obtained
* The optical image from the Hubble Spacetelescope on the left shows multiple images of a galaxy inthe background in blue color
* The reconstructed massdistribution of the galaxy cluster in the foregroundis shown on the right
* It demonstrates an amorphousdistribution of invisible mass on which peaks of luminousobjects are superimposed
* The invisible mass dominates the visiblemass of the cluster, as it does for galaxies
* Another convincing indication is obtainedby observing the components of the so called bullet cluster
* It consists of twocolliding galaxy clusters
* Using gravitational lensing andx-ray imaging, we can visualize the behavior of different forms ofmatter after a galaxy cluster collision
* The pink part of this image isare reconstructed from data of the satellite Chandra, observing the intensity ofX-rays emitted by the cluster
* This corresponds to the luminous materialdensity which shows the deformation, the acceleration by friction, and the coalescence which isexpected after such a collision for ordinary matter
* The blue part on the contrary, is the mass densely reconstructedthrough gravitational lensing
* The distribution shows thatthe majority of the mass of the two clusters passes through thecollision without too much interaction
* It is therefore in advance,with respect to the luminous mass
* We conclude from all this evidencethat dark matter accounts for about 85% of the mass of galaxies andtheir clusters
* But this percentage can vary a lot
* A recently discovered galaxy,Dragonfly-44, is even suspected to contain99.9% of dark matter
* It is therefore beyond doubtthat dark matter exists and contributes to the confinementof matter and light in galaxies, and probably also to their formation
* The gravitational behavior of thissubstance is the same as that of luminous matter
* So this is indeed a form of matter, but an unconventional one inthat it shines no light, does not reflect nor absorb it
* If it consists of particles,their properties must be the following
* They must be electrically neutral, elsethey would radiate light
* They should have evolvedat non-relativistic velocity at the epoch of matter-radiation equilibrium
* That's why we speak ofcold dark matter
* And they must interact weakly amongthemselves and with normal matter
* Otherwise the products oftheir reactions will be abundant
* And finally their density must becompatible with the missing mass balance
* The main research methods whichattempt to identify the generic dark matter particlechi are the following
* Search for chi production at the high energycolliders like the LHC according to the profile we just showed
* You will find examples ofthese on the CERN website
* So far researchers have not identified signals, but this line is vigorously by ATLAS and CMS
* And Anna has introduced you toresearch like this in module 7
* Search for interaction of dark matter with ordinary matter where one looks for recoil of a heavy nucleus
* Because of the low rates and tiny recoils, this is done with cryogenicliquid noble gas detector, for example with xenon
* You can find more information onthe website of our colleagues in Zurich
* The search forself annihilation products of dark matter particles which are their ownanti-particles
* Annihilations will give pairs ofordinary particles and anti-particles
* This could result in a detectablesignal in the energy spectra of otherwise secondary and rare cosmic rays like positrons and antiprotons and so on
* Martin and I follow this research linewith the Alpha Magnetic Spectrometer
* We search for products ofauto-annihilation between dark matter particles with our cosmicray spectrometer, AMS, installed on the InternationalSpace Station for several years
* The spectrometer identifies cosmic rayparticles and measures their energy
* It is sensitive to energies betweena fraction of a GeV up to TeV
* It has, so far,collected over 85 billion particles, the largest sample of cosmic raysanalyzed since their discovery more than a hundred years ago
* A result that could be relevant fordark matter detection is the fact that beyond a few tenths of GeVthe fluxes of cosmic positrons and electrons deviate from their normal form
* This is particularly noticeable forpositrons, antiparticles which are rarecompared to electrons
* This clearly indicates that there isa new source of electrons and positrons, with the characteristic energy ofseveral hundred GeV
* The question is whether this is a diffusesource such as the annihilation of dark matter, or a localized source such as one ormore pulsars close to Earth
* These two hypotheses can bedifferentiated by the detection of anisotropies in the arrivaldirection of electrons and positrons
* A higher level of anisotropy isexpected from localized nearby sources
* We will probably be able todistinguish the two candidate mechanisms with future datafrom the AMS experiment
* Also, the rate at which the spectrumfalls back to its normal shape, after the maximum, is full of information
* If the extra source isannihilation of dark matter that mass imposes a well defined upperlimit on any annihilation product
* Here, we show an example ofa dark matter particle mass of 700 GeV in red
* If there are astrophysical sources, the disappearance of the signal will be muchslower, as indicated by the blue line
* We are thus actively fencing in dark matterfrom all sides with experimental searches
* And I hope to still see the dark matterparticle identified during my lifetime
* I am much less optimisticregarding dark energy, which is discussed in the next video
* [MUSIC]


--- SKIP ---: 01_8-3-dark-energy.en.srt


--- SKIP ---: 01_8-3-dark-energy.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_8-3-dark-energy.en_SENTbySENT.txt
* [MUSIC] In this eighth module, we are discussingtwo mysterious components of the universe which are dark matter and dark
* And in this third video,we'll review dark energy
* After following this video,you will know how we know about this new form of omnipresent energy and why itsexistence is still a matter of debate and what are the mainproperties of dark energy
* To understand the signs ofpresence of dark energy, we must visit the expansionmechanism of the universe
* In the late 1920s, Hubble observed that the line spectraof distant galaxies are red shifted
* This is because of the Doppler effectassociation with the recession velocity v
* The wavelength lambda prime observed onEarth is offset with respect to lambda, the wavelength in the rest frame of the emitter.The red shift parameter is called z, equal to Р Р†РІвЂљВ¬РІР‚В lambda/lambda
* Using the redshift to measure the velocityv, and the magnitude as an estimator of the distance r to the emitter, one empiricallyobserves HubbleР Р†Р вЂљРІвЂћСћs law, v = Hr
* Recessional velocities are,thus, proportional to distance with a coefficient calledthe Hubble constant H
* Hubble's law corresponds to a uniformexpansion of all distances including all wavelength by a factor r(t) where r_0 is the current scale att = t_0 which is today
* Without loss of generality, we cannormalize any distance to r_0 = 1
* R then becomes ageneric distance scale
* The Hubble constant is givenby the relative rate of change in R, R_dot/R
* Contrary to its name, H is not constantbecause of the decelerating effect of gravity on the expansion of the Universeand the accelerated effect of dark energy
* Today, we find H_0 roughly equal to 70kilometers per second per mega parsec, with an accuracy of a few percent, although the various methods fordetermining this constant, give somewhat different results,as shown in the plot on the right
* One expresses large,astronomical distances in parsec
* One parsec roughly equals 31 10^12 kilometers, and is defined as the distance at which the meanradius of the Earth orbit around the sun subtends an angle of one arc second.The evolution of the Universe is dominated by the actionof gravity since early in its history
* It follows the solution of equationsdescribing general relativity
* For a homogeneous and the isotropicdistribution of matter at large scales, it is described by the Friedmann equation
* The first term containing Newton'sconstant G_N and the mass or energy density rho of matter describesthe decelerating action of gravity
* The constants K andLambda determine the asymptotic evolution
* The cosmological constant Lambdapotentially corresponds to an energy associated with a vacuum,the so-called dark energy
* For now, we neglect this term, although it may dominatethe evolution of the Universe today
* If you're interested in the motivationbehind such an equation, we recommend the smallcalculation in video 8.3a
* The constant K corresponds to an intrinsic curvatureof space generated by its total energy
* There are three distinct cases
* For K = -1, this correspondsto a total positive energy
* This case describes a so-called openuniverse that extends to infinity with R-dot tending towards one forlarge t
* In this case, the curvature term -K/R^2 is positive
* For K = +1, corresponds toa negative total energy, a closed universe with negative curvature which extendsto a maximum radius and then shrinks
* The special case,K=0 is that of a s0-called flat universe,where the kinetic and potential energy are equal, the totalenergy and thus the curvature are zero
* The rate of expansion tends towards R-dot = 0 on the long term
* An inventory of the contents ofthe Universe today shows a remarkable density similar to the densitycorresponding to K = 0
* So we neglect this term
* Integrating the Friedmann equation forthe special case K = Lambda = 0 and in non relativistic approximation, asimplified expansion equation is obtained
* From today's value of Hubble's constant,we can derive t_0, the age of the Universe, whichcorresponds to 9.4 Gy
* This is well below the edgeof the order subject we know about which varies between 11 and14 Gy
* Obviously, a negative K or a positivevalue of the cosmological constant Lambda would lead to an increased t_0 prediction by the Friedmann equation
* Since K is roughly equal to 0, we need a substantial amount of darkenergy to obtain a reasonable age prediction
* For K = 0 and the cosmological constant Lambda not equal to 0, the Friedmannequation acquires the last term
* It corresponds to a constant energydensity associated with the vacuum itself
* This corresponding energy densityadds to the matter density as shown in the second equation
* Considering the equation of state,we see that this energy exerts an internal pressure on the expansion of the Universeas shown by the third equation
* If Lambda is larger than zero,this pressure is negative and accelerates the expansion opposingthe decelerating action of gravity
* To understand how we measure the expansionvelocity in the past, we must remember that the photons reaching us from a largedistance were issued in a distant past
* By observing the red shiftof a characteristic line, we can measure the velocityof the emitter in the past
* And it can be compared to that of a closersource from photons emitted more recently
* For this,we need an estimate of the distance z, which is independent of the red shift
* The observed flux F, of photons, can beconverted into the luminosity distance, D_L, if the emitted luminosity L is known
* The luminosity distance is relatedto the astronomical magnitude m, by the numerical conversiongiven in this formula
* For non relativistic recessional velocity,we have v roughly equal to z
* For a constant Hubble parameter,we thus expect a relationship m(z) = a + b log10(z), betweenthe magnitude m and the red shift z
* Provided one can identify a standard kindof source with constant emitted luminosity L, one can then find a sample of m_iat sufficiently different z_i and test this proportionality
* Thermonuclear explosions of type 1Asupernova are such a standard candle
* Their brightness can be derived fromthe properties of the light curve, i.e
* the photon flux over time
* Measurement results are shown here,with the log of the red shift, ie, the recessional velocity as the ordinate,and the magnitude as the abscissa
* Turns out, that forlarge distances, the recession of velocity is always less than what isexpected for a Lambda equal to zero
* The expansion of the universeis accelerating
* It is now faster than it was in the past
* For this discovery,Perlmutter, Schmidt and Riess have received the 2011physics Nobel Prize
* But a word of caution is required here
* The methodology providing evidence for dark energy is continuouslyunder scrutiny
* In a recent paper, Subir Sarkar and his collaboratorshave analyzed a larger sample of sources
* This plot shows the difference ofthe measurements from the the straight line in themagnitude red shift relation that we've shown in the previous slide
* It is clear that the spread of the datais comparable if not greater than the expected effect of dark energyindicated by the blue line
* No dark energy correspondsto the dashed red line
* Th authors conclude that a Universewithout dark energy is improbable of the order of 0.3% butit is not impossible
* The universe today therefore probablyconsists of 26.8% Dark Matter, 68.3% Dark Energy totalling 95.1%
* This leaves place for nomore than 4.9% of ordinary matter
* The density of dark energy is very low
* It's of the order of 6 10^-27 kilograms per cubic meter, such that the total Solar system up to theorbit of Pluto contains only a negligible amount compared to the Solar mass
* But since the distribution is uniform, dark energy dominates the evolution ofthe Universe at the cosmological scale
* Different forms of darkenergy have been proposed
* And energy density, filling spacehomogeneously, like a cosmological constant Lambda or custom designed scalar of fieldswhich generate this effect dynamically
* For a more in-depthdiscussion of dark energy, I refer to the article by Ruth Durercited at the bottom of this page
* With this, we have almost concludedour tour of subatomic physics
* If we compare to the reductionist programof particle physics, that is to understand the complete Universe based onits microscopic properties, we realize that we have understood a lotabout a small fraction of what's there
* The many parameters of the standard model,the masses or the Higgs couplings, the couplingconstants to forces, mixing angles, etc ought to be fixed by a moreprofound layer of theory
* Unknown ingredients, dark matter onthe side of matter, dark energy and inflation on the side of forces, clearly indicate that much ofthe Universe remains to be discovered
* And, in addition,even how to integrate gravity into our microscopic model ofthe Universe is far from clear
* This leaves enough work forfuture generations of physicists, and why not you
* In the last video of this module, we interview Professor Ruth Durrerabout her vision of dark energy
* [MUSIC]


--- SKIP ---: 02_8-3a-motivating-the-friedmann-equation-optional.en.srt


--- SKIP ---: 02_8-3a-motivating-the-friedmann-equation-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_8-3a-motivating-the-friedmann-equation-optional.en_SENTbySENT.txt
* [MUSIC] To motivate the Friedmann equation, we are going to considerthe movement of mass m at a cosmologicaldistance R from us
* At cosmological scales,the Universe is isotopic and homogenous, such that the test mass will be attractedby a mass M, which is 4Р СџР вЂљ/3 r^3 times the average massdensity rho of the Universe
* Newton's Law gives us thatm times the acceleration of the test mass is equalto minus Newton's constant times the test mass timesthe mass M divided by R^2
* We can reorder this equation to haveall terms on the left of the equal sign
* Let me integrate this second equation
* We get that 1/2 n times the test mass velocitysquared minus Newton's constant times the product of the two massesdivided by R is a constant of motion
* This is equivalent to saying that thekinetic energy plus the potential energy is a constant of motion
* You can easily verify that this is correctby taking the time derivative of this result
* Now, if you set the constant ofintegration equal to -1/2 k and introduce our result for M,then we get this equation
* If we now multiply both sides by 2/R^2,we get that (R-dot/R)^2, which is in fact the Hubble constantsquared, is equal to 8Р СџР вЂљ Newton's constant divided by 3,minus k/R^2
* Now we can still add to this acosmological constant as Einstein did and obtain thus the completeFriedmann equation
* [MUSIC]


--- SKIP ---: 01_8-4-what-hides-behind-dark-matter-and-dark-energy-optional.en.srt


--- SKIP ---: 01_8-4-what-hides-behind-dark-matter-and-dark-energy-optional.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_8-4-what-hides-behind-dark-matter-and-dark-energy-optional.en_SENTbySENT.txt
* [MUSIC]>> Here we are with the last video of the last module of ourintroductory course on particle physics
* And in this last video, we will go into some more depth on the preceding discussion ofdark energy and dark matter
* To do that, we have invited ourselves to a colleague from the theoretical physics department of University of Geneva
* Let me present to you Ruth Durrer,professor of theoretical physics who is a specialist on cosmology, the physics subject which remains most concerned with these two phenomena,thus far inaccessible to experimentation at existing accelerators
* So, at the end of this video, you will understand a bit better how dark matter and dark energy act on the universe that surrounds us
* So, Ruth, I think there is little doubt onthe existence of dark matter, is there
* Or am I mistaken, are therestill people who believe that dark matter does not exist
* >> Yes, there are such people
* Dark matter, as you have already heard in the preceding videos, has been confirmed by only oneinteraction, which is gravity, and by no other, so they ask the question: should our theory of gravitation Р Р†Р вЂљРІР‚Сљ to discoverdark matter, one only needs Newtonian gravitation Р Р†Р вЂљРІР‚Сљ should it bemodified at large distance scales
* There are people who have tried that,and who were able to explain, for example, the fact that the rotational curve of galaxies does not descend like one would expect, ifgravitation obeys KeplerР Р†Р вЂљРІвЂћСћs law
* But even if one can modify gravitation such that one obtainsflat rotational curves also, there is still a lot moreconfirmation for the existence of dark matter
* >> Like gravitational lensesР Р†Р вЂљР’В¦>> Exactly
* >> Р Р†Р вЂљР’В¦the motion of galaxies, and their interactions, like the Bullet Cluster for exampleР Р†Р вЂљР’В¦ >> Exactly
* And if you want to explain all that bymodifying the theory of gravitation, you can for example do thiswith what is called TeVeS, but it is a horribly complicated theory andone makes hypotheses which are much more complex and non-minimal, than to just add a particle
* So, I would say that 99% of the scientists are convinced that dark matter is what it takes and not a modified theory of gravity
* >> And in that case, there should bea particle which constitutes dark matter, and one should be able to seeits interactions, either among themselves, as we try with AMS, or with normal matteras out colleagues try in Zurich, for example, in their underground experiments, or by the artificial creation of this matter,at the LHC for example
* So, up to now, we have notsucceeded to do so, but it is never too late to try
* So, if such a particle existed, what would be the implication for the Standard Model of the existence of an additional particle,which we need to explain this, donР Р†Р вЂљРІвЂћСћt we
* >> Of course, such a particle is beyond the Standard Model of particle physics but there are plenty of hypotheses on the existence of such a particle
* For example, in supersymmetry
* one expects that there be astable supersymmetric particle
* Or one can add a heavy neutrino,to explain, for example, the generation of quarks andleptons in the universe and this could, at the same time, also play the role of dark matter
* A low mass neutrino does not work,because it has too large velocities to be confined in galaxies, etc
* So, we need a particlewith a minimal mass of at least some kiloelectronvolts
* Standard candidates rather havesome hundred GeV of mass
* But what is the interaction of this particle with normal matter
* Of course, we do not know
* If it is comparable to weak interactions,in the coming years one should discover it either at LHC,or with direct or indirect interactions
* But if the interactionis much weaker, if we had, for example a gravitino, which interacts via the gravitational force, we will not discover itby these experiments
* >> But we are still in good hopethat during our own active lifetime we will know of what is consists
* >> Yes, I do hope so
* It is one of these problems, which arewith us since 70-80 years
* >> Since Zwicky, yes
* >> Yeah
* >> So, on the contrary, I have much less hope as far asdark energy is concerned, no
* So, can you share with us your vision of dark matter
* First of all, according to you, what is it
* >> I donР Р†Р вЂљРІвЂћСћt know
* This is the honest answer, we must leave somethings to do for young people, to explain to us
* I donР Р†Р вЂљРІвЂћСћt know what dark energy is
* So, I can tell you that currentdata are in good agreement with the assumption, that dark energy isjust a cosmological constant
* But I will talk a little about how one has discovered the existence of this dark energy
* One has seen that the universe is currently in an accelerated expansion, and not as one had thought, that due to gravitationthe expansion would slow down more and more
* In fact, one has found that,since a while, this slowing down has reversedand has become an acceleration
* And this acceleration, one can explain it, if there is a componentpractically with negative gravity
* So, we need, for example, something which has a very strong pressure, a negative pressure
* Negative energy density is notpossible according to the Friedmann equations which are a consequence of the Einstein equationsР Р†Р вЂљР’В¦ >> Well, we have scratched the surfaceof these equations a little bit earlier in the course, so, if you are no more familiar with this, please watch again the previous video, which talks just about the Friedmann equation
* So, if the famous lambdais the only thing which exists, this would be a property of our universe, which was created together with our universe, wouldnР Р†Р вЂљРІвЂћСћt it
* So, by chance, well,it has the value it has, and we must live with it, no
* >> It is more complicated than that
* The problem is that this lambda,this cosmological constant, must have changed, for example, if the interactions of the universepassed through a phase transition
* >> Yes
* Like inflation, to just name one
* >> For example, during inflation
* And during that transition,the cosmological constant has changed its value, which was 10 to the power 120 greater that the value we measure today
* So, this value requires anenormous fine tuning
* >> I.e
* of the initial conditionsto get there
* >> And most of all thisis not what we call a Р вЂ™Р’В«Р вЂ™Р’В naturalР вЂ™Р’В Р вЂ™Р’В» fine tuning in the sense that in field theory this constant is not protected from corrections
* If one modifies the theory a litle bit,this constant changes enormously, etc
* So, from the point of view ofa quantum field theory, such a constant is very, very unnatural, unexpected, bizarre
* >> So, all of this requires effectively that his field is a quantum field, no
* Is it really necessary that this be so, or could it not simply bea classical field, which does not have a quantum representation,which does not exist in a theory at small scales,does not exist or is not necessary
* >> Well, the cosmological constant itself is not a field, but it is an effective constant, which comes fromthe quantisation of all other fields
* And that the electron is wellrepresented by a quantum field, or the quarks, I believe that youhave discussed that in your course
* So you cannot say that at very small scales,this is not the case
* I would even say that usuallyall fields, even effective ones, even non-fundamental ones, can bedescribed by quantum fields, that they exhibit a quantum natureif one talks about very small excitations
* >> Like phonons in a solid,for example
* >> Exactly, like phononsin crystals
* But here, we have two explanations, which are a little bit more satisfactory, but morecomplicated and also not very attractive
* One is, one adds a scalar field, which is not constant but nearly constant
* And with that, if the fieldis sufficiently constant, one can explain dark energy
* But the difference to a cosmologicalconstant becomes more and more diffuse there
* Another one is that one changes thetheory of gravitation at large scales
* You see, one has tested EinsteinР Р†Р вЂљРІвЂћСћsgravitation for distances beyond a tenth of a millimetre, a hundredth of a millimetre, up to the size of galaxies, and maybe at the distance scale of the universeone must add modifications
* This can be done, there are modifications,for example concerning the graviton, which can have a very small mass
* This mass must also be fine tuned
* But at least the quantum corrections,if one develops a quantum theory of gravitation, are small,they are logarithmic corrections, which do not blow up everything, when one describes the facts by a quantum theory,like the cosmological constant does
* >> I believe that it is, however, correct tosay that this form of energy is not easily amenable to human experimentation, is it
* This is a phenomenon, which really only exists at a cosmological scale, and which stays confined to this domain
* >> If it is a cosmological constant, it is accessible only bygravitational forces
* All other forces are not sensitive to a constant difference in energy
* But, if it is not a cosmological constant, but if it is a modification,lets say, take this example, a modification of gravity,one should be able to also see it on other scales,with very high precision experiments, etc
* Or, if, for example, the graviton had a mass, this would mean that the graviton has five helicities and not only two
* Ans maybe with certain experiments,still gravitational ones, one would be able to excite these other helicities of the graviton
* So, there would be this otherpossibility of see that
* >> Experimental possibility
* >> Yes
* But I would say also, however, that a cosmological experiment isa human experiment
* So, this is not to scale,but the scale tested at LHC is as far from thehuman scale as the cosmological scale
* >> There, I admit, that is true
* >> You agree, Martin
* >> OK
* So, thank you very much for this interview
* I think that it is very important also to indicate like an open windowtowards the future of our profession
* Because the course does not stop here
* It invites you to stay interestedin the forthcoming experimental as well as theoretical progress in the field
* So, I invite you to have eyes and earsopen, for what will happen, and for whatwill probably again revolutionise our field in the coming decades
* Thank you for your attention
* [MUSIC]


--- SKIP ---: 01_kinetics-course-introduction.en.srt


--- SKIP ---: 01_kinetics-course-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_kinetics-course-introduction.en_SENTbySENT.txt
* Hi, and welcome to this coursesequence on spacecraft kinetics
* My name is Hanspeter Schaub and I'm a professor here atThe University of Colorado Boulder
* The sequence will have four components
* The first component we're want totalk about continued mechanics and also rigid body dynamics
* How we developed equations ofmotion from basic principles
* The next component is going to lookat a rigid body of a space craft and study how it's being stabilized
* We are looking at torque free motions andequilibrium exists and which ones are stable
* The third component talksabout gravity gradients
* This is a common method of stabilizingthe space craft without having active feedback
* And we'll be looking at the derivationof this gravity gradient torque, but also the force, its stability,and equilibrium
* The last, the fourth component,is going to look at a spacecraft which has multiple momentum exchangedevice developed
* In fact, you've developed a verygeneral formulation with variable speed control moment gyros
* And then we can simplify the formulationsfor CMGs and reaction wheels.


--- SKIP ---: 02_module-1-introduction.en.srt


--- SKIP ---: 02_module-1-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_module-1-introduction.en_SENTbySENT.txt
* Hi and welcome to the firstsegment of spacecraft kinetics
* In this section we're going to betalking about equations of motion of a space object
* In fact, we're going tostart with basic principles
* We're going to go to a deformable body,something that can change shape, and then we're going to move and freeze it toa rigid body, which is very typical for many a spacecraft mission
* In all these applications, we're studyingangular momentum on how this stuff spins
* We're looking at the kineticenergy of these objects
* And we're also showing you how touse these principles to develop equations of motion
* Why do you need this
* The equations of motion is a fundamentalproperty you have to analytically derive, so then you can demur to simulate it and predict what the spacecraft will actually do
* This is also often used formission analysis tools.


--- SKIP ---: 03_overview-of-kinetics.en.srt


--- SKIP ---: 03_overview-of-kinetics.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_overview-of-kinetics.en_SENTbySENT.txt
* We're going to go to kinetics
* We focused a lot on howto describe orientations
* And there's lots of sets, actually, there's an infinity ofdifferent attitude sets
* And they all have benefits and drawbacks
* Now we're going to workon the full dynamics
* And that means we're going to focuson mass, inertia, forces, torque, that kind of stuff
* And how do we find,ultimately always, omega dot
* That's kind of what we're after,fundamentally
* So, here's some topics, we're going tostart out with a continuous system
* Again, that's from chapter two
* We're going to jump straightto that formulation
* Derive some fundamental properties
* Do everything in a vectorialformat formulation
* That's kind of important and nice
* So some of you may nothave seen this before
* Then we're going to freeze that blobof jelly, basically, into a rigid body
* Some of the things will simplify
* And you have to be very carefulas to which terms simplify
* Momentum, energy, all those thingsthat we use to derive equations
* And we'll talk about the inertia tensor,energetic equations
* We talk about stabilityof torque-free spins, the different equilibrias that we have
* Why does a body happy, happy totumble in one set of direction and then other directions if this goes crazy
* All that stuff will come from there
* Dual spin spacecraft, those are,used to be more common platform
* You still see them occasionally
* But they used to make allthe geosats that way
* With, basically, you want the antennafacing at the earth once per day and with revolution
* because it's a geo.It's always point at us
* And then the other part isspun up at a different rate
* I think Cassini is also a dual spinner
* It's a big antenna platforms thatare spinning at a different rate than the rest
* And there's instabilitythat comes out of this
* So this is just basicallya system of rigid bodies
* So what we've done here isgoing to be a single rigid body
* And then we have two rigid bodies
* Another one that we want toderive is gravity gradient torch
* Then we'll go back to very much f=ma,look at the field equations, expand them
* Why do you truncate
* Because there's simple questions like, I know that if I change my orbit,I will change my attitude torque
* The further I am from the Earth,the smaller that torque will be, because gravity's smaller, so differentialgravity's going to be smaller
* But is the inverse true
* If I change my orientation,do I impact my orbit
* And that's the kind ofstuff we'll see there
* And so,we'll go through in great detail a lot, again in a vectorial formulation andgo there
* But that's kind of the basic dynamics
* Later on in class we will also dospacecraft with n-reaction wheels
* In fact, variable speed CNGs,which then contain reaction wheels
* But that will be at a later stage.


--- SKIP ---: 01_1-continuous-system-super-particle-theorem.en.srt


--- SKIP ---: 01_1-continuous-system-super-particle-theorem.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_1-continuous-system-super-particle-theorem.en_SENTbySENT.txt
* Continuous system, basically jello,blobs of jello, right
* This is kind of whatwe're starting out with
* So we have a dynamical system, that's thisand our every self-respecting dynamics class has to have theseamorphous flying potatoes right
* It's just a general thing and we want tonow compute certain properties of it
* Newton's Law is simply F = MA,written in this form
* You can see
* And now, because I have a continuum, it'skind of hard to do it for the full thing, a blob of Jello, right
* Different things will havedifferent forces acting on it
* So what we want to do is trackinfinitesimal little elements here, and that's my little box that'sDM infinitesimal object
* Just like classic calculus that you'veseen many many times before hopefully
* So df is the force that's actingon the differential element, dm
* R is my inertial position vector, sobig R is the inertial position vector
* Little r is my position vector relativeto the system's center of mass
* So whatever this bulb is you havean infinity of little DM's that all add up to this thing
* They have in common at this instantthat's where the center of mass is so that's a classic location
* We'll be writing all our equationsabout that point so that's it
* That's basically F = MA times that
* So but for F = MA it was importantthat we have an inertia derivative so these dots are derivatives asseen by the inertial frame, and you have to write your positionrelative to the inertial origin
* That's why you wouldn't do little r doubledot, you have to do big R double dot, relative to the inertial frame then dF
* Now these forces,we can categorize them generally
* There's external stuff and internal stuff
* Who can give me an example of an externalforce that might be acting on a spacecraft
* >> Drag
* >> Drag, right, atmosphericdrag is one of them definitely
* Gravity could be an externalforce acting on it
* You could have solar radiation pressure
* You may have your thrusters
* This is a man made object,maybe you have some way to control it
* Now you have to do some stuff
* That's all the external things, so what are examples of internal forcesacting on this blob of jello
* >> Torquers
* >> Actually, good question
* So magnet torquers are actually objectsthat push off the external magnetic field
* I would see them as external [INAUDIBLE]influences acting on these elements
* The element might be inside the craft, butit's still pushing off an external field
* So what would be an internalforce then that you might have
* >> Reactions
* >> Reactions is a good example
* because you have thesefly disks that we put in, sometimes called flywheels orreaction wheels or control movement gyros that are allspinning objects inside our spacecraft, and then they have motors attached thatwill spin them up or spin them down
* That motor is taking the wheel andit's pushing off the space craft
* So as a dynamical system it basicallymeans some part of jello is pushing off the other part of the jello andthat's what cause the spinning
* This would be an internal force forthe system all right
* If you do a free body diagram of just thereaction wheel then maybe we can treat it as an external one on that system
* But here we have space craft jellocould be fuel and all this stuff
* Fuel's another one
* Fuel slash backing back and forth
* Those are all internal forces
* And that will be key because we'llbe talking about internal forces, external forces, andhow do things impact momentum and energy
* And there are some good high level thingsthat are really useful as a spacecraft analysts
* So we're going to breakit off in two ways
* Now if I need a totalforce acting on jello, I have it gazillion dm's,I have to integrate over them
* So if you look at chapter 2 we doa summation because we have a gazillion of them
* And if you have a continuum yousimply replace the summation with an integral sign
* That's really, if you go back and lookat calculus and how you did integrals, you kind of broke it up intolittle bitty chunks and then made those chunksinfinitesimally small
* It's basically this big summation
* So if you're summing up over this,the claim here is the total force acting on this blob is the sum of allthe forces acting on the individual DMs
* Which is simply going to bethe sum of the external forces
* What happens to the internal forces
* >> It blots it, it cancels out
* >> Yeah, which law is that
* >> Newton's third law
* >> Yeah, it's one of Newton's laws, right
* So if you take a wall, and push againstthe wall, the wall is actually going to push back with you exactly the sameamount but in opposite directions
* So as I'm torquing on a spacecraft,applying forces to the wheel, you're getting equal andopposite forces applied to the spacecraft
* When you sum them up all thosethings have to mutually cancel
* So internal forces never contributeto a net force on the system, only the external ones do that
* So I'm sure you've seen that before
* Now some basic properties of jello isany continuum, any dynamical system is whatever the mass distribution is,it will have a center of mass location
* And there's many ways to define it
* I'm going to show youit's at least two here
* One of them is the center of mass isessentially your mass averaged location
* So Rc is the center of mass of this blob
* If you look at R times dm
* You really, you think of it you gotone kilogram, half a meter out
* Two kilograms, a full meter out
* And five kilograms,a half a meter to the left, right
* You would add them up witha distances divide by a total mass
* That's going to bethe center of mass location, if you have this massdistribution on a system
* If it's continuum, instead ofsumming you do integrals of mass, you know,the mass of the object times its location
* And then we divide bythe total mass to get Rc
* So that's a classicdefinition of center of mass, this works forany continuum dynamical system
* Now we can break this up because theseare vectors, the inertial position vector
* So we can say R here hasto be RC pass the r
* Again, this is done ina purely vectorial way
* I'm not saying r has to be expressed inthe body frame or in the inertial frame
* That's a book keepingelement we keep to later
* Right now we're just adding vectors
* Vectors plus vectors and doing with that
* So if you do this you can seethis will actually break up and let's do that one quickly here
* We had that
* Rc + r
* Dm that's the sum of two vectors
* So I'm going to do this, and say okay
* That's going to be Rc dm + rdm
* And my little subscript b that notationis actually a triple integral
* I have to integrate over the entire body
* But instead of writing triple integralswith all the limits, this is a short kind
* I just do one integral with b that meanit understood to be integrating over an entire, whenever this body is,all right
* So we can break these things up
* That's nice
* That should be a vector
* Then there's some simplificationsthat are going to happen
* We knew earlier, by definition,this was M times Rc right
* This term can somebody say howthis is going to be refined
* All right
* Kevin
* >> You'll get RC out of the interval>> Okay
* >> We get big M times R
* >> Yeah this is nothing but the sum of allthe mass elements which is the total mass
* You can get there
* So now Kevin can you explainto me why it's okay to take Rc varies with time and everything
* Why is it okay to takeit outside the integral
* >> because we're onlyintergrating the phase
* >> Right.>> We're integrating over the body
* So when you see these B integrals,think of that, over this body, let's say my center of mass was righthere by the microphone just easy right
* Stop I'm looking at this andgoing at this instant, whatever the mass distribution is,my left hand is part of the system the center of mass for the left hand isstill down here, right, for the system
* That Rc location forthe right hand is also going to be here
* Every element of my body,because it's a continuum, it shares the samecenter of mass location
* So as far as the body integral goes,it's just a constant
* Just like integral of 3 times x
* You pick the 3 outside the integral andjust do integral of x right
* And continue, that's how we can treat it
* So this is just a spatial integral
* Yes rt varies with time but we're doing a spatial integrationover the body volume right
* And that location is a fixed it doesn'tchange depending on if you're looking at the nose of the spacecraft orthe tail of the spacecraft
* It's one system and that systemhas one center of mass location
* So yes that's the reason, andwe'll use this trick several times today
* So if it didn't quite make sense nowhopefully it will sink in more and more
* So you can do all of this
* That gives me MRc Plus little rdm = MRc
* These cancel andyou will have little r times dm = 0
* This is the other way
* If you do your classic sophomorelevel center of mass stuff, you have 5 kilograms here,2 kilograms there, you add them up
* If all your positions are takenrelative to the center of mass
* All these mass times positionshave to sum up to be 0
* That means you've balanced it perfectly
* And that's what it looks like forgenerally speaking
* We have the little r dm's bodyintegrals have to be equal to 0
* That's just a complete 3D versionthat works for any jello
* So good
* So that, from here,a few steps you can prove this
* These are the kind of things I would definitely expect you to be ableto do easily and quickly in an exam
* So if you haven't done much of this,practice
* Now, what we're going to do next iswe're going to differentiate this
* So we're going to take thatdefinition that we just had, the center of mass location,all this is good, and I'm going to take twoinertial time derivatives
* So that means on the left hand side,mass is constant
* I'm not losing orgaining mass in this dynamical system
* And RC, I just have to put twodots over it and I'm done
* This is kind of like homework 3.6that you guys did that had inertial derivatives and stuff
* In vectorial form this is dead simple,two dots and you're done
* The right hand side dm I guessdoesn't change, we're not losing or gaining mass with the system
* This is a body integral,as Kevin was saying
* And so the only thing that varies is r
* So we get big R andit has two dots over it
* But then you go back and look at Newton'sequation that mass times inertial acceleration is the forceacting on that one
* And sothis can be replaced with also the force
* The integral over the DF force and we show that the integral of the DF forceis nothing but the net external force
* You can ignore all the internal forces
* So you end up with an equation thatshould look pretty darn familiar
* Mass acceleration equal to force
* But you've used it primarilyI'm assuming on particles
* This is the particle, here's the mass, here's the force this iswhere it's going to go
* This actually also works on a continuum
* Blobs in space
* Anybody seen the Muppet Show
* There was pigs in space, you know,a lot of jiggling going on
* That's that kind of stuff
* This works for anything, even muppets
* Okay, so this is the key thing
* We call this the superparticle theorem
* What this basically says, no matter what the dynamical system is,this complete closed system, you can treat the center of mass of thatsystem will act just like a particle
* If I know there is two forcesacting on it from a megatometer and maybe from the atmospheric drag forcethat Daniel was talking about, that's it
* Then those are the only two forces I haveto consider acting on the center of mass and I will predictthe translational motion perfectly
* Now that blob may pull apart
* It may do all kinds of weird stuff
* So if your external force depends onthe shape, then it gets more complicated
* So if this blob would be pulling apart,then with gravity gradients the part's closer to the planets would havedifferent force than the parts top
* The net forces changebecause of the shape
* That makes it more complicated
* But we didn't have gravity
* We have just net thrustersyou've got blobs in space
* Somebody fires a thruster
* And this thing is going to take off andgo
* Just by looking at the force and knowing the mass, I can predict what'sgoing to happen to the center of mass
* I don't know what happensto the shape yet, but I do know what happens tothe center of mass of that system
* Which is a very powerful argument
* So that's what's calledthe super particle theorem
* Any blob in space
* If you just are concernedwith the center of mass, the center of mass willact like a particular
* F = Ma holds butF has to be the net external force
* M is the total mass and Rc double dots hasto be the inertial second time derivative.


--- SKIP ---: 02_2-continuous-system-kinetic-energy.en.srt


--- SKIP ---: 02_2-continuous-system-kinetic-energy.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_2-continuous-system-kinetic-energy.en_SENTbySENT.txt
* Let us do some more fun
* Kinetic energies forparticles, you guys know that
* That's mass over two timesvelocity squared essentially, that's what you've had
* This is the vectorial form of that
* I have dm, soinstead of mass I just have dm over two
* That's essentially what that does
* Times my inertial speed squared
* I'm doing this in a vectorial way,so R dot is my, you know if R is my inertial position vector,I need to have my inertial velocity
* That's the first inertial timederivative of R, that's an R dot
* I'm dotting it with itself, that's going to give me my inertialvelocity magnitude squared
* It's just a vectorial way to write it, butit's a very general way to write this
* So that's it
* Now that's for one dm,I need it for the whole blob
* You simply integrate again over the body
* That's where the integral comes in
* It's just summing them all up
* So good, now we have kinetic energy
* That's not the most convenient form
* We don't typically write it thisway because it's kind of hard
* We would like to break it up in terms ofrc and kinetic energy off the center of mass and then we're looking at kineticenergy about the center of mass and that will help us separate rotationalstuff, deformational stuff and translational stuff
* That's what you'll seepopping out of this
* So let's do this
* R dot
* R was defined as Rc + r, so R dot,you just put dots everywhere
* Again, vectorial form, dead simple, right
* The 3.6 comes back
* Don't do part b any more
* Do part a where we only take timederivatives and vectorial parts
* You plug this in andyou carry out the various dot products
* You guys know how to do basicdot products in calculus
* I'm not going to do that again
* So we end up with these terms
* And, as Kevin was saying earlier, in thesebody intervals, anything that's RC and RC dot, those are all going to be thingsthat are fixed over the body interval
* Because every point in that blobhas the same center of mass
* Therefore, it has the samecenter of mass velocity
* So we can always treat these quantitiesas constants over the integration
* So when you carry, you know,this is a step I'm not doing here, I'm purposely not, because I want youguys to, you should do this yourself
* [COUGH] Run through the notes,that's how it's going to stick
* If we do that, these can be pulled out
* Same thing gets pulled out here
* And at the end there's a factor oftwo with the half that cancels, and you have also this other term
* Now one of these will go to zero
* Medal
* Which one of these is going to be zero
* >> Tom Tom
* >> Why is this one going to be zero
* That's always my second question
* First part is 50/50
* Might be lucky
* Who recognizes this part
* Trevor
* >> Well, we just went over that the body integral of the radius times the->> That's the vector
* It's not radius
* Let me correct quickly
* That's the position vector
* >> Position vector, yeah,that's [INAUDIBLE]
* >> Radius would be a scalar
* >> [CROSSTALK] And sothat's equal to zero
* >> Yes.>> Take the derivative of thatthat should still be zero
* >> Exactly without the dot this is nothingbut the center of mass definition
* We rewrote that instead of the massaverage location also saying that if all locations are relative to the centerof mass those summing ups have to give you zero
* So integral of little r times dn is zero
* So therefore, the derivative ofzero is still going to be zero
* So this one, the center of mass location
* This is, basically,using the center of mass definition
* That one will go to zero leavingus with this term and this term
* Now this term is nothing buttotal mass again
* So I have a big M
* So mass over 2 velocity squared,so you can see for the blob, the center of mass acts likea particle again, which is really nice
* And if you're doing an orbit problem, this would be your orbital energyof your spacecraft basically
* And then the second part is this integral,body integral of r dot, so that's the position vector,of each DM relative to the center of mass
* Get its inertial derivative though
* That's important
* This is a dot
* This is not a body frame derivative
* That's the inertial derivative andwe sum them up
* So this is basically your kineticenergy about the center of mass
* And in this form it contains two parts
* One part of kinetic energycomes from rotation
* If all the stuff is rotating thenthese things could be spinning, and that gives you all thatkind of kinetic energy
* The other part is because this is blobs,you might have deformational energy, where things are changing shape aswell and you're redistributing mass
* I'm not gaining or losing mass in thissystem, but I'm just redistributing
* So if you had fuel slosh bouncing around,that's one example you know
* So you might have deformationalenergy happening here
* So that's what that is, but this is the kinetic energy of a jello,written in the very form, basic form
* Now, we very often want to have power, that means the timederivative of kinetic energy
* We have that expression, broken up intothe translational part of the cm and energy about the cm
* If you differentiate this,you come up with these here
* Let me show you that one trick
* If you don't see that,how to go from there
* If you have a vector, x dotted with x
* If I have a scalar x squared and thenI take a time derivative of the scalar I will simply have 2 times x times x dot,right
* Very simple
* Here, if you have this vectorialquantities I mean these expressions we see a lot of vectors dotted withvectors again, especially themselves
* If you have this and you take a timederivative and here, I'm going to take an inertial time derivative, soI can just put dots over my vectors
* With the chain rule, you would have x dot, dotted with x,plus x dotted with x dot, right
* Why is this the same as 2times x dotted with x dot
* Why can I simply add these two things up
* >> [INAUDIBLE] Reverse the order
* >> Right
* The answer here,the dot part is actually a scalar
* So if you do this in vector forma dotted with b is the same thing as b dotted with a
* If you're doing it in matrix form thiswould have been written as a trans x transpose x
* Right
* It's equivalent
* And in that case too,the answer is a scalar
* So any scalar you can transpose andit's the same scalar
* So it allows you to reverse the matrixorder with the right transposes on it
* This is nothing but the vector form of it
* So here, here we just end upwith 2 times x times x dot, or you could've rewritten this byputting the dot on the first one
* Whatever's more convenient inyour analytical development
* So practice that if you haven't
* That's how I go from R dot R dot
* The one half cancels with the two
* Same thing here
* Little r dots there's a one half in frontof it that cancels with the two that comes out of the differentiation
* This is what you end up with
* Now we're going to apply some stuff
* We know from the super particletheorem that the mass time initial acceleration of the center of massis equal to the net external force
* So that's good
* So we can plug in this becomes nothing butf
* Over here little r dot we haveto do a little more math
* We knew that big R is Rc plus little r,so you just put two dots over everything
* Now we have the inertial derivativesof all these quantities, and I can plug that one in
* So that will break up this integral asbeing Rc double dot, dotted with R dot
* And, sorry, there's an R double dot anda Rc double dot that plugs in
* You break up the math, this isthe form that you're going to have
* So this part is actually pretty much done
* So the power equation gives youforce dotted with velocity
* The shift makes sense,hopefully with high school physics, if you look at power stuff
* That's typically always the forcetimes a velocity measure
* That's the instantaneous powerbeing produced mechanically
* These other parts,we're going to have to look at
* Now here, anybody see a termthat's going to go to zero
* >> How about the one at the end
* >> Yep, this one again, right
* Due to the center of mass property
* These things will pop up everywhere andwe love that, because zero is great
* It really simplifies the stuff
* So we're going to see that one goto zero and this is nothing but mass times the initial acceleration of aninfinitesimal element that was nothing but dF, that little force
* So on the body, this is your general powerexpression that you would have to do and you can write, if you have toenergy change between two points, you would integrate theseequations over time
* And this is one form oryou can do a substitution of variables
* This is a classic thing you've probablyseen where you can also do it force times distance gives you the energytake put into this system
* So, you can replace it
* There's different formsyou can write this
* This is the general one
* What we'll use in class will bethe rigid body specific one, but I just wanted to highlightfirst the general formulation
* We're going to then write it later on
* because this one doesn't make muchsense practically for you right now
* Once you make it rigid, we'll havea turn that would be very very clear
* This is how we compute this.


--- SKIP ---: 03_3-continuous-system-linear-momentum.en.srt


--- SKIP ---: 03_3-continuous-system-linear-momentum.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_3-continuous-system-linear-momentum.en_SENTbySENT.txt
* Okay
* Linear momentum,just kind of wrapping things up for blobs, since we're onto blobs
* The linear momentum is always mass timesvelocity, is your linear momentum
* Then a completely vectorial way ina blob you would have your mass is DM, your velocity inertial is R dot,and P is my linear momentum
* So DP is my linear momentum of thatdifferential element that you have
* If you want the total linearmomentum of a system, you have to integrate over the body again,and you just plug in all these things
* Then same rules, we will plug in, instead of R we have Rc + little r,and we can break this up
* We can pull this Rc out again
* And this integral by now, hopefullyboring you can go yep, that's zero
* Right, that's the center of mass propertyagain, and that one's going to vanish
* This one we've replaced with total mass
* So that's it
* So for a blob, again,like the super particle theorem, need to know what is the total mass of the systemand how is the center of mass moving
* And then we know what's going on
* If you differentiate it, this is howyou come up with Newton's equation for a constant mass solution
* So mass is preserved
* We're not gaining andlosing mass in the system
* Taking the inertial derivativeof linear momentum and you plug that into this equation,this R dot becomes an R double dot
* This is nothing but the force acting onthat element but integrated over a body
* You only care aboutthe external forces again
* Which is a very powerful statement
* So if you go to space stationhave flew away from earth and she's going through deep space
* And astronauts in there all of a suddenstart running up on a treadmill
* Are they ever going to change thecenter-of-mass motion of the spacecraft
* No.They may change the orientation, they may change the shape
* But these internal forces cannever change your linear momentum
* That's what we saw inthe superparticle theorem, too, that only external forces impact howthe center of mass evolves through space
* So, this is a kind of handy,handy, formula.


--- SKIP ---: 04_4-continuous-system-angular-momentum.en.srt


--- SKIP ---: 04_4-continuous-system-angular-momentum.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_4-continuous-system-angular-momentum.en_SENTbySENT.txt
* A little bit more curious,angular momentum
* With angular momentum we have to specifyabout which point we're taking moments
* We take torques about a certain point and we'd measure angular momentum aboutthe same point typically in a system
* So here, I mean people often usecenter of mass, but I'm not that nice
* I'm giving you a general point p
* And so sigma is now my position vectorof dm relative to this moment point
* >> [COUGH]>> This is the hinge point
* For some reason I want to knowmomentum about this on my body is tumbling out here
* How does that behave
* So we'll derive the general formulationand then you will see when it sympathize down to the down to the classyanswers many of you are familiar with
* The momentum here H aboutpoint P angular momentum
* It's always position crossed linearmomentum of that same quantity
* So sigma, that was my positionvector relative to P, so I have a dot, inertial derivative on that
* And you plug it in
* Sigma is R
* RP would be the position vector goingfrom here all the way up, right
* So sigma is nothing but R- RP
* You should start plugging this in
* Let's see, we do it with differentiationso that we get a dot here and then we get a doubledot on the second term
* >> This first one, trivially, goes to 0,a vector crossed itself is always 0, that's kind of boring
* But it's nice because this will vanish andwe're left with this term
* So, you're going to see okay
* Now, what happens with this term
* And we plugged instead of sigmadouble dot, we have R double dot and Rp double dot
* And I plugged those in
* Now, you notice R, I cannot takeoutside of the body integral because R depends on which element inthe body am I pointing to
* So that's going to be different forevery dm
* You just can't take it outside
* Rp on the other hand that'sa general hinge point that I have
* It's not really connected to the body andkeeping it very, very general
* And so that one is just fixed Rp
* Might be stationary, it might be moving,it might be spinning or who knows what it's doing
* And whatever it's doing,if I differentiate it twice, I need its inertial acceleration
* Its second order derivative
* But that one I can takeoutside of my body integral
* So good, we're left with those term
* Now let's look at this one
* If we focus just on what'sthe body integral of sigma dm
* So sigma, again, is r minus rp
* So I can break that up as the integralof Rdn minus the integral of Rpdn, but Rp I can take outsideof the body integral, which allows me to justget a mass times this
* And this part, if you recognize it, that was the right hand side ofthe center of mass definition
* Right?n times Rc was equal to body integral big Rdm
* So I'm using that definition fromthe other center of mass definition
* So this just becomes M Rc,this one here becomes M and then a Rp
* So this term here,I can rewrite as given by there
* Okay, where's this going
* If we look at torques,the torques about point B is basically the moment arm cross withthe force acting on that particle
* So, if there's a magnetic torquebar as mentioned earlier, it may have a particular torque,force acting
* Once the moment of thatforce relative to point P
* All right, soit's sigma crossed R double dot dm which is the same thing asthe force acting on that element
* If you write this,we can rearrange this, and so you can see this termactually appeared over here
* Here, we've simplified that term to here,but this first term appears as being nothingbut the torque around that point P
* Minus this, well that was it,that is the talk about p
* So I can use this,the inertial derivative of H about point p is equal to the torque about point p,plus this other stuff
* And I'm leaving it as slightly greyed,because we typically, a lot of dynamics books don'ttalk about this, at least
* Many people just remember the inertialderivative on momentum is torque which is true at times
* So what must be true of point pto make this second term vanish
* Tosh, how can you makethis term go to zero
* >> [INAUDIBLE]>> No because [INAUDIBLE] or not this doesn't matter actually
* This only has Rc which is,this true for continuum as it is for rigid one and RP is just an arbitrarypoint outside of the body that I picked
* And I could place it anywhere
* CK
* >> RP at RC
* >> Yeah, if you set RP,it happens to be equal to RC
* In that case, this one minus itselfis zero and that will vanish
* And then probably the most common useof h dot equal to l is they've assumed implicitly that is about a center ofmass location, all moments are about Rc
* And for spacecraft staff and if you keep spinning things, we will tendto use the center of mass as a point, a pivot point about whichwe take all of the moments
* But it doesn't have to be
* Sometimes you have a space craft anda CAD drawing, and for some reason what you got with the mass distributionis all the locations are not about that
* It's like an off-balanced wheel
* All of the sudden you have to account forthat difference, and this is what you would have to do
* What's the other way
* There's a second way we canmake this term go to zero
* Evan
* >> You can makethe difference between Rc and Rp perpendicular tothe acceleration of Rp
* >> Okay, there's a third wayyou can make it go to zero
* [LAUGH] That's kind of a hardway to retract that but you might come up witha condition that would do that
* Good point
* What's the second way
* What do you guys think
* Roda what is that
* We have almost exhausted all the terms,what's left
* >> RP is constant
* A treat of
* >> Okay if RP is constantthe RP double both is zero
* But that's true but I would say RPbeing constant is a little bit
* >> RP dot is constant
* >> Could also be constant right
* So what do we call emotion that has,either it's fixed in space or it's only moving inertiallyat a constant rate
* What do we call such motion
* No not nonlinear, inertial, exactly
* The definition for something beinginertial, an inertial point typically is it's a non accelerating point,and that's what's required
* The condition is really justRP double dot has to be 0
* If that point is non-accelerating
* So if it's moving in a constant line,we're fine
* If something is spinning immediatelyit's centrifugal accelerations and stuff, you know,it's not going to to be inertial
* But you could take a point that's notcenter of mass, but it's an inertial point about which you take moments andthen H dot equal to L holds as well
* So in fact, some of the homeworks we'llbe getting into you need to use both
* Sometimes you take Hs andLs about center of mass
* And sometimes you're finding this inertialpoint, o, and you can do it there
* And both sets will give you someinformation that you can use to do that, all right
* So we're not going to do muchabout general body fixed points or other different formulations of thatthat exists, you can look them up
* Just be aware Hr is equal tol is not universally true
* It's only true if you take yourmoments about center of mass or inertial points then we're guaranteedthis is going to go to zero
* Those are two conditionswe'll use in class.


--- SKIP ---: 05_optional-review-continuous-momentum-and-energy-properties.en.srt


--- SKIP ---: 05_optional-review-continuous-momentum-and-energy-properties.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_optional-review-continuous-momentum-and-energy-properties.en_SENTbySENT.txt
* Okay, let's do a brief review
* There's a lot of little math steps,that we went through last time
* These are definitely steps I feel, you should be able to do from scratch,basic principle
* And we're going to cover somenuances that we go through
* So
* [INAUDIBLE] no actually,it's going to go here, that'll work
* So one of the first things we werelooking at is, we've got a blob dn
* This blob has a center of mass,and we have some inertial frame
* This is the center ofmass position vector
* This little dn element hasa little r vector, and then capital R is to find usthe inertial position of that element
* I think it solved it
* That's kind of where we started out from
* So let's see
* Cody, what is the Super Particle Theorem
* >> Not quite sure
* [INAUDIBLE] last night
* >> When it's fresh
* >> [LAUGH]>> But yeah, I watched the video late last night,and it wasn't
* >> You slept through the videolast night you're saying
* >> [LAUGH] Yeah.>> I see, okay
* Good, what is the super particle, Andre
* Super particle theorem
* >> I couldn't tell you
* >> Did you watch the video
* >> It's just been a long week
* >> Okay, Super Particle Theorem
* >> The acceleration of the bodybecomes on the external forces >> Right, so actually close
* What did you mean byacceleration of the body
* [NOISE] we have to be more specific
* All right, this is a continuum
* This could be your fuel slashing in space,a jello
* You know astronauts eat jello in space, so there's jello wobbling throughthe space station I'm sure somewhere
* How does this stuff
* What's the dynamics of these things
* So when you say the acceleration of jello,which part of the jello
* >> [INAUDIBLE]>> Hmm
* >> Every part of the jello
* >> No
* Can't be right, right
* because jello may have left side isperfectly steady, the other side is wobbling, two seconds laterit will all shift and change
* So you can't have every part ofthe jello having the same acceleration
* Even if it's rigid, does this pen havethe same acceleration everywhere
* No, right
* So right away that statement,you're on the right track
* What was it Brett, right
* >> It's the center of mass
* >> It's the center of mass
* So the Super Particle Theorem says,that the total mass of this system times Rc double dot = F
* Now David, what goes into this F
* >> It's basically an integralover all the particles, the sum of the forces over allthe particles in the body
* >> Yeah
* Robert, can you be more specific
* This is true
* But it's not, there's more to this
* There's some refinements that we can do
* Which forces do we have to reallyconsider when we do this integration
* >> External forces
* >> External
* What happens to the internal forces
* Russell
* When you sum up over the body,what happens to internal forces
* >> [INAUDIBLE]>> Sorry
* >> They cancel each other
* >> They cancel each other, exactly
* Right
* So this bolt has a force of one newton,because another plate is pushing on it
* But vice versa, the plate is havinga minus one Newton force somewhere
* And these things willall sum up to be zero
* So internal force is completely banished
* Only the external forces, so this isreally dF external that's kind of what you can think of this,integrated over the whole body
* This is what we derived last time
* And basically it's a very powerful thing
* We'll be using it one of the examples, you'll be using it inthe current homeworks as well
* So without knowing what's going on withfuel slosh and all the other stuff
* If you just know the externalinfluences on your space craft, regardless of what flexing isgoing on inside in deformations, especially if it's rigid as well
* Of course, you can predict whatthe center of mass must be doing
* And the center of mass motion forspacecraft, that's basically your translation,your orbit's problem
* So we can account for all of that
* Now there's ways that attitudecouples into this total force
* Can you think of an example where, youneed to keep track of what the shape is and the orientation of an object,to figure out what the external force is
* Daniel
* >> Drag
* >> Drag, atmospheric drag right
* So there are particulartypes of disturbances, acting on a space craft thatdepend on the orientation
* And if it's this shape in space, orthis shape in space as we'll see in a few weeks, gravity gradientsmake a big difference right
* So there are external influencesthat do matter on the shape
* So those become harder obviously to track, because now you haveto track orientations, your codes immediately slow way down,because for attitude you have to have much smaller time steps than orbits typically,and so lots and lots of challenges
* But this is it
* This is the Super Particle Theorem
* Now we had the center of mass definition,MRc equal to this
* This was one of them, right
* Basically, the center of mass ofa blob is the mass averaged location, that's one way to look at it
* Instead of an integral,putting in a summation sign, it looks just like your classicstatics book that you had
* Mass averaged location
* What was the other definitionthat we used over and over again, for center of mass of a property
* Thibault, do you remember
* >> The weighted average ofthe positions with the r plus small r
* That's a good answer
* >> Yeah there we go
* So this is the average positionrelative to the center of mass, have to add up to zero
* Then basically it'sthe balance point right
* You put that little lever rightthere in the center of mass, and you'll be able to balance something
* I can't I'm not quite goodenough this morning all right
* But it's something like that
* It's not my pen, I don't care
* >> [LAUGH]>> No of course I care
* So these are center of mass definitions
* And then we said, we can take two derivatives,put the dots in here all right
* This was one thing we didon the left hand side, if you take two inertialderivatives you just get this
* Then we have the second derivativeof this integral Rdm right
* And from here we endedup with this expression
* Bret right,it was you that brought up that question
* That was an excellent question
* Why can we take these derivativesinside this interval, because the body if it's jello,the boundary actually varies with time
* If B is defined to be thisboundary of the actual jello
* So in the textbook we have, there's actually a statement early in thatparagraph on that section saying hey, when you do these body integrals orthese integrals over B, the domain has to be carefullyselected to encompass all the mass
* Basically what it means is,you create B in this case for a continuum is not justthe body surface itself
* You can make a box bigger than that
* This isn't a fluids or continuum problem
* There's not a mass flow of air,or some plasma, or something coming with water,coming through here
* It's a fixed shape
* And it's doing some stuff
* So you can define the bounds of theseintegrations to be bigger, basically make it big enough that no matter whatthe worse case deflections are, you've got a bounding boxthat's big enough to cover it
* So when you're doing allthese integrals afterwords, something times dm, out herethe dm is simply going to be zero
* If this stuff deforms and encompasses it,all of the sudden dm becomes non zero
* That's a way to look around it
* This avoids Reynolds transport theorem or lightness stuff, that otherwiseyou'd have to use on the boundary
* But again, this is a fixed shape
* We're not adding,losing mass to the system, we're just looking atdeformations right now
* So there's a discussion ahead withmy co-author, John Jenkins and I have to give credit also toJohnny Hurtado, professor at A&M, he writes a lot of analytical books
* He pointed me to some good references
* This type of derivative, we also callsometimes the material time derivative, or the co-moving time derivative
* because you're reallyfollowing each dm element
* And we're not creating new dms
* There's not a flow of dms like ina fluid flow, that comes in and out of the surface area
* On the boundary, as you change stuffthere's no mass flux coming in and out of the boundary either
* So lots of different ways to look at it
* But the easiest explanation I think forengineers is, just for this kind of problems you've got a spacecraft flexing, you're getting all these equations of motions, the results I'veshown are classic and definitely true
* It's just this step there'ssome subtleties there
* So Brett very good
* Gold star forasking the right question from analytical- >> That was Hansel actually
* >> Hansel?I thought that was you
* Well gold star for honesty
* So Hansel, he's not here today
* >> [LAUGH]>> Well somebody right back there who askeda great question, thank you
* But that was an issueI wanted to bring up
* This is a subtlety, but this is an easyway to look around that form continuum
* Once we turn rigid, all this stuffis completely simple anyway
* Then all these results definitely hold
* But even for a continuum, the resultsI showed you are absolutely true
* But if you do these derivations in thesebooks, there's lots of little subtleties
* And moving a derivative insidethis differential operator, is something you alwayshave to do carefully
* So I didn't have a good answer last time,but I do have a better answer now
* So we did derive this
* And this gave us in the end,this was the dFs and this was nothing but a Super Particle Theorem
* Good, so we derive that
* Now, let's review quicklyangular momentum
* Brian, of a blob, what do youremember about angular momentum
* >> It's
* >> When
* >> When there is no external torques
* >> So, if you're saying ifL is zero then H dot = 0
* So, it's a vectorial quantity
* Right.This becomes important
* So when you say it's preserved, we're saying the inertial derivativeof this vectorial quantity is zero
* So it's a constant as seenby an inertial observer
* As we go through equations of motiontoday, you will see the angle momentum expression, as seen by the body fixedobserver, is actually not constant
* So the body relativederivative is not zero
* But the inertial derivative is zero
* Which is a really good integration check,when you write in code
* Every time stamp,recompute the derivative
* All outside the derivative
* Compute h.And then map h, because you're typicallycomputing the body frame, map everything into the end frame
* And those three end frame components,should be nice flat lines
* Then you get warm fuzzy feelingsthat you're doing the right thing
* Now when is this true
* When is h dot equal to L
* CK.Is that always the case
* >> It's not accelerating
* Center of mass is not accelerating
* >> No
* Center of mass can be accelerating
* You're on the right track, butyou're talking about the wrong point
* When we have moments and torques,we need to specify something
* Robert
* >> When the about the center of mass
* >> That was one option
* When we derived this H dot, we found itwas H dot equal to L, plus something
* And that something had an RP minus RC
* So if the point, about whichwe're taking moments in torques, is the center of mass thenthat second part went to zero
* The other one is related towhat CK is talking about
* There was something about being inertial
* But it's not the center of mass beinginertial, but it's really rp double log
* So if the point about which you'retaking moments is an inertial point, it could be stationary
* That's cool
* Or it could be moving at a constant speed,also has zero acceleration, then this equation holds
* So that's an important thing, today youwill see when we get through equations of motion, especially a slender rod, in homework you're doing onethat's tipping off a point and has some friction, we'll do one,there's no friction slides in place
* But here we'll be usingSuper Particle Theorem, H dot = L, and when we use H dot = L we have to makesure we do it about the center of mass of the dynamical system, orabout an inertially fixed point
* And then this will work right
* So good
* Those were two importantsubtleties that we needed
* But this is about H dot
* Let's step back and talk about H itself
* Can somebody tell me something about H
* For a blob of jello
* Right the fundamental definition is,this integral over a domain B
* You have position crossed withlinear momentum of that one right
* Is this the form we typically use then
* Evan
* >> No we usually use the sigma form, whichdefines that difference between r and rp
* >> Right we can make that one general
* There's something else though
* We can break this angular momentum, same thing with kinetic energy,with these blobs
* There's a way that we can actuallyseparate into two different chunks
* Do you remember, Evan
* >> I'd have to look to tell you butI think we- >> Just in words
* In words what then we can see
* >> We can separate itinto two integrals of the positions crossed, andthen position of acceleration
* >> Lucas, help him out
* >> I'd have to look at my notes
* >> Matt
* >> So we're going to define R in termsof little r and R of the center of mass, and then [INAUDIBLE] integrals andone of them cancels to zero
* >> Yep some stuff definitely equalsto zero, we're left with two parts, you guys are on the right track
* But what are those two, angular momentum
* Shayla, do you remember
* >> [INAUDIBLE]is equal to [INAUDIBLE] across R
* So you sub that in
* >> When is this one true
* >> [INAUDIBLE]
* >> Yes
* Is this true for a blob
* Maurice
* I'm full of good questions every morning
* >> [LAUGH]>> This should not be a surprise, this many weeks into the semester
* Who knew he was going to ask mequestions about last lecture
* >> [LAUGH]>> I know
* [INAUDIBLE] couldn't foresee this at all
* >> When is this true, people
* >> For a rigid body
* >> Rigid body
* It's only true for a rigid body, that'sin fact [INAUDIBLE] go to rigid bodies
* But we're already answeringquestions about that, right
* People sometimes quickly assumeto look at this stuff and direct to deriving of the exam
* R dot rigid, R dot must be zero
* No
* Each little particle is going to havesome inertial derivative of this vector
* It's not growing, it's not shrinking,because it's rigid
* But it is non-zero because it's tumbling
* So this part is only true if it's rigid
* Let me make that not next to it
* If rigid
* But, as Matt was saying,we do make this thing, you plug it in, you do all the stuff
* Okay
* Somebody, somebody here surelyremembers how we break this up
* What are the two chunks
* >> That minus
* >> Yeah, what is that part
* >> There is the cross product
* >> No, not dm
* Okay
* So this is the second part
* But again, if you get into this form[INAUDIBLE], what have you assumed
* [SOUND] Okay, so I'm hearing a lot ofsub-results that are true for rigid
* Let's go to a blob
* H is equal to R crossed, R dot dm
* You can rewrite this
* Where essentially Rc, why is that
* Okay
* Crossed MRc dot plus integral of little r dot DM
* Why is this form convenient
* What is the first part then
* Andrew
* >> [INAUDIBLE] the angular momentum ofthe center of mass about some point
* >> Right, sothis is about the inertial point or something that we've picked, right
* There are moments about that
* R is defined relative, it's the Rc not R
* Right.So it's important with these problems, and you start from the fundamentals
* You're always going to get this,well this is a blob, I have all my positionvectors [INAUDIBLE] inertial
* We break it up like Matt explained,relative to center, the motion of the center mass plusmotion relative to the center of mass
* Momentum, you want to writeexactly the same way
* Why is that convenient
* This in essence,gives you the translational side
* That's the orbit problem when[INAUDIBLE] flying through space, right
* So, you can separate moment to orbital,a momentum is essentially this part
* This part contains what type of motion
* Griffin
* >> Attitude
* >> Attitude motion, and what else
* This is blob still
* >> Deformation
* Deformations, right
* >> So shape changes,fuel sloshing, flexing of panels, all this kind of stuff wouldalso be accounted in this
* So this is the anglular momentumabout the center of mass
* And this is the angularmomentum of the center of mass
* That's the importantdistinction we keep making
* So in this class we derive it,we get these terms but now we're going to focus on this part
* And if you go look at the kinetic energy, we can write that invery much the same way
* We derive that, similar propertiesthat we used, the center of mass properties terms drop out, butyou end up getting the kinetic energy of the center of mass plus the kinetic energyabout the center of mass, all right
* So this is the classic thing we cankeep doing, over and over again.


--- SKIP ---: 01_5-rigid-body-angular-momentum.en.srt


--- SKIP ---: 01_5-rigid-body-angular-momentum.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_5-rigid-body-angular-momentum.en_SENTbySENT.txt
* Enough of blobs, let's get rigid
* All right, so now we're going to deal witheverything on, things are going to freeze
* Instead of just general continuum, butI think this is a good classic thing
* Earlier stuff, definitely thingsthat I will put on the exam
* Something like that's going tobe on there guaranteed
* But now we're going to freeze it
* How do we do that
* How does that change my definitions
* How does it change momentum, energy, all this kind of stuff andwe want to look at this
* So now angular momentum about a point O,this is an inertial origin
* I've picked that already
* I can write that as my position vector orcross or with dots
* That goes to each DM
* I didn't draw the the DMs here anymore
* But this is now a rigid boby
* So if it's rigid, every point inthe body has the same angular velocity
* If I'm spinning, then the speed ofmy right hand is different than the speed of my left hand,the velocity, right
* because one's moving forward, that'sa different vector than a velocity vector moving backwards relative to me,opposite for you guys, all right
* But the angular velocity,if we're spinning, everybody needs to be rotatingat one degree per second
* Otherwise if the panel number two isrotating at two degrees per second, panel number one is only rotatingat one degree per second, those panels are going tocatch up at some point, right
* It's deforming, that's not a rigid body
* So as before when we argued, RC was commonwith the body integrals here we would have tricks where we can say omega is constanton a rigid body or blog the jello
* That's not true because everybody couldbe spinning in different ways right in that case
* So that's one thing
* Another one, this is the basic definition
* You've seen now how we break this up
* We write r as big R as Rc plus little r
* And then same thing here, with thoughts,do the cross products on your own
* Make sure you can derive this
* And then you come there
* There will be terms that vanish, but againthe angular momentum about point O can be written as, this is the angularmomentum of the center of mass plus the angular momentumabout the center of mass
* Kind of what we did with energy as well
* So I'm leaving this up to youto practice and go through and make sure you can go from here to here
* Now this part, that's your Orbits class
* You've all taken some typeof Orbits class probably
* And you hang momentum on orbit andhow it's conserved and from that you get all of the differentchronic intersections and trajectories
* And that comes from here
* That's cool, butwe don't care about that part
* This class is all aboutattitude of spacecraft, right
* The translational side, as you see throughthe super particle theorem, you can really handle separately and track what happensto the center of mass of a spacecraft
* I care about what happens aboutthe center of mass in this class
* So I have wheels, I have gyroscopics,all the stuff, that's what I care about
* That's what the attitude dynamics is
* So instead of HO, I'm just going to keepthis part which I'm going to write as HC
* That's the angular momentumabout the center of mass and that will simply be r cross r dots dm
* Same definitions we had before right
* So that's good
* So now if this is rigid
* People, if this is rigid,what happens to this derivative
* >> r dot, it goes to zero doesn't it
* >> Okay, who agrees with that
* Who disagrees with that
* And the rest of you are asleep,okay, or just confused, that's fair
* I'm also confused sometimes
* So, you agree that it would go to zero
* Sorry, what was your name again
* >> Ansel
* >> Ansel, thank you
* Why do you think it would go to zero
* >> I thought that's howa rigid body was defined, that the points don't moverelative to the center of mass
* >> What does this dot mean
* >> [INAUDIBLE]>> So this is your body
* And to track this point, this littleknob at the end of the pen, right
* It's inertial, I mean it's an inertiallyfixed spin axis, it's a rigid body
* Is the velocity as seen by you,an inertial observer, zero
* Right, the position vector would be centerof mass to this little knob, right
* And that vector is clearlyrotating as seen by you guys
* So as seen by what frame would this timederivative go to zero if it is rigid
* >> Body frame
* >> The body frame
* That's the key
* So I'm glad you guys mentioned inertiabecause this an easy stumbling block
* Everybody starts out with, it's rigid
* All the dots go to zero
* No
* This is the inertialderivative of the velocity
* If it's rigid, it just means as I'm rotating,my right hand is always to my right
* It's not moving up, down,otherwise I'm not being a rigid body
* So only as seen by the body are thesetime derivatives zero for a rigid body
* That's the key thing thateverybody always misses otherwise
* So good, so now if we do that, we knowhow to do this transport theorem, right
* Kinematics comes back andwe take the body frame derivative, why
* Because we know it's going to go to zero,we love zero
* And what you're leftwith is omega cross r
* Okay, good
* We do that so r dot is nothing but omegacrossed r and I can plug that in here
* So I get an r cross omega cross r
* This form is not very convenient
* I said omega is constantas seen by the body itself
* If it's rigid, every point in that bodyneeds to be tumbling at the same rate or it's deforming
* But in a cross product like this, I can'tjust pull the middle term out, all right
* So I want to make it either at the lefthand side, or the right hand side
* Then I can take it outside of the bodyintegral, and that's what I'm doing here
* On A cross B is a samething as minus B cross A
* So I flipped it, and then I have r crossr cross omega with the minus sign
* And in matrix form, this r cross rcross is nothing but r tilde r tilde
* Again, that's wherethe minus sign comes from
* And then now I can take the omega outside of that interval because it isrigid, right, that is the key assumption
* Anybody recognize what thisterm is going to become
* Angular momentum turns tobe something times rates
* >> Inertia
* >> Inertia, yeah,moment of inertia, exactly
* So these can become our inertia tensorthat you've seen from your statics and mechanics classes
* So we're just going to derive this now.


--- SKIP ---: 02_6-rigid-body-inertia-tensor.en.srt


--- SKIP ---: 02_6-rigid-body-inertia-tensor.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_6-rigid-body-inertia-tensor.en_SENTbySENT.txt
* If you pick vector components, this isjust written in a very corner frame, independent way
* I'm just taking the cross product operatorand representing it in a matrix form
* Now to actually numerically compute it,you'd have to take r1, r2, r3
* And then your first rule becomes 0 minusr3 plus r2, right, and you break it down
* That means you've pickeda particular body frame
* So if you do that and that matrix with theminus sign, it gives you this definition
* If you replace r1, r2, r3 with just x,y, and z this should look very familiar
* And now you would have your y squaredplus z squared, x squared plus z squared, x squared plus y squared
* Those are your differentmoments of inertia definitions
* And then we have our off diagonalterms that appear as well
* So generally, to have a rigid body yourinertia tensor, which is what I'm showing here, will be a three by three matrixwhen you numerically evaluate it
* But to do so, there's two conditions
* One, we've picked about whichpoint we're taking moments
* These r's are defined relativeto the center of mass
* And then when you numerically evaluate it,you pick a particular coordinate frame and say, okay, my one access point is forward
* The second one is to the left andthen the third one is up
* If you pick a different coordinate frame,you would have different components
* And you get a different inertia matrixrepresentation of the inertia tensor
* The inertia tensor is really an invariant, that's it forthis space craft has one inertia tensor
* But then how we numerically express it
* There's an infinity of answers, becauseI could pick a infinity of body frames to break out these vectors anddo the tildes and compute this
* Now this body integral is not very fun
* It gets tedious
* Cat programs love this
* They know where every nut andbolt and panel and fuel tank is, and everything that goes on the spacecraft
* So it simply has to sum them up, knowthe location, do this math, times dn and sum everything up, andit spits it out in a heartbeat
* Doing it analyticallya little bit tedious, so we will look at tricks that we don'thave to redo this integral every time
* What if I am not taking moments about thispoint, but I am putting this at the end of a robot arm andI need movement about this other point
* Do I have to redo all this math
* So angular momentum expression,as we said, was just hc
* You already identified that term asbeing nothing but the inertia tensor
* I am writing it as Ic times Omega
* There is now somenotational subtlety here
* Here I picked a particular bonding frame
* Here I am not specifying body
* So I'm really equating matrix math isequivalent to this tensor vector math
* The inertia tensor, think of it asa two-dimensional vector, right
* I can write these quantities in a generalway, but then when I evaluate any vector I have to have a coordinate frame tobreak down the components and add and subtract them
* But you can write them ina very coordinate agnostic way
* And that's what I'm having here
* I'm not saying, if this is the b frame,this better be in the b frame
* Otherwise, you're adding apples andoranges
* But, this can also both be in the qframe or the r frame, it doesn't matter
* In the vectorial way, we can justwrite the tensor operator like this
* So that's the Inertia Tensor.


--- SKIP ---: 03_6-1-rigid-body-inertia-about-alternate-points.en.srt


--- SKIP ---: 03_6-1-rigid-body-inertia-about-alternate-points.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_6-1-rigid-body-inertia-about-alternate-points.en_SENTbySENT.txt
* So now there's two aspects
* Either we need to have a different pointabout which we're taking moments or we're taking a different corner frame
* And hopefully you'veseen some of this before
* Just going to go throughthis pretty quickly
* The book derives this,if you want to look at this steps, but I'm just going to give you the answer
* So if you have the inertia tensorabout the center of mass and that's typically what a staticsmechanics book gives you
* And now you have this block, orthis cone, or this panel, right
* And then it gives you X, Y, andZ coordinates, and assumes that things are lined up with symmetry, it gives youthis answer, basically, in that form
* For some reason this panel,you don't need the inertia, the moments
* About its center of mass, butit's going to be attached to a spacecraft
* The arm is the panel
* The panel center of mass is here, but the spacecraft center of massmight be somewhere else
* How do I get these moments about here
* You could redo all these integrals
* Or this parallel axis theorem basicallyallows you to take moments about other points
* And the way this is written is you needthe inertia tenser about the center of mass, that's always going to bethe smallest inertia you'll have, any further away andit's going to get bigger
* And you get mass times distance squared,that's probably how you remember parallaxes theorem forfixed axis rotation
* If this is the inertia about center and all of a sudden I'm spinningabout the end-point
* You would have that distance squared timesmass that you have to add to the inertia
* This is a 3D version of that
* Total mass,I need to know what is that shift
* So I'm taking moments about O
* There's a vector going fromO to the center of mass
* And I'm calling that one RC again
* And I've got a tilde formto avoid a minus sign so it's plus mass times distance squaredessentially but in a tilde formulation
* So that's how we can,we don't have to reevaluate the inertia tenser every time wehave a different moment point
* You just use this theorem
* Here's the one subtletypeople often trip over
* In here again, we mention these tenserswhen you numerically value a three pathway matrices
* You have to pick a coordinate frame
* Make sure you're adding these thingsup in the same coordinate frame
* That includes this
* So these RC tildes betterbe broken down in the same N frame if this is given in the N frame
* Or if this is given in the B frame,you have to write RC in the B frame
* RC's often given in the other frame
* You have a, your cube set,it goes on to the space station
* You probably have your cube set inertiaabout at the center of mass but then it's in the space, andthat's in the cube set frame
* But where, it is in the space station itstypically expressed to you in a space station coordinate frame
* All right, relative to the space stationyou put that cube set at this launch location
* Well, then you have to of courseuse a DCM to map vectors from a space station frame to bodyframe before you apply this stuff
* That's the one step I often see missed
* Right, so just make sure if you do thismath everything's taken with respect to the same frame.


--- SKIP ---: 04_6-2-rigid-body-inertia-about-alternate-body-axes.en.srt


--- SKIP ---: 04_6-2-rigid-body-inertia-about-alternate-body-axes.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_6-2-rigid-body-inertia-about-alternate-body-axes.en_SENTbySENT.txt
* The other one is,what if we have a different body frame
* There's an infinity of frames I can attachto a rigid body and be a body fixed frame
* In our derivation, all we assume was thatthe derivative as seen by b was zero
* But there's an infinity of such frames
* So, andyou will see in real life a lot of frames
* There might be a docking port frame
* There's a flight frame
* There's a space craft frame
* There's a structure frame
* There's a sensor frame
* There's a star truck of frame
* There's a gyro frame
* There's lots of frames, right
* And all of a sudden I need the inertianow about some other frame
* I don't want to redo that integrals again
* How do we translate it
* And this is the answer in essence
* You remember how we did vectors
* So, with a two-letter notation,this becomes dead simple
* So, if we have a vector in the n-frame and I want a vector into the b-frame I haveto multiply this times the Dc once
* Now, ten serves our industry initialtimes like two dimensional vectors
* So, I'll still use the DCM to markfrom one frame to another, but I have to use the DCM twice
* And that's what this formula shows
* Again, I'm not going to derive thisin a book, but you can go to that
* It's a very simple one
* With these two letter notation you cansee this the tensor having one frame B
* I'm trying to get the tensorin different frame F
* And now I have to pre and post multiplyit on both sides times the right DCM
* So here it's FB times FB transpose
* Another way to write it would be FB thisinertia tensor to B frame times BF, right
* So, then from the left and right handside your mapping things to the F frame, then you know you're on the right track
* But that's it
* So, we used the DCM twice
* Any questions on this one
* I assuming many of youactually seen this before
* Some of you may not, but you can catch up then withthe details with the notes in the book
* Now, does an infinity frameswe typically like a frame that makes our inertia tensordiagonal especially for an analysis
* So, every rigid body can beexpressed with the body fixed with the particular body fixed frame suchthat the inertia tend to representation
* Becomes diagonal, then I only have to track three inertiaterms not nine in that whole full thing
* So, for analysis, this is very, veryhandy, and we want to be able to do this
* In the code, when we write simulations,we're going to solve for control problems, where we just use theinertia tensor eye in a very general way, because that way we're not requiringsomebody to have found that magic place, and then what if you get rid of some fuel,now things have shifted
* We can write it ina very very general way
* In the codes
* But for analysis,this is a very handy thing
* So, how do we find this
* Let's see, this is the original one
* This is my FB over here,I've taken this FB transposed and brought it over to the right
* Over here by right multiplying times FB
* So, that same matrix appears here andhere
* And then when you start to carryout those components and equate, what does this have to be
* This basically sums it up there
* You can go ahead andyou will quickly find that this DCM again, becomes nothing butan eigenvalue-eigenvector problem
* In fact, what you have is,the rows of this DCM are the eigenvectors of this three by three matrixrepresentation of the body's inertia
* And the principle inertias, that's what we call these things when wedo it in diagonal form, are nothing but the eigenvalues associatedto these eigenvectors
* So again, foreigenvectors to form at the ECM though, we need them to be normal,probably should have had hats on here
* These have to be unit vectors, all right
* And they have to be orthogonal
* And the other key result isyou have to be right-handed
* This is a big error sourcepeople have right here because Matlab justgives you three vectors
* It has no idea what you're trying to do
* So what you have to check in the end iswhen you assemble this matrix is that the V1 cross to V2 has to give you Plus V3and Mathlab doesn't check that for you
* All right?It may give you minus V3
* So if you get something that'sleft-handed, just reverse the sign of one of them and now you have a coordinateframe that is right-handed
* But this gives you the mapping from thecurrent E frame into a principle frame F whose representation ends up beingjust the three diagonal inertias
* Which you have, good
* So with these two tricks,power access and this one, we can now, we never, once we have the inertia tense
* So we tend to not have to redothat body interval again
* You simply have some nice clean analyticmappings to shift origin or to shift the body fix point of a body frameall the components are taken Yes sir
* >> So the F frame is just a framewhere the inertia tensor is nice
* >> Yes
* And if you looked at statics mechanicsbooks it tends to be like symmetry axes
* You can quickly see that's whereeverything bounces out and these off diagonal terms, they all vanish
* So, if you had that, this pen, if oneaxes lines up with this symmetry axes and the other two are orthogonal Thatwould give you that kind of a frame
* But if somebody gives you this weirdframe where this is your stuff and you're putting it in a skewed way,you're going to have all this stuff
* So if you have this and that's your body,and you're going okay, I can always make a coordinate transformation such that thisbecomes diagonal and then we can go there
* And this is really nice for analysis,because without loss of generality you can always assume I can write my rigid bodytumbling motion in a principle cone form in which case I'll only havethree inertias to worry about.


--- SKIP ---: 05_7-rigid-body-kinetic-energy.en.srt


--- SKIP ---: 05_7-rigid-body-kinetic-energy.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_7-rigid-body-kinetic-energy.en_SENTbySENT.txt
* Kinetic energy, let's start here
* Now we did this for blobs in space
* And for blobs in space we were able toshow kinetic energy was nothing but the kinetic energy off the centerof mass plus kinetic energy about the center of mass
* But this second term containsboth deformational energy, if panels are flexing anddoing or fuel is sloshing
* And the rotational part, right
* Now let's use the same assumption
* r dot for a rigid body,it doesn't go to zero, but the r dot just became omega crossed r,the body relative derivative of zero
* So we're also just going tofocus on the rotational side
* This is basically your translationalenergy which comes out of your orbits class
* We're not going to focus on orbits inhere, just the rotational dynamics, so we're not going to cover that
* And this is where I pluggedin r dot is omega cross r
* So you get a bunch of cross products,dot product
* And you know right away theremust be some magic trick identity that we can rearrange this
* That's kind of what I'm doing here,almost actually
* First, and I'm using trig here, this omegais a constant as seen of the integration
* If it's rigid, every point hasto be rotating at the same rate
* So this omega I can just take outside
* There's a dot product
* Okay I did use a vector identityalready to rewrite this into this form, and now I could take your omegaoutside to the dot product
* Here I'm still left withomega in the middle but we have the trick thata cross b is minus b cross a
* That puts it on the right hand side
* And you can take that one out as well
* In fact if you go back and look at Hc,this whole definition is nothing but Hc
* In fact this term becomes nothing butyour inertia tense times omega
* And the inertia tense timesomega was nothing but angular momentum about that point c
* So it's nice, we now have, rotationalenergy can simply be written as one half omega dotted with angular momentum
* Those are two vectors dotted together
* When you dot them, mathematically make sure they'retaken with respect to the same frame
* But here is written ina frame agnostic way
* So angle rotation, sothat's the same thing, H is I omega, you might remember as rotational energybeing inertia over 2 times angular rate squared for fixed axis rotation
* This is the 3D version of that
* You would have one-halfomega transpose I omega
* And that's basically inertia omega squaredover 2, essentially that's what it is
* Power
* We had earlier,if the time derivative from a blob, the first part translation was just forcetimes the inertial velocity, again, that's the translational sign
* What we do care about here is T dot
* So if you differentiate this term,you will end up with this
* Now to get this form, you need to havethe rotational equations of motion, which we haven't derived yet
* But I will let you, this is somethingyou should make a note in exam, definitely go back and make sure you cango from here to here, but it simplifies
* But the beauty of this is,for translation, we have force started withtranslational velocity
* With rotation, you have torquedotted with angular velocity
* It's really the same type ofterm that we're going to have
* And that's what makes,this is what gives you your power rate
* To the system
* When is T-dot going to be zero
* Let's ignore translation,we'll just focus on this
* When is my power equationgoing to be zero
* Sheila, what do you think
* Without reading more,I want to hear you think
* >> The angular velocity is zero or->> You could, if you're not spinning
* >> Center of mass is acceleration is zero,the Rc
* >> Well we're going intranslation right now
* >> Okay.>> Just focus on this one, the rotational side
* What makes this second term go to zero
* Omega could be zero, yes
* It's kind of a trivialdynamical system then, yes, if the energy is zero thenthe energy rate is going to be zero
* But that works, yep
* What else could you do
* >> [INAUDIBLE] Make Lc zero
* >> So what is Lc here
* [INAUDIBLE]
* >> No
* What is LC here
* >> Torque
* >> It's a torque
* So this is a torque about point c
* And in fact when we get this torque, this torque is due to external forceswhen we derived all this stuff
* So for this dynamical system,if your external torque on that rigid body is zero,you won't dissipate energy
* This makes a great integration check
* So as you guys are writing numerical code,you've got something that's spinning and there's no external torque on this system
* I know energy has to be preserved
* If we had H dot equal to L,that was the same thing
* The angle momentum as seenby the inertial observer, that's what that dot meant right,inertial derivative
* As seen by inertial observer, H has to be a constant vector if noexternal torque is acting on it
* These things become fantasticintegration checks
* This is for a single rigid body
* But even if you do multi-body,complex panels flapping, reaction wheels, gyros spinning, twisting, this stuffstill has to hold, which is really nice
* And now if there is a torqueacting on that system
* I can actually predict very quicklyhow my kinetic energy needs to change
* And this becomes a nice integration check,because I can compute kinetic energy from the simulation numerically andthen differentiate it to get T dot
* And compare, I know I applied this gravity gradienttorque, this is my spin rate at the time
* Energy should have changed by thismany joules per second, right
* So these tools becomes very,very useful validation tools, but also for analysis you will see
* So torque-free motion is whenmomentum is inertially preserved and kinetic energy is preserved,because this is zero
* The third option actually could exist,in that the dot product goes to zero
* Maybe you have very particular torquesbeing applied, such that no matter what your spin rate is, right nowthe torques are orthogonal to that
* In that case you havea non-working force acting on it
* That's what they callit because it doesn't, not doing work means it doesn'tchange my energy state
* So there's three ways,either omega zero, Lc zero, or those two things are orthogonal
* Then T dot goes to zero
* And again over, if you have to work downbetween points and time, you can do this with a time integral or you couldalso do it in the spatial integral.


--- SKIP ---: 06_8-rigid-body-equations-of-motion.en.srt


--- SKIP ---: 06_8-rigid-body-equations-of-motion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_8-rigid-body-equations-of-motion.en_SENTbySENT.txt
* Let's derive the equationsof motion of a rigid body
* We know how to describethe orientation of a rigid body
* We have Euler angles, we have DCMs
* We've got and CRPs, MIPs
* All these things andwe always have differential equations and how they relate back to omega
* If the omega is not just prescribed or measured, if you reallyhave a free tumbling body
* You kick off the satellitefrom the rocket
* What happens as it gets released
* I need to be able to mathematicallypredict how omega will evolve, and that means I need to finddifferential equations for omega
* And what we're going to use always,for translation, we use f equals ma essentially
* That's what it boils down to,that's one of the forms
* Here, for rotation,we always go back to H dot equal to L
* And so, here,H is taken about the center of mass
* So, we know H dot equal to L holds
* And L is the torque
* About of all the extra influences aboutthe center of mass of the system
* So okay if we know it's the inertiaderivative of H that is equal to this equal to this torque
* So we have to be now a little bitcareful in how we derive this
* I've chosen to take a body relativederivative of this plus now, I have two omega b, relative to n,crossed with that h vector again, right
* The transport theorem isn't just forpositions and velocities and so forth
* It's true for any vectorial quantitythat you're differentiating, as seen by a rotating frame
* Angular momentum counts as also a vector
* So this is true
* Now why did we choose to dothe body frame derivative of this
* If we do this, and I just use chain rule, we know h we defined as beingthe inertia about point c times omega
* So that's two terms
* And taking the time derivativeof this chain rule, right
* You get the derivativeof the first term plus the derivative of the second termwith the right multiplications
* That's good, now it says this isgoing to become equal to i omega dot
* There's two steps in thisone little equal sign
* What happens to this part
* What happens to body framederivative of the inertia tenser
* Jordan.>> Finishes
* >> Why?>> Constant in time
* >> So even if this thing is tumbling andspinning and going through space as seenby you inertial observers
* The mass distribution keeps changing
* This point is here, it's up, it's left,it's flat, it's all over the place right
* That's why doing this derivative onany inertia tensers inertia frame you can do it
* But it becomes a time varying quantity andyou have to track all this stuff
* And it gets harder
* Whereas the derivative of the inertiatensor as seen by the body frame is trivial if it's rigid
* Because in the mass distribution,as seen by myself, if I'm rigid and I'm rotating and doing stuff, thatmass distribution is exactly the same
* And this is going to vanish
* If you had a deployable mass, you slowly having your solar panelsfrom your cube sat and doing something
* Then some servos that are moving them out
* Well then you would have body relativederivatives and that's the point where you include extra terms,all of a sudden, into these equations
* That's what gives you those extra stuff
* So good, so that term vanished
* Now here, this dot, Lewis,implies what type of derivative
* >> It implies an inertial derivative
* >> Here it's a body frame derivative
* So how did I go from a body framederivative to inertial derivative
* >> Make the vectorsconsistent between the two
* >> Right,this isn't omega of b relative to n
* So therefore, the b framed derivative and the n framed derivativehave to be the same
* That's the one vector whereyou find this kind of stuff, where the derivatives betweenthe two frames is the same if it's the angular velocitybetween the two frames
* Because the omega crossproduct term always goes to 0
* Exactly
* So, if you want to be careful,show all these steps
* In an exam don't just go from here andthat's clearly this
* I'm, you can be missing points
* I want to see all these sub steps
* Argue every case as you understand,this is why this goes to zero here
* And argue correctly why thisother one goes to this, right
* So, good
* So, the body around this derivativeis just going to be i*omega-dot
* Plus this cross-product term
* So, we're almost there
* Now, you put this together andyou get this differential equation
* I put this cross-product, H=Ic, so I have omega cross is the samething as omega two the h
* That's essentially how wegot to this last step
* I took it over to the right hand side, so I have i omega that is equal to minusomega til the i omega plus l c
* That's the classic ordersrotational equations of motion
* This is what predicts now, in your integration,how does my omega evolve in time
* And for a rigid body,tumbling like this, there's two aspects
* One is, this is a gyroscopic
* And you notice, it's omega and omega,so it's omega squared, is essence
* And it's a second order term
* If you look at linearized departures, youmiss all of this stuff, it just vanishes
* So, this is the quadratic,this is your gyroscopics and you'll see different waysthis manifests itself
* The other part is our external torque,and that's it and it looks really simple
* Why did this become sohard so quickly sometimes
* Well, we'll talk aboutdifferent ways to write this
* This form, we have a nice, generic i
* So, we can have a principle coordinateframe as we talked about earlier
* Or we can have any body fixed frame
* This can be a regular 3 by3 matrix representation and it will work, all right
* So, this is a very general format
* So in your integration, I would recommendthis is the equation you should implement because that way you're solvingalways the most general case and the easier cases becomesub classes of that
* If you pick, sorry Jordan
* >> Quick notational question,you have sub scripts on l and h but you don't have them on i
* >> Yeah
* Is that purposeful
* Or wouldn't you [CROSSTALK]
* >> Just lazy
* >> Same point
* >> I was just lazy
* >> Okay
* >> If you want to keep track,I do recommend
* If you want to keep track of them, this has to be the inertiaabout point C in this case
* If you wanted to keep track of that
* For these kind of rigid body dynamics, people very quickly drop them andit's just implied
* But it's a subtlety
* If you have multi body stuff and you takein moments and torques about you know, there's a different body fix point,there's a docking port point
* Definitely keep track of those suckers, because it's easy to get it mixedup when you're adding these things
* So here I just droppedit out of convenience, this is, you see this a lotactually in the notations, they don't declare themselves asbeing lazy, but [SOUND] I don't care
* Okay, so we have this
* Now, let's say we havea principal corded frame
* As we were hearing earlier, that means all the matrix representationof this tensor will just have diagonals
* Lots of off diagonals go to zero
* And the same thing here
* So, omega I omega will just becomei1 omega 1, i2 omega 2, i3 omega 3
* Really simple
* And then that 10 to the omega 2, you carry out this math andyou up with these equations
* So, these are equivalentto these equations, this just assumes I've chosenprincipal axes of the body
* Whereas this allows forany body fixed axises
* So, yes integration wisethis is what you use
* But, in analysis we often find itmuch easier to just look at this
* And in fact we will be using theseequations a lot here coming up
* The torque free motion anddiscuss different things
* So, you can see the classickind of results and L, L 1 2 3, is basically, this is all taken ina body fixed frame that's principle
* So, these are the same vector componentswith respect to that frame And then we go
* So, you can see now for example, if you have a axis symmetric body,we talked earlier about different shapes
* because if you have a cylinder, a rocketbody, a lot of things in space tend to be barrels because everythingfits in a rocket
* Well the rocket itself is kind of a barrelshape, it has an axis of symmetry
* In that case two principleinertias will always be equal
* So since in here the gyroscopics are allthese differences of two principle inertias you know right away [INAUDIBLE]metric bodies one of these gyroscopic terms is going to vanish right andthat's an insight to have
* I'll see this in a fewcases that we'll look at
* Now let's talk about howto integrate these things
* One question I have for you is, does, we've derived differentialnematic equation, just MRPs
* We know sigma odd is equal to one overfour b times is omega vector right
* So omega appears defiantlygoing to need that
* Otherwise we just need sigma Here,I need omega, omega, the inertia, it's a rigid body so with relative to Bframe, this is a fixed inertia tensor
* And then, you have external torques
* Nowhere in here do you see sigmas, orquaternions, or any attitude measure
* So if I have two differential equations,the question then becomes can you integrate just omegas first andthen do the attitude
* Or should you aways be integratingomegas in attitudes simultaneously
* [SOUND], I see some wrinkles now,okay, good
* Can we do it
* The sigma starts omega
* So, you know you can't do sigmas first,but I could do omegas first, integrate forward and then use that answerand then separately integrate omegas
* What do you think
* Andre
* >> I'd say simultaneously
* >> Because
* But you delivered the question
* >> I know
* [LAUGH] >> Hopefully you'regood enough at by now where you know I'm asking you a trick question
* And B, the gut feeling probably is I knowsimultaneous should definitely work
* Separating, now you need to arguea defense why was that valid, right
* There's simple answers, definitely
* I would also do it simultaneously,but why
* Is it ever okay to just integrate omegas
* And then do that
* Daniel.>> Don't have torques
* >> Okay.Torque free motion
* If I have torque free motion,I don't have my that works only here
* If I don't have the torque, absolutely
* You could just integrate omega
* Now in my codes, let me just say upfront,I always do it simultaneously
* Just, that's the most general answer,right
* And I don't want to write code forthese cases when I have no torque or here I have torque
* If I do them simultaneously,it doesn't matter if I have torque or not
* But absolutely, you could do that butlet's say we do have torque
* I have some thrusters I'm firing
* There's two thrusters,four thrusters, they're firing
* They're producing a torque
* Can you still integrate the omegas firstand then apply them to the sigma dots
* Need to have a situation where yourangular rates aren't coupled to your actual angle, itself, right
* >> Well, yes, the angularaccelerations we're worried about
* It's omega dot
* Does omega dot couple with the angles
* This will never makeit couple with angles
* This never makes it couple with angles
* The only term that could make uscouple with attitudes Is this
* My example with thrusters
* If I'm firing pairs of thrustersthat produce a torque and spin it,does that matter now on the altitude
* The thrusters are body fixed,so I get this torque
* If I spun around, then I thrust again,relative to the body, you always get in the same torque,it's actually just going to show up a bunch of constants,no attitude dependence that works
* Give me a torque thatis attitude dependant
* >> Gradient
* Spencer
* >> Solo radiation pressure
* >> Solo radiation pressure
* Right.Daniel, talking about atmospheric drag,those effects
* Gravity gradients
* There's all these kind of disturbances,often environmental
* All of a sudden, you need the attitude
* And then, whoa, now it matters
* When we do another thing[INAUDIBLE] as humans, we will be developing feedback control,and even the simplest form the torque, we come up with a thruster control torque,which is minus a gain times attitude error minus a gain time rate error or somethingvery simplistic like that, right
* And all of a sudden, through ouralgorithm, we're coupling in our attitude
* because we want to point here,not just come to rest over here, right
* And the thruster firings willbe a function of attitude
* So yes, so when you look at these thingsand it's a good PHD prelim oral questions
* There are ways we can one way decouplethem and solve omega separately and doing that parallel as Andre was saying
* Absolutely your gut feeling is right
* That's probably the wayit always will work and in fact that's how you should program it
* And the way attitude couples into it,thought, is only through this part, which could be environmental effectslike drag, SRP, gravity gradient or also we could external torques
* That's our control solution, all right
* That's what's producing these things
* And that's where attitudecouples in as well.


--- SKIP ---: 07_8-1-integrating-rigid-body-equations-of-motion.en.srt


--- SKIP ---: 07_8-1-integrating-rigid-body-equations-of-motion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_8-1-integrating-rigid-body-equations-of-motion.en_SENTbySENT.txt
* So, we want to integrate in a coupled way
* So, let's talk about this as youcan be writing code like that
* Let's just use sigmas
* I'm using my attitude beingexplicit here all right
* The other set of stakes that Ihave to integrate now are omegas
* So, we're going to put inan omega B relative to N
* So, your code you've written earlier tointegrate just the attitude rates can even omega
* It all works, it's just instead of omegabeing looked up in a separate sine and cosines or some function,it's now computed every time step and updated as well
* So you have to doeverything simultaneously
* Your x dot equals to F function
* F is basically the first partis nothing but sigma dot
* And the second part is omega dot
* That's what you have to find
* In your code, you already have this part
* So you know that and it's based onthe current omega, the integration, that's fine
* And now this one,also depends on the current omega but it also needs the inertiatensor representation
* And it needs to know what the externaltorques are and that's it
* So you can see once you have thosenice clean writings set up for dynamical systems,we can then easily expand
* Later on if we have reaction wheels,we have to keep track, those are extra states,CMGs, extra states
* You just start expanding the state vector
* But you can build on your prior work,and that makes life much easier, okay
* Any questions on this
* So, these are basic equations of motion
* H dot equal to L you saw
* It's like two lines withthe right arguments, and you get the equations of motionin a very general tensor form.


--- SKIP ---: 08_8-2-example-slender-rod-falling.en.srt


--- SKIP ---: 08_8-2-example-slender-rod-falling.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_8-2-example-slender-rod-falling.en_SENTbySENT.txt
* Where we have a slender rodthat's falling to the ground
* So basically, think of this rod
* You sign in this up ona frictionless surface
* Think of an ice rink, a very slick icerink and he's standing it up and for some reason this is perturbed
* There's no friction force hereholding your lower end in place
* So once you slide off you'rejust going to slide out
* So it's basically just going tofall down and slide down like this
* That's what's going to happen
* And what we're going to try to findhere are our equations of motion
* And we're going to use these veryprinciples, super particle theorem, HL equal to L
* The inertia tenser definitions and soforth to derive all the right quantities
* So I'm giving you here from a materialstatics book you can find easily if you have a slender rod then the inertiaabout it's center of mass is mass over 12
* L squared, L's length of the rod
* So slender means we'reignoring the other dimensions
* It's just a homogeneous, very,very thin mass distribution, right
* So that's what you get there
* So we're going, okay, so we have that
* Now let's look at the angular momentum
* If we want to write Hc, the anglemomentum above the center of mass, we needed the inertia tensor timesthe angular velocity of this stuff
* And you can see,I've got a body fixed point, a body fixed frame, E,that I'm defining here
* So EL, E theta, where is E3 pointing
* Let me just make sure you'relooking at the picture, right
* Into the board or out of the board
* >> Into.>> Into the board, right
* eL, e theta, e3,third finger points into the board, that's where it's pointing, okay
* So the angular velocityas we're tilting in 1d, it's going to be theta dot about e3,right
* So that's what this part right here,those two terms, that's omega of e relative to n forthis body
* Now I need the inertia tensor about thisone, so let's just write that one out
* You've seen the matrix notations, I want to make sure that youget all this stuff right
* So if we have this in the E frame,it's a principle frame, you will have I1, I2, I3
* And, let's just ignore this
* E relative to N, theta dot e3
* What does theta dot e3 looklike as a 3 by 1 matrix
* 0, 0, theta dot, right
* And yes, you have these other inertias
* We said, it's a slender rod sothere are some terms about that
* But in the end,this matrix times this matrix is just going to give me 0,0, I3 theta dot, right
* In different components, which is equivalent tothat I3 theta dot E3
* And in this problem I3 isthe N over 12 L squared
* That's the inertia about that,the third axis that we have, in and out of the board
* All right, we didn't needthe inertias about the long axis or anything else like that
* That's where, so when you've,this is something you want to practice
* Once it clicks,you go how was this ever confusing
* But you want to be able to go fromthe inertia stuff to this quick other formulations especiallywith the plane of rotation
* It should always giveyou equivalent results
* So good, so that's how we get this part
* We have to angle momentum about C
* Now to get equations of motion, one way we often do with rotationalside is we use Euler's equation, which means H dot = L and taking momentsabout center of mass, H dot = L holds
* And I need to have Labove the center of mass
* So let's see what do we have here
* What torch is being applied
* The only torch that's beingapplied here is this normal force, somethings holding that tip fromsliding beneath the I surface, right
* So the I is still pushing up
* It's just not pushing laterally
* So it's giving it lateral stability, but it is holding that point in place,all right
* Why does gravity's acting on this
* Why doesn't gravity cause any torques
* >> Ax on the center of mass
* >> Right, gravity ax on the center ofmass and therefore the moment on for the gravity force
* That's when you apply it,it would actually vanish
* Very good, okay
* So, we need the moment arm
* What is the point of force relative to thecenter of mass then that's this vector
* So, this length is L, so if going from here to here is minusL over 2 in the eL direction, right
* Back to week one,vectors are distances times direction
* The distance is eL over 2
* The direction is minus eL hat
* That's the moment armcrossed with the force, which is the normal force on the surface,right
* And you now have an eL crossed in n2
* Well you're going to have to map oneinto the other and that's what you get, a sign term in here in terms of e3
* So we can write this out
* So good, we're looking forequations of motion for theta, but all of a sudden we have tointroduce an extra unknown
* We don't know what thisforce is on the surface
* So we know right away H equalto L is not going to be enough
* You can't have twounknowns in one equation
* People try, they try really hard,it just doesn't work
* So we'll need additional equations
* Let's first wrap this up,we have H, we have L, now the derivative of this H, inertialderivative has to be equal to this L
* Well e3, this is a rotating frame butwhat can you say about e3
* Is that a rotating axis ora fixed heading axis
* It's fixed, actually, right
* It's the other two that are rotating
* So e3 is actually N1,it's the same thing as minus N3
* And N3's definitely an inertial frame sothat's why taken the intertial derivative of this, I don't haveto treat e3 as a rotating axis
* It's actually a fixed axis
* So this inertia is fixed
* I'm not changing the massdistribution of the rod
* The only thing that varies is theta
* So you very quickly get the inertiatimes theta double dot
* And here I've dropped e3
* Because in the end,everything's along the e3 axis
* So it gives me my one thing
* So H dot equal to L
* I brought L over to the left hand side
* And that's how that comes in
* So this is one equation
* I'm looking for always secondorder differential equations for equations of motion
* And so acceleration, that's my thetadouble dot acceleration equation
* But it have an extra unknown
* So H dot equal to L was not enough,what else do we have
* People
* >> Super particle theorem or energy
* Energy here is pretty smartbecause there's no friction
* >> Yeah, energy doesn't typicallyhelp quite in these equations of motion typically
* The principles we use is either H = L,there's different points we could use
* We've used for now the point c
* What was the other pointwe could have used
* An inertia point thatwas another approach
* And you can try H equal to L about centerof mass or about the inertial point and they can give you different information
* And that might be a wayto get a second equation
* But what we're going to do here isactually use Newton's equation
* Basically, super particle theorem, right
* That said, well whatever the sumof the external forces is, mass times the inertialacceleration to center of mass, has to be equal to that force, right
* So if we do that,the center of mass location, I'm just going to call this coordinate y,you can see here
* So Y doubled up in two because its owncenter of mass is only moving in N2 direction
* That makes it easy,it's an inertial direction
* Take it twice derivative it's justY doubly NY doubled up in two
* That's my big M times rcdouble dot that we have to review the particle theorem, right
* Now that has to be equal to the sum ofthe forces acting on the system, and this system only has two forces
* There is a force on the surface that'spushing back against the pen tip, keeping it just in place
* And there's gravity acting on the slot andthat's why we're falling
* Otherwise, if you have slipperysurface on the space station and without any other human slip
* So with gravity +N it'sin the N2 direction and NG is in the -N2 direction sothis gives you your differential equation
* But you look at this and go, I can seeBrian already going wait a minute
* We get an end that's good butnow we introduce a y
* We just seem to be chasing our tail here
* Every time we have an equationwe have an extra unknown
* So now we have two equations and threeunknowns we're not making any progress
* And Brian's absolutely right,so what are we missing
* We need an extra equation
* Are y and theta independent
* Spencer, are those two independentcoordinates of the dynamical system
* Or another question is, this dynamicalsystem has how many degrees of freedom
* >> One
* >> One, right,there's only one degree of freedom
* There's only one angle, right
* Now with that angle, we can prescribewhat that height has to be
* So there must be a geometric relationshipbetween the y coordinate and the theta coordinates, right
* Because you have y and theta, this didn'tturn it into a two degree freedom problem
* It's still a one degreeof freedom problem
* So what is the relationship
* And that's what we do here
* It's very simple, this line would be Lover 2 cosine, that gets you to heighth y
* That's what I have here, all right
* So if I have theta, I know y
* And now here, I need theta double dot, that means you simply take 2 timesderivative of this y expression, chain rule of this cosine, so you getsome sines and cosines and other stuff
* But that's how your y doubledots relate to your thetas
* Theta dots and theta double dots, right
* So those are not, we had two kinematicvariables that was convenient
* This y was very convenientwhen writing f = ma
* But in the end,we have to pick one of them and write everything in termsof one of the coordinates
* So if you do this, you plug this in here
* You can now,actually this depends on y and n, this depends on y and theta,I can now write n in terms of theta
* So I get rid of one of the variables, y
* And now the last step is this,this has to go back up in here and now we can write ourequations of motion for this slender rod falling in place,slipping down like this
* Looks a little bit more complicated
* It's amazing how life gets complicatedquickly, even with simple examples
* Now with this differential equation,is this a linear differential equation or a non-linear differential equation
* Non-linear
* There's sines,cosines of the states, right
* There's even theta dot squares, sinesquared of stuff, definitely not linear
* So who thinks they can quicklysolve this differential equation
* Darn, I always hope somebody raises theirhand because then I want to talk to you about a PhD program
* because I can't solve this
* Maybe a mathematician can solve this
* But it's tricky, right
* So how do we solve this
* Well, we go back to integration, right
* You put this in state space form
* x1 is equal to theta
* x2 is equal to theta dot
* Then you get your sets of equations
* You can integrate
* So numerically, no problem
* But analytically, this can be a challenge
* And very often in these problemswe want to have at least integration of one time
* That means, I'm looking for therelationship between positions and rates
* And it happens, you've done this,high school physics problems
* Bouncing balls,perfectly elastic bouncing ball, right
* The total energy has to be preserved
* It's a conservative system
* So therefore, we have ourpotential energy of the ball, and we have the kinetic energy
* And as you're up,you have a lot of potential energy
* No kinetic energy
* Let go, it trades potential energy for kinetic energies, butthe sum has to be the same
* Potential energy alwaysdepends on position
* Never rates
* Kinetic energy, you see the definition
* It's always ex dots, theta dots,it's all the rate of the coordinates
* So if you're looking for a relationship,and one of the homeworks asks you for this in part B in particularly, what's the relationshipbetween some states and rates
* Your first step shouldn't necessarily beto try to integrate this equation once
* That might be quite hard
* The trick is you're going to look foris the system conservative, and if yes,now we can look at the energy balance
* So people was talkingearlier about energy, this is typically where I use energysystems and I can come up with directly in analytic, at this angle whatis my rate going to have to be
* It's good conservative
* Now in this system there'sno lateral friction
* There's nothing doing work on the systemit's just a conservative one
* And this point here is not doing workbecause this point is not moving up and down
* Work is typically forcetimes distance moved and this point is not movingin this direction
* So this force end also
* This system is conservative
* And we can use conservation
* So this part should hopefully be boring
* Very simple, mgh, right
* Or this case, y,we have it as in terms of the angle theta
* I know what the potentialenergy is of this rod
* I need the total mass of this rod,the moment arm, the height of the surface, I've got that
* The kinetic energy,now remember how do I get this
* Kinetic energy, like momentum, I can breakup as the kinetic energy of the center of mass plus the kinetic energyabout the center of mass
* For weird complicated tumbling things likethis I really recommend that approach
* Sometimes there are shortcuts withother stuff that you can quickly do but this is a way that's very rigorous, youwon't double count terms all of a sudden
* So the kinetic energy,all the center of mass is mass over 2 times the onlyvelocity we'll have is y dot
* And we know how to relatey dot to theta dot right, by using that earlier geometryexpression and differentiating
* And then here is the momentover 2 times theta dot squared
* That's the one-half omegatranspose i omega but put back into everything's about E3
* And it all simplifies down tothe simple scalar equation
* So we've got that
* So you plug in that kinematicrelation between y dot and theta theta dot simplify
* This is what you end up with
* So you do something very similarin the homework to this
* So now we have kinetic energy andpotential energy and if you sum the two up, I'm seeinginitially this rod is standing up, and yes, something has to disturb it but the disturb it's beentreating us infinitesimal
* So the total energy is basicallyjust the initial potential
* And then something turns it ever soslightly and it will start to slip, right
* And so the initial one is this
* And then we want to look at what isthe relationship at a later time so now we know at a later time we plug in thisplus this has to always be equal to this
* This is the total energy system
* So no matter how far you slippedof whatever angle you're at, I can come up with a relationship
* And in fact, solve for the thetadot which we do here analytically
* So energy's become very powerfulexpressions that we can use in these systems to actually predict some greatrelationships to states as well
* If you looked at the priordifferential equations, I would challenge anybodyto just glance at this
* And then predict that this is howstates and rates have to relate
* It's not intuitive,that's why we have these principles, these mathematical processesin there in place, to do that
* So anyway that kind of wraps that one up
* Any questions on this example
* So when you solve this equations,and there's a few in the homework, if you want to look for h dot equal to l,but apply it about points that make sense
* Either center of mass,that's often a very good place to start
* Or you might find thatinertial point as well
* And that might,both of those equations might give you all the information you need
* The other one that we have isF = m a of the center of mass, that's the super particle theorem
* Between the combinations of that youshould always get all the states, everything that you need
* If you have multiple kinematic states,it's only one degree of freedom look for the geometric relationship
* How does theta relate to y or z orwhatever you introduced, all right
* And if the statement is somehowrelates states to rates immediately think energies
* Look for the system most likelyto system is conservative
* And that allows you to exploitconservation of energy in some way and come up with these relationships, okay
* Good, so that's good stop, not,well for that topic that ends there
* We've got two minutes, that's good
* Well let's do a quick thought experiment
* So now what we'll move nextinto is torque free motion
* Daniel already mentioned earlier that ifits torque free motion certain special things happen
* And in fact,spacecraft once deployed from a rocket, the initial stage is alwaystumbling in one way or a manner
* And then you have to recover,maybe we use magnetic torque bars or we use thrusters orreaction wheels, or something
* And we want to go positive
* Or these all these different challenges
* And even otherwise, you don't havea situation typically where you're continuously controlling attitudebecause you just run out of resources, even with reaction thatonly use electrical energy
* It's a lot of effort
* You try to exploit as much youcan the natural dynamics, and the natural dynamics is no torque,it's just there
* So can we come up withspacecraft that spin
* And people do that quite often
* They spin stabilize a single rigid body
* Or we'll be looking at dual spinners thatmeans we have multiple parts that spin, but without any feedback
* And then multiple parts that's basicallya stepping stone into reaction wheels, momentum exchange devices,which we'll derive afterwards and stay up there as well
* So that's kind of the motivation for whydo we want to look at torque free motions
* Really a classic problem, even with threeaxis control these days you still want to understand the different modes
* Why are some motions stable
* Why are some motion unstable
* And one of the equilibria spin conditions
* And if I put it in a particular spin,will it just stay there or will it wobble out of that spin andgo and get in the way
* And one way we can investigate thatends up being angular momentum
* The angular momentum vector H of a rigidbody, we know if it's torque-free, H dot has to be equal to 0 which immediatelygives us a constraint equation
* But this first cut at it thoughis very complicated because if I do everything in the inertia frame,I will get three components
* They all have to ce zero
* That's great but your momentum inthe body frame, if I have a principal coordinate frame, is simply i 1 omega 1,i 2 omega 2, i 3 omega 3, right
* We mentioned principal coordinate framethat inertia tension that's just diagonal
* So it becomes a very simple product
* h is equal to i omega
* But then we have to map thisinto the inertial frame
* And here I'm using [INAUDIBLE] interms of three to one Euler angles
* And immediately,you get all these relationships
* But you can see there's tons of sines andcosines and omegas and everything varies with time
* And true, that's a constraint, but it's very had to wrap your brain aroundthat and get some analytic insight
* So next time when we start offwe're going to start here and I'm going to show you a different approachwhich leads to the pole hold methods
* Those of you who have taken 3200 haveseen a little of this stuff already
* But it's a classic approach inhow we can discuss stability, but we'll take it all a stepfurther then from that as well.


--- SKIP ---: 09_tips-for-solving-spring-particle-systems.en.srt


--- SKIP ---: 09_tips-for-solving-spring-particle-systems.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_tips-for-solving-spring-particle-systems.en_SENTbySENT.txt
* Another one, I just wanted to highlight,because this comes up a lot, is this one
* This problem here
* Mass over two
* We've done everything in class that youneed to get these equations of motion
* So when we're getting equations ofmotion from mechanical systems, what type of fundamentalproperties do we use
* Lewis
* >> [INAUDIBLE]>> No
* Not to get equations of motion
* We use conservation ofenergy if I'm looking for relationships between rates and states
* But you can't use conservation of energyto get your second order differential equations
* >> [INAUDIBLE]>> Okay
* So there's F equals mass timessome acceleration vector
* Right
* When does this hold
* >> Mass
* >> Okay, mass constant, what else
* >> [INAUDIBLE]>> This has to be inertial derivatives, so this r vector has to be takenrelative to an inertial point
* And you take inertial time derivatives,yeah, when else
* >> It's constant
* >> Well, yeah mass is constant, yep
* Does it apply to this pen
* Russell, you're saying yes
* >> It's constant mass
* >> It's constant mass
* So it is good for rigid bodies
* >> [INAUDIBLE]>> [LAUGH] >> [LAUGH] >> Okay
* >> [INAUDIBLE]>> You're applying what to it
* [INAUDIBLE]>> [LAUGH] >> I'm getting wet there's so much back paddling here
* Okay.>> [LAUGH] >> So yes to this to what
* This is Are made
* Come on, how hard is that right
* >> What was your question?>> People write whole PhDs on this equation
* Anybody doing Orbitz,you can tell your parents that's it
* I spent five years workingon this equation you know
* That's it
* F = MA
* How hard is it
* But it is hard
* It gets very quickly hard
* So where does it apply to
* And I'm saying this pen
* Can we use F = MA on this pen
* Andre, what do you think
* >> Absolutely
* >> Okay, good answer
* Now second part is what
* >> What
* >> Why
* >> [LAUGH]>> You want to model the trajectory of the pen or something
* >> [LAUGH] What part of the pen
* I need it more specifically
* >> Center of mass
* >> Center of mass
* Right
* What did we call that theorem
* >> Super particle theorem
* >> Super particle theorem, right
* So F= MA holds forthe super particle theorem
* That's, in fact, how you do your wholeProblem, and you just basically ignore the rest of the mass distribution,you say the space station is a point
* Which is a decent assumption forsome analysis, obviously not a good assumption forother analysis
* Depends on what you're doing again
* So good, so this could be true fora whole system not just for a point mass
* We typically have it written forpoint masses
* If it's a super particle theorem,what is F then it that case
* >> External forces
* >> A single external force
* >> The sum of all
* >> The sum of all the external influencesthat happened on the system, right
* So that's important because you canactually use that in this system to argue things about are there any externalforces on this dynamical systems
* And if you ask what does that mean,and if not, what does that mean undercenter of mass motion
* But that's one of them, so this works fora system, but it also works for a particle
* Don't forget the very basics
* You can do F=MA on a particle as well,and this also holds, and you have to write this relativeto any inertial point, I'm just going to give you the tape,it doesn't have to be some point dot here
* There's a much more convenient inertialpoint in this problem that you could write everything relative to
* And now things become very simple
* But what's the otherequation that we've used
* So we have F=MA on particles onthe center of math if it's a system
* And in this case you could do either
* You could do free body diagram anddo on that or what else
* >> H.=L
* >> H.=L
* All right
* And that also works but if you say H.=L, you're taking points about where
* It's like moments talk about which point
* >> Well you can pick the point right
* But the center of mass iswhere you're doing it about
* [CROSSTALK]>> You can use center of mass
* Is there different points you could
* It could be an inertial point,right, and either
* And you can play with that
* And then you write up your momentum
* Do this, or you can do these equations
* Or you will find maybecombinations of this
* You have to have enough, how manydegrees of freedom does the system have
* Two, the rules of freedom ishow many independence states do you need to fully describethe current configuration, right
* And the r, there's I thinkthis here has a radius r and then you have some angle theta
* So in the end you need differentialequations for both of these, right
* So you're going to have to use thesevector equations and break them up
* There's many different waysyou can solve this, all right
* But this is something where I'm lookingfor you to apply these very principles
* There's lots of easy ways you can do it,but breaking everything down, and sines and cosines galore, I'm givingyou a rotating frame for a reason
* I want you to use that E theta direction
* Write it that way, it'll give youan answer that's actually really, really fast and compact
* That's what you're looking for
* Once you see how to apply thoseprinciples it goes very, very quickly.


--- SKIP ---: 10_optional-review-rigid-body-properties.en.srt


--- SKIP ---: 10_optional-review-rigid-body-properties.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_optional-review-rigid-body-properties.en_SENTbySENT.txt
* If we make it rigid
* We've already jumped aheada little bit which is good
* Sometimes just rearranging your orderhelps things sink in more, right
* If it's rigid,what is the key differentiation
* So Sheila was on the right track earlierthat it's all about these derivatives, especially this little r dot
* And if it's rigid, then the derivative of this vector as seen bythe body frame has to be 0
* So you just end up with omega cross r,right
* If it's not rigid, then this little massparticle is maybe deploying, it's moving, it's wobbling, it's doing something
* And you have extra turns
* That's, in fact,what you'd have to include
* Now you plug this in, andwe only focus about this one
* You can separate this also for rigid body,like this plus this other term
* I'm not going to do that here
* But in the end, the angle momentum about the center of mass ended up being this minus r tilde, r tilde, dm times omega
* What did we call thisbig bracketed term here
* >> Is that the inertia tensor
* >> That's the inertia tensor
* And I like using the word tensor versusmatrix, because there's a difference
* We have a position vector but then we use a matrix to define the vectorcomponents with respect to some frame
* So the matrix represents a vector butthe vectors you can fundamentally just add vectors and add arrows andyou don't have to assign frames
* Same thing here
* Now in this tilde notation, this isbasically the cross product operator which will be the vector equivalent of it,right
* You have to make sure that r tilde
* You have to take this vector, r,with respect to some frame, the B frame, as an example
* This would be in the B frame,that's what you measure
* Now it's apples and apples andyou can do all your matrix math
* You wouldn't have this in the C frame andthis in the B frame
* And then you'd be mixing frames andit just wouldn't work out well, all right
* So we have to do the integration bypicking a body frame and then we get this
* And also little r is defined relativeto this body's center of mass
* That's how we defined little r
* What if we have a different point
* Maybe this thing isn't spinningabout its center of mass, but it's pivoted to an end of an arm,and it's pivoting like this
* All of a sudden, I need the inertia about this endpoint,not about the center point, right
* Do we have to redo thisintegration over and over again
* No, right
* So there's formulas on how to do this
* This, in essence,is my inertia tensor times omega
* So written like this, treat this as a completelycoordinate-independent formulation
* When you're actually numerically evaluatedin some program like MATLAB or C or something
* You have to make sureit's the same frames
* But when we derive controls, we'll just write it this way andnot assign frames yet
* That's the bookkeepingyou do at the very end
* So good, that was the inertia tensor
* So let's wrap up some final things
* What if we have a,let's just flip the order
* Let's do attitudes first,just to mix it up
* What if we have a different orientation
* You have the inertia tensorgiven to you in B frames but I want the inertia tensorin frame components
* I don't have to redo allthose body intervals again
* Once you have them, you're good
* >> Do you have to left multiply andright multiply
* >> Okay, sogive me the two letters of each DCM
* >> [INAUDIBLE]>> So it would be BE, right, or no EB, sorry, backwards
* >> Won't let me erase
* Okay, EB, and the next one is
* >> [INAUDIBLE]>> Or B
* I like to remember it this way actually
* because this way if I know BE, great,then have to transpose this one
* If I know EB, fine,you have to transpose that one, right
* But it's basically if this is in the Bframe, then it's a two-dimensional
* Think of tensors liketwo-dimensional vectors
* So instead of using the DCM once,it's a 2D thing, you have to use it twice
* And you're absolutely correct,it's a left and a right multiplication
* And when you bump them up like thatthe letters B should match up
* This is all on the B frame
* And then what's on the outsideeverything's being mapped to the E frame and you get a inertiatensor in the E frame
* So a different rule of mnemonics trickthat you can help to remember this stuff
* Definitely use it twice
* Good, so that's how we avoid, once wehave this in some body fixed frame, we can easily map it to anyother body fixed frame
* I will use this trick several times,especially when deriving variable speed, c and g equations of motion, and so forth
* So what do I mean bya principal coordinate frame
* Is it Tosh
* What does that mean
* >> The [INAUDIBLE]
* >> Mm-hm, so let's say F is principal
* So what about the diagonals
* >> Of the principal
* >> Let's just call this I1, I2, I3
* What about the off diagonals
* >> They're 0
* >> So, they're 0
* If this is a principal frame, you have a coordinate frame suchthat you get a nice diagonal form
* Chuck, can we always do this
* Or are there assumptions onthe shape that allow us to do this
* It's a rigid system
* >> Yes, you can always do it
* >> You can always do this
* That's why for analysis very oftenyou see papers or even our own stuff
* We need to start out withassuming it's a principal frame
* because instead of havingnine elements to track and now with symmetry it's actually six, butstill it's about I can go down to three
* Three principal inertias fully definethe mass distribution of a system
* Without loss of generalitywe can always do this
* In the code, though, we typically solve, actually we do control problemsthat include the full tensor
* Because in real life they willnever give you the mass balance
* You may start out with a frame that'sperfect, and at the very last minute astronaut A and B switch places, andnext thing you know your CG's offset
* Crap, my inertia tensor's nowfully populated, darn astronauts
* So there's always something
* So in the code,we want to have formulations and controls that handle any inertia tensor
* But we want to also realize foranalysis and we design it typically they're diagonal ornearly diagonal
* The off diagonal termsmight be very small
* We want to have solutions that work foreverything
* So good, this is symmetricmatrix from the definition
* Could you have inertias, I1 = 800, I2 = 20, and I3 = 50
* I'm just using generic units
* I'm not throwing in anything particular,they're just consistent numbers
* Is that possible
* So we didn't discuss, I'm just curious
* Everybody here has seeninertia tensors before
* Are there constraints inthe principal inertia values
* You find lots of publicationsthat they publish stuff, where they throw in inertias like this
* And as an editor I can go,hey, wait a minute
* This is a non-physical system
* There are limits to howdifferent your inertias can be
* In fact there's an inequalityconstraint that says, the I, principal inertia + the J of principalinertia have to be greater than or equal to the kth principal inertia
* So if you sum any two of them,you have to be bigger than the third, whatever the third is
* And if you go, andlet's just look at that
* Here we go
* If you look in this,this is the I1, I2, I3
* These off diagonals are all 0, right
* So I1 i r2 squared and 3 squared
* This one is r1 squared and 3 squared
* So summed up, I get r1 squared2 squared and 2r3 squared
* Compared to the third, it's just r1squared and 2 squared plus an r3 squared
* That squared term can at best be 0,which means they're equal
* But if anything else, it's going to haveto have something bigger, all right
* So when you set up inertias, be carefulthat you actually use a realistic example where the sum of 82 principalinertias has to be bigger than or equal in a limiting case to the third one
* So there's different kind ofproperties that you can pick up here
* So good, we have that
* Now we know how to do this
* How do we go from,what's the relationship
* If you have a regular 3x3 matrix and you're trying to findthe principal inertias
* How do you go from the 3x3 tensor matrixrepresentation to the three principals
* What was back row scratching your head
* What's your name
* >> Mark.>> Mark, thank you
* >> Can you repeat the question please
* >> Sorry?>> Can you repeat the question please
* >> How do I go from a 3x3 inertiatensor representation to a diagonal
* How do I find the principal values of->> You have to find the eigenvalues and the eigenvectors
* >> Exactly, right
* So you have to find eigenvalues,eigenvectors of the system
* And the eigenvalues,of the 3x3,they are all of the principal inertias, that's cool
* And then the associated eigenvectorsare the axes of that principal inertia
* And are relative to the body,it turns out
* This is a principal axis, and this is a principal axis,then you'd have a third one, right
* Now are these eigenvectorsalways going to be unique
* Jordan, think of a cylinder
* If you get this math, I can give you a nice 3x3 matrix ofa cylinder with some weird skewed frame
* You find principal inertias
* If it's a cylinder, what shouldyou expect now, all of a sudden
* >> Expect one to be up the axis andtwo to be in that, in any plane
* >> Right.>> Anywhere in that plane
* >> So you will have a repeated eigenvaluesset orthoganol to the symmetry axis
* The inertia of a cylinder about this axisor this axis is just going to be the same
* So you get a repeated eigenvalue
* And the plane is unique in that case,but not necessarily the values, right
* So this is how thesethings all relate again
* And these matrices are symmetric,turns out they're also symmetric definite because the principalinertias have to be positive
* You would never havea negative principal inertia
* It just doesn't make physical sense
* So, okay, so good properties there, good
* Now, the last thing we want to review is,what if we have a different point
* We have the inertia tensor about c, I want the inertia tensor about a point q
* How do I go from this to this, withoutredoing all the math, all the integration
* Kevin
* >> You need add,The mass of the whole body times, Just like the vectorbetween the two points
* >> Yeah, so let me just say that c relative to q, they're close
* It's usually a parallel axis there, right
* If you do it for1d rotation it was always easy, it was something the inertia aboutthe center of mass plus the distance
* So if I have the inertiaabout the center of mass, I want the inertia about this endpoint
* I do mass times distance squared,it's squared I think, that I get there
* This is essentially masstimes distance squared, and this is the distance betweenthose two points that you'd have
* It doesn't have to be an inertia point, it could be another point as well,like base point
* Now what are some the trickeries in here
* This is typically given to you in the Q
* Let's say this is your spacecraft queue,Star Trek, right
* Anybody remember Q
* That was one of the characters in there
* So in his spacecraft,Q lives in a very Q-centric world
* So this Rc relative to Q isusually given to you in a Q frame
* This stuff is probably givento you in the body frame
* Now before I actually can do this math, what do you have to dowith these quantities
* >> You have to change them
* Body frame to Q frame
* I'm sure, but body frame to Q frame
* >> So you have to map this to the Q,is that the only way to do this math
* Warda, or is there another option
* You could, because this isn't the Q,everything is kind of in the Q space, you'd have to make this into Q
* What else could we do
* This isn't a B
* Is there any way you canmake this in the B frame
* Tony, what would you do
* >> Do a rotation matrix on the R
* >> You can also just say, well,so I know this in the Q frame or I can also find c relativeto q in the B frame
* Which is BC times R C relativeto Q in the Q frame, right
* If you did this now you plugthese in here, and then this
* Just make sure it's consistent
* I didn't say we have to havethe answer in B or Q components
* You can do either
* Well, you can do one and then mapthe answer back into the frame you want
* That works as well, if it's a thirdframe that's not either C or Q or B
* So you can see lots ofdifferent ways this goes
* This is the general math butif this is the coordinate independent way, a coordinate frameindependent way to write it
* When you evaluate it, still makesure you have all the right stuff
* Otherwise, nothing works
* Okay, good.


--- SKIP ---: 11_optional-review-rigid-body-equations-of-motion.en.srt


--- SKIP ---: 11_optional-review-rigid-body-equations-of-motion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 11_optional-review-rigid-body-equations-of-motion.en_SENTbySENT.txt
* Last time, we derived the equationsof motion of a rigid body
* I got little cube with me here,it's somewhat rigid right now
* How do we find the equations ofmotion of a rigid body, Spencer
* Before you read too much
* >> You use super particle theorem on thiscenter of mass because it's rigid, so the center of mass shouldn'tbe changing position
* >> True,if you worry about the translational part
* At this stage of the class, reallyas we're talking about rigid bodies, we're going to start just droppingthe translational, for most of it
* If not I will make it very explicit
* So if I'm talking aboutthe equations of motion, I'm really just talking aboutthe rotational side of it
* So how do we find the rotationalside of the equation
* What are we actually looking for
* What's the variable
* Yeah, we're actually looking foromega dot, right
* That's the,omega is already a rate information so omega dot is the acceleration
* That's your angular acceleration
* Once we have it we can integrate it
* So whereas translation have f equals ma, you go straight from forces toacceleration of your position description, in attitude we have this kinetics andkinematics always broken up
* We have somehow added to coordinate ratesrelated to omega, and then an omega dot relates to forces and torques andeverything acting on it, right
* So you have this clearsplit that you have to do
* So here we're looking forthe second part, the kinetics
* What's the fundamental property,Robert, that we use to drive this
* >> [COUGH]>> [INAUDIBLE] >> Which principle did we apply
* >> Conservation of angular momentum
* >> Why is it conserved
* Why is the rotationalmotion of a rigid body, why does it have a conservedangular momentum
* >> because->> Ansel, can you help him
* >> It's torque-free
* >> If it's torque-free, butI didn't mention torque-free motion
* So let's assume it has torque,what do we need then
* How do we get to an omega dot
* Mariel, which principles do weuse to get equations of motion
* >> Like H equals the derivative of H time, or plus, omega cross
* >> Okay, you've takenthe derivative of it already, but what is the inertial derivative ofthe angular momentum of the system
* >> The right hand side of->> Yeah, L
* >> L, there we go, right
* So like f equals ma, this is good for a continuum if we have center of mass, or,and here implied if I don't write a sub c, it's always implied to be centerof mass in this notation, right
* So we can use H=L, the key features is,this dot has to be an inertial derivative, like f equals ma, those a's haveto be the inertial acceleration
* And this L is the net sum of allthe external ports acting on the system, which right now we're just writing as L
* Later on, that could be gravity gradienttorques, it could be drag torques, it could be control torques withthrusters, or something like that
* Many ways to break it up, good
* So let's review quickly, this is going tobe a good, what is H of a rigid body
* All right, once we said this thing wasn'tblob and jello and flexing, it's solid, what did H become
* Was it, Brett
* >> Not sure
* >> What is angular momentum
* Go back to your sophomore level class,fixed axis rotation
* What is angular momentum
* >> Is it the inertia times->> Yes, inertia times what
* >> The regular rate
* >> Yes, andthis is the 3D version of that
* i omega, right
* Review this stuff, otherwise, hour and 15 minutes you're not going to havetime to remember such things, okay
* We're getting up to that exam point
* So if H is this, this is the inertiatensor, right, we talked about that
* This is written as is in a coordinateframe independent way, you just have to make sure if this is in the B frame,this needs to be also in the same B frame
* And this gives you the answer ina rotating frame and the B frame but you could pick any frame you wish
* Good, now we need to do H dot
* So Mariel actually alreadygot us on this track
* We need an inertial derivative and we choose to take a bodyframe derivative of H
* I won't go all the details,we did that last time
* This is just a review
* Why do we choose to doa body frame derivative
* Kevin
* Why is that going to make our lifeeasier dealing with this term
* Let's break it up,you're going to have chain rule
* You're going to havethe body frame derivative of this tensor timesomega plus the inertial tensor times [COUGH]the anglular velocity
* And that's not H dot,let me just, scratch that
* We're just doing, we're choosing todo the body frame derivative of H
* So Kevin, why do the body framederivative of I omega easier
* >> Because then the derivative ofthe inertia matrix is going to be zero
* >> Exactly, and see by the body,every point to here, if you just lock your arms out and you start rotating, as you'rerotating that arm is always to your left
* The mass distribution,all those moments you computed, and you got the inertia tenser,they're fixed, as seen by the body
* As seen by you guys as I tumble an object,the mass distribution is clearly changing
* So if you did the inertialderivative directly on this, you'd have lots of extra terms
* You'd have to map it tothe inertial frame, DCN, DCN dots, DCN dots r minus omega til DCs
* And it all looks much more complicated,but it's the same simple answer
* This ends up being,as seen by the body observer, it's 0
* So that's why we do this,what happens to this derivative
* Anybody remember
* What happens to that, yes
* >> It's just omega dot,because it's the same inertial frame
* >> Because this is really,if I write omega, it's short for omega B relative to N
* We're typically dealing with B and N for the next several weeks sothis becomes much easier
* The B and the N frame derivative are thesame, the cross product always drops out
* Good, so if you do all this stuff,then H dot as Mariel was pointing out, really ends up giving you I omega dot plusI have to do the transport theorem so I have an omega crossed H andH is I omega, and that's equal to L
* There we go
* Is this only true forparticular coordinate frames, or is this true for any frame
* Daniel, what do you think
* >> An inertial frame
* That's two frames
* >> Yeah, this is really written ina very frame agnostic way again
* We haven't picked anything, we just solvedit, like we did earlier with positions and angular velocities
* They're just vectors, we can start adding, subtracting them without everspecifying where does EL really point
* Once you want to get a numerical answer, well you have to resolve the geometry andhave all the right stuff
* And so this is kind of the same way,this is a very, like a vector
* We have vectors and tensors butthey're written in a frame agnostic way
* And when you do the math, just makesure everything's in the same frame
* Especially when we get to the controlside, we'll be doing this a lot
* This is how we'll bederiving our controls, but when you code it,you have to go, wait a minute
* This will make a R, that's coming in, that's in the R frame andthis stuff is in the B frame
* Well then implied, you're going tohave to do some translations
* Matt
* >> I was writing when you wrote it,[COUGH] and I don't remember from last time
* Where does the second term inthat L equation come from
* >> This one
* >> Yeah
* >> I need H dot equal to L
* And basically what we do is, we takethe body frame derivative of H, but I need the inertial derivative, soyou need omega crossed H as well
* And omega cross, H is I omega, and omega cross H is the samething as omega tilde I omega
* That's the form we typically see it
* >> Cool, thank you
* >> And then that's L
* So you can see, in exam this is somethingthat shouldn't take you more than three minutes if you know what you're doing
* But there's lots of subtleties,if you just jump to the answer, the answer's in the equationsheet you guys have
* Just giving me the answer willgive you zero points in the exam
* It's all about the path and the details
* So make sure every time we gothrough this, hopefully more and more will sink in
* Make sure you get this stuff
* So, good, now we have very specific framesthat make your inertia tensor diagonal
* Trevor, what do we call such frames
* >> Principle frames
* >> Was principle coordinate frames, are there an infinity ofprinciple coordinate frames
* You say no
* And you slow down
* [LAUGH]>> Well, for a particular application, for a particular rigid body,it'll be the same
* >> So, here's a nice rigid body, are there infinity ofprincipal coordinate frames
* >> Mandara, you think so
* Why
* >> because we have one axisas they symmetry axis, we can have the other two inthe plane orthogonal too
* >> Okay but if it's a cube
* >> Then all of them are->> See, all of a sudden, ooh, wait a minute
* >> [LAUGH]>> If it's a cube what happens to my principle inertias
* >> They're all the same
* >> Yeah, they're repeated
* Hm, right, all these easyquestions at 8:00 in the morning
* >> [LAUGH]>> I need more coffee
* Okay, so if they're all the same, why doesit make you hesitate all of the sudden
* >> because the vectors, the uniqueness
* >> Yeah, then you have to kind of, the eigenvectors form differentways that you can map to there
* You have to take a closer look at it
* If it's a body,let's go to a simpler body
* This one has three distinct inertias
* It's definitely rigid, right
* Are you going to have more thanone principle coordinate frame
* Bryan, you don't think so
* >> I think you probably, yeah,I think you probably could
* It depends on the symmetry of the object
* >> This is it, I'm showing you the object,there's no more depends, it is
* >> Right, but if you take the momentof inertia around one of those principal axis, negative momentof inertia on the other one
* >> Right, for every body,it doesn't actually depend on the shape, every body has at least some principalaxis that will diagonalize it
* And maybe an infinity, if it's a cylinder,that's kind of what you guys are thinking of, if it's a cylinder, there's definitelyan infinity of ways that you have it
* But if you have even three discreteones like this, or it's something very amorphous it will still have threeprincipal inertias, principal axis
* But when you pick those eigenvectors,you remember wait a minute, I can have a positive direction butwho says this isn't your principle axis
* Maybe you want a frame the points towardsthe tail because that's where your docking porter is or you want to port towards,find the points towards the nose because this is a flight frame and youkind of worry about where you're flying
* There's immediately, well there's twooptions and then there's another one and so there's a kind ofpermutation you can go through, there's an infinity of principleframes that a general body would have
* But there's definitely a finite setbecause you can always rearrange what's your first, what's your second,what's your third
* And plus or minus,just always keep it right-handed, right
* So yeah,there are several that we can pick and so if we look at that,we went through that actually
* If this is diagonal, these simplify downto those three scalar equations we saw, and then we can do that
* Now, the last question we hadwe covered was integration
* If you want to integrate the completemotion we have something and we give it a spin and it tumbles
* How do we now numerically solve this
* Tosh, help us out,how do we now write an integrator for a complete 3D attitude dynamics
* >> So you'd look at your omega dot and[INAUDIBLE]
* >> But besides omega dot,what else do you need
* What describes the fullattitude state of a rigid body
* >> I guess, [INAUDIBLE] general forces
* >> Nope, I'm asking forwhat describes, what coordinates do you need to fully describethe orientation of a rigid body
* >> There's no other answer butMRPs, I would say
* >> Not MRPs,it was a good answer, definitely
* >> [LAUGH]>> Thanks for sucking up, I appreciate it
* >> [LAUGH]>> So you need an attitude measure, right
* Just like if you have f equals ma, spring mass to amperes system,think back to that form
* Okay, we've got x double dots,that's nice
* But I have, every integrator writesthese things back into first order form
* So you define that x1 is equal to x,and x2 is equal to x dot
* And then x1 dot is equal, andyou just do that classic stuff
* We have to do the same thing for attitude,it's just we have different equations
* So we still need the attitude measure, that was the integrator you wroteearlier in these classes, right
* So you had something forMRPs or quaternion or whatever you wish to,some attitude measure
* So that means you have a statevector that is going to be now a, if it's an MRP it's six by one
* If it's a quaternion it's a seven by one,right, this is what we have to propagate forward
* Otherwise this is very much what you didbefore, you have your current states
* Then you compute k1 isequal to the derivative
* So if x dot is equal to an f function,depending on these, all right
* Then the first order one would just giveme what's the derivative of these states
* And then xn + 1 is xn + k1 times delta t
* Or you can do a fourthorder on the cut out or whatever you wish to integrate, right
* It's the same integration thatyou're doing in those problems, you're just expanding now, now we haveto keep track of attitude and rates
* Now there was some discussion thatwe had regarding, could we integrate attitude separately from our kineticsequation, from our omega dot equation
* So, Nick, do you remember the arguments
* How does attitude actually coupleinto this differential equation
* >> [COUGH] I guess you couldsingle out the omega dot term
* >> No, omega is the state
* It's not,>> I guess I don't understand the question
* >> How does attitudecouple into this equation
* Does this differential equationdepend on my instantaneous attitude
* >> No, well, I was confident
* >> It was very confident,I give you kudos for that
* It was completely wrong, butit was very confident, absolutely
* Why does attitude couple into this,where, right
* because omega that's just another state,that's not the coupling itself
* It's a derivative of some stuff
* The interia tensor, well,that doesn't really, I don't have different massbecause I point differently
* It's a rigid body,it doesn't matter on the orientation
* The only thing left is L,How does attitude couple into L
* What are some physicalexamples of torques
* Daniel?>> Some torques are added to it independently
* >> Yes.>> Drag, SRP
* >> Drag, SRP, gravity, gradience,or even our feedback control, you will see very much,that's where it couples
* So while there's instances where youcould just solve for omega first and then solve forthe attitude as you did kind of
* I just gave you the omegas essentiallyin earlier homeworks, right
* When you code it,I highly encourage just to avoid that, just give the general answer,it's simple enough to do
* And you want to solve your attitude andyour omegas all simultaneously
* Later on in class we can even addother stuff like reaction wheels or, that quickly moves to 6010,the follow on class
* Matt?>> [COUGH] Excuse me, I have a question about thatequation on the last page
* So when you were just asking thatquestion I was thinking that you were pointing towards the I's becausethis is an inertial derivative and the inertial frame I will change
* But are these is constant becausewe derived it in the body frame
* >> These are just tensors
* I mean if you say constant I have toask constant as seen by what frame
* The inertia is not a matrix like a DCM, where it's just a three by three groupingof cosines that we picked, right
* We could have picked something else
* This is really fundamentally a tensor
* Which means just like a vector it, when you numerically evaluate it youhave to pick a coordinate frame
* So I just said look this been a completelyvectorial thing I can take the body frames derivative of this andwhat happens then is, well the body frame derivative of H,and H is I omega
* You break it up into two parts, right
* Here, I can immediately say this part isgoing to go to zero, which simplifies it
* And this derivative body frame is the samething as the inertial derivative, as we discussed
* So this H B frame derivative becomesnothing but I omega dot, that's this part
* Could then, to get the inertialderivative, I have to add omega cross H, which is equivalent to here
* So this gives me the answer but I've never actually pickeda particular courting frame
* Remember when we're usingtransport theorem and we say we're taking the derivativeof vector as seen by this frame
* It doesn't mean you have towrite that vector in that frame
* Often we have,that's why we've chosen that frame
* Here, we haven't chosen the B framederivative because we have a particular coordinate frame, we've chosen a B framederivative because as seen by the B frame, the mass distribution for a rigid body isconstant and that derivative goes to zero
* >> I think this was my confusion,no matter was I is, it's constant
* >> It's constant, exactly
* For any shape with asymmetries and whatever's going on,this is always true, right
* The only thing is, it's rigid
* That's the single rigid body andnow we have this in a very general way
* You can see this looks suspiciously simplein undergraduate stuff we go through this very, very quickly
* But then all this, there's all theselayers of details that are on top of this that take a little bit moretime to sink in, so, work with this.


--- SKIP ---: 01_module-2-introduction.en.srt


--- SKIP ---: 01_module-2-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_module-2-introduction.en_SENTbySENT.txt
* Hi and welcome to the secondsegment of Spacecraft Kinetics
* Here, we're going to be looking attorque free motion on rigid bodies
* We start out with a single rigid body and study how this actuallywill evolve over time
* How does the spin change
* And this is all coupledto the gyroscopics
* We will study this withseveral different methods
* One of them is called Portal
* It's a very cool graphical way actuallyto study large scale motions and why are certain spins stable and unstable
* We're also then going to be looking atdifferent specialized analytic answers where we can consider things likeaxisymmetric bodies that have special answers or bodies that have
* Distinct inertias like this box here,we go to skinny, intermediate, and maximum edge
* You'll answer questions like why is thisspin more or less stable, while if you do the other spin about the intermediateaxis, you'll find it flips very quickly
* So we're going to show those results
* In the end,we're going to look at the dual spinner, which another passive wayto stabilize an object
* So while certain spin orientations forthe single body are unstable, with a double body system, we canactually stabilize any of those axes
* And we go through the mathematicsof developing equations of motion, looking at equilibria, andthen discussing stability again.


--- SKIP ---: 02_1-torque-free-motion-polhode-plots.en.srt


--- SKIP ---: 02_1-torque-free-motion-polhode-plots.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_1-torque-free-motion-polhode-plots.en_SENTbySENT.txt
* And what we're going to do next is we'regoing to spend a little bit of time, at least two lectures, talking abouttorque free motion, because for spacecraft this isa pretty common situation
* You're not always thrusting
* You're not always reacting, because you'reusing lots of resources, energy, fuel
* So how do we understandtorque free motion
* In fact there's many missions that exploittorque free motions to spin stabilize or do all kinds of stuff
* And then we'll look at somedisturbances like gravity gradients, we'll derive that from scratch usingvery much the same kind of notation
* And dual spinners, that's another one
* And then we'll jump intothe control stuff afterwards
* Okay, so I didn't put that one off
* Let's talk about torque-freeattitude motion
* As we've been saying today,H dot is equal to L
* If it's torque-freethe L just becomes zero
* That says the nerve, whatever thisvector is, H is just a vector in space
* And a vector has a magnitudetimes a direction
* All we're saying with H dot equal to Lis that as seen by an inertial observer, this vector is fixed
* So that means, what you just seen before,H is equal to I omega, we compute all this stuff, we have I in the bodyframe, we have omega in the body frame
* We very often write H is equalto something, something, something in the body frame
* The body frame components of H fortorque free motion are not zero
* The inertias are fixed, but the omegasare going to vary, go back and forth
* But if you reconstruct in the body frame, this is what the vector is,now you know what the body attitude is
* So times BN, right
* You map it back into the end frame
* Those, the three inertia framecomponents have to be fixed
* And that's essentiallywhat we're doing here
* This is in the body frame
* This is typically how we write it
* Here we've assumed what type ofbody frame to get this form
* Principle, exactly
* Now it's diagonal
* We'll do this a lot for analysis
* We can always do this for anybody
* It just simplifies our basic stabilityanalysis that we're looking at
* So that we do that
* Then times some DCM inwhatever coordinates you wish
* Some people that usesomething besides MRP
* I just want to highlight that
* That does happen
* So you get this andnow you have to take the derivative
* This is only the N frame components
* Now you have to take the derivative ofall this stuff and set it equal to zero
* And you get a lot of theta one dots and omega dots and yeah that has to betrue but what do I do with this dots
* It's not very insightful
* So that's this isfundamentally what happens
* So this is a good test ifyou're writing an integrator because you give it initial attitude
* Give it a spin
* No torque
* Set the torque to zero andthat equations of motion let it tumble
* Let it spin andyou watch the attitude history
* And at every time step,if you compute this
* From the attitude computed DCN, map your momentum coordinates fromthe body into the inertial frame, you should have three coordinatesthat give you perfect flat lines
* If they do that, then you get really warm fuzzy feelingsthat your integrator is working
* It's not a guarantee that you getwarm fuzzy feelings something
* There's always ways people canget creative and screw things up
* But, if you preserve momentumin the inertial frame that's a really good indicatoryou're on the right track
* It's good for numerical checks,it's not good for analysis
* So the next step is now foranalytical insight
* How do we look at this stuff
* So really, the key component is we wantto do everything in the body frame
* It helps us
* And we want to look at, we want tomake use that momentum is preserved
* If we're doing torque free motion is theresomething else that preserved as well
* [COUGH]
* Any momentum
* Yes, Spencer, energy actually
* Do you remember the power equation T dot
* Ended up being omega dotted with l,and at l0
* That was one of the cases,how we can get 0 power on the system
* So [INAUDIBLE] has tobe preserved as well
* That's a result we'll jump into next
* So if you do everything in the body frame,H was equal to i omega
* Omega, in the body frame isthe classic omega one b one, omega two b two, and so forth
* If you just take in the h vector andputting it in body frames, I'm just using h one, H two, H three
* That's just my labels of the bframe components of the H vector
* And I omega means H onemust be I one omega one
* That's that first vector component of H, because I'm using a principle framenow that has diagonalised my stuff
* She is saying okay,good where we going with this
* It's written age or in the body frame
* Now instead of using justa re-written version of the prior slide what we're going to do next isinstead of saying all three in actual vector component have to be constant,nice flat lines when you plot them out, we're just going tofocus on the magnitude
* because the magnitude is a scalar
* And as we discussed in the first week, to take a derivative of a scalardoesn't have a framed dependency
* So if H as a vector isconstant in the frame, that must mean it's magnitudehas to be constant as well
* And therefore, the magnitude is something I can alwayscompute even in body frame components
* So that's a nice trick
* We go, okay, how do we get the magnitude
* Well, we're going to get the magnitudesquared by just dotting H with itself
* Or in a matrix form we do H transpose H
* Same math, gives you the same stuff
* So this times itself just gives you I onesquared, omega one squared, I two squared, omega two squared
* And you start adding them up
* And all of this has togive you a constant
* Because whatever spin you gave the systemwhatever gyrations are going on these things have to add up
* Omega ones twos andthrees can vary with time but they have to add up to give you the samenumber in the end same momentum
* So good this gives me one equation
* Kinetic energy was the otherone that we talked about
* If you look at kinetic energy that wasone half omega transpose i omega, and if I is diagonal it reallysimplifies very quickly
* And you end up with one halfinertia rate squared for each of the principle axis, that's it
* But energy is also preserved
* So you notice in these two equations, theindependent coordinates are the omegas
* And giving it an initial spin, andI know the omegas, my rates, can change
* But that gives me three degrees of freedomfor the rates, subject to two constraints
* Momentum magnitude has to be fixed
* Energy has to be fixed
* So in the end Jordan, two constraints,three degrees of freedom, how many degrees offreedom are you left with
* One, right
* So that means immediately,once we have top free motion, the Omega time history has become down toa single curve in three dimensional space
* It's a one B sub spacethat we have to find
* And so right now looking at this howdo we intercept this, and this, and predict how that behaves
* This is not quite geometrically intuitive
* That's where the next stuff comes
* Let me go back here
* Could somebody tell me
* Just replace omega one,two and three with X, Y and Z as your three coordinatesthat we're tracking
* If you have AX squared plus BX squared plus Y squared plus CZsquared equal to a constant
* What type of shape are you describing
* >> Okay, not a circle because thisis a three dimensional shape
* It's not a sphere
* >> [CROSSTALK]>> A, B, and C are different
* If A, B, andC were the same it would ge a sphere
* So what is the shape then
* >> Ellipsoid
* >> It's an ellipsoid that you actually,this is a classic equation for the surface of an ellipsoid
* So that means, this is kind of like stuff, where we have this 4d hyper sphere,that's hard to visualize
* A 3d surface, I can draw, sowe'll see visualizations of this
* But this equation actuallymeans that your solutions for omega 1, 2, 3, reside on this ellipsoid
* Does the ellipsoid have a constant shape,or does it change its shape with time
* >> [INAUDIBLE]>> Why
* >> Because its x,y, andz parameters [INAUDIBLE] over time
* >> X, y, andz are your independent coordinates
* Let's look at that
* Too much fire, okay
* If we have this, this is more of a classicway, you might see this ellipsoid and that's some constant,right Is this an ellipse
* If a, b, and c are just constants isthis an ellipse of a fixed shape, or is this ellipse varying with size
* >> Fixed shape
* >> Fixed shape, right
* And so here we just havea lot of coordinates that
* Where people get quickly confused iswhat is the independent stuff that we're looking at
* So the omegas would be independent things,like x, y and z
* You see in the classic ellipsoidal,Wiki notes or something
* I1, 2 and 3, those are principle inertiasthat are fixed in time because we have a rigid body
* If these weren't rigid,these would not be fixed things
* And we'll see that actually with dualspinners, so you have multiple buttons
* Same thing here,this also will make a squared y
* So that's x squared y squaredz squared times some constant equals to something that's constant
* This is also an ellipse, sothat that George was talking about right, that's the space weare actually looking for
* We have two constraints,this is an ellipse, that's an ellipse
* This two has to be intercepted and that'sthe answer, and that's not very intuitive, it's not easy to intercepttwo ellipsis to
* So people came up withthis other approach
* Instead of treating omega one, two, three, as the independent coordinates we'retrying to figure out what's happening
* We use scaled versions of omega one,two, three
* Basically you multiply in times ofprinciple inertias so the new independent coordinates are simply your body frameangular momentum vector components
* So I'm treating H1, 2, 3s
* I can find H1, 2, 3 time histories,and then to map them back to omegas, all I do is divide them by the principalinertias and you get omegas again
* But if you do this, and you get momentum,constraint looks like this, what type of geometric shape is this
* This is a sphere, all right, it's basically constants equal to xsquare plus y square plus z square
* So this is definitely a sphere,that's easy to draw, as you will see
* And then the energy constraint, in terms of this,I will let you do this on your own
* You just have to plug in that h1is i1 omega1, yeah we arrange it you end up getting the energy constraintof divided by t gives you this
* This is kind of a classic normalizedforward where the ellipsoidal form is something old square equal to one
* And then this these terms if you go lookup ellipsoids which you could do easily
* These become related to your semi-minor,semi-intermediate, and semi-major axes of that ellipsoidthat you're going to have, right
* This is just a unit, not a unit sphere
* It's a sphere of size H, and then youget these energies that come in there, and this is something wecan start to put together
* So for torque-free motion, to consider what happens to the rates overtime as you're jumbling and tirading for anybody, this is nothing cylindrical orsymmetric, it's any inertias
* These are the two constraints, we'vemoved from Omega space to h space, and that gave us a simpler way togeometrically find these things
* So that's a sphere, andthis is the classic ellipsoidal equations, that you can find your a, bs and cs
* Which are you're semi-axes for the three things, so yep,that's what you can find there
* So we'll have three,if we have three distinct inertias, you will have three distinct axis, and a key element again is well let's see,can t vary on a spacecraft
* I'm full of simple questions this morning
* Torque-free motion,there's no external torque acting on a spacecraft,could t vary, ansel
* >> Yeah
* >> Could h vary
* If it's torque-free, no externalforce acting on the spacecraft
* You don't think so,you guessing, you feeling lucky
* >> H = L, it goes back to that
* Is that good for a rigid body
* Yes, is it good for a continuum
* Yeah, so if you have the spacecraftit's not rigid, it has fuel slosh
* It has people wandering around in there,it's a space station
* It has big panels that can flex,space station again, huge panels right
* H dot equal to l still holds, if there's no external torque actingon the system, H has to be preserved
* So for all the torque-free motions,we always treat H as a constant
* That's religion, I mean,it doesn't change, t, though, the energy
* We say this is rigid, but how rigid is any structure,everything has a little bit of flex
* There's always something,maybe very stiff, but there is always some amount of flexing
* So as soon as you flex,what happens mechanically
* What happens to your energy state
* Yeah, you're going tostart dissipating energy
* There's always a resistance to flexing andthere's some damping coefficient
* It might be really, really small but if internal friction there's stuffrubbing against ach other there
* There's walls, there's alwaysfriction ways to dissipate energy, so even though it might be almost rigid andyou now nothing is truly rigid
* So in practice in this math we areassuming right now it's perfectly rigid but that's an artefact of our mathematics
* In real life as an engineer werealize nothing is perfectly rigid, in fact what was the first satellitethat went up for the U.S.
* >> Explorer 1
* >> Explorer
* How did explorer 1 do
* It was kind of in this shape, they go hey, we looked at this equations andif we spin about this axis
* I heard spinning stabilizes things,so they spun about this axis right
* Had big antenna sticking out,that's how they communicated
* Those antenna were all flopping, doing stuff, anybody remember howlong before it went unstable
* It was less than an orbit, bery glorious
* After that they started to listento astrodynamicist they go to help if you do it by the right axis andthe right stuff, and all right
* So that was one because it is flexingit definitely lost energy and you will see here shortly whywith all these constraints
* This leads to something that canbe very unstable, actually, and what does it move towards
* There's definite stable equilibrium,but it's not this spin, where you're spinning about this nicesymmetry axis, the skinny one, right
* So energy can vary,that means, momentum doesn't, if it's torque-free,our momentum sphere is locked
* But for that amount of momentum there isa finite range of energies that you can have, this ellipsoid hasto intercept with momentum
* So there's a minimum energystate you can have, and there's a maximum energystate you can have
* So just because you have a fixed amountof momentum you cannot predict what the actual energy state is
* There's a range of energies you can haveas we dissipate energy we go from one to another on our own
* What happens though as we change energy, you can see it's 2x the principle inertiax the energy it takes square root
* As energy scales, it's going toscale all of my axes simultaneously
* So this ellipsoid, basically,grows homogeneously or shrinks homogeneously with energy
* As you change energy, you don't just makethis ellipsoid longer in one direction and skinnier in another
* It just grows and scales evenly
* Right?That's the key thing you want to getout of this equation
* Good, now, let's look at this
* This is my first of many figures
* We're going to assume,without loss in generality, that our principal in our body frame,the principal frame, it's lined up such that B1gives Axis of maximum inertia
* That would be like kind of likethis axis here on this box
* Then you have B2 is axisof intermediate inertia
* That's the one in-between
* That would be thiskind of a skinnier side
* And then axis of least inertia is here
* As we said Principal framesis to find that permutation
* I can always choose a framewhere this is true
* So, I don't have to do thismath six different ways
* I can just do it once
* And you can flip yourframes when if needed
* And now we're plotting thesethings in momentum corner space
* Not omega space butwe realize that omega 2 omega H, sorry H3 H2 Are just omega 1 times I1 andso forth
* The momentum shows up as a sphere,that's nice
* The ellipsoid shows up here,and it has to intercept
* So, we said earlier we've got threecoordinates we're looking for, omega 1, 2, 3, subject to two constraints
* The answer must be a curve
* And that's where our curve is
* Is that the only intersection
* >> There's one I'm not showing
* It's on the backside
* Thank you.>> [LAUGH] >> So, even here, so if you have energy specified and momentum specified, there's actually twopossible trajectories you could be on
* They're related
* They're kind of mirror images
* But the shape isn't flat,this is kind of potato-shaped
* Things, ellipsoid, butwrapped around a sphere, that's what the intersectioncurve looks like
* And that's what you would have
* And here you would wobblearound in this direction, over there it's in this direction
* So, this gives you something,this scale body inertia, you can tell right away,this is where my omegas have to reside
* This can also be used asan integration check
* So now we can play with energy levels and start to look at different spin conditionsand also talk about stability of these
* So, I know, those of you taking 3200,you've seen these slides before
* So, then we'll quickly go to new stuff
* With H, let's look atthe smallest Ellipse you can do
* If you shrink your energy thenremember these axes are proportional to the principal inertias so this axis b1that has the largest principal inertia
* It's the longest elongation
* If you shrink the ellipsis small as youcan make it, the longest elongation is going to be the only point that justbarely touches the momentum sphere
* That's kind of the geometricinterpretation
* So that means,what kind of spin do you have
* That's a single intersection point here orhere
* So that means, in this case, you have a spin that's doingeither you're rotating positive or negative about your B1 axis, but you'redoing a pure spin about a principle axis
* And so in this case here,actually it would wobble and you'd be spinning this case that way
* So H2 and 3 are 0 because you only havean H1 axis intercept, that's there
* And you plug it back into the equations,in the kinetic equations
* And in the end, if you have H andthe principle inertias, you can compute with this whatthat minimum energy state is
* So, there's a Clementine Mission thatwent to the moon, very successful
* It was one of the first ones thatfound signs of potential water, ice kind of in the shadowy partsof the polar craters of the moon
* Then after we was going to go off andvisit some asteroid or comet or something
* And along the way they had a slightglitch where all of the sudden the thrusters were told to be on and stayon just because until you run out of fuel
* It wasn't just all the thrusters, maybe itwas balanced, it was more like there's one thing went on, and so it spun up toa crazy momentum and the mission was over
* Now, it's torp free It's still,probably whatever is flexing going on in the structure might stillbe dissipating energy but it will never ever come to rest unless you have someexternal force acting on the system
* You need an external torque to changea total angle momentum, all right
* So even with damping in the systemthat you have fuel slosh, it'll dissipate it butit can only dissipate it down
* to this, that's the limiting case
* Any lower energy that ellipsoid andthe sphere don't intersect
* You're violating momentum
* Now you've changedmomentum of the system and we must have applied an external force
* Maybe SRPs could do some of this stuff
* That's one thing we do withspace debris tracking
* SRPs Atmospheric drag
* I'm looking at electrostatic drag forces,as well, and torques
* They can change momentum over time, which really complicatesthe analysis of the objects
* But, this is one of them
* So, good.Do you think this is going to be stable
* This is an equilibrium spin
* That means, if I put my body in thiscondition my omega 2, and 3 are 0
* If you go back to look at the otherdifferential equations, what you end up getting is omega 1 data zero oromega 2 data zero, or omega 3 data zero
* All right, let's actually look at,let me just go back a few
* Here we go
* If Omega 2 And omega 3 are 0,while 2 times 3, that's all 0
* 0 times something is 0, somethingtimes 0 is 0, and torques are all 0
* You can see a pure spin about b1is going to be in equilibrium, where all the omegas are 0, right
* So good
* So we found that
* Now we want to know,is this going to be a stable equilibrium
* So if I take this object, and I do a pure spin about this, I'm nevergoing to physically give it a pure spin
* I'm just not that good
* All right
* I'm always off by a smidgen
* So, stability is always well
* This particular spin rate would be perfectto give you zero rates in everything
* But if you're off by a little bit,are you going to stay close
* Or is that going to drive it upside down
* Gravity gradient is the easy example,right
* Here, like this kind of a pendulumwould be stable, if I do this, anyhow, it keeps wobbling,then have friction, it just keeps wobbling here tostay close versus this one
* This is in equilibrium
* But if I wouldn't hold it tight and I'moff by a little bit, it drives it away
* That's an unstable one, all right
* Here, if we have neighboring motion,we can't make energy any smaller, we wouldn't intercept
* So we just make energy slightly bigger,what happens to the interception curves
* Do they stay tight andbounded around that equilibrium
* Louis
* Yes, everything looks rounded
* >> So, if you make it a little bit bigger,you would think, okay, you've got this littlebit of a curve there
* Okay, you're wobbling some
* If you're not doing a fierce spin,you would wobble some
* And we see that, right
* If you take this object andI take it here and spin it, that spun pretty well, no biggie
* Let's see So I've got some videos here
* Same inertias, I'm showing an objectthat kind of scales with these inertias
* I'm giving it a sphere spin,which would be in equilibrium
* I should never see it wobble by otheraxis, it's just doing that pure B1 spin
* Here I'm giving it some slightoffsets with half a degree, and you can see, they look almost identical
* They are not perfectly identical butthey stay, these little wobbles they stay very smalland bounded and life behaves well,right
* Which kind of makes sense becausewe're doing deviations about a minimum energy states
* And as you've often learned in physics,nature loves minimum energy
* Everything kind of convergesto minimum energy state
* Right, that's the stableone That we would have
* So, that's this spin
* If we now look at intermediate energy,we increase our energy, right
* Everything scales evenly, now of a sudden, the intermediate access which isalong B2 intercepts You would have a pure spin about this point,or a pure spin about the other
* That means when these object werespinning about this axis in a positive or negative set
* Those are the two options if youhave this specific energy state
* And as before, you said H1 andH3 equal to 0
* And then, you can quickly solve thatintermediate energy state is momentum squared over 2 timesthe intermediate inertia
* If you have that energy state, theseare the two points you could be spinning
* But it's not the intersectionline isn't just 2 points, like with the minimum energy state
* There's also this wholecurve that happens, it's a saddle point thatwraps around itself
* That is a physical motion as well, andthat's called the separatrix motion
* So if you're spinning nearly about it,now, if I do a pure spin here, I'm good
* That should give me just a spin,but is that one going to be stable
* If you're off slightly, if you're not juston this point, but we increase energy
* And all of a sudden you're ata point slightly above it up here
* Are you going to stay close,With these things
* What do you think
* No, right
* So this curve actually takes youfrom here, then back over here
* Here it comes in, so the question is ifyou're on this curve, well, wait a minute
* If I hit this point, do I go this way orthat way, what happens
* The answer is you never hit that point
* Those spin conditions, you can putyourself on it mathematically perfectly
* But if you're on the separatrix motion, you will get there withinfinite amount of time
* It's an asymptote, right
* Otherwise mathematically you can see youhave a decision point all of a sudden does the stuff go left or right
* And that never happens,because you just asymptotically, it would take an infinite amount oftime to actually reach that point
* And who is that patient
* So if you're off slightly, you will see interception linesthat kind of look like this
* But anytime I get close tothis interception point, that's when I know this actuallytakes a long, long, long time
* It'll hang out there, and then, eventually,it goes back over to the other side
* This is why, if you try to flip an object aboutthe axis of intermediate inertia, right
* It flipped, and now it didn't,there we go, it flipped again, and it flipped again
* In one twist and I'm not trying hard,it immediately does 180, 180, 180
* It's very unstable in that sense, right
* That becomes because ofthese kinds of behaviors
* So, intermediate axisspins are never stable
* They're highly unstable,but they may be deceiving
* They may look stable fora short period of time
* So, let's see if I canget this video to work
* Went through the commercial
* Let's see if YouTube is going to do this
* This is on the space station, they havean object, they took it and they spun it
* Why is it doing this motion
* >> That's so cool [LAUGH]
* It's perturbed very slightly and goes on
* >> It's definitely a spinas they're doing it here, this is a spin about the axisof inner median inertia
* But there's a little bit of a wobble,it's not a perfect spin
* I guess astronauts aren'tthat well trained, all right
* >> [LAUGH]>> So, this is hard to do, but you can see
* For short periods of time,it almost looks stable, right
* It gets close andit stays close, then crap
* All hell breaks loose, right
* And you flip upside down again,and then you hang out for awhile
* No, YouTube, thank you,who knows what it's going to show us
* >> [LAUGH]>> Okay, but it goes back and forth, yep, you can stop
* So that's what's happening here
* You can see, it looks stable forshort periods of time, but it's getting close to here,hangs out for a while
* But then, eventually, it's going toget over here and then hang out for a while and then come back
* It never settles at one point,that's why it's not stable
* You may look like you're staying close fora finite period of time
* But as we go through, later on,the control proof, or the stable mean, and so forth
* Once you enter a bounded region,you have to remain in that region forever, and you will not
* because if you're off, you may stay therefor 10,000 years, because you got really, really, really, really close
* But eventually you will, you give itenough time, you will bounce back
* And it will go off to the other side
* Hang out for a while and then come back
* So that's kind of a really cool video,I like that one
* It kind of illustrates what's happening,right
* This is where you're going one direction, and then it floats around andcomes back here
* And, except for the air drag in that spacestation, it's really a torque-free motion
* And it's just bouncing back andforth satisfying, this stuff
* This is actually whatleads to chaos as well
* So with a single rigid body, he can proof completely rigorousmathematic that this is a chaotic system
* If you're spinning nearly arounda separatrix kind of energy state
* because a infinitesimal changehere has you spinning this way
* And another one has you spinning this way,which is different orientations
* And so infinite sensitivity to smallchanges is what redefines chaos
* And so separatrix motions isa chaotic type of motion
* So you see all kinds ofpapers published on it
* So chaos is fun, here we look at it, I've just done a minor minor [INAUDIBLE],again 0.5 degrees
* And even after less than one revolution,hugely different orientations, right
* That's what you're seeingwhen you flip this thing and let it spin and its already tumbled
* So definitely unstable,let's see what's the maximum energy state
* If you scale this ellipseas big as you can, you end up with this kind of a hugeellipse, it still has to intercept
* And that's going to be now atthe polar points, the b3 axis
* So this is a pure spin aboutto axis of least inertia, because that's how we define b3
* And that would be this, andso if I try to spin this, it's reasonably stable,it's just an awkward way to spin it
* Little bit of a tumble,but it looks stable
* Again, you make your other Other 2, 0
* Now from this term, you can derive energyis h squared over 2, minimum inertia
* That makes sense, you divide by the smallest inertia toget the biggest energy state, right
* So that's the maximum energy you couldhave with this amount of momentum
* To have any more, you have to applyexternal torques and increase your sphere
* But you intercept at 2 points,which is good
* Now, here, if you have,we can't have more energy
* That's a maximum energy state,if we have slightly less, Nathan, is that motion going to be stable orunstable
* >> Unstable
* >> Why
* >> Because it'll go to the minimum
* >> Why
* >> because it's going to lose some energy,it's going to dissipate some energy
* >> If you don't consider energy loss,and this was really Explorer 1, how bad could it be
* Really, it's just a little dappy,nothing, it's very small, right
* So without energy loss, if you're likethis, that's exactly what Explorer 1 was doing, spinning aboutthe skinny axis of the rocket
* They just got it going,you would just be wobbling here
* This looks perfectly stable, butas soon as you count the energy loss, you know this ellipse hasto get smaller and smaller
* And at some point,you're going to go through the separatrix
* At that point, who knows what happens,and you might end up upside down, right side up
* It's impossible to predict,it's a chaotic thing, right
* And, then, at the end, with energy loss,where will we converge to
* >> [INAUDIBLE]>> Yeah, this ellipse will go smaller and smaller and smaller
* And the smallest one wouldbe the motions here
* So, in the end, everything in nature withrigid body converges to a flat spin
* So for those of you doingspace situational awareness, tracking debris objects and so forth, this is where things would convergeassuming null external torques, right
* So once you include SRP, andas a recent graduate we did this a lot
* We're looking at the staticswith Joe's work, things can go quitedifferent all of a sudden
* because now you need an external influenceto pump up momentum and energy level, and it takes you out again
* And things get way more complicated,much, much harder to track
* But if it is torque free,these are the classic results
* Good, and here's an example,there's no energy dissipation here
* So this one, yes,it has a slight difference
* You can see it a littlebit more pronounced, but overall,nothing like the intermediate axis one
* That one really went hog wild andwent all over the place
* So those are the three,you can look at all infinite [INAUDIBLE], that's what I'm looking at here
* So minimum energy would be here,maximum energy would be here
* Separatrix energies is here, andyou can see the arrows how they go
* So if you look at your H1, omega 1, 2, 3 coordinates spaces,you can actually quickly tell
* Actually, we're wobbling aboutan axis of maximum inertia
* Because I'm wobbling aroundin a positive sense
* If I have my omegas orHs move around this axis, and you can see that's actuallyorbiting in a negative
* So this is a positive sense,this is a negative sense
* I know I am spinning about an axisof least inertia, or near to it
* And if it's flipping back andforth your closer to the separatrix, it's doing some crazy stuff
* But you can look at allthese interceptions, and this kind of gives you a quick geometricway to interpret stability rigid bodies
* When we do the dual spinner, we'll do a complete mathematicalway to talk about stabilities
* And we'll rediscover the same results, just with a more of a linearizationapproach on how that works.


--- SKIP ---: 03_1-1-example-special-polhode-plots.en.srt


--- SKIP ---: 03_1-1-example-special-polhode-plots.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_1-1-example-special-polhode-plots.en_SENTbySENT.txt
* Quick questions
* What kind of shape do I have if myinterception curves look like this
* >> Symmetric.>> Is it axisymmetric
* I know, you took it in 3200
* You've seen this one
* But why is it axisymmetric
* >> The energy ellipsoid is the samewidth in one and two axis
* >> The interceptionlines have constant H3
* If you go back andlook at the differential equations here, H3 that means omega three is constant, this will go to omega three dotgoes to zero if I2 is equal to I1
* And then you can have a constant H3,right
* That's the intersection pointthat you're going to have, and we're spinning this way
* If you're here though, that means that myomega three, my H3 coordinate is zero, therefore omega three coordinate is zero
* If omega three is zero, then this one is already zero tobegin with because of the inertias
* If omega three is zero these, omega threesmake both of those terms go to zero
* That's why you get points
* Those are now pure spin conditionsthat you would have and they don't wobble beyond that
* What kind of shape is this going to be
* So basically, it says whatever spin axisI pick, it's just going to stay there
* >> Sphere.>> Sphere
* >> A sphere, good
* With a sphere, you can take a sphere andspin it about any axis and it'll just keep spinning
* And that is a pure spin
* So, the sphere is an easy one
* No matter how bad you are,you're spinning about a principal axis, or it wouldn't be a sphere
* Is there another shape you could use
* The cube
* All you need is your principal inertiashave to be equal, and for a cube, that's the case
* We don't have a sphericalmass distribution, but we still get three equal
* That's why it's easy,actually, to throw a cube
* A cube should be random, in that case
* So if you go to Vegas and throw the dice,it should give you some random stuff
* Every throw should havean equal probability, unless you're playing witha professional gambler, in which case, they put a slight mass in there, right
* And bias it in one direction
* And all this kind of is no longer true,because we no longer have equal inertias
* That's how gamblers today,they're very smart with the math
* I'm sure you did it this way,not just testing that
* >> [LAUGH]>> [LAUGH] >> But the cube is one of the things, exactly
* Spheres people often think about it,but the cubes, cubes ask these kind of things as well
* If you want to spin them about any axis,actually you can spin them, as long as it's a perfectmass distribution
* While we build cube sized spacecraft, theinternals aren't necessarily homogeneous, so even with a cube outer shape,you still have to look the internal
* Where's the battery
* Where's the antenna?Right, that could shift and give you three unique inertias
* But if you fill it up with lead andlaunch it, that would happen
* Okay.


--- SKIP ---: 04_2-torque-free-motion-axisymmetric-solution.en.srt


--- SKIP ---: 04_2-torque-free-motion-axisymmetric-solution.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_2-torque-free-motion-axisymmetric-solution.en_SENTbySENT.txt
* So good, analytic one,this is pretty straightforward
* Actually, you do something onthis in the homeworks, as well
* So if we have torque free motion,we've assumed the principal frame
* These are the three equations you have
* The only thing I've dropped was the l1,2, 3, there's no external torque
* So this is a pure spin, you take anobject, and you spin it up, what happens
* But in particular now,we want to look at an axisymmetric case
* So here we're going toassume this diagonal still
* And if we assume it's axisymmetric,like a cylinder, rocket bodies
* Many spacecraft kind of have axisymmetryjust to coming out of the launch vehicle, to have to get through the atmosphere
* So it is a common shape assumption
* We picked b1, b2 to be a transverse andthen b3 is the axis of symmetry
* So I1 and I2 have to be equal,I'm just calling it It, right
* Those are the two transverse axes
* If you do that, and plug it in,the last one that was I2 minus I1, or I1 minus I2, that's going to go to 0
* So immediately we have an omega 3 dot
* Whatever spin you give itabout the axis of symmetry, that spin rate just stays a flat line
* Doesn't change
* The other two will actually change and they are the function of the inertiaabout the symmetry axis and the transverse inertia, andof course, initial conditions
* So now we have two equations andtwo unknowns
* This one falls out because omega 3 dot,that makes omega 3 a constant
* That means up here omega 3 issimply the initial omega 3
* It's no longer not known, it's a knownquantity by initial conditions
* So, we're left with omega 1, and omega 2 and we've got two firstorder differential equations
* How do we solve this
* This is one of the cases when you'retrying to solve these things, you try to get rid of the dots
* And the easiest path is not to get rid ofthe dots is actually to add more dots and that gives you an answerthat we can find in the end
* If I differentiate this equation thisis shouldn't be bold actually, unbold
* But just take the dots
* Inertia is a constant
* Omega 2, omega 3's a constant, so there'sno omega 3 dot, but omega 2 could vary
* You can see omega 1 only depends onomega 2, and if I go back a slide, the omega 2 dot only depends on omega 1,again, treating omega 3 as a constant
* So if I differentiate 1, I now getan omega 2 dot, which depends on omega 1
* And you can plug that in andyou end up with this equation, that's omega 1 double dot plussomething times omega 1 equal to 0
* Which for engineers, like yes, I knew there'd be a spring-masssystem somewhere, right
* This is a typical spring-mass system
* You know how to find these answers, andthey will give you the typical sines and cosine results
* So, x double dock + kx can yousolve that differential equation
* That's what it boils down to,for an axis symmetric case
* You can do the same things for omega 2, it gives you the same kind ofa constant Inertia's a constant, omega 3 is a constant, so all of thisis nothing but k in the end, right
* If you did a spring-mass analogy
* So for axi-symmetric cases,it's easy to do
* Then, I think in the homeworkyou do this yourself
* Show me that you remember how to solvesimple first order differential equations
* You plug in the conditions,come up with these coefficients
* And this one here is called omega p
* I can rewrite it, and sonow it has to do with this
* What's interesting here is is I3 is forexample less than IT
* That's this kind of stuff
* The inertia about the transverse on thispen is much bigger than the inertia about the symmetry axis all right
* So in that case this isa ratio less than 1 minus 1, it's going to give youomega 3 which is positive
* That's going to give younow a negative omega p
* We saw on the pole hold plusdoes momentum spheres and energye lipsoids if I'm doing a spinnear the axis of least inertia, that was the i-3 axis, sothose wobbles up there
* We would be orbiting in a negative sense,and that comes from the sine right here
* If we have I3 being the axis of largestinertia, so we have just a plate
* Think of a big, flat plate basicallyspinning, right, and you're off slightly
* Now I3 is actually, so it's oproid body,I3's bigger than the transverse inertia, and this becomes more than 1,then -1 is still positive
* That's why there we saw those curvesorbiting in a positive sense
* But this is the classicanswer that you have for a rigid body, no torques,but it's axis symmetric
* So we make that one assumption,and this is just a classic result
* Make sure you can derive this
* This is pretty straightforward
* Here are some answers
* If you integrate the equations, youwould see, just using those differential equations we talked, i omega dot plusomega ~ i omega equal to 0, in this case
* And you integrate this stuff, you wouldget these curves, which then show you yes, as predicted, I get a sine Like curve withthe face shift, or a cosine in some cases
* And you get [INAUDIBLE] in omega
* That's for the rates
* If you do the attitude motion,this is the same thing
* I'm just showing here all your angles
* Again, people, try to be diverse
* Something non-MRP
* We'll get to those a lot more later
* So what happens is, the attitudemotion is very difficult to predict
* So for torque-free motions, the parts that are easy are the spinparts with this equation
* And we can predict spin stability, but wedon't necessarily have pointing stability
* That's a whole nother thing
* And we'll get to thatin three-axis control
* But if you need spin stability, that'swhere these kinds of analysis really help.


--- SKIP ---: 05_3-torque-free-motion-general-inertia-case.en.srt


--- SKIP ---: 05_3-torque-free-motion-general-inertia-case.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_3-torque-free-motion-general-inertia-case.en_SENTbySENT.txt
* Torque free motion
* Momentum has to be constant
* The momentum magnitude has to be constant, which is what I'm writinghere in the first equation
* And kinetic energy has to be constant
* So we're not considering actualmechanical energy loss right now
* Like, before, like the Paul will plots,let's assume T and H are perfectly preserved
* You can write the momentum at energyconstraints in terms of your omegas
* H was I omega, so that forthe magnitude is the component squared
* That's easy, magnitude squared
* And kinetic energy was 1/2, sothe 2 comes to the left-hand side
* This one was just to make a transposeI Omega, that I is a diagonal
* Again, makes it very easy
* This is the form that you would have
* Now these are two constraints
* And we have three variables
* And quickly this illustrates again,that the omega curve that you're going to get isn't going to be a plane ora volume, the solution space
* It's going to be one dimensional curvein three dimensional omega space, right
* That's what we're looking for
* We have three unknowns, omega one,two and three and two constraints
* So I can always use these two constraintsand that's what I'm laying out here
* I say, okay well let me just pick towrite everything in terms over omega 1
* Why?because it's the first thing one that appears
* So I can use this andsolve for omega 2 squared and that's what you have in this equation
* And I can solve this foromega 3 squared which comes up here
* So you've got two equations andtwo terms, omega one and two that I'm solving for, sojust rule any algebra and you reduce it
* So, now because of these constrains if Ihave an omega one and I know my momentum and I know my energy added atthe beginning, I can quickly tell you what the magnitude squared of omega two has andthe same thing for omega three, all right
* So it's just the way ofre-writing momentum and energy constrainsexclusively in omega terms
* Now what makes omega 1 special
* Nothing really
* There's nothing special about omega 1
* You could've just as easily solvedeverything in terms of omega 2 or you could've used in two equations andsay, well, I'm going to solve everything foromega 1 and 2 in terms of omega 3, right
* You can solve this any which way you wish
* And substitute them again
* I will use all of them
* This was in the paper by Junkins,Jacobson, Blanton that you've gota reference down here
* It's actually from 1973
* Most of you weren't even born
* But it's an eloquent result here andyou will see, this has some analogy tothe axisymmetric cases
* But it gives you a more generalformulation that you don't often see
* So this page, all we've done is we'vetaken momentum energy equations and we've used it to express the omegasin terms of momentum and energy and one of the other omegas, that's it
* So let's go back to the original problem
* This is the one we're trying to solve
* We've got these differential equations
* There's no L's on the right-handside because there's no torque
* How do we solve this
* Before with axis symmetry,one of them was 0
* So we could say omega 3 is fixed andtherefore we took a derivative of this, substitute into the others, right
* And came up with nicely decoupled ones
* Now everything varies with time andI can no longer do that trick directly
* But there's still similar steps
* We're going to start out withthe same kind of a step
* We have three fully coupled andnow non-linear differential equations, whereas before I had two coupledlinear differential equations
* I'm still going to take a derivative justbecause it worked so well for the axis and metric let's try it here, right
* And you do this, and then with chain rule,Omega is Omega 2's 3's Omega 1, everything varies with time, and here you go, to makea 1, 2, 3 double outs divided by inertia
* That's basically it
* So you're going okay,great, where is this going
* So you took a derivative again
* Now similar as to with the axissymmetric case, omega 1 dot for the axis symmetric only depended onomega 2 because omega 3 was constant
* Well, what we're going to do nowis we plug in the second and third differential equation into here
* And rewrite this all and you end up with this expressionhere that you going to have
* So omega 1..,is equal to omega 1 omega 2 squared
* And omega 1 omega 3 squared
* As you can see there'sstill quite coupled
* There's still non-linear Just I went fromthree non linear first order differential equations to three non linear secondorder differential equations
* Seems like we're going backwards,we're not making much progress
* But here's the elegant thing now,from the prior slide, I have for example omega 2 squaredIn terms of just a constant and something times omega 1
* And the same thing for omega 3 squared
* So if you look at the secondorder differential equations, here is omega 1, omega 1
* I can write omega 2 squared interms of a constant and omega 1
* And the same thing for omega 3 squared
* So by using the momentum andthe kinetic energy constraints, I can substitute those in andinstead of having time varying quantities, I have everything in terms of constants ofenergy and consular momentum magnitude
* And what you can do for one,you can follow the same process here
* We use here the expressions where omega1 and 3 are written in terms of omega 2
* And here we use the third set that writesomega 1 and 2 in terms of omega 3, right
* There's three different ways we couldtake two constraints and solve for two to three variables
* If you do that and plug them in,so that's the process, those equations we found,and you plug them in here
* And then you do the same thing for theother two look what happens in the end
* This is omega 1,just a bunch of constants
* Omega 1 times constant somethingtimes omega 1 squared
* So you're going to get omega 1 term and then something times omega 1 squaredwill give you omega 1 cubed essentially
* So the final form for everyone ofthese omegas, I can write it as a, what's called a homogeneousundamped Duffing equations
* Homogeneous just meansthe right hand side is 0
* Undamped, there's no omega dot
* Just omega double dots and omegas
* And the Duffing equation, is this classic,this would be a spring mass equation
* The Duffing equation is a spring mass witha cubic Stiffness term added to it, so like a cubic spring insteadof a linear spring
* It's a common modelingthing to see as well
* So, all three of the omegas actuallyhave an equation of this form
* But you would have these As andBs which depend on omega 1, 2 and 3, and you can see,the inertias are computed differently, and when you plug it in, energy andmomentum come in with different terms so we have formulas forthe As and Bs have to be
* So this is actually very elegantbecause we often see systems that are, we end up with x double dot plus kx,right
* If it's x double dot plus k equal to 0, it should be trivial to talkabout linear stability, at least
* You've linearized the system forsmall motions locally
* If k is positive, we know we'll havea restoring force let me just draw that out because we're about to mute that
* So if you, If I have M
* Forget M, we'll just do normalized
* That means x double dot = kx
* So if x is here, you can lookat what happens to x double dot
* If x is positive,the x double dot is going to be negative
* And it's a linear relationship
* So if you're too far ahead, the force isgoing to restore you back to the origin
* If you're too far behind,and x is negative, -k be the positive value that thenmakes it positive, you can catch up
* This gives you the typical oscillatorequation that you'd have, but it's a stable motion
* So that works
* But this result is typically dueto a linearization that you get
* Here have we linearizedanything when we derived this
* No, we just used full nonlineardifferential equations, differentiated them,substituted in energy momentum, and you end up with three equations,we've a first order term and a cubic term
* The cubic term 2, if you do structures,you often see this cubic term
* But it's the result of an approximation
* Once you go beyondthe first order stiffness, the next term people typicallyinclude is the cubic term
* If the fractions get really big likestrain hardening on a spring or something
* You get this extra stiffness thatcomes in, that's the cubic term
* But again, in structures, that's an approximationof a much more complex behavior
* It's like the next orderterm that's included
* Here this is a perfectlyrigorous equation
* So in structures,this is often found as an approximation
* Here there's no approximation
* Is it exact thing fortumbling general inertia, motions
* So good, so we want to study this now
* A little bit more detail
* We have three equations
* When we only had these parts, that was the axisymmetric caseit was easy, spring mass
* It was a sine anda cosine response, right
* Now here it's going to geta little more complicated
* Unfortunately I don't have analyticanswers as we have with the axisymmetric codes but there are some arguments we cantalk about like global stability of these motions and departures that you can writeit in this form is kind of a nice thing
* So yeah,then I'll lead departure from Hooke's law
* That's the linear part,this is an exact differential equation
* So we can do this
* So this is actually three equations
* Are these three equations decoupled
* >> [COUGH]>> Sorry, what was your name
* >> Mark.>> Mark, are they decoupled
* >> Yes
* >> Okay.Are they independent
* >> Yes
* Well, not because of the constants
* >> You said it with such convictionyou almost had me convinced
* Why are they not independent
* Everybody agrees they're decoupled
* If you look at this each equationhas only omega 1s in there
* And the next term only has omega 2's andthe other one has only omega 3's there's no omega 1 times omega3's as we had originally
* So we definitely made them independent
* Once you have all the initial conditionsand these parameters you can solve three independent differential equationsnumerically and get the answer
* But independent is somethingdifferent that means, lets say I have a spinabout omega 1 only and the next simulation is a spin about omega1 and tumble about B2 or something
* It is the same omega 1 butit has a different B2
* What will be different inthese differential equations
* because you're right,they aren't independent, Matt
* >> They are energy momentum terms
* >> Exactly
* The energy momentums are actuallywhat cross couples them, so they're not independent
* I can't just go well,if omega 1 is one radium per second, I have a fixed answer that's not true
* Because the coefficients that gohere depend on momentum and energy
* And so it's a little bit more complicatedif you also tumbling about another access, your energy state is different,momentum states are different, and that will give you different A's and B's
* So you have to solve it forthat particular case
* So there are three uncoupled equations butnot independent equations
* Is that make sense
* They're coupled through this coefficientsthrough energy and momentum, precisely
* So, the three uncoupled oscillators andthat's there
* If I write them out to As and Bs, thisis what they are, as you can see, T and H has appeared
* The inertia's always the same,it's the same with your body
* But as your math was saying,if H is different and T is different, I would have differentcoefficients, and all of a sudden and then we get a different responsewith these omegas, right
* So that's where it does matter
* But it's very elegant so for the generalcase you can always write this as a harmonious,homogenous on them to Duffling equation
* Now with these parameters we'll lookat this a little bit more carefully but you can see, for example, the cubic stiffness terms Bs,there's differences of inertias again
* So we know right awayif it's axis symmetric, some of these things will go away,some insight you get
* But at the same time,I'd say if it's a cube or a sphere, all of these terms go away
* For a sphere, none of that matters
* Even in here there's always differencesof inertia so for sphere again, As and Bs go away which we talked about
* A sphere you can tumble about any axis andit'll just continue to tumble, your mega 1, 2, 3s are all flat lines,always, or for a cube the same response
* But for general bodies,if I1 is your largest inertia
* You can see this is going to bea positive term times a positive term, this is going to bea positive cubic stiffness
* Down here again, if I1 is the largest,so this is going to be negative, that's negative,negative times negative is positive again
* Again we'll have a positivestiffness whereas here you'll have a negative stiffness
* So is positive stiffness good orbad for a stability for a cubic one
* >> Good
* >> It's good
* It's pretty much analogous
* Instead of a liner response, now youhave something that's kind of cubic
* But you need the same kind of a sign,right
* If you're positive, you want somethingpulling you back to the origin
* The origin is the equilibriumthat we'll be studying here
* And if you're negative, you wantsomething positive to pull you back
* It's just got to be more aggressive forbig departures, but way less aggressive for small departures
* So there's a differencein the cubic terms
* That's why for a linearization, this isthe linear part it's going to dominate
* But if you go really big departures,the cubic one is always going to win
* At some point,x cubed is going to be bigger than x, regardless of what these constantcoefficients are, these As and Bs
* So good
* So you can see just looking atthe signs of this we can get some insight into whatmust be happening and we'll cover this a little bit more inanother slide as we go through it.


--- SKIP ---: 06_4-torque-free-motion-integrals-of-motion.en.srt


--- SKIP ---: 06_4-torque-free-motion-integrals-of-motion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_4-torque-free-motion-integrals-of-motion.en_SENTbySENT.txt
* There's an integral, every one of thoseequations we can actually integrate and come up with these conserved quantities
* You can think I'm calling him K here, this is not kinetic energy,it's something different
* But it's like energy, soit's an integral of motion basically
* So it leaves us a waypointto go to a set of slides
* So let's say we have ourclassic mx double dot = -kx
* Anybody know what the integralof motion of this one is
* What's the preserved quantityof this differential equation
* Spring mass system
* What's constant
* You did it in the homework withtwo particles in the spring mass
* Part B, what did you have touse to get that relationship
* Energy, right
* Basically
* We know out of this, this is nothing buta spring mass system
* So we know that that kinetic energy and the spring potential energy summedup will give us a constant, right
* But we know that
* Can we mathematically prove it
* So I'm going to show you quicklyhow to integrate these system
* And this is a simple linear system
* With this other term there, the cubicstiffness has an x cubed instead of an x
* But even x cubed is trivial to integrate
* I expect you guys to knowhow to integrate x cubed
* In the next homework you willhave other terms in there
* There was one homework whereyou end up with a sine theta, but even sine theta isn't that evil
* I know you guys know how tointegrate sine theta, hopefully
* So you can come up with theseintegrals of motions, all right
* So let's see how we can do this
* And there's some little tricks
* You'd have to write them down toremember all the little steps
* So I've got the second orderedderivative of x equals to minus kx
* This works nicely
* Now I'm going to do a substitution whereI'm saying v is simply x dot, right
* It's commonly done,like you do in second order system, we put in first order forms andintegrate it
* That's typically what we do
* So this side can berewritten as dv/dt = -kx
* And you can can also say, well, let me multiply this dtOver to the other side
* So mass times differential velocitiesequal to -kx times differential time
* This phone,this side is easy to integrate
* That's just mdv
* The integral of that is just going toa give you v plus the constant
* But the right hand side, x depends ontime and we don't have an answer for it in this form yet
* Is not as easy, so once you get tothe stage breaking these dts and dvs up, the trick is you want tomultiply both sides times v which is of course dx/dt,right that's what .x means
* So if I multiply bothsides over with this
* Here on the left hand side,I'm going to have mvdv, that's easy
* So, right hand side -kx times v and v is dx/dt.dt
* These dt's cancel and you end up with nothing but -kxdx, that's it
* Now we've got a set of equations wecan easily integrate and I'm not doing in between two specific points in time I'mjust going to get the indefinite integral
* So, if you do the indefiniteintegral of this, the integral v with respect to v isjust going to be v squared over 2 right
* So you end up with mass velocitysquared over two which is nothing but kinetic energy
* The right hand side, the integral of x with respect to x isjust going to be -kx squared over 2
* And then out of this whole thingyou have to do plus a constant
* What's this constant physicallygoing to be in this problem
* If you look at it the constant mvsquared over 2 plus kx squared over 2, what is that
* Total energy exactly that's it
* That's because it has a physical thing butin a more abstract sense when you have differential equations wecan often do this step but you don't get something that'sactually in terms of energy it's just an equation constant of whateverthese other things are right
* So here happens to be total energy butif you go back to these differential equations and do the same stepsbring this to the right hand side
* Instead of just having a minus A omegaI also Also have minus B omega cubed, I did the integrals of those in the endthen I'll have an x to the 4th over 4 and an x squared over 2 withthe right constants, and an integration constant, right
* And that's what we found here,so if you do that step, and I encourage you to practice thatonce because in the homework you have to use it anyway for one of the solvethe homework for, you can get this
* So this is the integration constant,you can see this is not mass over velocity squared the units are wrong thisis actually velocity rates, this is an acceleration squared,this can't be energy but it's something energy like in thatterm and this is a preserve quantity
* If I get my resulting tumbling motionout of your integration, and every integration times that if you're computingon mega .2 integrated and you have your current omega and you go through thismath, you should always get the same k
* All right
* So this becomes the great integrationcheck for talk free motion as well
* And I think one of the homeworks, in thenext homeworks said has you numerically stimulate this and validate that thisactually, you stimulate this numerically, you compute this analyticallywith the T's and the H's
* And this math should alwaysgive you back that same value that everything make sense
* That's a good numericalcheck of what's going on
* So this k1, 2's and 3's are nowwritten out in terms of the energies, these your integration constants forthe system
* So I'm giving you the completeanswer here at this stage.


--- SKIP ---: 07_5-torque-free-motion-phase-space-plots.en.srt


--- SKIP ---: 07_5-torque-free-motion-phase-space-plots.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_5-torque-free-motion-phase-space-plots.en_SENTbySENT.txt
* What other insight do we have, if we assume, as we did with the pole hold plots
* So without loss in generality, remember, we can always flip the principal axis such that the largest inertia is axis one, intermediate inertia is axis two and the least inertia axis is axis number three, right
* So, I assume this ordering
* Then, we found earlier the B's for one and three had to be positive, meaning they have very strong stability for large departures
* Here, that's negative, something we have to consider
* But intermediate axis, we know, this one is always unstable, right
* That was the separatrix stuff, so not too surprising
* It's actually linearly stable, nonlinearly unstable and the other two's you don't have it defined
* It depends on the situation, on how you're doing that and how you tumbling it for that, you know, the energy levels to get the right sign
* So, it's different ways we can do this
* So, when you're looking at these systems for small departures, we said, well, you know, k times x is always going to be bigger close to x's around zero, than another a times x is going to be bigger than b times x cubed if x gets small enough
* As x gets very very small, x cubed is even smaller, right, whereas x is going to be bigger in that sense
* At some point, this magnitudes always crisscross and as x gets large, at some point, x cubed will dominate
* So, you can use these coefficients to argue if you have a particular sign
* If A1 is positive, that means I've got a positive spring stiffness
* That omega one motion should stay nicely bounded and stable, nice oscillatory part
* If you have big departures and B is negative, that means once you go too far from the origin, it doesn't just oscillate at some point, it's going to just take off to infinity
* That's what you find out in this analysis
* Or vice versa, if a is negative, that means, well, it won't be stable
* Small departures drive you away from the origin, but if B happens to be positive, in that case, remember you can't have your x's then go to infinity because at some point x cubed is going to dominate and it will try to bring it back
* And, in nonlinear system you get things called limit cycles, and it doesn't converge to zero, but these two terms fight each other and you get these cyclic motions that happen in the end
* That's what it converges to
* So, the take off, this whole class is on nonlinear systems that talk about these things
* So yeah, B1 can always be restoring if it's positive, and we showed that
* Phase plane plots
* Let's talk about that
* Many of you have seen them, but not everybody, not everybody's had quite an engineering background
* So, if I have a simple mx double dot plus kx system, all right, what is a phase space plot
* What's on the horizontal axis
* Gamma x
* x
* And what's on the vertical axis
* x-dot, right
* So you solve this
* So, after some math or numerically, you find what x is going to be, and you have also a solution what x-dot is going to be
* If it's numerical, you could, you know, you're always getting your positions and your rates and you're integrating, so you could keep track of all of that
* The phase space plot is nothing but a visualization of my position and rates
* So, I'm not plotting it versus time, but I'm plotting added positions and velocities compared themselves directly
* So, if you have an oscillator equation I give it an initial deflection here, that's where I'm starting, and I have a sinusoidal response, right
* Initially, I take the spring
* I deflect it and then I just gently let go
* The system would just oscillate, right
* What happens to the phase space plot
* What does that curve look like, for spring mass system
* Andrei
* Circle
* It's a circle, for this case, right
* So, at some point, this potential energy goes into kinetic energy right and then it slows down again
* And then, the net positions become negative and then it becomes positive again and you're just going to circle around, right
* If I give it less deflection, you have a curve that does this
* If you give it more deflection, you have bigger curves, right
* Do these curves ever intersect
* If you start here, could this curve do this and go through here
* Then it's a different system
* If it's the same dynamical system, can you have phase space lines intersect
* And the answer is really no
* The challenge with that, if they intercept, if you had a different phase space plots, right
* It means if some curve does this and some other curve does this, when you hit this intersection points which way do you go
* It's a second order dynamical system
* If I'm giving it a position velocity, the accelerations are dictated by equations of motion
* You can't be going in two different directions
* Maybe unless you go on quantum stuff or something, you know
* But for classic mechanics systems, if given a position velocity, there is a very distinct acceleration and that velocity will evolve in a certain direction
* So, you don't typically see these lines intersect, but you get these flow diagrams that you can draw, and they will show you how the stuff evolves
* OK
* So, That's just a phase space, there should be a dot here
* That's what a phase space plot is
* With a phase space plot, let's still look at x double dot + kx, just x double dot + the natural frequency squared x equal to zero
* What is an equilibria, no, actually that's not the one I'm looking for
* Sin(x) equal to zero
* This is basically your planar and normalized version of a planar pendulum
* That was this problem we're talking about earlier
* With this system, what are my equilibriums going to be
* When is x doubled dot and x dot gonna go to zero
* If what
* When is x double dot gonna be zero
* That's the easy one
* Zero and 180
* Thank you
* So, if, x is equal to zero or pi
* So, on a phase space plot, plus or minus pi, right, because you can go upside down this way or this way, and if it hangs straight down, let's call that zero
* Right
* We know if we linearize this, it's just x double dot plus x, and you guys were arguing earlier, in that case, around the equilibrium, that's at the zero equilibrium I would have something where my phase space plots look like circles
* Alright
* And they have a certain direction
* But if you go here, and you'd linearize around that
* Here, you'd end up with x double dot equal to minus x, x double dot minus x is equal to zero, which gives you negative stiffness, and it's actually hyperbolically unstable
* So there's these asymptotes you can draw, and that's good for both of them
* So as we have larger departures, these phase space plots can all look like this
* And, if you're on these lines, you would do weird stuff, where you could tumble from one with enough speed and hit the, you know, you can go from here and give it enough initial speed to where you would hit over here again, and do different kinds of motions, right
* But, that's what these phase space look like, so you can quickly identify equilibriums
* If you do this and there's programs that will give you this flow, the phase space flow, and you will see the dead spots
* Those are the equilibriums and around it, the flows visually very quickly tell you this looks stable neighboring stuff or no neighboring
* Some of it comes in, other stuff goes crazy, right
* So, that's my quick review, if you haven't seen phase space plots
* So, these kind of things with linear and cubic part can be used for that, as well
* So this is one of the phase space plots we could talk about, where they flow
* Omega's nearby, those omega two's look good, but then there's a limiting case, as well
* And it turns out, with this omega two this was the separatrix case, but that was the intermediate axis case
* There's a limit
* If I'm doing a pure spin about omega two, that's one of the conditions, and then anything inside is a non-pure spin about the intermediate axis, and you can, it turns out, you can show, this paper showed, I'm not doing that in class
* But there's different limiting conditions that they can come up with, physical motions can never be outside here
* You have to be within this arc
* You can never actually exceed initial conditions
* It will give you nonphysical initial states that you'd have to have to get there.


--- SKIP ---: 08_5-example-phase-space-plots-for-varying-energy-levels.en.srt


--- SKIP ---: 08_5-example-phase-space-plots-for-varying-energy-levels.en_SENTbySENT.rtf


--- PROCESSING FILE --- 08_5-example-phase-space-plots-for-varying-energy-levels.en_SENTbySENT.txt
* Now, here, I ran through a simulation to kind of show you how these things evolve, and how we can use these Omega's phase-space plots
* So I got Omega 1 versus Omega 1 dot
* So my state versus a rate, state versus rate, state versus rate, the same phase-space plot
* I'm starting out with a minimum energy case actually, which is here
* So, H overI2, if T becomes my intermediate one, this value goes to one, this is kind of a nice normalized way to look at it
* But here T is less, so this value goes bigger, so here on this pole hold plot and spinning right here purely about B1, in the phase-space plots so you can see I have a B1 and no other velocity, it stays there
* If it weren't in equilibrium that point would be moving through that plot
* And the other two are perfectly zero
* So that's a pure spin about B1
* That's a minimum energy case
* Now I'm holding momentum constant and I'm pumping up the energy
* So what happens - this one shift slightly
* It basically means you look at this coordinate here it was fixed
* If I'm looking at this curve inside, that curve will be recessed inward from that equilibrium point, and there's a slight wobble to it because it's a potato shaped like curve
* That's why you see a little bit of a wobble in that coordinate, but the other two axes, the Omega 2 which it spins about this axis
* These coordinates kind of sweep back and forth that's what you're seeing here
* And the Omega 3 coordinates also go up and down up and down
* Right
* So it goes through the series
* And this is what these answers would look like
* So you can predict these motions given those second order differential equations we derived or you can just get them numerically by solving Euler's original equations
* And that's we just take an energy and slightly bumped it up
* If we bump it up more now I'm actually very close to the separatrix condition
* Not quite there but I'm pretty close
* So it's like one of these curves
* And I get there and hang out here along and then I come back again
* And if you plotted this in a phase space you get this teardrop looking thing that's at t=0
* And this is where you hang out a long time and then you go back around, because we're close to the separatrix condition
* The Omega 2 part that one just kind of oscillates back and forth doesn't look too crazy
* The Omega 3 speed versus velocity starts to pinch, and that's what you see happening here, cause that has to do with the slowdown as [a student] was saying earlier as we get close to these corner points and the separatrix stuff, that's where things really slow down all of a sudden
* And so that position versus rate stuff - not intuitive here - but if you solved it, that's what you would have
* So good, that's almost separatrix
* If you make it a separatrix you get this
* And the way I get a closed curve is I had to really cheat and look at the conditions on both sides and integrate
* Because we know starting from here, this is basically on one of these separatrix lines
* We know it would take an infinity of time to reach here
* That's only the asymptote that we would reach
* I can get the other part by starting on the other curve
* And that kind of completes the picture
* All right
* So it looks like a bow tie but you never go from one end of the bow tie to the other end of the bow tie or propeller or whatever you want to call this shape
* And this is this limiting case as predicted early from the phase-space plot, that's what you have with the separatrix
* Good
* If we add more energy now we're getting to some of these curves up here it starts to look like before
* This one's a little pinched dogbone shape still got an eyelid
* This other one I lose one of these
* Now I'm either on left or the right hand side
* Which one depends also on initial conditions
* This is where you go through this infinite sensitivity stuff
* It's hard to predict when you're doing just tumbles
* Are you going to spin about positive or negative
* That's the chaotic part of this system
* But here the numerics took me to one side
* That's what I'm left with, then as I pump up energy now it starts to tighten
* Now we get to these inner curves and at the very end I pumped up energy as much as I can
* I intercept here so you can see the phase space plots Omega ones and twos are just zero steady points
* And I'm back in an equilibrium
* That's doing a pure spin about axes of least inertia
* So I hope we get it
* This is just an illustration of how we can use phase-space plots to actually analyze whole ranges of motion
* Pole holds was one of them
* This is another approach that you see quite conveniently
* And we can also validate because you can predict these motions with those that make second order differential equations or you can solve the coupled non-linear equations that we had earlier
* They should all give you the same answer
* This is often a nice way to validate that all this math we did, with momentum and energy constraints, we did it correctly
* Because otherwise these things wouldn't agree
* Any questions on this
* This is the general inertia case
* So we don't quite get the nice sines and cosines analytic answer, but we do get three de-coupled duffing equations which is kind of elegant, as a sub-result.


--- SKIP ---: 09_6-torque-free-motion-attitude-precession.en.srt


--- SKIP ---: 09_6-torque-free-motion-attitude-precession.en_SENTbySENT.rtf


--- PROCESSING FILE --- 09_6-torque-free-motion-attitude-precession.en_SENTbySENT.txt
* Now, let's talk about attitude
* With the axis symmetry I gotsome really easy looking omegas
* One of the most flatline isgets you the sine and cosines
* [SOUND].That's how we get the amplitude and the right phase
* But that's pretty straight forward, right
* So, but the resulting motion, just lookingat these yaw, pitch, rolls relative to inertial frame, they were all overthe place, and very nasty to predict
* Lots of wiggles, bumps, andstuff that was going on
* So, it wasn't very intuitive topredict what happens to the natural procession of a torque-freeattitude motion
* So this is a classic resultthat people have done
* And anybody heard ofmutation procession before
* Good
* Was it Russell
* What does mutation mean
* >> It's where you're likeslowly going around and circling around what you're [CROSSTALK]>> So is this mutating or is this processing
* Is it mutating now or processing
* Who thinks mutation processiondefinitions are confusing
* >> Like slowly around the depth
* >> Good.I hate them, quite frankly
* I'm always confused by those darn things
* Why
* In the end,those mutation procession things, as I'll show you, they're nothing butolder angle rates
* And, as often in the literature,we're not consistent
* Some people talk about 3-1-3Euler angle rates which means certain motions mean something
* That's the notation part
* That's the procession part
* It's a 3-1-3 versus a 3-2-1
* The processions are often very similarbecause they are both 3 first axis
* But the 3-2-1s and the 3-1-3s are the twocommon things you will see people use to describe torque free attitudemotions and look at the tumbles
* But they don't always tell you what theyare doing until you look at the math, it takes a long time soI'd rather they just tell me, look I'm studying it using threeone three over under rates
* I know right away what you are talkingabout verses mutation and damping
* But it is a common mutation, commonthing you hear so let's cover it and I want to show youa little bit what it does
* The other issue is sowe are going to use older angle rates
* to start to prescribe how much doesthis wobbling disk process around and what's happening there
* The other trick is, whereas myearlier example acts as a metric, I was plotting my yaw pitch rollangles relative to the inertial frame
* With nutation precession, those terms, we're never talking aboutattitude motion relative to inertial
* We're talking about attitude motionrelative to your momentum vector
* That's the key difference
* So, if this thing is spinning this way, you have a big momentumvector sticking up
* Great
* Then you talk about precessingabout that momentum vector and how much you're nutating andwobbling Around the momentum
* If you're spinning this way, then procession is really definedaround that momentum vector, right
* So it has nothing to do withwhere your inertial system is, it's torque-free motion
* Momentum vector is preserved
* So, if we do that, let's go through this
* I know some of you have seen this
* So, you have some momentum vector,it's torque-free motion, as seen by inertial observer,this is a fixed quantity
* You give something some spin It'sgoing to have some fixed momentum
* And whatever else happens and how it gyrates and wobbles,that momentum has to be fixed
* So, we can now pick an inertialframe that is lined up with n3
* Just historically they pick the thirdone for some reason, to be = -H
* So now, I can talk about attitudemotion relative to this frame here
* And n one two are really arbitrary, they don't really matter muchin the end you will find
* So I can write the momentum vectoras minus h times n three and this is also an frame, right
* It's just lined, however you released it,that momentum was this direction
* So n three goes in the opposite,that's it
* So now we can write that andwe can say okay, good this makes my h vector in this particular end frame,all right this is a special end frame, not a general end frame,is zero zero something times a dcm
* This allows me to write my momentum vector components in the bodyframe in an easier way
* Generally this H if you have an arbitraryinertial frame H would have an H1 two and three in frame component
* Here we only have a third component, so that means times the DCM you are not onlypulling out the parts of the third column
* That saves you lots of Algebra
* Why do we do that
* So here's the DCM andusing 3-2-1 Euler angles here so I'll get 3-2-1 Euler angle rates out ofthis stuff times that zero zero minus H
* You do this, you have the H times sine andthe minus minus cancel
* Here we have H with a minus anda sine and a cosine of the third angle, which is rolled andthe second angle which is pitch
* So phi is rolled, theta is pitch, andthe same thing for the third term
* And this is the momentumvector in the body frame
* But then, you remember from kinetics,H is also equal to i omega, right
* That's what we derived forrotational motion
* And in principle coordinate frame
* This is simply i one, omega one, i two,omega two, i three, omega three
* So this is an elegant way that we can usethe three dimensional and get momentum vector to provide three constraints on howdoes omega and the angles have to roll it
* And you can see out of the 3-2-1 Eulerangles pulling out this column here because it was all about the third one,theta one doesn't appear here
* There's no yaw angle in here
* Which kind of makes sense because therewill be the motion about the momentum ,vector that happens there
* So, if this is the spinning and the processing rate you're going to have,if we take the system and twist it for 80 degrees about the momentum vector,it's completely asymmetric
* It gives you the samekind of a wobbly motion
* So that's kind of what manifestsin the Mathew, does know we are
* There is H and these omegas
* Well, this is nice, so I don't have tointegrate differential kinematic equations to come up with, at this attitude,what is omega going to be
* It's kind of like the energy conservation,the bouncing ball problem, right
* That we've used the completethree dimensional h vector here instead of just the magnitudeas we did with pole plots
* So that's good
* So now, we can divide by inertia andyou get this expression
* So, I can write analytically,if this is the pitch and this is the roll, these are the omegas you must have orotherwise you're violating momentum
* So good, we have that
* Now the next step is we have ourdifferential kinematic equations for my Euler angle rates and omega
* Now I just had an expression of omegas interms of these angles and you plug that in so instead of having a differentialkinematic for theta, you know, your state rates then you differentiateomega to get the accelerations, here we used angular momentum tocompletely get rid of omega dots and I get, I end up with torque free motionthat's three coupled non linear
* But first order of differential equations
* So I got, I used angular momentumto get rid of some of those dots
* Didn't have double dots in the end, inattitude angles, I only have single dots
* And this would be your procession, this would be your mutationif you used a 3-2-1
* And then, the third roll, we often justcall roll as the final roll motion
* But that's the wobbly plate problem, we'veall seen this plate on a table, right, that wobbles It doesn't keep the sameplane, that plate kind of goes around and precession anddoes some weird stuff, right
* That's all going to bepredicted now by these motions
* If you look at this, positive, positive,H magnitude is positive, sin squared, cosine squared, all positive
* The precession rate, your yaw rateessentially, is always negative
* And this comes out of the definitionthat we've chosen and end frame which is in the minus H direction otherwisethere will be a sign flip
* So is different this could be differentbut this is more the classic one whereas the pitching,that's basically a mutation rate
* Does this, if this spinning,is there an up and down motion that happens because of this
* And you can see, for example,if i3 is equal to i2
* This term actually vanishes andyou get rid of notation rates, as well
* So different shapes callcertain rate things to change
* Anyway, so this is the classic one forgeneral inertias, and we cannot be positive
* If you have an axis symmetric case, so I'm just assuming here B1is my axis of symmetry
* So, I1 is unique and I2 and I3 are equal
* And you plug it into those equations
* They simply fly down toa constant mutation rate and a constant processionrate that you would have
* This would tell you thatif the sphere is spinning, that at about the momentum vector,this object is spinning, but it's also slowly processing around
* It has to do that toconserve angular momentum
* And so, these are some classic resultswhere you can now actually make predictions about the attitude motions, and turns out all their angles are kind ofconvenient for some of this stuff
* They're nicely to be worked out
* And this tells you what happens tothe motion, since data is constant, your roll rate that you would have inthis situation also will stay constant
* So this is pretty classical
* We build a lot of spaceships thatare kind of, at least originally, almost cylindrical, very axi-symmetricjust because they come out of rockets and it's been released and have a wobble
* These equations are very common to kind ofanalyze what happens post tip off, how are things going to process,what's going to go on
* So, it's a convenient form
* Now, there's some other stuff people
* I'm just going to highlight this
* We're not going to go through details
* There's no particular homeworks on this
* But if you have angular momentum vector,here, this is my axis of symmetry, for example, that I had
* I'm spinning about this axis,and I'm slowly precessing around
* That's the momentum that I have
* So the current angular velocity vectoris not equal to just this spin, because you're spinning about b1 andsome of the other axis
* And there's all these different angles,but you're basically revolving around thiswhile processing around the he vector
* So these two motions that I'mdoing is basically describe cones
* And there's different ways peoplehave written these equations, but you can show mathematicallybecause this is equivalent to, those are the right equationsthis is a special case
* What they call a space cone anda body cone, so this is your momentum factorthat's fixed and our whole space
* The Omega Vector willtend to evolve around it depending on axis symmetry or not
* And then there's the bodyaxis that you have
* That one is going topossess around as well
* And so, it's like, you can mathematically describe itas one cone rotating on another
* And this is a What I wantis the largest inertia
* So that means it's kind of like a frisbee,a flat plate, spinning but slightly wobbling
* That's kind of an oblate condition
* If you have a prolate condition,which is more this pen, like a and or rocket body, andis spinning about the axis of symmetry and wobbling, you end up also witha body cone and a space cone
* But you can see you're kind ofwobbling on the outside of the, the thing's on the outside
* Whereas here, it's kind ofwobbling around it as a whole
* So, if you study some classic papers ontorque-free motions, you might come across some of these space cones, body cones andwhat I hope you remember is wait a minute, I remember this has to dowith these intersections
* And read up of on other angle rates andhow we can rewrite them as conic motions essentially cones andcones rolling this was all good and popular way back before we had allthese wonderful computer tools
* These days use integrate and[SOUND] out comes the answers
* But people done an amazing amount ofwork in attitude as well to get analytic answers and this is kind of one ofthe stages where this stuff comes from.


--- SKIP ---: 10_6-example-phase-space-plot-of-duffing-equation.en.srt


--- SKIP ---: 10_6-example-phase-space-plot-of-duffing-equation.en_SENTbySENT.rtf


--- PROCESSING FILE --- 10_6-example-phase-space-plot-of-duffing-equation.en_SENTbySENT.txt
* The Duffing equation gets a little bit more interesting
* So, I'm just showing here v is equal to a unit a and a unit b, so I just have, basically, x dot is equal to x double dot plus x plus x cubed
* That's what I'm simulating in this one
* But, this gives me now that phase space plot we're talking about with the Duffing equation, and there's a reversal of signs as well
* This part would be stabilizing; this part is actually destabilizing
* That's kind of what we had with the omega two motion
* That was that case, and this is the phase space
* If these have opposite signs, your x double dot can go to zero if all the x's are zero, which is kind of makes sense
* That's right here, and around it we get something that looks a lot like an oscillator equations, nearly circular stuff
* But, you can also get an equilibrium if x is, you know, if x is equal to one, then you have minus one plus one cubed just still one gives you equal to zero
* So, plus one is one and minus one
* So, those are two equilibriums that we can read out from this phase space plot, that we can do
* Then, we can have some fun
* We can play with this and make this a little bit bigger
* So here, I'm plotting the same phase space plot of all the possible, you know, lots of initial conditions
* If you started up here, this is what would happen to your curves and I'm plotting for a fixed amount of time
* This is a way then I can show you, numerically, the separatrix motions
* We saw it in the video, those, that spinning handle, right
* It hung out there for a certain amount of time, and then it went back to the other side, and came back
* And, we talked about how you hang out near the separatrix motion, as you get there
* So, here, what I've got something is I can put an initial condition and it quickly solves the differential equations, and shows me the resulting phase space motion
* If I put my initial condition up here, you know, starts very big
* I had a cube, an unstable cubic term, so that one would go off to infinity, as expected
* Right
* If I'm really, if I have small departures, stable linear term keeps me stable but if I get too far, at some point the unstable cubic will dominate
* And that's what's happening
* If I reduce my integration time, you will see that curve gets smaller
* So, you can see now what happens
* Here, I mean, the linear part, I'm just doing a fraction of an orbit
* But, as I start to get close to the separatrix motion, you can see I don't get very far
* I'd have to get really precise
* So, as I increase, I'm not exactly on it
* But you can see as I'm increasing, that curve gets close and really hangs out there for a while, and eventually it moves back
* That's precisely what we saw happening with that handle that the astronauts spun, right
* It hung out there for a while
* If I could get more precisely on it, I mean it is very very sensitive
* If I'm off, it hangs out there even longer
* And if I were perfectly on it, it would hang out there forever, and never quite get there
* If you're off infinitesimally, and you go in a whole different place, right
* And that's the definition of chaos, infinite sensitivity to initial conditions
* You're smidgen to left, and you go off there
* You smidgen right, you go somewhere completely different
* That's why this is just a, hopefully, visual illustration of why we're talking about separatrix motions and the conditions
* So, it's kind of fun to play with
* But as we come in and have enough time to actually complete my phase space plots
* I'm also showing speed in here somewhat, so as I'm coming in
* I don't need that
* Anyway
* What was I talking about
* Speeds
* Yes, this is showing something about the speeds
* Here you got green is faster, blues and purples is very fast, but once you come in, past the greens, yellows, so the reds that gets much slower again
* If you're close to the equilibrium, you just have a nice slow, just a little bit of a wobble
* And if you get close here you really slow down
* But then around it, we speed up to flip back again
* So this is just kind of a nice way to close out the torque-free motion part for a single rigid body
* We've seen the video that illustrated it
* We've seen up whole hold plots that do it graphically
* We've seen mathematical formulations where we did the axisymmetric and general cases, and the different predictions that you can do about these different motions and how things behave.


--- SKIP ---: 11_optional-review-torque-free-motion.en.srt


--- SKIP ---: 11_optional-review-torque-free-motion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 11_optional-review-torque-free-motion.en_SENTbySENT.txt
* We're looking at torque free motion
* And we did plots
* Let me jump to this one
* So what are the some key thingswe did with these polar plots
* Nathaniel, can you talk me through here
* What does this stuff actually show us, how do we get these kind of plots,what are we doing
* >> We're showing the energy as the, and the stability of the spinning, rigid body
* >> Okay.>> So- >> So what's this sphere
* Let's go back to basics,you're jumping into details
* >> I don't remember the name of it
* >> Okay
* Was it Andrew
* >> No
* >> Sorry, next to Nathaniel, yes, Ick
* >> Nick.>> That was off, completely
* >> The momentum sphere
* >> It's a momentum sphere, right
* So instead of using omega one's,two's, and three's as independent rate coordinates,we use h one's, two's, and three's
* Which is nothing but omega i's timesthe principal inertia, that's it, right
* But it's convenient becausethe momentum magnitude being constant, not the momentum vector
* We're using a sub result,just a magnitude being constant
* It gives us a nice geometric answer, it's a sphere, what causes theseintersections on this sphere
* So we're intersecting a sphere with what
* An ellipsoid,an ellipsoid represents energy
* So your rotational kinetic energy,using the same H1 2 coordinates, we're able to rewrite andit's a classic ellipsoidal shape
* So we've got this ellipsoid andwe have to intersect, so here I'm showing you lotsof different energy levels
* Nathaniel was talking about stability
* If you hear stability, the first thing you have to thinkabout is stability about what
* So in these plots we identifiedsome equilibrias, spin equilibrias
* So if you take an object andyou spin it about a certain axis, it's just going to keep on spinning,and that omega stays constant
* And all the omegas stay constants, right
* What were the equilibrias we identifiedfor a torque free rigid body
* Matt.>> H1 and H3
* >> Well, if you have it only inH1 intersection, that's true
* This was here, could you have a pure spin,an equilibria here
* >> Pragmatically, yes
* >> Then is it an equilibria or not
* All right,this is a common source of confusion
* That's why I'm glad we'll be going overthis again especially as we get into control stuff
* Equilibrium just means, x dot is equalto zero, and here, x is my omega right
* So all my omega rates are zero,it's not mathematical, not mathematical
* That's an equilibrium ofthe system all right
* Equilibrium has nothingto do with stability
* Stability is a different argument butsometimes, people confuse equilibrium being asstable as things turning a round
* So you've got the classical pendulumthis is one of the equilibrium
* And what's the other equilibriumwe have over planar pendulum
* Right, upside down
* Those are two equilibrius,now its a must, that's it
* But if I look at now stability Ican talk about neighboring motions, if you just off a little bit on this one
* Gravity will basically help stabilize and it stays closed a littlebit that thing it settles
* If we turned it upside down, if wehave to use a little bit of departure, are you going to stay close andof course not
* We know it's can deviate away, right
* So, just keep those twomathematical concepts separate, equilibrium just meansyour X star is equal to 0
* If you put it in this conditionit would remain there perfectly
* Stability now talks about well if I'm offa little bit and that's kind of where the real world starts because we neverhave it perfectly, well do I stay close
* So of these you basically answeredthe two spins that would be stable if I have a slightly more thanmy minimum energy condition, I would be one of these wobbles, andyou can see you stay reasonably close
* Same thing here this isthe maximum energy condition, I'm spinning aboutthe axis of least inertia
* And if I'm off a little bit you can see wobble lines these intersectionlines are staying close
* This one though is unstable, that'sthe one where you take your hammer and you flip your tool, it always flips180 very, very, very quickly, right
* So what happens, you go from this side andyou quickly go over here, all right
* Now, there is a very particular energycase, this is the minimum energy, maximum energy andhere is the intermediate access energy
* For minimum, maximum orits general inertia there's only one point one kind ofa spin you're spinning about b1 or b3
* If you have the intermediate energy levelyou could be spinning here mathematically, or you could also be on this inner sectionline which is called the separatrix
* It's not just a single spin forthe intermediate energy level that's the solution, it's actuallythere's these different arcs
* Now if you're on the let's say,you can see the arrows, they come in
* What can you say about how you willapproach this pure spin condition
* >> Tebow, like if you're exactly on it,it'll take infinite to get there
* >> Right
* You never actually reach this pointin a fine right amount of time
* RIght, so you're only asymptoticallyever reach it on this energy if you slightly off this one
* We saw that in the video last timewith the astronaut spinning that key
* Right, it kind of span
* It looked like it was reasonably stable,a little bit of wabble but staying close
* The next thing you know,it flipped over, wabbled here and then it flipped back again,and it just kept doing that
* That was one of the lines like here orhere
* So when it's close to the sphere spinabout the intermediate axis of inertia, it tens to hand out there a long,long time
* And then it flips over, butyou never remain there
* Whereas this one, you can hang out neara pure spin about axis of maximum inertia
* And you will stay there forever, whereasthis one you will keep flipping back and forth back and forth
* Now why don't we typically fly space craftspinning about the axis of least inertia
* So that's kind of like havinga rocket body spinning this way
* Besides seeing whathappened to explorer one, what's the mathematical reason wedon't like that stability up there
* Debo
* >> There's any kind of friction you'regoing to go down in the energy level and get to the separate
* >> This is all assuminga perfectly mathematically rigid body and any real body will have somepanels that will flex just a little bit, inside there might be justa little bit of give
* Every time you have a little bit offriction you're losing mechanical energy, and you could lose some,these are all internal forces, all right
* With internal forces I canactually change my energy state, I can lose energy, butcan you bring your energy state to 0
* With enough flapping of the panels,of fuel sloshing going on, will your space craft ever come to rest
* Daniel, what do you think
* >> No
* >> Why not?>> The minimum you can get to is just the
* The [INAUDIBLE] is only tangentto the sphere from the inside
* >> Which one was that
* That was this one
* All right, you do [INAUDIBLE]
* Right, your momentum internal forces andfuel slosh, as complicated as equations are
* Partial differential equations and surfaceinteractions and every stoke equations and who knows what else
* It only internal forces andwe've shown up angular momentum of a system cannot change unlessyou apply external forces
* So, that's why when you're loosing energy,you will asymptotically get to this kind of the case which youcan never bring the craft to rest
* All right, so those are all quickanswer questions that we've had
* So good, these little pole hole plots,they are quite common, you see these sometimeswith different analysis
* We'll see after, it's going to doa spin or similar configuration
* We're not spending too much time on onebut [INAUDIBLE] classic literature, you'll often find thesekind of illustrations
* And I wanted to make sureyou're familiar with that
* Here the thing we did lasttime was Torque-Free Motion
* These are the equations where we assumeto have a body of frame that's principal, therefore the inertia tensor is diagonal,right
* We get this nice form
* Now, if we have an axis symmetric body, you can see from here whathappens on the right hand side
* You always have differences of inertia,and if it's axis symmetric that basically means two inertias have to beequal about like this pen, about orthogonal axis are equal
* Therefore one of the termsis going to go to zero and immediately we know that omega dot iszero and that's going to be a constant
* Very, andthe trick how to solve this last time was, we want to go from these equations
* We know Omega 3 is constant, and to solve this they're now to couplefirst order differential equation Omega 1 that depends on Omega 2, andOmega 2 that depends on Omega 1
* Anybody remember the trickhow we got to solve these two coupled first orderdifferential equations
* Yeah?>> One of the equations
* >> We differentiate them again,which can seem counterintuitive
* We're trying to get rid of dots, in fact we add dots firstbecause it makes it easier
* By differentiating them weget basically omega 1 dot, omega 3's a constant, you get omega 2 dot
* Now we get to plug in the coupled one thatdepends on omega 1, and you end up with a differential equation that's onlyomega 1s, but we traded two coupled
* First order differential equations for two uncoupled second orderdifferential equations right
* So that was a trade off but this oneis a classic spring mass system so you can solve this very easily
* Anybody who has differential equationsshould know how to solve this all right, which is what we did
* So this is a classic answer ifyou have an axisymmetric body And when we do a numerical simulation,just looking at the tumble rates, you can see one of them flat lines
* That's expected, so the spin about the axis of symmetryis always going to be constant
* And the other two give you thisnice sinusoidal response, but if you look at the attitude,it's not easy to predict.


--- SKIP ---: 01_7-dual-spinner-equations-of-motion.en.srt


--- SKIP ---: 01_7-dual-spinner-equations-of-motion.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_7-dual-spinner-equations-of-motion.en_SENTbySENT.txt
* We have wrapped up for pre-motion, right
* So that's a spacecraft tumbling
* There's different ways to write it
* We can predict the angular velocities if it's axisymmetric analytically in a closed form
* If it's not axisymmetric general,there were these homogeneous undamped duffing equations that we can write,which is kind of elegant, that in your current homework you will actually apply this different ways
* What we're moving to next is different ways to start, not just having a rigidbody by itself spinning and trying to be stable, 'cause that doesn't always work out
* A common design that moved us from torque-free motion, where people looked at natural equilibrias of a -one single solid spacecraft, that's the simplest thing you can build, there's no moving parts
* But it has limitations about which axis you have to pretty much spin about axis of max inertia if you wanna turn stable with energy loss
* Now we're going to look at different systems
* The Dual-Spinner is a pop --- used to be a very popular design for GEO satellites
* It's still being built for some of them
* I think Cassini is actually a dual spinner
* It has this huge platform that spun at a different range than the lower platform and it helps the stability as well
* And so that's a very classic result that still applies
* Then we're gonna look at also gravity gradients
* That's the way people build satellites with it ---exploit differential gravity to stabilize the spacecraft
* So, but those are all passive weight
* We don't have any active feedback sensing
* Where am I pointing, where should I be going, and how do I close this loop
* That will be then in the third part of the class where we talk about nonlinear control for the feedback control developments
* We're kind of putting --- we're gonna have a little bit of theory on control theory
* You get all the basics basic that we just need for this class
* I'm not giving a whole class on nonlinear control, but this is the specifics you need, and this-and this is how we apply it specifically for the attitude control problem
* All right
* So, now dual spin and gravity gradient, those are passive ways to stabilize a spacecraft
* So let's look at this
* What we can write is --- I'm just modeling my spacecraft like this
* This doesn't necessarily have to be an axisymmetric body
* I just drew a cylinder cause it was easy to draw
* What I do have is a coordinate frame B, that's a principle coordinate frame, which we now know means, I've chosen an option where my inertia tensor just becomes a diagonal
* All right
* So, you have that and I'm lining up my spin wheel with where its spin axis is lined up with one of my principal axis, and just without loss in generality, I just called it the first one
* All right
* So, that's how this thing is lined up
* So, this flywheel can have a speed, big Omega, that's the speed it has relative to the body
* If you zero big Omega, that means this body now acts as a single rigidbody
* You know, the brakes failed and they clamped up and if the spacecraft tumbles the wheel tumbles, right
* But if you have a non-zero Omega, that means the wheel is moving so it's a way of having now, basically, two rigidbodies
* We're not looking at flexing at this point but it's a multi-body system that we're actually solving with this
* So, let's start looking at these things
* We're going to use, as before, we use H dot equal to L for a single rigidbody
* We're going to do H dot equal to L for this two-body system
* And the first thing we need is to get momentum
* Different ways to write this
* IS is my inertia tensor of the spacecraft
* IW is the inertia tensor of this flywheel, and this is a full three by three, all right
* But, since I've chosen a B frame where IS is a diagonal, and you can see this flywheel is symmetric so it has a unique inertia - I'm just calling that inertia, IW - along the spin axis
* And then there's two transverse inertias that are equal
* But in the B one, two, and three frame it's also gonna be an IS diagonal matrix
* The B frame is both the principal frame for the spacecraft, and for this wheel because of the symmetry assumption
* So, from that, actually, you can have a combined sector
* I is actually the combined spacecraft plus wheel inertia tensor, and it's also gonna be diagonal
* A diagonal plus a diagonal gives you a diagonal
* So, I'm just calling these I one, two, and three
* The wheel inertia about B one, its spin axis, is just going to be IW the scalar of it
* For convenience
* Now, that's the inertia tensor, now we want to write angular momentum
* Different ways you can add up the contributions
* One way is, you could say, 'OK, the spacecraft is spinning', and you can see, this is actually lined up in the CG
* The CG of the wheel, the CGA of the spacecraft, they are coincidence here
* It doesn't have to be
* If it's not coincident, that part of the mass is like having a bolt one meter removed, you just use parallel axis theorem, and adjust the inertia tensor of the spacecraft
* That's what you typically do
* So, without loss of in generality we can typically write it this way
* But here, I'm showing you one way where I'm saying, the total inertia times Omega, that's really gonna be the inertia of the spacecraft times Omega, which makes sense that Omega is B relative to N
* That's the classic angular momentum you've seen
* Then, the wheel momentum is gonna be the wheel inertia times Omega W relative to..
* And-and I'm gonna break that up actually into mathematics here
* So we have I is equal to IS plus IW
* And if I'm saying now, IS times Omega BN, that's the momentum of the spacecraft
* Sorry, IS times Omega BN, and IW, I need the angular velocity of W relative to N
* But W relative to N is simply gonna be big Omega times B one plus Omega B relative to N
* This is your angular velocity of the wheel frame relative to the body, alright
* That Omega was defined relative to the body frame
* So, like in that exam problem where you had feet, that second angled part one defined relative to the first link, you know, this is how it comes up conveniently
* So, that makes it easy
* So now we've got this, so this is really gonna be expanded as IW times Omega BN plus IW times this part, alright
* This and this combines to IS plus IW times Omega BN, plus this part is really a three by three that you have
* And this in the B frame, 'cause that's the principal frame of the wheel, and the angular velocity is just gonna be Omega zero, zero, in the B frame
* If you use B frame components
* So, you can see out of this all you're gonna get is this inertia which is IW times Omega, and these other ones don't matter cause they're all multiplied times zero
* So, out of the end result, this thing just becomes IW, big Omega, and that's in the 1 axis
* So, if you carry this out, you would get this zero, zero
* And that's the same thing as B one hat times that
* This is nothing but the inertia tensor times this
* So, those things added up
* Different ways you can get to it, alright
* So, here I'm doing a little bit more of a direct way, where I kind of doing this implicitly
* OK, this is the angular momentum as if the wheel were locked, and then I'm adding the angular momentum of the wheel relative to the body
* Different ways you can approach it
* But try different ways cause it should always give you the same, and these are simple derivations again
* This is prime stuff for a final exam
* You know, I can- something you can do, you should be able to do
* So, now we have H written out, and this tensor, I'm not specifying any particular frames at this point
* Anyway, it just, it all adds up
* So, we need H dot equal to L
* We're gonna choose to differentiate this vector as seen by the body frame
* Why
* Because we know it's seen by the body frame, the-the I primes will be zero
* But then we have to add Omega crossed, there is momentum vector again, alright
* Same thing is what we did with a single rigidbody, we're applying it to this dual-spinner now
* This part looks just like the rigidbody, which is actually have the inertias of two rigidbodies, if one were locked relative to the other, and it gives you the same results
* So, you'd have the body frame derivative of Omega, which is the same thing as the inertial derivative of Omega, alright
* Cause Omega BN, the crossed products vanish
* So, this gets you exactly the same parts plus Omega cross this vector, that gets you Omega till the I Omega
* So, this part is just like a single rigidbody, just a t- if that t- If that's- if that's, if that wheel locks in, it is a single rigidbody, alright
* Essentially
* That's one way to look at it
* This second part
* People typically call this momentum of the wheel relative to the body, a little h, little - a lowercase h
* You see this often in the literature, so I'm gonna use the same notation
* So, IW a - this is a little h
* So, as seen by the body frame, this wheel can change speed, it can spin up, it can spin down
* So, I'll have an h dot in the B one, and then Omega crossed hB1
* This vector, it has to be equal to the external torque
* So, if you carry this out, you can plug in Omega as being Omega one B one, Omega two B two, Omega three B three, and you cross with B one, you know how to do that, the B one B ones cancel, the B two B ones give minus B three, and then the B three, B one, gives you minus B two, and then everything is moved over to the other side
* So, we have, like before I'll make a dot equal to this, that's like a single rigidbody
* I have dropped L at this point saying, 'Let's look at a torque-free motion case', and the rest of the gyroscopics are also brought over to the right-hand side to those are the wheel gyroscopics that come in
* If you change the wheel speed, you get some effect along B one
* If you just are spinning and you're tumbling with the spacecraft and your wheel is spinning and you're tumbling, there's some cross coupling terms that appear in here
* Alight
* But that's it
* I have now derived the equations of a dual-spinner where the spin rate doesn't even have to be constant
* So, let's look at this more
* This is written in a complete tensor notation, so this doesn't have to be a principal frame actually
* This still works even without that assumption
* But if we assume it's a principle frame, we can write this as a diagonal
* This other part, Omega till the I Omega, if this I is a diagonal, it simplifies like with a single rigidbody
* And the other terms, we had something in the B one, two, and three direction, we can rewrite into this
* This is the gyroscopics of having a spinning or accelerating wheel there
* That's how it impacts a spacecraft.


--- SKIP ---: 02_8-dual-spinner-spin-equilibria.en.srt


--- SKIP ---: 02_8-dual-spinner-spin-equilibria.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_8-dual-spinner-spin-equilibria.en_SENTbySENT.txt
* Now, let's look at this
* What we're going to start to do now is,talk about stability
* And as soon as we talk about stability, we always talk about smalldepartures all right
* This is an equilibrium andthis is an equilibrium
* Equilibrium has nothingto do with stability
* Equilibrium just means,if I put it particular side of state
* Theta is equal to 180 degrees, if I ammeasuring this is zero, this would be 180
* What happens if I have smallmotions than stability?
* Equilibrium just means, if you this at this particular state,your state rates will go to 0
* X go to 0
* And as we did with the spin stabilityof a single rigid body, we're going to look at for what conditions now will thisvanish, if I did n't have any of this
* If I only have this, You can see, for what conditions will omega 1,2, and 3 dot go to zero
* One case is of course trivial,as you make all your rates 0
* That not exactly a spinning condition,it's going to have a trivial solution
* If you have something else though,the only way you can make with general inertias, the only way you can makeall of three terms go to zero Is how
* Andre
* >> By axisymmetric
* >> It doesn't have to be axis,we can look at axisymmetric
* If it's axisymmetric about one ofthe axis, this could go to 0 which says, omega 1 is constant, right
* And then, you have to make these twogo to 0 if omega 1 is a non 0 value
* The only way these can vanish, theseare not the same inertias cause it's not the spherical symmetry, is omega 3 andomega 2 would have to be zero, right
* That's one way, yes
* But for general inertias, if the inertiadifferences are never zero, how'd you make all three of them go to zero withouthaving all three omegas go to zero
* Just to big omega and [INAUDIBLE]
* >> Well,we don't have big omega right now
* Let's ignore the real
* If you just have single rigid body
* Spencer
* >> Would you spin it aboutthe axis of maximum inertia and then, have 0 spinningabout the other two axes
* >> You could.In fact, you could spin it aboutany of the principal axes
* because if omega 1 is nonzero, let's sayomega 1 was axis of maximum inertia
* Then omega 1 is nonzero, this is nonzero
* But Omega 2s and 3s is 0
* I got 0 times 0, something finite times 0, which is also 0 0 again something times 0,0 right it all vanishes
* This is where we identify quickly fromthe mathematics now the three equilibrium spins for general inertia isappears spin about to b1, b2 or b3
* Which also what we saw graphicallyin the pole hole plots
* And we discussed several different ways,right
* Those are the three spin equilibrius
* But in real life, we don't spinspacecraft around intermediate axis or leased axis because we have to worry aboutany anticipation and chaotic behavior
* So, it really limits your design tojust spin about axis of max inertia
* Geostationary satellites tend to be tall,those Boeing 501s I believe were these big tubular shapes and they want to spin sothey're always pointing at the earth
* So, they want to spin aboutthe least axis of inertia which we know is an issue with energyloss, and always be pointing at the earth
* And so, this dual spinner allows usto spin actually about any axis
* I could even spin with the dual spinabout axis of intermediate inertia
* And with the right spin conditions whichwe'll develop I can make it stable
* So this is a way to provide passivestability without the dual spinner, you could only long term spinabout axis of max inertia
* With the wheel once we add this stuff
* We look at the mathematics now
* I can show you that wehave other equilibrias
* And conditions where if wepick the right wheel speeds, I can make any one of themstable without feedback
* So rigid body,we have to spin about B1, 2, and 3
* Those are the equilibrias
* Now, let's do the sameexercise with a wheel
* And we're going to say thiswheel with a dual spinner, your nominal case is the wheelis moving at a constant rate
* That means omega dot vanishes
* Now, I want to find an equilibrium,where is omega 1 dot, 2 dot, and 3 dot 0
* And I'm going to have Non 0 omega 1,2s, or 3s
* I don't want everything to be stationary
* That's back to the trivial answer,but I also want to have a non 0 omega
* How can we make that work
* >> [COUGH]>> All right, because you kind of basicallygo through deductions
* Like Sherlock Holmes,you deduct what can't be possible
* Whatever is left, however improbably,must be the answer, right
* So if we start out here, this is alreadyzero because it's a constant wheel speed
* The only way to make this zero, and again,we're looking at general inertia still, in this case, is either to omega 2 or3 has to be zero
* Okay, let's pick omega 2
* Right
* Start the deduction
* If omega 2 is zero,this is going to be 0 and this is a finite wheel speedtimes 0 it's all going to be 0
* And you go hey, I like this
* Okay
* But now, omega 3
* If this is going to go to 0,you could make omega 1, 0
* But if we don't want allthree of them to be 0
* If you make omega 1 0,omega 3 has to be 0
* This term goes to 0
* Omega 1 being 0 times something
* If omega 3 is not 0,then you have nonzero times nonzero
* You don't get a 0 secondderivative of the omegas
* A zero derivative over the second Omega
* So, that wouldn't work
* So, instead what you can seeis you make Omega two zero
* That vanishes, cancels this,makes this all zero
* The only way you can make this one zerois to take Omega three that's zero
* Then even if Omega one is non zero
* It doesn't matter
* And the wheel can be non-zero,and it doesn't matter
* They're both multipliedtimes something zero
* So, that's going to be the equilibrium
* You notice the first axis is also, soI can have an omega one that's non-zero
* But that one axis is also the axisthat's a spin axis of the wheel
* That's where this came from
* About any other axis, you can't really make this workI could have picked omega three, went through the same logic, you end upwith the same answer with this stuff
* So, instead of being able to have spinequlibrias about any of the principle axes of the space craft with a dual spinner,you're now too constrained to only have an equilibria aboutthe spin axis of the wheel
* If I have a tumble about omega 2 andnot omega 1 and 3 I end up here with cross coupling terms that will giveme non 0 derivatives right that wouldn't be an equilibrium spin it would be moreof a general tumble that you would have
* So, yes Ansel
* >> You were talking about how this waspassive but you would need some kind of
* Big or bigger right
* If you have to actually carry this out
* >> You would spin it up
* And we'll get to the spin up part in a fewslides, probably on Tuesday next week
* But here it's just once we'veaxed the spin condition
* And then, you just have a little motorthat keeps it spinning at a fixed rate
* There's no external feedback that sayslook at the stars, look at the horizon, look at everything and stabilize me
* It's just holding it at a fixed speed
* That's it
* >> Big omegadot as zero
* >> Yes, so the dual spinner,the nominal case is big omega dot to zero.


--- SKIP ---: 03_9-dual-spinner-linear-stability.en.srt


--- SKIP ---: 03_9-dual-spinner-linear-stability.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_9-dual-spinner-linear-stability.en_SENTbySENT.txt
* So these are the equilibrias we're trying to identify
* When are - if I have equilibrium states, it's like with the pendulum, right
* Theta zero was an equilibrium, 180 was an equilibrium
* And then you can look at 180 plus deltas, right, to look at small departures
* With the omegas, I'm saying I have some omegas equilibrium spin, and then I can look at small departures
* What if I'm wobbling slightly off axis
* Do things stay close or does things go crazy
* Right, that would be unstable
* So if you look at equilibrium conditions, we'd make the big omega dot equal to zero
* I've basically rewritten it, but instead of just having omega one, two, threes, it's omega E1, 2 and 3s to highlight these equilibrium conditions
* And what came out of this was that we had to have this condition, essentially
* The spacecraft has to be spinning about the same axis as the wheel
* The other two have to be zero
* Then all my omega E1, 2s, and 3 dots become zero
* That's an equilibrium
* So now we're going to look at small departures
* So we're using linear stability analysis
* It is - if you haven't done too much of this, this is nothing but a basically spring mass damper-like system in the end
* Right
* Once we linearize about this motion, you end up with something plus cx dot plus kx, and then from then we can argue stability
* So the angular accelerations, if you put dots on everything, you would just have your nominal spins plus the departures
* And we know, for our equilibriums, the nominal spins about two and three are actually going to be zero
* This one could be none, or at the equilibrium, it has to be zero
* Omega E2 is going to be zero
* E3 is going to be zero
* This one is going to be a non-zero value
* This is going to be a non-zero
* So you just plug in the terms and one - there's different ways you can linearize
* Later on, we'll do Taylor series expansions and come up with first order terms
* Here, I'm just plugging it in
* I see delta times delta, that's second order, I drop it
* If you have omega E1, that's some number times a delta; well, that's still first order, I keep it
* First order times zero; well, that's definitely zero, right
* And you drop it
* But that's basically what you do when you run through these
* These equilibrias are both zero and only have first order terms
* So you can run
* And in your homeworks, you've also do some linearizations
* If you now drop all the second order or the zero terms, this is what you end up with a dual spinner
* So right away, this looks a little bit like the axisymmetric case we covered, where we had two inertias being equal and whatever was the axis of symmetry, the spin rate about that axis ended up being constant, while the other ones you could wobble and we had sines and cosine answers
* Here, in this mathematics, we have our departure
* This is not my nominal spin rate
* This is my delta omega one
* So if I'm supposed to be spinning at one degree per second, but somebody kicked it off with one point one degree per second, right, then you're delta omega one is point one degree per second
* This tells me how does that point one degree per second change with time
* And it turns out, it doesn't
* So if you're spinning off a dual spinner and you inject it into that orbit and instead of doing 360 degrees per day, if it's doing 360.1 degrees per day, well, it will just keep doing that
* So we call this kind of a marginal stability
* It doesn't grow, it doesn't shrink
* It doesn't do anything
* It's just flat lines there
* It's not - so it doesn't recover itself if it's off
* It doesn't get closer again at some point like that
* So if you - if you weren't happy with that behavior, you probably would need some active control to nudge it and get it within your tolerances
* I have to have a drift rate that's less than one thousandth of a degree per day or something, you know, to always be pointing at the Earth
* So - so dual spinner doesn't give you any passive stabilizing component
* It doesn't make it go unstable, it just - whatever air you have, that's what you stick with
* That's one way to look at this
* Now the other two, again, omega E1, that's our nominal spin rate
* 360 per day, that's one rev per day like a geo satellite would have to do
* These are the departure motions and you can see that my departure spin rate about the second axis is a function only of delta omega three
* So delta omega two dot depends on delta omega three and delta omega three dot depends on delta omega two
* The wheel speeds are just constants that we hold here
* So we have two coupled first order differential equations
* Matt, do you remember our trick we had earlier
* How to solve two coupled first order differential equations
* You take the derivative from it
* Exactly
* We want to get rid of the derivatives to find - or find an answer to this, and it turns out it's often easier to first differentiate again
* And that's what we're gonna do
* Because if I take the derivative of this, all of this is nothing but constant
* My nominal speed is a fixed value
* It's supposed to be doing 360 per day, right
* This is a fixed wheel speed; inertias are fixed
* So everything is a constant
* So I only have delta omega three dot
* Then, when I take this derivative, I can plug in this equation and get one second order differential equation
* Very similar to what we did mathematically with that single spacecraft axisymmetric case
* So if I do this, I took its derivative, all this is constant, you get this, plug in the other equation, you end up with this one
* Now this should look very nice because this is basically - instead of delta omega two as a variable, just call it X, and you end up with x double dot plus KX equal to zero
* And if you have any information about a spring mass system, the only way this is going to be stable and give you oscillatory part, is you have to have positive stiffness
* All right
* So we have to design this k
* This is not really a spring, this is just a mathematical coefficient that comes out of this - this dynamical system
* So we have to pick inertias and spins and nominal things such that k is going to be positive
* Right
* That's going to give us stability for the other two axes
* The first axis is just going to be marginal
* That's all you get
* Now, in this case, I have different ways to break it down
* Essentially, you have one bracketed term times a second bracketed term
* It has to be positive
* So Lucas, what can you say about the signs of the bracketed terms
* What must be true of them for this to be stable
* They have to cancel with each other
* How do you cancel
* What would you mean by canceling sines
* Does this first bracketed term have to be positive or negative
* And what the second bracketed term has to be
* Not sure
* All right
* We want the product of two terms to be positive
* So what must be true of the elements of that product
* They're both positive or both negative
* Right
* As long as they're the same sign, we are good
* Don't just jump right to well, this - if this has to be positive, this has to be positive, this has to be positive
* That's not quite true
* That's a condition, but it's not the only condition
* Either we have positive-positive, which is stability, or positive-negative, sorry, negative-negative, which is stability
* What you don't want to do is have positive times negative
* That would definitely be an unstable situation
* All right
* And that's - that's essentially, with all the math, that's what it breaks down
* So now, if we have some inertias and we have some nominal spin rate, I want to spin about this axis at two RPM, 50 RPM, whatever you're doing, what allowable wheel speeds do I have to guarantee I have positive stiffness
* All right
* This is what it boils down to
* So we can rewrite this different ways from this parameter here, k, I can factor out omega E1
* That means I divide this wheel speed by the nominal spacecraft spin rate and that's what's omega hat
* You see, omega hat is just a normalized version of the wheel speed
* So if this is point one, that means your wheel is rotating at 10 percent of the spacecraft speed
* If it's four, you're rotating four times faster than the spacecraft speed
* That's one way to look at it, it's a convenient way
* And then we factored out some other inertias and brought it back together
* This number squared is always going to be positive inertias, or hopefully positive
* Otherwise you have some imaginary system
* I'd be very interested in seeing that
* But then you're back to bracket times bracket
* But there's no more ratios
* It's a little bit simpler to look at
* And again, we need both of them to be positive or both of them to be negative
* Let's look at the one case
* We argued stability looking at pole hold plots if we don't have a wheel spinning, right
* So if we lock omega hat to be zero, we've got nothing but one rigid body and we should be able to recover our results we saw from the pole hold plots, which said without energy loss, spins about least inertia were stable, spins about max inertia were stable - we've stayed close - but spins about intermediate inertia were always unstable
* Right
* And we can see that if we look at this
* So if I take out the omega hat part, all you have is the difference between I1 and I3 and I1 and I2
* And you can readily see that if we have a spin about max inertia, if B1 is a max inertia case, then this difference has to be positive because I1 is the biggest one, so negative anything else is going to still be above zero; I1 minus I2 also has to be positive, because I1 is larger than I2; so positive-positive
* As we predicted with the pole hold plots, we're getting a stable response in a linear sense
* And the least axis of inertia, if I1 is the smallest inertia, then I1 minus I3 will be negative, I1 minus I2 will be negative and we have negative-negative and we're also stable
* That's the axis of least inertia
* The skinny spin
* So linearly, they look stable
* We know already with energy loss - and the pole holds actually gave us much more global arguments, this is only for linearized local arguments - but we regained the results that we had earlier
* Again, this is a classic result you should be able to do with those equations
* So let's look at non
* This is the condition we had if we do have the wheel speed
* So there's always two sets of conditions that comes out of this
* Either we pick a wheel speed such that this is bigger than zero - that means I1 has to be bigger than this part, so I bring all that to the right-hand side and that's what you have here - or I1 has to be bigger than this part over here, which I brought to the right-hand side
* So you end up with two inequalities
* And both of them have to be satisfied, right
* If both of them are satisfied, you are positive-positive
* If Instead of greater than, if I flip the sine and say well if this one is less than, that makes this negative, this is less than, that makes this negative
* So it's the same boundary points
* If you make it equal, you have two points on the wheel
* If you look at your wheel speed spectrum - zero's in the middle, then you go left, right, you will find two points that are critical, where one bracketed term switches sines and another point where another bracketed term switches sines
* Once you've identified them, you want to find out where you - are you between the points, are you outside of those points
* What is the domain that makes it stable
* The beauty is we can do this regardless of the inertias
* So I can always actually enforce this condition.


--- SKIP ---: 04_9-example-dual-spinner-stability.en.srt


--- SKIP ---: 04_9-example-dual-spinner-stability.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_9-example-dual-spinner-stability.en_SENTbySENT.txt
* So here's a example wewant to run through
* Here, I have some principle inertiasthat are 350, 300, and 400
* Now, just by the numbers, a littlebit unfortunate, the intermediate one if 50 beneath the max and is 50 abovethe min, so it's plus and minus 50
* This is why when we look at these wheels,the critical wheel speeds, where things go stable unstable,it happens to be symmetric
* But, generally these inertiasaren't split evenly like that
* So generally those critical wheel speedsare not necessarily symmetric, all right
* This example will have them symmetric
* The wheel inertia is ten kilograms,just to make a lot of math easy
* Spacecraft is to spin about 60 rpm, aboutb1, so that's our Omega e1 that you have
* And so now, we're trying to figure outhow fast do we have to spin this wheel at least to guarantee linearstability of the system
* So you want both bracketed termsto be either positive or negative
* Now, those two bracketed terms couldbe positive, that's the Set 1
* That's where we have I1 must be greaterthan these other two terms here
* In that case, the left bracket andthe right bracket are both positive, and then we have a stable system
* Set 2, actually just simply reverses this,greater than becomes a less than
* This is the condition that makes the firstand second bracket go negative and that is also a stable configuration,all right
* So now, we want to look at whatis the range of spin rates
* So the way I like to think of thisis just look at the spin axis
* We have zero
* And then, I can go positive spin rate andnegative spin rate
* And we're going to put in inequalitycondition to start to go it has to be at least to the right of this mark
* And it has to be at least to the leftof this mark, so what's left
* The union or intersections of these different areas,that's how I solve this stuff at least
* So if we're looking at this,in this problem if the wheel speed is zero,is this system going to be stable
* Brian
* >> They'd take a look atthe inequalities again
* >> No, no
* If the wheel speed is zero,there's no longer a dual spin, there's simply a single rigid body
* And we're spinning about b1
* About which inertia axisare we spinning then
* >> It's not going to be stable
* >> All right, because now we have 350
* So b1 is an axis of intermediate inertiain this particular example, right
* So we know up front, zero cannotbe included in my solution space
* I have to, if this is going to work, I have to have something positive ornegative
* And we'll see how that drops out
* So if we do this,here's the two inequality conditions
* The second one, forexample here, this is one set
* You can say okay, I2 minus,you can bring this term over, that gives you I2 minus I1,divide by this
* Iw, I2 minus I1,gives you minus 350 divided by 10
* No, it gets you minus 50 divided by ten,gives you minus five
* So by bringing this over, omega hathas to be bigger than minus five
* If I'm just going to draw that here,so let's say, here's the minus five part,that means, what did I say, less than
* All right,thinking too many steps ahead, okay
* No, it's greater than
* Okay, so that means we would have to be somewhere greater than minus five
* But that's only one condition
* Now the other condition, here I'm just going through the matha little bit more steps, right
* I'm bringing this condition and bringingthis part over to the left hand side
* I1 back over to the right hand side
* I divide by IW2, here it's I3 minus I1
* You plug in the numbers, which you dosomething similar in the homework, so I'm just not going to
* You know how to do this algebra
* Then omega hat as to begreater than plus five
* So if we look at this now and say, okay, there's also a plus five,and here's the other point
* This is the domain that makesthe second bracket go to B positive
* What is the actual solution space then forstability
* [INAUDIBLE] Great
* So that union between both, right
* because we need both ofthem to be positive
* That's going to be here, all right
* Outs greater than
* Is that the only domain, though
* Carlo, what do you think
* >> Will be less than minus five
* >> Less than minus five, now talk methrough why that it's also domain correct
* >> Because the second set of equationsdoesn't give us that answer
* >> Yep, the first set alwayshas greater than, greater than
* You've identified two points whereeach bracketed term flips signs
* Once you've found those, you've reallyfound, instead of greater than, it's all less than
* So instead of alwaysbeing to the right of, it's always going tobe all to the left of
* And, again, the same unions
* So if you did that to make both bracketsnegative, If I pick a different color, let me make blue for negative right
* Then you would have to be here or here and the union of that isjust going to be here
* So you can see as expected the originis not included in the solution space
* Because as Brian was pointing out, this is a single rigid body spinningabout axis remediated inertia
* We know it's not stable, butif the wheel spins up enough then at some point,you'll notice with this wheel spinning, you're spinning oars is an oblate body,you're spinning by axis of max inertia
* That wheel by itself,the way it's defined
* It's always going to be stable, right
* So if that wheel spins fast enough,one way to think of this is the stability of that wheel is going to overcomethe instability of the spacecraft spin and that's how we stabilize it
* But you have to get to some minimumamount where it's just equal and then you have to be greater than that,hopefully, quite a bit greater that it will increase your stiffness andyour response time as well, right
* So either you can go positive or you cango negative and that will get you there
* Now, so good
* So in this case, I have, this is one ofthe wheel's speed, the critical speeds, you could use or it has to be bigger than that really,that's what you have to write
* Not equal, but probably bigger than that
* Or it could also be lessthan minus 300 in this case
* There's two sets, both brackets positive,both brackets negative
* So if I'm giving you someproblem like this though, here I am saying,we are spinning about major axis
* So in this case, b1 is axis of maximuminertia and without a rotor spin, so the origin, we would have to be stable,which is what I am showing
* If we are spinning up more aboutthe spacecraft by definition, already has a positive spin, about b1
* That is how we derived to all this stuff
* That's how picked b1
* And now,the wheel is also spinning about that
* If the spacecraft is max inertia stable,the wheel is max inertia stable and they're both spinning about positive b1,it's always just going to be stable
* More and more stable
* If you start to spin itthe opposite direction though, even though the space craft by itselfwithout that wheel will stable, it has the speed momentumthat helps stabilize it
* What happens with the wheel,if it's in the opposite direction, it's going to start to pull out the totalmomentum gets reduced, actually
* If this is spinning at 10 RPM positive and the wheel is 100 RPM negative,you're pulling out momentum
* And in fact, the momentum perspective,at some point it acts like the separatrix, it acts like the unstableintermediate axis motion and you will drive a system unstable
* But the good news is no matter what axis,principle axis, you want to spin nominally, we can alwaysfind a wheel speed that will stabilize it
* [LAUGH] The bad news is no matter howstable the spacecraft was before you touched it, once you touch it, you havethe capability to drive it unstable
* So make sure you have the rightreal speeds otherwise your sponsor will not be happy
* At some point again,if you go fast enough, then the wheel momentum will dominate andit's very, very stable
* Whatever the spacecraft'sdoing is almost noise
* So with all duo spinners to extremesinfinity real speeds always stable
* But in between, there is a region,a finite zone, that is unstable
* So for an intermediate axis speed,which we looked at
* And in our problem, we had plus and minus five, that was just because of theinertias, it doesn't have to be symmetric
* If you see something like thisthat excludes the origin, right away I could say, this must be spinning about an axis ofintermediate inertia with a dual-spinner
* Just from the solution space
* And, if you have an axisof a least inertia, you're spinning about this region that youshouldn't be spinning about is actually in the positive spin direction and justall comes out of the mathematics then
* Jordan.>> Sorry, I missed how can it be stable if you'respinning it less than negative five
* >> Both bracketed terms
* because the two brackets haveto either be positive, and that was the argument forthe black hash lines
* But we found the two critical points
* If we also less thanthose critical points, then both brackets both become negative
* >> Okay
* >> And that's why this is also a possibleanswer, out of the mathematics
* >> Thanks.>> Yeah, good
* So anyway, butthis gives you now a quick solution space
* You can do these easy homework withthis yourself, to come up with it
* But just remember the extremumsare always included
* The origin is only included fora max and min inertia case and then you kind of look at the pattern
* If I see the pattern, I know rightaway what type of spin we're doing.


--- SKIP ---: 05_9-1-spin-up-considerations.en.srt


--- SKIP ---: 05_9-1-spin-up-considerations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_9-1-spin-up-considerations.en_SENTbySENT.txt
* Okay now we were looking atan old nominal big omega.zero
* The wheel's not accelerating
* We don't launch that way
* We launch with everything locked down andthen we release it
* And in fact, the craft will havesome spin after it gets kicked off
* And then we engaged its wheel andmomentum happens and how does it settle in the endas you're spinning up
* There are some classicanswers we can go through
* So To begin with, what's commonlydone with these dual spinners, they're released where it's spinning aboutan axis that's not aligned with the wheel
* Wheel was aligned with b1, sothe spacecraft, let's assume it's spinning about b2 or b3 or some combinationthereof, something orthogonal to b1
* So we want it to be doing this in the end,spinning skinny, but right now it's just doingthis kind of a tumble
* And then the reaction wheel is spun up
* If this is spinning, andit has inertia of one, and a spin rate of one, then inertia timesspin rate gives momentum of one
* Just non dimensional units
* I'm going to spin up my wheel untilits momentum magnitude matches that of the space craft after launchwhich is one in this case, right
* Now, in this kind of a dynamical system isIs the angular momentum vector conserved
* Tony
* >> No, because there's a torquebeing applied to spin up
* >> Right.There's a torque
* But the torque is appliedbetween which two bodies
* >> The wheel and the spacecraft
* >> Okay so for the system I'm talkingabout wheel and spacecraft system
* >> Okay.>> Is that an internal torque or an external torque
* >> It would be an internal
* >> Exactly.So there is still no external torque
* So for the combined hub and wheel system,the total momentum vector which is what we [LAUGH] used to derive theequations of motion like h dot equal to L
* That h still has to be fixedas seen by inertial observer
* So we can use that
* So then we want to really study whathappens to the attitude as we do this spin up, right
* And we're going to go through this
* So the initial spin rate, we said,we're tumbling here, right
* About b2, just without loss of generality,I'm tumbling at a rate 1, inertia 1, gives me momentum 1,that's what I have here
* And spinning up the momentum ofthe wheel relative to the body, that was the wheelinertia times big omega
* Big omega was omega ofwheel relative to b, right
* I'm simply having omega dots, that tellsme how little h is changing with time
* And we're just going toconstantly increase it right now
* We're not doing any input shaping orsomething like that, just going to ramp it up linearlyuntil you hit the desired speed
* And the desired speed will make little hbe equal to big H, that's what we said
* So the momentum of the wheel relative tothe craft is same as the total momentum of the system
* So the manuever timeyou can figure it out
* Well at the end I have to have this much
* That's my constant rate
* You can quickly compute
* This is going to take a hundred seconds,a thousand seconds depending on how quickly you're rampingup your wheel speed
* Right?This is how long it will take to reach this total amount of momentum
* So we can compute that
* Nominally we had launching like this,we're spinning right and then this wheel is going to be spinningup until its momentum magnitude matches this spacecraft momentum at the time T0,and this is going to line up
* Or is it
* We argued total H vectorhas to be constant, right
* We cannot change the totalmomentum of this two body system with internal torques as Tony was saying
* So h is always the same,it's always pointing up in this drawing
* If the wheel momentum is the same asthe spacecraft initial momentum, and the wheel is spinning about this axis
* Since the total momentum isthe momentum of the spacecraft plus the momentum of the wheel, doesn'tthat mean the spacecraft is despun, like what Nathan was talking about
* And it must be lined up this way
* Now, the way I'm asking that question,obviously the answer is no, right
* The trick is why
* Why
* What are the other attitudes that allowyou to have little h be equal to big H, but I'm not lining up perfectly
* Onzo, what do you think
* >> I can't think of anythingoff the top of my head
* >> Any ideas
* Think of this
* Right now we've beentalking about magnitudes
* What we have to add up really is vectors, the ang momentum vector of the body plusthe ang momentum vector of the wheels
* Yes
* >> Depending on the direction that you
* >> Well no, we are spinning up>> Okay, so you are assuming >> It's locked in, and we're there, right
* But it is dependent onthe direction of these vectors
* Just because little h is equal tothe magnitude of the initial big H doesn't mean the two directionshave to be the same
* And that's essentially, this is ourinitial h that we have, this system
* This is how we launched, wheels werelocked down, then we're speeding it up
* And, at the ends the wheel has a vector magnitude that is the same asthe initial magnitude of the system
* Little h was equal to big H,those are the scalars
* But you could have two vectorsthat have the same magnitude but not be in the same direction
* And then this is actually whatthe spacecraft body must be doing
* So this momentum vector plus this oneadd up to be the same as the original
* We argue we cannotchange initial momentum
* So, by doing this maneuver,we're not guaranteed, we, typically, when spacecraft launched this way,they want it to line up like this
* We talked about the Boeing 501s
* They have geostats that always pointat the earth, skinny ones like this
* You want them to be nice and even
* They're not doing this big wobble
* They call this coning motion
* This is your coning anglethat you can see right here
* So we'd like it to be zero, butit's not typically zero when it happens
* And there's different ways to explain whatis happening, but basically this momentum matching guarantee doesn't enforce thatthose two things actually line up
* Now the analysis of thisgets rather complicated
* Typically we have to, now I will show you some numericalresults to kind of talk about this
* We don't have nice analytic answersto guarantee these behaviors, but we can study this stuff
* I mean there's lots of theoriesbehind this but I'm giving it a spin
* Initially with Tom Blake you're not omega2 but omega 3 for 30 degrees per second
* Have wheel inertia, spacecraft stuff,everything's locked down
* This gives me an initial big H, momentum
* And now I'm going to go ahead and startspinning up that wheel at a constant rate
* So I just took the equations of motionyou saw earlier, last class, and I'm integrating them with these initialconditions and also tracking the attitude
* I'm not just tracking omega but I usedEuler angles and, I forget what I used, something, maybe MRPs
* And at two hundred seconds,I have finished that maneuver
* And you saw then at two hundred seconds,we were close to being lined up like this
* But there was still a little bit ofa wobble left, that happens there
* And so that amount of wobble, that's what'shappening with these amplitudes here
* We can predict that now andsee what's happening
* So we get close but not quite there
* Here I'm taking a thousand seconds,because I'm taking a lot more time
* So it'll take about a minute to run and you can see all these simulations runningand it keeps wobbling and spinning
* But it's a much more gradual process
* So what's going to happen nowin this process is It'll take, obviously takes more time to roll up,but if you look at the final omega two's before it was like plus minus sevendegrees and even these axis were bigger, we will have less of a coningangle at the end of this maneuver
* So when It gets close there we'llwant to take a look at that
* And that's the general trendswe have in these systems
* With a dual spinner we're just spinningit up, we don't want to be too aggressive because you end up with this hugemomentum vector off to the side
* You really have,then you have to do other stuff
* You want to have a coningangle as small as possible so a little patience goes a long way
* Take a little bit longerto spin this thing up and at that point,you have a smaller coning angle
* So it will get there
* We're about halfway there
* The way we get rid of this coning angle,you could use thrusters, in the end if you wantto change the attitude
* You could apply h dot equal to l, applysome thrusters, in the right control
* And change that momentum vector ofthe body, and puff it back into place
* But now we're using fuel,we hate using fuel in space
* There's an elegant method that people havedevised which called the mutation damper
* Anybody heard of a mutation damper before
* No
* What it does is you put basicallya ball in a tube of slush, oil, something highly viscous
* So it creates friction
* So we're losing energy
* All right
* And what we want to have is spinabout omega one in the end and so you make that damper, you line up thattube of slush along either b2 or 3
* So if you're still wobblingwith the conic motion, you're always actually exciting thatslosh, and you're losing energy
* And then people have shown this stuff, at the end it would actually get ridof the coning motion completely
* And that goes there
* We've used this as a 50 turn project inthe past where people have to integrate this and study the spin up andgo through that
* It's a fun project actually
* So take away notes is spin up, just because you match momentum magnitudesdoesn't mean you've matched the vectors
* Teaching those vectors andpatience goes a long way
* To get rid of the coning angle, you wantto put a mutation damper orthogonal
* That'll get rid of the energies ofthese modes here over time, and it'll settle in place
* And there's all kinds of,you can look up mutation dampers
* But here's the results
* So with two hundred secondsyou see where you are
* A thousand seconds,you know, five times longer, we've improved it by a factor of two
* There's really, it's an asintotic thing
* So if you want to get even closer,you might take a long time
* That's where,how patient are you, you know
* A little bit of mutationdamping can go a long way, and get rid of the coning motion
* Other things are, we've seen plots
* I'm just going to go through this,reasonably high-level
* But just to show you, plots have also beenapplied not just for rigid bodies, but also systems of rigid bodies likethese wheels and dual spinners
* The energy here, this is reallythe energy of the spacecraft only, here, not the real energyrelative to the spacecraft
* So not the part with i w over two,big omega squared
* So that's called E star
* The total momentum energy of the systemis as before, the momentum sphere just has to be constant, even with internaltorques acting because they're internal
* They're not changing the totalmomentum of the system
* Which is kind of nice,that's a constraint
* So we can rewrite the energyellipsoid of the spacecraft in terms of these coordinates
* And with a little math this is how you,this is what you come up with
* So because the energy that you have,the momentum about the one axis is due to the wheel and due to the spacecraft, soyou have to pull out the wheel momentum
* And then divide by the right stuffto come up with the energy terms of the spacecraft about the one axis
* The two and three axis look like before
* But this is a sphere, this is still anellipsoid, but it's a shifted ellipsoid
* If your h one two threes are essentiallyyour X, Y, Z, independent coordinates
* If you go look up the classicellipsoidal equation
* If you didn't have minus h this would bea centered ellipsoid that's there, and with the minus h, it actually shiftsthat ellipsoid along the one access
* So as we spin up the wheel thatenergy ellipsoid is going to move
* And that's what you see here
* Initially we launchedthe spacecraft spin is here
* We were spinning purely about b3 inthat numerical problem I showed you
* Then as we spin up the wheel you can see these are the momentumcoordinates that we have to satisfy
* That's the total momentumcoordinates of the spacecraft
* It intersects energy in here
* And the energy ellipsoid starts to shrinkinside and of the spacecraft cause as we spin up the wheel the spacecraft tendsto de-spin and change it's orientation
* Although momentum we'd likeit to go into the wheels
* So there's different critical points
* At one point this ellypsoid interceptsin this nice figure eight motion
* This kind of a separate trick stuffthat we've seen with rigid bodies
* And then when the momentum magnitudematches, this is what you end up with
* Just because you match momentum magnitudesdoesn't guarantee that you've despun the primary body completely
* And this is where a mutation damper wouldhelp get rid of that remaining energy and make that actually attractive andcollapse onto a point
* And that's what would be happening there
* So I'm just kind of showingthis more as a pictorial thing
* So you've seen this
* It's not something that'll be on the exam
* But these plots, these graphicalvisualizations of momentum and energy are quite powerful
* And if you read a lot ofclassical attitude control, you will see these kind of toolsbeing used in different areas.


--- SKIP ---: 06_optional-review-dual-spinner-eom-and-equilibria.en.srt


--- SKIP ---: 06_optional-review-dual-spinner-eom-and-equilibria.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_optional-review-dual-spinner-eom-and-equilibria.en_SENTbySENT.txt
* We're doing a review ofwhat we covered last time
* We had dual spinners
* So with a dual spinner, I had some spacecraft,didn't necessarily have to be symmetric
* But this spacecraft has b1, b2, b3 andyou'd have some panel attached to it
* So now, Nathan
* What do we do with the dual spinner
* What's the set up that we do here
* >> Well you have one section spinningto maintain your angular momentum
* Or, so it's spinning about its axis ofminimum energy, so maximum inertia
* >> Okay.>> And then the other section is not spinning essentially
* >> Is that required
* Do we have to spin about an axisof a minimum of inertia
* Does the second section have to be despun
* >> I guess not
* >> No, in fact that's what I'm goingto show today through an example
* We can stabilize which isthe beauty of dual spinners
* I can make any of the axis stable
* Now if you have energy loss the minimuminertia one you have to kind of be a little bit more careful there'ssome power equations you can find on this stuff
* But conceptually, we know withoutenergy loss this is a stable spin and this is a stable spin
* But a spin about the access ofintermediate act inertia tends to flip around and be unstable, all right
* So, with a dual spinner in thismathematics, we have a fly wheel
* How do we line up, Brett, how do we lineup this fly wheel in our dual spinner
* >> One of the body axis
* >> Yeah, one of the principal ones
* So, if we wanted to have a nominal spinhere, Omega1, that's my equilibrium spin
* I am going to add a wheel, which hasa spin axis, going to call it gs-hat, that's my wheel spin axis,which is the same thing as b1
* Those are lined up
* Good, then we went through,how do we find equations of motion
* We still use H equal to L
* But H is now due to two rigid bodies
* And there's different ways to derive it
* We went through that last time
* There's angular momentum of the spacecraft and the wheel that was I, that was a summed I times omega plus thewheel momentum routed to the spacecraft
* Or you can treat them as two separateones, I showed you that as well and you can combine again
* That's a great problem that I'veused before in the final so make sure you go through that
* It's a good simple exercise
* Later in class, you can do spacecraftwithin variable speed CMGs
* It's the same process butabout 12 pages more algebra
* So this is where you wantto practice the process so you don't get silly sign errors
* Then the rest of it justkind of becomes mechanical
* I'm going to do this,I'm going to do this, and you can use computertools as well to do that
* So practice this
* So we went through this
* Now I labeled this as an equilibriumspin omega 1E, all right
* What does it mean Mandarto be in equilibrium spin
* What does that mean
* [COUGH]>> All Omega dots go to 0
* >> Exactly, any dynamical system, anyflow process or whatever you have, if you have x dot equal to f, a nonlinear thing,for [INAUDIBLE] xe is x dot equal to 0
* And the planar pendulum has oneequilibrium here, one equilibrium here
* Does this have anything to do withstability, finding equilibrius
* No, which just it's a convenient pointabout which we tend to discuss stability
* But stability is a separate conceptfrom finding equilibrius, all right
* So we found the equilibrius andin particularly for the single rigid body there were threeequilibrium spins we discussed earlier
* Spinning about axis of least inertia,maximum inertia, but also intermediate inertia
* Those are equilibrium spins
* If you put it perfectly onthere it would tumble that way
* But if you bump it, if you perturb it, that little delta that we were talkingabout earlier, do you stay close
* What happens to my spin rates
* Right, do I wobble just a little bit andstay there, which is true for this kind of a thing
* But if I throw it this way you can seeit did several gyrations right away, that's an unstable motion, all right
* That's what we're after now
* And so good, sowe identified while the single rigid body could have equilibriumspins about all three axis
* For the duel spinnerthe equilibrium spins we end up using is primarilythe one about the GS axis
* I say primarily,let's look at that equation again
* [SOUND]Here, we argue that if I have a non-0Omega 1 and Omega 2's and 3's are 0, I always have all my dots
* Omega dots are going to be 0like Mandar was saying earlier
* Perfect, butyou can also have Omega E1 be non-0
* Omega E2 is 0
* Which makes this 0 and this 0
* You could pick particular inertias, aparticular E1 at a particular wheel speed, such that this combination with a non-0omega E3 actually goes to 0 as well
* That's also an equilibrium, butit's not one we typically fly, because now all of a sudden youhave a very particular solution
* You have to have exactly this wheel speed
* If you're a little bit fast,or little bit lower, you're out of that equilibrium part
* Whereas this other spin we had if thiswheel speed is supposed to be 10 rpm and I put in 11 rpm it's stillan equilibrium actually and still going to hold the stair
* And so, we did that, here we just addedwhat is the equilibrium plus delta and then dropped tie over terms, right
* And you end up with thesedifferential equations
* That it's stable,if you can see here, again
* If instead of putting in that 10 rpm butI gave it something slightly faster and perturbed, this can hold that speedbecause my angular acceleration about the one axis,the spin axis of the wheel, is just 0
* So you just stay there
* The other two, tends to couple and we have two first order differentialequations that are coupled and the way we solve these was,we differentiate again, substitute in
* So we replaced two coupled differentialequations with one second order decoupled differential equation, and in the end,it's all about these two bracketed terms
* This is your effective stiffness
* X doubled up plus K X,K has to be positive right
* And either we make this positive or this positive orwe make both bracketed terms negative
* Different ways we can write it
* We'll have in that example today, you will see omega hat that'sa non-dimensionalized
* We take our wheel speed, 100 RPM,divide by the spacecraft speed, 2 RPM, so megahat would be 50 in this case
* It's a 50 multiplier factor betweenthe spacecraft spin and the wheel spin
* And then it just breaks down tothese inertias that you need
* And you have to pick spin speeds suchthat both terms are positive, or both terms are negative
* If you put in 0 spin speed we recoverthe case of having a single rigid body
* And that's how we quickly found that thisstiffness is only going to be positive if my inertia is either the maximum inertia, that means we're doing the flat spin wediscussed earlier with the pole hose
* Or b1 is access of least inertia which at least linearly withoutenergy loss is also stable
* So you see in here also mathematicallinearized proof of the stability of the min and max inertia case
* The intermediate one gets positive andnegative, definitely not stable
* And the non-0 one inthe non-dimensionalized terms
* These are the conditions we need.


--- SKIP ---: 01_module-3-introduction.en.srt


--- SKIP ---: 01_module-3-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_module-3-introduction.en_SENTbySENT.txt
* Hi and welcome to the thirdsegment of Spacecraft Kinetics
* Here, we're going to be studying indetail the gravity gradient, torque and forces that happen on a rigid spacecraft
* So with the spacecraft, every part of themass distribution is a different distance away from the center of the Earth
* That means it's experiencinga different gravitational force
* Now, we have to sum itup over a whole body
* So in particular of interest to us is ifyou have the gravity gradient that you've computed, which orientations of a craftcaused the gravity gradient to be zero
* And when we're moving in a rotating frame,which one of these are now relative equilibrious will bedeveloping all of those and then there's some interesting examples
* You can look at whichone of those is stable
* Look at a tall slender object, the lower object weighs more has astronger gravity force than the top part
* So if you disturb the attitude,this would help stabilize it
* We'll begin to study suchconfiguration for full 3D
* This is a very useful topic
* There's many satellites ofgravity being stabilized or there are big thingslike the space station
* Gravity gradients definitelyimpact the attitude motion
* So, this section gives you a goodhandle on how to predict that torque.


--- SKIP ---: 02_1-gravity-gradient-torque-development.en.srt


--- SKIP ---: 02_1-gravity-gradient-torque-development.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_1-gravity-gradient-torque-development.en_SENTbySENT.txt
* Gravity Gradients
* This is kind of the last big thing we're doing in dynamics
* We've looked at single rigid body, we've looked that now, you know, torque free, with a little torque, some homework, you know, a little torque
* They move the dual spinner just in the rigid body
* That's a way to passively stabilize, there's no active feedback control, you have to make sure you designed it with the right spin rate, so the system is stable
* The other way we can passively stabilize the system is with gravity gradients, right
* This is all about, if you look at this pen, this lower part of the pen is closer to the Earth than the upper part of the pen and the gravitational acceleration depends on one over R squared
* So things closer to the center of the Earth weigh more
* Even though it's the same mass here and here, they have a stronger force and that gives you the gradient that acts on it, right
* There's a gradient across the body and how strong the gravity forces are
* So, now we want to look at these gradients on general objects and figure out what are the forces, what are the torques, what are the equilibrium's, and what are the stabilities
* Again, the same classic things that we did with the dual-spinner, getting these torques though is a little bit more interesting
* So, gravity gradients tend to be tall and slender
* This is the typical gravity gradient kind of this configuration
* Why
* Because if this thing is the normal condition, it turns out here the gravity gradients still give you zero torque
* They all act, all the gravity forces act through the center of mass, so there's no torque about the center of mass
* But if I twist it, and this one gets pulled stronger than this one, you get a restoring force, which actually helps stabilize it
* This will end up being another gravity gradient where everything has essentially the same distance from the center of the Earth
* So you'll get the same force, and they all just balance out, there's no torque
* But if I twist this one slightly, this one now weighs more than this one and you get a destabilizing effect, right
* So, as with the dual-spinner, sometimes equilibrium's can be stable and sometimes unstable and we like to find this way this for anti-symmetric
* What we want to derive is for general inertias at the space shuttle
* It has a very particular orientation when it was flying in a gravity gradient orientation
* Why
* Where does that come from
* So, it's the tidal forces
* So, we're going to get to mass and flying blobs again
* So, we're going to say, this is a general object
* It's going to be a rigid body in this case, we're not flying Jello, we're just flying rigid spacecraft
* But we have our typical R, that's the inertial position vector of your little infinitesimal mass element, every bolt, every screw, every panel, right, we're accounting for
* And it's position, inertially, can be written as the position of the center of mass of the spacecraft,plus the bolts position relative to the center mass of the spacecraft, right
* Just what we did earlier
* Now, the gravity acting on this differential element, if you look at Newton's Universal Law of Gravity you've got that G, the mass of the Earth, the mass of the elements, right
* G times N one, N two, but N one is Earth in and N two is DM divided by distance squared
* That would be this distance times a direction and it has to be in the minus R direction
* I probably should have drawn this arrow, this down here, that would have made more sense
* Anyway, next time
* But that's the mathematics, that's just Newton's Gravity Law acting on a DM particle
* Now, we have these classic definitions
* So what we're going to do now is we're going to first look at torques, gravity gradient torques, about the center of mass
* So, I have this point here, I need to get the moment arm crossed with this force
* That's how we did torque, right, position where we applied a force crossed with the force itself, about the moment, about the point C
* So, this would be easy
* That's little R crossed with this DF that we have
* And DF is repeated here
* So, we start to plug it in and substitute stuff
* The first step, we put this in here and R is RC plus little R
* Quickly you'll see while there's an R cross RC, and a little R cross little R
* What does that become
* Zero, right
* And we love zero by now
* Zero is really nice
* Zero is our friend
* So, immediately this term is going to drop out and it won't contribute to the torque
* So, we like that
* We end up with RC, we can take outside the integral, as we argued earlier and, you know, in blobs and space
* For the system every point in that system has the same center of mass location
* So it's not impacted by this body integral, But that leaves you with this
* Now, R does depend, right
* R is RC plus little R, so it's got little r imbedded
* You can't move that R outside
* This is where you end up with
* Now, this is where all up to now
* This is rigorous, and no approximation
* What we're going to do now is this is R cubed
* That's where all the complications come in and we're going to do a first order approximation
* R cubed is bloody close to RC cubed, right
* 7,000 kilometers from the center of the Earth, and then we're looking at a half a meter distance
* That's really not going to change at 7,000 kilometers too much, right
* As can be very, very close, which motivates, let's take a first order approximation of this and you get a really good analytical answer to these gravity gradient torques
* So, we have to do a linearization, essentially and I'm showing here how you can take this, plug in this stuff
* I'm doing a binomial expansion, factor things out, and in the end you're dropping off, you have to do this linearization of this term and you end up with this
* This is your zeroth order term, one over RC cube, which kind of makes sense, minus this times this
* This is your first order term, the first order here is in terms of R, little R, right
* You may have done Taylor Series Expansion in terms of X's and Y's and Z's
* I expect you not to do a Taylor Series Expansion terms of vectorial quantities
* So, I'm going to do this once with you here
* But this is definitely a skill on an exam I would expect you to be able to do
* Okay
* Let me get my notes up
* Quickly
* Yeah, that will work
* So, what we're trying to do is, we have this one term
* The thing I'm trying to expand about is I'm treating little R as the small quantity, right
* RC is the big quantity, that's 7,000 kilometers to your left
* But then, I only have little wiggles of plus\minus a fraction of a meter across the spacecraft,right
* So little R is a small thing, and the function I'm trying to approximate is one over R cubed, which is the same thing as R to the minus third
* R is just a scalar
* R is always defined that way
* So, now, if you look at a Taylor Series Expansion, if you have F of X, and we're doing an expansion about XR, just X is a scalar in this case, you would say Taylor says, 'Okay, that is the F at the reference point, plus one over one, vectorial times, the partial of F with respect to this state'
* And then this partial is evaluated at the reference times Delta X
* And Delta X would simply be X minus XR, right
* And then you can go second order and higher
* We're not going to go second order here, right
* That's the classic Taylor Series Expansion
* Let's apply this now here, where this function depends on a vector not a scalar
* Now, the function itself is a scalar function that makes life a little bit easier
* So, we have to figure out these terms
* So, applying this here we're going to say F of R is approximated as F at the reference which is F, at the reference is the center of mass, that means R is equal to zero
* Plus, one over one factorial, which is just one over one which is one, times the partial of F with respect to R evaluated at the reference, that's R is equal to zero
* That's the center of mass location
* Everything is about the center of mass now times instead of this is the vector dot product with the small quantity, which in this case is just R
* R is the small quantity
* So, we're doing the expansion about R is equal to zero, essentially
* This part, if R is equal to zero then R magnitude is equal to RC magnitude, and that's just going to be RC to the minus third, right
* That one's trivial
* Let's look at this
* This part we have to figure out first is partial derivative of it
* So, if F is R to the minus, third the partial of F with respect to little R, chain rule, you know, that's going to be minus three times R to the minus fourth times the partial of the radius with respect to this little R vector
* So, good
* We get there
* Now, we need to find this quantity
* So, to do that relationship I'm just going to go back to this stuff
* R squared is really this vector dotted with itself, which is the same thing as RC plus little R dotted with RC plus little R, right
* The magnitude squared of a vector is just a dot product of the vector itself, and the vector is written in terms of a song
* So, we've got that, good
* Now, I have the scalars here, this is a scalar at the end, but it's a scalar in terms of these vectorial quantities and some vector math
* Now, taking the derivative of this these, these partials, hopefully you remember how to take partial derivatives, on the left hand side
* I'm just going to get two times R, times the partial of R with respect to little R
* On the right hand side, if I carry this out, I need to take the partial derivative of, let's see
* Here you're going to have RC dotted with RC, plus two times RC dotted with an R, plus little R dotted with itself
* This part doesn't depend on little R, so that partial is going to drop out
* Here two RC times R, the partial of a vector with a with respect to itself, which is going to give you identity operator
* So, like the partial of X with respect to X just gives you one, right
* So, in this case you can end up with two times RC from this partial and then here this dotted with itself
* Like we talked about earlier, you know, when we had R transpose
* R take the time derivative, you get to two times R transposed R dot or taking partial derivatives
* This just gives you two times the R vector, in that case
* Yup
* So, if you're fuzzy on this, practice with this, approve these identities to do so, it just takes one or two steps
* Now, I'm looking for this partial, so I can..
* I'm just going to rewrite this
* These twos all cancel
* So the partial of R with respect to little R is just one over R times RC plus little R
* All right
* That's what we have
* Now, we can plug this back into here and we'll see what we're going to get
* We have minus three R to the four, minus fourth is another one, so R to the minus fifth, times RC plus little R
* You go, okay, getting close
* Now, we have to evaluate this sensitivity here at the reference where R is equal to zero
* So, if I compute that partial of this with respect to little R at R is equal to zero, then this R just becomes RC, and this little R just becomes zero
* And what you will end up with is minus three over RC to the fifth, times RC vector, essentially
* And now, we're just about there
* So, the first order expansion of this function is simply RC to the minus third, plus this term dotted with the little R vector
* And if I go look at my final result here, that's exactly what I had, one over RC to the third, minus three RC over RC to the fifth because three times two is five, three plus two is five, dotted with that first order expansion
* Right
* So, we've gone through this reasonably quickly
* This is something it's not going to sink in unless you do it yourself, and I think in one of the hallmarks, I'm asking you to do this
* Derive this, make sure you can do these different binomial expansions and then linearize this or just start from front, which I showed you with that, you know, make sure you know how to take partials of, you know, typical gradient
* This is your sophomore level calculus or freshman level calculus, whenever you took Calc II that kind of stuff like, right
* Partials of scales with respect to vectors, just gradients that we have to get
* That's all we have to compute because now we can plug this
* Now we're making this assumption that this R, this spacecraft is small compared to the orbit
* This is not the Star Wars, Death Star orbiting Endor or something
* There this approximation wouldn't hold
* For current man-made object it's a pretty good approximation
* So, if you plug that in, this is where we had that R over this other stuff, this is what that stuff combines
* I've taken some of the constants outside
* You carry out this multiplication, you will see the body integral of RDM, which we know from the center of mass definition goes to zero
* We still have zero one term less to worry about and that leaves you with this part
* Here, this one doesn't quite look convenient, but in essence you can see it's mass times distance squared
* At this point, hopefully, your spidey sense is tingling and this looks like something that could be related to inertia
* And so, we have to re-manipulate these equations, again, to get to that form
* So, if you do that we have lots of different vector identities, one of them is double cross product and if I solve for minus this term, you just bring this over, this over to the other side, and then you got it, you can relate that, this is what's inside that integral term, precisely
* So, A is equal to little R, C is equal to RC, B is equal to little R
* You apply the vector identity, you end up with this stuff, right
* So, doing that though, now you can see immediately we've got little R, till D, minus little R till the little R till D, that will go back into our body integral
* Hopefully, you already at this part recognize that's going to be the inertia term
* We have something else we need to identify
* So we plug that in
* You get to here and, so the only assumption, so far, still is that little R is small compared to RC, spacecraft is small compared to the radius of the orbit
* That first term, you can factor out RC to the left, which is done already, you can factor in RC to the right
* Because it doesn't matter on the body integral, that means you move the DM inside, and then you end up with the classic definition
* The other one is RC here, you can take that outside, and then you just have the body integral of little R dotted with itself, which is just R squared, which we can do
* So this term is what we can recognize as the inertia tensor, right
* That appears all these different places
* This one here is actually a polar moment of inertia
* But here we don't care about it, because the RC's you factored out, give you an RC crossed RC, which of course, again, goes to zero, which we like, right
* So that second term vanishes completely with this mathematics and now you end up with, I use in this inertia tensor definition
* We end up with this expression of, this is basically the linear, you know, this is the first order
* I shouldn't say linearized, we'll do that differently later
* This is the first order approximation of the gravity gradient torque, right
* When we expanded one over R cubed, we only kept first order term
* If you want higher order terms, you'd have to include those in expansions, and then it would be this plus some other stuff
* That would happen
* Now, when we write this, have I specified a particular coordinate frame that you have to express everything in
* Horace?
* No
* No, it's just vectors, vectors, even the tensor stuff, right
* We know when we evaluate this we have to pick probably somebody fixed frame
* That's how we do it mathematically
* But generally we can write the tensor just as a coordinate frame independent way
* If you have it in the B frame, and you need in the C frame, we know we have to pre- and post- multiply with the DCM to do a coordinate transformation, right
* But we treat the inertia tensor just like a body, a position vector or velocity vector
* So, we can write them in a very agnostic ways, which is nice
* It just means when you evaluate this make sure you have your orbit in the same frame as your inertial tensor
* What coordinate system do we typically use for orbits
* Mandar
* Inertial
* You could do inertial, right
* You might even use an orbit frame, we'll see later on, a rotating orbit frame, right
* You don't typically use a body frame
* That's probably the least you scream for an orbit because then it couples everything in crazy ways, right
* We want something different
* But the inertia tensor, we tend to express that one in the body frame
* So, this is just an equation where, right up front, I can tell that you probably are going to be given this information, in real life, using different frames, and that's fine
* So, implied in here is maybe a DCM rotation that you have to do
* You know, the tensor of the vectors are mapped from one frame to another, that's all
* So, this is the most compact way I can write it
* But again, implied might be some important transformation when you actually evaluate it
* So, looking at this, let's just jump ahead quickly
* Can anybody tell me for what type of inertia tensor will LG go to zero
* T-Bo
* It's diagonal, enough, probably not, just a identity scale
* Yes, diagonals running off
* If you have distinct three different inertias, this is not going to go to zero, because you actually scaled this vector in a way that it's no longer co-linear with itself, right
* But if it's an identity times a scalar, so what kind of shapes give us those kinds of tensors
* Sphere
* Sphere and
* Cubed
* Cube, right
* Keep that because we'll see that result again in other mathematics as well
* So, here just in a vectorial form you can see with the cross-product
* If it's a cross-product times itself, whatever shape makes that happen, that would make the gravity gradient torques, actually, to be zeroregardless of attitude.


--- SKIP ---: 03_1-1-gravity-gradient-torque-in-body-frame.en.srt


--- SKIP ---: 03_1-1-gravity-gradient-torque-in-body-frame.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_1-1-gravity-gradient-torque-in-body-frame.en_SENTbySENT.txt
* So good
* This is the vector form,the coordinate independent form
* Let's now actually applysome particular frames and there's different answersthat we get out of this
* It's always the same answer,but it's different expressions, different formulationsof that same answer
* So if I'm using an orbit frame, andhere I've used an aircraft-like frame, where if an airplane is flying you haveyour nose pointing in the one direction, your wings may be to the left or right
* I have yaw axis up,aircraft probably would have had it down
* But with orbits we tendto have our third axis or one of the axis up inthe radial direction
* So, 01 is my long track,02 is my cross track orbit normal, and 03 is my orbit radius direction vector
* They're all unit direction vectors
* That means Rc by definition is alwaysgoing to be 7,000 kilometers in that direction, all right
* And that direction is defined here by 03
* So, in the O frame, your position vectoron a circular orbit in particular, is just going to be constant
* It's just going to be 0, 0, Rc,all right, which is kind of nice
* So we can write that
* But we've seen the spacecraft part,the inertia tensor, we tend to write in the body frame
* So while the orbit positions couldbe written in very simple manners, we tend to need it in the body frame
* And now, so if this is your positionvector pointing up to your satellite, and you've got a coordinate frame on yoursatellite, depending on your orientation, you can have an infinity of differentvariations, and most generally, you're going to have to account forthree different vector components, for your Rc inertial position vector, always
* So, Rc 1, 2, 3, nothing but B frame components of my position vector,different ways to look at it
* So we have that
* Now we plug this in,I added these this morning
* Everything's in the body framejust to make it explicit
* So we had Rc, cross I Rc
* I've picked a principal coordinateframe here just to make, I can always do that fora rigid body, all right
* It exists, it makes youranalysis a little bit easier
* Now you can do this math,this multiplication is what talking about
* You get a little bit of scaling,then the cross product, and this is going to be your answer
* So this box, the answer's the sameas the earlier one after it's expressed everything nowin body frame components
* But we can again look atmore conditions now and try to figure out when will the gravitygradient torque go to zero
* Why do I care about it going to zero
* For equilibrious thatwe're about to study, that's thing if you have these conditionsand this is the one disturbance you're modeling, if that disturbance acts on it,you won't be at an equilibrious
* This is like gravity gradientswe talked about last time
* This would be a gravitygradient equilibria
* If you disturb it, then, this one weigh more than thispoint makes it restore itself
* So what orientations orwhat shapes give us that
* And as you guys mentioned earlier,one way to make these things go to zero is simply these differencesall have to vanish
* And that means, as you guys alreadyidentified, is that all the principal inertias must be equal which is eithera sphere or a cube, those kinds of shapes
* So, there are particular shapes thatcan make your attitude go to 0
* That's not or soyour gravity gradient torque go to 0
* And that's important, there was asatellite that we built here called Dandy
* Anybody know that one
* Heard about it a little bit, right
* It was a sphere for reason like that sowe could do this stuff, and didn't have any other gravity gradienttorques disturbing because I really wanted to measure atmospheric force effects, and I didn't need all the disturbancesacting on it very much
* So that was really leading to thisdecision, all right, that gave us zero gravity gradient torques,also how the atmospheric drag effects so you didn't have weird panels sticking out,there were other reasons too
* So the other way we can make it go tozero is we can look at these components
* Are there particular orientations
* Remember, Rc one and two and three, the position vector alwayspoints to straight outward but then depending on my attitude, I willhave different Rc 1, 2, 3 components
* Are there different orientations thatwill force this LG to go to zero
* And the answer I'm showing youis Rc is equal to Rc times bi
* So, is it David
* What does that mean for your orientation,if Rc is equal to Rc bi hat
* >> Does it mean you're aligning your bodyaxis with the O frame that you created
* >> Be more specific,what part of the O frame
* >> The radius vector
* >> Right, because if you say you're addinga body axis relative to the O frame- >> If they're principal inertia axis
* >> Then that implies allmy principal inertia axis have to line up with the O frame,and that's not true
* So your second argument is correct, and it's what we really care about isthe Rc part here that we have, right
* That's in the O3 direction here, it'sbasically the orbit to radium to axis
* And so that what it says is yourposition vector on that direction has to be a principal axis of your body
* And that could be B1, B2, or B3
* But it's just lockingone of your R axis in
* I'm going to use these to havethree distinct axis, right
* So we have, this is a principal axis,this is a principal axis, and this is a principal axis
* It just says that if I line up oneof those things as a principal axis
* Let's do the simple example, right
* Here I have my skinny axisin the vertical direction
* That satisfies that condition
* If I rotate about that axis, this is still in equilibrium, becauseof the symmetry of the stuff, right
* So you can see,that orientation doesn't matter
* It just matters that one ofthe principal axes is lined up
* This is another one that we identified, where right now the gravity gradientsare even and they cancelled each other
* But I can rotate about thatabout the gravity direction
* And I still have a zero gravitygradient torque, right
* That's what this condition means
* So it only locks one of my body axis to bealigned with the orbit direction vector
* That's it
* But it still leaves an infinity oforientations because you can rotate about that local vertical axis
* Okay, good, yes
* >> [INAUDIBLE] >> Thinking more like J2 and that stuff
* >> [INAUDIBLE]>> They're pretty small
* J2 is about a thousand timessmaller than the regular stuff
* So if you care about those accuracies, youcould do that and you'd have to account for that then in these developments,that would be actual terms
* I don't typically see those becausethis is already a pretty small torque
* Many simulations don't even include this,but if you do include it, great, and J2 is much, much smaller
* If you're going around asteroids,that's a whole different problem
* If you're looking atan asteroid binary system, I know some of you this yearmight be looking at those
* That's a full on thing
* Then you do these expansionslike I've done but on two bodies not just treating the Earthas a big point mass, as a big thing
* But for Earth, it is very sphericalas far as that goes, right
* But yep, no, great question
* So, this would be modified
* The process is the same, but you mighthave extra conditions to line it up with the local area, and what does that mean?


--- SKIP ---: 04_1-2-gravity-gradient-net-spacecraft-force.en.srt


--- SKIP ---: 04_1-2-gravity-gradient-net-spacecraft-force.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_1-2-gravity-gradient-net-spacecraft-force.en_SENTbySENT.txt
* Now we have ways to get the torque to be zero either the shape can make it go to zero or for any shape particular orientations if we locked up one of our principal axis and, you know, be, make it equal with the position vector
* So what we've just identified is if you look at this equation, if you have a circular orbit at 7,000 kilometers or a circular orbit at 42,000 kilometers Leo versus Geo, you're going to get different gravity gradient torques
* Kind of makes sense, right
* The further out you go the weaker gravity gets, that we could effect the gravity gradients becomes as well
* So as you change your orbits, it actually affects your attitude, because you get different torques acting on it
* So is the inverse true
* That's what we want to study here
* So if you take your spacecraft and it's pointing at the sun and you decide to rotate it with reaction wheels and point now at the Earth, you've taken all this finite mass and moved this distribution around
* Since orbits affect attitude, do attitudes affect orbits
* If they have different orientations, do I change my orbit type
* No
* The answer is yes
* You do
* The more important question is do you care
* How big is that term
* So we're going to step through this math a little bit quicker than what I did with the other stuff, but it's the same kind of principles, but you'll see it would have to go to second order expansions that are set up first because the first order expansions actually vanish and then you get this expression and I'm going to rewrite it
* So now, you get the gravity force much more precisely assuming it's not just a point mass, but it's a finite shape
* And now, orientation couples into it
* Where is your mass
* Do you have more mass lined up close to the Earth versus all the mass lined, you know, lined up evenly away from the earth
* That means different gravitational accelerations
* You can have different orbits out of it
* So let's go through the same math again
* It's the same blob, the same force, but instead of doing a body integral of R across the four step, which gave us torques about center of mass we just want the net force acting on this body
* So we just treat the body in a roll of all the little D.N
* forces that we're going to have
* So we just dropped R cross parts
* So several terms you'll see will be very similar
* That's why I'm kind of going through this quicker
* Now we have to do in the end, you plug in the stuff like before
* It's very, very similar
* Just you don't have that R cross term and then we have to do an expansion of one over R cubed, because that's RC plus little R, but I'm keeping the first order term, which we had before
* These two's would cancel, in that case
* But there's also a second order term here and here, those end up being critical because, again, first order vanishes
* You plug this in, manipulate
* Similar arguments as before, we can see these body integrals here, center of mass makes that vanish, center of mass will make this vanish
* Then we have other terms
* This is one we just expanded earlier with vector cross-product identities
* That ended up being the inertia tensor plus something
* Relative, parallel to RC which cancel because we cross with RC, but here we're not crossing with stuff so it's going to be a little bit different and that's going to be total mass
* This just screams for more vector identities just because, and that's just going to be the R squared
* It will give us a polar moment of inertia of the stuff
* So we apply, again, the same identity we used earlier, plug this stuff in, right
* It's the same process and you start to identify, ah, look this with the minus sign that becomes the inertia tensor
* This too, we can relate to inertia tensors and these R squares bodying with R squares are actually polar moments of inertia and that's defined here
* And this is something I'm just giving you
* You can look this up into a classic statics mechanics book, but the polar moment is the same thing as one half of the trace of the stuff
* You can actually prove this to yourself pretty quickly
* If you look at the I matrix, the diagonals are all X square plus Y square
* Y square plus Z square and X square plus Z square
* You start adding them up
* You basically get two times X square Y square C square and X square Y square, C square, is always little R squared
* So that's where you've just proven it, right
* That's the same thing
* So I can go from the inertia tensor, get the trace and do that half
* I'm also going to start factoring out more RC's here
* If I divide both by RC magnitude, I get just these unit direction vectors
* It will be a nice convenient form, but I have to factor out an extra RC squared over there
* So it's the same math steps
* It's just a lot of extra details and let's see what we get
* We use inertia tensor definition and in the end this is your more precise gravity force for an orbit
* All right
* Where if you look at this, and this is, in orbits class you tend to deal with gravity accelerations
* R dot is equal to minus as you ever are cube times R
* That was the classic orbit equation here and getting it to in terms of force everything is multiplied times M but it's basically the same
* And so you got minus MU over RC cubed times RC, right, for that one here
* That's the point mass approximation
* That's what 50\50 was all about, that orbits class
* Then, first order terms dropped and all we have left afterwards are all the second order terms, which every one of them we're able to write somehow is a function of the inertia tensor, which is kind of cool and I factor things out
* So, have this unit direction vectors and had extra RC squares that I had to factor out
* So now, this is the formulation
* So you can see, as you change your attitude, all of a sudden you will have different results and you have a small impact on your orbit
* So if you fly, flying this way and then you go this way, you will have a slightly different orbit
* But for Earth, man-made spacecraft on Earth
* This is a really, really small effect
* If you start flying around small asteroids and boulders, this may not be a small effect
* Right
* And this is stuff you have to actually account for when you do these extra expansions
* The classic point mass model is not going to work necessarily
* So in this class we're not doing asteroids, so we're going to look at this now quickly and do some dimensional analysis
* Inertia's are all mass of the spacecraft times distance squared for every element
* Kind of the large, good opera estimate just make it a sphere
* Then all the radii, all the mass, is as far out as you can do it
* We don't build spacecraft that way, but that would be kind of an upper bound
* So it's mass times the radius of the spacecraft squared divided by mass times the radius of the orbit squared, the masses cancel
* So only need to look at the ratios of spacecraft squared to radius of orbit squared
* Orbits, let's make Leo easy 7,000 kilometers squared at 7 million kilometers that's 10, 49 times 10 to the 12
* So it's about 10 to the 13-ish order of meters
* Man-made objects
* Around one-ish average radius
* If look at the mass distribution and everything
* So this term is one, plus something, one over 10 to the 13
* That's pretty small
* You're going to have to account for, you know, Lawrence forces, drag forces, origin pressure forces, out gassing forces probably of the material
* There's all these other disturbances that are way bigger than 10 to the minus 13
* You know, J2 that you were talking about does 10 to the minus three J four and five and those six is, okay, maybe, there are three, two, three orders of magnitude smaller again
* Right?
* But still about that level, we're nowhere near 10 to the minus 13
* So for Earth Application that's why typically you don't see this, but it is there and with these tools you can develop it
* But again, now we're getting into pretty cool missions too around other small bodies, trying to get around boulders and flying stuff and your crafts might be, you know, this might be much more of a significant effect
* Asteroids still tend to be basically lumps of stuff
* We don't build spacecraft as cannonballs or lumps of stuff
* This spacecraft has lots of empty space, right
* So the inertia ratios are still going to be big, it might still be quite small, but it might not be negligible either
* So it's kind of a cool result people, good prelim questions, you know
* Does your attitude affect your orbit
* And the answer is yes
* Always, Spencer?
* Still a little confused as to how like small asteroid, like uneven bodies like that, of the gravity gradient work as more of a factor
* Because isn't it
* Use a metrical force
* Force
* It's proportionately a bigger influence, because with this big square bracketed term as basically normalized to point mass approximation of that object is just one
* And then how much is this going to be
* So you just have to look at, well what's my inertia
* And if we're still about size one, meter-ish
* You know size spacecraft and this isn't 7 million meters, but now all of a sudden 50 meters, because you're flying around the five meter boulder, you what I mean
* It's still going to be small, but not 10 to the minus 13 small, right
* And then, there's bigger binary systems and other kind of stuff people are studying
* It definitely makes an effect
* There's some binary asteroid systems, where you have, you know, Shear's done a lot of work on this stuff
* He's got a whole book on this
* But then, it affects it more
* That makes sense
* So good
* So we've covered now how to derive gravity gradients, we need that one approximation that the spacecraft is small compared to the orbit
* We got the nice vectorial way to write it and in some different coordinate frame versions
* This is the force version
* This is more FY, but it's just so you can see the answer.


--- SKIP ---: 05_2-gravity-gradient-relative-equilibria-orientations.en.srt


--- SKIP ---: 05_2-gravity-gradient-relative-equilibria-orientations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_2-gravity-gradient-relative-equilibria-orientations.en_SENTbySENT.txt
* Next thing you want to do is now that wehave a model of gravity gradient torque, we want to talk about equilibrium
* And in this application, I havethe word relative equilibrium state
* We talked about equilibria simply meaning,if we have x dot equal to f as a dynamical system, equilibrium means at whatstates x is x dot going to be zero
* All right, that's it
* And then, those are fixed points inyour states phase or flows phase, whatever you might want to call it
* A relative equilibriummeans we're not looking for stuff where the spacecraft rotationrelative to the inertial is constant
* But actually,it's relative to a rotating frame
* And what you typically have in orbits is, we care about the motion of a spacecraftas seen by a rotating orbit frame
* We have a frame that line,one axis lines up with orbit radial, the old frame is an old radial, alright
* One is the long track,one is a cross track stuff
* That's a rotating orbit frame
* And we often care, if I'm flying to space station like that,always pointing at the Earth, I'm actually interested in the motion of the spacestation, relative to this orbit frame
* How does gravity, torques andeverything and gyroscopics effect that
* So we're going to look atrelative equilibrias here
* The equations of motion is the same
* It's a rigid body, we derived itwith b relative to n, still, right
* And then this is the gravity gradienttorque which we just derive
* We can now plug that in in differentforms and do stuff with it
* And omega BN is the angular motion of B relative to the orbit frameplus the orbit frame motion
* In this analysis,we're assuming a circular orbit, which means omega o relativeto n is simply a constant, it's your mean orbit rate about your crossaxis or orbit normal axis momentum axis
* Whatever you call it, right
* So that's just a constantorbit rate that we have
* We're rotating at somany degrees per second
* That's a nominal rotating frame motion,but what we also have with equilibria is, we're looking for conditions whereomega B relative to O go to zero
* That means, if I have myrotating frame that I'm flying, how can I put my craft in here,such that gyroscopics and torques, and everything don't causeany change in omega BO
* So we want omega BO timederivatives to be zero as well
* And omega BO the motion should be zero
* This must not have a battery
* Okay
* So that's the overarching goal, right
* So we have the orbit frame o1, 2, and 3
* And now, we have b1, 2, and 3 drawn in
* And right now, it's in a generalorientations for what attitudes
* So we have two parts now, forwhat attitudes will my torque go to zero
* That's one thing that can causenon-zero accelerations here
* And the other question is, forwhat attitude will my gyroscopic, relative to the orbit frame,that term has to vanish as well
* And so, we're going to lookat both of them individually
* For the gravity gradient torque to be 0,we said we could have certain shapes, we could make it a cube,we could make it a sphere
* Then, as always the case,as kind of the trivial case
* So let's put that one aside
* Now we're going to look at the moregeneral inertia tensor case, and say hey, with kind of a stage craft,how do I orient it
* And what we found was, as long as youline up one of your three principle axes with the orbit radius,that whole torque vector goes to zero
* All right
* So if I do that without loss in generalityhere, I'm going to line up B3 with O3
* It's just easier to line up
* It could be really be any of them
* And if that's lined up, if you lookat the picture, what happened, well, actually, that comes in the next step
* What happens then is, in the O frame,my inertia tensor of the space craft, and as seen by general orbit frame,depending how the attitude, that's going to be a generalthree by three matrix
* The orbit frame typically isn'ta principal frame of your spacecraft
* But because of this condition,we know that O3 must be a principle frame
* That means the off diagonal partswith the third axis have to all be 0
* But I still don't know whatthe rest of the spacecraft does
* This means the three axis has toline up with my gravity vector but there is an infinity of rotations, right,that you could rotate about that vector
* And if you have your orbit frame,if it's tilted like this, 45 degrees, you would have a generaltwo by two inertia tensor
* It's only if it's lined up,like you were talking about, David, perfectly with the orbit frame,then, it would be perfectly diagonal
* So, right now, this doesn't require that
* So we get this block diagonal form
* And this is now how they illustrated that,O3 is equal to B3, but there's B1 and B2
* Just because my third axis islined up with gravity my one and two axes, I don't know yetwhat they have to do, right
* So, this condition simply makes mygravity gradient torque go to 0
* So now, we also want to look at this term, because that can causeangular accelerations
* So if we make a B/0 by definition of beinga relative equilibria, we want to stay there, we don't want to tumble andmove relative to this orbit frame
* The orbit motion itself is this constant,O times O2
* All these accelerations have tobe 0 to stay at such a condition
* Now, we can plug theseconditions into here
* Omega B/N is Omega B/O plus Omega O/N
* Classic stuff that you've done
* And so, we can combine thisat the equilibrium condition, plug it into that gyroscopic term, andif you do this, in one of your homeworks, you actually go through this mathyourself, it goes really quickly
* It's really this utility matrixtimes the diagonal inertia, times the 3-by-1, not very hard
* You do this because this one is only 0 n0 in the O frame, a lot of things vanish
* And in the end,you end up with this vector
* That's your gyroscopic accelerationthat you get from a body that had zero initial conditions
* So, in all cases here,the spacecraft is not twisting and gyrating relative to the orbit frame
* We're enforcing that at the equilibriumwe expect this to be zero
* But depending on the attitude you'rekicking in, the gyroscopics might give you additional accelerations, whichmeans it's not an equilibrium, right
* You would now have a non-zero dots,omega dots, in the system, so how can we make this to zero
* One option is>> [COUGH] >> could you make N go zero
* Matt, what do you think
* What does N mean again
* >> The average rate
* >> Right
* If N goes to zero, where's yourspacecraft relative to the earth
* >> Going straight in
* >> No
* As you get closer to the earth,what happens to that
* Yeah, it goes faster and faster
* So at the center,you've probably reached an infinite speed
* Slight challenges with that
* Except for Hollywood, Hollywood[INAUDIBLE] movies [INAUDIBLE] travel
* Yeah that's not [INAUDIBLE]Hollywood makes it work, but for the rest of us not so lucky
* If your n goes to 0, the further out your orbits are,the slower your orbital rates go
* And to make it go to 0 youhave to be infinitely far out
* So you're really not in orbit anymore
* So making this 0 is reallynot a practical thing
* The other thing we can do is,we can say this term can be 0
* Now, what does that mean
* I want to go back to this blockdiagonal form that we had
* Keep in mind, this is the inertia tensor, we typically always writeit in the body frame
* The key thing to realize in this and the following analysis is, this is alwayswritten relative to the orbit frame
* That means,I3 is the inertia about the O3 part
* I1 is the spacecraft inertia aboutthe O1 axis, and I22's about the O2
* And, if you have certain angles, you mayhave some cross coupling inertia, right
* Now, we're making these terms go to 0
* What does that mean now, David
* About, to be at a gravitygradient relatively equilibria
* What orientation must we have
* >> That the body framesalign with the other frame
* >> Yep
* That means, basically mathematically,the result we get
* This stuff only happens if the inertiatends to description, as seen by that rotating orbit frame, and it'sa constantly rotating orbit frame here
* It has to be a diagonal form,that's the only way this is going to work
* So your earlier statement is right
* For an equilibria, we do need all threeprincipal axes to actually line up
* There's still finite permutations,you could have B1 line up with +03, -03, +02, -02, +01, -01, right
* And then different permutations tokeep it as a right handed frame
* But there's more than just one answer
* That's the same as saying,look at the craft, it could be this way, it could be this way
* If I'm flying this way,I could flip it this way
* I just can't have it flyat a skewed angle, right
* The axes have to line up with a longtrack, both for vertical and cross track
* That's what this condition means,and that's what we found here
* So that's the result,this is not the requirement for gravity grading torque to be zero
* This is the requirement forthese relative equilibria
* Yes sir
* >> So congruent that [INAUDIBLE] cylindrical spacecraft [INAUDIBLE]
* >> Yes.You could
* You could.Very good
* All right
* So now,the different combinations of this, if you have a cylindrical spacecraft,you line up one of these axes, the other two axes, there's an ambiguityon what is the principle is saying
* So you could make it cylindrical,if your mission allows it, and you want to exploit gravity gradients,that's a great thing
* Often, structures people have issueswith solar panels and sizes, and they don't want to make it cylindrical anddarn structures people
* But, from the dynamics point of view,yes, that would actually make it easier
* But it also actually loses any,you will look later, we'll see three axiscontrols that happens
* If you make it cylindrical, a downside is, if I have a three dimensional shape,I can look at it
* And if anything is perturbed aroundany of the axes, it will be stable
* That means these angulardepartures don't just grow
* If I given a little bit of twistthere's something gyroscopically bringing that again
* If you make it a cylinder,we will lose that
* because then all of a sudden, because of the symmetry there never wouldbe a restoring force about that access.


--- SKIP ---: 06_3-gravity-gradient-linear-stability-about-equilibria.en.srt


--- SKIP ---: 06_3-gravity-gradient-linear-stability-about-equilibria.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_3-gravity-gradient-linear-stability-about-equilibria.en_SENTbySENT.txt
* So now we found equilibrius, the next step is stability about this equilibrius
* And like with the dual-spinner, at this stage, we're just going to use linear stability analysis
* So, we're going to come up with these equations, linearize and make small, and small departure approximations
* And we're doing it in one way and in your homework you actually duplicate this, but do it with MRPs instead of all our angles basically
* But it falls very much the same steps, so that's why I'm going through this part a little bit quicker
* This is much more about the high level thing, make sure the concepts make sense
* The mathematical details, you will do it in your homework anyway
* That's where you do that
* So, now we're looking at how can we use gravity gradients
* These are just equilibrius, right
* And we know that this is an equilibria, and this is an equilibria
* But this equilibria is stable cause, if you have a small departure, it's visually very easy to see
* This part weighs more than this one, so it can have a restoring force that gets you back to the equilibrium point, or at least towards it
* It won't be asymptotic, it'll just oscillate
* But this is also an equilibria
* And if you perturb it, you're going to be driven away from that equilibria towards the other one
* And so, that local motion is not going to stay linearly stable
* So, how can we identify this for all three axes, and make this completely stable if we wish
* So, we used the same O frame again, RC, everything is there
* This is from different notes for some- instead of having N, I have a big Omega
* That's in the orbit rate but it's the same thing, just different label
* So, that's your orbital speed that you would have, it's basically nu over your rate, circular orbit radius cubed
* That gives you, in radians per second, your orbital speed
* And we're going to now look at, we're assuming the principle chorded frame
* That's a key assumption, so inertia tensor in the body frame is there
* And the motion, now we do allow non-zero angular motion, right
* If this is my equilibrium, I want to bump it and see what happens with small motions
* So now I have to account for some Omega BO's in this development, right
* That's how you get your equations of motion about this state
* So, how do we describe that here
* I'm going to use all the angles three, two, one, yard pitch roll sequence
* And you've seen this differential equations before
* This is how I can relate my Omega BO
* But these angles now are B body relative to orbit
* They're not body relative to inertial
* If we needed body relative to inertial, you know how to do that, right
* We know how to add, three, two, one, all of our angles
* You can map into the DCMs
* That's one approach, right
* Then multiply amount and pull them out again, if you have to
* So, this is what's going to go into here
* This is the constant orbit rate, but it's about 02, not about a body axis
* So, I need the DCM to go from the orbit to the body frame, and I'm using the same three, two, one angles
* So, that's this classic one you've derived, this is the one we've seen in the first part of the class
* So, if I need to map my orbit motion, which is basically zero, big Omega, zero, that's the orbit rate in the orbit frame into a vector, into the body frame, you multiply times here
* So, this is going to pull out the second column at zero, big Omega, zero times a three by three gives you that big Omega, times the second column
* That's what you end up with
* If you want to choose different attitude parameterizations you can do it
* It's just going to have MRPs here, or CERP, or quaternions, or whatever you want to use
* You can write this motion using whatever angles, you guys are very good now with kinematics
* So, good
* Now we have, we'll make a B..
* Both Omegas are now written in the B frame, which is nice
* So, we can add them up
* I add up both matrix representations of it, and so this is the math that you get
* So you can see the yaw pitch and roll rates, again, are the motions of the body relative to the orbit frame, and the big Omega accounts for that the frame itself is in a constant rotational state, right
* So, all these terms add up there
* But that's now my Omega BN parameterized this way
* This is good for anything, there's no approximation in these kinematics
* We did assume that the spacecraft is on a circular orbit but that was about it
* So, now if we want approximate small departures, we can actually linearize this expression for small motions
* Big Omega's not a small term, but we can assume now my yaw pitch, roll angles, and the associated yaw pitch roll rates
* These are all going to be small oscillations, slow oscillations
* What happens there
* So, they're all treated as small variables, and we're linearizing them all about zero
* And then that's the result you get
* Let's look at the first line
* That's already linear, that's just your roll rate
* Here we have sign of pitch times yaw rate
* Well sign of pitch linearizes to pitch right
* Sign of X becomes approximately X for small departures
* So, that's small times small, it's small quadratic
* We drop it, right
* Here we have a cosine of small, linearizes to one, times sine of small, linearizes to the small
* So, that's the first order term
* And that's what you see in the first line here
* So, that's what we end up with only these two terms
* That's our first order approximation
* You can do the same steps for the other two axes
* And in fact, I encourage you to do it on your own, I don't need to do this for you
* And in the homework, you do it with MRPs
* So, good
* Now, this isn't the body frame, we need, in the end, Omega dot
* But we can use our handy dandy identity that Omega is Omega BN, so the N framed derivative, and the B framed derivatives are the same
* Right
* So, I don't have to do any cross-product stuff all I have to do is, this term is going to vanish, and all I have to do is take a derivative of these three matrix components, and that is the inertial derivative of this particular Omega BN vector
* Right
* So, this is still rigorous
* No approximations
* It just means here, big Omega is constant - I'm on a circular orbit - so there's no bigger make a dot
* Everything else receives an extra dot over it
* Now, I have a first order approximation for Omega dot, first order approximation for Omega, and we can start
* Well, we're almost ready to start applying it to here
* We can linearize this term with that, this term will still be make it times Omega
* There's an extra step we have to do
* What we're still missing is the gravity gradient torque
* We have a general expression, we need to now get an approximation of the gravity gradient torque around one of these equilibrius
* How is that torque vary if I pitch, roll, yaw slightly, you know, around it
* So, let's look at that
* We did this math already earlier, this is how we get to this stuff
* Now, we have a very particular BO matrix in terms of yaw, pitch and roll, times zero, zero something
* So, we're going to pull out the third column of this Bo matrix, which is nothing but these sines and cosines, times RC
* So, this is now my RC one, two, and three, the B frame vector components of the position vector is written this way
* And there's no approximation here yet
* And you can substitute this expression into this earlier expression we derived, where we have products of RC ones, twos, and threes, and this gives you this answer now
* So, this is still..
* We haven't made any small angle approximations yet in this expression
* This is still perfectly valid
* You can now describe your gravity gradient torques as a function of yaw, pitch, and roll angles of the body relative to this orbit frame
* That's what this yaw, pitch, and roll means
* And, again, you can make inertial tensors specific to make it go to zero, but we're not doing that here
* So, we're looking at small departure motions
* One thing that stands out is the same one
* If you look at this, because it's the third column with the DCM there, there is no yaw angle in here, which actually makes somewhat physical sense
* Right?' We line things up, we know that if this is lined up, it's a zero gravity gradient
* That's true, that answer is true regardless of how I rotate about that axis
* And in this system we call that axis three, and for a yaw, pitch, roll, that's a three to one rotation
* So, any three rotation doesn't really affect that gravity gradient torque
* That's what you find duplicated here by having used these all the angles in this sequence, which is kind of nice
* So, this is a general expression
* Now we want to linearize this cause we're looking at linear results
* What if we have not just general big motions, but I'm just having a little wiggles, right
* These angles are going to be small cosines become one, sine of two axis, just two X again
* So that comes in there and another cosine to one
* Here you have a two- Theta becomes, sign of two Theta becomes two Theta
* But here you have a sine times a sine, so that small times small, that's going to be higher order and drops out
* So, generally, while yaw doesn't appear, you do get a torque about the third body axis
* Right
* Nominally, the lining up B one, two, and three with 0, one, two, and three
* You do get a torque but it's actually really small
* That's the one that kind of helps you, though, restore yawing motion if needed
* Right
* That's what we need there
* But if you linearize, it's small enough to where you can drop it, and it doesn't appear there, so that becomes a second order term that you would have
* So, good
* Now, we have R
* With a little bit of math, we've got a linearized version of gravity gradient in terms of three, two, one, order angles relative to the orbit frame
* That's how we define all this stuff
* So, at this stage we're ready to start to put this together
* This is still our fundamental equations of motion of a rigid body, s single rigid body, not a dual-spinner or something but close enough, right
* So, we've got this linear, and we're plugging in those conditions including that the inertia tensor is diagonal
* This one, we've seen before, it gives you these terms, these differences, with Omega twos and threes, Omega ones and threes and all the products of Omega's
* Plugging in these Omegas that's what you get
* And then the gravity gradient torque, it only had first and second components, the third one dropped out completely in the linearization that we have
* So, the last step you have, because this is Omega till the I Omega, this is still Omega squared
* Linearizing Omega wasn't quite enough, you still have to, at this point, drop second order terms
* So, we can look at that
* And the pitch equation, the faded one is actually a nice example
* You've got pitch acceleration here, you've got pitch angles here, and in between things cross coupled with yaw and roll
* But if you look at these terms, it's yaw rates times roll rate
* That small time small, drops out, yaw rates times yaw angle, again, small times small
* It's going to be second order
* Roll times roll rate, second order, and roll times yaw angle, also again small time small
* So, the second equation, once you linearize and drop the second order gyroscopic terms, all you're going to be left with is this term, and this term
* That's what I've written here
* That's the pitch equation, right
* So, if we had- I'm flying along this way this is my one axis, two axis, three, positive pitch
* That's basically, that's this motion
* If you're flying along like this, how does this motion, how is it going to be stable
* So now, let's look at that result
* When you linearize, these things always look at spring mass damper systems, right
* And there's no damping in this system, it's gravity, it's a conservative force
* It's like, it just adding a springiness to the system, that's all you get out of it
* So, there is never asymptotic convergence with gravity gradient stabilization, it's just a marginal stability like a spring and a mass
* And if it's deflected, it's going to oscillate but it shouldn't get bigger or smaller, at least not within the linear stuff that you're doing
* So, this is our stiffness that we have to look at, and to make this pitch motion stable, we need this to be positive
* Three is positive, a real number squared guaranteed positive
* I2, principle inertias, they're all positive - you never have negative principle inertias
* I haven't seen anybody build such a structure
* So, the only way to make this positive negative is through the relative size of I1 and I3
* So, the way this is written I1 actually has to be bigger than I3 for the pitch motion to be stable
* Now, again, what I1 and 3 mean
* These are the principle inertias we've linearized about the O frame
* So I1 is the inertia of the craft nominally aligned with the 01 axis, and the I3 is the inertia of the craft nominally about the 03 axis to orbit radial axis
* So, if you look at the spacecraft, pretty distinct inertias, this would be gravity gradient stable for pitch motion
* I'm flying this way, so the inertia about this axis, this inertia is I1
* It's definitely much bigger than the inertia about the gravity axis three, right
* This is much skinnier than this, and that would be stable
* So, the pitch motions actually would be stable
* If you reverse that, well, now all of the sudden, you have a negative stiffness, and that's how it appears mathematically
* This would deviate
* But there's other ways you can do this as well
* There's other shapes
* I1 had to be bigger so you could fly
* Then this, so this way you could fly it as well
* And let's see
* No, that wouldn't work, I3 is now this
* This is I2, if I do it
* How do I have to do this then
* So, if I want this to be larger, I fly it there, and this to not to be the skinniest one - but I could fly, I could fly this way basically
* And then the pitch motion, which kind of makes geometric sense, this would also be stable, right
* So, it's different
* That's what comes out of it
* If you want to pitch motion to be stable, you have to line up your spacecraft such that O1 axis inertia is bigger than the 03 axis inertia
* Now, that just stabilizes one of the angles
* It doesn't guarantee that yaw and roll are going to be stable, in this case
* So we have to look at the other two differential equations
* Now, the fate of one actually- let me look at that one again - here, there were some faded dots that appeared but then multiply times here and here, they're all small
* The only one that's first order is going to be this product
* And the same thing down here, there's a [inaudible] times this
* Everything else is going to be dropping out a second order
* So, the theta dots drop out of the roll and pitch at the roll and yaw equations, and the pitch are perfectly decoupled from the other two
* So, pitch this is what we need
* Now we're focusing on roll and yaw motion, which to first order decouple
* This form of writing it, takes a little bit of algebra - quickly a few steps
* This is just a classic form you find in a lot of textbooks and papers that deal with this topic
* People come up with these KR and Ky ratios which are differences, inertia, two minus the other, two minus the other, divided by the third basically
* That's what they've done
* And there's probably historical reasons for that
* But this is how they rewrite it
* So, now we ended up with second order coupled differential equations
* And we have to look at the stability of this
* The way you do this in linear controls, a linear analysis, dynamic analysis class
* We look at the characteristic equation, right
* You write this stuff up into first order form, get the determinant of the, you know, one minus, that matrix sends s, get the determinant
* This in the first order form - because the second or differential equation - would give me a four dimensional state
* Roll, pitch, sorry, yaw, roll, yaw-rate, roll-rate
* So, you end up with a fourth order polynomial
* What has to be true of the roots of this characteristic equation
* Well, they can't have any positive real parts
* These roots can be real, they can be imaginary, that's fine too
* Imaginary tipping implies oscillatory motions, real roots implies asymptotic convergence or divergence depending on where they are
* And we just need real parts of it, right
* So, all four roots we have to make sure they're either on, basically, not on the positive plain but on the negative, or the imaginary axis, to guarantee some form of stability
* Now there's different criteria
* Some of you have taken classes on this, you might have recognized this Routh Hurwitz criteria that you can use, and I'll apply that here in a moment
* I'm not going into the details, it's really not important
* If you haven't seen this, there's whole courses you can take on this
* This is more about the results for the level of this class, you are not hand-deriving these conditions
* But, in essence, we've got a quartic term, we've got a quadratic term and then a zeroth order term
* And that's something we can take heavy advantage of
* It's easier to get roots because you could read, instead of solving for Lambda, you basically solved it for Lambda squared, which is the quadratic form
* And then the square root of that gives you the actual roots
* That's how you find all four possible routes cause it's always plus minuses and how does that work
* So, that's what we're going to use
* Now, skipping a bunch of derivations, this is what you find on these kinds of topics
* These are the conditions in terms of those betas
* This is how those terms are defined, and this is the inertia ratios, how you have to highlight this
* This is what would guarantee that all the roots are not positive
* In the KR-KY space, which has these ratios, how do you size stuff
* That's the equivalent kind of condition
* This one I added
* This came from the pitch conditions, and the pitch conditions written in KR-KY just mean KY has to be bigger than KR
* So, if you think of that condition, it gives you one half of the whole KR-KY space that drops out because you have to be on the plus side
* This one, too, actually, KR, X times Y has to be positive
* Well, that means that your X and Y are either positive or X and Y are both negative
* Right
* Then the product is going to be positive
* So that means your answers have to be either in the quadrant
* So if you're looking at it- Now, we'll see the quatrains in a moment
* But that restricts it to two quadrants
* Just instead of using X, KR-KY written in terms of inertia, looking at how they are defined
* This really boils down to this second inertia has to either be the largest - so that's the inertia about the 02, that's the inertia about the orbit normal axis, it's all equivalent - it has to either be the largest inertia or the least inertia
* And these four conditions you're seeing here
* If we plug those visually, and you can get discovered Matlab, mathematica, and plot these things out
* This is what you end up with
* So, we have these conditions that we had to be, one had to be bigger than the other
* The product had to be positive which put this in this quadrant or this quadrant
* And the other ones that inequality gave us this region that were stable, or this slither here
* The slither is because of this other constraint that we had from this equation, which gets a little bit more complicated to visualize, but that's what happens mathematically
* This is what guarantees that we have stability
* So, what does this mean
* This means, in these regions, if I have my - and this one has basically, it boils down to I2 so the largest inertia - in this region here, just little white region, you have a condition where I2 is the least inertia
* In both of them, if I have small departures, not just in pitch but in yaw, or in roll as well, that these motions would stay stable
* It won't just start to tumble about other axes cause you could be stable this way but then unstable about this axis, and that wouldn't be good for the space station; they don't like to flip upside down, right
* So, those are the two possible regions
* We typically fly this kind of a scenario
* That means I2 is the largest inertia
* I'm sure many of you have seen the images of the space shuttle, it's flying, its happy, its nose is typically pointing up
* For the space shuttle the nose is actually the axis of least inertia
* So, it's kind of like the skinny side, right
* With the wings going out, and everything, that's the axis of maximum inertia like this flat plate
* And then the axis along from wingtip to wingtip
* If you look at a side profile, it's more than looking at the nose, but it's not as much as looking at the broad side
* So that's the axis of the two axes, it's the axis of intermediate inertia
* What this says is, you have to pick your maximum inertia, which is basically looking straight out from the cargo bay from the shuttle, you know
* Wings are sticking out, noses up
* You want that to line up with your orbit normal
* So if you're flying along this way - this is my local gravity direction - my axis of flight direction, and then my normal axis is this way
* I have to line up my cargo bay with the orbit normal, essentially
* That's what I have to do
* Then I still need, I want bigger than I3, so the inertia about my long track axis, which is this axis, has to be bigger than the inertia about my orbit radius axis, which is my local vertical
* That's why the space shuttle tends to fly this sidestepping motion
* Well, it used to fly
* That was its gravity gradient stabilized orientation
* It didn't take any fuel, any thrust, little astronauts wake up bump the wall
* That was enough to just kind of stay close, and it didn't go crazy, you know
* But that's where these inertia ratios come from
* If you're going to fly one here, it's trickier
* This is a first order analysis
* Higher order terms are ignored
* In particular flexing has been ignored
* So, if we have it's not rigid but things could move, this quickly can become unstable as well, which you have to be really careful, ok
* So, historically, People like this one but, again, first order analysis is nice
* Life isn't first order, life isn't linear, it's non-linear and messy, and these higher order terms might have, actually, a strong impact, especially the flexing part, you know, the small attitude
* If it were rigid, this is all rigorous and right
* But if you have flexing happening all of a sudden with the motions, does that give you gyroscopic stack and, you know, the stability you have is this big and the gyroscopic is this big, the gyroscopic is going to overrule and take you all over the place.


--- SKIP ---: 07_extra-example-gravity-gradient-polar-pear-mission.en.srt


--- SKIP ---: 07_extra-example-gravity-gradient-polar-pear-mission.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_extra-example-gravity-gradient-polar-pear-mission.en_SENTbySENT.txt
* After all that math andlinearization and everything, it really boils down to a pretty simple
* This is how you fly an equilibrium whichwe've identified all three axis line up, all three orbit axis have to beprinciple axis of the body so you line that dictatesparticular orientations
* And then, to be stable, you have tomake sure this condition is satisfied
* And it's not just one, if this is stable,flying sideways, you know
* And so is this one, right
* You could fly nose up and nose down
* Do you care if you're flying nose up ornose down
* >> But it depends on the application
* If the shuttle does not want to use fuel,it doesn't care
* This spacecraft did care
* This is a famous one,the Polar Bear Mission, it has, you can see these gravitygrating stabilized, all need
* [LAUGH] they need the threeaxis to be the skinnier one, so they put the small mass and to save weighton a very thin boom all the way out
* And so now the inertias about anyother axis are going to be big, because of the big moment arm betweenthis mass and this honking mass
* But along the axis,that's the least inertia
* That's what we needed forstability, right
* And they go through this stuff, andI2, bigger than I1, bigger than I3
* Life is good, what could go wrong
* This craft does care that thispoint is looking at the earth
* Why
* That's why they put all the sensors
* It didn't put them on this side
* So this was launched to gravitygradiants stabilize the satellite, reasonable mass, not huge but,reasonable mass
* And it was supposed to point this way,and what actually happened after the first period in full sunlight,the attitude degraded significantly
* Which basically means shit happened,bad stuff happened
* Attitude degraded significantly,essentially, means it inverted itself
* Instead of being here and a little bitstable, this whole actually tumbled, banded off to go there
* And then you go back through the shadow,and everything is good
* And now we said, this is stable
* But so is this
* And in this case, we do care
* But the satellite doesn't,it's just following physics
* And it goes, hey, I'm perfectly happy
* You can bump me all you want
* I'm stable, I'm going to stay here
* So it's like, great
* What on Earth does happened
* And it wasn't supposed to happen
* So, several attempts were madeto reinvent this thing and finally they were able to get it
* They basically have to give it a kick
* And the way they can give it a kickwithout using fuel is, despin or spin off your wheel to crazy amountsis going to apply this huge torque
* They needed something to move it passthis linear local state stable regime
* And once the bigger motion happenedjust basically give it a kick and it tumbled and then recovered andthis other one
* And then use the wheel to cleanup the mess and get it close and hopefully stay stable again
* So, good news is theywere able to recover, bad news is why does it even happen
* Jordan, you got a question
* >> [INAUDIBLE]>> What did we miss here then
* What assumption do you think wasviolated with the space craft
* And there's a clue
* After the first periodof fully sunlit orbit
* What happens with sunlightput in a space craft
* >> A radiation pressure
* >> Could be radiation pressure,they don't think that was the cause but definitely something I would look at, isthe [INAUDIBLE] do you have a craft which this huge solar sails basicallyattached that would cause significant
* They don't think that was the cause here,but definitely related
* Spencer
* >> Outgassing
* >> I think outgassing you've always have,or what causes more outgassing inthe sunlight condition do you think
* >> I figured in the first fullysunlit orbit that it would have out-gassed most of what itwas going to out-gassed initially
* >> You think because it's a first orbit,not because it's sunlit
* >> Yeah
* >> Maybe
* Again, I don't have the details of this,but these are all good ideas
* Right now, you start to wonder,what did we miss
* What's going on here
* What happens with sunlight, though
* >> Heating up
* >> You heat up
* This is a very lightweight structure
* What heats up, is one side of it
* What happens to the other side
* Or what happens to the heated breath
* I can see some->> That side will expand [INAUDIBLE] so [INAUDIBLE]
* >> And if we're curving,what do we violate
* Rigid
* It's not rigid, this was a really,really lightweight structure, they had to get this tucker way out there
* There's not much stiffness to this andthey didn't really model well the thermal deformations thatcan happen on these kinds of an orbit
* So there was flexing going on
* Now flexing doesn't necessarilyimmediately make it go crazy
* But this was just an unlucky missionthat flexing happened to be happening in such a way
* That it was able to give itthe right kick at the right time, to get out of one equilibrium andin the end once it all settled, it settle into the other equilibrium
* Perfectly stable, that's the trickiness
* Gravity gradiants do stabilize
* But it really doesn't care ifit's positive or negative
* Every one of those equilibriums hasa flip that's still like an equilibrium
* And if you do care, then you have to have a mean to putit into the right equilibrium, right
* And then locally it's there
* And so here's a case a lesson's learned, where the thermal deformationsreally did matter
* And so flex endure, that's whatI heard was the primary culprit
* All these other ideas are fantastic ideas,and I'm sure they tested every one of those as well, just make noticeanother bounding case assumption
* With these even cause this effect right
* To model and simulate that
* So, it gets tricky.


--- SKIP ---: 01_module-4-introduction.en.srt


--- SKIP ---: 01_module-4-introduction.en_SENTbySENT.rtf


--- PROCESSING FILE --- 01_module-4-introduction.en_SENTbySENT.txt
* Hi, and welcome to the fourthsegment of space craft kinetics
* Here, we're going to be looking at thecomplex equations of motion that you have of a rigid space craft
* But on it, we now have a series of flywheels or other momentum exchange devices
* We'll be first studyingthe different types of devices
* There's reaction wheels,there's control moment gyroscopes, and then there's also variable speed CMGs
* And then we'll develop the math
* We'll actually develop the math in a morecomplicated way than most general way with the variable speedcontrol moment gyroscope
* And then I'll show you how youcould simplify these equations to retain the classical CMG andreactional equations of motion
* So this is a great classical treatment,reaction wheels are used very, very generally on spacecraft
* Their big benefit is theyonly need electrical energy, there's no thrust involvedto do the attitude
* Same thing with controlmoment on the gyroscopes, they're more expensive, butthey produce much bigger torques
* And yes,as you will see in the mathematics
* They also give you more headaches andmuch more mathematics
* So it's a lot of fun.


--- SKIP ---: 02_1-introduction-to-momentum-exchange-devices.en.srt


--- SKIP ---: 02_1-introduction-to-momentum-exchange-devices.en_SENTbySENT.rtf


--- PROCESSING FILE --- 02_1-introduction-to-momentum-exchange-devices.en_SENTbySENT.txt
* We're going to be talking aboutmomentum exchange devices
* This still belongs to the category of kinetics in the sense that we'retrying to find equations of motion
* We have found equations of motion andyou started that with blobs, let me frozen sowe have a nice rigid body
* Then we found them for a single rigidbody, studied equilibrium, stability, all the uncontrolled things
* Then we had systems of rigid bodieswhere we had maybe a dual spinner, so it was a craft in one wheel
* Now we're going to go a little bit crazyhere, not just do craft in one wheel but craft in n wheels
* And not just body fixed wheels buteven ones that can spin and twist relative to the body
* Those things are calledcontrolled mono gyroscopes
* So with all these extra thingsthere's benefits but also challenges
* The mathematics gets a lot more complex
* So in your last homework actually youderived these in via CNG equations, the path is all in the book
* We're covering everything in class, so as we go through these I'mgoing to show you some highlights
* Maybe go through some of these equations
* Show you how you can getfrom this step to this step
* But I'm not going to do everysingle mathematical detail
* You do that actually at the end when youput it back yourself in the homework
* But then you see all the sub steps
* You can see yep this iswhat I should be getting
* Great I'm on track
* If you're stuck with a sub step you canuse the next sub step and move on, right
* And then come back to thatone later if you have to
* So everything's there
* So the way I'm teachingthis is more of a overview
* We want to cover the topics andconcepts and how this comes together
* So we'll talk aboutmomentum control devices
* There's some pictures andjust conceptually why do people like this
* It's kind of an icing
* And then we can get intothe math equations of motion and we're going to derive itin the most general way
* There's something called verbalspeed control moment gyroscope
* Typically there's just CMG'swithin a single axis or dual axis, double gamble CNG devices
* But there are also some that have beenresearched that have been variable speed and you'll see the benefits
* If we do a variable speedcontrol moment job scope upfront we're doing the most complex version
* And then at the end we can go well,what if it is just a reaction mill
* What if it is a CMG
* So we can free certain modes in themathematics and certain terms go to zero
* And you regain the classic reactionalsolution or CMG solution or the hybrid, right
* So instead of doing this two, three times,we'll do it once in the most general and then specialize
* That's the approach that we're doing
* So we'll go through a single VSCMG first,talk about the motor torque calculations
* Clusters often too,that's we have multiple devices
* Basically comes to summation, once you know how to do one doingthe others is kind of a ditto
* It's more of a bookkeeping step soit doesn't take long to do that.


--- SKIP ---: 03_1-2-overview-of-momentum-control-devices.en.srt


--- SKIP ---: 03_1-2-overview-of-momentum-control-devices.en_SENTbySENT.rtf


--- PROCESSING FILE --- 03_1-2-overview-of-momentum-control-devices.en_SENTbySENT.txt
* Okay, so let's talk about control moment devices, here
* They're very popular
* Why do we like reaction wheels, CMG's
* Brian
* You've heard of these devices right
* Yeah
* Robustness
* Why robust
* I don't know
* There's only..
* It's just a spinning wheel and not a whole lot
* We had that discussion this morning
* Yeah
* You've heard of the Kepler mission
* Alright, But that was the thing that failed, is this spinning wheels
* How can a spinning wheel fail
* Well, it's never quite..
* But you know, it is that
* Right
* Others might argue that a Kurd area of research for example are these micro thrusters, there's a lot of people coming up with very very small little PPT thrusters and polaroid thrusters that put out in milli newton, micro newton so that because otherwise if you have bigger thrusters
* Its one Newton or nothing
* A lot of the controls you do need like you know 10 million newton meters not 10 newton meters
* And so these thrusters are way too rough in how they do it
* They do..
* These devices do give you subtle forces which is nice precision pointing
* if you Think of Kepler
* They have to stare very carefully at the sky
* They don't want this rough on off actuation
* They want a really gentle subtle thing
* And these devices give you that kind of a what they call control bandwidth right
* they just don`t have on off but I can do half or quarter on or I can get infinitesimally smooth with a nice voltage based motor
* So
* So that is good
* They are simpler devices
* What's the other, what are other benefits that we could have with momentum exchange devices
* Redundancy
* You might have redundancy, but you could also have redundancy with thrusters if you wanted to, Right
* Yeah Daniel
* You don't use fuel
* You don't use fuel, right
* In space, fuel is everything
* If you look at the control solutions that we develop very often we have to be careful that we're not just fighting gravity all the time
* You know, whatever nature is doing if the sole pressure's trying to tilt to five degrees and you go no I just want to be vertical just because you're fighting that
* That that torque all the time
* That means your wheels are going to spin up or are you using fuel continuously and you know that's a bad thing in space, so we always look for ways to be as one, as much one with nature as possible
* Right, because we just can't afford to do anything else
* So that's a very important point
* These momentum exchange devices don't use fuel
* They use electrical energy and electrical energy as long as your solar panels are there and they properly deployed you know and there are all these other little conditions then you can run this indefinitely
* Now what's the challenge when you go into Pluto
* Do you think you could still use reaction wheels out of Pluto Spencer
* The sun's going to be too strong to generate enough electricity to power them
* So New Horizons How did they do attitude control
* Electric from an RTG
* So you still have reaction wheels
* You could have reaction wheels i actually don't know if New Horizons used thrusters or reaction wheels
* I'm guessing they had reaction wheels on board, but you'd have to have a different energy source
* Right
* But it's still, okay
* It's not infinite like a solar panel but highly highly efficient
* So even in the deep space applications these wheels are quite nice
* You know we have means of generating electricity far more easily than having tons and tons of fuel
* You know you can stash energy replenish your energy
* These RTG`s are much more compact than having all that fuel that had to last all those years to do that
* So that's the big benefit
* All right, With momentum exchange devises what are some of the challenges though
* What do you think
* Zero crossings
* Used to be
* So there is stickage
* Now the more I talk with manufacturers about this and you go look at the specs they go zero crossings naah
* That's so old school
* No
* We don't worry about that anymore
* They can get good enough
* And the issue we talked about was stickage
* If you go slow enough all of a sudden you want to cross zero at a nice spin-off prescribed rate
* Once you get close enough all of a sudden it goes Uhh
* And it basically sticks and then you have to give it enough force to unstick it again
* And It gives you that slight wobble that Kepler really would hate
* You know, so you might have to worry about zero crossing but they're getting really good with these things now
* So that becomes less of an issue
* What are other ones.Ryan
* Russell
* Russell
* De-spinning the wheel
* Momentum management
* That's something we'll keep talking about
* So in the equation we developed you will see, hey this works
* This works infinitely
* But keep in mind these wheel speeds in the mathematics actually can grow infinitely large
* And in reality you can't do that
* Your wheel will literally fall apart at some point
* It's spinning so fast
* What are other issues that you have with these devices
* The momentum management, it will be true for CMG's and for reaction wheels
* We don't cover much of them in this class the follow on 6010 goes into way more detail on momentum management because its a whole complexity
* Or CMGCO's singularities if they line up
* Right
* Usually comes out of momentum management issues but there are also controllability problems that sometimes with these devices you may not be able to produce general torques
* So there's classic CMG singularity that we must about to talk about
* I'm going to show them here but don't go, We're running out of time doing the details 6010 goes in way more details from this stuff, but yeah they appear
* But also you basically got this washing machine right, something that's shaking and rattling and going around
* How balanced is that wheel typically
* Pretty good hopefully
* But is it perfectly balanced
* Right, never
* Nothing in life is absolutely perfectly balanced
* So you're actually you know its like having a little imbalanced mass
* And the faster you're spinning you're putting continuously now a slight shake and disturbance on the craft at the frequency of the wheel
* So if you consider internal modes fuel slosh
* Panels that might be flexing structural resonances your sense of platform has to be very steady because you want to stare at the stars with Kepler and it has a certain natural frequency and if you hit that natural frequency with these wheels, you might be exciting a little bit more than you want it, you know
* So you have to worry about those things, so balancing of the stuff
* Modeling in bound in class with an all perfectly balanced
* In modeling one has some current students who are just not publishing papers in the full stuff
* It's amazing how this little one motor torque equation that takes up this much space, takes up like a page all of a sudden
* If you do the full model
* So there's some papers, if you're curious I can point you to
* So big benefits, no fuel that's really the biggest thing but also fine tune control
* That's really important if you have to do just very just a smidgen left you know kind of control
* But there's challenges with all these devices and the mathematics
* So this is typically what they look like this is a very simple reaction wheel, some of them just basically spinning discs, a blob of mass, some electronics something that holds it together in case it breaks
* You don't want to smash everything else it becomes a bomb essentially
* So it has to hold itself together as it's a material but with reaction wheels, the key is this is all bolted down
* I like this picture because it looks kind of beefy you know
* Just remember this wheel is bolted down
* In the mathematics for a reaction wheel we'll always assume that all those axes are fixed
* The spin axis doesn't, you know change with respect to the body
* So we have body fixed spin axis
* You can have multiple wheels to generate arbitrary torque
* Each wheel you just get to a torque about the spin axis
* You apply one Newton meter torque
* Then you get a minus 1 Newton meter torque back onto the craft right, at Newton's laws
* You push with one Newton you get pushback back at one Newton
* That's the same principle
* There is no amplification there's nothing to generate a general three dimensional torque vector
* You didn't have to go this one has to produce 0.2 meter, this one 0.5, this one 0.3 and you spin them off at particular ways
* Right
* And we'll see that in the mathematics
* How do we arrange these, from a torque command onto wheel speed commands
* But they can saturate
* No wheel can spin infinitely fast and that's a problem
* To apply a torque it has to be spinning up the wheel
* So if you're persistently pushing on the craft like atmospheric drag might do
* And you're holding an attitude that's not in equilibrium with that drag, you're pushing back with the wheels to hold the attitude
* And that means continuously you're spinning up that wheel more and more and more and more and at some point it just goes okay, I'm done
* I'm taking off
* We may run into heat issues
* Heat can be an issue as well
* Other ones to look like this
* Here are some ITHACO ones
* These might be very same that was flying on Kepler
* Often look pancake shaped
* Why do these high end wheels often look more like a pancake
* Why not make them skinny, long like a cork bar or something
* But you kind of put the big rod with the wheel out there
* What do you think
* Bigger torque
* Sorry
* You have a bigger torque for your speed
* Technically correct because the motor torque, or whatever that motor produces That's a torque you get back on the craft
* Pressure is on the outside
* The Inertia is the big thing
* The bigger, the more out you put your wheel inertia, as the wheel mass the bigger the inertia is going to be
* So if you look at 1D rotation where you have i times the anglular acceleration equal to torque, the angular acceleration will be smaller
* If you have more inertia
* Right if it's a beefier wheel that means more inertia and you put the 1 newton meter torque on there
* You're not going to spin up as much
* That means they don't saturate as quickly and that's a nice thing
* You're still storing the same amount of momentum, torque times time gives you momentum
* So the more momentum we store you will find every one of these wheels introduces new gyroscopics
* With the dual spinner, we looked about which wheel speed should we have such that the gyroscopics actually help us or if you're evil, don't help you and destabilize it, right
* There's both that you can do with this stuff
* Now we'll see the same effects happening in a general wheel configuration
* All right
* So the more momentum you have it makes it really stable
* But if you have to point here and then point over here very quickly the momentum will work against you
* The more stable it is the harder it is sometimes to move it
* That's what stability gives you
* But that's why these things are flat
* We have so much mass they give you 10 kilograms the best you can do is a ring of 10 kilograms all the way out
* In reality you need something around it to hold it together
* You need some thin spokes to hold it together
* You need enough stiffness so these things don't vibrate like crazy or you know start having other modes that get excited
* So there's always a tradeoff but you do like as much mass as possible out
* That gets you the most inertia for the mass that you're allocated for this device
* Good if you look inside you can see it's basically this
* Most of the mass is out here
* This one happens to have a flat but it's a very thin kind of thing that comes out, they have certain shapes
* This is all for structural purposes
* You're looking at resonances, trying to make it a hyper stable wheel
* You don't want this thing to beat off balance washing machine thing
* So a lot of effort goes into that and they're getting really good these days
* And there is always some electronics that drives it
* Some of them are analog
* Many of them, some of the cool ones I've seen from Germany these days are digital
* You just basically give it a command and it does everything, tracks it's friction, tracks it's zero crossing, tracks its heat, if it gets too hot it automatically cuts down
* So there are some really nice what they call smart reaction wheels that we've seen there too
* You can find those on the web
* Honeywell makes also, they are a huge reactionary manufacturer that make up a lot of these devices
* Now Control Moment Gyroscope look very similar
* Same pancake
* That means we've got a spinning disk
* We want as much inertia as possible and there's still a motor in here actually that controls the wheel speed, because in fact none of these devices launch start up like with the dual spinner
* Once you're in the craft it's all bolted down, and once you're up there you have to figure out how do I now spin up this whole system
* All right
* So with a CMG, what's different from a reaction wheel, a reaction wheel, Ideally you'd like to have around zero speed ish or at least a low speed
* The higher the speed you will see from a motor torque equation and we've seen the work energy principle already
* It will cause more power be required
* So we want the speeds low
* With a CMG, we want a high speed because the thing that drives us here is not the motor torque actually but the gyroscopic effect
* I'm assuming you've all done this experiment with the bicycle wheel you spin it up, right, and then you tilt it and you get this weird kick in another direction right
* That's really the gyroscopic effect because if you spun it up like this you get momentum vector sticking out
* When you tilt it, you've changed the momentum, changed momentum is torque
* So that's actually going to spin you about this other orthogonal axes
* Right
* That's what we're taking advantage of
* So these should be spinning at a, you know 5000 10000 RPM
* Some of the smaller ones are going way more than 10000 even, it's a very high need to be very very balanced very carefully designed
* Immediately, that means more money for one of these devices
* But you have a motor that gets you to that speed and then holds it roughly at that speed
* But then there's a second motor here that's the new part that allows that spinning wheel now to be Gimbaled
* That's what they call the gimbaling angle
* How much and as you Gimbel it if this is your spin axis of the wheel, as we Gimbel about this, you know you're changing the spin axis now relative to the body
* So when we do these derivatives there will be body relative derivatives in CMG
* All right
* For a reaction wheel, those are not there
* So the big benefit here too and you'll see in the mathematics is actually the torque amplification small input torques allow you to get a large torque back on the thing
* So that small input really what you're taking advantage of is the gyroscopic that happens so the faster the wheel is spinning
* The bigger the gyroscopic will be for that input and you can put in one penny and get a dollar out of it so to speak, you know
* And that's why it's great if you have huge things to move, very big satellites
* It might take huge reaction wheels to move them but you can do it way better with a CMG device or at the space station it actually uses double gimballed CMG clusters to kind of hold their attitude and do stuff
* And double gimballing has some benefits, momentum absorption capability but most of the devices you see are like this single gimballed, they have a single axis not a double, you know, gyrating axis
* That makes it even more complicated
* So drawbacks, definitely mechanically more complex
* Controls are definitely much more complicated
* You will see in the equations of motion and we go from variable speed CMG to our classic CMG and a classic CMG just holds the wheel speed constant versus variable allows you to go all over the place
* It doesn't simplify it much
* It's still really complicated to just just really complicated
* You know, the good down to reaction wheels it becomes actually quite doable
* So the mathematics is def, it's trickier, singularities we're mentioning
* You're getting a Torque that's orthogonal to this axis and the spin axis and so that third axis actually varies with time
* So depending on what you're doing you can get these things to line up in a plane which is a singularity you're talking about
* And if it controls as I need a torque out of that plane you just can't produce that
* And that's the gimble lock, kind of a consideration
* So we'll see hints of that in the mathematics that come up some singularities
* So good how did they look
* They're not
* You don't typically fly one device so you have clusters of CMG's, often four with clusters of four
* The nice thing is you can...
* Each wheel has momentum
* Each wheel is spinning let's say 10000 RPM, that's an easy number and you can align them in such a way that two wheels are pointing out so the outward parts cancel the upwards part add up
* The other two wheels are pointing downwards in the other direction where the total momentum of the fourth CMG cluster is zero normally, And that's nice because having zero momentum means I stay agile
* The momentum I have like we saw with the dual spinners, you get very very stable but it also means you become more lethargic it takes a huge effort to drag all that momentum through space that takes a huge torque to do that
* So people like this for agility purposes
* You can do the same with reaction wheels but you need more than three
* You can do it with four reaction wheels, tetrahedron configurations where you can set up a system that has a nominal zero momentum device
* So again so there's whole lectures we can do on how to configure these things
* But that's kind of what they look like in clusters
* We'll typically in class, you'll see my pictures being mimics of this one, the pyramid CMG cluster
* Also popular configuration for reaction wheels.


--- SKIP ---: 04_2-vscmg-equations-of-motion-development.en.srt


--- SKIP ---: 04_2-vscmg-equations-of-motion-development.en_SENTbySENT.rtf


--- PROCESSING FILE --- 04_2-vscmg-equations-of-motion-development.en_SENTbySENT.txt
* Okay, so we've done a reviewof what these devices are
* There are certain benefits,everything has drawbacks, now we need to get into the math of it
* How do we get the equationsof motion of these things
* So we're going to be steppingthrough this carefully
* We are going to do it forspacecraft with a single VSCMG
* So that's a single variable-speedcontrol-moment gyroscope
* That's a single axiscontrol-moment gyroscope
* There have been a fewthat have flown this way
* Yes, Jordan
* >> Sorry,going back really quick to the CMGs, do you know if there are any that uselike flux spinning to do like, so that could just levitate the bearing androtate them
* >> There are, yeah
* because, especially, well,with the variable speed, the Air Force had a nice program,Fred Levy was running that, to look at energy storage, because as youspin up this wheels, as you de-spin them, you can actually pull and you could turnmechanical energy in the dimo effect
* You can turn into electrical energy,so this could replace a battery
* But you have to spin to pretty highspeeds to make them efficient
* So they're looking at 30,40,000 RPM's, really fast and mechanically with worrying about frictionand little imbalances is quite tricky
* So there's some that are looking atmagnetic bearings, levitation, and those kind of things
* Not necessarily flux pinning, I haven'theard that one being used but, magnetic bearings, absolutely, you will findsome of those devices looking at that
* Yep, so there's a lot of mechanicalchallenges and how to do this well, robust, it survives launch, where youget shaken to death, almost hopefully, not slight
* So anyway, so think of VSCMG as a Hybrid,we'll have the math for the CMG and forthe reaction wheel all embedded in one
* So we can talk to this once
* I want you to understand this path,deal the parts of just specialties of it, that's going to be our goal
* So goes with time, to wrap this up
* So very convenient becausewe can run both but, this VSCMG's are devicesbeing researched and done actually phoned some small sats viaCMG and tested those as well already
* So this is not just theoretical,this is starting to happen
* But this is stuff I did way back for myPhD, it's one of my chapters in the PhD
* So we're going to try and look at this
* One of the niceties I'm going tohighlight is we talked about CMGs having singularities
* What we'll find is VSCMG actually avoidsthis by move, by changing the wheel speeds, I can actually produce torquesabout axis or to the tork direction
* And that can be useful,it's highly redundant, each device if it's a variable speed you could useit as a reaction wheel, and as a CMG
* So that's two control modes that are fordevices that gives you eight control modes, andit's still a three degree problem
* So you've got a lot of redundancybuilt in which is sometimes nice, and also combine power energy storage,something we just discussed
* That's something people have beenresearching and looking at and would be nice,that we didn't need batteries as much
* So how do we get equations of motion
* It all basically boils down to this onelittle, simple equation, all right
* How hard could that be
* It's kind of like, hey you're doingyour whole dissertation f=ma, that's it
* Right, if you're doing orbits,trajectories, unstable manifolds
* All you're doing, and Daniel's laughing, that's really that's allyou're doing is f=ma, right
* How hard is that, in attitude it'sh.equal to l how hard can that be
* And I'll show you herethis is the hint of that
* If you want some more fun go chatwith Cody and John from my lab, they've been doing these imbalanced VSCMGequations that are quite interesting
* So let's review this,what is h.equal to l
* What is l here
* Start in the right hand side, Andre
* >> [INAUDIBLE]>> Be more specific
* >> [INAUDIBLE]on the body
* >> Which body
* because we now have multiple
* >> Rigid body
* >> Only on the rigid bodies andnot on the wheels
* No, external torque
* >> Exactly, right
* If this is a dynamical system, this applied to blobs in space,jello flying through space
* But it was the net external torqueacting on this dynamical system
* Now we don't have blobs butwe will have systems of rotating, it's a multi-rigid body problemessentially that we're solving here
* So that's just the net external torques
* We don't need motor torques
* Whatever that reactional spintorque is doesn't appear here, because that's an internal torque
* The Gimbal access motor torque does notappear here it's also an internal torque
* So just the externals, gravity gradients,solar radiation pressure drag, maybe you have thrusters to augment this
* Because maybe for momentum dumpingpeople still use thrusters sometimes, that could be good
* Now what is the h on the left hand side
* Robert
* >> On the tip of my tongue, I'm just->> The total angular momentum
* >> Total angular momentum, right
* All of this dynamic assistance
* So if it's a blob, it's just the entirething, it's not quite a blob here
* For us it's a spacecraft, plus the wheels, plus the frame whateverholds these things together
* Everything that has momentum,angular momentum, we have to account for
* And then what's this Baud up here, whattype of time derivative are we taking
* And as you know we often forgood reason do things in a body frame, but transport theorem isgoing to be all over this
* We have to do that, right
* We're also about which point havewe taken torks in momentum here
* Center of mass, actually
* So this either has to be a centerof mass point or taking moments and torques about an inertial point
* Then h equal to l is true
* If you're talking about a body fix point,that's anything else than center of mass, there was extra turnumsthat have to appear here
* So again these inbalance things makesthings immediately much more complicated
* So h equal to l
* We can assume this is all aboutthe center of mass of this system
* All the wheels are balanced so even when I'm trying gyratingI'm not really changing
* When I'm putting the gimballing angles inI'm not changing the center of mass of that CMG configuration, I'm justchanging where the axis is pointing
* I'm changing the inertias but not center of mass, sothat makes huge simplifications
* So we need some frames to define thisstuff, and I've got this gimbal frame
* So you will have gs is my spin axis,so this is your wheel, if it's just the reaction wheelthis is all you would have
* A reaction wheel in a gimbling frame, thisis how we can twist that spinning wheel, GG is the gimble axis, and that other
* And the CMG devices solves a pancake withthe motor knob sticking out left and right, it's actually the gg axis
* And so gs is the spin axis, gimble axis,and then gt is at the transverse axis, it's the third axis thatcannot complete a full frame
* GS crossed to GT gives you plus GG, okay
* So that's what these are,we've defined them
* Big omega here is going tobe the wheel speed and we're treating it here as time varying
* Later on we can freeze it to make ita CMG device, not a variable speed CMG
* Gimbel angles are defined through gamma,so the gimbel rate at which I am twisting these things isgamma dot, and that's what that's defined
* So that's the rotationrate about this gg axis, so kinematics is going to come back in
* And then so the full frame is gs, gt,gd, that's the g frame that we have
* This is the one we'll use a lot
* So let's talk about angle velocities, the angular velocity of the gimbalframe relative to the body
* This is where we attach this device toa body, because the motor is taking it and it's twisting it left and right, right
* And so this is the twist rate and the axisabout which you're twisting is gg
* So the angular velocity of the g framerelative to the b frame is just going to be gamma times gg
* It's the classic kinematics we didin the first part of the class
* There's a wheelframe,I'm going to introduce this quickly, and then within a few steps,we're going to ignore it again
* We'll make some argumentswhy we can ignore it
* So the wheelframe needs three axis
* I'm picking principal axis, so the spinaxis, ds, I can reuse it just to be lazy
* That's my first one andthen I have a wt and a wg which are two axis thatare fixed relative to the wheel, so as the wheel rotates, these axisare going to rotate with the wheel, right
* So if you look at the wheel frame,you can go ahead and get the angular velocity of the wheelsystem relative to the gimbal frame, and that's simply going to be the wheel's spinrate times the wheel spin axis, that's it
* So if you sat on the wheel frame it's setall this gimbal frame, look at the wheel you would see the wheel's spinning aboutthat axis at that rate and vice versa
* So now we have our two
* If you need omega of w, relative to b,you would just add up the two of course, and that's how, so we can get anycombinations of omegas that we need
* Let's talk about inertias
* I'm assuming this thing is built in a waysuch that I have three principal inertias of this gimbal contraption andthey'd line up with the gs, gt, gt frame
* Recently good assumption,may not be perfect but it's a good simplifying in the analysisthat we're doing right now
* So I have IGS, IGG, GT and IGG
* So IG is the inertia's of the gimbalframe along the ST and G axis
* That's where the subscriptsare coming from
* For the wheel, we can write that inthe wheel frame, you're going to have an inertia about here so that's going tobe the wheel inertia about the s axis
* And then I have Iwt, because the wheelis perfectly symmetric, right
* No imbalances, no other warping,all these kind of stuff
* It's going to be the sameinertia about the any two orthogonal axis in the planeof the disc, of the wheel, right
* So I just have Iwt, Iwt
* Now, here I'm saying the wheelinertia in the gimbal frame, is actually going to be the same as wheelinertia expressed in the wheel frame
* Why does that happen
* I think this is really,that's an inertial tensor
* This is a matrix representationof the inertial tensor, where I picked the w frame
* Here I'm claiming if Ipicked the W frame or the G frame,they both give you the same answer
* Why do you think that is
* >> There's a degenerateEigenvalue in the w inertia
* >> You're getting mathematical
* No, but you're right
* There is a repeated Eigenvalue in here
* That means that these axes are actually, the Eigenaxes that generatesthese inertias are not unique
* If we go back and look at that
* We talked about Eigenvalueof an axis symmetric body
* Where we had IS andIT in some of the torque free motion of an axis symmetric body,all of that stuff
* So you don't have to pick
* I could really, to get this diagonalfrom I just have to pick this axis and I have to pick any two axis thatare orthogonal to GS will do
* If any two axis will do,I can always pick GT and GG if you wanted to, andthey'll give you the same answer
* So actually I wrote upa quick mathematical thing
* So really I'm going to evaluate this now,I'm pulling in library
* I'm going to define now herethis as a diagonal matrix in this case the g frame, I've got this
* Now, since GS is my first axis,I'm doing what we call m1 basically that was the one axisrotation that we needed with an angle
* So, you'd have 1, 0, 0 orI can do metrics form of wg, right
* So that's the classic note, that'sthe rotation because we're doing one axis rotation where the GS is the first axis
* So if I translate here fromthe gimbal frame to the wheel frame, this is what I could do,I get this answer and then you can identify what does this cosinesquared the same thing sine squared
* Those things are justgoing to drop out to b1, and after all this math you get nothing but exactly the same result again even thoughwe did this code of transformation
* So if you don't believe the geometricarguments, you can quickly do the math and validate and go, yeah
* Actually, this inertia tensor isdiagonally both in the w frame and in the g frame, that's all we need, because that saves us a lot of transposewithout then end up all you're doing is creating a lot of trigs thatbecome one in the end and not needed
* Good, so that's kind of helpsexplain that one last slide
* Now I need to get some corner frames andattitudes
* We have the body attitude,we know how to describe that already, MRP's, DCM,Cortanians whatever you want to wish
* We need to get the attitude of the gimballframe relative to the body frame
* And if you go back andlook at how we defined DCM's, right
* It was basically the mapping from N to Band I'm just going to write that one out
* If your recall BN ended up being n1, n2, n3 in B frame components, that was one way to write it or each row, Was the b1, 2 and 3 in N frame components
* So if we go back and look at thosedefinitions, if you have the three axis, you can actually constructthe DCN very quickly
* And in fact here, I'm using this one, soinstead of having, what do i have here
* Let me go back
* Here we have BG instead of BM
* So instead of n1, 2, 3, I have the Gfirst, second and third axis I put in
* And then the B frame componentwhich is how we define them and that's give you to DCM
* So that works
* So if we have BG
* Now if I need to get the inertiatensor which was diagonal in the G frame which is great
* But I typically will need it in the endin the body frame, we'll do a lot of body frame relative derivatives, I would haveto reimposed multiply with the DCM, right
* To map it from one frame intoanother frame and you can do that
* The mathematics here become quite simple,IG is a diagonal and this one I can write out like this
* So, let's just kind ofdo this by hand once
* So, if I have BG is equal to my first vector, my second, my third, and then I need to compute BG times I in G frame components times B, now G transpose, right
* That would give me IG and the body frame
* Now, if you write it in the matrix formlike this, it's going to be nothing but gs, gt, gg that's the BG times this diagonal which was Igs 0,0, 0 Igt, 0, 0, 0 Igg times the same matrix transposed
* So, this transpose becomes gs transposed,gt transposed gg transposed, right
* And now you can just start to carryout all this matrix math here
* If you look at the second part,this is going to be Igs times gs
* You can think of this like a vectrix, matrix of vectors thatwe talked about earlier
* So out of this, all you'll going toget is Igs times gs hat transpose Igt, the second row, 0 times this,0 time this, drops out, gt transpose plus Igg, gg transpose
* So that's that part times this, so, [LAUGH] GS's, let's see
* Actually that's not right, hold on
* This is not a single line
* This is a three by threetimes a three by one
* This is not plus, that's wrong
* This would have to go here,and this goes here
* This should be a three by one
* It's a three by threetimes a three by one
* That should be a three by one,one by three times three by one
* Now all I have to do is gs timesthis term, gt times that term, gg times this term, andthat's where you get the final answer
* So from here, if I go backwards, IGs, Gs, Gs transpose plus these other terms
* That's all we're doing
* So it's a nice analytic way thatwe can do these projections from the inertia of one frame to another
* And you will see this is a handy resultto what we'll use several times as we go through that
* So that's what was done here
* This one also in the gimbal frame,I can just do the same thing, but instead of IGs, IGT,I have IWs, IWT and that's it
* It's a little bookkeeping
* So you get exactly the same result
* So now we have the inertia'swritten in two different frames
* Good, next step, Angular Momentum
* You guys said H had to be the angularmomentum of the total system
* The system will be composedof a single VSCMG, so it's a spacecraft,that's part B, that's the body
* Then I have G that denotes the inertia and momentum of the gimbal frame that hassome mass and it rotates and does stuff
* And then you have HW which isthe momentum of just the wheel itself spinning about that
* So we have to add up all these momentums
* And each one of these momentumsis of these bodies relative to the inertial frame
* So for the body this is dead simple,you've done this
* I'm using IS now, that is myinertia tensor of the spacecraft
* You'll see a differentI appearing later on
* So this one right now is justof the spacecraft itself
* It has the center of massof the reaction wheel, CNG devices already accounted for in that
* But what we're not doing is the momentumof the wheel-disk part spinning about the center of mass of those disks
* So a lot of it is already lumped in there
* And this part will be easy to go forth
* The other ones get more complicated
* So for the gimbal frame,it's the same math at the first step
* We have IG times,now I need omega G relative to N and omega G relative to N is omega G relativeto B plus B relative to N, right
* Earlier we kept calling this just omega,here and being a little explicit because we've got lots of differentframes and lots of different omegas
* So it's a little biteasier to keep track of
* So we need both
* This one was simply gamma dot times Gg andthat's put in here
* And the other one is omega BN
* The inertia one I've written withthis projections into G frame components already
* So, IG times omega BNgives me this answer, and IG times this one willgive me this answer
* Now, again,I'm jumping through a few steps directly
* So let me just look at it once
* This is a tricky one to do yourself in thehomework and different ways to solve this
* One thing you could say is,you know you have IG like this, and omega G relative to Bis just gamma dot times Gg
* Well Gg times Gg heretransposed just gives you 1
* That's good
* Gg times Gt transposed,what's that going to happen
* The dot product between Gt and Gg
* Zero, they're orthogonal, right
* So that drops out
* And same thing with the Gg times Gs
* They're also orthogonal, they drop out
* So that's one way to do it
* I think on the next slide I show youanother way with the matrix method
* That will give youthe same answer hopefully
* It's the same physics
* Now these terms, gs transposedwith omega BN will happen a lot
* If you look at,if we were showing the definition, let us recall how wetypically write omega
* So omega BN, we typically write it asomega 1b1 + omega 2b2 + omega 3b3
* So we have a reframe, the omega 1, 2, 3s are nothing but the 1,2 and 3 access components
* Omega 1 is really definedas b1 dotted with omega BN, or in matrix form this is equivalentto b1 transpose omega BN, all right
* Now, here we don't have b1 dotted withomega, we have gs dotted with omega
* So if you have omega BN, gs hat, this is really what is going togive you, if you think of this, if this is your omega vector
* And here is your gs vector
* It's giving you the gs componentof that omega vector essentially
* And we're just going to call that, insteadof omega 1, 2, 3, we've already used 1, 2, 3 for the body frame stuff
* So I can't reuse the same names,I'm just going to use omegas, omegat and omegag for the gs, gt,gg axis of that stuff
* So a slight notational thing butit helps us
* So that's what you see defined right here
* Where we have Omega s is gshat transpose with omega
* Omega T is gT transpose with omega andgg is the projection of g onto omega
* So the omega vector, this is again withoutany subscripts, we imply it's omega BN
* At some point it just gets old to writeall that stuff over and over again
* So this is omega BN is equal to these three vector componentsof that along the g axis
* So if you use that definition then youhave here gs transpose times omega and that becomes nothing butthis little omega s
* So, the same momentum expression here canbe rewritten a little bit more compactly in this form and that will help usin same label keeping that we do
* So, now we have to angular momentumvector off the g frame relative to the inertial frame
* What we need next is the angularmomentum of the wheel
* >> [INAUDIBLE]>> Itself
* Then it's the same formula
* You need the angular velocity ofthe wheel relative to inertial, and we know the angular velocity ofthe wheel relative to gimbal
* That was big omega times gs
* That was the spin axis side
* Gimbal relative to body, that was the gamma dot times Gg,that's the gimbaling rate
* And then of course, this is the classicspacecraft body rate that you'd have
* If you plug that in you now havethree of these terms to evaluate
* And I will just to show you different waysto do it, I'll do it different ways here
* This first term I've written out, and it's going to be this inertia tensorwhich we rewrote earlier as a result of the principal inertias timesthese outer products times omega
* And in here quickly you can seeagain gs hat transposed omega
* That's what we defined to be omega s
* The projection of the gs axis ontoomega was the omega s component
* Same thing with omega t and omega g
* So that's one way we canget that first term
* That gives us this one
* Now we want to get the other two
* I'm showing you a matrix representation,for some people this might bea easier way to think
* Both of them should allgive you the same stuff
* This term I can write in G framecomponents as this diagonal matrix
* G relative to B,that was gamma dot times Gg
* So, in g frame component it's00 gamma dot, all right
* And then you just do your typical matrixmath with which will give you 00 IWt that along the third axis,as the vector representation of that
* That's the third axis is Gg, soyou always get back the same answer
* You could do the same thing also forthis one, just here omega w relative to g was big omega times gs, so it's big omegaalong the first axis of the wheel frame
* This inertia tensor in the wheel frame
* You carry out the matrix math, you get just something in the first axis,which is the gs representation
* So, this ties back to the, you know,week one stuff that we did
* Vector matrix representation
* You should be able to go back andforth and whatever's most convenient It'll get youthere, it should be the same answer
* Now, we have these, we add them upto the other term, you combine them, this gives us now the angularmomentum of the wheel that we need
* Okay, great
* A few more things, as we take derivatives,we'll want inertial derivatives and, of course, we'll use transport theoremsbecause a lot of these inertia tensors are fixed by the body frame
* And also some of theseother axis have benefits
* So, the gs, gt, gg axis you could write analytically ifyou know their orientation at launch
* I locked them down and gs was pointinghere and gt was pointing here, and there's no gimble angle, right
* And after launch, you rotated 15 degrees, you can actually compute withyour classic cosines and sines
* What are the currentorientations of those axes
* gg stays always the same, hopefully,that means you bolted it down correctly, all right
* The gimbal axis is supposedto stay body fixed, always
* But for a VSCMG, the GSGT, we haveto treat generally as time varying
* So, you can write this andin code in fact, it would simulate this
* If I know my gimbal angle Ican't compute at any instant
* If I know my initial orientations atlaunch what are my current orientations of this frame of the wheel
* How far has it twisted
* All right, sowe will need derivatives of this stuff
* If we take body frame derivatives,different ways you can do it
* If you want to, you could just use thisexpression here and take derivatives
* because these are actuallyfixed as seen by the body
* And cosine becomes minus sine,which is right here
* Sine becomes cosine, andyou can see the derivative of this is going to be the gt direction andvice versa
* And the derivative of this one is justcommon sense, is going to be zero
* That's one way
* Or you can also use a transporttheorem and say, well wait a minute, instead of taking the b frame, what if Itook the g frame derivative of this stuff
* And if you have the g framederivative of gs that is zero, I see by the frame itselfthese axes don't move
* Plus you would need the omega grelative to b, which is gamma delta gg, crossed with this axis, you get a g,a third axis cross with gs, the first axis which givesyou plus the second one
* You can see the transport theorem,you get the same answer
* Different ways you can approach it
* I like the transport, it's very compact,you can get there very, very quickly without writing it out
* So, we can get the body frame derivatives, the key is the third one,that's where it's locked down
* That one doesn't vary, the other twoare a function of the gimbal rate
* If you need inertial derivatives,which we can do it here, we've chosen to do b-frame derivatives
* We've already got theseanswers as a sub-result, plus the omega crossed these axes again
* And you can do that, andcarry out, if you write omega
* The easy trick here is to get thisanswer in your homework I would say
* Write omega node as omega 1 b1,omega 2 b2 because you're crossing the gs
* Instead write omega as omega s gs,omega t gt, right
* Use the g frame components of omega andthose definitions and that's where these terms come in
* And then, it's just a classiccross products between vectors in the same frame
* So, 1 crossed 2 gives you 3, 3 crossed 1give you minus 2, all the usual rules
* And that's how you canget there then as well
* So, that would work
* So then,you should derive this yourself then
* I'm just kind of showing youthe highlights and how we go after it
* Since we have omega s, omega t and omega g, the vector components ofthe body rate in the g frame components
* We will also have derivatives of this
* Omega s, omega t, omega g are scalars
* So, what type of derivative amI taking on the left hand side
* Tebow
* >> Time derivative it's->> As seen by what frame
* >> Doesn't matter
* >> Doesn't matter, right
* Just a scalar, sothat stuff comes back again
* If it's just a scalar it'sjust a time derivative
* Over here, Tebow, what type ofderivative have I chosen to use here
* >> An inertila derivative
* >> Inertial derivative
* But that was purely a choice, I didn'thave to use an inertial derivative
* I could have used any,as long as I'm consistent, you can't use these derivative chain rulesinto one part in a and one part in b
* If you've taken a, make everything a,if you've taken b, make everything b
* The math will work itself out
* So, you can do that, sothat term is just okay, the angular acceleration dottedin the the gs direction, great
* This term here, gs hat transposed omega
* If you go back and look at gs hat is here, so we have all this math times,what did we do, times omega, gs hat transposed omega
* So, if you can see here, gs hat,this stuff, transposed omega, gt transposed with omega,what does that give me
* >> Omega t
* >> Omega t, exactly
* That was the projection
* Gg transposed omega gives you omega g
* And you're going to have an omega g, omegat with that product and here omega t, omega g with the product
* 1 plus, 1 minus, they both cancel and allyou're left with is here times gt times that term, that second term, which was gttransposed omega which gives you omega t
* Let's say we did body frame
* How is that going to look different
* Let me do that by hand
* So, just so I can prove, so if we use thisformula, I don't need to fire here, okay
* If we use this formula as Tebow says,that's just a time derivative
* Now, let's say,I'm going to use body frames
* I'm going to use primes as a body frameinstead of writing ddt and b's and all that stuff
* You would have gs transposed prime, right, times omega plusgs hat omega BN prime
* Well, one thing, omega BN prime, how doesthat relate to the initial derivative
* It's the same thing, right
* Omega, the B and the N frame is the same
* So, that's kind of cool
* We get right away gs hat transposedomega BN dot, the inertial derivative
* So, that's good
* This one, we need the bodyframe derivative of gs, and if you go back, we did that actually andI had showed you the results
* Here we go
* The body framed derivative of that,different ways you can derive it, but I'll use the transport theorem,was nothing but gamma dot gt
* And if I plug that one in,gamma dot gt transposed omega BN, this whole thing is nothing butthe definition of that and you get the same answer
* So, as expected, hopefully, we took here,b frame derivatives, in the slides I'm taking n frame derivatives,I get the same answer both ways
* So, that's always a good thing to practicethen you know you're doing all your math correctly
* So, you do this and you apply this now forall the three axes and now we have the inertial derivativethat you will need as a sub result once we start to take H dot andstart grinding
* So, we have that
* One other thing we'll use isyou will see a lot in the math, we have ig plus iws appearing
* And that's the inertia ofthe wheel plus the inertia of the gimbal frame thatholds the wheel and twists
* And so, we can sum them up
* If you see js, it's nothing, but basically the inertia of the combinedwheel gimbal frame system
* So, just a notational thing,because there's lots of stuff happening
* And now the fun, you need to do thisyourself, I'm showing you the highlights
* [LAUGH] But this is now where youapply your excellent skills on transport theorem and differentiation,we need H dot = L, so I would say since we've broken it upas H of the hub B H of the gimbal and H of the wheel, do each separately
* It just helps manage all the algebra
* Otherwise you're bound to getone letter crossed with another
* Do one by at the time
* So if I take H dot usingthe transport theorem
* I take the derivative asseen by the gimbal frame, because I'm using a lot ofgimbal frame components
* But then I need to add plusomega of the gimbal frame, relative to the inertial, right
* because dot is still the inertialderivative, cross with that H expression, carry all that algebra
* This is what you get,I'll let you do that
* You guys are very good at this now
* You do the same thing forthe gimbal stuff and this is what you get, the gimbal frame stuff
* And then for the body itself, well that'spretty trivial, we've done this before for a single rigid body, you regainthe same derivative expression, right
* Now we pack it together H dot= L is a sum of all three
* We're going to use this definition,J was the inertia of the gimbal frame and the wheel, the combined VSCMG device
* This is the inertia of the rigidpart of the spacecraft
* So this one is actually constant,as seen by the body frame
* This one isn't, because inertia,everything is spinning and twisting
* And I now is the combined spacecraftinertia, that's the full thing
* The rigid part plus all these spinning,twisting wheel parts, all combined
* That means I in this notationactually becomes time varying
* If you simulate these things,every time step, you have to recompute where are theseaxes, where are these inertias and sum up all these inertiacontributions again
* So it becomes even as seen by the body, Iis time varying but IS is the rigid part
* That's what you took advantage of when youdid the earlier differentiation of HB, that it was fixed asseen by the body frame
* Yes, Louis?>> How do you guys account for the center of mass of the gimbal system,in the body or no
* >> So all of these things havebeen taken in account for
* IS here actually already accounts forthe parallel axis part
* That if the CG of the wheels aren'tmounted in the center of the spacecraft, center of mass of the spacecraft,but they're offset somehow
* That is a fixed offset, andthat's already accounted for actually here when we derive this stuff
* So here these are just the wheelparts that that's the momentum and inertia is spinning about theirown perspective center of masses
* So center of mass is all subtlety
* I'm glossing over somewhat, butthis is rigorous, this works, it's just you have to account fordepending on where you place them, okay
* There's this much mass out there, that M distance squared termis already put into this part
* because that part is fixed,relative, it's a balanced wheel
* If it's inbalanced, your question would bevery good, because then with an imbalance, as I'm rotating, then the center of mass of the wheel is actually orbiting insidethe craft and then this wouldn't work
* You'd have to be much more carefulabout which points you do it so
* Being balanced allows us to,as complicated as it is, and I'm sure you'll agree in the homework, beingbalanced makes this much, much easier
* So that's a key assumption, sonow we throw this all together
* H dot = L, and I combine terms,which you will do as well, you can come up withthese kind of a terms
* Now this is the I inertialtensor of the hub, the rigid plus all the spinning stuff
* You can write it out into this form,which is our equation of motion of the spacecraft with a singlevariable speed CMG
* L is still the net external torquewe were talking about earlier, so that could be your gravity gradient torqueacting on this or deviation pressure, if we have thrusters acting forgenerating pure torques
* But it's all aboutthe system center of mass
* And then inside you have all these terms
* So the first thing I always do is let'smake sure these equations make sense if we simplify them
* If we bolt down like on launch, we have nogimbling, we have no wheel acceleration, everything is locked down for launch, Ishould get back the equations of motion of a single rigid body, which wasthis part and this part and the L
* Everything else should vanish
* So if you look at that and you see, okay,if I have gamma dot, if I'm locked down, there's no gimbling going on
* So gamma dot has to be 0
* This vanishes, this vanishes, let's see, gimbal acceleration vanishes
* That's 0 and this is 0, sono gimbling makes a lot of them vanish
* If you take the remainingequations you've got one here, IWS omega dot, and you've got thisis all vanished, that vanished
* You got this term that's non-zero,and this term that's non-zero
* Go back and look at your dualspinner equations of motion
* There we lined it up with the realaxis being along B1 or something
* So if you make GSB1, you get exactly the same equations again,so that's a nice validation
* If the wheel is locked down,then big omega is 0
* That means this term vanishes as well,this term vanishes as well, and there's no wheel acceleration
* So, as expected, all these terms vanish once youlock it down, which is always good
* Now, so this is good for both devices, but you can see the gimblingadds a lot of terms
* There's gamma, gamma, gamma,all the stuff that happens here
* What if you have a reaction wheel mode,we talked about that
* We basically get a double spinequations of motion, way simpler
* What if we make it a classic CMG
* In that case, the wheel's speed hasto be constant, not variable speed
* Let's see how much it simplifies then
* One term, woop-de-doo
* You got all this other stuff, so the CMGs really aren't that mucheasier than the variable speed CMGs, you just now accounted forall the other stuff spinning and gyrating
* >> Why is it that theyhaven't flown VSCMGs
* >> They have, and in fact everyCMG is in fact a variable speed CMG because it launches spun down andthey have to slowly spin it up
* But what they do is a simple controlthat they, it's complexity of the stuff
* Here, let me show you what generatesthe control that you have
* We have body rates are pretty small
* I mean, we're talking small
* People freak out when this craft goesmore than two degrees per second, that's nothing
* The wheels will be going way, way faster
* So CMGs, we're looking at 10,000 rpm
* So the big omega is going tobe the big honking elephant
* So this is small, gimbal rates are small,this stuff is all small
* What's going to give us the big torque
* It's going to be this term, right here,that's the wheel speed, which is huge
* IWs, which is your biggest inertia of thisdisk because we move the mass out about the GS axis, that give us that ring,the pancake shape
* And gamma dot is directlyproportional to that
* So, if you hold the fixed wing speed, thisis the control torque that we would use in a control application, andthat's what they're after
* You could make everything else variable,but that's really more in a later research, we've been finding inhow we can avoid singularities
* But the trick is, with the reaction wheel,what generates the torque is this one
* I'll show you the motor torqueequation in the next class
* But as you accelerate a wheel you get,with a minus sign, an opposite torque back onto the craft
* But you only get one Newton meter in,you get one Newton meter out
* Here though, if I gimble, with a littleeffort, the faster the wheel is going, the bigger the torque I get
* And that's what they've been focusing on
* So, devices could do this
* The issue is the motor torque about thespin axis typically are not that strong
* If you have to muscle through asingularity acting like a reaction wheel, you're simply going to saturate thatlittle motor very, very quickly
* So the way they're designing it,they're doing the minimal effort required, which means it tracks it within a simplebound, but it's not very tight bound, and it doesn't have much
* It may take, it just needs you to spin itup and keep it roughly at the same speed, that's all they need
* So it would be a hardware change
* So some have flown them like this andactually demonstrated that you can do it, it's just a little bit more complexityin the control and people, air force in particular have been looking at theseform of energy storage devices and to account for them
* There's extra complexity,they feel like I can do it
* Or some CMG manufacturer who waschatting with me during my PhD too, and they're saying well, we could also takea reaction wheel off the shelf and a CMG off the shelf, and combine both devicesto get the same mathematical benefits
* Off the shelf is alwayscheaper than trying to custom design specifically for something
* So until these become common,there's different ways you can do it
* But for here, this is kind of,where are we going to go
* So what we can see, my final comments onthis is, with these equations of motion, you see now there that as the wheel speedgrows, we can get a very large torque
* But also there's limits in each reactionwheel, how fast you can spin it and that's that big omega dot
* The gimbling is a nice mode, butyou will also have singularities
* Actually, I think I couldshow those as well
* This will be something about the gt axis,that's one axis
* If I have four devices,I'm going to have four gt axes
* And depending on how you've lined it up, you can have all thoseaxes become coplanar
* And if your control is outside of that,which will happen commonly with external disturbances, that'sa gimbal lock situation
* Because these axis about which I get thesenice generous torques vary with time, it just makes a lot ofthings more complicated
* But that was the singularity thatwe have so, anyway so you can see, CMGs, definitely a lot of benefits,the amplification but also mechanical challenges,more expensive
* But you get a lot of bang for your buck, way bigger torques than what youget with a reaction wheel, but it comes at a cost andthe controls get more challenging, too.


--- SKIP ---: 05_3-vscmg-motor-torque-equations.en.srt


--- SKIP ---: 05_3-vscmg-motor-torque-equations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 05_3-vscmg-motor-torque-equations.en_SENTbySENT.txt
* So what we want to do next is actually look at motor torque equations
* If we go and look at this differential equations, this is in a vectorial form, but really if you think of it in the scalar components, how many differential equations does this line, this boxed line give me
* Three
* Three
* How many states does this system have
* Three
* Well, you have omegas
* There's attitude, but for attitude, we have the differential kinematic equations, right
* So attitude is always covered, so let's just ignore the attitude part
* But this differential equation, you could solve for omega_dot
* Great
* But what is Omega_dot
* Right
* Per wheel, you don't know what that angular acceleration is gonna be
* What is gamma_double_dot
* We don't know that either
* So there's two extra degrees of freedom in this system
* Each mechanical device provided one additional degree of freedom because we have a single-axis rotation going from body to gimbal, gimbal to wheel
* So this only gives you three differential equations
* We need five, and that's because we have one device
* If we have five of these devices, I need way more, but then this kind of becomes repetitive
* So we have let's say we have four VSCMGs, this is still the equation you would use
* You would need this with summations over all the devices and I'll show you how to do that
* But then we still need what's called the motor torque equations per device
* Because,ultimately, what you would simulate is, hey, I'm putting in one newton-meter on that spin axis for the reaction wheel and half a newton-meter on the gimbal axis
* What's the dynamic response gonna be
* All right
* So we need these extra equations which we don't have yet
* So that's what we're gonna look at next
* How do we find these motor torque equations
* And essentially, we go back to the board and say, look, we're looking at H_dot equal to L
* If you think of it as a free-body diagram Р Р†Р вЂљРІР‚Сљ let me just draw that out
* If we think of this as a Р Р†Р вЂљРІР‚Сљ you've got your wheel
* Right
* And here's the spin axis, and the wheel is free to rotate about g_s
* There's your rotation
* Now Omega
* So this axis is a motor Р Р†Р вЂљРІР‚Сљ I know there's a motor torque that makes it accelerate about this axis
* If you have zero voltage with the motor broke, it would be a free-spinning wheel as, you know, it would spin up, spin down
* There's no motor torque applied
* This is very similar to that [inaudible] problem you did with the cylinder and that rotisserie grill architecture
* Right
* And it was the b-b_prime axis
* That was the axis where it was free to spin
* So if we had no motor torque, this would be a free-spin axis
* With the motor torque, you get to control what torque is applied
* All right
* So we know this is where our motor torque acts, but this is just one axis
* You will have two other axes that are orthogonal to this
* And as the spacecraft is tumbling and moving Р Р†Р вЂљРІР‚Сљ remember, this axis has a particular orientation in the craft Р Р†Р вЂљРІР‚Сљ the structure has to actually produce these other two torques
* So, we can do H_dot equal to L, about the center of mass of this wheel now, which is what we kind of derived earlier already, and we can then use that to relate and come up with a scalar equation that we need
* So that's what I'm showing you here
* So if you do this, H_dot equal to L Р Р†Р вЂљРІР‚Сљ the dynamical system is just the wheel Р Р†Р вЂљРІР‚Сљ the only thing that interfaces with the wheel is the motor torque in one axis and then the structural torques along the other two
* That's what makes sure this wheel doesn't just flip sideways relative to the gimbal frame, right
* As you gimbal it, you're specifying two of the three dimensions of the wheel
* It's the spin that's actually free
* So we can do this, and you've derived this already, we had this result earlier when we derived the full equations of motion, so I get to rewrite it again
* And the trick now is we have to recognize here that H_dot equal to L, that torque that's acting on just the wheel, the torque that's along the g_s axis must be what I call u_s
* That's the spin-axis motor torque
* The other two I'm calling tau
* Those are the structural torques that keep this wheel aligned relative to that
* If you needed to know what the structural torques were, you're worried about breaking those hinges and bearings and stuff, you can actually go back here and then do your simulation and then, postprocessing, plug in all these states
* And all these g_t's and g_g's are gonna be the structural torques that are acting on the system
* So this approach actually gives you the internal torques, if you want
* Now the equations of motion, I don't need them
* So what we do need to do is what is along the g_s axis, that must be equal
* So here, you can see we've got only this part
* This part must be equal to the motor torque, and that's where I find my motor torque equation here
* It's essentially the motor torque is the wheel inertia times the angular acceleration plus these two other terms
* If we ignore gimbaling, how big is your spacecraft acceleration compared to wheel acceleration
* What do you think
* About the same size
* An order of magnitude difference
* Two, three orders of magnitude difference
* How fast the spacecraft rotate, you think
* What's a fast speed with before they declare emergencies
* Three degrees a second
* Two degrees, three degrees, just a couple of degrees per second, doesn't take much
* You know, how fast does the wheel go
* Maximum speed, 5-6,000 RPM, way faster
* So it's accelerations are gonna well exceed what the spacecraft
* So some people actually just go, you know what, this is my motor torque equation, which really makes your life simpler because it decouples this equation completely from the attitude states and the gimbal states
* But it's not the true thing
* Momentum won't be preserved if you do that
* This is the full answer that you have
* And in fact, if you're gimbaling at the same time, the gimbal rate does cross-couple back into this torque
* There's a gyroscopic torque that you have to account for
* And so this is the full motor torque equation that you have
* Right
* So now we have this extra differential equation we needed
* We had earlier one for omega_dot
* With this one, if I throw it in, I can solve for this one
* But you can see it's also coupled to this one
* So you get linear systems of equations you have to solve simultaneously
* Or you could take this Р Р†Р вЂљРІР‚Сљ I'll show you in a moment Р Р†Р вЂљРІР‚Сљ we can take this and back-substitute it in, and this will give us the reaction where only creations of motion that I'll show you Р Р†Р вЂљРІР‚Сљ the classic results
* So, different ways you can formulate it
* So that's one extra differential equation
* We also need it for the gamma_double_dot
* That needs the motor torque u_g
* What's that torque there
* There, the dynamical system I'm using, it's not just the gimbal frame, but inside the gimbal frame is a wheel
* And the torques I'm worrying about is outside of the gimbal frame, so the gimbal frame to body is where the motor torque is attached between gimbal and body
* So, inside of it, the dynamical system is actually both the wheel with the gyroscopics and the frame with its gyroscopics
* So we computed these h_dot's earlier
* If you sum them up, this is what you get
* And now, this stuff about the gimbal axis actually has to be equal to the motor torque
* The other two are the structural torques being produced
* So it's the same kind of a process, right
* Two structural
* This is the motor torque here that's really spinning this combined Р Р†Р вЂљРІР‚Сљ as you rotate the frame, you're also rotating the wheel
* It's a combined system
* And you can come up, you can solve for this in the end and then that's what you get
* So if you drop this and ignore other terms, you could roughly say that torque is equal to inertia times angular acceleration, but it's a pretty crude approximation
* This gives you the full coupling
* And you can see, if you have a torque, you can get your angular acceleration for the gimbal, but also you get the spacecraft angular acceleration coupling into it
* So, either you back-substitute or you solve it as a linear system of equations
* But now we actually have five differential equations and given torques acting on the system, we can solve for everything.


--- SKIP ---: 06_4-vscmg-eom-variations.en.srt


--- SKIP ---: 06_4-vscmg-eom-variations.en_SENTbySENT.rtf


--- PROCESSING FILE --- 06_4-vscmg-eom-variations.en_SENTbySENT.txt
* Now, we're going to lookat how this all simplifies
* If we have a single reaction wheel,we mentioned earlier, if you just have these all 0
* Gimbal rates at zero,gimbal acceleration is zero
* That means this whole frame islocked down, relative to the body, these earlier equationssimplify to this form
* And that's nice
* So now, what we can do toois you could rewrite this
* We're going to use the motor torqueequation to get rid of big omega dot
* So I'm taking that extra differentialequation, I'm going to solve for omega dot, back substitute it so I get my spacecraft accelerationsin terms of the motor torque
* One thing, I can show you thisin identity, this term here, with a little bit of algebra, you canshow that it relates to omega cross gs
* They just,if you carry out the cross product terms, that's what you come up with
* So that's what I used toreplace this with this part
* The next thing is this is the motortorque equation without gimbaling, so there's not gamma tau term in there
* And that's good
* And so you can see in here,there is a Js times big omega dot
* Js times big omega dot
* I could then directly substitute this,I can take Js times this, bring it over to the left hand side and substitutethis back up in here, I can do that
* If you do that, you end up witha term here that's going to be Js
* This is Js times this,you're still going to have a Js over here, gs, gs transposed omega dot
* Here we have the fullinertia tensor times this
* And this inertia was the spacecraft inertia plus the gimbal and wheel frame inertia
* So I is all of this plus Js,Ts, gs transpose, as well
* But since, when you substitute thisback in there, you get this extra term
* It's just like this lastterm you have here
* Those two actually cancel
* So, for the reaction wheel form that I'mshowing you, people often ignore this and include that extra term,which doesn't make momentum work
* This will be the full answer
* You can then, so redefining that, I canrewrite these groups in terms a little bit, but this is more the classic formthat you would see for reaction wheels
* For reaction wheels we come up withcontrol loss that I'll show one example of then, where we come up withtorque level control loss
* CMGs as I cover in 6010, we don't comeup with motor torque level control loss
* We come up with gimbal rates asMario is pointing out right
* We want to take advantage of thatgyroscopic torque as we twist
* So we command a twist rate and then you have a sub server systemthat implements that twist rate
* But that's bunch oflectures in the future
* So this is the classicequation of motion of a wheel, of the spacecraft witha single reaction wheels
* But oriented in a very general way, gs,gT, don't have to line up with B one, two andthree like we did with the dual spinner
* That's what you'd end up with in there,so good
* Now that's a single device
* If you do a single CMG, that's reallynot much, as you guys mentioned earlier, this one term vanishes, butyou're left with everything else
* This is still the form that we use becausewe don't solve for the motor torques, we don't back substitute here
* In fact, this is the term that givesus the huge gyroscopic effect
* The big omega times the small gimbal rate, which is still a verybig torque acting on it
* So, in fact, to control the valves of thisyou find they come up with laws to come up with these desired gimbal rates to giveyou all the commanded steering and gyroscopics
* But this is the fulltorque level solution
* Now we've done single VSCMG devices
* Typically you don't fly a single one, wefly clusters of four at least with VSCMGs, with reaction wheels you may have three,four
* I've seen some with six and more
* Just depends on, you might usemore than three for redundancy but also maybe for torque
* Maybe a single wheel that you can get offthe shelf gives you one Newton meter, but your maneuvers require one anda half Newton meter
* So you may double up on the wheelsjust to get more bang there
* So we have to deal with clusters,systems of them
* And in essence everythingwe've done still holds
* It just comes down to book keepingproblem if you have multiple wheels
* Then where we had one wheel,that is going to be a gsI, right
* The first gs axis, the second gs axis
* The same thing for the transverse andthe gimbal, everything has 1 through n
* And there's some convenient projectionmatrices where I'm just making a three by N matrix of the N number of CMG devices,all the projections calculated
* This inertia, it was beforethe HUB plus the single VSCMG, now list a HUB plus a summationof all those, all right
* So we just carry out thatkind of a calculation
* And the rest of the gyroscopic terms havegrouped this into these tau vectors
* Those are the gyroscopic terms and withinthem they're n by ones you will see
* Each one of these torques actsabout gs1 through gsN axes
* And then the gT1 through gN axis,and the gG one to the gGN axis
* So it allows you to write in a little bit more compact way, this way whereasbefore, we had gs times all those terms
* If you did it like this, it would take you probably two pagesto write out every single term
* So it allows you to cheat a little bit,and just use some substitutions and notations to simplify
* So if you can do one wheel, really doing multiple wheelsis just a bookkeeping problem
* All the hard part is done, now I justwant to have a nice bookkeeping method
* What we can look at forexamples too is kinetic energy
* We have the kinetic energy that the hub,great, and then you got the wheel
* It has a spin rate relative to the bodyand the wheel also can gimbal
* So if you just go back and look at omega W relative to N, it hasboth big omega and gamma down in there
* Its inertia, the combined inertia system,you can write this all out, that's the kinetic energy
* The beauty and you guys aren't doing itin this class, 6010 gets to do this fun
* But you take the derivatives of this,plug in the equations of motion, lots of algebra later
* You come up with the same lookingpower equation that we've had before
* We've solved this power equation andjust for the rotational part you proved that omegadotted with L was the power that you have
* If an external torque is acting on it
* So the way you want tolook at this though, this is kind of calledthe Work-Energy principle
* This torque is the torque that actson the body relative to inertia
* You're pushing off with thrusters,you're really pushing off inertial space, so to speak with that
* Omega is body relative to inertia
* Big omega here, that's the wheel speed ofthe wheel relative to the gimbal frame
* Us is the motor torque acting betweenthe wheel and the gimbal frame
* Little gamma dot is the angular velocitybetween the gimbal frame and the body
* And ug is the torque acting betweenthe gimbal frame and the body
* This patterns holds, and you'll see this in a lot ofanalytic dynamics text materials
* Once you've recognized it andknow how it gets there, instead of taking this derivative andgetting there it's really powerful
* Saves you lots of days of algebra
* But anyway, sowe have a nice power expression even for the really complicatedmulti VSCMG equation
* We don't do much with it in this class,but other classes you might see them
* So the next step is now let's wedid the equations of motion for a single reaction wheel
* If we apply the same principle,we have this IRW, instead of we only have to account forthe transverse and gimbal axis directions ofthe wheel inertia in this IRW
* But instead of just one,we have n of them
* So it's just a summation again, right
* We have this h vector
* We saw this h vector with a dual spinner
* At some point I definedthe momentum of the second, the dual part,relative to the body like that
* And that's also appearing here
* This is kind of a common notation
* And you put this all together, witha little bit of algebra, it's not much
* You can write now yourequations of motions and nice matrix form where us is the stack,the n by 1 of all the motor torques
* And then you can get out of thisyour angular rate of acceleration
* The nice thing about this form is l don'thave big omega dot showing up anymore
* l mean once l know whatthe motor torques are, l essentially decoupled thesetwo differential equations
* l can get omega dot directly
* And that same motor torque you appliedto the motor torque equations, and then you know now what big omega dot is
* You substitute it in as a known and you get your big omega dots,the wheel acceleration
* So this gives you a way, we've kind of analytically oneway solved the sets of equations
* That's good.So that's if you have a system of them
* A popular configuration of gs, that'sall the projection axis is you line up
* The first wheel with b1, the second wheelwith b2 and the third wheel with b3
* In that case,this projection matrix is nothing but 100010001 which is an identity matrix,right
* And then the gs just drop out andyou end up with this form
* But this form is nice because if you eventry to do it perfectly with b1 what if you're off by a degree or two
* This form allows you to solve it in a muchmore general way without that perfect alignment assumption
* But that's a differential equation wherewe do control we'll use this particular differential equation, and come up with a control developmentto do stabilizing that you'll see.


--- SKIP ---: 07_optional-review-of-momentum-exchange-devices.en.srt


--- SKIP ---: 07_optional-review-of-momentum-exchange-devices.en_SENTbySENT.rtf


--- PROCESSING FILE --- 07_optional-review-of-momentum-exchange-devices.en_SENTbySENT.txt
* A review from last time, we talkedabout momentum controlled devices, let's do a quick thing
* What was the big benefit, Kevin, of momentum controlled devices versusthrusters to do attitude control
* >> Can have a more precisecontrol of the attitude
* >> Okay, I mean, we can give justa really small torques on it
* Though that's slowly changing becausepeople are coming up with very interesting micro thrusters that canalso do nano Newton meters of force
* And so historically that's been preciselytrue, 10, 20 years from now, we'll see
* [LAUGH] It's evolving,but that's definitely so we can make some more forces
* What else, Mariel
* >> You don't have to use fuel
* >> No fuel, that is the big benefit
* So regardless of, well, those little microdevices are probably very efficient, they may not take much fuel
* But it's still a finite resource
* Versus these wheels,it's purely electrical
* Part of that is a motor,an electric motor, that we drive
* You give it a voltage,it spins up, all right
* So with reaction wheel,you put 1 Newton meter in on that torque, you get 1 Newton meter back
* It's a 1 to 1 relationship, which is nice
* But we have to also develop the motortorque equations, which we'll do today
* What we did last time was developedequations of motion of a spacecraft with the single variables b, c, and g, orat least, I outlined how you develop them
* There's lots of little stepsin between that you're doing
* But so today too, we need extra equationsof motion that we'll talk about today when it comes together
* What is the benefit of a CMG devicethen compared to a reaction wheel
* Mandar, what do you think
* >> CMGs use a high spin rate,which stabilize, as opposed to reaction wheels,which need to spin
* >> So it's the highest spin,what gives you a stability
* >> No, sorry, they use high spinrate to generate the torque
* >> Generate the torque, exactly
* There's a huge gyroscopic coupling
* If your wheel is spinning quickly,and my arm is my torque vector, if you're twisting that arm,you're changing that momentum vector
* And h dot equal to l,a change in momentum, must be a torque
* That's that huge gyroscopic torquethat can be taken advantage of it
* Great, so we get huge torques
* If you have to maneuver very quickly ormaneuver very large objects, like space stations and really bigsatellites, CMGs are definitely preferred
* Otherwise, you would need huge wheels
* What's the challenge withreaction wheels though
* They're simple, they're cheaper,what's the big issue
* So less torque, right, but what else
* >> So there can be staticdynamic imbalance of the wheel
* >> I didn't think about that,but that's correct
* You could have an imbalance
* That's always the case, butthat's also true for a CMG
* No mechanical device is everperfectly balanced, all right
* So and a CMG actually moving at a veryhigh frequency is going to give you this very high frequency jitter that you justhave to make sure your system handles, and it's not an issue
* Every structure kind of absorbs some ofthat jitter, acts like a low-pass filter
* So, people have to design that
* Yeah, so imbalances,if you're doing a reaction wheel, you go from slow speed to high speed
* And you go through all the frequencies, so you may want to model if youhave structural residences
* If the sense of platform hasa 10 hertz first mode stiffness, you may not want to hang out at 10hertz a long time with a wheel
* because you would beexciting that frequency
* So there might be thingslike that to consider
* But what's the fundamental challenge
* Why can't we just use reaction wheels andapply a torque indefinitely
* Andrew
* >> Desaturate
* >> Desaturate, right, at some point,you physically just can't go faster
* The bearings break down,there might be heat dissipation issues
* There's all kinds of stuff, an issue
* So with CMGs,we're going at a fixed speed nominally
* So I don't have any speed limits becauseI'm just running at a fixed speed
* I can always keep twisting
* What is the problem wehave with CMGs then
* Casey.>> We have gimbal lock
* >> Gimbal lock, right
* So with the reaction wheels, the axis about which we producea torque is fixed as seen by the body
* because its wheel is bolted down, right
* And we had some pictures on this,let me just go down a few
* I like it because it looks beefy,it's really bolted down, this spin X, the motor axis doesn'tchange as seen by the body
* So it's always, you put on this1 Newton meter on this wheel, it always gives you a torque about thataxis, no matter what the body is doing
* Versus if you go look at CMGs, which wehad here, now, this is our spin axis
* But then there's a gimbal axis,and that varies with time
* And the gyroscopics we werehearing about earlier, that's always about that transverse axis
* If this is my spin axis andthat's my gimbal axis, then the change in momentum is about thethird axis, that's the GT axis we called
* And that axis varies as you gimbal
* So I could only get that biggyroscopic torque about a single axis
* And what can happen with gimballock is with multiple devices, those axes can all become coplanar
* In fact, that's what would happenif you would just go there, take the spacecraft, and an astronaut justgoes there and keeps pressing against it, just to be an irritant,that spacecraft will hold an attitude
* But eventually,all the gimbals will line up, such that all the GT axes are orthogonalto that torque being applied
* And then you have gimbal arc,and everything starts tumbling
* So any momentum exchange devices has somemomentum limitations in terms of speeds or orientations or how you cannot absorbinfinite amount of momentum onto a system
* That's just not physically possible
* There's always a finitelimit that we're seeing
* So good, this is what we went through
* Now deriving equations of motion, what was the one overriding equationthat drives all this stuff
* >> [INAUDIBLE]>> H dot=L, so Casey, let's go through this quickly
* H was what for this system
* >> The total angular momentum
* >> Of the dynamical system, right
* And here we have the spacecraft,we have a gimbal structure, and then we have the wheel withinthat gimbal structure
* So we actually have three components
* What was the dot, Kevin
* >> The initial derivative
* >> Right, the derivative asseen by the inertial frames
* Immediately transport theorem, right,we're going to have to use that a bunch
* And then the L
* >> External torque
* >> The net external torque acting on it,so motor torques don't go in that L
* Motor torques are internal systems, where the spacecraft is being pushedoff relative to the gimbal frame
* And the gimbal frame pushes offrelative to the wheel frame, those are internal torques
* They don't show up in that L that we had,good
* So, we went through this H dot=L,how hard could that be, right
* And it's a lot of details,a lot of book keeping
* So, some rigor is helpful here
* Just notationally, to review,because we see the same, [COUGH] excuse me, today,gs is our spin axis of the wheel, gt is the transverse axis then,and gg, that's the gimbal axis
* So for gimbaling gamma dot,wheel speed, big omega, all right, that was kind of the rough breakdown
* We had the gimbal frame that weactually used a lot in the derivation
* There's also body frame with a typical b1,2, and 3, but you see in this system, it tends to be easier to writeeverything in the gimbal frame
* We have the angular velocitiesof gimbal relative to the body, wheel relative to gimbal, soyou can add, subtract them as needed
* And why was it in the end, if we assumethis gimbal frame is principle and the wheel frame, we've picked one thatlines up with symmetry, it's principle, why is it that the wheel inertia isthe same in the wheel frame as it is in the gimbal frame
* What was the reason why that was casebecause that's not generally true, right, if you have two different frames
* And that's only true for IW, not for IG
* IG, if you look at this,it has three distinct inertias
* IW has a spin axis inertia, andthen the two other inertias are the same
* >> Does the wheel inertia
* >> Because of the symmetry, exactly
* If you did the DCM, this is a rotationbetween a wheel fixed frame and the gimbal frame
* The only difference is the rotationabout the one axis, the GS, and if you put in a DCM,pretty imposed with the one axis rotation
* Because of the symmetry here,you end up stuff that cancels, and that doesn't matter in the end,so you get the same thing
* And I show that in Mathematicaquickly without doing it by hand
* But that's a trick we use
* So that's why in the end,we define the wheel frame, but we never actually use it afterwardsonce we get past this step
* And say well, the wheel tensor, we canexpress it easily in a diagonal form also with a G up here, instead of a W
* We went here, we took our DCM,so if we have these three axes, we did this kind of when we workedwith direction cosine matrices, right
* The BN matrix, you could write asB1 transpose, B2, B3 as rows or N1, 2, and 3 as columns
* So instead of BN, we have BG, so the G frames become the threecolumns that you have
* We can express that
* If you then do the matrix math here, whichwe did last time, you can write it as the principle inertias times the outerproducts of the base vectors
* It's a very convenient form,because we know a lot of algebra on this
* Any questions on these things too
* If there's any questions on last material,yes, Casey
* >> The gimbal frame is literallythe frame holding the wheel, right
* >> Yes, gimbal frame is this one here GG,so this axis lines up always with that
* So, on a general CMG device, this is theonly one that's fixed as seen by the body
* That's where you bolt down the CMG
* But the other two axes as you gimbal,so if this is my gimbal axis, the GS axis of the wheel and the GT,those are varying, they rotate about GG
* That's what's happening there, yep
* So GS, GG, and GT,that's where they come from
* Good, so we went through that
* So now to get H,as you were saying earlier, H has to be the total angularmomentum of this dynamical system
* And here we have threerigid body components
* We account for all of them
* Spacecraft to hub itself is easy,that's just inertia tensor times omega BN, we've done that before,a single rigid body
* The gimbal frame has the samekind of formulation, the gimbal inertia times the angularvelocity of gimbal relative to inertial
* And we write that one as a sum of angularvelocity of gimbal relative to body plus our typical body angular velocity
* And this one is nothing, butgamma.tensor GG, and there was ways
* I showed you vector ways to do this mathor matrix ways, I actually think later, here, we did matrix ways
* So this is kind of the core stuffwhen you write these momentums, just remember it has to berelative to the inertial again
* You don't just put in the angular momentumof the wheel relative to the body
* You need the full momentum of the system,H dot = L, inertial angular momentum that went there
* Good, run through this, then there wasa variety of derivatives we had to take, which hopefully,you could do with the transport theorem, that was pretty straightforward
* The more interesting ones iswhat were omega S, omega T, and omega G, what were those omegas
* Usually, we have omega 1, 2, and 3, which is the B1, 2,and 3 frame component, right
* Kevin, do you remember
* >> The components ofthe omega vector in G frame
* >> Yes, so the omega S is the GS componentof omega, and omega T is the GT, so instead of using omega 1, 2,we've taken the exact same omega vector
* Just instead of using the body frame,we're using this gimbal frame
* We're breaking it up into threedifferent components, right
* And just convenientbecause those transpose, those mappings happened everywhere
* So now this is a scalar
* So Tebo, I think last time,you answered this one
* Taking a derivative of the scalar, with respect to what frame are wetaking this time derivative
* >> You don't take it with respectto a frame, it's a scalar
* >> A scalar, but the scalar isa product of a bunch of vectors, a dot product essentially
* So over here,what frame do you get to pick
* >> Whichever one you'd like
* >> But?>> It has to be the same
* >> So if you have A times B,you can't say, well, I will take the Qframe derivative of A
* And then later on, if chain ruled the N frame derivative ofB, once you pick a frame across a product, across a scalar part of that product,you're pretty much committed, all right
* And this is if you do it inertial,you can plug it in, and I think I also showed last time that ifyou did it in the body frame, for example, or the gimbal frame,that's another one you could pick
* You'll always get the same answeras you would expect, all right
* So this was a good exercise of takingderivatives of scalars since scalars are a function of vectorial quantities,to put that together
* So just definition fortoday, you see this again
* J is nothing, but the summation of the inertia of the frameplus the wheel within the frame
* because these sums appear everywhere,so we define J as that
* And then, yeah, the fun, which you did inhomework, there's some sub-results there
* We do all this, andthen the final definition is IS, which is the inertia of the hub itself,plus the inertia of the VSCMG combined, gives us the spacecraft inertia
* So this one now, does this Ivary as seen by the body frame
* >> Yes.>> Yeah, this one is fixed
* It's a rigid hub, but if this isa variable speed CMG as you're gimbaling, that wheel,the mass distribution does change
* If you just had a reaction wheel,does J vary as seen by the body, if you only have a reaction wheel
* All right, no, because that wheel, eventhough you're spinning it up and down, because it's perfectly symmetric balanced,there's no change in mass distribution
* One particle replaces the next particle
* So, anyway, so keep that in mind,when you do these simulations, in this case, you're not going to simulatethis in this class, but 6010, you would
* These are the things you would have toupdate every time step, 6010 is fun
* There's some really interestingcode you're writing there
* You guys think estimation is bad,you have no idea
* This is fun stuff
* So now we have our equations of motion, this is kind of where weended up with last time
* This is a rigid spacecraft plusa single VSCMG device, and we still have the externaltorques that act on it, right
* That's not motor torques,that's gravity gradient torques or radiation pressure, all this good stuff
* And as before, if it's a reaction wheel,what all vanishes
* We'll see that again today
* What all goes to 0 if it's a reactionwheel, instead of a VSCMG
* Endor
* >> Gamma dot terms
* >> Gamma dot, yeah, anything else
* Gamma double dot also goes to 0,so this vanishes, this vanishes
* All this other stuff vanishes,and in fact, you get only this term,you get this term and this term
* If you go back and look at yourdual spin equations of motion, let me just put this up
* With the dual spin stuff,you had exactly these same terms
* The one difference was,we didn't have GS GT GG, there, the dual spinner,we lined up our wheel with B1
* But in essence, B1 then is GS,all right, that is that axis
* So just make that replacement,it's a 1 to 1 thing
* This is a slightly more general version, where your wheel doesn't haveto line up with the B1 axis
* That's what we found
* If it is a CMG, Kevin,how much simplifies
* >> You only get rid ofthe omega [INAUDIBLE] >> That's it, whoopdy do, we're still left with 6 million terms
* So now,especially when you have lots of CMG, that's why you can see the mathematics ofCMGs, way more complicated right away
* In fact, if you have a dual spinnerconstant speed, even this time goes to 0, gets more simpler
* But this is where we ended up last time.
TOTAL lines: 42003 | TOTAL files: 563