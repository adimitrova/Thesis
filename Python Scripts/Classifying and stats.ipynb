{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/data_science_python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import string\n",
    "\n",
    "# ---- for TF-IDF & NLTK\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from pathlib import Path\n",
    "from beautifultable import BeautifulTable\n",
    "\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate\n",
    "\n",
    "allRunsAccuracy = []\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "import pandas\n",
    "import sklearn\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import StratifiedKFold, cross_val_score, train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.learning_curve import learning_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First, randomize the dataset by getting 200 out of the 250 values per class which is equal to 1/5th of the dataset, every time it is different so we can output different results and get average performance values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1250\n",
      "249\n",
      "201 \t 201 \t 198 \t 201 \t 200\n"
     ]
    }
   ],
   "source": [
    "file = open(r\"C:\\Users\\ani\\Dropbox\\Stuff\\university\\data\\250PerClass.txt\", 'r', encoding = \"ISO-8859-1\")\n",
    "sentences = file.read().split('\\n')\n",
    "\n",
    "CD,CM,AP,SM,EX = 0,0,0,0,0\n",
    "print(len(sentences))\n",
    "\n",
    "with open(r\"C:\\Users\\ani\\Dropbox\\Stuff\\university\\data\\200RandomPerClass.csv\", 'w', encoding = \"ISO-8859-1\") as oFile:\n",
    "    while len(sentences) >= 250:\n",
    "        curLine = random.choice(sentences)\n",
    "        curLineParts = curLine.split(\"|\")\n",
    "\n",
    "        if curLineParts[0] == \"CD\" and CD <= 200:\n",
    "            sentences.remove(curLine)\n",
    "            oFile.write(curLineParts[0]+\"|\"+curLineParts[1]+\"\\n\")\n",
    "            CD += 1\n",
    "        elif curLineParts[0] == \"CM\" and CM <= 200:\n",
    "            sentences.remove(curLine)\n",
    "            oFile.write(curLineParts[0]+\"|\"+curLineParts[1]+\"\\n\")\n",
    "            CM += 1\n",
    "        elif curLineParts[0] == \"AP\" and AP <= 200:\n",
    "            sentences.remove(curLine)\n",
    "            oFile.write(curLineParts[0]+\"|\"+curLineParts[1]+\"\\n\")\n",
    "            AP += 1\n",
    "        elif curLineParts[0] == \"SM\" and SM <= 200:\n",
    "            sentences.remove(curLine)\n",
    "            oFile.write(curLineParts[0]+\"|\"+curLineParts[1]+\"\\n\")\n",
    "            SM += 1\n",
    "        elif curLineParts[0] == \"EX\" and EX <= 200:\n",
    "            sentences.remove(curLine)\n",
    "            oFile.write(curLineParts[0]+\"|\"+curLineParts[1]+\"\\n\")\n",
    "            EX += 1\n",
    "                \n",
    "print(len(sentences))\n",
    "print(CD,\"\\t\",CM,\"\\t\",AP,\"\\t\",SM,\"\\t\",EX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now off to the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                           Sentence\n",
      "0    CM         however,let's talk about the inputs first \n",
      "1    SM        that's the fundamental theorem of calculus \n",
      "2    EX  these are two places where the derivative is e...\n",
      "3    CM                               let's get rid of it \n",
      "4    AP  you can use OMITTED it's always smooth,if you ...\n",
      "5    EX                      the graph is always wiggling \n",
      "6    EX  if we knew where those degrees were granted,sa...\n",
      "7    CM  a processing element is a digital device,which...\n",
      "8    CM  let's examine the minimum ram and rom required...\n",
      "9    CM                       what happens at the bounces \n"
     ]
    }
   ],
   "source": [
    "# ADD THE FILE THAT IS NOT PREPROCESSED YET\n",
    "prefix = r\"C:\\Users\\ani\"\n",
    "sentences = pandas.read_csv(prefix + r'\\Dropbox\\Stuff\\university\\data\\200RandomPerClass.csv', sep='|', quoting=csv.QUOTE_NONE,\n",
    "                           names=[\"Label\", \"Sentence\"], encoding = \"ISO-8859-1\")\n",
    "print(sentences[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>we could also change the release and the attack</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CD</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>this is a graph of a function the input to thi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CM</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>so,we would like the height to be less than or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EX</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>what are the critical points of this function</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SM</th>\n",
       "      <td>201</td>\n",
       "      <td>201</td>\n",
       "      <td>the input change by some factor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentence                                                               \n",
       "         count unique                                                top freq\n",
       "Label                                                                        \n",
       "AP         198    198   we could also change the release and the attack     1\n",
       "CD         201    201  this is a graph of a function the input to thi...    1\n",
       "CM         201    201  so,we would like the height to be less than or...    1\n",
       "EX         200    200     what are the critical points of this function     1\n",
       "SM         201    201                   the input change by some factor     1"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.groupby('Label').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Label                                           Sentence  length\n",
      "0    CM         however,let's talk about the inputs first       42\n",
      "1    SM        that's the fundamental theorem of calculus       43\n",
      "2    EX  these are two places where the derivative is e...      59\n",
      "3    CM                               let's get rid of it       20\n",
      "4    AP  you can use OMITTED it's always smooth,if you ...     107\n",
      "\n",
      "\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Quantity')"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x162a1d292b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentences['length'] = sentences['Sentence'].map(lambda text: len(text))\n",
    "print(sentences.head())\n",
    "\n",
    "sentences.length.plot(bins=20, kind='hist')\n",
    "\n",
    "print(\"\\n\")\n",
    "sentences.length.describe()\n",
    "print(list(sentences.Sentence[sentences.length > 500]))\n",
    "\n",
    "#sentences.hist(column='length', by='Label', bins='auto',figsize=(10, 15), color=\"c\")\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Quantity')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [however, let, 's, talk, about, the, inputs, f...\n",
       "1       [that, 's, the, fundamental, theorem, of, calc...\n",
       "2       [these, are, two, places, where, the, derivati...\n",
       "3                             [let, 's, get, rid, of, it]\n",
       "4       [you, can, use, OMITTED, it, 's, always, smoot...\n",
       "5                      [the, graph, is, always, wiggling]\n",
       "6       [if, we, knew, where, those, degrees, were, gr...\n",
       "7       [a, processing, element, is, a, digital, devic...\n",
       "8       [let, 's, examine, the, minimum, ram, and, rom...\n",
       "9                       [what, happens, at, the, bounces]\n",
       "10      [but, maybe, it, 's, not, a, trick, because, i...\n",
       "11      [music, we, 've, seen, df/OMITTED, and, we, 'v...\n",
       "12      [that, 's, the, sense, in, which, the, instant...\n",
       "13      [and, then, you, have, to, figure, out, the, p...\n",
       "14      [when, the, ball, leaves, my, hand, it, 's, go...\n",
       "15      [this, means, that, the, data, should, be, in,...\n",
       "16      [finally, it, 's, just, a, matter, of, evaluat...\n",
       "17      [all, i, can, really, do, is, figure, out, the...\n",
       "18      [week, six, has, got, a, bunch, of, small, tes...\n",
       "19      [and, that, 's, just, when, OMITTED, is, equal...\n",
       "20      [so, the, first, thing, we, need, to, learn, i...\n",
       "21      [when, it, 's, just, to, the, top, of, its, tr...\n",
       "22      [then, this, formula, would, be, telling, you,...\n",
       "23      [finally, the, system, may, have, some, applic...\n",
       "24      [you, not, only, have, to, pick, a, u, but, yo...\n",
       "25                    [let, 's, find, an, antiderivative]\n",
       "26      [we, want, to, fill, the, array, which, is, NU...\n",
       "27      [what, we, need, to, do, is, to, read, those, ...\n",
       "28      [you, also, need, to, describe, the, standards...\n",
       "29      [we, 've, also, had, the, sudden, change, of, ...\n",
       "                              ...                        \n",
       "971     [if, you, do, n't, know, or, remember, why, co...\n",
       "972               [and, then, it, started, slowing, down]\n",
       "973     [we, 're, using, the, idea, of, limits, to, co...\n",
       "974     [but, instead, of, using, map, i, 'm, just, do...\n",
       "975     [it, 's, called, waveform, and, we, 're, writi...\n",
       "976     [so, let, 's, start, with, what, 's, called, a...\n",
       "977     [so, we, working, on, the, interval, from, to,...\n",
       "978     [but, not, just, play, them, as, they, are, we...\n",
       "979     [i, hope, to, see, you, in, the, next, videos,...\n",
       "980     [by, using, this, bisection, method, and, an, ...\n",
       "981     [let, 's, evaluate, the, integral, of, NUMBER,...\n",
       "982     [next, we, have, protected, health, informatio...\n",
       "983     [then, what, we, 're, also, going, to, test, i...\n",
       "984     [at, the, end, of, this, whole, process, the, ...\n",
       "985     [here, in, this, example, the, function, 's, d...\n",
       "986     [and, i, sort, of, know, that, i, must, be, st...\n",
       "987     [our, first, inclination, might, be, to, try, ...\n",
       "988     [to, answer, this, question, you, should, desc...\n",
       "989     [from, planning, a, project, to, collecting, y...\n",
       "990     [NUMBER, squared, say, is, NUMBER, alright, so...\n",
       "991                                    [so, let, 's, see]\n",
       "992     [yeah, the, next, step, is, to, list, the, cri...\n",
       "993     [the, bigger, the, community, is, the, more, l...\n",
       "994                          [and, here, 's, an, example]\n",
       "995     [let, 's, first, think, about, when, the, deri...\n",
       "996     [pdf, for, example, has, become, the, de, fact...\n",
       "997     [and, i, know, the, function, 's, got, a, loca...\n",
       "998     [again, if, privacy, concerns, affect, your, a...\n",
       "999     [well, i, 'm, going, to, draw, a, little, tiny...\n",
       "1000    [i, know, the, function, 's, decreasing, here,...\n",
       "Name: Sentence, Length: 1001, dtype: object"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split a sent into its individual words\n",
    "def split_into_tokens(sent):\n",
    "    #sent = unicode(sent, 'utf8')  # convert bytes into proper unicode\n",
    "    return TextBlob(sent).words\n",
    "\n",
    "sentences.Sentence.apply(split_into_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [however, let, 's, talk, about, the, input, fi...\n",
       "1    [that, 's, the, fundamental, theorem, of, calc...\n",
       "2    [these, are, two, place, where, the, derivativ...\n",
       "3                          [let, 's, get, rid, of, it]\n",
       "4    [you, can, use, OMITTED, it, 's, always, smoot...\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-processing\n",
    "def split_into_lemmas(sent):\n",
    "    words = TextBlob(sent).words\n",
    "    # for each word, take its \"base form\" = lemma \n",
    "    return [word.lemma for word in words]\n",
    "\n",
    "sentences.Sentence.head().apply(split_into_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1938\n"
     ]
    }
   ],
   "source": [
    "# Data to vectors\n",
    "\n",
    "# convert each message, represented as a list of tokens (lemmas) above, \n",
    "# into a vector that machine learning models can understand\n",
    "\n",
    "bow_transformer = CountVectorizer(analyzer=split_into_lemmas).fit(sentences['Sentence'])\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nr of features:  1938\n",
      "Nr of features after cleaning:  1889\n"
     ]
    }
   ],
   "source": [
    "#message1000 = sentences['Sentence'][999]\n",
    "#print(message1000)\n",
    "#\n",
    "#bow1000 = bow_transformer.transform([message1000])\n",
    "#print(bow1000)\n",
    "#print(bow1000.shape)\n",
    "#print(\"OMITTED appears 3 times, i appears twice etc\")\n",
    "\n",
    "featureList = bow_transformer.get_feature_names()\n",
    "finalFeatureList = []\n",
    "\n",
    "def removeNumsFromFeatureList(featureList):\n",
    "    isNum = re.compile(\"[0-9]\")\n",
    "    hasApostrophe = re.compile(\"'\\w+\")\n",
    "        \n",
    "    for feat in featureList:\n",
    "        if isNum.match(feat): pass\n",
    "        elif hasApostrophe.match(feat): pass\n",
    "        elif \"OMITTED\" in feat.upper(): pass\n",
    "        elif \"NUMBER\" in feat.upper(): pass\n",
    "        elif (\"-\" or \"+\") in feat.upper(): pass\n",
    "        else: finalFeatureList.append(feat)\n",
    "\n",
    "print(\"Nr of features: \",len(featureList))\n",
    "removeNumsFromFeatureList(featureList)\n",
    "print(\"Nr of features after cleaning: \",len(finalFeatureList))\n",
    "\n",
    "#print(bow_transformer.get_feature_names()[5214])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (1001, 1938)\n",
      "number of non-zeros: 14731\n",
      "sparsity: 0.76%\n",
      "(1001, 1938)\n"
     ]
    }
   ],
   "source": [
    "sentences_bow = bow_transformer.transform(sentences['Sentence'])\n",
    "print('sparse matrix shape:', sentences_bow.shape)\n",
    "print('number of non-zeros:', sentences_bow.nnz)\n",
    "print('sparsity: %.2f%%' % (100.0 * sentences_bow.nnz / (sentences_bow.shape[0] * sentences_bow.shape[1])))\n",
    "\n",
    "#after the counting, the term weighting and normalization can be done with TF-IDF, using scikit-learn's TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer().fit(sentences_bow)\n",
    "#tfidf1000 = tfidf_transformer.transform(bow1000)\n",
    "#print(tfidf1451)\n",
    "\n",
    "# To transform the entire bag-of-words corpus into TF-IDF corpus at once:\n",
    "sentences_tfidf = tfidf_transformer.transform(sentences_bow)\n",
    "print(sentences_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN THE CLASSIFIER!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.99 ms\n"
     ]
    }
   ],
   "source": [
    "# Using Multinomial Naive Bayes classifier\n",
    "%time label_classifier = MultinomialNB().fit(sentences_tfidf, sentences['Label'].fillna(\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('Predicted:', label_classifier.predict(tfidf1000)[0])\n",
    "#print('Actual:', sentences.Label[999])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========Confusion matrix=========\n",
      " [[163  11   2  13   9]\n",
      " [  0 178   0  16   7]\n",
      " [ 10  14 155   7  15]\n",
      " [  6  14   0 174   6]\n",
      " [  4   7   1  12 177]]\n",
      "(row=Actual, col=Predicted)\n",
      "\n",
      "_______________Multinomial Naive Bayes________________\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "         AP       0.89      0.82      0.86       198\n",
      "         CD       0.79      0.89      0.84       201\n",
      "         CM       0.98      0.77      0.86       201\n",
      "         EX       0.78      0.87      0.82       200\n",
      "         SM       0.83      0.88      0.85       201\n",
      "\n",
      "avg / total       0.86      0.85      0.85      1001\n",
      "\n",
      "Accuracy:\t 0.85\n",
      "______________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_predictions = label_classifier.predict(sentences_tfidf)\n",
    "#print(all_predictions)\n",
    "\n",
    "print('\\n========Confusion matrix=========\\n', confusion_matrix(sentences['Label'].fillna(\"\"), all_predictions))\n",
    "print('(row=Actual, col=Predicted)')\n",
    "\n",
    "print(\"\\n_______________Multinomial Naive Bayes________________\\n\")\n",
    "print(classification_report(sentences['Label'].fillna(\"\"), all_predictions))\n",
    "print('Accuracy:\\t {0:.2f}'.format(accuracy_score(sentences['Label'].fillna(\"\"), all_predictions)))\n",
    "print(\"______________________________________________________\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
