{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How do researchers deal with it:\n",
    "- [Word embeddings Wiki](https://en.wikipedia.org/wiki/Word_embedding)\n",
    "- [Gensim Python library](https://en.wikipedia.org/wiki/Gensim)\n",
    "- [Word embeddings]()\n",
    "- [Inference Rules]()\n",
    "\n",
    "### LSTM: \n",
    "- [Long-Short term memory (LSTM)](https://www.datacamp.com/community/tutorials/lstm-python-stock-market#lstm)\n",
    "- [Learn via example](https://iamtrask.github.io/2015/11/15/anyone-can-code-lstm/)\n",
    "\n",
    "### Literature:\n",
    "- [Intent extraction from social media texts using sequential segmentation and deep learning models](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8119461) uses CRFs and Bi-LSTM for intent extraction from texts from social media in 2 categories - Cosmetics and Tourism. Look into these algos\n",
    "    - Citation: \n",
    "`@INPROCEEDINGS{8119461, \n",
    "author={T. L. Luong and M. S. Cao and D. T. Le and X. H. Phan}, \n",
    "booktitle={2017 9th International Conference on Knowledge and Systems Engineering (KSE)}, \n",
    "title={Intent extraction from social media texts using sequential segmentation and deep learning models}, \n",
    "year={2017}, \n",
    "pages={215-220}, \n",
    "doi={10.1109/KSE.2017.8119461}, \n",
    "month={Oct},}`\n",
    "\n",
    "\n",
    "- In [Semantic Indexing for Recorded Educational Lecture Videos](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=1598977) they extracted scripts from videos with timestamps on each word and cluster them in order to allow for finding of the exact position of a particular thing in the video. They also use a retrieval method to find “example”, “explanation”, “overview”, “repetition”, “exercise” for a particular word or topic word. \n",
    "    - Citation: `@INPROCEEDINGS{1598977, \n",
    "author={S. Repp and M. Meinel}, \n",
    "booktitle={Fourth Annual IEEE International Conference on Pervasive Computing and Communications Workshops (PERCOMW'06)}, \n",
    "title={Semantic indexing for recorded educational lecture videos}, \n",
    "year={2006}, \n",
    "pages={5 pp.-245}, \n",
    "month={March},}`\n",
    "\n",
    "\n",
    "- In [Olex: Effective Rule Learning for Text Categorization](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4641927) Sees the problem as a text classification task and applied Inference Rules onto it. Not particularly for intent mining, but for different categories, similar to what I have. The inference rules are of the form: \\begin{equation}If \\space T_1 \\space or \\space \\dots \\space T_n \\space occurs \\space in \\space document \\space d,\\space and \\space none \\space of \\space T_{n+1} \\dots T_{n+m} \\space occurs \\space in \\space d, \\space then \\space classify \\space d \\space under \\space category \\space C \\end{equation}  This includes `one` positive literal and `0+` negative literals and temrs are `n-grams`\n",
    "\n",
    "    - Citation `@ARTICLE{4641927, \n",
    "author={P. Rullo and V. L. Policicchio and C. Cumbo and S. Iiritano}, \n",
    "journal={IEEE Transactions on Knowledge and Data Engineering}, \n",
    "title={Olex: Effective Rule Learning for Text Categorization}, \n",
    "year={2009}, \n",
    "volume={21}, \n",
    "number={8}, \n",
    "pages={1118-1132}, \n",
    "doi={10.1109/TKDE.2008.206}, \n",
    "ISSN={1041-4347}, \n",
    "month={Aug},}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.5",
   "language": "python",
   "name": "python3.5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
