{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m ipykernel install --user --name Python3.5\n",
    "\n",
    "Ref: https://stackoverflow.com/questions/39007571/running-jupyter-with-multiple-python-and-ipython-paths/39022003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\a.dimitrova\\Desktop\\Course data Thesis\\clustering\"\n",
    "\n",
    "texts = []\n",
    "counter = 0\n",
    "\n",
    "# DOCUMENT LIST CONSISTS OF TEXTBLOB files. All input files need to be converted to TEXTBLOB \n",
    "# and then saved in this list in order for TF-IDF to work\n",
    "doclist = []\n",
    "\n",
    "for root, subdirs, files in os.walk(path):\n",
    "\n",
    "    for curFile in os.listdir(root):\n",
    "\n",
    "        filePath = os.path.join(root, curFile)\n",
    "\n",
    "        if os.path.isdir(filePath):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            try: \n",
    "                text = \"\"\n",
    "                curFile = open(filePath, 'r', encoding = \"ISO-8859-1\") #IMPORTANT ENCODING! UTF8 DOESN'T WORK\n",
    "                fileExtRemoved = os.path.splitext(os.path.abspath(filePath))[0]\n",
    "                \n",
    "                sentences = curFile.read().split(\"\\n\")\n",
    "                for sent in sentences:\n",
    "                    text += sent+\"\\n\"\n",
    "                \n",
    "                texts.append(text)\n",
    "\n",
    "            finally: \n",
    "                curFile.close()\n",
    "\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ['000', '1d', '20', '2d', '3d', '70', 'abstractions', 'accelerating', 'acceleratio', 'acceleration', 'according', 'actual', 'actually', 'add', 'additional', 'adn', 'advantage', 'aggregation', 'allow', 'anonymization', 'apparently', 'applying', 'approximations', 'aren', 'arguably', 'aspect', 'assign', 'atomaton', 'attitude', 'automata', 'automaton', 'avoid', 'avoidance', 'avoids', 'away', 'ax', 'ball', 'bar', 'based', 'basic', 'begin', 'behaved', 'behavior', 'believe', 'belongs', 'better', 'beware', 'big', 'bit', 'body', 'bounce', 'bounces', 'break', 'bt', 'bu', 'build', 'building', 'buildings', 'bunch', 'buy', 'c1', 'c2', 'called', 'cancel', 'capture', 'captures', 'car', 'care', 'case', 'cases', 'catch', 'categorization', 'caused', 'celsius', 'center', 'change', 'changes', 'changing', 'character', 'chart', 'cheap', 'check', 'checks', 'choice', 'choices', 'circle', 'citation', 'claim', 'class', 'clearly', 'close', 'closest', 'coded', 'coding', 'collected', 'come', 'comfortable', 'compact', 'completed', 'complicated', 'component', 'compression', 'computed', 'concludes', 'condition', 'conditions', 'confidential', 'configuration', 'consider', 'contain', 'continuous', 'control', 'controlling', 'converting', 'convince', 'cool', 'cooling', 'copies', 'copy', 'corner', 'corresponds', 'cough', 'course', 'craft', 'current', 'cuz', 'cx', 'danger', 'data', 'dealing', 'decide', 'definitely', 'degrees', 'denominator', 'derivative', 'derivatives', 'deserves', 'design', 'designing', 'desired', 'desk', 'details', 'develop', 'developed', 'developing', 'did', 'didn', 'different', 'differential', 'dimension', 'dimensional', 'dimensions', 'direction', 'directions', 'discrete', 'discussion', 'display', 'distance', 'distribution', 'disturb', 'documentation', 'doesn', 'doing', 'don', 'dot', 'dots', 'double', 'downshift', 'driving', 'dropping', 'dynamic', 'dynamical', 'dynamics', 'earlier', 'earth', 'easier', 'easiest', 'easing', 'effecting', 'effective', 'effectively', 'elegant', 'encoded', 'encodes', 'encourage', 'end', 'energy', 'enters', 'entry', 'epsilon', 'epsilons', 'equal', 'equation', 'equilibrious', 'es', 'especially', 'evolving', 'exactly', 'example', 'examples', 'excess', 'excuse', 'experiencing', 'exploration', 'expressive', 'fact', 'factor', 'fahrenheit', 'far', 'fifth', 'file', 'files', 'finally', 'fine', 'finite', 'force', 'forced', 'forces', 'form', 'format', 'formats', 'frame', 'fsubq', 'fully', 'g12', 'g21', 'g23', 'g31', 'gas', 'gear', 'gears', 'general', 'generally', 'gets', 'getting', 'gives', 'glosses', 'goal', 'goes', 'going', 'good', 'gradient', 'gradients', 'graph', 'gravitational', 'gravity', 'greater', 'guard', 'guards', 'guys', 'handle', 'happen', 'happening', 'having', 'heard', 'heater', 'heaters', 'heating', 'help', 'hi', 'hidden', 'hide', 'hiding', 'humanoid', 'hybrid', 'idea', 'immediately', 'impact', 'important', 'include', 'inconsistencies', 'indefinitely', 'individual', 'innocent', 'input', 'inputs', 'inside', 'instance', 'instead', 'insure', 'interacting', 'interested', 'interesting', 'interview', 'introduce', 'introducing', 'invariant', 'involve', 'involving', 'jump', 'jumping', 'jumps', 'just', 'kinds', 'kinetics', 'know', 'larger', 'later', 'learn', 'lecture', 'let', 'lets', 'like', 'line', 'linear', 'lineup', 'little', 'll', 'logic', 'look', 'looking', 'looks', 'loraking', 'loses', 'lot', 'low', 'lower', 'lti', 'lump', 'machine', 'magically', 'make', 'making', 'map', 'mass', 'matrices', 'matrisis', 'matrix', 'matrixes', 'matter', 'matters', 'mean', 'meaning', 'means', 'messing', 'messy', 'methods', 'migrating', 'minor', 'mobile', 'modalities', 'mode', 'model', 'modeled', 'models', 'modes', 'module', 'moment', 'motion', 'moves', 'moving', 'multiple', 'multiplication', 'multiplications', 'multiply', 'naturally', 'need', 'needs', 'new', 'nonsense', 'normalization', 'note', 'notion', 'number', 'numbers', 'numerator', 'object', 'obstacle', 'obstacles', 'occur', 'oh', 'okay', 'old', 'ones', 'operate', 'operation', 'opposed', 'orientations', 'original', 'output', 'outputs', 'paper', 'particular', 'particularly', 'particulars', 'pedal', 'people', 'percentages', 'perform', 'phenomena', 'physical', 'pid', 'pie', 'piece', 'pieces', 'plural', 'plus', 'point', 'position', 'positions', 'possible', 'possibly', 'practice', 'predict', 'pressing', 'previous', 'prime', 'project', 'px', 'py', 'q2', 'qualitative', 'quantitative', 'questionnaires', 'quiet', 'quite', 'radius', 'ran', 'ratios', 'reach', 'reading', 'really', 'reason', 'reasons', 'recommend', 'references', 'reformulation', 'regulators', 'relative', 'relevant', 'remember', 'representations', 'researchers', 'reset', 'resets', 'resources', 'responses', 'return', 'revisit', 'rewritten', 'rich', 'right', 'rigid', 'rm', 'rn', 'robot', 'robotic', 'robotics', 'robots', 'role', 'rosy', 'rotating', 'rpm', 'running', 'safe', 'safely', 'said', 'sanity', 'satellites', 'saw', 'say', 'says', 'second', 'section', 'segment', 'sense', 'sensing', 'sensitive', 'separates', 'set', 'shared', 'shifter', 'shut', 'sign', 'similarly', 'simple', 'simplest', 'simply', 'singular', 'slack', 'slender', 'slight', 'smashing', 'sorry', 'sound', 'space', 'spacecraft', 'spinning', 'stabilize', 'stabilized', 'stable', 'standalone', 'standard', 'start', 'started', 'state', 'states', 'static', 'station', 'step', 'steroids', 'strings', 'stronger', 'study', 'studying', 'subtracting', 'sucking', 'sudden', 'suere', 'sum', 'summarize', 'supposed', 'sure', 'survey', 'sweethearts', 'switch', 'switched', 'switches', 'switching', 'systematic', 'systems', 'taking', 'talk', 'talking', 'tall', 'techniques', 'tell', 'tells', 'temperature', 'textual', 'theory', 'thermostat', 'thing', 'things', 'think', 'thinking', 'threshold', 'time', 'times', 'today', 'topic', 'torque', 'transcripts', 'transform', 'transformation', 'transformations', 'transformed', 'transition', 'transitions', 'translate', 'triple', 'true', 'trust', 'try', 'turn', 'turns', 'type', 'typically', 'typing', 'typos', 'understand', 'unfortunately', 'unlike', 'use', 'used', 'useful', 'usefull', 'using', 'usually', 'ux', 'value', 'values', 'variabl', 'variable', 'variables', 'variant', 've', 'vector', 'velocity', 'visualize', 'voila', 'want', 'warm', 'way', 'ways', 'weighs', 'welcome', 'whoop', 'wish', 'won', 'wonderful', 'words', 'work', 'worked', 'works', 'world', 'writ', 'write', 'writing', 'written', 'writting', 'wrong', 'x1', 'x2', 'x3', 'x4', 'xdot', 'zero']\n",
      "centers: [[0.01910363 0.         0.05731088 ... 0.         0.09551813 0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.06915524]\n",
      " [0.         0.01690157 0.         ... 0.01690157 0.         0.06662697]]\n",
      "labels [3 2 1 0]\n",
      "intertia: -2.55351295663786e-15\n",
      "Top words per cluster:\n",
      "Cluster: 0 texts: 1\n",
      "\tgoing\n",
      "\tstate\n",
      "\tmode\n",
      "\tguard\n",
      "\tjump\n",
      "\tway\n",
      "\tswitch\n",
      "\tgoal\n",
      "\tgear\n",
      "\tbehavior\n",
      "Cluster: 1 texts: 1\n",
      "\tdata\n",
      "\ttransformations\n",
      "\texample\n",
      "\tmodule\n",
      "\ttransformation\n",
      "\ttransform\n",
      "\tresponses\n",
      "\tnumber\n",
      "\tanonymization\n",
      "\twish\n",
      "Cluster: 2 texts: 1\n",
      "\tgravity\n",
      "\tspacecraft\n",
      "\tgradient\n",
      "\tforce\n",
      "\tattitude\n",
      "\ttorque\n",
      "\tobject\n",
      "\tdifferent\n",
      "\tlook\n",
      "\tdistribution\n",
      "Cluster: 3 texts: 1\n",
      "\tdot\n",
      "\tx2\n",
      "\tgoing\n",
      "\tx1\n",
      "\tmatrix\n",
      "\tactually\n",
      "\twrite\n",
      "\tsystems\n",
      "\tsimply\n",
      "\tdimensional\n",
      "\n",
      "\n",
      "Prediction\n",
      "what we saw in the previous lecture was  how to model switch systems in a rather  general way using these things called  hybrid automaton.\n",
      "today, i want to show that just because  we know how to design good linear time  invariant controllers and we know how to  draw a hybrid automaton, doesn't mean  that we can just say, [sound] we're done,  we can do everything we want to be able  to do.\n",
      "in fact, what i want to do today is talk  to you about a rather famous counter  example that makes thinngs hard when  you're in the hybrid world.\n",
      "Cluster: 0 texts: 2\n",
      "\tgoing\n",
      "\tstate\n",
      "\tmode\n",
      "\tguard\n",
      "\tjump\n",
      "\tway\n",
      "\tswitch\n",
      "\tgoal\n",
      "\tgear\n",
      "\tbehavior\n"
     ]
    }
   ],
   "source": [
    "#example from online\n",
    "\n",
    "\"\"\"\n",
    "texts = [\"This first text talks about houses and dogs\",\n",
    "        \"This is about airplanes and airlines\",\n",
    "        \"This is about dogs and houses too, but also about trees\",\n",
    "        \"Trees and dogs are main characters in this story\",\n",
    "        \"This story is about batman and superman fighting each other\", \n",
    "        \"Nothing better than another story talking about airplanes, airlines and birds\",\n",
    "        \"Superman defeats batman in the last round\"]\n",
    "\"\"\"\n",
    "\n",
    "# vectorization of the texts\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(texts)\n",
    "# used words (axis in our multi-dimensional space)\n",
    "words = vectorizer.get_feature_names()\n",
    "print(\"words\", words)\n",
    "\n",
    "\n",
    "n_clusters = 4\n",
    "number_of_seeds_to_try= 10\n",
    "max_iter = 300\n",
    "number_of_process=2 # seads are distributed\n",
    "model = KMeans(n_clusters=n_clusters, max_iter=max_iter, n_init=number_of_seeds_to_try, n_jobs=number_of_process).fit(X)\n",
    "\n",
    "labels = model.labels_\n",
    "# indices of preferible words in each cluster\n",
    "ordered_words = model.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print(\"centers:\", model.cluster_centers_)\n",
    "print(\"labels\", labels)\n",
    "print(\"intertia:\", model.inertia_)\n",
    "\n",
    "texts_per_cluster = numpy.zeros(n_clusters)\n",
    "for i_cluster in range(n_clusters):\n",
    "    for label in labels:\n",
    "        if label==i_cluster:\n",
    "            texts_per_cluster[i_cluster] +=1 \n",
    "\n",
    "print(\"Top words per cluster:\")\n",
    "for i_cluster in range(n_clusters):\n",
    "    print(\"Cluster:\", i_cluster, \"texts:\", int(texts_per_cluster[i_cluster])),\n",
    "    for term in ordered_words[i_cluster, :10]:\n",
    "        print(\"\\t\"+words[term])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "text_to_predict = \"\"\"what we saw in the previous lecture was  how to model switch systems in a rather  general way using these things called  hybrid automaton.\n",
    "today, i want to show that just because  we know how to design good linear time  invariant controllers and we know how to  draw a hybrid automaton, doesn't mean  that we can just say, [sound] we're done,  we can do everything we want to be able  to do.\n",
    "in fact, what i want to do today is talk  to you about a rather famous counter  example that makes thinngs hard when  you're in the hybrid world.\"\"\"\n",
    "Y = vectorizer.transform([text_to_predict])\n",
    "predicted_cluster = model.predict(Y)[0]\n",
    "texts_per_cluster[predicted_cluster]+=1\n",
    "\n",
    "print(text_to_predict)\n",
    "print(\"Cluster:\", predicted_cluster, \"texts:\", int(texts_per_cluster[predicted_cluster])),\n",
    "for term in ordered_words[predicted_cluster, :10]:\n",
    "    print(\"\\t\"+words[term])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
