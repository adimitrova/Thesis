{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Plan of action\n",
    "- grab sentence by sentence file\n",
    "- split each sentence in n-grams (1-2-3-4)\n",
    "- compare n-grams with dictionary\n",
    "- if n-gram is contained in any of the dictionaries, grab the whole sentence and mark is as the respective \\_\\_label\\_\\_='whatever'\n",
    "    - if more than one label can be assigned, assign them both\n",
    "    - if a label is already assigned, assign the next one too and raise a message\n",
    "- compare sentences, if they contain equivalent labels, merge them into a paragraph and put the label on it. Do until we reach a sentence with a different labels\n",
    "\n",
    "This will be the training data\n",
    "\n",
    "Test data will be 2-3 more courses I will find in sourcera and split the same way as my current data, \n",
    "will learn a classifier with it and try to classify them\n",
    "\n",
    "### Whats and Whys\n",
    "- ***Overall goal***: to create a labeled training set, but not by evaluating it manually more than selecting terms to look for\n",
    "- ***N-gram extraction***: To help find the dictionary terms\n",
    "- ***Keywords extraction from title***: to help figure out the main topic of the LO\n",
    "\n",
    "##### Next steps\n",
    "* After finding and matching the n-grams as per sentences, I will add the respective label to the end of the sentence with a comma before. \n",
    "* Then will split each sentence by these commas and save into a list. \n",
    "* Then if a sentence has one item in the list, i.e. only sentence, that means it will have no label. If it has 2 elements in the list, that means it has one label if it has 3 elements - 2 labels etc. \n",
    "    * if it has no label - adopt the label that the first sentence above it has, go from that sentence up until a label is found and assign it\n",
    "        * if the sentence above has one label, adopt it\n",
    "        * if 2 labels - do nothing\n",
    "    * if one label - good\n",
    "    * if 2 labels - manual check and leave one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Dictionary terms for my 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conceptdescr_dict = ['this research','refers to','last but not least','number one',\n",
    "                     'number two','number three','drawback','advantages',\n",
    "                     'disadvantages','benefits','drawbacks','defined',\n",
    "                     'there are many types','important to understand',\n",
    "                     'let\\'s look at','when we use the term','imagine that',\n",
    "                     'refers to as','key concepts','this is a term','more specifically',\n",
    "                     'helps to','is used to','makes it easier to',\n",
    "                     'provide information about','when talking about','critical to understand',\n",
    "                     'let\\'s take a look at','what is','crucial','can be used to','ensures',\n",
    "                     'rule of thumb','consider','last but not least','topic of this',\n",
    "                     'topic of today','one way to','another possibility is',\n",
    "                     'next one is','problem','to address','want to do','different ways',\n",
    "                     'approach is to','tries to','try to','topic is','method','task',\n",
    "                     'in this way','we specify','by combining','results']\n",
    "\n",
    "conceptmention_dict = ['called','use the term','more specifically','this includes',\n",
    "                       'activities surrounding','show you','additionally','should include',\n",
    "                       'types of','recommends','known as','known for','advantages to',\n",
    "                       'disadvantages to','benefits','drawbacks','plays a key role',\n",
    "                       'refers to as','first one is','we introduce','techniques',\n",
    "                       'second one is','traditional','method','-based']\n",
    "\n",
    "application_dict = ['best practices','best practice','means that','practical benefit',\n",
    "                    'sorts of things','good practices','best to','you should','you shouldn\\'t',\n",
    "                    'may find that','can use','this is important','particularly importnant',\n",
    "                    'is why','useful to','recommended that','consider','useful to']\n",
    "\n",
    "example_dict = ['example','there are many','many types','include','can see','hands on',\n",
    "                'includes','exemplar','prototype','sample','case','illustration','analogy',\n",
    "                'let\\'s think of','may want to','some of','most of','different types of',\n",
    "                'e.g.','for example','key aspects','key concepts','in other words',\n",
    "                'of these are','of them are','rather than','such as','pros and cons',\n",
    "                'a long list','various','for instance','it\\'s like','different ways',\n",
    "                'tried to','instead of']\n",
    "\n",
    "summary_dict = ['by the end of','as you know','have a good understanding','will begin by',\n",
    "                'will cover','well delve','will discuss','will be able to','will understand',\n",
    "                'to summarize','summary','take away','to conclude','as you know','introduced',\n",
    "                'be aware','we\\'ve looked at','last week we discussed','discuss how to',\n",
    "                'will describe','the goal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Import all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import all necessary modules for EVERYTHING here\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import string\n",
    "import time\n",
    "\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-based __label__=example\n"
     ]
    }
   ],
   "source": [
    "# 1,2,3,4 grams\n",
    "\n",
    "\"\"\"\n",
    "search for part of string in a string as:\n",
    "\n",
    "searchFor = 'THIS'.lower()\n",
    "for item in conceptmention_dict:\n",
    "    if searchFor in item:\n",
    "        print(\"found \\\"{}\\\" in \\\"{}\\\"\".format(searchFor,item))\n",
    "   \n",
    "just as a caution, if you have a string \"paratyphoid is bad\" \n",
    "and you do a if \"typhoid\" in \"paratyphoid is bad\" you will get a true\n",
    "\"\"\"\n",
    "\n",
    "searchFor = 'based'.lower()\n",
    "\n",
    "for item in conceptmention_dict:\n",
    "    if searchFor in item:\n",
    "        print(item+\" __label__=example\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Trying to find n-grams in the dictionary\n",
    "\n",
    "- Very unsure with monograms - lots of matches with simple stopwords, some of them make sense, but very few.\n",
    "- Very little found with trigrams, but if found - it's good\n",
    "- Bigrams should work good, but not too good\n",
    "- Tetragrams give no result whatsoever, also because there are very few items in the dictionaries that have 4 words to match with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dummy text to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### WITHOUT STOP WORDS\n",
    "\n",
    "textnoSW = \"\"\"music hello 'm good to see back our course \n",
    "before start with this video let me remind what has been covered earlier videos \n",
    "by should have an idea of what an embedded processor how it works \n",
    "should also be familiar with features of an embedded processor \n",
    "must remind again this course make emphasis on microcontrollers \n",
    "therefore large field of embedded processors reduced to only microcontrollers \n",
    "after learn about microcontrollers next step would be to somehow put your hands on them start actually working with them \n",
    "one way to do so to buy microcontroller breadboard set of resistors capacitors wires whatever else necessary to build proper electrical circuits assemble all circuits by yourself on breadboard \n",
    "well it does n't sound cool because it 's long process \n",
    "know there always one resistor need missing end there will be little motivation to continue playing with microcontrollers \n",
    "luckily there another option to buy ready made platform with mounted microcontroller to start working with it immediately \n",
    "this video 're going to talk about these platforms \n",
    "let 's start with arduino \n",
    "arduino widely known platform for fast prototyping \n",
    "platform uses atmel microcontrollers at its core \n",
    "overall there are about 24 boards available \n",
    "on website can find them organized according to application areas such as internet of things wearable others \n",
    "besides boards there are many shields built specifically for our arduino devices \n",
    "functionality of these shields vary lot \n",
    "for example with an mp3 shield can build your own mp3 player if need one \n",
    "wi-fi shield great tool to build applications let 's say domain of internet of things \n",
    "joystick shield suitable for control purposes \n",
    "so if want to extend functionality of board your application can plug shield \n",
    "luckily it can easily be done thanks to sockets installed arduino \n",
    "arduino also provides its own integrated development environment for software development which easy to use really speeds up development process \n",
    "second platform would like to mention stm nucleo platform \n",
    "at its core there are stx complex cortex microcontrollers from m0 to m4 \n",
    "so can choose here between speed energy consumption \n",
    "boards also have extension connectors connectors are compatible with arduino shields which very convenient \n",
    "also there so-called morpho connector for other kind of shields \n",
    "very convenient feature of this platform programmer/debugger mounted on board \n",
    "there an online id available for this platform as well as whole set of tools including operating system tools developer ecosystem for building internet of things solutions \n",
    "offline ides are also available \n",
    "they are more complex than arduino 's one but they give more freedom to developer \n",
    "would say this platform for more experienced users \n",
    "here mentioned two kinds of general purpose platforms can be extended with help of shields to target some specific areas \n",
    "there are of course more platforms available on market \n",
    "some of them target one specific area might not be extensible \n",
    "so there legit question might have \n",
    "how do select certain platform from this diversity \n",
    "first of all choice obviously should be application-oriented \n",
    "for example if want to do some digital signal processing might want to use microcontroller supports some dsp operations \n",
    "if need high computational power then cortex m4 or cortex m3 microcontrollers would suit well since they have highest clock frequency among previous mentioned mcus \n",
    "therefore your choice would be either arduino due or stm nuclear cortex m4 m3 \n",
    "if small size crucial for there no need of high performance then probably want to check arduino micro \n",
    "it also important to consider platforms are interchangeable sense same application can be implemented on two different platforms \n",
    "something would like to emphasize community crucial when it comes to choosing platform \n",
    "bigger community more likely problems might face have already been solved by someone else which case can probably find answer internet \n",
    "would like to show real project was implemented using microcontrollers \n",
    "it metering system \n",
    "imagine have tube there some liquid flowing through tube \n",
    "goal of system to measure liquid 's flow speed \n",
    "since know size of tube need to calculate volume of liquid during time interval \n",
    "finally need to store those measurements memory \n",
    "what more device should have user interface like keyboard small screen \n",
    "so where to start \n",
    "well start by dividing tasks two components metering unit control unit \n",
    "next thing to do would be to decide how to measure liquid flow speed \n",
    "this can be done using ultrasound \n",
    "need to emit an ultrasonic sound receive it back do some spectral analysis to estimate liquid flow speed \n",
    "do n't worry if do n't understand what spectral analysis \n",
    "here what want to show approach \n",
    "so need to do some digital signal processing to get liquid flow speed \n",
    "after get those measurements do some simple averaging finally store those processed measurements \n",
    "okay so have set of tasks signal processing averaging storing user interface \n",
    "it would make sense to map set of tasks onto two microcontrollers \n",
    "let 's say signal processing will be done on mcu 1 will call this part metering unit \n",
    "other tasks will run on control unit which will be implemented on mcu2 \n",
    "both parts will be connected together using uart interface \n",
    "since mcu1 does spectral analysis cortex m4 microcontroller would suit well since it has dsp extensions \n",
    "will also need an adc to sample ultrasonic signal \n",
    "on other hand mcu2 does not need to support dsp operations \n",
    "but it need to be fast enough to communicate with screen keyboard while doing averaging at same time \n",
    "it should have enough pins to work with keyboard at least two uart units to work with screen to communicate with metering unit \n",
    "cortex m3 would fit well \n",
    "it useful to leave some room for expansion \n",
    "this means might want to have some extra functionality to device future \n",
    "therefore selected microcontrollers should have enough resources terms of performance memory \n",
    "finally it important to notice system can be implemented many other ways \n",
    "this video discussed ways on how to actually start working with microcontrollers using platforms \n",
    "hopefully have an idea of how to pick an appropriate platform for your application \n",
    "good luck \n",
    "sound \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## N-GRAM IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### WORKS\n",
    "\n",
    "def get_ngrams(text, n):\n",
    "    n_grams = ngrams(word_tokenize(text), n)\n",
    "    return [ ' '.join(grams) for grams in n_grams]\n",
    "\n",
    "def find_grams_inDict1(gramsList,sentenceList):\n",
    "    sentences = sentenceList\n",
    "    \n",
    "    for gram in gramsList:\n",
    "        for item in conceptdescr_dict:\n",
    "            if gram in item:\n",
    "                print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _ConceptDescription_\".format(gram, item))\n",
    "                \"\"\"\n",
    "                for sent in sentences:\n",
    "                    if gram in sent:\n",
    "                        print(\"\\\" \"+sent+\"\\\"\\n\")\n",
    "                \"\"\"\n",
    "        for item in example_dict:\n",
    "            if gram in item:\n",
    "                print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _Example_\".format(gram, item))\n",
    "                \"\"\"\n",
    "                for sent in sentences:\n",
    "                    if gram in sent:\n",
    "                        print(\"\\\" \"+sent+\"\\\"\\n\")\n",
    "                \"\"\"\n",
    "        for item in conceptmention_dict:\n",
    "            if gram in item:\n",
    "                print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _ConceptMention_\".format(gram, item))\n",
    "                \"\"\"\n",
    "                for sent in sentences:\n",
    "                    if gram in sent:\n",
    "                        print(\"\\\" \"+sent+\"\\\"\\n\")\n",
    "                \"\"\"\n",
    "        for item in application_dict:\n",
    "            if gram in item:\n",
    "                print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _Application_\".format(gram, item))\n",
    "                \"\"\"\n",
    "                for sent in sentences:\n",
    "                    if gram in sent:\n",
    "                        print(\"\\\" \"+sent+\"\\\"\\n\")\n",
    "                \"\"\"\n",
    "        for item in summary_dict:\n",
    "            if gram in item:\n",
    "                print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _Summary_\".format(gram, item))\n",
    "                \"\"\"\n",
    "                for sent in sentences:\n",
    "                    if gram in sent:\n",
    "                        print(\"\\\" \"+sent+\"\\\"\\n\")\n",
    "                \"\"\"\n",
    "\n",
    "                \n",
    "def find_grams_inDict2(gramsList1,gramsList2,sentenceList):\n",
    "    print(\"_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList1,sentenceList)\n",
    "    print(\"\\n_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList2,sentenceList)\n",
    "    \n",
    "\n",
    "def find_grams_inDict3(gramsList1,gramsList2,gramsList3,sentenceList):\n",
    "    print(\"_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList1,sentenceList)\n",
    "    print(\"\\n_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList2,sentenceList)\n",
    "    print(\"\\n_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList3,sentenceList)\n",
    "\n",
    "\"\"\"\n",
    "sentences = textnoSW.split(\"\\n\")\n",
    "MonoGrams = get_ngrams(textnoSW,1)\n",
    "BiGrams = get_ngrams(textnoSW,2)\n",
    "TriGrams = get_ngrams(textnoSW,3)\n",
    "TetraGrams = get_ngrams(textnoSW,4)    # nothing.. senseless\n",
    "\n",
    "#find_grams_inDict1(MonoGrams, sentences)\n",
    "find_grams_inDict2(BiGrams, TriGrams, sentences)\n",
    "#find_grams_inDict3(MonoGrams, BiGrams, TriGrams, sentences)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extracting N-Grams and matching title keywords to real files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def title_extrKeys(curFilePath):\n",
    "    titleinx = len(curFilePath.split(\"\\\\\"))-1\n",
    "    fullTitle = curFilePath.split(\"\\\\\")[titleinx]\n",
    "    \n",
    "    # remove all surrounding stuff like my naming convention etc from the title \n",
    "    mainTitlelist = fullTitle.split(\"_\")\n",
    "    maintitle = mainTitlelist[1]\n",
    "    punct = {'_','-','.'}\n",
    "    finaltitle = \"\"\n",
    "    \n",
    "    # extract the final title, i.e. the main part of the title\n",
    "    for word in maintitle.split():\n",
    "        for letter in word:\n",
    "            if letter in punct:\n",
    "                finaltitle += \" \"\n",
    "                pass\n",
    "            else:\n",
    "                finaltitle += letter\n",
    "    \n",
    "    title_keywords = []\n",
    "    for word in finaltitle.split(\" \"):\n",
    "        if word == 'en':\n",
    "             pass\n",
    "        else:\n",
    "            title_keywords.append(word)\n",
    "    \n",
    "    return title_keywords  # returns a list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<behaviors>> FOUND IN <<so first lecture 're going return this idea of behaviors >>\n",
      "<<behaviors>> FOUND IN <<but actually talked about behaviors before >>\n",
      "<<behaviors>> FOUND IN <<so this really what need do need revisit behaviors context of control failure >>\n",
      "<<behaviors>> FOUND IN <<these are key behaviors always need >>\n",
      "<<behaviors>> FOUND IN <<so our job design these two behaviors using what 've already learned >>\n",
      "<<behaviors>> FOUND IN <<well solution again make dependent on or actually distances so normal e. aviod this being overly cautious are actually going switch between behaviors fact what 're going do using something like induced mode sliding mode very gracefully combine goal goal avoid obstacles but for let me just point out one clever thing for instances say want care more about obstacle closer get so want be bigger closer obstacle get >>\n",
      "<<behaviors>> FOUND IN <<par- particular 've seen these 2 key behaviors goal goal avoid obstacles >>\n",
      "_____________________________________________________________________\n",
      "\n",
      "========= FOUND \"known as\" IN \"known as\" \t|LABEL|\t _ConceptMention_\n",
      "========= FOUND \"of this\" IN \"topic of this\" \t|LABEL|\t _ConceptDescription_\n",
      "========= FOUND \"think of\" IN \"let's think of\" \t|LABEL|\t _Example_\n",
      "========= FOUND \"of this\" IN \"topic of this\" \t|LABEL|\t _ConceptDescription_\n",
      "========= FOUND \"be able\" IN \"will be able to\" \t|LABEL|\t _Summary_\n",
      "========= FOUND \"these are\" IN \"of these are\" \t|LABEL|\t _Example_\n",
      "========= FOUND \"be able\" IN \"will be able to\" \t|LABEL|\t _Summary_\n",
      "========= FOUND \"be able\" IN \"will be able to\" \t|LABEL|\t _Summary_\n",
      "========= FOUND \"be able\" IN \"will be able to\" \t|LABEL|\t _Summary_\n",
      "========= FOUND \"be able\" IN \"will be able to\" \t|LABEL|\t _Summary_\n",
      "========= FOUND \"for instance\" IN \"for instance\" \t|LABEL|\t _Example_\n",
      "========= FOUND \"of this\" IN \"topic of this\" \t|LABEL|\t _ConceptDescription_\n",
      "========= FOUND \"there are\" IN \"there are many types\" \t|LABEL|\t _ConceptDescription_\n",
      "========= FOUND \"there are\" IN \"there are many\" \t|LABEL|\t _Example_\n",
      "========= FOUND \"of these\" IN \"of these are\" \t|LABEL|\t _Example_\n",
      "========= FOUND \"be aware\" IN \"be aware\" \t|LABEL|\t _Summary_\n",
      "========= FOUND \"topic of\" IN \"topic of this\" \t|LABEL|\t _ConceptDescription_\n",
      "========= FOUND \"topic of\" IN \"topic of today\" \t|LABEL|\t _ConceptDescription_\n",
      "========= FOUND \"can see\" IN \"can see\" \t|LABEL|\t _Example_\n",
      "========= FOUND \"of this\" IN \"topic of this\" \t|LABEL|\t _ConceptDescription_\n",
      "========= FOUND \"'s take\" IN \"let's take a look at\" \t|LABEL|\t _ConceptDescription_\n",
      "\n",
      "_____________________________________________________________________\n",
      "\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\ani\\Desktop\\Course data Thesis\\one file\"\n",
    "\n",
    "for root, subdirs, files in os.walk(path):\n",
    "\n",
    "    for curFile in os.listdir(root):\n",
    "\n",
    "        curFilePath = os.path.join(root, curFile)\n",
    "\n",
    "        if os.path.isdir(curFilePath):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            if not curFilePath.endswith(\"_sentNoPunctNoSWTiny.txt\"):\n",
    "                pass\n",
    "            else: \n",
    "                curFile = open(curFilePath, 'r', encoding = \"ISO-8859-1\") #IMPORTANT ENCODING! UTF8 DOESN'T WORK\n",
    "                oFilePath = str(curFilePath.split(\".en\")[0])+\".en_BoWv2Top50.txt\"\n",
    "                \n",
    "                # extract keywords from the title of the file\n",
    "                title_keywords = title_extrKeys(curFilePath)\n",
    "                \n",
    "                # convert the file content into a string variable holding everything there\n",
    "                sentences = curFile.read().split(\"\\n\")\n",
    "                text = \"\"\n",
    "                for sent in sentences:\n",
    "                    text += sent+\"\\n\"\n",
    "                    \n",
    "                # look for title keywords within the text\n",
    "                for keyword in title_keywords:\n",
    "                    for sent in sentences:\n",
    "                        if keyword in sent:\n",
    "                            outp = str(\"<<\"+keyword+\">> FOUND IN <<\"+sent+\">>\").strip()\n",
    "                            print(outp.strip())\n",
    "                    \n",
    "                # extract n-grams\n",
    "                MonoGrams = get_ngrams(text,1)\n",
    "                BiGrams = get_ngrams(text,2)\n",
    "                TriGrams = get_ngrams(text,3)\n",
    "\n",
    "                # look for grams in text\n",
    "                find_grams_inDict2(BiGrams, TriGrams, sentences)\n",
    "                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
