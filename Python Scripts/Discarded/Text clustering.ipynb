{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python -m ipykernel install --user --name Python3.5\n",
    "\n",
    "Ref: https://stackoverflow.com/questions/39007571/running-jupyter-with-multiple-python-and-ipython-paths/39022003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "path = r\"C:\\Users\\a.dimitrova\\Desktop\\Course data Thesis\\clustering\"\n",
    "\n",
    "texts = []\n",
    "counter = 0\n",
    "\n",
    "# DOCUMENT LIST CONSISTS OF TEXTBLOB files. All input files need to be converted to TEXTBLOB \n",
    "# and then saved in this list in order for TF-IDF to work\n",
    "doclist = []\n",
    "\n",
    "for root, subdirs, files in os.walk(path):\n",
    "\n",
    "    for curFile in os.listdir(root):\n",
    "\n",
    "        filePath = os.path.join(root, curFile)\n",
    "\n",
    "        if os.path.isdir(filePath):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            try: \n",
    "                text = \"\"\n",
    "                curFile = open(filePath, 'r', encoding = \"ISO-8859-1\") #IMPORTANT ENCODING! UTF8 DOESN'T WORK\n",
    "                fileExtRemoved = os.path.splitext(os.path.abspath(filePath))[0]\n",
    "                \n",
    "                sentences = curFile.read().split(\"\\n\")\n",
    "                for sent in sentences:\n",
    "                    text += sent+\"\\n\"\n",
    "                \n",
    "                texts.append(text)\n",
    "\n",
    "            finally: \n",
    "                curFile.close()\n",
    "\n",
    "print(len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words ['airlines', 'airplanes', 'batman', 'better', 'birds', 'characters', 'defeats', 'dogs', 'fighting', 'houses', 'main', 'round', 'story', 'superman', 'talking', 'talks', 'text', 'trees']\n",
      "centers: [[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.45718777 0.         0.53486839 0.         0.\n",
      "  0.         0.         0.         0.27983771 0.27983771 0.30257906]\n",
      " [0.54140529 0.54140529 0.         0.22630417 0.22630417 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.16056958 0.         0.22630417 0.         0.         0.        ]\n",
      " [0.         0.         0.47031955 0.         0.         0.\n",
      "  0.27204122 0.         0.29455022 0.         0.         0.27204122\n",
      "  0.20899219 0.47031955 0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.52016297\n",
      "  0.         0.36907117 0.         0.         0.52016297 0.\n",
      "  0.36907117 0.         0.         0.         0.         0.43177993]]\n",
      "labels [0 1 0 3 2 1 2]\n",
      "intertia: 1.5404174117179061\n",
      "Top words per cluster:\n",
      "Cluster: 0 texts: 2\n",
      "\thouses\n",
      "\tdogs\n",
      "\ttrees\n",
      "\ttalks\n",
      "\ttext\n",
      "\tdefeats\n",
      "\tairplanes\n",
      "\tbatman\n",
      "\tbetter\n",
      "\tbirds\n",
      "Cluster: 1 texts: 2\n",
      "\tairlines\n",
      "\tairplanes\n",
      "\ttalking\n",
      "\tbetter\n",
      "\tbirds\n",
      "\tstory\n",
      "\tdogs\n",
      "\tbatman\n",
      "\tcharacters\n",
      "\tdefeats\n",
      "Cluster: 2 texts: 2\n",
      "\tbatman\n",
      "\tsuperman\n",
      "\tfighting\n",
      "\tdefeats\n",
      "\tround\n",
      "\tstory\n",
      "\tairplanes\n",
      "\tbetter\n",
      "\tbirds\n",
      "\tcharacters\n",
      "Cluster: 3 texts: 1\n",
      "\tmain\n",
      "\tcharacters\n",
      "\ttrees\n",
      "\tdogs\n",
      "\tstory\n",
      "\tairplanes\n",
      "\tbatman\n",
      "\tbetter\n",
      "\tbirds\n",
      "\tdefeats\n",
      "\n",
      "\n",
      "Prediction\n",
      "what we saw in the previous lecture was  how to model switch systems in a rather  general way using these things called  hybrid automaton.\n",
      "today, i want to show that just because  we know how to design good linear time  invariant controllers and we know how to  draw a hybrid automaton, doesn't mean  that we can just say, [sound] we're done,  we can do everything we want to be able  to do.\n",
      "in fact, what i want to do today is talk  to you about a rather famous counter  example that makes thinngs hard when  you're in the hybrid world.\n",
      "Cluster: 2 texts: 3\n",
      "\tbatman\n",
      "\tsuperman\n",
      "\tfighting\n",
      "\tdefeats\n",
      "\tround\n",
      "\tstory\n",
      "\tairplanes\n",
      "\tbetter\n",
      "\tbirds\n",
      "\tcharacters\n"
     ]
    }
   ],
   "source": [
    "#example from online\n",
    "\n",
    "\n",
    "texts = [\"This first text talks about houses and dogs\",\n",
    "        \"This is about airplanes and airlines\",\n",
    "        \"This is about dogs and houses too, but also about trees\",\n",
    "        \"Trees and dogs are main characters in this story\",\n",
    "        \"This story is about batman and superman fighting each other\", \n",
    "        \"Nothing better than another story talking about airplanes, airlines and birds\",\n",
    "        \"Superman defeats batman in the last round\"]\n",
    "\n",
    "\n",
    "# vectorization of the texts\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "X = vectorizer.fit_transform(texts)\n",
    "# used words (axis in our multi-dimensional space)\n",
    "words = vectorizer.get_feature_names()\n",
    "print(\"words\", words)\n",
    "\n",
    "\n",
    "n_clusters = 4\n",
    "number_of_seeds_to_try= 10\n",
    "max_iter = 300\n",
    "number_of_process=2 # seads are distributed\n",
    "model = KMeans(n_clusters=n_clusters, max_iter=max_iter, n_init=number_of_seeds_to_try, n_jobs=number_of_process).fit(X)\n",
    "\n",
    "labels = model.labels_\n",
    "# indices of preferible words in each cluster\n",
    "ordered_words = model.cluster_centers_.argsort()[:, ::-1]\n",
    "\n",
    "print(\"centers:\", model.cluster_centers_)\n",
    "print(\"labels\", labels)\n",
    "print(\"intertia:\", model.inertia_)\n",
    "\n",
    "texts_per_cluster = numpy.zeros(n_clusters)\n",
    "for i_cluster in range(n_clusters):\n",
    "    for label in labels:\n",
    "        if label==i_cluster:\n",
    "            texts_per_cluster[i_cluster] +=1 \n",
    "\n",
    "print(\"Top words per cluster:\")\n",
    "for i_cluster in range(n_clusters):\n",
    "    print(\"Cluster:\", i_cluster, \"texts:\", int(texts_per_cluster[i_cluster])),\n",
    "    for term in ordered_words[i_cluster, :10]:\n",
    "        print(\"\\t\"+words[term])\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "text_to_predict = \"\"\"what we saw in the previous lecture was  how to model switch systems in a rather  general way using these things called  hybrid automaton.\n",
    "today, i want to show that just because  we know how to design good linear time  invariant controllers and we know how to  draw a hybrid automaton, doesn't mean  that we can just say, [sound] we're done,  we can do everything we want to be able  to do.\n",
    "in fact, what i want to do today is talk  to you about a rather famous counter  example that makes thinngs hard when  you're in the hybrid world.\"\"\"\n",
    "Y = vectorizer.transform([text_to_predict])\n",
    "predicted_cluster = model.predict(Y)[0]\n",
    "texts_per_cluster[predicted_cluster]+=1\n",
    "\n",
    "print(text_to_predict)\n",
    "print(\"Cluster:\", predicted_cluster, \"texts:\", int(texts_per_cluster[predicted_cluster])),\n",
    "for term in ordered_words[predicted_cluster, :10]:\n",
    "    print(\"\\t\"+words[term])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
