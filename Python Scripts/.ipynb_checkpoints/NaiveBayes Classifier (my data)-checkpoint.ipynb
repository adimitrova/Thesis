{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stevenloria.com/simple-text-classification/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "import random\n",
    "import time\n",
    "\n",
    "allRunsAccuracy = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(r\"C:\\Users\\ani\\Desktop\\Course data Thesis\\Intent Mining ALL files\\allMerged.txt\", 'r', encoding = \"ISO-8859-1\")\n",
    "sentences = file.read().split('\\n')\n",
    "text = \"\"\n",
    "\n",
    "for sent in sentences:\n",
    "    text += sent+\"\\n\"\n",
    "\n",
    "sentences = text.split(\"\\n\")\n",
    "\n",
    "nrsplit = 0\n",
    "textsize = len(sentences)\n",
    "trainTestRatio = round(0.75 * textsize)\n",
    "\n",
    "print(\"#Sent Train: \",trainTestRatio,\" | #Sent Test: \",textsize-trainTestRatio)\n",
    "\n",
    "trainS = []\n",
    "testS = []\n",
    "\n",
    "while not len(sentences) == 0:\n",
    "    nrsplit += 1\n",
    "    if nrsplit <= trainTestRatio:\n",
    "        curLine = random.choice(sentences)\n",
    "        sentences.remove(curLine)\n",
    "        trainS.append(curLine) \n",
    "    elif nrsplit > trainTestRatio:\n",
    "        curLine = random.choice(sentences)\n",
    "        sentences.remove(curLine)\n",
    "        testS.append(curLine) \n",
    "        \n",
    "\n",
    "print(\"Sent: \",len(sentences),\" | Train: \",len(trainS),\" | Test:\",len(testS))   \n",
    "\n",
    "train = []\n",
    "test = []\n",
    "\n",
    "for sent in trainS:\n",
    "    parts = sent.split('|')\n",
    "    if len(parts) > 1:\n",
    "        label = parts[0]\n",
    "        sent = parts[1]\n",
    "        tup = (sent,label)\n",
    "        train.append(tup)\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "for sent in testS:\n",
    "    parts = sent.split('|')\n",
    "    if len(parts) > 1:\n",
    "        label = parts[0]\n",
    "        sent = parts[1]\n",
    "        tup = (sent,label)\n",
    "        test.append(tup)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "### ------------------ END SPLITING TEST / TRAIN with my own data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Takes about 5 min to train and output result PER ITERATION!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ------------------ Naive Bayes train\n",
    "start = time.time()\n",
    "runs = 0\n",
    "\n",
    "while(runs <= 10):  \"\"\" -------- ATTENTION: Nr of Iterations TIMES 5 MIN!!! -------------- \"\"\"\n",
    "    with open(r\"C:\\Users\\ani\\Desktop\\Course data Thesis\\NBayeslog.txt\", \"a\", encoding = \"utf-8\") as oFile:\n",
    "        startIter = time.time()\n",
    "        #bayes = NaiveBayesClassifier(train)\n",
    "\n",
    "        # Compute accuracy\n",
    "        accuracy = bayes.accuracy(test)*100\n",
    "        allRunsAccuracy.append(accuracy)\n",
    "        oFile.write(\"\\nAccuracy: {0:.2f} %\".format(accuracy))\n",
    "        print(\"\\nAccuracy: {0:.2f} %\".format(bayes.accuracy(test)*100))\n",
    "\n",
    "        # Show 50 most informative features\n",
    "        # This cannot be saved in the output file as it return None\n",
    "        bayes.show_informative_features(50)\n",
    "        runs += 1\n",
    "        endIter = time.time()\n",
    "        print(\"iteration execution time: {0:.2f} min\".format((endIter - startIter)/60))\n",
    "        \n",
    "end = time.time()\n",
    "print(\"Runs: \",len(allRunsAccuracy))\n",
    "print(\"Execution time: {0:.2f} min\".format((end - start)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from textblob import TextBlob\n",
    "start = time.time()\n",
    "\n",
    "train = [\n",
    "    ('I love this sandwich.', 'pos'),\n",
    "    ('This is an amazing place!', 'pos'),\n",
    "    ('I feel very good about these beers.', 'pos'),\n",
    "    ('This is my best work.', 'pos'),\n",
    "    (\"What an awesome view\", 'pos'),\n",
    "    ('I do not like this restaurant', 'neg'),\n",
    "    ('I am tired of this stuff.', 'neg'),\n",
    "    (\"I can't deal with this\", 'neg'),\n",
    "    ('He is my sworn enemy!', 'neg'),\n",
    "    ('My boss is horrible.', 'neg')\n",
    "]\n",
    "test = [\n",
    "    ('The beer was good.', 'pos'),\n",
    "    ('I do not enjoy my job', 'neg'),\n",
    "    (\"I ain't feeling dandy today.\", 'neg'),\n",
    "    (\"I feel amazing!\", 'pos'),\n",
    "    ('Gary is a friend of mine.', 'pos'),\n",
    "    (\"I can't believe I'm doing this.\", 'neg')\n",
    "]\n",
    "\n",
    "with open(r\"C:\\Users\\ani\\Desktop\\Course data Thesis\\NBayeslog.txt\",\"a\",encoding = \"utf-8\") as oFile:\n",
    "    cl = NaiveBayesClassifier(train)\n",
    "    \n",
    "    \"\"\"\n",
    "    # Classify some text\n",
    "    print(\"The other notion is existential stability,which means there exists the flipped it's called an existential quantifier   ==>  \",bayes.classify(\"The other notion is existential stability,which means there exists the flipped it's called an existential quantifier \"))  # \"pos\"\n",
    "    print(\"In fact,like saw,we looked at a counter example that allowed us to actually destabilize,which means drive the state off to infinity,by being unlucky or unclever in how we transitioned in and out of the different modes    ==>> \",bayes.classify(\"In fact,like saw,we looked at a counter example that allowed us to actually destabilize,which means drive the state off to infinity,by being unlucky or unclever in how we transitioned in and out of the different modes \"))   # \"neg\"\n",
    "\n",
    "    # Classify a TextBlob\n",
    "    blob = TextBlob(\"And in the next lecture,we will see,first of all,why the tortoise is able to beat the hare and what to do about it,meaning how do you make the rabbit overtake the turtle  \"\n",
    "                    \"We know what the solution to this system is\", classifier=bayes)\n",
    "    print(blob)\n",
    "    print(blob.classify())\n",
    "\n",
    "    for sentence in blob.sentences:\n",
    "        print(sentence)\n",
    "        print(sentence.classify())\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Compute accuracy\n",
    "    accuracy = cl.accuracy(test)*100\n",
    "    oFile.write(\"Accuracy: {0:.2f} % \\n\".format(accuracy))\n",
    "    print(\"Accuracy: {0:.2f} %\".format(cl.accuracy(test)*100))\n",
    "\n",
    "    # Show 5 most informative features\n",
    "    cl.show_informative_features(5)\n",
    "    \n",
    "end = time.time()\n",
    "print(\"Execution time: {0:.3f} sec | {1:.5f} min\".format((end - start),(end - start)/60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
