{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(0.75) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-d9925cd403cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-d9925cd403cf>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mtrain_test_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.75\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_titles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0mpool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreateTokenPool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_titles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ani\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\model_selection\\_split.pyc\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2029\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2031\u001b[1;33m     \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2032\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2033\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ani\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ani\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \"\"\"\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m     \u001b[0mlengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ani\\Anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\utils\\validation.pyc\u001b[0m in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    117\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[1;32m--> 119\u001b[1;33m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[0;32m    120\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array array(0.75) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from prettyprint import *\n",
    "import os\n",
    "import re\n",
    "from datetime import datetime as dt\n",
    "from utils import *\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#index label in the dictionary\n",
    "idx_lbl = 'idx'\n",
    "dfreq_lbl = \"docfreq\"\n",
    "\n",
    "class NaiveBayes:\n",
    "    \"\"\"\n",
    "    This is an implementation of Naive Bayes classifier.\n",
    "    In the training phase, this classifier will learn the prior probability for each class\n",
    "    and also the conditional probability of each feature for each class.\n",
    "    After the training phase, it can easily predict the class label for a given input vector.\n",
    "    By calculating the posterior probability of each class for the given vector, input vector's\n",
    "    class label will be the label of the class having maximum posterior probability.\n",
    "    lbl = argmax_{k} p(C_k | x) === argmax_{k} p(x | C_k) * p(C_k)\n",
    "    \"\"\"\n",
    "    def __init__(self, class_labels, tdict):\n",
    "        \"\"\"\n",
    "        constructor will get a list of the class labels, a dictionary of terms (as created before).\n",
    "        Then, by calling the train function, probabilities will be learned from the training set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        class_labels: list\n",
    "                      list of class labels\n",
    "        tdict: dictionary\n",
    "               a dictionary of terms and number of occurences of term in each class\n",
    "        \"\"\"\n",
    "        self.k = len(class_labels)\n",
    "        self.priors = np.zeros((self.k, 1))             #prior probabilities for each class\n",
    "        self.cctermp = np.zeros((len(tdict), self.k))   #class conditional term probabilities\n",
    "        self.ctermcnt = np.zeros((self.k, 1))           # total number of terms in a class\n",
    "        self.lbl_dict = dict(zip(class_labels, range(self.k)))\n",
    "        self.class_labels = class_labels\n",
    "        self.tdict = tdict\n",
    "\n",
    "    def train(self, class_counts, tfidf_but_smoothing = True):\n",
    "        \"\"\"\n",
    "        this will learn the prior and class conditional probabilities for the set of documents\n",
    "        for learning class prior probabilities, it will use the class_counts list\n",
    "        for learning class conditional probabilities for each class, it will use the\n",
    "        term dictionary provided\n",
    "        Parameters\n",
    "        ----------\n",
    "        class_counts: list\n",
    "                      number of documents in each class\n",
    "        tfidf_but_smoothing: boolean\n",
    "                             if True, tfidf weighting will be used (ntn.ntn)\n",
    "                             if False, smoothing will be used\n",
    "        Returns\n",
    "        -------\n",
    "        \"\"\"\n",
    "        # First learn the prior probabilities\n",
    "\n",
    "        if len(class_counts) != len(self.priors):\n",
    "            print(\"error! number of classes don't match\")\n",
    "            return\n",
    "        for i in range(len(class_counts)):\n",
    "            self.priors[i, 0] = class_counts[0] * 1.0 / sum(class_counts)\n",
    "\n",
    "        # now learn the class conditional probabilities for each term\n",
    "        for term, data in self.tdict.items():\n",
    "            idx = data[idx_lbl]\n",
    "            for cl in self.lbl_dict.viewkeys():\n",
    "                if cl in data:\n",
    "                    self.cctermp[idx, self.lbl_dict[cl]] += data[cl]\n",
    "                    self.ctermcnt[self.lbl_dict[cl], 0] += data[cl]\n",
    "\n",
    "        # print self.cctermp\n",
    "\n",
    "        if not tfidf_but_smoothing:\n",
    "            for i in range(len(self.tdict)):\n",
    "                for j in range(self.k):\n",
    "                    self.cctermp[i,j] = (self.cctermp[i,j] + 1) * 1.0 / (self.ctermcnt[j] + len(self.tdict))\n",
    "        else:\n",
    "            for i in range(len(self.tdict)):\n",
    "                for j in range(self.k):\n",
    "                    if self.cctermp[i,j] > 0:\n",
    "                        self.cctermp[i,j] = (self.cctermp[i,j] + 1) * np.log(self.ctermcnt[j] * 1.0 / self.cctermp[i,j])\n",
    "\n",
    "    def predict(self, doc):\n",
    "        \"\"\"\n",
    "        this method will predict the label for the input document using the Naive Bayes classification method\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc: list\n",
    "             input document for which its label is going to be predicted, this argument should be provided as a list of tokens\n",
    "        Returns\n",
    "        -------\n",
    "        output: object\n",
    "                an element of the class_labels list\n",
    "        \"\"\"\n",
    "\n",
    "        doc_vec = self.__createVectorRepresentation(doc)\n",
    "\n",
    "        class_score = [0] * self.k\n",
    "        for i in range(self.k):\n",
    "            log_class_conditional = np.log(self.cctermp[:,i] + 1e-14)\n",
    "            class_score[i] = log_class_conditional.transpose().dot(doc_vec)[0] + np.log(self.priors[i,0])\n",
    "\n",
    "\n",
    "        return self.class_labels[class_score.index(max(class_score))]\n",
    "\n",
    "\n",
    "    def predictPool(self, doc_collection):\n",
    "        \"\"\"\n",
    "        this method will get a dictionary of collection of documents and predict their label.\n",
    "        Parameters\n",
    "        ----------\n",
    "        doc_collection: dictionary\n",
    "                        dictionary of collection of documents for which we want to predict their label\n",
    "        Returns\n",
    "        -------\n",
    "        lbl_pool: dictionary\n",
    "                  dictionary of collection of labels for each corresponding document will be returned\n",
    "        \"\"\"\n",
    "        lbl_pool = {}\n",
    "        for cl in self.class_labels:\n",
    "            lbl_pool[cl] = []\n",
    "            for doc in doc_collection[cl]:\n",
    "                lbl_pool[cl].append(self.predict(doc))\n",
    "\n",
    "        return lbl_pool\n",
    "\n",
    "    def __createVectorRepresentation(self, tokens_list):\n",
    "        \"\"\"\n",
    "        this method will create a vector space representation of the list of tokens provided\n",
    "        Parameters\n",
    "        ----------\n",
    "        tokens_list: list\n",
    "                     list of tokens all of whom which may or may not belong to the dictionary provided\n",
    "        Returns\n",
    "        -------\n",
    "        vec: np.ndarray\n",
    "             vector as a numpy array of size (len(tdict), 1) for which every row shows the number of\n",
    "             times a token has appeared in a given document\n",
    "        \"\"\"\n",
    "        vec = np.zeros((len(self.tdict), 1), dtype=np.int8)\n",
    "        for token in tokens_list:\n",
    "            if token in self.tdict:\n",
    "                vec[self.tdict[token][idx_lbl], 0] += 1\n",
    "        return vec\n",
    "\n",
    "\n",
    "def calculateMetrics(class_labels, lbl_pool):\n",
    "    \"\"\"\n",
    "    this method will calculate the tp, tn, fp, fn metrics for each class\n",
    "    of documents from the pool labels provided\n",
    "        tp: number of documents in the class that are correctly labeled as belonging to class\n",
    "        tn: number of documents not in the class that are correctly labeled as not belonging to class\n",
    "        fp: number of documents not in the class that are incorrectly labeled as belonging to class\n",
    "        fn: number of documents in the class that are incorrectly labeled as not belonging to class\n",
    "    Parameters\n",
    "    ----------\n",
    "    class_labels: dictionary\n",
    "                  labels of the classes\n",
    "    lbl_pool: dictionary\n",
    "              dictionary of lists of labels\n",
    "    Returns\n",
    "    -------\n",
    "    metrics: dictionary\n",
    "             dictionary of dictionaries of metrics for each class\n",
    "    \"\"\"\n",
    "    metrics = {}\n",
    "    for cl in class_labels:\n",
    "        metrics[cl] = {}\n",
    "        tp = 0\n",
    "        tn = 0\n",
    "        fp = 0\n",
    "        fn = 0\n",
    "        for lbl in lbl_pool[cl]:\n",
    "            if lbl == cl:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        for ncl in class_labels:\n",
    "            if ncl != cl:\n",
    "                for lbl in lbl_pool[ncl]:\n",
    "                    if lbl == cl:\n",
    "                        fn += 1\n",
    "                    else:\n",
    "                        tn += 1\n",
    "\n",
    "        metrics[cl][\"tp\"] = tp\n",
    "        metrics[cl][\"tn\"] = tn\n",
    "        metrics[cl][\"fp\"] = fp\n",
    "        metrics[cl][\"fn\"] = fn\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def main():\n",
    "\n",
    "    root_path = r\"D:\\Ani's Documents\\~ Documents ~\\TUDelft\\~ Lectures and Homeworks\\~ MSc THESIS\\CODE\\20 Newsgoup data set\"\n",
    "    #top_view folders\n",
    "    folders = [root_path + \"\\\\\" + folder + \"\\\\\" for folder in os.listdir(root_path)]\n",
    "\n",
    "    #there are only 4 classes\n",
    "    class_titles = os.listdir(root_path)\n",
    "\n",
    "\n",
    "    #list of all the files belonging to each class\n",
    "    files = {}\n",
    "    for folder, title in zip(folders, class_titles):\n",
    "        files[title] = [folder + f for f in os.listdir(folder)]\n",
    "\n",
    "    train_test_ratio = 0.75\n",
    "\n",
    "    train, test = train_test_split(train_test_ratio, class_titles, files)\n",
    "\n",
    "    pool = createTokenPool(class_titles, train)\n",
    "    print(len(pool[class_titles[0]]))\n",
    "    tdict = createDictionary(class_titles, pool)\n",
    "    print(len(tdict))\n",
    "\n",
    "    dumbBayes = NaiveBayes(class_titles, tdict)\n",
    "    class_count = [len(train[cl]) for cl in class_titles]\n",
    "\n",
    "    start = dt.now()\n",
    "    dumbBayes.train(class_count, False)\n",
    "    end = dt.now()\n",
    "\n",
    "    print('elapsed time for training the Naive Bayes')\n",
    "    print(end - start)\n",
    "\n",
    "    id = 1\n",
    "    start = dt.now()\n",
    "    lbl = dumbBayes.predict(tokenizeDoc(test[class_titles[id]][3]))\n",
    "    end = dt.now()\n",
    "\n",
    "    print('elapsed time for testing Naive Bayes')\n",
    "    print(end - start)\n",
    "    print(lbl == class_titles[id])\n",
    "\n",
    "    test_pool = createTokenPool(class_titles, test)\n",
    "    start = dt.now()\n",
    "    test_lbl_pool = dumbBayes.predictPool(test_pool)\n",
    "    end = dt.now()\n",
    "\n",
    "    print('elapsed time for testing a pool of documents')\n",
    "    print(end - start)\n",
    "\n",
    "    metrics = calculateMetrics(class_titles, test_lbl_pool)\n",
    "    total_F = 0\n",
    "    for cl in class_titles:\n",
    "        print(cl)\n",
    "        P = (metrics[cl][\"tp\"] * 1.0 / (metrics[cl][\"tp\"] + metrics[cl][\"fp\"]))\n",
    "        R = (metrics[cl][\"tp\"] * 1.0 / (metrics[cl][\"tp\"] + metrics[cl][\"fn\"]))\n",
    "        Acc = ((metrics[cl][\"tp\"] + metrics[cl][\"tn\"])* 1.0 / (metrics[cl][\"tp\"] + metrics[cl][\"fp\"] + metrics[cl][\"fn\"] + metrics[cl][\"tn\"]))\n",
    "        F_1 = 2 * R * P / (R + P)\n",
    "        total_F += F_1\n",
    "        print('precision = ', P)\n",
    "        print('recall = ', R)\n",
    "        print('accuracy = ', Acc)\n",
    "        print(' ')\n",
    "\n",
    "    print('macro-averaged F measure', (total_F / len(class_titles)))\n",
    "\n",
    "\n",
    "    # saveDictToFile(tdict, 'dictionary.csv')\n",
    "    #\n",
    "    # redict = readFileToDict('dictionary.csv')\n",
    "    # print len(redict)\n",
    "    #\n",
    "    # print redict == tdict\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
