{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### ----------------------------------------------------------------------------------------------------------------------------------\n",
    "## Plan of action\n",
    "- grab sentence by sentence file\n",
    "- split each sentence in n-grams (1-2-3-4)\n",
    "- compare n-grams with dictionary\n",
    "- if n-gram is contained in any of the dictionaries, grab the whole sentence and mark is as the respective \\_\\_label\\_\\_='whatever'\n",
    "    - if more than one label can be assigned, assign them both\n",
    "    - if a label is already assigned, assign the next one too and raise a message\n",
    "- compare sentences, if they contain equivalent labels, merge them into a paragraph and put the label on it. Do until we reach a sentence with a different labels\n",
    "\n",
    "This will be the **TRAIN data**\n",
    "\n",
    "**TEST data** will be 2-3 more courses I will find in coursera and split the same way as my current data, \n",
    "will learn a classifier with it and try to classify them\n",
    "\n",
    "### Whats and Whys\n",
    "- ***Overall goal***: to create a labeled training set, but not by evaluating it manually more than selecting terms to look for\n",
    "- ***N-gram extraction***: To help find the dictionary terms\n",
    "- ***Keywords extraction from title***: to help figure out the main topic of the LO\n",
    "\n",
    "##### Next steps\n",
    "* After finding and matching the n-grams as per sentences, I will add the respective label to the end of the sentence with a PIPE | before. \n",
    "* Then will split each sentence by the PIPEs and save into a list. \n",
    "* Then if a sentence has one item in the list, i.e. only sentence, that means it will have no label. If it has 2 elements in the list, that means it has one label if it has 3 elements - 2 labels etc. \n",
    "    * if it has no label - adopt the label that the first sentence above it has, go from that sentence up until a label is found and assign it\n",
    "        * if the sentence above has one label, adopt it\n",
    "        * if 2 labels - do nothing\n",
    "    * if one label - good\n",
    "    * if 2 labels - manual check and leave one\n",
    "    \n",
    "### ----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Import all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import all necessary modules for EVERYTHING here\n",
    "import os\n",
    "import sys\n",
    "import os.path\n",
    "import string\n",
    "import time\n",
    "import re\n",
    "\n",
    "import math\n",
    "from textblob import TextBlob as tb\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.util import ngrams\n",
    "\n",
    "import re, string, unicodedata\n",
    "import contractions\n",
    "import inflect\n",
    "from bs4 import BeautifulSoup\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionary terms for my 5 classes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conceptdescr_dict = ['this research','refers to','last but not least','number one',\n",
    "                     'number two','number three','drawback','advantages',\n",
    "                     'disadvantages','benefits','drawbacks','defined',\n",
    "                     'there are many types','important to understand',\n",
    "                     'let\\'s look at','when we use the term','imagine that',\n",
    "                     'refers to as','key concepts','this is a term','more specifically',\n",
    "                     'helps to','is used to','makes it easier to',\n",
    "                     'provide information about','when talking about','critical to understand',\n",
    "                     'let\\'s take a look at','crucial','can be used to','ensures',\n",
    "                     'rule of thumb','consider','last but not least','topic of this',\n",
    "                     'topic of today','one way to','another possibility is',\n",
    "                     'next one is','problem','to address','want to do','different ways',\n",
    "                     'approach is to','tries to','try to','topic is','method','task',\n",
    "                     'in this why','we specify','by combining','results','because','due to',\n",
    "                     'in other words','in fact','means','done through','implies']\n",
    "\n",
    "conceptmention_dict = ['called','use the term','more specifically','this includes',\n",
    "                       'activities surrounding','show you','additionally','should include',\n",
    "                       'types of','recommends','known as','known for','advantages to',\n",
    "                       'disadvantages to','benefits','drawbacks','plays a key role',\n",
    "                       'refers to as','first one is','we introduce','techniques',\n",
    "                       'second one is','traditional','method','-based','what\\'s', 'what is',\n",
    "                       'says']\n",
    "\n",
    "application_dict = ['best practices','best practice','means that','practical benefit',\n",
    "                    'sorts of things','good practices','best to','you should','you shouldn\\'t',\n",
    "                    'may find that','can use','this is important','particularly importnant',\n",
    "                    'is why','useful to','recommended that','consider','useful to','instead',\n",
    "                    'tips','tip','advice','advised','encourage','experiment','explore']\n",
    "\n",
    "example_dict = ['example','there are many','many types','include','can see','hands on',\n",
    "                'includes','exemplar','prototype','sample','case','illustration','analogy',\n",
    "                'let\\'s think of','may want to','some of','most of','different types of',\n",
    "                'e.g.','for example','key aspects','key concepts','in other words',\n",
    "                'of these are','of them are','rather than','such as','pros and cons',\n",
    "                'a long list','various','for instance','it\\'s like','different ways',\n",
    "                'tried to','instead of','say','challenge','assume']\n",
    "\n",
    "summary_dict = ['by the end of','as you know','have a good understanding','will begin by',\n",
    "                'will cover','well delve','will discuss','will be able to','will understand',\n",
    "                'to summarize','summary','take away','to conclude','as you know','introduced',\n",
    "                'be aware','we\\'ve looked at','last week we discussed','discuss how to',\n",
    "                'will describe','the goal','know that','step','first','second','third',\n",
    "                'finally','next','consideting','can see','we\\'ve seen','learned','recall',\n",
    "                'remember','last time']\n",
    "\n",
    "ignore_dict = ['inaudible','OMITTED','NUMBER','sound','music','laughter','yeah','blank_audio']\n",
    "\n",
    "### ------------------------ RULES -----------------------------\n",
    "\n",
    "def rule_example(texttomatch):\n",
    "    sentences = texttomatch.split('\\n')\n",
    "    res = \"\"\n",
    "\n",
    "    csvregex2 = r'(?i)(?:(\\b[a-z]+\\b)[,}])'\n",
    "    wordsregex = r'(includ|some|such as|example)'\n",
    "\n",
    "    for sent in sentences:\n",
    "        rescsv = re.findall(csvregex1, sent)\n",
    "        reswords = re.findall(wordsregex, sent)\n",
    "\n",
    "        if(len(reswords) > 0 and len(rescsv) > 1):\n",
    "            res += sent+\"|_Example_\\n\"\n",
    "        else:\n",
    "            res += sent+\"\\n\"\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def rule_concMention(texttomatch):\n",
    "    sentences = texttomatch.split('\\n')\n",
    "    res = \"\"\n",
    "\n",
    "    csvregex2 = r'(?i)(?:(\\b[a-z]+\\b)[,}])'\n",
    "    wordsregex = r'(recommend|key aspect|types of|principles|principle)'\n",
    "\n",
    "    for sent in sentences:\n",
    "        rescsv = re.findall(csvregex1, sent)\n",
    "        reswords = re.findall(wordsregex, sent)\n",
    "\n",
    "        if(len(reswords) > 0 and len(rescsv) > 1):\n",
    "            res += sent+\"|_ConceptMention_\\n\"\n",
    "        else:\n",
    "            res += sent+\"\\n\"\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "# CHECK THIS https://www.nodebox.net/code/index.php/Linguistics#verb_conjugation\n",
    "def isPastTense(texttomatch):\n",
    "    # if sentences have past tense verbs AND are in the first 10 rows of the file,\n",
    "    # they are likely to be labeled as SUMMARY \n",
    "    print(\"isPastTense()\")\n",
    "    \n",
    "def isFutureTense(texttomatch):\n",
    "    # if sentences have future tense verbs and WILL AND are in the last 10 rows of the file,\n",
    "    # they are likely to be labeled as SUMMARY\n",
    "    print(\"isPastTense()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Trying to find n-grams in the dictionary\n",
    "\n",
    "- Very unsure with monograms - lots of matches with simple stopwords, some of them make sense, but very few.\n",
    "- Very little found with trigrams, but if found - it's good\n",
    "- Bigrams should work good, but not too good\n",
    "- Tetragrams give no result whatsoever, also because there are very few items in the dictionaries that have 4 words to match with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### Dummy text to play with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### WITHOUT STOP WORDS\n",
    "\n",
    "textnoSW = \"\"\"music hello 'm good to see back our course \n",
    "before start with this video let me remind what has been covered earlier videos \n",
    "by should have an idea of what an embedded processor how it works \n",
    "should also be familiar with features of an embedded processor \n",
    "must remind again this course make emphasis on microcontrollers \n",
    "therefore large field of embedded processors reduced to only microcontrollers \n",
    "after learn about microcontrollers next step would be to somehow put your hands on them start actually working with them \n",
    "one way to do so to buy microcontroller breadboard set of resistors capacitors wires whatever else necessary to build proper electrical circuits assemble all circuits by yourself on breadboard \n",
    "well it does n't sound cool because it 's long process \n",
    "know there always one resistor need missing end there will be little motivation to continue playing with microcontrollers \n",
    "luckily there another option to buy ready made platform with mounted microcontroller to start working with it immediately \n",
    "this video 're going to talk about these platforms \n",
    "let 's start with arduino \n",
    "arduino widely known platform for fast prototyping \n",
    "platform uses atmel microcontrollers at its core \n",
    "overall there are about 24 boards available \n",
    "on website can find them organized according to application areas such as internet of things wearable others \n",
    "besides boards there are many shields built specifically for our arduino devices \n",
    "functionality of these shields vary lot \n",
    "for example with an mp3 shield can build your own mp3 player if need one \n",
    "wi-fi shield great tool to build applications let 's say domain of internet of things \n",
    "joystick shield suitable for control purposes \n",
    "so if want to extend functionality of board your application can plug shield \n",
    "luckily it can easily be done thanks to sockets installed arduino \n",
    "arduino also provides its own integrated development environment for software development which easy to use really speeds up development process \n",
    "second platform would like to mention stm nucleo platform \n",
    "at its core there are stx complex cortex microcontrollers from m0 to m4 \n",
    "so can choose here between speed energy consumption \n",
    "boards also have extension connectors connectors are compatible with arduino shields which very convenient \n",
    "also there so-called morpho connector for other kind of shields \n",
    "very convenient feature of this platform programmer/debugger mounted on board \n",
    "there an online id available for this platform as well as whole set of tools including operating system tools developer ecosystem for building internet of things solutions \n",
    "offline ides are also available \n",
    "they are more complex than arduino 's one but they give more freedom to developer \n",
    "would say this platform for more experienced users \n",
    "here mentioned two kinds of general purpose platforms can be extended with help of shields to target some specific areas \n",
    "there are of course more platforms available on market \n",
    "some of them target one specific area might not be extensible \n",
    "so there legit question might have \n",
    "how do select certain platform from this diversity \n",
    "first of all choice obviously should be application-oriented \n",
    "for example if want to do some digital signal processing might want to use microcontroller supports some dsp operations \n",
    "if need high computational power then cortex m4 or cortex m3 microcontrollers would suit well since they have highest clock frequency among previous mentioned mcus \n",
    "therefore your choice would be either arduino due or stm nuclear cortex m4 m3 \n",
    "if small size crucial for there no need of high performance then probably want to check arduino micro \n",
    "it also important to consider platforms are interchangeable sense same application can be implemented on two different platforms \n",
    "something would like to emphasize community crucial when it comes to choosing platform \n",
    "bigger community more likely problems might face have already been solved by someone else which case can probably find answer internet \n",
    "would like to show real project was implemented using microcontrollers \n",
    "it metering system \n",
    "imagine have tube there some liquid flowing through tube \n",
    "goal of system to measure liquid 's flow speed \n",
    "since know size of tube need to calculate volume of liquid during time interval \n",
    "finally need to store those measurements memory \n",
    "what more device should have user interface like keyboard small screen \n",
    "so where to start \n",
    "well start by dividing tasks two components metering unit control unit \n",
    "next thing to do would be to decide how to measure liquid flow speed \n",
    "this can be done using ultrasound \n",
    "need to emit an ultrasonic sound receive it back do some spectral analysis to estimate liquid flow speed \n",
    "do n't worry if do n't understand what spectral analysis \n",
    "here what want to show approach \n",
    "so need to do some digital signal processing to get liquid flow speed \n",
    "after get those measurements do some simple averaging finally store those processed measurements \n",
    "okay so have set of tasks signal processing averaging storing user interface \n",
    "it would make sense to map set of tasks onto two microcontrollers \n",
    "let 's say signal processing will be done on mcu 1 will call this part metering unit \n",
    "other tasks will run on control unit which will be implemented on mcu2 \n",
    "both parts will be connected together using uart interface \n",
    "since mcu1 does spectral analysis cortex m4 microcontroller would suit well since it has dsp extensions \n",
    "will also need an adc to sample ultrasonic signal \n",
    "on other hand mcu2 does not need to support dsp operations \n",
    "but it need to be fast enough to communicate with screen keyboard while doing averaging at same time \n",
    "it should have enough pins to work with keyboard at least two uart units to work with screen to communicate with metering unit \n",
    "cortex m3 would fit well \n",
    "it useful to leave some room for expansion \n",
    "this means might want to have some extra functionality to device future \n",
    "therefore selected microcontrollers should have enough resources terms of performance memory \n",
    "finally it important to notice system can be implemented many other ways \n",
    "this video discussed ways on how to actually start working with microcontrollers using platforms \n",
    "hopefully have an idea of how to pick an appropriate platform for your application \n",
    "good luck \n",
    "sound \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## N-GRAM & RULES IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "##### --------------------- RULES to look for specific patterns ----------------------- ######\n",
    "\n",
    "def rule_example(texttomatch):\n",
    "    sentences = texttomatch.split('\\n')\n",
    "    res = \"\"\n",
    "\n",
    "    csvregex2 = r'(?i)(?:(\\b[a-z]+\\b)[,}])'\n",
    "    wordsregex = r'(includ|some|such as|example)'\n",
    "\n",
    "    for sent in sentences:\n",
    "        rescsv = re.findall(csvregex1, sent)\n",
    "        reswords = re.findall(wordsregex, sent)\n",
    "        \n",
    "        #if both patterns return result then we can label the sentence\n",
    "        if(len(reswords) > 0 and len(rescsv) > 1):\n",
    "            res += sent+\"|_example_\\n\"\n",
    "        else:\n",
    "            res += sent+\"\\n\"\n",
    "            \n",
    "    return res\n",
    "\n",
    "\n",
    "def rule_concmention(texttomatch):\n",
    "    sentences = texttomatch.split('\\n')\n",
    "    res = \"\"\n",
    "\n",
    "    csvregex2 = r'(?i)(?:(\\b[a-z]+\\b)[,}])'\n",
    "    wordsregex = r'(recommend|key aspect|types of|principles|principle)'\n",
    "\n",
    "    for sent in sentences:\n",
    "        rescsv = re.findall(csvregex1, sent)\n",
    "        reswords = re.findall(wordsregex, sent)\n",
    "\n",
    "        #if both patterns return result then we can label the sentence\n",
    "        if(len(reswords) > 0 and len(rescsv) > 1):\n",
    "            res += sent+\"|_conceptmention_\\n\"\n",
    "        else:\n",
    "            res += sent+\"\\n\"\n",
    "            \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ---------------------------------------------- Label sentences ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def search_grams(sent,grams,dictionary,label):\n",
    "    for gr in grams:\n",
    "        for item in dictionary:\n",
    "            if gr in item:\n",
    "                # if no labels are added or if there are labels but not the current one, proceed\n",
    "                if (nr_labels(sent) > 0 and label_in(sent, label) == False) or (nr_labels(sent) == 0):\n",
    "                    lbl = \"|_\"+label+\"_\"\n",
    "                    sent += lbl\n",
    "                    return sent+lbl\n",
    "                    #print(\"GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+lbl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#### WORKS\n",
    "\n",
    "def get_ngrams(text, n):\n",
    "    n_grams = ngrams(word_tokenize(text), n)\n",
    "    return [' '.join(grams) for grams in n_grams]\n",
    "\n",
    "def label_sentences(sentenceList):\n",
    "    sentences = sentenceList\n",
    "    sent_processed = []\n",
    "    \n",
    "    for sent in sentences:\n",
    "        #Split each senetnce to bi- and tri- grams\n",
    "        bigrams = get_ngrams(sent, 2)\n",
    "        trigrams = get_ngrams(sent, 3)\n",
    "        \n",
    "        #print(len(bigrams),\" | \", len(trigrams))\n",
    "        # ---- bi-grams\n",
    "        \n",
    "        search_grams(sent,bigrams,conceptdescr_dict,\"conceptdescription\")\n",
    "        \n",
    "        \n",
    "        for gr in bigrams:\n",
    "            for item in example_dict:\n",
    "                if gr in item:\n",
    "                    print(\"looking for label: example: {}\".format(label_in(sent, \"example\")))\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"example\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_example_\"\n",
    "                        sent_processed.append(sent+\"|_example_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" | SENT {}.\".format(gr,sent+\"|_example_\"))\n",
    "\n",
    "            for item in conceptmention_dict:\n",
    "                if gr in item:\n",
    "                    print(\"looking for label: conceptmention: {}\".format(label_in(sent, \"conceptmention\")))\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"conceptmention\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_conceptmention_\"\n",
    "                        sent_processed.append(sent+\"|_conceptmention_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+\"|_conceptdescription_\"))\n",
    "\n",
    "            for item in application_dict:\n",
    "                if gr in item:\n",
    "                    print(\"looking for label: application: {}\".format(label_in(sent, \"application\")))\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"application\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_application_\"\n",
    "                        sent_processed.append(sent+\"|_application_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+\"|_application_\"))\n",
    "\n",
    "            for item in summary_dict:\n",
    "                if gr in item:\n",
    "                    print(\"looking for label: summary: {}\".format(label_in(sent, \"summary\")))\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"summary\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_summary_\"\n",
    "                        sent_processed.append(sent+\"|_summary_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+\"|_summary_\"))\n",
    "\n",
    "        # ---- tri-grams\n",
    "        for gr in trigrams:\n",
    "            for item in conceptdescr_dict:\n",
    "                if gr in item:\n",
    "                    # if no labels are added or if there are labels but not the current one, proceed\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"conceptdescription\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_conceptdescription_\"\n",
    "                        sent_processed.append(sent+\"|_conceptdescription_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+\"|_conceptdescription_\"))\n",
    "\n",
    "            for item in example_dict:\n",
    "                if gr in item:\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"example\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_example_\"\n",
    "                        sent_processed.append(sent+\"|_example_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" | SENT {}.\".format(gr,sent+\"|_example_\"))\n",
    "                    \n",
    "            for item in conceptmention_dict:\n",
    "                if gr in item:\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"conceptmention\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_conceptmention_\"\n",
    "                        sent_processed.append(sent+\"|_conceptmention_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+\"|_conceptdescription_\"))\n",
    "                    \n",
    "            for item in application_dict:\n",
    "                if gr in item:\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"application\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_application_\"\n",
    "                        #sent_processed.append(sent+\"|_application_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+\"|_application_\"))\n",
    "                    \n",
    "            for item in summary_dict:\n",
    "                if gr in item:\n",
    "                    if (nr_labels(sent) > 0 and label_in(sent, \"summary\") == False) or (nr_labels(sent) == 0):\n",
    "                        sent += \"|_summary_\"\n",
    "                        sent_processed.append(sent+\"|_summary_\")\n",
    "                        #print(\"2-GRAM \\\"{}\\\" in SENT {}.\".format(gr,sent+\"|_summary_\"))\n",
    "        \n",
    "            if (nr_labels(sent) == 0) and (sent not in sent_processed):\n",
    "                sent_processed.append(sent)\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    for sent in sent_processed:\n",
    "        print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_grams_inDict1(gramsList,sentenceList):\n",
    "    sentences = sentenceList\n",
    "    \n",
    "# TODO - make it label each sentence at the end once an dictionary term is found. \n",
    "    for sent in sentences: \n",
    "        for gram in gramsList:\n",
    "            for item in conceptdescr_dict:\n",
    "                if gram in item:\n",
    "                    print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _ConceptDescription_\".format(gram, item))\n",
    "                    sent += \"|_conceptdescription_\"\n",
    "\n",
    "            for item in example_dict:\n",
    "                if gram in item:\n",
    "                    print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _example_\".format(gram, item))\n",
    "                    for sent in sentences:\n",
    "                        if gram in sent:\n",
    "                            sent += \"|_example_\"\n",
    "\n",
    "            for item in conceptmention_dict:\n",
    "                if gram in item:\n",
    "                    print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _conceptmention_\".format(gram, item))\n",
    "                    for sent in sentences:\n",
    "                        if gram in sent:\n",
    "                            sent += \"|_conceptmention_\"\n",
    "\n",
    "            for item in application_dict:\n",
    "                if gram in item:\n",
    "                    print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _application_\".format(gram, item))\n",
    "                    for sent in sentences:\n",
    "                        if gram in sent:\n",
    "                            sent += \"|_application_\"\n",
    "\n",
    "            for item in summary_dict:\n",
    "                if gram in item:\n",
    "                    print(\"========= FOUND \\\"{}\\\" IN \\\"{}\\\" \\t|LABEL|\\t _summary_\".format(gram, item))\n",
    "                    for sent in sentences:\n",
    "                        if gram in sent:\n",
    "                            sent += \"|_summary_\"\n",
    "                        \n",
    "    for sent in sentences:\n",
    "        print(sent)\n",
    "                        \n",
    "# ------------------------------------------------------------------------------------------\n",
    "                \n",
    "def find_grams_inDict2(gramsList1,gramsList2,sentenceList):\n",
    "    print(\"_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList1,sentenceList)\n",
    "    print(\"\\n_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList2,sentenceList)\n",
    "    \n",
    "\n",
    "def find_grams_inDict3(gramsList1,gramsList2,gramsList3,sentenceList):\n",
    "    print(\"_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList1,sentenceList)\n",
    "    print(\"\\n_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList2,sentenceList)\n",
    "    print(\"\\n_____________________________________________________________________\\n\")\n",
    "    find_grams_inDict1(gramsList3,sentenceList)\n",
    "    \n",
    "    \n",
    "# check how many labels this sentence has assigned\n",
    "def nr_labels(sentence):\n",
    "    parts = sentence.split(\"|\")\n",
    "    partsSize = len(parts)\n",
    "    \n",
    "    if partsSize == 0: return -1\n",
    "    elif(partsSize == 1): return 0    \n",
    "    elif(partsSize == 2): return 1\n",
    "    elif(partsSize == 3): return 2\n",
    "    elif(partsSize == 4): return 3\n",
    "    elif(partsSize == 5): return 4\n",
    "    elif(partsSize == 6): return 5\n",
    "    \n",
    "\n",
    "# check if a certain label is part of the sentence\n",
    "def label_in(sentence, labelin):\n",
    "    parts = sentence.split('|')\n",
    "    \n",
    "    label = \"_\"+labelin+\"_\"\n",
    "    \n",
    "    for i in range(0,len(parts)):\n",
    "        if label in parts[i]:\n",
    "            return True\n",
    "        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Extracting N-Grams and matching title keywords to real files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def title_extrKeys(curFilePath):\n",
    "    titleinx = len(curFilePath.split(\"\\\\\"))-1\n",
    "    fullTitle = curFilePath.split(\"\\\\\")[titleinx]\n",
    "    \n",
    "    # remove all surrounding stuff like my naming convention etc from the title \n",
    "    mainTitlelist = fullTitle.split(\"_\")\n",
    "    maintitle = mainTitlelist[1]\n",
    "    punct = {'_','-','.'}\n",
    "    finaltitle = \"\"\n",
    "    \n",
    "    # extract the final title, i.e. the main part of the title\n",
    "    for word in maintitle.split():\n",
    "        for letter in word:\n",
    "            if letter in punct:\n",
    "                finaltitle += \" \"\n",
    "                pass\n",
    "            else:\n",
    "                finaltitle += letter\n",
    "    \n",
    "    title_keywords = []\n",
    "    for word in finaltitle.split(\" \"):\n",
    "        if word == 'en':\n",
    "             pass\n",
    "        else:\n",
    "            title_keywords.append(word)\n",
    "    \n",
    "    return title_keywords  # returns a list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#path = r\"C:\\Users\\ani\\Desktop\\Course data Thesis\\PROCESSED\\data-management - TRAIN\"\n",
    "#path = r\"C:\\Users\\ani\\Desktop\\Course data Thesis\\one file\"\n",
    "path = r\"C:\\Users\\a.dimitrova\\Desktop\\Course data Thesis\\one file\"\n",
    "\n",
    "for root, subdirs, files in os.walk(path):\n",
    "\n",
    "    for curFile in os.listdir(root):\n",
    "\n",
    "        curFilePath = os.path.join(root, curFile)\n",
    "\n",
    "        if os.path.isdir(curFilePath):\n",
    "            pass\n",
    "\n",
    "        else:\n",
    "            if not curFilePath.endswith(\"_sentNoPunctEnchancedNoSWTiny.txt\"):\n",
    "                pass\n",
    "            else: \n",
    "                curFile = open(curFilePath, 'r', encoding = \"ISO-8859-1\") #IMPORTANT ENCODING! UTF8 DOESN'T WORK\n",
    "                oFilePath = str(curFilePath.split(\".en\")[0])+\".en_BoWv2Top50.txt\"\n",
    "                \n",
    "                # extract keywords from the title of the file\n",
    "                title_keywords = title_extrKeys(curFilePath)\n",
    "                \n",
    "                # convert the file content into a string variable holding everything there\n",
    "                #fulltext = curFile.read()\n",
    "                sentences = curFile.read().split(\"\\n\")\n",
    "                text = \"\"\n",
    "                for sent in sentences:\n",
    "                    text += sent+\"\\n\"\n",
    "                \n",
    "                # label sentences with rules\n",
    "                text = rule_example(text)   # look for _Example_ sentence\n",
    "                text = rule_concMention(text)    # look for _ConceptMention_ sentence\n",
    "                #print(text)\n",
    "                \n",
    "                # look for title keywords within the text\n",
    "                for keyword in title_keywords:\n",
    "                    for sent in sentences:\n",
    "                        if keyword in sent:\n",
    "                            outp = str(\"<<\"+keyword+\">> FOUND IN <<\"+sent+\">>\").strip()\n",
    "                            print(outp.strip())\n",
    "                    \n",
    "                # extract n-grams\n",
    "                MonoGrams = get_ngrams(text,1)\n",
    "                BiGrams = get_ngrams(text,2)\n",
    "                TriGrams = get_ngrams(text,3)\n",
    "\n",
    "                # look for grams in text\n",
    "                find_grams_inDict2(BiGrams, TriGrams, sentences)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "looking for label: example: False\n",
      "looking for label: example: False\n",
      "looking for label: example: True\n",
      "looking for label: conceptmention: False\n",
      "looking for label: example: False\n",
      "looking for label: summary: False\n",
      "looking for label: summary: True\n",
      "looking for label: summary: True\n",
      "looking for label: summary: True\n",
      "\n",
      "\n",
      "\n",
      "a big advantage of creating or saving your research data principle a text format file can be read a plain text editor, like windows notepad, \n",
      "examples human-readable such as apples, oranges, potatoes etc. |_example_|_example_\n",
      "they can be opened any operating system by a wide range of applications. \n",
      "some of well-known file types of extensions including of plain text files are.txt,.csv,.asc,.html, and.xml.|_example_|_example_\n",
      "some of well-known file types of extensions including of plain text files are.txt,.csv,.asc,.html, and.xml.|_example_|_conceptmention_|_conceptmention_\n",
      "most software packages allow export exchange formats, so can create a text file for import into another program. \n",
      "ISPCA recommends using items like broom, stick, pen, pencil \n",
      "key aspects of using items are good translation, good salary, respect whatever else. |_example_|_example_\n",
      "as you know we will study in this lecture tralala|_summary_|_summary_\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: generator 'ngrams' raised StopIteration\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nsentences = texttomatch.split(\\'\\n\\')\\nfor sent in sentences:\\n    if sent.strip():  # if sentence is not a blank line, proceed, else skip\\n        print(\"# of Labels: \",nr_labels(sent))\\n        print(sent)\\n'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1,2,3,4 grams\n",
    "\n",
    "\"\"\"\n",
    "search for part of string in a string as:\n",
    "\n",
    "searchFor = 'THIS'.lower()\n",
    "for item in conceptmention_dict:\n",
    "    if searchFor in item:\n",
    "        print(\"found \\\"{}\\\" in \\\"{}\\\"\".format(searchFor,item))\n",
    "   \n",
    "just as a caution, if you have a string \"paratyphoid is bad\" \n",
    "and you do a if \"typhoid\" in \"paratyphoid is bad\" you will get a true\n",
    "\"\"\"\n",
    "\n",
    "searchFor = 'based'.lower()\n",
    "\n",
    "\"\"\"\n",
    "for item in conceptmention_dict:\n",
    "    if searchFor in item:\n",
    "        print(item+\" __label__=example\")\n",
    "\"\"\"     \n",
    "#csvregex1 = r'((?<!^,)\\w+(,(?!$)|$))+'\n",
    "\n",
    "# for set of rules: \n",
    "# apply every rule on every sentence \n",
    "# if there's a match, return TRUE, if TRUE, append the label at the end of the sentence\n",
    "        \n",
    "texttomatch = \"\"\"a big advantage of creating or saving your research data principle a text format file can be read a plain text editor, like windows notepad, \n",
    "examples human-readable such as apples, oranges, potatoes etc. \n",
    "they can be opened any operating system by a wide range of applications. \n",
    "some of well-known file types of extensions including of plain text files are.txt,.csv,.asc,.html, and.xml.\n",
    "most software packages allow export exchange formats, so can create a text file for import into another program. \n",
    "ISPCA recommends using items like broom, stick, pen, pencil \n",
    "key aspects of using items are good translation, good salary, respect whatever else. \n",
    "as you know we will study in this lecture tralala\n",
    "\"\"\"\n",
    "\n",
    "#texttomatch = rule_example(texttomatch)   # look for _Example_ sentence\n",
    "#texttomatch = rule_concMention(texttomatch)    # look for _ConceptMention_ sentence\n",
    "\n",
    "sentences = texttomatch.split(\"\\n\")\n",
    "\n",
    "label_sentences(sentences)\n",
    "\n",
    "#split sentence to label and sentence itself.\n",
    "\n",
    "\"\"\"\n",
    "sentences = texttomatch.split('\\n')\n",
    "for sent in sentences:\n",
    "    if sent.strip():  # if sentence is not a blank line, proceed, else skip\n",
    "        print(\"# of Labels: \",nr_labels(sent))\n",
    "        print(sent)\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
